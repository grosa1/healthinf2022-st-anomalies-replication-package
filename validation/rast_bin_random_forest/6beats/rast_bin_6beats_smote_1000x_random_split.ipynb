{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 6 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3      dw_4      dw_5     mfw_1  \\\n0  e0106  21.861233  21.421103  21.536569  6.108208  0.880920  1.079942   \n1  e0106  26.408089  27.988299  27.611772  7.776970  1.129695  1.195165   \n2  e0106  25.977641  26.935251  26.561891  7.477219  1.098311  1.176663   \n3  e0106  25.189643  25.649484  25.620624  7.261496  1.066191  1.162694   \n4  e0106  24.659920  24.559022  24.462891  6.972141  1.008067  1.143318   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.914392 -1.844370 -1.138702  ... -0.068189  0.053454 -0.067161  0.067961   \n1 -0.806390 -1.774080 -1.792590  ... -0.031130  0.017521 -0.014034  0.023165   \n2 -0.849446 -1.805917 -1.623971  ... -0.025147  0.006059 -0.022267  0.043209   \n3 -0.825414 -1.684836 -1.477246  ... -0.040045  0.024580 -0.029490  0.040770   \n4 -0.881397 -1.797336 -1.316414  ... -0.064038  0.044904 -0.045340  0.042700   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.093129  0.027961 -0.038417 -0.011442  0.005966    NSR  \n1 -0.043346 -0.016159 -0.012820 -0.007157 -0.012377    NSR  \n2 -0.061407 -0.003576 -0.026326  0.004760 -0.015544    NSR  \n3 -0.057996 -0.012361 -0.019814  0.007333 -0.030823    NSR  \n4 -0.063328 -0.010253 -0.004272 -0.024278  0.001717    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>21.861233</td>\n      <td>21.421103</td>\n      <td>21.536569</td>\n      <td>6.108208</td>\n      <td>0.880920</td>\n      <td>1.079942</td>\n      <td>-0.914392</td>\n      <td>-1.844370</td>\n      <td>-1.138702</td>\n      <td>...</td>\n      <td>-0.068189</td>\n      <td>0.053454</td>\n      <td>-0.067161</td>\n      <td>0.067961</td>\n      <td>-0.093129</td>\n      <td>0.027961</td>\n      <td>-0.038417</td>\n      <td>-0.011442</td>\n      <td>0.005966</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>26.408089</td>\n      <td>27.988299</td>\n      <td>27.611772</td>\n      <td>7.776970</td>\n      <td>1.129695</td>\n      <td>1.195165</td>\n      <td>-0.806390</td>\n      <td>-1.774080</td>\n      <td>-1.792590</td>\n      <td>...</td>\n      <td>-0.031130</td>\n      <td>0.017521</td>\n      <td>-0.014034</td>\n      <td>0.023165</td>\n      <td>-0.043346</td>\n      <td>-0.016159</td>\n      <td>-0.012820</td>\n      <td>-0.007157</td>\n      <td>-0.012377</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>25.977641</td>\n      <td>26.935251</td>\n      <td>26.561891</td>\n      <td>7.477219</td>\n      <td>1.098311</td>\n      <td>1.176663</td>\n      <td>-0.849446</td>\n      <td>-1.805917</td>\n      <td>-1.623971</td>\n      <td>...</td>\n      <td>-0.025147</td>\n      <td>0.006059</td>\n      <td>-0.022267</td>\n      <td>0.043209</td>\n      <td>-0.061407</td>\n      <td>-0.003576</td>\n      <td>-0.026326</td>\n      <td>0.004760</td>\n      <td>-0.015544</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>25.189643</td>\n      <td>25.649484</td>\n      <td>25.620624</td>\n      <td>7.261496</td>\n      <td>1.066191</td>\n      <td>1.162694</td>\n      <td>-0.825414</td>\n      <td>-1.684836</td>\n      <td>-1.477246</td>\n      <td>...</td>\n      <td>-0.040045</td>\n      <td>0.024580</td>\n      <td>-0.029490</td>\n      <td>0.040770</td>\n      <td>-0.057996</td>\n      <td>-0.012361</td>\n      <td>-0.019814</td>\n      <td>0.007333</td>\n      <td>-0.030823</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>24.659920</td>\n      <td>24.559022</td>\n      <td>24.462891</td>\n      <td>6.972141</td>\n      <td>1.008067</td>\n      <td>1.143318</td>\n      <td>-0.881397</td>\n      <td>-1.797336</td>\n      <td>-1.316414</td>\n      <td>...</td>\n      <td>-0.064038</td>\n      <td>0.044904</td>\n      <td>-0.045340</td>\n      <td>0.042700</td>\n      <td>-0.063328</td>\n      <td>-0.010253</td>\n      <td>-0.004272</td>\n      <td>-0.024278</td>\n      <td>0.001717</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_6beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    69911\nST     21247\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.255941  0.126826  0.086712  0.088051  0.075713 -0.024569   \ndw_2    0.255941  1.000000  0.839774  0.443129  0.156197  0.418729 -0.461763   \ndw_3    0.126826  0.839774  1.000000  0.617379  0.233068  0.346060 -0.532862   \ndw_4    0.086712  0.443129  0.617379  1.000000  0.899451  0.053813 -0.237258   \ndw_5    0.088051  0.156197  0.233068  0.899451  1.000000 -0.086599 -0.014596   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.032264  0.028086  0.046009  0.039039  0.015851 -0.077794  0.050496   \ncfr_13 -0.023128  0.110780  0.046174  0.024440  0.009964  0.068140  0.004871   \ncfr_14 -0.040651 -0.007514 -0.030837 -0.029533 -0.028118  0.011829  0.019891   \ncfr_15 -0.060588 -0.119066 -0.133170 -0.087767 -0.040683 -0.021598  0.089608   \ncfr_16 -0.042833 -0.078764 -0.047183 -0.029773 -0.015438  0.032908 -0.030729   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.012953 -0.001384  0.002394  ... -0.045708 -0.051747 -0.019303   \ndw_2   -0.218036 -0.003468  0.007413  ... -0.141060  0.127367  0.228143   \ndw_3   -0.300954 -0.002069  0.003404  ... -0.206438  0.110265  0.261460   \ndw_4   -0.145344 -0.000228  0.000760  ... -0.142178  0.036774  0.117609   \ndw_5   -0.019561  0.000277 -0.000251  ... -0.064023 -0.004814  0.020295   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.076659 -0.000726  0.004327  ... -0.121386 -0.206635 -0.113087   \ncfr_13  0.004627  0.000306  0.000798  ...  0.120777  0.028507 -0.219328   \ncfr_14  0.024541  0.001952 -0.001142  ...  0.088392  0.207586  0.043674   \ncfr_15  0.046544  0.005107 -0.006644  ...  0.251295  0.160789 -0.072934   \ncfr_16  0.002356  0.007116 -0.004854  ...  0.229052  0.144069  0.166645   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.008486 -0.000878 -0.032264 -0.023128 -0.040651 -0.060588 -0.042833  \ndw_2    0.164508  0.044436  0.028086  0.110780 -0.007514 -0.119066 -0.078764  \ndw_3    0.116256 -0.047562  0.046009  0.046174 -0.030837 -0.133170 -0.047183  \ndw_4    0.038427 -0.043639  0.039039  0.024440 -0.029533 -0.087767 -0.029773  \ndw_5    0.008379 -0.014492  0.015851  0.009964 -0.028118 -0.040683 -0.015438  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.008140  0.053560  1.000000 -0.006207 -0.033331 -0.303526 -0.194998  \ncfr_13 -0.269074 -0.065839 -0.006207  1.000000  0.164767  0.075217 -0.175495  \ncfr_14 -0.179302 -0.289882 -0.033331  0.164767  1.000000  0.131088 -0.151555  \ncfr_15 -0.151000 -0.104688 -0.303526  0.075217  0.131088  1.000000  0.190121  \ncfr_16  0.094130 -0.009039 -0.194998 -0.175495 -0.151555  0.190121  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.255941</td>\n      <td>0.126826</td>\n      <td>0.086712</td>\n      <td>0.088051</td>\n      <td>0.075713</td>\n      <td>-0.024569</td>\n      <td>0.012953</td>\n      <td>-0.001384</td>\n      <td>0.002394</td>\n      <td>...</td>\n      <td>-0.045708</td>\n      <td>-0.051747</td>\n      <td>-0.019303</td>\n      <td>-0.008486</td>\n      <td>-0.000878</td>\n      <td>-0.032264</td>\n      <td>-0.023128</td>\n      <td>-0.040651</td>\n      <td>-0.060588</td>\n      <td>-0.042833</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.255941</td>\n      <td>1.000000</td>\n      <td>0.839774</td>\n      <td>0.443129</td>\n      <td>0.156197</td>\n      <td>0.418729</td>\n      <td>-0.461763</td>\n      <td>-0.218036</td>\n      <td>-0.003468</td>\n      <td>0.007413</td>\n      <td>...</td>\n      <td>-0.141060</td>\n      <td>0.127367</td>\n      <td>0.228143</td>\n      <td>0.164508</td>\n      <td>0.044436</td>\n      <td>0.028086</td>\n      <td>0.110780</td>\n      <td>-0.007514</td>\n      <td>-0.119066</td>\n      <td>-0.078764</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.126826</td>\n      <td>0.839774</td>\n      <td>1.000000</td>\n      <td>0.617379</td>\n      <td>0.233068</td>\n      <td>0.346060</td>\n      <td>-0.532862</td>\n      <td>-0.300954</td>\n      <td>-0.002069</td>\n      <td>0.003404</td>\n      <td>...</td>\n      <td>-0.206438</td>\n      <td>0.110265</td>\n      <td>0.261460</td>\n      <td>0.116256</td>\n      <td>-0.047562</td>\n      <td>0.046009</td>\n      <td>0.046174</td>\n      <td>-0.030837</td>\n      <td>-0.133170</td>\n      <td>-0.047183</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.086712</td>\n      <td>0.443129</td>\n      <td>0.617379</td>\n      <td>1.000000</td>\n      <td>0.899451</td>\n      <td>0.053813</td>\n      <td>-0.237258</td>\n      <td>-0.145344</td>\n      <td>-0.000228</td>\n      <td>0.000760</td>\n      <td>...</td>\n      <td>-0.142178</td>\n      <td>0.036774</td>\n      <td>0.117609</td>\n      <td>0.038427</td>\n      <td>-0.043639</td>\n      <td>0.039039</td>\n      <td>0.024440</td>\n      <td>-0.029533</td>\n      <td>-0.087767</td>\n      <td>-0.029773</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.088051</td>\n      <td>0.156197</td>\n      <td>0.233068</td>\n      <td>0.899451</td>\n      <td>1.000000</td>\n      <td>-0.086599</td>\n      <td>-0.014596</td>\n      <td>-0.019561</td>\n      <td>0.000277</td>\n      <td>-0.000251</td>\n      <td>...</td>\n      <td>-0.064023</td>\n      <td>-0.004814</td>\n      <td>0.020295</td>\n      <td>0.008379</td>\n      <td>-0.014492</td>\n      <td>0.015851</td>\n      <td>0.009964</td>\n      <td>-0.028118</td>\n      <td>-0.040683</td>\n      <td>-0.015438</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.032264</td>\n      <td>0.028086</td>\n      <td>0.046009</td>\n      <td>0.039039</td>\n      <td>0.015851</td>\n      <td>-0.077794</td>\n      <td>0.050496</td>\n      <td>0.076659</td>\n      <td>-0.000726</td>\n      <td>0.004327</td>\n      <td>...</td>\n      <td>-0.121386</td>\n      <td>-0.206635</td>\n      <td>-0.113087</td>\n      <td>0.008140</td>\n      <td>0.053560</td>\n      <td>1.000000</td>\n      <td>-0.006207</td>\n      <td>-0.033331</td>\n      <td>-0.303526</td>\n      <td>-0.194998</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.023128</td>\n      <td>0.110780</td>\n      <td>0.046174</td>\n      <td>0.024440</td>\n      <td>0.009964</td>\n      <td>0.068140</td>\n      <td>0.004871</td>\n      <td>0.004627</td>\n      <td>0.000306</td>\n      <td>0.000798</td>\n      <td>...</td>\n      <td>0.120777</td>\n      <td>0.028507</td>\n      <td>-0.219328</td>\n      <td>-0.269074</td>\n      <td>-0.065839</td>\n      <td>-0.006207</td>\n      <td>1.000000</td>\n      <td>0.164767</td>\n      <td>0.075217</td>\n      <td>-0.175495</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.040651</td>\n      <td>-0.007514</td>\n      <td>-0.030837</td>\n      <td>-0.029533</td>\n      <td>-0.028118</td>\n      <td>0.011829</td>\n      <td>0.019891</td>\n      <td>0.024541</td>\n      <td>0.001952</td>\n      <td>-0.001142</td>\n      <td>...</td>\n      <td>0.088392</td>\n      <td>0.207586</td>\n      <td>0.043674</td>\n      <td>-0.179302</td>\n      <td>-0.289882</td>\n      <td>-0.033331</td>\n      <td>0.164767</td>\n      <td>1.000000</td>\n      <td>0.131088</td>\n      <td>-0.151555</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.060588</td>\n      <td>-0.119066</td>\n      <td>-0.133170</td>\n      <td>-0.087767</td>\n      <td>-0.040683</td>\n      <td>-0.021598</td>\n      <td>0.089608</td>\n      <td>0.046544</td>\n      <td>0.005107</td>\n      <td>-0.006644</td>\n      <td>...</td>\n      <td>0.251295</td>\n      <td>0.160789</td>\n      <td>-0.072934</td>\n      <td>-0.151000</td>\n      <td>-0.104688</td>\n      <td>-0.303526</td>\n      <td>0.075217</td>\n      <td>0.131088</td>\n      <td>1.000000</td>\n      <td>0.190121</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.042833</td>\n      <td>-0.078764</td>\n      <td>-0.047183</td>\n      <td>-0.029773</td>\n      <td>-0.015438</td>\n      <td>0.032908</td>\n      <td>-0.030729</td>\n      <td>0.002356</td>\n      <td>0.007116</td>\n      <td>-0.004854</td>\n      <td>...</td>\n      <td>0.229052</td>\n      <td>0.144069</td>\n      <td>0.166645</td>\n      <td>0.094130</td>\n      <td>-0.009039</td>\n      <td>-0.194998</td>\n      <td>-0.175495</td>\n      <td>-0.151555</td>\n      <td>0.190121</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows Ã— 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_132', 'fft_234', 'fft_161', 'fft_182', 'fft_236', 'fft_221', 'fft_227', 'fft_256', 'fft_232', 'mfw_7', 'fft_247', 'fft_237', 'fft_167', 'fft_208', 'fft_246', 'fft_183', 'fft_150', 'fft_136', 'fft_144', 'fft_216', 'fft_252', 'fft_141', 'fft_191', 'fft_219', 'fft_185', 'fft_214', 'fft_230', 'fft_223', 'fft_149', 'fft_245', 'fft_189', 'fft_169', 'fft_220', 'fft_153', 'fft_206', 'fft_188', 'fft_195', 'fft_201', 'fft_138', 'fft_154', 'fft_162', 'fft_178', 'fft_235', 'fft_180', 'fft_143', 'fft_204', 'mfw_5', 'fft_164', 'fft_229', 'fft_131', 'fft_179', 'fft_155', 'fft_255', 'fft_160', 'fft_207', 'fft_181', 'fft_159', 'fft_213', 'fft_187', 'mfw_12', 'fft_238', 'fft_198', 'mfw_10', 'fft_248', 'fft_251', 'fft_184', 'mfw_14', 'fft_241', 'fft_148', 'fft_224', 'fft_211', 'fft_130', 'fft_194', 'fft_171', 'mfw_8', 'fft_156', 'fft_212', 'fft_254', 'fft_250', 'fft_146', 'fft_210', 'fft_240', 'fft_226', 'fft_218', 'fft_140', 'fft_203', 'fft_158', 'fft_142', 'fft_200', 'fft_199', 'fft_176', 'fft_193', 'fft_186', 'fft_222', 'fft_202', 'mfw_11', 'fft_173', 'mfw_6', 'fft_147', 'fft_217', 'fft_242', 'fft_225', 'fft_253', 'mfw_13', 'fft_166', 'fft_135', 'fft_157', 'fft_134', 'fft_244', 'fft_233', 'fft_231', 'fft_137', 'fft_151', 'fft_165', 'fft_197', 'mfw_16', 'fft_177', 'fft_133', 'fft_139', 'fft_163', 'fft_209', 'fft_174', 'fft_196', 'fft_205', 'mfw_15', 'fft_145', 'fft_170', 'fft_215', 'fft_190', 'fft_249', 'fft_228', 'mfw_9', 'fft_192', 'fft_152', 'fft_243', 'fft_172', 'fft_175', 'fft_239', 'fft_168', 'cfr_16'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_24\n",
      "fft_25\n",
      "fft_27\n",
      "fft_28\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "fft_37\n",
      "fft_38\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 76\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\n0  21.861233  21.421103  21.536569  6.108208  0.880920  1.079942 -0.914392   \n1  26.408089  27.988299  27.611772  7.776970  1.129695  1.195165 -0.806390   \n2  25.977641  26.935251  26.561891  7.477219  1.098311  1.176663 -0.849446   \n3  25.189643  25.649484  25.620624  7.261496  1.066191  1.162694 -0.825414   \n4  24.659920  24.559022  24.462891  6.972141  1.008067  1.143318 -0.881397   \n\n      mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -1.844370 -1.138702 -0.004752  ...  0.006001  0.061446 -0.068189  0.053454   \n1 -1.774080 -1.792590  0.205786  ...  0.027369  0.028651 -0.031130  0.017521   \n2 -1.805917 -1.623971 -0.321053  ...  0.008456  0.040828 -0.025147  0.006059   \n3 -1.684836 -1.477246  3.056053  ...  0.029771  0.026605 -0.040045  0.024580   \n4 -1.797336 -1.316414  6.265323  ... -0.010154  0.059279 -0.064038  0.044904   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.067161  0.067961 -0.093129  0.027961 -0.038417 -0.011442  \n1 -0.014034  0.023165 -0.043346 -0.016159 -0.012820 -0.007157  \n2 -0.022267  0.043209 -0.061407 -0.003576 -0.026326  0.004760  \n3 -0.029490  0.040770 -0.057996 -0.012361 -0.019814  0.007333  \n4 -0.045340  0.042700 -0.063328 -0.010253 -0.004272 -0.024278  \n\n[5 rows x 76 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21.861233</td>\n      <td>21.421103</td>\n      <td>21.536569</td>\n      <td>6.108208</td>\n      <td>0.880920</td>\n      <td>1.079942</td>\n      <td>-0.914392</td>\n      <td>-1.844370</td>\n      <td>-1.138702</td>\n      <td>-0.004752</td>\n      <td>...</td>\n      <td>0.006001</td>\n      <td>0.061446</td>\n      <td>-0.068189</td>\n      <td>0.053454</td>\n      <td>-0.067161</td>\n      <td>0.067961</td>\n      <td>-0.093129</td>\n      <td>0.027961</td>\n      <td>-0.038417</td>\n      <td>-0.011442</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26.408089</td>\n      <td>27.988299</td>\n      <td>27.611772</td>\n      <td>7.776970</td>\n      <td>1.129695</td>\n      <td>1.195165</td>\n      <td>-0.806390</td>\n      <td>-1.774080</td>\n      <td>-1.792590</td>\n      <td>0.205786</td>\n      <td>...</td>\n      <td>0.027369</td>\n      <td>0.028651</td>\n      <td>-0.031130</td>\n      <td>0.017521</td>\n      <td>-0.014034</td>\n      <td>0.023165</td>\n      <td>-0.043346</td>\n      <td>-0.016159</td>\n      <td>-0.012820</td>\n      <td>-0.007157</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25.977641</td>\n      <td>26.935251</td>\n      <td>26.561891</td>\n      <td>7.477219</td>\n      <td>1.098311</td>\n      <td>1.176663</td>\n      <td>-0.849446</td>\n      <td>-1.805917</td>\n      <td>-1.623971</td>\n      <td>-0.321053</td>\n      <td>...</td>\n      <td>0.008456</td>\n      <td>0.040828</td>\n      <td>-0.025147</td>\n      <td>0.006059</td>\n      <td>-0.022267</td>\n      <td>0.043209</td>\n      <td>-0.061407</td>\n      <td>-0.003576</td>\n      <td>-0.026326</td>\n      <td>0.004760</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>25.189643</td>\n      <td>25.649484</td>\n      <td>25.620624</td>\n      <td>7.261496</td>\n      <td>1.066191</td>\n      <td>1.162694</td>\n      <td>-0.825414</td>\n      <td>-1.684836</td>\n      <td>-1.477246</td>\n      <td>3.056053</td>\n      <td>...</td>\n      <td>0.029771</td>\n      <td>0.026605</td>\n      <td>-0.040045</td>\n      <td>0.024580</td>\n      <td>-0.029490</td>\n      <td>0.040770</td>\n      <td>-0.057996</td>\n      <td>-0.012361</td>\n      <td>-0.019814</td>\n      <td>0.007333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24.659920</td>\n      <td>24.559022</td>\n      <td>24.462891</td>\n      <td>6.972141</td>\n      <td>1.008067</td>\n      <td>1.143318</td>\n      <td>-0.881397</td>\n      <td>-1.797336</td>\n      <td>-1.316414</td>\n      <td>6.265323</td>\n      <td>...</td>\n      <td>-0.010154</td>\n      <td>0.059279</td>\n      <td>-0.064038</td>\n      <td>0.044904</td>\n      <td>-0.045340</td>\n      <td>0.042700</td>\n      <td>-0.063328</td>\n      <td>-0.010253</td>\n      <td>-0.004272</td>\n      <td>-0.024278</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 76 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 36.11899924278259 s\n",
      "Accuracy 0.9322071083808688 precision 0.9321316049998448 specificity 0.8780956380881422 recall 0.9322071083808688 f1 0.93216863425782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 35.79499816894531 s\n",
      "Accuracy 0.9348946906537955 precision 0.9351695331482061 specificity 0.8875309361487711 recall 0.9348946906537955 f1 0.9350232747551332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 35.83799767494202 s\n",
      "Accuracy 0.9317134708205353 precision 0.9318783787482711 specificity 0.8809615089635149 recall 0.9317134708205353 f1 0.9317928502121892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 33.64099860191345 s\n",
      "Accuracy 0.9329201404124616 precision 0.9333139377964733 specificity 0.8854916421443465 recall 0.9329201404124616 f1 0.9331006255818447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 33.20899939537048 s\n",
      "Accuracy 0.9338525669153137 precision 0.9336608003172286 specificity 0.8800056474634541 recall 0.9338525669153137 f1 0.9337513457670094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 33.55599880218506 s\n",
      "Accuracy 0.9351140851250549 precision 0.935172494619512 specificity 0.885411353516505 recall 0.9351140851250549 f1 0.9351428430702425\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 33.107999086380005 s\n",
      "Accuracy 0.934401053093462 precision 0.9345208069972331 specificity 0.8849441442902991 recall 0.934401053093462 f1 0.934459147481404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 33.88499999046326 s\n",
      "Accuracy 0.9367595436594998 precision 0.9369522022094612 specificity 0.8877847249475144 recall 0.9367595436594998 f1 0.9368512974691617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 33.89599823951721 s\n",
      "Accuracy 0.9325362000877578 precision 0.9324529717382382 specificity 0.8808462937071071 recall 0.9325362000877578 f1 0.932493650581507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 33.63599920272827 s\n",
      "Accuracy 0.9348398420359807 precision 0.9348725179008175 specificity 0.8823252605580603 recall 0.9348398420359807 f1 0.9348560457332051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 33.7789990901947 s\n",
      "Accuracy 0.936704695041685 precision 0.9365524378429825 specificity 0.8824143049629273 recall 0.936704695041685 f1 0.9366251752814779\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 33.75300216674805 s\n",
      "Accuracy 0.9363207547169812 precision 0.9364692798605017 specificity 0.8861431637662425 recall 0.9363207547169812 f1 0.9363922915475138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 33.59999680519104 s\n",
      "Accuracy 0.9358271171566477 precision 0.9362111302661085 specificity 0.8881359618785695 recall 0.9358271171566477 f1 0.9360029171635654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 33.926003217697144 s\n",
      "Accuracy 0.9351689337428697 precision 0.9350344215185586 specificity 0.8808540021196983 recall 0.9351689337428697 f1 0.9350991498253418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 34.18299651145935 s\n",
      "Accuracy 0.9341268100043879 precision 0.9345061526619095 specificity 0.8865572192380153 recall 0.9341268100043879 f1 0.934300926652821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 33.23499536514282 s\n",
      "Accuracy 0.936704695041685 precision 0.9369128322744907 specificity 0.888674145546474 recall 0.936704695041685 f1 0.9368033914567988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 33.868998527526855 s\n",
      "Accuracy 0.9324265028521281 precision 0.9322630854855739 specificity 0.8794269989281749 recall 0.9324265028521281 f1 0.9323410458065224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 33.33799934387207 s\n",
      "Accuracy 0.9371983326020185 precision 0.937266633679409 specificity 0.8878160853849365 recall 0.9371983326020185 f1 0.937231852405048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 33.75299835205078 s\n",
      "Accuracy 0.9377468187801667 precision 0.9378252062268835 specificity 0.8889132486577687 recall 0.9377468187801667 f1 0.9377851718543364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 33.433000564575195 s\n",
      "Accuracy 0.9330298376480912 precision 0.9334386006595228 specificity 0.8824433880141354 recall 0.9330298376480912 f1 0.9332175687616516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 33.236671924591064 s\n",
      "Accuracy 0.9340171127687582 precision 0.934011753811227 specificity 0.8819239295539335 recall 0.9340171127687582 f1 0.9340144295902778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 33.838239908218384 s\n",
      "Accuracy 0.9356625713032032 precision 0.9355443868678089 specificity 0.88220478146981 recall 0.9356625713032032 f1 0.9356015016603673\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 33.367223501205444 s\n",
      "Accuracy 0.93505923650724 precision 0.9348806872198338 specificity 0.8823289191125988 recall 0.93505923650724 f1 0.9349651614492099\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 34.238255739212036 s\n",
      "Accuracy 0.936704695041685 precision 0.9365835109955553 specificity 0.8839402075165004 recall 0.936704695041685 f1 0.9366419444266089\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 34.11325216293335 s\n",
      "Accuracy 0.9310552874067574 precision 0.931200055987113 specificity 0.8783435316213509 recall 0.9310552874067574 f1 0.931125377916935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 33.49622869491577 s\n",
      "Accuracy 0.9331395348837209 precision 0.9331035516672394 specificity 0.8836738102283311 recall 0.9331395348837209 f1 0.9331213650760984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 33.71823716163635 s\n",
      "Accuracy 0.936046511627907 precision 0.9364073394434115 specificity 0.8904579177153475 recall 0.936046511627907 f1 0.9362118217398049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 33.739238262176514 s\n",
      "Accuracy 0.9328104431768319 precision 0.9330085793250181 specificity 0.8830452854636925 recall 0.9328104431768319 f1 0.9329050199289075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 33.74023795127869 s\n",
      "Accuracy 0.9333040807371654 precision 0.9331868131897669 specificity 0.8781948182488778 recall 0.9333040807371654 f1 0.9332436479144143\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 33.75823950767517 s\n",
      "Accuracy 0.9322071083808688 precision 0.9321958575173699 specificity 0.8766961243174497 recall 0.9322071083808688 f1 0.9322014680860041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 33.842241287231445 s\n",
      "Accuracy 0.9362659060991663 precision 0.9362659060991663 specificity 0.8869436811396031 recall 0.9362659060991663 f1 0.9362659060991663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 33.55223083496094 s\n",
      "Accuracy 0.9295743747257569 precision 0.9291038222909562 specificity 0.869844918256645 recall 0.9295743747257569 f1 0.9293053086792143\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 33.56723213195801 s\n",
      "Accuracy 0.9346204475647214 precision 0.9345891663523297 specificity 0.883571995690273 recall 0.9346204475647214 f1 0.934604674075911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 33.69823479652405 s\n",
      "Accuracy 0.9353334795963142 precision 0.9352753663864183 specificity 0.8819926985069501 recall 0.9353334795963142 f1 0.9353039705912823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 33.486228227615356 s\n",
      "Accuracy 0.936046511627907 precision 0.9361319888418403 specificity 0.8863619210843295 recall 0.936046511627907 f1 0.9360882990574716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 33.04621148109436 s\n",
      "Accuracy 0.9333589293549802 precision 0.9334548614635075 specificity 0.8804911125739966 recall 0.9333589293549802 f1 0.933405822505372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 32.924208641052246 s\n",
      "Accuracy 0.9325362000877578 precision 0.9324604511404201 specificity 0.8780010945843744 recall 0.9325362000877578 f1 0.9324976006542648\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 33.25422024726868 s\n",
      "Accuracy 0.9341268100043879 precision 0.9342307398592419 specificity 0.8838634639762462 recall 0.9341268100043879 f1 0.9341774435116058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 33.22621941566467 s\n",
      "Accuracy 0.9375274243089075 precision 0.9377003818553402 specificity 0.8917257516328863 recall 0.9375274243089075 f1 0.9376098795932192\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 33.72123837471008 s\n",
      "Accuracy 0.9354431768319439 precision 0.9358955455673894 specificity 0.8889768207051214 recall 0.9354431768319439 f1 0.9356474167824725\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 32.99820947647095 s\n",
      "Accuracy 0.9342913558578324 precision 0.9343809627092727 specificity 0.8814922014810684 recall 0.9342913558578324 f1 0.9343352044345011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 32.816203594207764 s\n",
      "Accuracy 0.9361562088635367 precision 0.9363184485868714 specificity 0.8879322608063284 recall 0.9361562088635367 f1 0.9362339941399547\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 33.6332311630249 s\n",
      "Accuracy 0.9370886353663888 precision 0.9371562101419051 specificity 0.888583152930182 recall 0.9370886353663888 f1 0.9371217949508165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 33.0832142829895 s\n",
      "Accuracy 0.9330298376480912 precision 0.9331476816548804 specificity 0.8814694969236163 recall 0.9330298376480912 f1 0.9330871331008241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 33.56123089790344 s\n",
      "Accuracy 0.9330298376480912 precision 0.9331362943961731 specificity 0.8812457651708099 recall 0.9330298376480912 f1 0.9330817338184755\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 33.25822067260742 s\n",
      "Accuracy 0.9362110574813515 precision 0.9364292018978506 specificity 0.8868598933212017 recall 0.9362110574813515 f1 0.9363144516045251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 33.03221273422241 s\n",
      "Accuracy 0.9336880210618692 precision 0.9333150823835219 specificity 0.8759916926473276 recall 0.9336880210618692 f1 0.9334794642821392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 33.55023121833801 s\n",
      "Accuracy 0.9348398420359807 precision 0.9345537000550975 specificity 0.8808729985979279 recall 0.9348398420359807 f1 0.9346834450148559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 33.31422209739685 s\n",
      "Accuracy 0.9345107503290917 precision 0.9345777459783765 specificity 0.8811588695884096 recall 0.9345107503290917 f1 0.9345437095716681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 33.90424585342407 s\n",
      "Accuracy 0.9340719613865731 precision 0.934576224417872 specificity 0.8874335803928506 recall 0.9340719613865731 f1 0.9342981188259105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 33.0892117023468 s\n",
      "Accuracy 0.93505923650724 precision 0.9351126272369134 specificity 0.8847693534716189 recall 0.93505923650724 f1 0.935085561843399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 34.17290902137756 s\n",
      "Accuracy 0.9375274243089075 precision 0.9375119536136401 specificity 0.886569463697755 recall 0.9375274243089075 f1 0.9375196551906416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 32.85586452484131 s\n",
      "Accuracy 0.937637121544537 precision 0.9377403304734647 specificity 0.886500477419418 recall 0.937637121544537 f1 0.9376873624248535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 32.42385220527649 s\n",
      "Accuracy 0.935388328214129 precision 0.9359066426463073 specificity 0.8883930409701108 recall 0.935388328214129 f1 0.9356199938672711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 33.219873905181885 s\n",
      "Accuracy 0.9336331724440544 precision 0.9336010591810782 specificity 0.880921521008614 recall 0.9336331724440544 f1 0.9336169826829724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 33.47987985610962 s\n",
      "Accuracy 0.9324265028521281 precision 0.932640663480201 specificity 0.883677556737638 recall 0.9324265028521281 f1 0.9325283195607876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 33.93889307975769 s\n",
      "Accuracy 0.9364853005704257 precision 0.9365494147246848 specificity 0.8858951209620782 recall 0.9364853005704257 f1 0.9365168195752468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 32.97886681556702 s\n",
      "Accuracy 0.9370886353663888 precision 0.9372009770026414 specificity 0.8877631706884248 recall 0.9370886353663888 f1 0.9371431586803362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 33.262874126434326 s\n",
      "Accuracy 0.9327007459412023 precision 0.9327858600944623 specificity 0.8792855308307546 recall 0.9327007459412023 f1 0.9327424691427938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 33.556883096694946 s\n",
      "Accuracy 0.9335783238262396 precision 0.9335192044195176 specificity 0.8796523071628142 recall 0.9335783238262396 f1 0.9335483149392488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 32.877861976623535 s\n",
      "Accuracy 0.9313843791136464 precision 0.9315468587259356 specificity 0.8755420448111405 recall 0.9313843791136464 f1 0.9314629032276055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 33.20287322998047 s\n",
      "Accuracy 0.936704695041685 precision 0.9366325765191666 specificity 0.8841973634149539 recall 0.936704695041685 f1 0.9366679004809942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 33.18787169456482 s\n",
      "Accuracy 0.9368692408951295 precision 0.9368851623418528 specificity 0.8850171294246436 recall 0.9368692408951295 f1 0.9368771677926679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 33.586883306503296 s\n",
      "Accuracy 0.9362659060991663 precision 0.9362553660831763 specificity 0.884337057408123 recall 0.9362659060991663 f1 0.9362606211209097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 33.12286901473999 s\n",
      "Accuracy 0.936704695041685 precision 0.9367150871339803 specificity 0.8864270289395683 recall 0.936704695041685 f1 0.9367098761777841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 33.786887645721436 s\n",
      "Accuracy 0.9331943835015357 precision 0.9332963550778542 specificity 0.8802449039153392 recall 0.9331943835015357 f1 0.9332441668741729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 33.48288035392761 s\n",
      "Accuracy 0.9341268100043879 precision 0.9342876318903648 specificity 0.8845015010390481 recall 0.9341268100043879 f1 0.9342041212268055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 33.58488321304321 s\n",
      "Accuracy 0.937966213251426 precision 0.9379213110125936 specificity 0.8882786147279937 recall 0.937966213251426 f1 0.9379434596269381\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 33.19787311553955 s\n",
      "Accuracy 0.9321522597630539 precision 0.9320915554273905 specificity 0.8766774043437626 recall 0.9321522597630539 f1 0.9321214589687298\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 33.33587718009949 s\n",
      "Accuracy 0.9345655989469065 precision 0.9344342975419977 specificity 0.8795054560719929 recall 0.9345655989469065 f1 0.9344976109908324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 33.66988492012024 s\n",
      "Accuracy 0.9358819657744625 precision 0.9359315303967042 specificity 0.8825325529737301 recall 0.9358819657744625 f1 0.9359064429560161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 33.197872161865234 s\n",
      "Accuracy 0.9359916630100922 precision 0.9362773074400668 specificity 0.8887118525673744 recall 0.9359916630100922 f1 0.9361248517090309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 33.19487237930298 s\n",
      "Accuracy 0.936978938130759 precision 0.9374915525667874 specificity 0.8936761040086246 recall 0.936978938130759 f1 0.9372060143790608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 33.43787956237793 s\n",
      "Accuracy 0.936978938130759 precision 0.937388896050862 specificity 0.8904130512644901 recall 0.936978938130759 f1 0.9371651091550364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 33.34987688064575 s\n",
      "Accuracy 0.9350043878894252 precision 0.9354479526633642 specificity 0.8877855216163696 recall 0.9350043878894252 f1 0.9352053422935792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 33.21487259864807 s\n",
      "Accuracy 0.9316037735849056 precision 0.9316094494222599 specificity 0.8761371449455045 recall 0.9316037735849056 f1 0.9316066077983829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 33.35387659072876 s\n",
      "Accuracy 0.9345107503290917 precision 0.9343109328895892 specificity 0.8807675246802319 recall 0.9345107503290917 f1 0.9344049114300791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 33.50787878036499 s\n",
      "Accuracy 0.9334137779727951 precision 0.9337166151466366 specificity 0.8840261487110997 recall 0.9334137779727951 f1 0.9335552300992277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 33.705886125564575 s\n",
      "Accuracy 0.9316037735849056 precision 0.9318218158951767 specificity 0.8792747996477889 recall 0.9316037735849056 f1 0.9317077516391425\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 33.146870136260986 s\n",
      "Accuracy 0.9352786309784994 precision 0.9351669095113585 specificity 0.8831286057915817 recall 0.9352786309784994 f1 0.9352209747226972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 33.24987506866455 s\n",
      "Accuracy 0.93505923650724 precision 0.9351458423906259 specificity 0.8847336101065166 recall 0.93505923650724 f1 0.9351015907866882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 32.70080089569092 s\n",
      "Accuracy 0.9330846862659061 precision 0.9333945630502483 specificity 0.8853569866690619 recall 0.9330846862659061 f1 0.9332289691747032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 33.275622844696045 s\n",
      "Accuracy 0.9355528740675735 precision 0.9357188080718414 specificity 0.8885303731763841 recall 0.9355528740675735 f1 0.9356323110371734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 32.80161905288696 s\n",
      "Accuracy 0.9345107503290917 precision 0.9345652387405314 specificity 0.8828121597695056 recall 0.9345107503290917 f1 0.9345376233382238\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 33.148621559143066 s\n",
      "Accuracy 0.9328652917946467 precision 0.933027507100562 specificity 0.879925987556339 recall 0.9328652917946467 f1 0.9329434892807333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 33.02162051200867 s\n",
      "Accuracy 0.9340171127687582 precision 0.9337923116634205 specificity 0.879614452688241 recall 0.9340171127687582 f1 0.9338972128222517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 32.86661744117737 s\n",
      "Accuracy 0.9351689337428697 precision 0.9353458999769912 specificity 0.8858936626627936 recall 0.9351689337428697 f1 0.9352536241579623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 32.81661677360535 s\n",
      "Accuracy 0.9338525669153137 precision 0.9336961053668347 specificity 0.8788062939462336 recall 0.9338525669153137 f1 0.933770987092151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 33.507627725601196 s\n",
      "Accuracy 0.9344559017112769 precision 0.9346358860759669 specificity 0.8867227146505837 recall 0.9344559017112769 f1 0.934541902998749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 33.83063578605652 s\n",
      "Accuracy 0.936704695041685 precision 0.9367256696765662 specificity 0.8860685968837808 recall 0.936704695041685 f1 0.9367151225951321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 33.425628662109375 s\n",
      "Accuracy 0.936375603334796 precision 0.9367561153668272 specificity 0.8892521542143009 recall 0.936375603334796 f1 0.9365496430457239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 33.654632329940796 s\n",
      "Accuracy 0.9320425625274243 precision 0.9320591668540805 specificity 0.8788715958176557 recall 0.9320425625274243 f1 0.9320508315665538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 33.48963022232056 s\n",
      "Accuracy 0.9364853005704257 precision 0.9367279223586588 specificity 0.8890539046176653 recall 0.9364853005704257 f1 0.936599427559661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 33.58562970161438 s\n",
      "Accuracy 0.9323716542343133 precision 0.9322475706210022 specificity 0.876530340835651 recall 0.9323716542343133 f1 0.9323076503549765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 33.324625730514526 s\n",
      "Accuracy 0.9354980254497587 precision 0.9353385342740946 specificity 0.8828910693693586 recall 0.9354980254497587 f1 0.9354144769022487\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 33.28662467002869 s\n",
      "Accuracy 0.9350043878894252 precision 0.9351294294444162 specificity 0.8855833901028789 recall 0.9350043878894252 f1 0.9350649537878016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 33.458627223968506 s\n",
      "Accuracy 0.9361013602457218 precision 0.9361169029002282 specificity 0.8864938212810918 recall 0.9361013602457218 f1 0.9361090982317152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 33.71463465690613 s\n",
      "Accuracy 0.9358819657744625 precision 0.9358872401571345 specificity 0.8846020685689682 recall 0.9358819657744625 f1 0.9358845992395846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 33.76063418388367 s\n",
      "Accuracy 0.9311649846423871 precision 0.9316947345821595 specificity 0.8823932653613336 recall 0.9311649846423871 f1 0.9314034405704997\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 33.14562225341797 s\n",
      "Accuracy 0.9336331724440544 precision 0.933811998001863 specificity 0.8840952473851034 recall 0.9336331724440544 f1 0.9337188201858472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 33.00662040710449 s\n",
      "Accuracy 0.936978938130759 precision 0.9369634634508299 specificity 0.8862491380042158 recall 0.936978938130759 f1 0.9369711671604625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 33.31962537765503 s\n",
      "Accuracy 0.9334686265906099 precision 0.9335950944741015 specificity 0.8837429464416796 recall 0.9334686265906099 f1 0.9335299193486492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 33.39262938499451 s\n",
      "Accuracy 0.9295195261079421 precision 0.9296181518891683 specificity 0.8758769504958023 recall 0.9295195261079421 f1 0.9295677844530486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 33.34562611579895 s\n",
      "Accuracy 0.9356077226853883 precision 0.9354206830149693 specificity 0.8788446835307283 recall 0.9356077226853883 f1 0.9355093038859423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 33.53062868118286 s\n",
      "Accuracy 0.9345655989469065 precision 0.9349289793554403 specificity 0.8874659407012134 recall 0.9345655989469065 f1 0.9347326784336404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 33.92463827133179 s\n",
      "Accuracy 0.9330298376480912 precision 0.9328096691852122 specificity 0.8775294740899717 recall 0.9330298376480912 f1 0.9329129073164829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 33.63763117790222 s\n",
      "Accuracy 0.9322071083808688 precision 0.9324527305690068 specificity 0.8811721289814299 recall 0.9322071083808688 f1 0.9323234285999057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 33.26162528991699 s\n",
      "Accuracy 0.9355528740675735 precision 0.935384260684874 specificity 0.880754132212407 recall 0.9355528740675735 f1 0.9354644840257705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 32.90661931037903 s\n",
      "Accuracy 0.9356625713032032 precision 0.9357112003127672 specificity 0.8839769181344861 recall 0.9356625713032032 f1 0.9356865832809529\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 33.54063010215759 s\n",
      "Accuracy 0.9382404563405002 precision 0.9381912042290076 specificity 0.8892235724689755 recall 0.9382404563405002 f1 0.9382154574925792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 33.41062808036804 s\n",
      "Accuracy 0.9345655989469065 precision 0.9342319904591432 specificity 0.8759979561276245 recall 0.9345655989469065 f1 0.9343819008754395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 33.05761909484863 s\n",
      "Accuracy 0.9340719613865731 precision 0.9340825090973345 specificity 0.8837671543248832 recall 0.9340719613865731 f1 0.9340772205437451\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 33.95563817024231 s\n",
      "Accuracy 0.9357722685388328 precision 0.9359186021590352 specificity 0.886998552371523 recall 0.9357722685388328 f1 0.9358427352727037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 33.401628255844116 s\n",
      "Accuracy 0.9356077226853883 precision 0.9360947110422816 specificity 0.8913320419379617 recall 0.9356077226853883 f1 0.9358252970146964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 32.65061378479004 s\n",
      "Accuracy 0.9327007459412023 precision 0.9325288345363307 specificity 0.8777814480461595 recall 0.9327007459412023 f1 0.9326107670826018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 33.8826367855072 s\n",
      "Accuracy 0.934401053093462 precision 0.9343286166396197 specificity 0.882629127589003 recall 0.934401053093462 f1 0.9343641111715636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 33.19862222671509 s\n",
      "Accuracy 0.9324813514699429 precision 0.9322439495947796 specificity 0.877638305519977 recall 0.9324813514699429 f1 0.9323545229477218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 33.5736300945282 s\n",
      "Accuracy 0.9365401491882405 precision 0.9363535973449043 specificity 0.8852883984416738 recall 0.9365401491882405 f1 0.9364412349097923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 32.930620431900024 s\n",
      "Accuracy 0.9371434839842036 precision 0.9369743789445937 specificity 0.8834868809155074 recall 0.9371434839842036 f1 0.9370545808899029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 33.57262921333313 s\n",
      "Accuracy 0.9350043878894252 precision 0.9351785894769217 specificity 0.88431474106825 recall 0.9350043878894252 f1 0.9350879110265315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 33.28262519836426 s\n",
      "Accuracy 0.934401053093462 precision 0.9346648280066733 specificity 0.8849072408162362 recall 0.934401053093462 f1 0.9345251049329069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 33.56562948226929 s\n",
      "Accuracy 0.93505923650724 precision 0.9348919572146954 specificity 0.8833154442180864 recall 0.93505923650724 f1 0.934971331607111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 33.37862777709961 s\n",
      "Accuracy 0.9347849934181659 precision 0.9348010721150131 specificity 0.8830593610880481 recall 0.9347849934181659 f1 0.9347929993543128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 33.57063102722168 s\n",
      "Accuracy 0.9338525669153137 precision 0.9337771238172645 specificity 0.8790314738021678 recall 0.9338525669153137 f1 0.9338141143674861\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 33.747631788253784 s\n",
      "Accuracy 0.9369240895129443 precision 0.9372382803124815 specificity 0.890059865164071 recall 0.9369240895129443 f1 0.9370695154898625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 33.07362079620361 s\n",
      "Accuracy 0.937362878455463 precision 0.9372533273878021 specificity 0.8857324511130727 recall 0.937362878455463 f1 0.9373062908101069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 33.636632680892944 s\n",
      "Accuracy 0.9359368143922773 precision 0.9358937471266203 specificity 0.8813138387026639 recall 0.9359368143922773 f1 0.9359150391597937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 33.92963743209839 s\n",
      "Accuracy 0.9358819657744625 precision 0.9357645991433853 specificity 0.8828714049720853 recall 0.9358819657744625 f1 0.9358213064944796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 34.14464521408081 s\n",
      "Accuracy 0.9342365072400175 precision 0.9340992282823991 specificity 0.8815941444525904 recall 0.9342365072400175 f1 0.9341651754374888\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 33.72362971305847 s\n",
      "Accuracy 0.9316037735849056 precision 0.9317821166927013 specificity 0.8802704458494349 recall 0.9316037735849056 f1 0.9316894239250062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 32.95661902427673 s\n",
      "Accuracy 0.938295304958315 precision 0.938772978321922 specificity 0.8958500194747412 recall 0.938295304958315 f1 0.9385074108465323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 33.35962533950806 s\n",
      "Accuracy 0.9357722685388328 precision 0.9356847338833956 specificity 0.8831956818511645 recall 0.9357722685388328 f1 0.9357274230382454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 34.00163793563843 s\n",
      "Accuracy 0.9334686265906099 precision 0.9332399763447841 specificity 0.8779923248998094 recall 0.9334686265906099 f1 0.9333467900017253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 33.50862979888916 s\n",
      "Accuracy 0.9327555945590171 precision 0.932625517391923 specificity 0.8761521519854514 recall 0.9327555945590171 f1 0.9326884089062507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 33.2246253490448 s\n",
      "Accuracy 0.9339074155331286 precision 0.9339570966296236 specificity 0.8812186478088269 recall 0.9339074155331286 f1 0.9339319551931146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 33.55563044548035 s\n",
      "Accuracy 0.9334686265906099 precision 0.9337372030997353 specificity 0.8847598432066789 recall 0.9334686265906099 f1 0.9335948033404066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 33.39162755012512 s\n",
      "Accuracy 0.9335234752084247 precision 0.9334598170149602 specificity 0.8805116021122024 recall 0.9335234752084247 f1 0.9334911138723897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 33.3746280670166 s\n",
      "Accuracy 0.935388328214129 precision 0.9353053325714803 specificity 0.8825876577173628 recall 0.935388328214129 f1 0.9353458762184408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 33.01561975479126 s\n",
      "Accuracy 0.9355528740675735 precision 0.935319762887235 specificity 0.88053020175306 recall 0.9355528740675735 f1 0.9354280514984434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 33.35362792015076 s\n",
      "Accuracy 0.9316037735849056 precision 0.9314820003642431 specificity 0.8776918033147855 recall 0.9316037735849056 f1 0.9315409481462708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 33.412627935409546 s\n",
      "Accuracy 0.9348946906537955 precision 0.9350708787612085 specificity 0.883308498366052 recall 0.9348946906537955 f1 0.934979195178766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 33.22762417793274 s\n",
      "Accuracy 0.9346204475647214 precision 0.9345370982773584 specificity 0.8818433541375521 recall 0.9346204475647214 f1 0.9345778228415421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 33.23462677001953 s\n",
      "Accuracy 0.9331395348837209 precision 0.9332574907983548 specificity 0.8814564688314538 recall 0.9331395348837209 f1 0.9331968844696651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 33.327298641204834 s\n",
      "Accuracy 0.9340719613865731 precision 0.9340179170507037 specificity 0.8796359992316595 recall 0.9340719613865731 f1 0.9340445661127875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 33.01426720619202 s\n",
      "Accuracy 0.9362110574813515 precision 0.936457494816661 specificity 0.8895877478376687 recall 0.9362110574813515 f1 0.9363267999560436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 33.902273416519165 s\n",
      "Accuracy 0.9344559017112769 precision 0.9344082962169099 specificity 0.881787517387148 recall 0.9344559017112769 f1 0.9344317983266704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 32.93526792526245 s\n",
      "Accuracy 0.9355528740675735 precision 0.9355687351082604 specificity 0.8845861372526018 recall 0.9355528740675735 f1 0.9355607711452113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 33.534271240234375 s\n",
      "Accuracy 0.9344559017112769 precision 0.9348969626312738 specificity 0.8878618136546426 recall 0.9344559017112769 f1 0.9346557281156672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 32.533262968063354 s\n",
      "Accuracy 0.9352786309784994 precision 0.9354898225990381 specificity 0.8866125701263317 recall 0.9352786309784994 f1 0.9353788825563322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 32.97626829147339 s\n",
      "Accuracy 0.9341268100043879 precision 0.9338003607321769 specificity 0.8775766120888617 recall 0.9341268100043879 f1 0.933946871724207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 34.056275367736816 s\n",
      "Accuracy 0.9349495392716104 precision 0.9350030383242179 specificity 0.8845441766324003 recall 0.9349495392716104 f1 0.9349759188035541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 33.3282687664032 s\n",
      "Accuracy 0.9355528740675735 precision 0.9357953587367002 specificity 0.886486990736312 recall 0.9355528740675735 f1 0.9356672424171892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 33.4492712020874 s\n",
      "Accuracy 0.9334686265906099 precision 0.9332598015795041 specificity 0.8785322841970932 recall 0.9334686265906099 f1 0.933357987870399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 32.76226329803467 s\n",
      "Accuracy 0.9359368143922773 precision 0.9360113882102883 specificity 0.8861742633418581 recall 0.9359368143922773 f1 0.9359733735760578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 33.46526861190796 s\n",
      "Accuracy 0.93505923650724 precision 0.935048766989233 specificity 0.8842055779336884 recall 0.93505923650724 f1 0.935053986948489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 33.364269733428955 s\n",
      "Accuracy 0.9364853005704257 precision 0.9365376902038353 specificity 0.8870894637259883 recall 0.9364853005704257 f1 0.9365111239083497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 32.97526502609253 s\n",
      "Accuracy 0.9322619569986836 precision 0.9325725851222174 specificity 0.8829134642663816 recall 0.9322619569986836 f1 0.9324069822984039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 33.244266510009766 s\n",
      "Accuracy 0.934730144800351 precision 0.934807604137681 specificity 0.8823981845182551 recall 0.934730144800351 f1 0.9347681434014936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 33.58727169036865 s\n",
      "Accuracy 0.9340171127687582 precision 0.934196439956065 specificity 0.8867320739215546 recall 0.9340171127687582 f1 0.9341028028581697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 33.42827010154724 s\n",
      "Accuracy 0.9314392277314612 precision 0.9314615303385106 specificity 0.8780910113435301 recall 0.9314392277314612 f1 0.9314503202801324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 33.17326593399048 s\n",
      "Accuracy 0.9346752961825362 precision 0.9345751667849117 specificity 0.8803858554224789 recall 0.9346752961825362 f1 0.9346238834332892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 33.31026840209961 s\n",
      "Accuracy 0.9372531812198333 precision 0.9371624716204441 specificity 0.8854812384485486 recall 0.9372531812198333 f1 0.9372066122416396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 34.02727437019348 s\n",
      "Accuracy 0.9347849934181659 precision 0.9346643182792319 specificity 0.8800680029020508 recall 0.9347849934181659 f1 0.9347226772823977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 34.69728183746338 s\n",
      "Accuracy 0.9335783238262396 precision 0.933841522223926 specificity 0.8825578907825764 recall 0.9335783238262396 f1 0.933702410770508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 35.647287130355835 s\n",
      "Accuracy 0.9357722685388328 precision 0.9355803911330378 specificity 0.8827549422600031 recall 0.9357722685388328 f1 0.9356706708127092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 33.973270416259766 s\n",
      "Accuracy 0.9354431768319439 precision 0.9353967671936904 specificity 0.8843528444429454 recall 0.9354431768319439 f1 0.9354196718255038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 33.75127363204956 s\n",
      "Accuracy 0.9334686265906099 precision 0.9339581320609155 specificity 0.8859477909764911 recall 0.9334686265906099 f1 0.9336892315143049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 33.62027096748352 s\n",
      "Accuracy 0.9339622641509434 precision 0.9339405600622238 specificity 0.880335691535187 recall 0.9339622641509434 f1 0.9339513525766291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 33.179269313812256 s\n",
      "Accuracy 0.9339622641509434 precision 0.9339514546110754 specificity 0.8810197951615784 recall 0.9339622641509434 f1 0.9339568445357013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 33.780272245407104 s\n",
      "Accuracy 0.9329749890302764 precision 0.9327357707008863 specificity 0.8787630261286906 recall 0.9329749890302764 f1 0.9328469050223774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 38.00130867958069 s\n",
      "Accuracy 0.9315489249670909 precision 0.9316752550863285 specificity 0.8788309280144844 recall 0.9315489249670909 f1 0.9316103100545343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 34.087275981903076 s\n",
      "Accuracy 0.9347849934181659 precision 0.9349131493731354 specificity 0.8834577420120255 recall 0.9347849934181659 f1 0.9348471024164459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 33.61427140235901 s\n",
      "Accuracy 0.9329749890302764 precision 0.9329642698309186 specificity 0.8811544794172209 recall 0.9329749890302764 f1 0.9329696147341178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 35.57028651237488 s\n",
      "Accuracy 0.9357722685388328 precision 0.9358767814280168 specificity 0.8843846830407959 recall 0.9357722685388328 f1 0.9358231746117445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 33.50627064704895 s\n",
      "Accuracy 0.9337428696796841 precision 0.9336687548567504 specificity 0.8804373186299548 recall 0.9337428696796841 f1 0.9337050863670393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 33.80227255821228 s\n",
      "Accuracy 0.9351140851250549 precision 0.9353822066860897 specificity 0.8859646108194998 recall 0.9351140851250549 f1 0.9352399435042134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 33.51127076148987 s\n",
      "Accuracy 0.9320974111452391 precision 0.9320635687291899 specificity 0.8756823442283942 recall 0.9320974111452391 f1 0.9320803558593732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 33.18826913833618 s\n",
      "Accuracy 0.9322071083808688 precision 0.9321217280904405 specificity 0.878611391554327 recall 0.9322071083808688 f1 0.932163477023519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 33.56326961517334 s\n",
      "Accuracy 0.9354431768319439 precision 0.9354590823001477 specificity 0.8843009947234431 recall 0.9354431768319439 f1 0.9354510961177362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 33.33126878738403 s\n",
      "Accuracy 0.9350043878894252 precision 0.9349173902312775 specificity 0.88328078028665 recall 0.9350043878894252 f1 0.9349598194041241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 33.33026909828186 s\n",
      "Accuracy 0.9330298376480912 precision 0.9331116055907003 specificity 0.882789762189703 recall 0.9330298376480912 f1 0.9330698974391878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 33.41826844215393 s\n",
      "Accuracy 0.9354980254497587 precision 0.9353626434417475 specificity 0.8804912380547395 recall 0.9354980254497587 f1 0.9354277944795655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 33.315269947052 s\n",
      "Accuracy 0.9318231680561649 precision 0.9316659324720066 specificity 0.8798300445370998 recall 0.9318231680561649 f1 0.9317410572598129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 33.760273694992065 s\n",
      "Accuracy 0.9359916630100922 precision 0.9359026140232743 specificity 0.8819247868152164 recall 0.9359916630100922 f1 0.9359460519631615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 34.06927561759949 s\n",
      "Accuracy 0.9319328652917946 precision 0.9318750099654607 specificity 0.8805109428061763 recall 0.9319328652917946 f1 0.9319034969753429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 33.52627158164978 s\n",
      "Accuracy 0.9348946906537955 precision 0.9349640400676735 specificity 0.8852688406752828 recall 0.9348946906537955 f1 0.9349287420051166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 33.0162672996521 s\n",
      "Accuracy 0.9310552874067574 precision 0.9309078223695477 specificity 0.8740948410626703 recall 0.9310552874067574 f1 0.9309788595535481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 33.50827169418335 s\n",
      "Accuracy 0.937033786748574 precision 0.9369629860892114 specificity 0.8858251312515906 recall 0.937033786748574 f1 0.9369976540283145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 34.04827547073364 s\n",
      "Accuracy 0.9337977182974989 precision 0.9341864559473 specificity 0.8843094825095099 recall 0.9337977182974989 f1 0.9339764290777702\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 33.79627561569214 s\n",
      "Accuracy 0.9324265028521281 precision 0.9326082941645005 specificity 0.8819998233925809 recall 0.9324265028521281 f1 0.9325136435700598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 33.06426501274109 s\n",
      "Accuracy 0.9371983326020185 precision 0.9375521079120338 specificity 0.8913873769800911 recall 0.9371983326020185 f1 0.9373604749925905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 33.32226920127869 s\n",
      "Accuracy 0.9342365072400175 precision 0.9342101848521245 specificity 0.8827648951291837 recall 0.9342365072400175 f1 0.9342232537680936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 33.054266691207886 s\n",
      "Accuracy 0.9363207547169812 precision 0.9360947517465597 specificity 0.8802474439021658 recall 0.9363207547169812 f1 0.9362001048998995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 33.3612699508667 s\n",
      "Accuracy 0.9342365072400175 precision 0.9344245934818335 specificity 0.8830243815841634 recall 0.9342365072400175 f1 0.9343265026860367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 33.50827097892761 s\n",
      "Accuracy 0.9362110574813515 precision 0.9362265678801113 specificity 0.8867176509558088 recall 0.9362110574813515 f1 0.9362187793364328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 33.6492702960968 s\n",
      "Accuracy 0.9328104431768319 precision 0.9328600936853707 specificity 0.8806395946086296 recall 0.9328104431768319 f1 0.932834969987809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 33.25626802444458 s\n",
      "Accuracy 0.9331943835015357 precision 0.9332947725765571 specificity 0.8815495592769711 recall 0.9331943835015357 f1 0.933243382265744\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 33.485270261764526 s\n",
      "Accuracy 0.936978938130759 precision 0.9368740000461915 specificity 0.8854479330451692 recall 0.936978938130759 f1 0.9369248218897839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 33.64627552032471 s\n",
      "Accuracy 0.9333589293549802 precision 0.9329824396945678 specificity 0.8767700351578581 recall 0.9333589293549802 f1 0.9331475884084915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 35.2732834815979 s\n",
      "Accuracy 0.9354980254497587 precision 0.9357727875876177 specificity 0.8861086945295114 recall 0.9354980254497587 f1 0.9356268213091952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 34.85128116607666 s\n",
      "Accuracy 0.9326458973233874 precision 0.9326799001842939 specificity 0.8777492587442264 recall 0.9326458973233874 f1 0.932662764792646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 34.625282287597656 s\n",
      "Accuracy 0.9341816586222027 precision 0.9340585075707006 specificity 0.8813779019506418 recall 0.9341816586222027 f1 0.9341179536902907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 35.32828378677368 s\n",
      "Accuracy 0.9331943835015357 precision 0.9333533495030768 specificity 0.8818301979180578 recall 0.9331943835015357 f1 0.9332709704716456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 34.7320442199707 s\n",
      "Accuracy 0.9340719613865731 precision 0.9340610896538183 specificity 0.8806071065181896 recall 0.9340719613865731 f1 0.9340665106328355\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 34.9330837726593 s\n",
      "Accuracy 0.9330298376480912 precision 0.9330027388909684 specificity 0.879741537533441 recall 0.9330298376480912 f1 0.9330161958736309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 34.24758958816528 s\n",
      "Accuracy 0.936046511627907 precision 0.9360057496602907 specificity 0.8857964994798 recall 0.936046511627907 f1 0.9360258935116107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 34.71747422218323 s\n",
      "Accuracy 0.9353334795963142 precision 0.93528652062153 specificity 0.8833604474932775 recall 0.9353334795963142 f1 0.935309698934849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 33.67997217178345 s\n",
      "Accuracy 0.9368692408951295 precision 0.936726562035816 specificity 0.8851296240709953 recall 0.9368692408951295 f1 0.9367947646978806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 34.17215824127197 s\n",
      "Accuracy 0.9378016673979815 precision 0.9379265234692311 specificity 0.8908892114793724 recall 0.9378016673979815 f1 0.9378619573851897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 33.968961238861084 s\n",
      "Accuracy 0.9354980254497587 precision 0.9354073934236081 specificity 0.8846307574402805 recall 0.9354980254497587 f1 0.9354515118101173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 34.51658391952515 s\n",
      "Accuracy 0.9316586222027204 precision 0.9317983345215298 specificity 0.87808076305993 recall 0.9316586222027204 f1 0.9317263504212597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 35.08712315559387 s\n",
      "Accuracy 0.9379113646336112 precision 0.9381183367105089 specificity 0.889878977262623 recall 0.9379113646336112 f1 0.9380094404459174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 34.25511908531189 s\n",
      "Accuracy 0.9365401491882405 precision 0.9363841447380136 specificity 0.8828257772599569 recall 0.9365401491882405 f1 0.9364585392350077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 35.39063739776611 s\n",
      "Accuracy 0.9380759104870557 precision 0.9378819298351199 specificity 0.8864836550672726 recall 0.9380759104870557 f1 0.9379726291216925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 34.29063844680786 s\n",
      "Accuracy 0.9342365072400175 precision 0.9344084791048283 specificity 0.8848894310074024 recall 0.9342365072400175 f1 0.9343189518283486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 34.4407696723938 s\n",
      "Accuracy 0.9325910487055726 precision 0.9326183625640202 specificity 0.8806170283444118 recall 0.9325910487055726 f1 0.9326046137803525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 34.02963066101074 s\n",
      "Accuracy 0.9368143922773147 precision 0.9367831787387486 specificity 0.8849401269554319 recall 0.9368143922773147 f1 0.9367986505093339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 33.83211803436279 s\n",
      "Accuracy 0.9331943835015357 precision 0.9332161425596353 specificity 0.8811301556256559 recall 0.9331943835015357 f1 0.9332052040438418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 35.79991436004639 s\n",
      "Accuracy 0.9356077226853883 precision 0.9356717862877688 specificity 0.8854492396259424 recall 0.9356077226853883 f1 0.9356392201035086\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 34.20763087272644 s\n",
      "Accuracy 0.9356077226853883 precision 0.9354519268910078 specificity 0.8847546807590775 recall 0.9356077226853883 f1 0.9355260488274071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 33.45011878013611 s\n",
      "Accuracy 0.9331943835015357 precision 0.9330365292987202 specificity 0.8777504275792052 recall 0.9331943835015357 f1 0.9331121136062328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 34.60912299156189 s\n",
      "Accuracy 0.9345655989469065 precision 0.9343383896403775 specificity 0.8790158953134746 recall 0.9345655989469065 f1 0.9344444364143\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 33.69362497329712 s\n",
      "Accuracy 0.9337977182974989 precision 0.9337388853932957 specificity 0.8801695385053494 recall 0.9337977182974989 f1 0.9337678526936436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 34.17763710021973 s\n",
      "Accuracy 0.9379113646336112 precision 0.9376388530390566 specificity 0.8859176976616567 recall 0.9379113646336112 f1 0.9377616797561731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 33.52056169509888 s\n",
      "Accuracy 0.9329749890302764 precision 0.9333124853881218 specificity 0.8848292348180609 recall 0.9329749890302764 f1 0.9331314188306925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 34.51520228385925 s\n",
      "Accuracy 0.9346204475647214 precision 0.9347204827629058 specificity 0.8826828433346809 recall 0.9346204475647214 f1 0.9346692584295893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 34.05411958694458 s\n",
      "Accuracy 0.9328652917946467 precision 0.933133488558089 specificity 0.8825405451965564 recall 0.9328652917946467 f1 0.9329915930664135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 33.83911848068237 s\n",
      "Accuracy 0.9327007459412023 precision 0.9325288998533648 specificity 0.8778125182064737 recall 0.9327007459412023 f1 0.9326108002579883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 33.17011642456055 s\n",
      "Accuracy 0.9352237823606845 precision 0.9350988139659603 specificity 0.8837924489130409 recall 0.9352237823606845 f1 0.9351589889785655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 33.73862838745117 s\n",
      "Accuracy 0.9313843791136464 precision 0.9310435642152262 specificity 0.872900284842203 recall 0.9313843791136464 f1 0.9311973641813592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 34.01911973953247 s\n",
      "Accuracy 0.9331395348837209 precision 0.933285303869275 specificity 0.8856726673039306 recall 0.9331395348837209 f1 0.9332097729734833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 34.07662510871887 s\n",
      "Accuracy 0.9365401491882405 precision 0.936396635259659 specificity 0.8845136036846932 recall 0.9365401491882405 f1 0.9364652571287578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 33.13111424446106 s\n",
      "Accuracy 0.9338525669153137 precision 0.934067070806577 specificity 0.8844535713908246 recall 0.9338525669153137 f1 0.9339544995620187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 33.78211808204651 s\n",
      "Accuracy 0.9354980254497587 precision 0.9356277482992378 specificity 0.8865193996289891 recall 0.9354980254497587 f1 0.9355607562201006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 34.70063233375549 s\n",
      "Accuracy 0.9338525669153137 precision 0.9337063402663917 specificity 0.8790629929769904 recall 0.9338525669153137 f1 0.9337765381844821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 34.92065119743347 s\n",
      "Accuracy 0.9329749890302764 precision 0.9331590372988948 specificity 0.8813126004531346 recall 0.9329749890302764 f1 0.9330632271667826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 34.06811881065369 s\n",
      "Accuracy 0.9342913558578324 precision 0.9340487108722273 specificity 0.8837117749606808 recall 0.9342913558578324 f1 0.9341601815784883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 33.854119539260864 s\n",
      "Accuracy 0.9358271171566477 precision 0.936279663489509 specificity 0.8904203588253515 recall 0.9358271171566477 f1 0.9360309270503966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 34.70163083076477 s\n",
      "Accuracy 0.9334686265906099 precision 0.9334845588576136 specificity 0.8830446649280761 recall 0.9334686265906099 f1 0.9334765597350447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 33.889872789382935 s\n",
      "Accuracy 0.9367595436594998 precision 0.9367130326355606 specificity 0.8848889389461965 recall 0.9367595436594998 f1 0.936735984704205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 34.230756998062134 s\n",
      "Accuracy 0.9354980254497587 precision 0.9357908500090005 specificity 0.8881288057312661 recall 0.9354980254497587 f1 0.9356344444045666\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 33.946632862091064 s\n",
      "Accuracy 0.935717419921018 precision 0.9355436621851078 specificity 0.8847470064249794 recall 0.935717419921018 f1 0.935625760814689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 33.81703519821167 s\n",
      "Accuracy 0.9391180342255375 precision 0.9392535876152613 specificity 0.891881714475627 recall 0.9391180342255375 f1 0.9391832772340939\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 33.56421184539795 s\n",
      "Accuracy 0.9356077226853883 precision 0.9352968841113869 specificity 0.8790198871074734 recall 0.9356077226853883 f1 0.9354369200767118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 33.67511558532715 s\n",
      "Accuracy 0.9334137779727951 precision 0.9334471132055595 specificity 0.8798624939500934 recall 0.9334137779727951 f1 0.933430311816968\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 33.78362846374512 s\n",
      "Accuracy 0.9318231680561649 precision 0.9323805056098802 specificity 0.8831272527563422 recall 0.9318231680561649 f1 0.932072751652947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 33.499117374420166 s\n",
      "Accuracy 0.9325362000877578 precision 0.9325699582327296 specificity 0.8783038239058091 recall 0.9325362000877578 f1 0.9325529456469511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 34.146172761917114 s\n",
      "Accuracy 0.9344559017112769 precision 0.9343770807174272 specificity 0.8812373440757223 recall 0.9344559017112769 f1 0.9344156551716574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 34.598148822784424 s\n",
      "Accuracy 0.9322619569986836 precision 0.9323119706642707 specificity 0.8797200490121326 recall 0.9322619569986836 f1 0.9322866657959672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 33.686572790145874 s\n",
      "Accuracy 0.9351689337428697 precision 0.9350666628817728 specificity 0.8828868996219265 recall 0.9351689337428697 f1 0.9351163138163046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 33.80288314819336 s\n",
      "Accuracy 0.9358819657744625 precision 0.9356196681312056 specificity 0.8822642180528314 recall 0.9358819657744625 f1 0.935739563131798\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 33.83012056350708 s\n",
      "Accuracy 0.9348946906537955 precision 0.935008941644436 specificity 0.8851085580531238 recall 0.9348946906537955 f1 0.93495018552861\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 33.5791175365448 s\n",
      "Accuracy 0.937033786748574 precision 0.93715935326442 specificity 0.8899876244117577 recall 0.937033786748574 f1 0.9370944399068305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 34.65759801864624 s\n",
      "Accuracy 0.9322619569986836 precision 0.932373022810015 specificity 0.8771872481472263 recall 0.9322619569986836 f1 0.9323161449201657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 34.0021185874939 s\n",
      "Accuracy 0.9336880210618692 precision 0.933470252918781 specificity 0.8787300087501495 recall 0.9336880210618692 f1 0.9335722826233499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 34.51404619216919 s\n",
      "Accuracy 0.9344559017112769 precision 0.9344829978211985 specificity 0.8823322629542463 recall 0.9344559017112769 f1 0.9344693569227717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 35.06923246383667 s\n",
      "Accuracy 0.9377468187801667 precision 0.9375288941009318 specificity 0.8837898444843093 recall 0.9377468187801667 f1 0.9376302176313129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 35.216635942459106 s\n",
      "Accuracy 0.9334137779727951 precision 0.9337821039462072 specificity 0.8840933852188317 recall 0.9334137779727951 f1 0.933583745712402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 35.182326316833496 s\n",
      "Accuracy 0.9329201404124616 precision 0.9331415617216813 specificity 0.8835646796264938 recall 0.9329201404124616 f1 0.9330252763791239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 34.78423547744751 s\n",
      "Accuracy 0.9315489249670909 precision 0.9317265029825197 specificity 0.8776301144112467 recall 0.9315489249670909 f1 0.9316343824154885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 34.50912022590637 s\n",
      "Accuracy 0.9312198332602019 precision 0.931372454129947 specificity 0.8774510985205684 recall 0.9312198332602019 f1 0.9312936492917364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 35.03612446784973 s\n",
      "Accuracy 0.9327007459412023 precision 0.9331175496342947 specificity 0.88340941090172 recall 0.9327007459412023 f1 0.9328916115223547\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 34.14712119102478 s\n",
      "Accuracy 0.9345107503290917 precision 0.9348501844072575 specificity 0.8820511526394541 recall 0.9345107503290917 f1 0.9346686692866258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 33.93409252166748 s\n",
      "Accuracy 0.9326458973233874 precision 0.932769281603673 specificity 0.8814614697314828 recall 0.9326458973233874 f1 0.932705810488678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 34.06556510925293 s\n",
      "Accuracy 0.9356077226853883 precision 0.9355970616256909 specificity 0.8830539979594968 recall 0.9356077226853883 f1 0.9356023771995525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 33.49715542793274 s\n",
      "Accuracy 0.9351140851250549 precision 0.9352496578454141 specificity 0.8862001160486995 recall 0.9351140851250549 f1 0.9351795646488763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 34.44405174255371 s\n",
      "Accuracy 0.9329749890302764 precision 0.933073530547389 specificity 0.8829327154309087 recall 0.9329749890302764 f1 0.9330230735950529\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 34.75483322143555 s\n",
      "Accuracy 0.9340171127687582 precision 0.9341316459819081 specificity 0.884382405336395 recall 0.9340171127687582 f1 0.9340727576453661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 33.891050577163696 s\n",
      "Accuracy 0.9319328652917946 precision 0.9321998678867517 specificity 0.8802896125137091 recall 0.9319328652917946 f1 0.9320589027628465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 33.509559631347656 s\n",
      "Accuracy 0.9337428696796841 precision 0.9334892488382824 specificity 0.8800950508096127 recall 0.9337428696796841 f1 0.9336061048819454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 33.725841999053955 s\n",
      "Accuracy 0.936046511627907 precision 0.9363540594622921 specificity 0.8879296663909767 recall 0.936046511627907 f1 0.9361894326828903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 33.55556297302246 s\n",
      "Accuracy 0.9370886353663888 precision 0.9373191577163057 specificity 0.8914553874122255 recall 0.9370886353663888 f1 0.937197071067144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 34.35005259513855 s\n",
      "Accuracy 0.9320425625274243 precision 0.9320591729635126 specificity 0.8788409437766097 recall 0.9320425625274243 f1 0.9320508346170554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 33.431050300598145 s\n",
      "Accuracy 0.9333040807371654 precision 0.9332493766419884 specificity 0.878212307812833 recall 0.9333040807371654 f1 0.9332763561259129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 33.714961767196655 s\n",
      "Accuracy 0.9319877139096094 precision 0.9320671302601362 specificity 0.8787181053001811 recall 0.9319877139096094 f1 0.9320266990668085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 33.49956226348877 s\n",
      "Accuracy 0.9380759104870557 precision 0.9381864672712674 specificity 0.8896082140209828 recall 0.9380759104870557 f1 0.9381295384971334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 34.007049322128296 s\n",
      "Accuracy 0.9345655989469065 precision 0.9345085547571345 specificity 0.8830730692562998 recall 0.9345655989469065 f1 0.934536629951571\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 33.673564434051514 s\n",
      "Accuracy 0.9348946906537955 precision 0.9348784386121471 specificity 0.8811571162461234 recall 0.9348946906537955 f1 0.934886530950887\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 33.92464303970337 s\n",
      "Accuracy 0.9321522597630539 precision 0.9325054967241159 specificity 0.8851706494471994 recall 0.9321522597630539 f1 0.9323153729739594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 33.85805010795593 s\n",
      "Accuracy 0.9327007459412023 precision 0.9329157834867225 specificity 0.8811393799289988 recall 0.9327007459412023 f1 0.9328032076682733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 33.33305048942566 s\n",
      "Accuracy 0.9336331724440544 precision 0.93365514217684 specificity 0.8805849731672729 recall 0.9336331724440544 f1 0.9336440979357323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 33.41705131530762 s\n",
      "Accuracy 0.9374177270732778 precision 0.9378428812243069 specificity 0.8928607362917684 recall 0.9374177270732778 f1 0.9376094412346578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 33.961562395095825 s\n",
      "Accuracy 0.934730144800351 precision 0.934730144800351 specificity 0.8837225206554691 recall 0.934730144800351 f1 0.934730144800351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 33.91159248352051 s\n",
      "Accuracy 0.9351140851250549 precision 0.935119393114638 specificity 0.8836648043568066 recall 0.9351140851250549 f1 0.9351167354067131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 33.46411418914795 s\n",
      "Accuracy 0.9333589293549802 precision 0.9336662027004934 specificity 0.8845332972198084 recall 0.9333589293549802 f1 0.9335022388012509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 33.86104989051819 s\n",
      "Accuracy 0.9346204475647214 precision 0.934382671655163 specificity 0.8800144783642928 recall 0.9346204475647214 f1 0.9344929973248721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 34.226051568984985 s\n",
      "Accuracy 0.937308029837648 precision 0.9373666446575797 specificity 0.8864000458530438 recall 0.937308029837648 f1 0.9373368824210553\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 34.286051750183105 s\n",
      "Accuracy 0.9363207547169812 precision 0.9362945738327816 specificity 0.8843367846801673 recall 0.9363207547169812 f1 0.9363075707211128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 33.91605043411255 s\n",
      "Accuracy 0.937033786748574 precision 0.9368692130597506 specificity 0.8855444504033066 recall 0.937033786748574 f1 0.9369471938766257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 33.14355969429016 s\n",
      "Accuracy 0.9374725756910925 precision 0.937503782546692 specificity 0.8875045831528329 recall 0.9374725756910925 f1 0.9374880444076255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 33.6476616859436 s\n",
      "Accuracy 0.9348946906537955 precision 0.9347859546830366 specificity 0.8815646577823686 recall 0.9348946906537955 f1 0.934838681352276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 33.85605263710022 s\n",
      "Accuracy 0.9334137779727951 precision 0.9334909141616262 specificity 0.8819753335786057 recall 0.9334137779727951 f1 0.9334516230750978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 34.67808222770691 s\n",
      "Accuracy 0.937308029837648 precision 0.9376010502542476 specificity 0.890949951943862 recall 0.937308029837648 f1 0.9374440965396037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 33.342050075531006 s\n",
      "Accuracy 0.9355528740675735 precision 0.9355272160590953 specificity 0.8855075993211321 recall 0.9355528740675735 f1 0.9355399527070815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 33.42556715011597 s\n",
      "Accuracy 0.9354431768319439 precision 0.9352753523214062 specificity 0.8810797613703847 recall 0.9354431768319439 f1 0.9353551913425179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 34.196614503860474 s\n",
      "Accuracy 0.9348398420359807 precision 0.9349400605800584 specificity 0.8826599132977442 recall 0.9348398420359807 f1 0.934888741810202\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 32.89309239387512 s\n",
      "Accuracy 0.9374177270732778 precision 0.9375936560392216 specificity 0.8903573386270507 recall 0.9374177270732778 f1 0.9375016466080355\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 33.520050287246704 s\n",
      "Accuracy 0.9330298376480912 precision 0.9327405737683759 specificity 0.8780833165441582 recall 0.9330298376480912 f1 0.9328723850862876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 34.01005291938782 s\n",
      "Accuracy 0.9337977182974989 precision 0.9341034459214018 specificity 0.8852358399544299 recall 0.9337977182974989 f1 0.9339402417743636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 34.117095947265625 s\n",
      "Accuracy 0.936978938130759 precision 0.9366559770996304 specificity 0.8833423098679687 recall 0.936978938130759 f1 0.9367986534607786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 33.42605185508728 s\n",
      "Accuracy 0.9343462044756472 precision 0.934238685560848 specificity 0.8821786499802416 recall 0.9343462044756472 f1 0.9342908167290634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 33.86404848098755 s\n",
      "Accuracy 0.9364304519526108 precision 0.9361604985215018 specificity 0.8802419858831002 recall 0.9364304519526108 f1 0.9362840611885745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 33.91556167602539 s\n",
      "Accuracy 0.9365401491882405 precision 0.9365140689258493 specificity 0.884763506167987 recall 0.9365401491882405 f1 0.9365270154736428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 33.750213384628296 s\n",
      "Accuracy 0.9351140851250549 precision 0.9349857863596908 specificity 0.881661854413311 recall 0.9351140851250549 f1 0.9350476075316374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 33.52905035018921 s\n",
      "Accuracy 0.9358271171566477 precision 0.9359804088232535 specificity 0.886405100260452 recall 0.9358271171566477 f1 0.9359008491314523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 33.74605107307434 s\n",
      "Accuracy 0.9308358929354981 precision 0.9310441279478814 specificity 0.8776262388739463 recall 0.9308358929354981 f1 0.9309355019208123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 34.140562534332275 s\n",
      "Accuracy 0.9352237823606845 precision 0.9357305302717199 specificity 0.8889935222767139 recall 0.9352237823606845 f1 0.935450426606835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 34.773563385009766 s\n",
      "Accuracy 0.9350043878894252 precision 0.9349683688287361 specificity 0.884637283109751 recall 0.9350043878894252 f1 0.9349861976961983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 35.249669551849365 s\n",
      "Accuracy 0.9337977182974989 precision 0.9339783195362034 specificity 0.8860385622582754 recall 0.9337977182974989 f1 0.9338840416996946\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 33.722052812576294 s\n",
      "Accuracy 0.9356077226853883 precision 0.9357516970853279 specificity 0.8849956880198934 recall 0.9356077226853883 f1 0.9356771882959156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 35.01905059814453 s\n",
      "Accuracy 0.9361013602457218 precision 0.9363270415421795 specificity 0.8884242285285717 recall 0.9361013602457218 f1 0.9362079742361603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 34.43705201148987 s\n",
      "Accuracy 0.9359916630100922 precision 0.9359347074485853 specificity 0.8839625015036578 recall 0.9359916630100922 f1 0.9359627337684041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 33.75505018234253 s\n",
      "Accuracy 0.9344559017112769 precision 0.9345856666609387 specificity 0.8822264619390154 recall 0.9344559017112769 f1 0.9345188111261169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 34.186583042144775 s\n",
      "Accuracy 0.9341816586222027 precision 0.9341599385942616 specificity 0.8803942585897077 recall 0.9341816586222027 f1 0.9341707389656326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 34.310606479644775 s\n",
      "Accuracy 0.9355528740675735 precision 0.9353539945730058 specificity 0.8797901798117629 recall 0.9355528740675735 f1 0.9354477146279301\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 34.98399639129639 s\n",
      "Accuracy 0.9342365072400175 precision 0.9343773599699599 specificity 0.8825677105095202 recall 0.9342365072400175 f1 0.9343046099912958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 34.89316177368164 s\n",
      "Accuracy 0.9326458973233874 precision 0.9325200449181327 specificity 0.8788389682070462 recall 0.9326458973233874 f1 0.9325808499296595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 34.52796268463135 s\n",
      "Accuracy 0.9347849934181659 precision 0.9345967774801629 specificity 0.8800004278788834 recall 0.9347849934181659 f1 0.9346857782645157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 33.72467279434204 s\n",
      "Accuracy 0.9354431768319439 precision 0.9352950500947692 specificity 0.8814692463899222 recall 0.9354431768319439 f1 0.9353659705023651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 35.224562883377075 s\n",
      "Accuracy 0.9331395348837209 precision 0.9331235147800057 specificity 0.8813656967264232 recall 0.9331395348837209 f1 0.9331314917491984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 34.35256028175354 s\n",
      "Accuracy 0.9361013602457218 precision 0.9360961612382629 specificity 0.885505894288362 recall 0.9361013602457218 f1 0.9360987570242236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 34.775562047958374 s\n",
      "Accuracy 0.9329201404124616 precision 0.9327488192488156 specificity 0.8781712142223941 recall 0.9329201404124616 f1 0.9328304548834734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 35.19313907623291 s\n",
      "Accuracy 0.9347849934181659 precision 0.9347281015397281 specificity 0.883403349963976 recall 0.9347849934181659 f1 0.934756100266614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 33.530216217041016 s\n",
      "Accuracy 0.9375274243089075 precision 0.9372730062276798 specificity 0.8853189593087528 recall 0.9375274243089075 f1 0.937388931606875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 34.43095898628235 s\n",
      "Accuracy 0.936046511627907 precision 0.9360253637710727 specificity 0.8835937738474657 recall 0.936046511627907 f1 0.9360358777803014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 34.51402258872986 s\n",
      "Accuracy 0.9383501535761298 precision 0.9383908393182776 specificity 0.8900986135531621 recall 0.9383501535761298 f1 0.9383702575499896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 34.31701874732971 s\n",
      "Accuracy 0.9336331724440544 precision 0.9340149466395096 specificity 0.8871054279382646 recall 0.9336331724440544 f1 0.933808137165076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 34.22815561294556 s\n",
      "Accuracy 0.9352237823606845 precision 0.9354631322488204 specificity 0.887321527626486 recall 0.9352237823606845 f1 0.9353366320402755\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 33.86553192138672 s\n",
      "Accuracy 0.9359916630100922 precision 0.9361050732628872 specificity 0.8863562885794889 recall 0.9359916630100922 f1 0.9360467285997075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 33.478965282440186 s\n",
      "Accuracy 0.9346204475647214 precision 0.9345489823732952 specificity 0.8838087758155772 recall 0.9346204475647214 f1 0.9345839934473409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 33.5150203704834 s\n",
      "Accuracy 0.9362659060991663 precision 0.9362230789034586 specificity 0.8819510230186383 recall 0.9362659060991663 f1 0.9362442507680715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 33.47805309295654 s\n",
      "Accuracy 0.936046511627907 precision 0.9359534817504548 specificity 0.8828556349319492 recall 0.936046511627907 f1 0.9359987830893309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 33.732038497924805 s\n",
      "Accuracy 0.9359368143922773 precision 0.9362654341420119 specificity 0.8889663658349244 recall 0.9359368143922773 f1 0.9360886657292427\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 34.22002029418945 s\n",
      "Accuracy 0.9333040807371654 precision 0.9331424679242682 specificity 0.8807518197703855 recall 0.9333040807371654 f1 0.9332195160978494\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 33.85402035713196 s\n",
      "Accuracy 0.9341816586222027 precision 0.9342038124165348 specificity 0.8801951743112317 recall 0.9341816586222027 f1 0.9341926757265846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 33.83102226257324 s\n",
      "Accuracy 0.938021061869241 precision 0.9379235480485326 specificity 0.8880532982059085 recall 0.938021061869241 f1 0.9379708124944778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 33.30401945114136 s\n",
      "Accuracy 0.9364853005704257 precision 0.9362838785055322 specificity 0.884516552346321 recall 0.9364853005704257 f1 0.9363780355533976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 33.7876296043396 s\n",
      "Accuracy 0.9352786309784994 precision 0.9351021389324798 specificity 0.8791414115023911 recall 0.9352786309784994 f1 0.9351860330381176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 33.825088024139404 s\n",
      "Accuracy 0.9346204475647214 precision 0.9347751545766729 specificity 0.8849271348643264 recall 0.9346204475647214 f1 0.9346949033312647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 33.738019943237305 s\n",
      "Accuracy 0.9318231680561649 precision 0.931708524382933 specificity 0.8756123751114222 recall 0.9318231680561649 f1 0.9317642122210164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 33.54302000999451 s\n",
      "Accuracy 0.9327555945590171 precision 0.9326384815089696 specificity 0.8780226695590531 recall 0.9327555945590171 f1 0.9326952470504346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 33.997021198272705 s\n",
      "Accuracy 0.9329749890302764 precision 0.9329087494849321 specificity 0.876908722671442 recall 0.9329749890302764 f1 0.9329413317763897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 33.38401985168457 s\n",
      "Accuracy 0.9342365072400175 precision 0.9345155975737226 specificity 0.8858692009621834 recall 0.9342365072400175 f1 0.9343672078905132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 35.08419990539551 s\n",
      "Accuracy 0.9339074155331286 precision 0.9339238664481018 specificity 0.8806921693361236 recall 0.9339074155331286 f1 0.9339156075252392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 35.044020652770996 s\n",
      "Accuracy 0.9338525669153137 precision 0.9337436531327199 specificity 0.8770391190381878 recall 0.9338525669153137 f1 0.933796607544272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 34.338101863861084 s\n",
      "Accuracy 0.9333040807371654 precision 0.9333477636873199 specificity 0.8815903046906699 recall 0.9333040807371654 f1 0.9333256862863349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 34.00606155395508 s\n",
      "Accuracy 0.9325910487055726 precision 0.9328848467274271 specificity 0.8842084526585535 recall 0.9325910487055726 f1 0.932728447550039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 33.62402057647705 s\n",
      "Accuracy 0.934730144800351 precision 0.9344989038670436 specificity 0.879260411765497 recall 0.934730144800351 f1 0.9346066240456371\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 33.74504113197327 s\n",
      "Accuracy 0.9356077226853883 precision 0.9356916722966534 specificity 0.8875117480813561 recall 0.9356077226853883 f1 0.9356487554119506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 33.97502088546753 s\n",
      "Accuracy 0.9326458973233874 precision 0.932898185181593 specificity 0.8791504847912297 recall 0.9326458973233874 f1 0.9327654669587682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 34.074376583099365 s\n",
      "Accuracy 0.9354980254497587 precision 0.935367079987082 specificity 0.8831664449719919 recall 0.9354980254497587 f1 0.9354300420478668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 34.173020124435425 s\n",
      "Accuracy 0.9321522597630539 precision 0.9325038575335839 specificity 0.8824730027425985 recall 0.9321522597630539 f1 0.9323152819220211\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 33.90601944923401 s\n",
      "Accuracy 0.935717419921018 precision 0.9363879860306549 specificity 0.8917683402497145 recall 0.935717419921018 f1 0.9360080054834818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 33.82153010368347 s\n",
      "Accuracy 0.9293001316366828 precision 0.9297084454035333 specificity 0.8800009730766293 recall 0.9293001316366828 f1 0.929488059905216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 34.19602060317993 s\n",
      "Accuracy 0.9338525669153137 precision 0.9337783559366439 specificity 0.8803898105672011 recall 0.9338525669153137 f1 0.9338147346110639\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 35.18768668174744 s\n",
      "Accuracy 0.9365949978060553 precision 0.9366560850963065 specificity 0.889705713267866 recall 0.9365949978060553 f1 0.9366250120798387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 34.762535095214844 s\n",
      "Accuracy 0.9342913558578324 precision 0.9345052025694545 specificity 0.8849804403731036 recall 0.9342913558578324 f1 0.9343929490737467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 34.08012914657593 s\n",
      "Accuracy 0.9364853005704257 precision 0.9366820292690258 specificity 0.888366930495987 recall 0.9364853005704257 f1 0.9365788497302329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 35.049612283706665 s\n",
      "Accuracy 0.9374725756910925 precision 0.9376211936863006 specificity 0.8898524561154134 recall 0.9374725756910925 f1 0.9375439675651119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 35.52604961395264 s\n",
      "Accuracy 0.93505923650724 precision 0.9349333074819862 specificity 0.8800157997090314 recall 0.93505923650724 f1 0.9349941118071642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 35.41948461532593 s\n",
      "Accuracy 0.935717419921018 precision 0.9358924586134063 specificity 0.8871095761327317 recall 0.935717419921018 f1 0.935801146265839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 34.36205577850342 s\n",
      "Accuracy 0.9327555945590171 precision 0.9328551689595688 specificity 0.8819568157071406 recall 0.9327555945590171 f1 0.9328041931015123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 34.93602204322815 s\n",
      "Accuracy 0.9330298376480912 precision 0.9332534540923056 specificity 0.8828239021088913 recall 0.9330298376480912 f1 0.9331360473538716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 34.57200074195862 s\n",
      "Accuracy 0.937362878455463 precision 0.9374374163644388 specificity 0.8870435708736624 recall 0.937362878455463 f1 0.9373994118890039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 34.387593507766724 s\n",
      "Accuracy 0.936978938130759 precision 0.9369639145726834 specificity 0.8885281607469528 recall 0.936978938130759 f1 0.9369713930695264\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 35.21360421180725 s\n",
      "Accuracy 0.9351689337428697 precision 0.9352580864902917 specificity 0.8824258426618634 recall 0.9351689337428697 f1 0.9352125507489806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 34.8520450592041 s\n",
      "Accuracy 0.9355528740675735 precision 0.9353219139666196 specificity 0.8812658046600266 recall 0.9355528740675735 f1 0.9354291531845793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 33.92604899406433 s\n",
      "Accuracy 0.9378565160157964 precision 0.9377903886738718 specificity 0.8859836804971805 recall 0.9378565160157964 f1 0.9378228158248704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 35.3531174659729 s\n",
      "Accuracy 0.9312746818780167 precision 0.9314271144992341 specificity 0.8809417545589151 recall 0.9312746818780167 f1 0.9313482449245474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 34.789021730422974 s\n",
      "Accuracy 0.9368143922773147 precision 0.936911834408436 specificity 0.8861146198041054 recall 0.9368143922773147 f1 0.9368618981105709\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 36.11802124977112 s\n",
      "Accuracy 0.9362110574813515 precision 0.9360937416142111 specificity 0.8830724636973691 recall 0.9362110574813515 f1 0.9361504188549254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 35.45253229141235 s\n",
      "Accuracy 0.9312198332602019 precision 0.931066645340705 specificity 0.8791626636038123 recall 0.9312198332602019 f1 0.9311399763576396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 34.07568287849426 s\n",
      "Accuracy 0.9356625713032032 precision 0.9360075548064606 specificity 0.8894409565157346 recall 0.9356625713032032 f1 0.9358213415973422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 33.80601978302002 s\n",
      "Accuracy 0.9322071083808688 precision 0.9324605305809324 specificity 0.8827858613717966 recall 0.9322071083808688 f1 0.9323267415202291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 33.88689184188843 s\n",
      "Accuracy 0.9381856077226853 precision 0.9380854241500992 specificity 0.8895833315522735 recall 0.9381856077226853 f1 0.9381338797728219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 35.42205619812012 s\n",
      "Accuracy 0.9358271171566477 precision 0.935966739390651 specificity 0.8875822566556169 recall 0.9358271171566477 f1 0.935894430296496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 34.74453377723694 s\n",
      "Accuracy 0.9345107503290917 precision 0.9346097889260248 specificity 0.8834402855190095 recall 0.9345107503290917 f1 0.9345590681752728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 34.674561738967896 s\n",
      "Accuracy 0.9370886353663888 precision 0.9369809205672106 specificity 0.883437885990101 recall 0.9370886353663888 f1 0.9370331140668631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 34.997023582458496 s\n",
      "Accuracy 0.9329749890302764 precision 0.9328805294301962 specificity 0.8800233283685883 recall 0.9329749890302764 f1 0.9329265668878182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 35.589019536972046 s\n",
      "Accuracy 0.9363207547169812 precision 0.9363986812431002 specificity 0.8885251035376486 recall 0.9363207547169812 f1 0.9363588880563148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 35.0281822681427 s\n",
      "Accuracy 0.9337428696796841 precision 0.9337428696796841 specificity 0.8832308884151898 recall 0.9337428696796841 f1 0.9337428696796841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 35.09254288673401 s\n",
      "Accuracy 0.9357722685388328 precision 0.935841504757912 specificity 0.8859129030799234 recall 0.9357722685388328 f1 0.9358062596151392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 34.33146071434021 s\n",
      "Accuracy 0.9334686265906099 precision 0.933586703256581 specificity 0.8815678947033762 recall 0.9334686265906099 f1 0.9335260321038543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 34.96405339241028 s\n",
      "Accuracy 0.9361013602457218 precision 0.9359492177633524 specificity 0.8845707738623753 recall 0.9361013602457218 f1 0.936021724533052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 35.49307179450989 s\n",
      "Accuracy 0.9322619569986836 precision 0.932062459195341 specificity 0.8739505743102773 recall 0.9322619569986836 f1 0.9321570958836919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 33.79002046585083 s\n",
      "Accuracy 0.9331395348837209 precision 0.9328738358107607 specificity 0.8800113931356282 recall 0.9331395348837209 f1 0.9329956140682057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 33.88602089881897 s\n",
      "Accuracy 0.9352786309784994 precision 0.9356219367465473 specificity 0.8880824008524478 recall 0.9352786309784994 f1 0.9354369813757605\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 34.15453124046326 s\n",
      "Accuracy 0.9341268100043879 precision 0.9342095851784304 specificity 0.8824416497282053 recall 0.9341268100043879 f1 0.9341673633279454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 33.7276029586792 s\n",
      "Accuracy 0.9362659060991663 precision 0.9363609041625529 specificity 0.8878013900510523 recall 0.9362659060991663 f1 0.9363122059242749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 34.053022623062134 s\n",
      "Accuracy 0.9334137779727951 precision 0.9334137779727951 specificity 0.880684258710326 recall 0.9334137779727951 f1 0.9334137779727951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 33.97901892662048 s\n",
      "Accuracy 0.9356625713032032 precision 0.9360052728614914 specificity 0.8899626011111509 recall 0.9356625713032032 f1 0.9358202336905733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 34.74902057647705 s\n",
      "Accuracy 0.9346752961825362 precision 0.9346912954391533 specificity 0.8833966531894867 recall 0.9346752961825362 f1 0.9346832624837121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 33.762107849121094 s\n",
      "Accuracy 0.9352786309784994 precision 0.9353954794482843 specificity 0.8874096504242495 recall 0.9352786309784994 f1 0.9353352767519139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 34.14153003692627 s\n",
      "Accuracy 0.9359916630100922 precision 0.9360176571108688 specificity 0.8865172672384616 recall 0.9359916630100922 f1 0.9360045675164422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 33.73102116584778 s\n",
      "Accuracy 0.9368692408951295 precision 0.9369614506592626 specificity 0.8858068036949831 recall 0.9368692408951295 f1 0.9369142599488062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 34.09802055358887 s\n",
      "Accuracy 0.9333040807371654 precision 0.9330451219948239 specificity 0.8754136201789144 recall 0.9333040807371654 f1 0.9331652523083932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 33.738529205322266 s\n",
      "Accuracy 0.9350043878894252 precision 0.9350205312706263 specificity 0.88285678898399 recall 0.9350043878894252 f1 0.9350124260655912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 34.52453017234802 s\n",
      "Accuracy 0.9327555945590171 precision 0.9328464125425616 specificity 0.8794678176172557 recall 0.9327555945590171 f1 0.9328000548157206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 34.26061391830444 s\n",
      "Accuracy 0.9346204475647214 precision 0.9348725703282885 specificity 0.8847588277534068 recall 0.9346204475647214 f1 0.9347393225414534\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 33.68201923370361 s\n",
      "Accuracy 0.9334137779727951 precision 0.933552268770537 specificity 0.8798810277982899 recall 0.9334137779727951 f1 0.9334808751752403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 34.29160141944885 s\n",
      "Accuracy 0.935388328214129 precision 0.9353779003717653 specificity 0.8847042015807526 recall 0.935388328214129 f1 0.9353830994776592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 34.073020696640015 s\n",
      "Accuracy 0.9306713470820536 precision 0.9308555139995188 specificity 0.8798303568574618 recall 0.9306713470820536 f1 0.9307597037539017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 33.95006227493286 s\n",
      "Accuracy 0.9349495392716104 precision 0.9354139607831325 specificity 0.8877095293990105 recall 0.9349495392716104 f1 0.9351592114487673\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 34.08654260635376 s\n",
      "Accuracy 0.9332492321193506 precision 0.9336723001535572 specificity 0.8852675985560745 recall 0.9332492321193506 f1 0.9334422394729791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 34.264081716537476 s\n",
      "Accuracy 0.9341268100043879 precision 0.9342664169390059 specificity 0.8832351158392256 recall 0.9341268100043879 f1 0.9341942990911964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 33.765021562576294 s\n",
      "Accuracy 0.937308029837648 precision 0.9373648706269935 specificity 0.8888128194263462 recall 0.937308029837648 f1 0.9373360004131052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 33.7720205783844 s\n",
      "Accuracy 0.9348398420359807 precision 0.9348084581275797 specificity 0.8834327494783997 recall 0.9348398420359807 f1 0.9348240168327852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 34.10252928733826 s\n",
      "Accuracy 0.9338525669153137 precision 0.9339282354116052 specificity 0.883787770970127 recall 0.9338525669153137 f1 0.9338896807462772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 33.219552993774414 s\n",
      "Accuracy 0.935717419921018 precision 0.935717419921018 specificity 0.88434177521079 recall 0.935717419921018 f1 0.935717419921018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 33.29001998901367 s\n",
      "Accuracy 0.9355528740675735 precision 0.9355798160484807 specificity 0.8834155200169175 recall 0.9355528740675735 f1 0.9355662516397834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 34.885549783706665 s\n",
      "Accuracy 0.9336331724440544 precision 0.9339770186929649 specificity 0.8868442831939415 recall 0.9336331724440544 f1 0.9337919387901973\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 33.58004117012024 s\n",
      "Accuracy 0.9346752961825362 precision 0.934827115239994 specificity 0.8833524770704366 recall 0.9346752961825362 f1 0.9347484916646894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 33.86159610748291 s\n",
      "Accuracy 0.9317683194383501 precision 0.9317469191653511 specificity 0.8802698538947393 recall 0.9317683194383501 f1 0.9317575609859566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 33.78105068206787 s\n",
      "Accuracy 0.9333040807371654 precision 0.9332818225886566 specificity 0.8778598543539297 recall 0.9333040807371654 f1 0.9332928918932313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 34.125020027160645 s\n",
      "Accuracy 0.9356625713032032 precision 0.9357106507070553 specificity 0.8848935341388533 recall 0.9356625713032032 f1 0.9356863097039853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 33.96802067756653 s\n",
      "Accuracy 0.9345655989469065 precision 0.9345602787145231 specificity 0.8828155918211895 recall 0.9345655989469065 f1 0.93456293512545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 35.21402287483215 s\n",
      "Accuracy 0.9335783238262396 precision 0.9339603980195401 specificity 0.885596770148032 recall 0.9335783238262396 f1 0.9337538254766897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 34.29046821594238 s\n",
      "Accuracy 0.934401053093462 precision 0.9343282098209268 specificity 0.8821834048623917 recall 0.934401053093462 f1 0.9343639063664715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 34.66056752204895 s\n",
      "Accuracy 0.9345107503290917 precision 0.9347347724336582 specificity 0.8858548502731632 recall 0.9345107503290917 f1 0.9346168627485518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 33.54202055931091 s\n",
      "Accuracy 0.9324813514699429 precision 0.9325654085871121 specificity 0.880206465478508 recall 0.9324813514699429 f1 0.932522551115894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 35.26225447654724 s\n",
      "Accuracy 0.937637121544537 precision 0.9375931532451443 specificity 0.8896812966468631 recall 0.937637121544537 f1 0.937614837864566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 34.78354263305664 s\n",
      "Accuracy 0.9331943835015357 precision 0.9333543849312969 specificity 0.8812879572965945 recall 0.9331943835015357 f1 0.9332714814767196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 33.879409074783325 s\n",
      "Accuracy 0.934730144800351 precision 0.9347083086988971 specificity 0.8802464901726883 recall 0.934730144800351 f1 0.9347191667467826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 34.599021196365356 s\n",
      "Accuracy 0.9359368143922773 precision 0.9359680610404253 specificity 0.886528952041356 recall 0.9359368143922773 f1 0.935952304503663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 34.082616090774536 s\n",
      "Accuracy 0.9345655989469065 precision 0.9343127508557691 specificity 0.8793671028769873 recall 0.9345655989469065 f1 0.9344294931365399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 33.58451700210571 s\n",
      "Accuracy 0.9348946906537955 precision 0.9348999735443118 specificity 0.8839206944058974 recall 0.9348946906537955 f1 0.9348973283981131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 33.59802174568176 s\n",
      "Accuracy 0.9356625713032032 precision 0.9363007551285373 specificity 0.8892166488511729 recall 0.9356625713032032 f1 0.9359420974441197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 33.91801881790161 s\n",
      "Accuracy 0.9354431768319439 precision 0.9356228191634354 specificity 0.8874927397035398 recall 0.9354431768319439 f1 0.9355289814729272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 33.726611375808716 s\n",
      "Accuracy 0.9356077226853883 precision 0.935457850400171 specificity 0.8831280564014442 recall 0.9356077226853883 f1 0.9355294425786904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 33.9135947227478 s\n",
      "Accuracy 0.9364853005704257 precision 0.9364335754733074 specificity 0.8844887930010046 recall 0.9364853005704257 f1 0.936459063853117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 33.90700316429138 s\n",
      "Accuracy 0.9348398420359807 precision 0.934727842502615 specificity 0.8827054538703344 recall 0.9348398420359807 f1 0.9347820511136582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 34.4690055847168 s\n",
      "Accuracy 0.9320974111452391 precision 0.932244396083088 specificity 0.8811646137282214 recall 0.9320974111452391 f1 0.9321684268273978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 34.13200116157532 s\n",
      "Accuracy 0.9371434839842036 precision 0.9375128879828151 specificity 0.8893335102118769 recall 0.9371434839842036 f1 0.9373128265021606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 34.08652114868164 s\n",
      "Accuracy 0.9346204475647214 precision 0.9344956323158274 specificity 0.8805220597265602 recall 0.9346204475647214 f1 0.9345558936416146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 35.004618406295776 s\n",
      "Accuracy 0.9343462044756472 precision 0.9344847120288362 specificity 0.8840137344591376 recall 0.9343462044756472 f1 0.9344131467101725\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 33.92960524559021 s\n",
      "Accuracy 0.9319877139096094 precision 0.93236231530437 specificity 0.8817101671955908 recall 0.9319877139096094 f1 0.932160873365706\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 33.489004373550415 s\n",
      "Accuracy 0.9343462044756472 precision 0.9341684133669506 specificity 0.8802693525368386 recall 0.9343462044756472 f1 0.9342527616141073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 33.539512157440186 s\n",
      "Accuracy 0.9321522597630539 precision 0.9323455283577443 specificity 0.879445812399513 recall 0.9321522597630539 f1 0.9322448673633229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 34.25400376319885 s\n",
      "Accuracy 0.934401053093462 precision 0.934856159817443 specificity 0.8865111448111829 recall 0.934401053093462 f1 0.9346072240392178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 33.66300368309021 s\n",
      "Accuracy 0.9313843791136464 precision 0.9313901516085079 specificity 0.8745452711123768 recall 0.9313843791136464 f1 0.9313872616397082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 33.588515281677246 s\n",
      "Accuracy 0.9323168056164984 precision 0.9321131965801505 specificity 0.87432724809356 recall 0.9323168056164984 f1 0.9322096152189786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 34.30509376525879 s\n",
      "Accuracy 0.9358271171566477 precision 0.9357746126500233 specificity 0.882939180288313 recall 0.9358271171566477 f1 0.9358004906449465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 34.58400321006775 s\n",
      "Accuracy 0.9339622641509434 precision 0.9341205023578667 specificity 0.8826791314378206 recall 0.9339622641509434 f1 0.9340384759425046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 32.207019329071045 s\n",
      "Accuracy 0.9346204475647214 precision 0.9347279273295895 specificity 0.8857461612342533 recall 0.9346204475647214 f1 0.9346727169294631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 30.928029775619507 s\n",
      "Accuracy 0.9368143922773147 precision 0.9369107058220036 specificity 0.8870466224337905 recall 0.9368143922773147 f1 0.9368613389473518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 30.45300841331482 s\n",
      "Accuracy 0.9353334795963142 precision 0.9355853858792103 specificity 0.8872859964955285 recall 0.9353334795963142 f1 0.9354519448497756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 30.922003507614136 s\n",
      "Accuracy 0.936046511627907 precision 0.9359954991120215 specificity 0.8853460881611774 recall 0.936046511627907 f1 0.9360206342649028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 31.020004272460938 s\n",
      "Accuracy 0.9333040807371654 precision 0.9336625670009779 specificity 0.8831944230187349 recall 0.9333040807371654 f1 0.9334699981268408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 30.67100214958191 s\n",
      "Accuracy 0.9363207547169812 precision 0.9364226823073575 specificity 0.8867273656012212 recall 0.9363207547169812 f1 0.9363703747633357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 30.209028959274292 s\n",
      "Accuracy 0.9345655989469065 precision 0.9347628065157016 specificity 0.8845284414715556 recall 0.9345655989469065 f1 0.934659662536449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 31.111799955368042 s\n",
      "Accuracy 0.9341268100043879 precision 0.9342118224395491 specificity 0.8802122577319619 recall 0.9341268100043879 f1 0.9341684739492776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 30.784729957580566 s\n",
      "Accuracy 0.9366498464238702 precision 0.936830846862659 specificity 0.8876480324614611 recall 0.9366498464238702 f1 0.9367362831516721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 31.29400324821472 s\n",
      "Accuracy 0.9348398420359807 precision 0.9347566862824079 specificity 0.8821454329931007 recall 0.9348398420359807 f1 0.9347973132860498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 31.553207635879517 s\n",
      "Accuracy 0.9352786309784994 precision 0.9353220115616979 specificity 0.8832870032934718 recall 0.9352786309784994 f1 0.9353000824840801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 31.402676582336426 s\n",
      "Accuracy 0.9342365072400175 precision 0.9348124699097963 specificity 0.8864918580974601 recall 0.9342365072400175 f1 0.9344923940624138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 30.6470046043396 s\n",
      "Accuracy 0.9356077226853883 precision 0.9355867035658763 specificity 0.8838459413278612 recall 0.9356077226853883 f1 0.9355971535353981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 31.15100121498108 s\n",
      "Accuracy 0.9326458973233874 precision 0.9325720595515982 specificity 0.8801532556181082 recall 0.9326458973233874 f1 0.9326082592119351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 30.326003551483154 s\n",
      "Accuracy 0.9351140851250549 precision 0.9351087190597626 specificity 0.8824234216565392 recall 0.9351140851250549 f1 0.9351113983606942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 30.728488445281982 s\n",
      "Accuracy 0.9329749890302764 precision 0.9329966434356722 specificity 0.8813976782106079 recall 0.9329749890302764 f1 0.9329857574370579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 31.596514463424683 s\n",
      "Accuracy 0.938624396665204 precision 0.9388640055731038 specificity 0.8933173916833234 recall 0.938624396665204 f1 0.9387366673329093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 31.110602378845215 s\n",
      "Accuracy 0.9366498464238702 precision 0.9368790391917071 specificity 0.8875403453041885 recall 0.9366498464238702 f1 0.9367581553235712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 30.495004415512085 s\n",
      "Accuracy 0.935717419921018 precision 0.9358223908720874 specificity 0.8882472737023122 recall 0.935717419921018 f1 0.9357684353900504\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 30.92300009727478 s\n",
      "Accuracy 0.9340171127687582 precision 0.9343001556549994 specificity 0.8845770374044852 recall 0.9340171127687582 f1 0.9341497585582549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 31.41200542449951 s\n",
      "Accuracy 0.936704695041685 precision 0.9369591081777765 specificity 0.8893073348806105 recall 0.936704695041685 f1 0.9368240373340105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 30.322001218795776 s\n",
      "Accuracy 0.9354431768319439 precision 0.9355883368214826 specificity 0.8874296756939206 recall 0.9354431768319439 f1 0.9355130709451489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 30.753003358840942 s\n",
      "Accuracy 0.9348398420359807 precision 0.9347251961064647 specificity 0.8808354790023308 recall 0.9348398420359807 f1 0.9347807134033953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 30.85600519180298 s\n",
      "Accuracy 0.9369240895129443 precision 0.9371531606490237 specificity 0.8898475284660808 recall 0.9369240895129443 f1 0.9370320768280496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 30.993001222610474 s\n",
      "Accuracy 0.9322071083808688 precision 0.9326083172639047 specificity 0.8820235765223129 recall 0.9322071083808688 f1 0.9323916613856047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 30.54200291633606 s\n",
      "Accuracy 0.9324813514699429 precision 0.93244415331821 specificity 0.8806891327458217 recall 0.9324813514699429 f1 0.932462573025949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 30.333003282546997 s\n",
      "Accuracy 0.9327555945590171 precision 0.9325354826316664 specificity 0.875663604999693 recall 0.9327555945590171 f1 0.9326389726546225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 30.762003421783447 s\n",
      "Accuracy 0.936978938130759 precision 0.9366901771287109 specificity 0.8821893457408188 recall 0.936978938130759 f1 0.936820577675326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 30.653006315231323 s\n",
      "Accuracy 0.9352237823606845 precision 0.9352290173355893 specificity 0.8848281537713142 recall 0.9352237823606845 f1 0.9352263961499797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 30.703997373580933 s\n",
      "Accuracy 0.9322071083808688 precision 0.9322848728374267 specificity 0.8806000093290344 recall 0.9322071083808688 f1 0.9322452717548028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 30.82000470161438 s\n",
      "Accuracy 0.9348398420359807 precision 0.9349757180279346 specificity 0.8823447157282638 recall 0.9348398420359807 f1 0.9349056240362948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 32.19600439071655 s\n",
      "Accuracy 0.9356625713032032 precision 0.9356156280775072 specificity 0.883564359498821 recall 0.9356625713032032 f1 0.9356387978023242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 33.5070013999939 s\n",
      "Accuracy 0.9334137779727951 precision 0.933178783300872 specificity 0.8773435156340768 recall 0.9334137779727951 f1 0.9332884160298488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 33.24800181388855 s\n",
      "Accuracy 0.9337977182974989 precision 0.9335226341838226 specificity 0.8748849682424689 recall 0.9337977182974989 f1 0.9336496055287276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 32.7200026512146 s\n",
      "Accuracy 0.934730144800351 precision 0.9346378846100029 specificity 0.8828321691203831 recall 0.934730144800351 f1 0.9346828166137717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 32.82600212097168 s\n",
      "Accuracy 0.9321522597630539 precision 0.9323704370322573 specificity 0.8795635734648762 recall 0.9321522597630539 f1 0.9322562847162541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 33.39900088310242 s\n",
      "Accuracy 0.9371983326020185 precision 0.9372644313444629 specificity 0.8903281630770802 recall 0.9371983326020185 f1 0.9372307585409305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 32.681002616882324 s\n",
      "Accuracy 0.9337977182974989 precision 0.9338569455886291 specificity 0.8835368904924757 recall 0.9337977182974989 f1 0.9338268872264385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 32.973002910614014 s\n",
      "Accuracy 0.9326458973233874 precision 0.9325399143684526 specificity 0.8787002845801962 recall 0.9326458973233874 f1 0.9325914308094869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 33.27400183677673 s\n",
      "Accuracy 0.9346204475647214 precision 0.9344869387768527 specificity 0.8811825800449705 recall 0.9346204475647214 f1 0.9345511823895549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 34.22300314903259 s\n",
      "Accuracy 0.936046511627907 precision 0.9363582174941466 specificity 0.8868348301654814 recall 0.936046511627907 f1 0.9361914574963871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 33.13200640678406 s\n",
      "Accuracy 0.9317134708205353 precision 0.9322194034614479 specificity 0.8843206751270855 recall 0.9317134708205353 f1 0.9319413306119997\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 33.722003698349 s\n",
      "Accuracy 0.9337977182974989 precision 0.9338770881738985 specificity 0.885600176496036 recall 0.9337977182974989 f1 0.9338365830355838\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 33.09200477600098 s\n",
      "Accuracy 0.9350043878894252 precision 0.9348042439578006 specificity 0.8790154674838137 recall 0.9350043878894252 f1 0.9348986080601791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 33.330002784729004 s\n",
      "Accuracy 0.9362659060991663 precision 0.9362761039116444 specificity 0.887640447062506 recall 0.9362659060991663 f1 0.9362709902427885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 33.69900393486023 s\n",
      "Accuracy 0.9331943835015357 precision 0.9337183564770261 specificity 0.8881302025982507 recall 0.9331943835015357 f1 0.9334281772916493\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 34.77500343322754 s\n",
      "Accuracy 0.935717419921018 precision 0.9356762471307919 specificity 0.8848344123212949 recall 0.935717419921018 f1 0.9356965961515882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 34.0010027885437 s\n",
      "Accuracy 0.9367595436594998 precision 0.9367857044551348 specificity 0.8864533299225075 recall 0.9367595436594998 f1 0.9367725307650849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 35.01100182533264 s\n",
      "Accuracy 0.9362110574813515 precision 0.9362269259467613 specificity 0.8849183023312474 recall 0.9362110574813515 f1 0.9362189580992255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 33.810001850128174 s\n",
      "Accuracy 0.9340171127687582 precision 0.9342743495716358 specificity 0.8847422421814192 recall 0.9340171127687582 f1 0.9341382574873605\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 33.60600233078003 s\n",
      "Accuracy 0.938021061869241 precision 0.9379710016382262 specificity 0.8878671509653824 recall 0.938021061869241 f1 0.9379956574554198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 33.21200513839722 s\n",
      "Accuracy 0.9334137779727951 precision 0.9335585431595507 specificity 0.8832166998481814 recall 0.9334137779727951 f1 0.9334836740556492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 33.910001277923584 s\n",
      "Accuracy 0.9316586222027204 precision 0.9311607707684032 specificity 0.8710476745195337 recall 0.9316586222027204 f1 0.931369543941342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 34.51700234413147 s\n",
      "Accuracy 0.934401053093462 precision 0.9345073354304675 specificity 0.8864890293846825 recall 0.934401053093462 f1 0.9344527317602701\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 34.68300485610962 s\n",
      "Accuracy 0.9342365072400175 precision 0.933954594323243 specificity 0.8782962879109878 recall 0.9342365072400175 f1 0.9340834545372095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 33.829002141952515 s\n",
      "Accuracy 0.9355528740675735 precision 0.9356621531350793 specificity 0.8889720038655969 recall 0.9355528740675735 f1 0.9356059005765233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 34.42000365257263 s\n",
      "Accuracy 0.9351689337428697 precision 0.9348972880317984 specificity 0.8804364272871634 recall 0.9351689337428697 f1 0.9350214348098963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 33.79900288581848 s\n",
      "Accuracy 0.9361013602457218 precision 0.9359655509360523 specificity 0.8833878125405342 recall 0.9361013602457218 f1 0.9360307351464898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 33.70000219345093 s\n",
      "Accuracy 0.934730144800351 precision 0.9344656934257923 specificity 0.8771848269559422 recall 0.934730144800351 f1 0.9345877471278811\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 34.16400456428528 s\n",
      "Accuracy 0.9343462044756472 precision 0.9344715135787441 specificity 0.8850137245795929 recall 0.9343462044756472 f1 0.9344069119602245\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 34.96700143814087 s\n",
      "Accuracy 0.937033786748574 precision 0.9368852156422774 specificity 0.8845168762147784 recall 0.937033786748574 f1 0.9369561303331587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 34.5230028629303 s\n",
      "Accuracy 0.937362878455463 precision 0.9374255483017414 specificity 0.8882014853943806 recall 0.937362878455463 f1 0.9373936761132057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 33.6570029258728 s\n",
      "Accuracy 0.9338525669153137 precision 0.9338317400136182 specificity 0.8836001036467626 recall 0.9338525669153137 f1 0.9338420948259141\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 33.73800230026245 s\n",
      "Accuracy 0.9336331724440544 precision 0.9339264557300949 specificity 0.8832256095099555 recall 0.9336331724440544 f1 0.9337705513003097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 34.02400279045105 s\n",
      "Accuracy 0.9341816586222027 precision 0.9345415417983669 specificity 0.8865230297711649 recall 0.9341816586222027 f1 0.934347447850708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 33.5660035610199 s\n",
      "Accuracy 0.9330846862659061 precision 0.9328962565166165 specificity 0.8770322252463543 recall 0.9330846862659061 f1 0.9329856540427635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 34.314000844955444 s\n",
      "Accuracy 0.9357722685388328 precision 0.9357361478561809 specificity 0.8848381013514692 recall 0.9357722685388328 f1 0.9357540263223396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 35.524003982543945 s\n",
      "Accuracy 0.936046511627907 precision 0.9360981146979831 specificity 0.8880031372208645 recall 0.936046511627907 f1 0.9360719448604112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 34.479005098342896 s\n",
      "Accuracy 0.9336880210618692 precision 0.933493630687936 specificity 0.8807228011887256 recall 0.9336880210618692 f1 0.9335852302695509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 32.37200093269348 s\n",
      "Accuracy 0.9368692408951295 precision 0.93661327371612 specificity 0.8845681841097666 recall 0.9368692408951295 f1 0.936730009111988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 30.98300266265869 s\n",
      "Accuracy 0.934730144800351 precision 0.9349998002105135 specificity 0.8871270862447195 recall 0.934730144800351 f1 0.9348564929153098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 31.311003923416138 s\n",
      "Accuracy 0.9381856077226853 precision 0.9382110520708251 specificity 0.8894181976360194 recall 0.9381856077226853 f1 0.9381982365067169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 32.15827488899231 s\n",
      "Accuracy 0.9348398420359807 precision 0.9346662449735927 specificity 0.8802822819637715 recall 0.9348398420359807 f1 0.9347487312015974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 32.05042481422424 s\n",
      "Accuracy 0.9342365072400175 precision 0.9344914931839454 specificity 0.8855992387877438 recall 0.9342365072400175 f1 0.9343565384496564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 31.844003438949585 s\n",
      "Accuracy 0.9340719613865731 precision 0.9344403126615822 specificity 0.8845297215292784 recall 0.9340719613865731 f1 0.9342418749498124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 31.11000108718872 s\n",
      "Accuracy 0.9356625713032032 precision 0.9354382502619045 specificity 0.8805513739528789 recall 0.9356625713032032 f1 0.9355428218561003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 31.73401165008545 s\n",
      "Accuracy 0.9350043878894252 precision 0.9349462132495797 specificity 0.8817322901521593 recall 0.9350043878894252 f1 0.9349748491294906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 31.866995811462402 s\n",
      "Accuracy 0.9363207547169812 precision 0.9361608032486609 specificity 0.8806999145985787 recall 0.9363207547169812 f1 0.9362371456252991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 31.63800311088562 s\n",
      "Accuracy 0.9345655989469065 precision 0.9343031188002062 specificity 0.8790814256069901 recall 0.9345655989469065 f1 0.9344238943532035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 31.038002490997314 s\n",
      "Accuracy 0.9325910487055726 precision 0.9325215728237446 specificity 0.8792278648914617 recall 0.9325910487055726 f1 0.9325556884078843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 31.75800061225891 s\n",
      "Accuracy 0.9384050021939447 precision 0.938420214973888 specificity 0.8894516209994662 recall 0.9384050021939447 f1 0.9384125749077984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 31.618003129959106 s\n",
      "Accuracy 0.935388328214129 precision 0.9354418034033825 specificity 0.8848337643575614 recall 0.935388328214129 f1 0.9354146946718387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 31.69000244140625 s\n",
      "Accuracy 0.9348398420359807 precision 0.9346118985146407 specificity 0.8772150846398905 recall 0.9348398420359807 f1 0.9347185688915739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 31.5030038356781 s\n",
      "Accuracy 0.9368143922773147 precision 0.9371329299497968 specificity 0.8919921508118633 recall 0.9368143922773147 f1 0.9369612649218094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 31.24000096321106 s\n",
      "Accuracy 0.9350043878894252 precision 0.9346527434413902 specificity 0.8758423290287989 recall 0.9350043878894252 f1 0.9348095169141913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 31.344002962112427 s\n",
      "Accuracy 0.9371983326020185 precision 0.9371521145832865 specificity 0.8856235781526575 recall 0.9371983326020185 f1 0.937174919796283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 31.576003074645996 s\n",
      "Accuracy 0.9337977182974989 precision 0.9339138742039053 specificity 0.8831144018285203 recall 0.9337977182974989 f1 0.933854169035843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 31.440001249313354 s\n",
      "Accuracy 0.9342913558578324 precision 0.9341750981033522 specificity 0.8794132531706611 recall 0.9342913558578324 f1 0.9342314200200819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 31.06000280380249 s\n",
      "Accuracy 0.9344559017112769 precision 0.9348709157182319 specificity 0.8849719481942355 recall 0.9344559017112769 f1 0.9346456815411506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 31.34499979019165 s\n",
      "Accuracy 0.9348398420359807 precision 0.9348611309501771 specificity 0.8838311776974073 recall 0.9348398420359807 f1 0.934850427248854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 31.59600305557251 s\n",
      "Accuracy 0.9382404563405002 precision 0.938189369687557 specificity 0.8864016767073066 recall 0.9382404563405002 f1 0.9382145353304137\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 31.05000138282776 s\n",
      "Accuracy 0.9303971039929794 precision 0.9307664873634316 specificity 0.8802833881926285 recall 0.9303971039929794 f1 0.9305682362712397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 30.940001487731934 s\n",
      "Accuracy 0.9322619569986836 precision 0.9322460692172704 specificity 0.8815354596597735 recall 0.9322619569986836 f1 0.9322539803224329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 31.249002695083618 s\n",
      "Accuracy 0.9348946906537955 precision 0.9352734456546888 specificity 0.8872070219247754 recall 0.9348946906537955 f1 0.9350684374057436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 31.820101499557495 s\n",
      "Accuracy 0.9331943835015357 precision 0.9334589947950424 specificity 0.8838681450254795 recall 0.9331943835015357 f1 0.9333189115486135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 31.26200270652771 s\n",
      "Accuracy 0.934401053093462 precision 0.9346497758014995 specificity 0.885726808779366 recall 0.934401053093462 f1 0.9345182745249118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 31.436002731323242 s\n",
      "Accuracy 0.936375603334796 precision 0.9366302521064529 specificity 0.8890207140916317 recall 0.936375603334796 f1 0.9364950798721625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 31.69000220298767 s\n",
      "Accuracy 0.9350043878894252 precision 0.9355039300259143 specificity 0.8877182794235875 recall 0.9350043878894252 f1 0.9352285942739905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 31.588003396987915 s\n",
      "Accuracy 0.9337977182974989 precision 0.9335982559709348 specificity 0.8787216844311487 recall 0.9337977182974989 f1 0.933692338216582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 31.338003158569336 s\n",
      "Accuracy 0.9352237823606845 precision 0.9350747889467311 specificity 0.8808904386024577 recall 0.9352237823606845 f1 0.9351461416146206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 31.246001720428467 s\n",
      "Accuracy 0.9328104431768319 precision 0.9327506061937949 specificity 0.8782402616562562 recall 0.9328104431768319 f1 0.9327800761493531\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 33.00100302696228 s\n",
      "Accuracy 0.9321522597630539 precision 0.9321577184008251 specificity 0.8797269474052479 recall 0.9321522597630539 f1 0.9321549854121974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 33.34400296211243 s\n",
      "Accuracy 0.935717419921018 precision 0.936192042186209 specificity 0.8912039159141314 recall 0.935717419921018 f1 0.9359299997396454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 33.17700242996216 s\n",
      "Accuracy 0.936978938130759 precision 0.936719145284818 specificity 0.8834906404346071 recall 0.936978938130759 f1 0.936837727330266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 33.074002504348755 s\n",
      "Accuracy 0.9371983326020185 precision 0.937332933170605 specificity 0.8880362584942675 recall 0.9371983326020185 f1 0.9372632960537329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 33.74200224876404 s\n",
      "Accuracy 0.9351140851250549 precision 0.9350070250450658 specificity 0.8829166440033988 recall 0.9351140851250549 f1 0.935058919859347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 33.11600422859192 s\n",
      "Accuracy 0.9350043878894252 precision 0.9349781235288437 specificity 0.8833641790257096 recall 0.9350043878894252 f1 0.9349911629780183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 33.73600125312805 s\n",
      "Accuracy 0.9371983326020185 precision 0.9372886478696097 specificity 0.8876592003084963 recall 0.9371983326020185 f1 0.9372424098524965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 33.16900444030762 s\n",
      "Accuracy 0.9326458973233874 precision 0.9327367273396598 specificity 0.8793925370938388 recall 0.9326458973233874 f1 0.9326903643004794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 33.375001192092896 s\n",
      "Accuracy 0.9335234752084247 precision 0.9335234752084247 specificity 0.8805468505044666 recall 0.9335234752084247 f1 0.9335234752084247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 33.64200210571289 s\n",
      "Accuracy 0.9359368143922773 precision 0.9356557430139324 specificity 0.8804750976934927 recall 0.9359368143922773 f1 0.9357836673939528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 33.18600392341614 s\n",
      "Accuracy 0.935388328214129 precision 0.9355549858398153 specificity 0.8853115882198437 recall 0.935388328214129 f1 0.9354683090249203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 33.850998401641846 s\n",
      "Accuracy 0.9347849934181659 precision 0.9345233713085566 specificity 0.8794415137427216 recall 0.9347849934181659 f1 0.934643711794436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 33.14599967002869 s\n",
      "Accuracy 0.9329749890302764 precision 0.9330749338265556 specificity 0.8817841437614603 recall 0.9329749890302764 f1 0.933023769382058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 33.36299920082092 s\n",
      "Accuracy 0.9354980254497587 precision 0.9353359039017684 specificity 0.8815965115158794 recall 0.9354980254497587 f1 0.935413140251712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 33.70600128173828 s\n",
      "Accuracy 0.9347849934181659 precision 0.9349000123766136 specificity 0.8845040780860867 recall 0.9347849934181659 f1 0.9348408696992924\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 33.60099983215332 s\n",
      "Accuracy 0.936704695041685 precision 0.9369948068046954 specificity 0.8896641660133672 recall 0.936704695041685 f1 0.9368397034150459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 33.29400110244751 s\n",
      "Accuracy 0.9381307591048705 precision 0.9380143673711508 specificity 0.8877827673851126 recall 0.9381307591048705 f1 0.9380704109585548\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 33.07799935340881 s\n",
      "Accuracy 0.9334137779727951 precision 0.933826008567174 specificity 0.8887607456253954 recall 0.9334137779727951 f1 0.9336011007152321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 33.093997955322266 s\n",
      "Accuracy 0.9362110574813515 precision 0.9364915156490787 specificity 0.8902943261094969 recall 0.9362110574813515 f1 0.9363417016869582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 33.43899917602539 s\n",
      "Accuracy 0.9384050021939447 precision 0.938613763228161 specificity 0.8917219882569704 recall 0.9384050021939447 f1 0.9385037023573946\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 33.450000524520874 s\n",
      "Accuracy 0.9324265028521281 precision 0.9321965137205301 specificity 0.8753588332253484 recall 0.9324265028521281 f1 0.9323043180695495\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 33.221999406814575 s\n",
      "Accuracy 0.9338525669153137 precision 0.9340788674250594 specificity 0.8846169222518498 recall 0.9338525669153137 f1 0.9339598248727726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 33.67399978637695 s\n",
      "Accuracy 0.9361013602457218 precision 0.9361477060171185 specificity 0.8880201896671854 recall 0.9361013602457218 f1 0.936124234732081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 33.370997190475464 s\n",
      "Accuracy 0.9340719613865731 precision 0.9339504414462492 specificity 0.8823737050678973 recall 0.9340719613865731 f1 0.9340090833290636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 33.6390016078949 s\n",
      "Accuracy 0.9368143922773147 precision 0.9366618901023768 specificity 0.88233780067978 recall 0.9368143922773147 f1 0.9367347451430922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 33.36199951171875 s\n",
      "Accuracy 0.9333589293549802 precision 0.9331284594909323 specificity 0.8772952268683362 recall 0.9333589293549802 f1 0.9332361689893627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 33.6279993057251 s\n",
      "Accuracy 0.93505923650724 precision 0.93505923650724 specificity 0.8820734186712913 recall 0.93505923650724 f1 0.93505923650724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 33.12999963760376 s\n",
      "Accuracy 0.936375603334796 precision 0.9362655545161153 specificity 0.8848748354699201 recall 0.936375603334796 f1 0.9363187777869749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 33.0699987411499 s\n",
      "Accuracy 0.9336331724440544 precision 0.93369933241144 specificity 0.8816965641807921 recall 0.9336331724440544 f1 0.9336657197015642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 33.41099977493286 s\n",
      "Accuracy 0.9344559017112769 precision 0.9347266506765185 specificity 0.8847388608636141 recall 0.9344559017112769 f1 0.9345830837700029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 33.39699959754944 s\n",
      "Accuracy 0.9328652917946467 precision 0.9326024818652632 specificity 0.8768583985245528 recall 0.9328652917946467 f1 0.9327238796657984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 33.16499948501587 s\n",
      "Accuracy 0.9320974111452391 precision 0.9317368985475003 specificity 0.8754258545298463 recall 0.9320974111452391 f1 0.9318969943786645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 33.2309992313385 s\n",
      "Accuracy 0.9361013602457218 precision 0.9366569366759451 specificity 0.8908241206981437 recall 0.9361013602457218 f1 0.9363470637029883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 33.276997804641724 s\n",
      "Accuracy 0.9351140851250549 precision 0.9349774337863541 specificity 0.8824028072017642 recall 0.9351140851250549 f1 0.9350430536525705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 33.079707860946655 s\n",
      "Accuracy 0.9325910487055726 precision 0.9324480371517049 specificity 0.8774475368079113 recall 0.9325910487055726 f1 0.9325168457161329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 32.97124361991882 s\n",
      "Accuracy 0.934730144800351 precision 0.9348863942173534 specificity 0.8841883985288199 recall 0.934730144800351 f1 0.9348053591356226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 33.54900050163269 s\n",
      "Accuracy 0.9340171127687582 precision 0.9339898355706857 specificity 0.8797342726888712 recall 0.9340171127687582 f1 0.9340033808860297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 32.9359986782074 s\n",
      "Accuracy 0.9312746818780167 precision 0.9313829417080259 specificity 0.8787987967971961 recall 0.9312746818780167 f1 0.9313274882035674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 33.11803317070007 s\n",
      "Accuracy 0.9334686265906099 precision 0.9332199616374195 specificity 0.8773555526763235 recall 0.9334686265906099 f1 0.9333353711854078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 33.516031980514526 s\n",
      "Accuracy 0.9340171127687582 precision 0.9336508782735576 specificity 0.8758422807684847 recall 0.9340171127687582 f1 0.9338129550165916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 32.79799818992615 s\n",
      "Accuracy 0.934730144800351 precision 0.9345849032462904 specificity 0.8800522034358613 recall 0.934730144800351 f1 0.9346545960838216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 33.20000100135803 s\n",
      "Accuracy 0.9324265028521281 precision 0.9325036270989231 specificity 0.8814064709736256 recall 0.9324265028521281 f1 0.9324643470695855\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 33.25299549102783 s\n",
      "Accuracy 0.9338525669153137 precision 0.9337385948815509 specificity 0.8808042847732589 recall 0.9338525669153137 f1 0.9337937921526519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 33.02999782562256 s\n",
      "Accuracy 0.9314392277314612 precision 0.9317302627507897 specificity 0.8786263734881095 recall 0.9314392277314612 f1 0.9315762294703813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 33.255000591278076 s\n",
      "Accuracy 0.9329201404124616 precision 0.932968108321082 specificity 0.8834824009656718 recall 0.9329201404124616 f1 0.932943829216347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 33.36899924278259 s\n",
      "Accuracy 0.9337428696796841 precision 0.933851511524637 specificity 0.8843640470869977 recall 0.9337428696796841 f1 0.9337957237717294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 34.706032276153564 s\n",
      "Accuracy 0.9339622641509434 precision 0.9339622641509434 specificity 0.8826212801988206 recall 0.9339622641509434 f1 0.9339622641509434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 32.935999393463135 s\n",
      "Accuracy 0.9337977182974989 precision 0.9341669064432662 specificity 0.8856557525531076 recall 0.9337977182974989 f1 0.9339676965232276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 33.625000953674316 s\n",
      "Accuracy 0.936375603334796 precision 0.9364074224688039 specificity 0.8853461755529242 recall 0.936375603334796 f1 0.9363913783850945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 33.56599760055542 s\n",
      "Accuracy 0.9375274243089075 precision 0.9378367373291138 specificity 0.8900979833059033 recall 0.9375274243089075 f1 0.937670757085102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 33.40499830245972 s\n",
      "Accuracy 0.9336331724440544 precision 0.9337690376098178 specificity 0.8816305846495949 recall 0.9336331724440544 f1 0.9336989681496368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 35.3039984703064 s\n",
      "Accuracy 0.93505923650724 precision 0.935390457374324 specificity 0.8877470879639295 recall 0.93505923650724 f1 0.9352124312100227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 34.49745512008667 s\n",
      "Accuracy 0.9374725756910925 precision 0.9375224073577955 specificity 0.8914631238586209 recall 0.9374725756910925 f1 0.9374971238203043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 33.80185627937317 s\n",
      "Accuracy 0.9375274243089075 precision 0.9373616187294929 specificity 0.887228683677789 recall 0.9375274243089075 f1 0.9374399717346374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 33.28420305252075 s\n",
      "Accuracy 0.9343462044756472 precision 0.9343514927074337 specificity 0.8835309406083067 recall 0.9343462044756472 f1 0.9343488449041543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 33.8459997177124 s\n",
      "Accuracy 0.9366498464238702 precision 0.9366239562481643 specificity 0.8854041073942666 recall 0.9366498464238702 f1 0.9366368079169068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 33.472819566726685 s\n",
      "Accuracy 0.9379113646336112 precision 0.937952291136789 specificity 0.8893959162426183 recall 0.9379113646336112 f1 0.9379315892928024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 33.65433359146118 s\n",
      "Accuracy 0.9340719613865731 precision 0.9341935643841108 specificity 0.8835108658876801 recall 0.9340719613865731 f1 0.9341309748959667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 34.016331911087036 s\n",
      "Accuracy 0.9335234752084247 precision 0.9339715894807166 specificity 0.8871628858978509 recall 0.9335234752084247 f1 0.9337264006350726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 33.5310001373291 s\n",
      "Accuracy 0.9349495392716104 precision 0.9354848542835319 specificity 0.8898251043315403 recall 0.9349495392716104 f1 0.935187393334119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 33.62377214431763 s\n",
      "Accuracy 0.9349495392716104 precision 0.9352489656088446 specificity 0.8859659969748461 recall 0.9349495392716104 f1 0.9350892173980735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 33.2413010597229 s\n",
      "Accuracy 0.9339074155331286 precision 0.9340939686115316 specificity 0.8834981020432049 recall 0.9339074155331286 f1 0.9339966658978293\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 33.542184352874756 s\n",
      "Accuracy 0.9350043878894252 precision 0.9348586724446029 specificity 0.8825541688252713 recall 0.9350043878894252 f1 0.9349284153185041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 32.935546875 s\n",
      "Accuracy 0.9340171127687582 precision 0.934178306615656 specificity 0.8842470404424914 recall 0.9340171127687582 f1 0.9340946098681207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 33.46635031700134 s\n",
      "Accuracy 0.9342365072400175 precision 0.9342845003412908 specificity 0.884212098318165 recall 0.9342365072400175 f1 0.9342602058178852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 33.238033056259155 s\n",
      "Accuracy 0.9348946906537955 precision 0.9354702415361275 specificity 0.8911417018942248 recall 0.9348946906537955 f1 0.9351480184163197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 33.41449785232544 s\n",
      "Accuracy 0.9349495392716104 precision 0.9351399660486556 specificity 0.8850818993265893 recall 0.9349495392716104 f1 0.9350404631187414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 33.9189989566803 s\n",
      "Accuracy 0.9333040807371654 precision 0.9333948686329174 specificity 0.879815444949337 recall 0.9333040807371654 f1 0.9333485222816176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 33.542580366134644 s\n",
      "Accuracy 0.9351140851250549 precision 0.9351194324338213 specificity 0.8830697019059625 recall 0.9351140851250549 f1 0.93511675505662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 33.116422176361084 s\n",
      "Accuracy 0.9335234752084247 precision 0.9336465453249044 specificity 0.8821992348328612 recall 0.9335234752084247 f1 0.9335832217471903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 33.34425759315491 s\n",
      "Accuracy 0.9362659060991663 precision 0.9362868241078774 specificity 0.886034423110492 recall 0.9362659060991663 f1 0.936276305595677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 33.55389094352722 s\n",
      "Accuracy 0.9325910487055726 precision 0.933160484984687 specificity 0.8840818461199185 recall 0.9325910487055726 f1 0.9328452392437309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 33.13686180114746 s\n",
      "Accuracy 0.935717419921018 precision 0.9358255915322046 specificity 0.8858957145365102 recall 0.935717419921018 f1 0.935770020005116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 34.41032671928406 s\n",
      "Accuracy 0.9341816586222027 precision 0.9348430418409832 specificity 0.8898966319028644 recall 0.9341816586222027 f1 0.9344696018709888\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 34.38200068473816 s\n",
      "Accuracy 0.9363207547169812 precision 0.9364355419527612 specificity 0.8855824995679316 recall 0.9363207547169812 f1 0.9363764975490968\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 33.74900031089783 s\n",
      "Accuracy 0.9330298376480912 precision 0.9328394693352794 specificity 0.8782299483723941 recall 0.9330298376480912 f1 0.9329295935552046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 34.62699890136719 s\n",
      "Accuracy 0.9336331724440544 precision 0.9336010710905179 specificity 0.8809517390332691 recall 0.9336331724440544 f1 0.9336169886548162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 33.68299841880798 s\n",
      "Accuracy 0.9335234752084247 precision 0.9332723330536004 specificity 0.875032649647967 recall 0.9335234752084247 f1 0.9333892533491981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 34.27299904823303 s\n",
      "Accuracy 0.9335234752084247 precision 0.9335234752084247 specificity 0.8805163920162876 recall 0.9335234752084247 f1 0.9335234752084247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 34.49400019645691 s\n",
      "Accuracy 0.9333040807371654 precision 0.9331977774597408 specificity 0.8787946121987481 recall 0.9333040807371654 f1 0.9332494454134951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 33.80599880218506 s\n",
      "Accuracy 0.9345655989469065 precision 0.9348071382391018 specificity 0.886169486939968 recall 0.9345655989469065 f1 0.9346795532479413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 34.218998432159424 s\n",
      "Accuracy 0.9340171127687582 precision 0.9341477164422763 specificity 0.8814251140699294 recall 0.9340171127687582 f1 0.9340804433344926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 33.48899841308594 s\n",
      "Accuracy 0.9350043878894252 precision 0.9352802584249131 specificity 0.887305190818094 recall 0.9350043878894252 f1 0.9351334671799587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 33.87700366973877 s\n",
      "Accuracy 0.9330298376480912 precision 0.9328737298436757 specificity 0.8759449725089671 recall 0.9330298376480912 f1 0.9329486410703368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 33.85799860954285 s\n",
      "Accuracy 0.9363207547169812 precision 0.9367157703189429 specificity 0.8902941792592607 recall 0.9363207547169812 f1 0.936500621386012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 33.50251054763794 s\n",
      "Accuracy 0.9351689337428697 precision 0.9350396069408827 specificity 0.883966594975889 recall 0.9351689337428697 f1 0.9351017764844082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 32.86770582199097 s\n",
      "Accuracy 0.9354431768319439 precision 0.9358287589687412 specificity 0.888928924012819 recall 0.9354431768319439 f1 0.9356193892303308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 33.66300010681152 s\n",
      "Accuracy 0.935388328214129 precision 0.9357550939853418 specificity 0.8857735687446529 recall 0.935388328214129 f1 0.9355573352210631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 33.26300001144409 s\n",
      "Accuracy 0.9325362000877578 precision 0.9325253745996013 specificity 0.8801066229983747 recall 0.9325362000877578 f1 0.9325307726434273\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 34.83900022506714 s\n",
      "Accuracy 0.9347849934181659 precision 0.9346263380670101 specificity 0.8851037913252977 recall 0.9347849934181659 f1 0.9347016887852897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 34.79399919509888 s\n",
      "Accuracy 0.9364853005704257 precision 0.9373834093166435 specificity 0.8932546308462597 recall 0.9364853005704257 f1 0.9368612859649317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 34.658000230789185 s\n",
      "Accuracy 0.935717419921018 precision 0.9357822707754078 specificity 0.8845331822844714 recall 0.935717419921018 f1 0.9357493081908042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 35.001999378204346 s\n",
      "Accuracy 0.938295304958315 precision 0.9383529494425056 specificity 0.8882902018522897 recall 0.938295304958315 f1 0.9383236716325482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 35.07299876213074 s\n",
      "Accuracy 0.9342913558578324 precision 0.9343938058369573 specificity 0.8804889147070916 recall 0.9342913558578324 f1 0.9343413666464281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 34.178998708724976 s\n",
      "Accuracy 0.9313295304958316 precision 0.9309744917532509 specificity 0.8725619076782724 recall 0.9313295304958316 f1 0.931133877315901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 34.8340003490448 s\n",
      "Accuracy 0.9365949978060553 precision 0.9366368725703209 specificity 0.8868650478102656 recall 0.9365949978060553 f1 0.9366156970421247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 34.58230495452881 s\n",
      "Accuracy 0.9327007459412023 precision 0.9327281662149383 specificity 0.8803606706225707 recall 0.9327007459412023 f1 0.9327143640281279\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 33.44611597061157 s\n",
      "Accuracy 0.9333589293549802 precision 0.9330617686124065 specificity 0.8760626622719415 recall 0.9333589293549802 f1 0.9331973812759586\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 33.99325108528137 s\n",
      "Accuracy 0.9340171127687582 precision 0.9338902462623481 specificity 0.8819914229642675 recall 0.9340171127687582 f1 0.9339513791273106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 34.19088077545166 s\n",
      "Accuracy 0.934401053093462 precision 0.9342958435642629 specificity 0.8802095150133536 recall 0.934401053093462 f1 0.9343469578157622\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 33.78968834877014 s\n",
      "Accuracy 0.9336880210618692 precision 0.9332199181015254 specificity 0.8749343084438347 recall 0.9336880210618692 f1 0.9334159696755147\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 35.15006470680237 s\n",
      "Accuracy 0.9354431768319439 precision 0.9357388270080259 specificity 0.8855580986421936 recall 0.9354431768319439 f1 0.9355812848063418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 33.81439256668091 s\n",
      "Accuracy 0.9324813514699429 precision 0.9325528017882558 specificity 0.8814530603409831 recall 0.9324813514699429 f1 0.9325164575415857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 33.52195477485657 s\n",
      "Accuracy 0.9361562088635367 precision 0.935977683500102 specificity 0.8828731495321452 recall 0.9361562088635367 f1 0.9360621055209524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 32.12626051902771 s\n",
      "Accuracy 0.9387340939008337 precision 0.9387289367312299 specificity 0.8875903558958874 recall 0.9387340939008337 f1 0.9387315115322247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 32.63848257064819 s\n",
      "Accuracy 0.9317134708205353 precision 0.9316417994472712 specificity 0.8761665060806959 recall 0.9317134708205353 f1 0.9316770100566328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 31.955324172973633 s\n",
      "Accuracy 0.9339622641509434 precision 0.9344583058231624 specificity 0.8863850090484103 recall 0.9339622641509434 f1 0.9341854558262297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 32.147284269332886 s\n",
      "Accuracy 0.9317134708205353 precision 0.9319223491485853 specificity 0.8829168365126732 recall 0.9317134708205353 f1 0.9318129384433178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 31.777413368225098 s\n",
      "Accuracy 0.938021061869241 precision 0.9385390337613656 specificity 0.8946709628341396 recall 0.938021061869241 f1 0.9382499550877279\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 31.239058256149292 s\n",
      "Accuracy 0.9343462044756472 precision 0.93439352774256 specificity 0.8853811590833949 recall 0.9343462044756472 f1 0.934369569347674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 31.92602777481079 s\n",
      "Accuracy 0.93505923650724 precision 0.9349385218945235 specificity 0.8834059463701077 recall 0.93505923650724 f1 0.9349967504190068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 32.143375396728516 s\n",
      "Accuracy 0.9330298376480912 precision 0.9332683133027553 specificity 0.8819771217879638 recall 0.9330298376480912 f1 0.9331428628770252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 31.43899965286255 s\n",
      "Accuracy 0.9336880210618692 precision 0.9337039302020207 specificity 0.8832857250061867 recall 0.9336880210618692 f1 0.9336959426076372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 31.59999990463257 s\n",
      "Accuracy 0.9341816586222027 precision 0.9342928981036666 specificity 0.882713473651128 recall 0.9341816586222027 f1 0.9342357945903449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 32.42891335487366 s\n",
      "Accuracy 0.9358271171566477 precision 0.9360275573608635 specificity 0.8864607655596048 recall 0.9358271171566477 f1 0.9359225128416687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 31.543147563934326 s\n",
      "Accuracy 0.9323716542343133 precision 0.9324446408640308 specificity 0.8796333271385219 recall 0.9323716542343133 f1 0.9324075243496633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 32.34699892997742 s\n",
      "Accuracy 0.9345107503290917 precision 0.9344497141220427 specificity 0.8843817759945853 recall 0.9345107503290917 f1 0.9344797037993746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 32.37399983406067 s\n",
      "Accuracy 0.9354431768319439 precision 0.9354268937974124 specificity 0.8812953366800601 recall 0.9354431768319439 f1 0.9354350014683174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 31.633000135421753 s\n",
      "Accuracy 0.9346204475647214 precision 0.9347432334211612 specificity 0.8830457373482091 recall 0.9346204475647214 f1 0.9346800391200554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 32.299999713897705 s\n",
      "Accuracy 0.9332492321193506 precision 0.9335061467346444 specificity 0.8843490306667822 recall 0.9332492321193506 f1 0.9333702594664801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 31.719998598098755 s\n",
      "Accuracy 0.9356625713032032 precision 0.9358338540732505 specificity 0.8860951869383626 recall 0.9356625713032032 f1 0.9357446395377783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 32.32499980926514 s\n",
      "Accuracy 0.9368143922773147 precision 0.9366493372084741 specificity 0.8852135264222468 recall 0.9368143922773147 f1 0.9367275617379736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 33.342000007629395 s\n",
      "Accuracy 0.935717419921018 precision 0.9358028895985248 specificity 0.8861745825890808 recall 0.935717419921018 f1 0.9357592059373209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 32.11899948120117 s\n",
      "Accuracy 0.9337977182974989 precision 0.9336685270100227 specificity 0.8804352572207551 recall 0.9337977182974989 f1 0.9337308117781162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 31.873838901519775 s\n",
      "Accuracy 0.934401053093462 precision 0.9347502097682983 specificity 0.8890818878040503 recall 0.934401053093462 f1 0.9345616107356747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 31.586437463760376 s\n",
      "Accuracy 0.9348398420359807 precision 0.9347569350477392 specificity 0.8823852682330702 recall 0.9348398420359807 f1 0.9347974386559932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 30.931640625 s\n",
      "Accuracy 0.931494076349276 precision 0.9313439942843603 specificity 0.872792748643656 recall 0.931494076349276 f1 0.9314163149442826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 31.21499800682068 s\n",
      "Accuracy 0.9322619569986836 precision 0.9320085122821625 specificity 0.8752351760288393 recall 0.9322619569986836 f1 0.9321263348397384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 31.60100293159485 s\n",
      "Accuracy 0.9330298376480912 precision 0.932928793567597 specificity 0.8787875002783546 recall 0.9330298376480912 f1 0.9329779797706478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 31.616997003555298 s\n",
      "Accuracy 0.9327555945590171 precision 0.932766649221626 specificity 0.879207704450914 recall 0.9327555945590171 f1 0.9327611070919987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 31.552000284194946 s\n",
      "Accuracy 0.9374725756910925 precision 0.9376026867242011 specificity 0.8874718699129684 recall 0.9374725756910925 f1 0.9375354663143864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 32.33714962005615 s\n",
      "Accuracy 0.9351689337428697 precision 0.9351270173762712 specificity 0.8831173204285645 recall 0.9351689337428697 f1 0.9351477376776485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 31.901998281478882 s\n",
      "Accuracy 0.9352237823606845 precision 0.9350353308674494 specificity 0.8801086649110744 recall 0.9352237823606845 f1 0.9351244299577406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 32.046146869659424 s\n",
      "Accuracy 0.9326458973233874 precision 0.9328062878422779 specificity 0.8807503111432595 recall 0.9326458973233874 f1 0.9327231986831064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 31.709908723831177 s\n",
      "Accuracy 0.9333589293549802 precision 0.9334950064348762 specificity 0.8848290965048334 recall 0.9333589293549802 f1 0.9334246867437187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 31.48395538330078 s\n",
      "Accuracy 0.9355528740675735 precision 0.9358332537630077 specificity 0.8863510278272344 recall 0.9355528740675735 f1 0.9356841198872202\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 32.436076402664185 s\n",
      "Accuracy 0.9358819657744625 precision 0.9357844787796572 specificity 0.8831691046983297 recall 0.9358819657744625 f1 0.9358318744468029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 31.58799982070923 s\n",
      "Accuracy 0.936978938130759 precision 0.9371333225594193 specificity 0.8894933784144035 recall 0.936978938130759 f1 0.9370530111702815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 31.407187700271606 s\n",
      "Accuracy 0.9331943835015357 precision 0.9333378403007213 specificity 0.8838161822019164 recall 0.9331943835015357 f1 0.9332636371192996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 31.999165534973145 s\n",
      "Accuracy 0.9361562088635367 precision 0.9362889561793453 specificity 0.8850603180314532 recall 0.9361562088635367 f1 0.9362204234999525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 31.61699867248535 s\n",
      "Accuracy 0.9341268100043879 precision 0.933877742367595 specificity 0.8775235008545927 recall 0.9341268100043879 f1 0.933993303606499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 31.46698307991028 s\n",
      "Accuracy 0.9308358929354981 precision 0.9307536042412003 specificity 0.8757610342610562 recall 0.9308358929354981 f1 0.9307939220871249\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 31.85994577407837 s\n",
      "Accuracy 0.9358271171566477 precision 0.9360410103158996 specificity 0.8859294554827906 recall 0.9358271171566477 f1 0.935928673029712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 31.77401900291443 s\n",
      "Accuracy 0.9355528740675735 precision 0.9356887850168495 specificity 0.8862694495412506 recall 0.9355528740675735 f1 0.9356185132362494\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 31.771785020828247 s\n",
      "Accuracy 0.9331395348837209 precision 0.9333936725682526 specificity 0.881041778184911 recall 0.9331395348837209 f1 0.9332597326022716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 31.136520862579346 s\n",
      "Accuracy 0.93505923650724 precision 0.9351136530107969 specificity 0.8832349000013451 recall 0.93505923650724 f1 0.9350860722249892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 30.78561282157898 s\n",
      "Accuracy 0.937033786748574 precision 0.9375298165524091 specificity 0.8931031439526665 recall 0.937033786748574 f1 0.9372544376331193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 32.52105259895325 s\n",
      "Accuracy 0.9340171127687582 precision 0.9337889123751733 specificity 0.8784085978073021 recall 0.9340171127687582 f1 0.9338954750450944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 31.8650004863739 s\n",
      "Accuracy 0.9336880210618692 precision 0.9337379929640812 specificity 0.880607924813024 recall 0.9336880210618692 f1 0.9337127059862592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 31.324079275131226 s\n",
      "Accuracy 0.9327007459412023 precision 0.9324510096837404 specificity 0.876650388138614 recall 0.9327007459412023 f1 0.9325669930653405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 31.54336929321289 s\n",
      "Accuracy 0.9355528740675735 precision 0.9357941534271973 specificity 0.8868898301460634 recall 0.9355528740675735 f1 0.9356666522367418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 31.36766028404236 s\n",
      "Accuracy 0.936375603334796 precision 0.9364487930503533 specificity 0.8878987060562866 recall 0.936375603334796 f1 0.9364114729221327\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 31.877422094345093 s\n",
      "Accuracy 0.9350043878894252 precision 0.9351887224177193 specificity 0.8851568186938259 recall 0.9350043878894252 f1 0.9350925142426391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 32.29702568054199 s\n",
      "Accuracy 0.9346204475647214 precision 0.9345553541928692 specificity 0.8792475069990705 recall 0.9346204475647214 f1 0.934587360049274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 31.62054944038391 s\n",
      "Accuracy 0.9330846862659061 precision 0.9332282660855458 specificity 0.8836798309969047 recall 0.9330846862659061 f1 0.9331540025563654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 32.057276248931885 s\n",
      "Accuracy 0.9337428696796841 precision 0.933952679680593 specificity 0.881374519101099 recall 0.9337428696796841 f1 0.9338429438551912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 30.814000129699707 s\n",
      "Accuracy 0.9339622641509434 precision 0.9340962619288018 specificity 0.8829748836936964 recall 0.9339622641509434 f1 0.934027131615727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 30.636998176574707 s\n",
      "Accuracy 0.9367595436594998 precision 0.9368181875023677 specificity 0.8860462547653624 recall 0.9367595436594998 f1 0.9367884125931738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 28.532999277114868 s\n",
      "Accuracy 0.9357722685388328 precision 0.9356632139547866 specificity 0.8817757236927295 recall 0.9357722685388328 f1 0.9357160871906032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 29.114928722381592 s\n",
      "Accuracy 0.936375603334796 precision 0.9368676753047211 specificity 0.8910650199184265 recall 0.936375603334796 f1 0.9365954765963843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 29.077351808547974 s\n",
      "Accuracy 0.9310552874067574 precision 0.9309719050414861 specificity 0.8747551323932997 recall 0.9310552874067574 f1 0.9310127646935512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 28.844000339508057 s\n",
      "Accuracy 0.935717419921018 precision 0.9355388244958425 specificity 0.8826301173668303 recall 0.935717419921018 f1 0.9356232972669551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 29.045999765396118 s\n",
      "Accuracy 0.9337977182974989 precision 0.9340348036332853 specificity 0.8829528471649634 recall 0.9337977182974989 f1 0.9339100273397692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 29.417999505996704 s\n",
      "Accuracy 0.9359368143922773 precision 0.9360569050847016 specificity 0.8856424379392731 recall 0.9359368143922773 f1 0.9359950551526897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 29.247636318206787 s\n",
      "Accuracy 0.9348946906537955 precision 0.9347585587633738 specificity 0.8766173765416372 recall 0.9348946906537955 f1 0.934824251265563\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 29.098998546600342 s\n",
      "Accuracy 0.9347849934181659 precision 0.9346955401334065 specificity 0.8809333665094924 recall 0.9347849934181659 f1 0.9347391885117938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 29.27453327178955 s\n",
      "Accuracy 0.9342365072400175 precision 0.9341360254863984 specificity 0.8798718053228073 recall 0.9342365072400175 f1 0.9341849211191267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 29.566569566726685 s\n",
      "Accuracy 0.9362659060991663 precision 0.9365335186025642 specificity 0.8887351971397337 recall 0.9362659060991663 f1 0.9363911616364893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 29.270236253738403 s\n",
      "Accuracy 0.9362659060991663 precision 0.9360330849541444 specificity 0.8793997291158575 recall 0.9362659060991663 f1 0.9361414803721327\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 28.76400065422058 s\n",
      "Accuracy 0.9386792452830188 precision 0.9388054685877462 specificity 0.8905863493226951 recall 0.9386792452830188 f1 0.9387401959123323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 28.699902772903442 s\n",
      "Accuracy 0.9335783238262396 precision 0.9338107006712405 specificity 0.8844677325699148 recall 0.9335783238262396 f1 0.9336883330105098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 29.903040647506714 s\n",
      "Accuracy 0.9333589293549802 precision 0.9332875387546117 specificity 0.877365337189897 recall 0.9333589293549802 f1 0.9333226022477595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 29.50199842453003 s\n",
      "Accuracy 0.9328104431768319 precision 0.9329734571660759 specificity 0.8825889531458592 recall 0.9328104431768319 f1 0.9328888645407952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 28.92701745033264 s\n",
      "Accuracy 0.9309455901711277 precision 0.9311008314504439 specificity 0.8792242476387193 recall 0.9309455901711277 f1 0.931020546748195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 28.45999836921692 s\n",
      "Accuracy 0.9341816586222027 precision 0.9338215551320551 specificity 0.8763783415924287 recall 0.9341816586222027 f1 0.9339811333621044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 30.690969467163086 s\n",
      "Accuracy 0.9347849934181659 precision 0.9350965864340497 specificity 0.8843083515196516 recall 0.9347849934181659 f1 0.934930303457559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 28.457999229431152 s\n",
      "Accuracy 0.9333040807371654 precision 0.933599866191705 specificity 0.882295780105964 recall 0.9333040807371654 f1 0.9334427037934285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 28.51300048828125 s\n",
      "Accuracy 0.9365401491882405 precision 0.9372639718568851 specificity 0.8940793333971204 recall 0.9365401491882405 f1 0.936849742276702\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 28.66200017929077 s\n",
      "Accuracy 0.9327007459412023 precision 0.932807633298381 specificity 0.8807150043006666 recall 0.9327007459412023 f1 0.9327528586485102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 28.890999794006348 s\n",
      "Accuracy 0.9366498464238702 precision 0.936524709092787 specificity 0.8844144820990375 recall 0.9366498464238702 f1 0.9365849422646164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 29.298999786376953 s\n",
      "Accuracy 0.9358271171566477 precision 0.935903889920155 specificity 0.8837661366089286 recall 0.9358271171566477 f1 0.9358647687798038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 28.993000507354736 s\n",
      "Accuracy 0.9342913558578324 precision 0.9344771862855203 specificity 0.8866240251022657 recall 0.9342913558578324 f1 0.9343800387370589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 29.443997859954834 s\n",
      "Accuracy 0.9352786309784994 precision 0.9354690294891878 specificity 0.8852984893200998 recall 0.9352786309784994 f1 0.9353695305552198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 29.049001693725586 s\n",
      "Accuracy 0.9323716542343133 precision 0.9320609361632226 specificity 0.874329601965514 recall 0.9323716542343133 f1 0.9322024682990276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 28.567997694015503 s\n",
      "Accuracy 0.9308358929354981 precision 0.9309110244019944 specificity 0.8762792405240832 recall 0.9308358929354981 f1 0.9308728359174244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 28.571000576019287 s\n",
      "Accuracy 0.9341268100043879 precision 0.9341857908826928 specificity 0.8840621957269319 recall 0.9341268100043879 f1 0.934155855320636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 29.35099959373474 s\n",
      "Accuracy 0.9356625713032032 precision 0.935958234530437 specificity 0.8856969699722523 recall 0.9356625713032032 f1 0.9358006698469811\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 28.0360004901886 s\n",
      "Accuracy 0.935388328214129 precision 0.9356028309669336 specificity 0.8854215304235613 recall 0.935388328214129 f1 0.9354902007927438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 28.3340003490448 s\n",
      "Accuracy 0.9364853005704257 precision 0.9367795434914102 specificity 0.8883918694753059 recall 0.9364853005704257 f1 0.9366223383506479\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 28.022000074386597 s\n",
      "Accuracy 0.9333040807371654 precision 0.933821323720574 specificity 0.8847698929723784 recall 0.9333040807371654 f1 0.9335366230306981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 31.22999930381775 s\n",
      "Accuracy 0.9367595436594998 precision 0.9367964353978971 specificity 0.8862404227533802 recall 0.9367595436594998 f1 0.9367778064161385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 32.33400082588196 s\n",
      "Accuracy 0.935717419921018 precision 0.9360220983519301 specificity 0.8850228125936384 recall 0.935717419921018 f1 0.9358596019663975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 35.173999071121216 s\n",
      "Accuracy 0.9336880210618692 precision 0.9336610210136435 specificity 0.8804025583151293 recall 0.9336880210618692 f1 0.9336744283146183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 41.94000005722046 s\n",
      "Accuracy 0.9327007459412023 precision 0.9329167761840508 specificity 0.8854012687512178 recall 0.9327007459412023 f1 0.9328032424851552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 28.275997400283813 s\n",
      "Accuracy 0.9318231680561649 precision 0.9316872247291621 specificity 0.8752200481323331 recall 0.9318231680561649 f1 0.9317528786971383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 28.984001636505127 s\n",
      "Accuracy 0.9331943835015357 precision 0.9332164163319749 specificity 0.880099871409837 recall 0.9331943835015357 f1 0.933205340672028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 29.240999460220337 s\n",
      "Accuracy 0.9331395348837209 precision 0.9329700861624775 specificity 0.8743091692003402 recall 0.9331395348837209 f1 0.9330511930404128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 28.757999658584595 s\n",
      "Accuracy 0.9336331724440544 precision 0.933788822985348 specificity 0.8838289982477221 recall 0.9336331724440544 f1 0.9337081142181232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 29.29699969291687 s\n",
      "Accuracy 0.9342913558578324 precision 0.9343455658317923 specificity 0.8831019522533007 recall 0.9342913558578324 f1 0.934318090914652\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 29.458000659942627 s\n",
      "Accuracy 0.9327007459412023 precision 0.9329391300126535 specificity 0.8818009670062665 recall 0.9327007459412023 f1 0.9328137406683402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 28.876998901367188 s\n",
      "Accuracy 0.937966213251426 precision 0.937981387957781 specificity 0.8893952689931893 recall 0.937966213251426 f1 0.9379737670729948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 29.35699963569641 s\n",
      "Accuracy 0.9349495392716104 precision 0.9351875119244528 specificity 0.8855406958106669 recall 0.9349495392716104 f1 0.9350619815425749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 29.81700110435486 s\n",
      "Accuracy 0.9352786309784994 precision 0.9350922590924721 specificity 0.8829424051626448 recall 0.9352786309784994 f1 0.935180101518866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 28.95599913597107 s\n",
      "Accuracy 0.9349495392716104 precision 0.9347870819933212 specificity 0.8811619027296131 recall 0.9349495392716104 f1 0.9348644994936613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 29.488999366760254 s\n",
      "Accuracy 0.9329749890302764 precision 0.9328966940920681 specificity 0.8754144196547639 recall 0.9329749890302764 f1 0.9329351057858942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 29.08300018310547 s\n",
      "Accuracy 0.9351689337428697 precision 0.9353713903384411 specificity 0.8852363085468282 recall 0.9351689337428697 f1 0.9352653434833635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 29.29799723625183 s\n",
      "Accuracy 0.9354980254497587 precision 0.9358515995135653 specificity 0.8888388119584125 recall 0.9354980254497587 f1 0.9356606188189056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 28.821000337600708 s\n",
      "Accuracy 0.9345655989469065 precision 0.9346709390804707 specificity 0.8830264479684486 recall 0.9345655989469065 f1 0.9346169269220715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 30.11000084877014 s\n",
      "Accuracy 0.9329749890302764 precision 0.9332660853518486 specificity 0.8834215817000123 recall 0.9329749890302764 f1 0.9331113422833379\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 28.805999040603638 s\n",
      "Accuracy 0.9348398420359807 precision 0.9347651588712274 specificity 0.8803872039523617 recall 0.9348398420359807 f1 0.9348017666086313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 29.137999773025513 s\n",
      "Accuracy 0.9335234752084247 precision 0.9337891220784655 specificity 0.8837586782711415 recall 0.9335234752084247 f1 0.933648492065483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 28.901997804641724 s\n",
      "Accuracy 0.9322619569986836 precision 0.9325631907039474 specificity 0.8819228931228394 recall 0.9322619569986836 f1 0.9324030105738319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 29.083001613616943 s\n",
      "Accuracy 0.9362659060991663 precision 0.9361189868492955 specificity 0.8849997267418084 recall 0.9362659060991663 f1 0.9361891085008842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 28.62599754333496 s\n",
      "Accuracy 0.9402150065818341 precision 0.940245569748391 specificity 0.8906680352211609 recall 0.9402150065818341 f1 0.940230151525329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 29.31318712234497 s\n",
      "Accuracy 0.9326458973233874 precision 0.9327352183719914 specificity 0.8807940267695461 recall 0.9326458973233874 f1 0.93268961538791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 28.92499804496765 s\n",
      "Accuracy 0.9375822729267222 precision 0.9375822729267222 specificity 0.88706264302131 recall 0.9375822729267222 f1 0.9375822729267222\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 28.756998777389526 s\n",
      "Accuracy 0.9331395348837209 precision 0.9331558064427842 specificity 0.8811614456828999 recall 0.9331395348837209 f1 0.9331476375118024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 28.45182776451111 s\n",
      "Accuracy 0.936978938130759 precision 0.9372193807460092 specificity 0.8880809681195392 recall 0.936978938130759 f1 0.937092233601321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 28.73999834060669 s\n",
      "Accuracy 0.9359368143922773 precision 0.936277769987305 specificity 0.8890757866322455 recall 0.9359368143922773 f1 0.9360939599896125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 29.263000965118408 s\n",
      "Accuracy 0.9319328652917946 precision 0.9317907787138252 specificity 0.8776456341941534 recall 0.9319328652917946 f1 0.9318591435004041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 29.241998434066772 s\n",
      "Accuracy 0.9367595436594998 precision 0.9366239686962613 specificity 0.8838522344994483 recall 0.9367595436594998 f1 0.936689023429039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 28.787001609802246 s\n",
      "Accuracy 0.9351140851250549 precision 0.9348513636649114 specificity 0.8792527026227921 recall 0.9351140851250549 f1 0.9349722121751727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 28.945998430252075 s\n",
      "Accuracy 0.9354980254497587 precision 0.9354150811374808 specificity 0.8826946140958408 recall 0.9354980254497587 f1 0.9354555985301174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 29.791999578475952 s\n",
      "Accuracy 0.9324265028521281 precision 0.9325667196355866 specificity 0.8782275877004936 recall 0.9324265028521281 f1 0.9324944688590562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 29.081000089645386 s\n",
      "Accuracy 0.9325910487055726 precision 0.9327339429281325 specificity 0.8803737095985051 recall 0.9325910487055726 f1 0.9326601877946236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 28.414999961853027 s\n",
      "Accuracy 0.9342913558578324 precision 0.9342913558578324 specificity 0.8815643304226022 recall 0.9342913558578324 f1 0.9342913558578324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 28.857999801635742 s\n",
      "Accuracy 0.9354431768319439 precision 0.9354591409887494 specificity 0.8840057189409174 recall 0.9354431768319439 f1 0.9354511254184262\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 28.769001722335815 s\n",
      "Accuracy 0.9358271171566477 precision 0.9360755939475924 specificity 0.8867226349330747 recall 0.9358271171566477 f1 0.9359441438588232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 28.406999111175537 s\n",
      "Accuracy 0.9323168056164984 precision 0.9325919037639184 specificity 0.8839393673644473 recall 0.9323168056164984 f1 0.9324459571606409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 28.493998765945435 s\n",
      "Accuracy 0.9375822729267222 precision 0.9377241987450116 specificity 0.8873467441296218 recall 0.9375822729267222 f1 0.9376506894813768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 29.20000123977661 s\n",
      "Accuracy 0.9308358929354981 precision 0.9304009865443144 specificity 0.8671183776533931 recall 0.9308358929354981 f1 0.9305925744246978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 29.12199902534485 s\n",
      "Accuracy 0.9359916630100922 precision 0.9360581301008243 specificity 0.8891917143060288 recall 0.9359916630100922 f1 0.9360242774291526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 29.16399884223938 s\n",
      "Accuracy 0.9371983326020185 precision 0.9371529337560978 specificity 0.8870197357564858 recall 0.9371983326020185 f1 0.9371753313004071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 29.82999873161316 s\n",
      "Accuracy 0.9333589293549802 precision 0.9335720527103297 specificity 0.8823018886767181 recall 0.9333589293549802 f1 0.9334604265117836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 32.255000829696655 s\n",
      "Accuracy 0.9325910487055726 precision 0.9326294190227049 specificity 0.8806882251981952 recall 0.9325910487055726 f1 0.9326100538116817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 34.27099967002869 s\n",
      "Accuracy 0.93505923650724 precision 0.9350085663017184 specificity 0.8853288324005014 recall 0.93505923650724 f1 0.9350335338665905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 34.08499884605408 s\n",
      "Accuracy 0.9328104431768319 precision 0.9332145006803598 specificity 0.8860510807054924 recall 0.9328104431768319 f1 0.9329951178733609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 31.763999938964844 s\n",
      "Accuracy 0.9313843791136464 precision 0.9311582455686261 specificity 0.8745414967944193 recall 0.9313843791136464 f1 0.9312644873777096\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 34.7309992313385 s\n",
      "Accuracy 0.9354980254497587 precision 0.9356194821553409 specificity 0.8844625403263899 recall 0.9354980254497587 f1 0.9355569477618528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 35.413999795913696 s\n",
      "Accuracy 0.9362110574813515 precision 0.9361740615398012 specificity 0.883160324621949 recall 0.9362110574813515 f1 0.9361923754737542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 34.043001890182495 s\n",
      "Accuracy 0.9355528740675735 precision 0.935764967450506 specificity 0.8886748538591871 recall 0.9355528740675735 f1 0.9356533272025578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 31.108997583389282 s\n",
      "Accuracy 0.9355528740675735 precision 0.9353209307373083 specificity 0.8809298065342587 recall 0.9355528740675735 f1 0.9354286496213189\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 30.331998109817505 s\n",
      "Accuracy 0.9375822729267222 precision 0.9375322267482595 specificity 0.8876532850613228 recall 0.9375822729267222 f1 0.9375568768543845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 31.631000518798828 s\n",
      "Accuracy 0.9365949978060553 precision 0.9367828646188782 specificity 0.8871997489371647 recall 0.9365949978060553 f1 0.9366846103159792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 30.83799958229065 s\n",
      "Accuracy 0.9359368143922773 precision 0.9358945753479828 specificity 0.8829111250265277 recall 0.9359368143922773 f1 0.9359154549477149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 30.86299967765808 s\n",
      "Accuracy 0.9362659060991663 precision 0.9361940069227457 specificity 0.8842097744801412 recall 0.9362659060991663 f1 0.9362292244915597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 31.211999654769897 s\n",
      "Accuracy 0.9305068012286091 precision 0.9304788916058604 specificity 0.8758885121601638 recall 0.9305068012286091 f1 0.9304927547397841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 30.55999994277954 s\n",
      "Accuracy 0.9358819657744625 precision 0.9358768499050724 specificity 0.8866381647609509 recall 0.9358819657744625 f1 0.9358794041489589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 30.244999885559082 s\n",
      "Accuracy 0.9357722685388328 precision 0.935538392767073 specificity 0.8803678044365534 recall 0.9357722685388328 f1 0.9356470401395779\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 30.69900107383728 s\n",
      "Accuracy 0.9353334795963142 precision 0.9356901775045027 specificity 0.8865233060603547 recall 0.9353334795963142 f1 0.9354979705214036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 31.048998594284058 s\n",
      "Accuracy 0.9346204475647214 precision 0.9346204475647214 specificity 0.8837911677715897 recall 0.9346204475647214 f1 0.9346204475647214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 31.82100224494934 s\n",
      "Accuracy 0.937966213251426 precision 0.9378436930336571 specificity 0.8867158121405603 recall 0.937966213251426 f1 0.9379026107848285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 31.855998039245605 s\n",
      "Accuracy 0.93505923650724 precision 0.9354297359358643 specificity 0.8876778091917162 recall 0.93505923650724 f1 0.9352293429929626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 31.659998416900635 s\n",
      "Accuracy 0.9336331724440544 precision 0.933559539797728 specificity 0.8809079631387627 recall 0.9336331724440544 f1 0.9335956324325537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 31.31100058555603 s\n",
      "Accuracy 0.9320425625274243 precision 0.9324726675978965 specificity 0.8830583128272859 recall 0.9320425625274243 f1 0.9322391314475692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 32.18799924850464 s\n",
      "Accuracy 0.9364304519526108 precision 0.9364771044149822 specificity 0.8877055402707509 recall 0.9364304519526108 f1 0.9364534783635186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 33.920998334884644 s\n",
      "Accuracy 0.9349495392716104 precision 0.9347892290628136 specificity 0.8822164703849172 recall 0.9349495392716104 f1 0.934865590328002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 33.62399983406067 s\n",
      "Accuracy 0.9359368143922773 precision 0.9360891953032064 specificity 0.8869477879656404 recall 0.9359368143922773 f1 0.9360100948754679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 33.24099922180176 s\n",
      "Accuracy 0.9337428696796841 precision 0.933479477230577 specificity 0.879726029342512 recall 0.9337428696796841 f1 0.9336004260080517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 32.82599997520447 s\n",
      "Accuracy 0.9352237823606845 precision 0.9352289503466775 specificity 0.8858349551550693 recall 0.9352237823606845 f1 0.9352263626720315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 32.43199896812439 s\n",
      "Accuracy 0.9307261956998684 precision 0.9305029422415013 specificity 0.8716332141706152 recall 0.9307261956998684 f1 0.9306083276881649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 33.65058922767639 s\n",
      "Accuracy 0.9377468187801667 precision 0.9372911783856333 specificity 0.8806057684070836 recall 0.9377468187801667 f1 0.937477353338647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 34.45470976829529 s\n",
      "Accuracy 0.9352786309784994 precision 0.9348253490184051 specificity 0.876227737138049 recall 0.9352786309784994 f1 0.9350158500351337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 33.4391143321991 s\n",
      "Accuracy 0.9340719613865731 precision 0.9338980683564666 specificity 0.8797698535823926 recall 0.9340719613865731 f1 0.9339807250315139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 33.60999894142151 s\n",
      "Accuracy 0.936704695041685 precision 0.936663417310726 specificity 0.8851678785971763 recall 0.936704695041685 f1 0.936683816797382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 33.15909934043884 s\n",
      "Accuracy 0.9336880210618692 precision 0.9336506317094457 specificity 0.8809383056286215 recall 0.9336880210618692 f1 0.9336691451354528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 33.49232220649719 s\n",
      "Accuracy 0.9344559017112769 precision 0.9343907579240549 specificity 0.8853190174796851 recall 0.9344559017112769 f1 0.9344227126574695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 33.74736261367798 s\n",
      "Accuracy 0.935388328214129 precision 0.9354315091617135 specificity 0.8837248382288699 recall 0.935388328214129 f1 0.9354096800987505\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 33.59404802322388 s\n",
      "Accuracy 0.9365401491882405 precision 0.9369120403714224 specificity 0.8898050027715437 recall 0.9365401491882405 f1 0.9367103831661295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 33.91302704811096 s\n",
      "Accuracy 0.937637121544537 precision 0.9381964205170576 specificity 0.8954181039483066 recall 0.937637121544537 f1 0.9378820244141447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 33.80725598335266 s\n",
      "Accuracy 0.9346204475647214 precision 0.9345683564568384 specificity 0.882926018815861 recall 0.9346204475647214 f1 0.9345940321611153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 33.71926689147949 s\n",
      "Accuracy 0.9364853005704257 precision 0.9366653352793527 specificity 0.8853018236553316 recall 0.9364853005704257 f1 0.9365714636294721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 32.89100122451782 s\n",
      "Accuracy 0.9341268100043879 precision 0.9345563712928473 specificity 0.8872438825024526 recall 0.9341268100043879 f1 0.9343219960339781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 33.354997396469116 s\n",
      "Accuracy 0.9363207547169812 precision 0.9365175549997425 specificity 0.885787912567187 recall 0.9363207547169812 f1 0.9364145586774378\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 35.41899847984314 s\n",
      "Accuracy 0.9339622641509434 precision 0.9341723960415406 specificity 0.8813792796370794 recall 0.9339622641509434 f1 0.9340624888077278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 34.9830002784729 s\n",
      "Accuracy 0.9315489249670909 precision 0.9316395339192907 specificity 0.8789535935801194 recall 0.9315489249670909 f1 0.9315932895565335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 35.717000007629395 s\n",
      "Accuracy 0.9312746818780167 precision 0.9312016724893526 specificity 0.8743478433141194 recall 0.9312746818780167 f1 0.9312375500819903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 34.80900025367737 s\n",
      "Accuracy 0.9335234752084247 precision 0.933670376705121 specificity 0.8820794292061084 recall 0.9335234752084247 f1 0.9335944245499895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 33.053563594818115 s\n",
      "Accuracy 0.938021061869241 precision 0.9376878077122784 specificity 0.882241674902049 recall 0.938021061869241 f1 0.93783480544974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 32.391467571258545 s\n",
      "Accuracy 0.9328104431768319 precision 0.9327309149166549 specificity 0.8796390994823363 recall 0.9328104431768319 f1 0.9327698504969816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 33.80821084976196 s\n",
      "Accuracy 0.9337977182974989 precision 0.9341458709121704 specificity 0.8843951077948846 recall 0.9337977182974989 f1 0.9339589159873788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 35.35957407951355 s\n",
      "Accuracy 0.9359916630100922 precision 0.9359344730738811 specificity 0.8836346711537728 recall 0.9359916630100922 f1 0.9359626159270824\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 32.975008726119995 s\n",
      "Accuracy 0.9368692408951295 precision 0.9374739478411035 specificity 0.8944482788600789 recall 0.9368692408951295 f1 0.9371324944371925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 33.217997312545776 s\n",
      "Accuracy 0.9342913558578324 precision 0.934322896778324 specificity 0.8848471333852342 recall 0.9342913558578324 f1 0.9343069942672267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 34.82750940322876 s\n",
      "Accuracy 0.9346752961825362 precision 0.9347853775411971 specificity 0.887878008490708 recall 0.9346752961825362 f1 0.9347287298114244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 34.93199944496155 s\n",
      "Accuracy 0.9340719613865731 precision 0.9341596915311456 specificity 0.8831094215465035 recall 0.9340719613865731 f1 0.9341148803024958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 33.59553074836731 s\n",
      "Accuracy 0.9364853005704257 precision 0.936243958523858 specificity 0.8825348058801722 recall 0.9364853005704257 f1 0.9363552751901366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 32.96632957458496 s\n",
      "Accuracy 0.9351140851250549 precision 0.9347013163820201 specificity 0.8762809017067541 recall 0.9351140851250549 f1 0.9348792096302627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 32.05499863624573 s\n",
      "Accuracy 0.9335234752084247 precision 0.9334173333181122 specificity 0.8790332034543916 recall 0.9335234752084247 f1 0.9334689189486791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 33.217010736465454 s\n",
      "Accuracy 0.934730144800351 precision 0.9348990302365211 specificity 0.8838215515893896 recall 0.934730144800351 f1 0.93481123966717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 33.54850935935974 s\n",
      "Accuracy 0.9339622641509434 precision 0.9339731893367282 specificity 0.8808615599571461 recall 0.9339622641509434 f1 0.9339677118761984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 34.9616219997406 s\n",
      "Accuracy 0.9347849934181659 precision 0.9346490130581792 specificity 0.8826229578821734 recall 0.9347849934181659 f1 0.9347143086402827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 35.45899820327759 s\n",
      "Accuracy 0.939282580078982 precision 0.93938019095616 specificity 0.8918485847699853 recall 0.939282580078982 f1 0.9393300322542296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 33.582974433898926 s\n",
      "Accuracy 0.9363207547169812 precision 0.9366337762074451 specificity 0.8883428009738658 recall 0.9363207547169812 f1 0.936465993405928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 34.216963052749634 s\n",
      "Accuracy 0.9358271171566477 precision 0.9354383650283817 specificity 0.8805181952091508 recall 0.9358271171566477 f1 0.9356052032243063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 33.46097779273987 s\n",
      "Accuracy 0.934730144800351 precision 0.9350234740477089 specificity 0.8839225821666304 recall 0.934730144800351 f1 0.9348674722543072\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 33.521401166915894 s\n",
      "Accuracy 0.9362110574813515 precision 0.9361843983452653 specificity 0.8828109081939556 recall 0.9362110574813515 f1 0.9361976338310486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 35.16517353057861 s\n",
      "Accuracy 0.9326458973233874 precision 0.9329048652872313 specificity 0.8812584345474761 recall 0.9326458973233874 f1 0.9327682267251748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 33.32000398635864 s\n",
      "Accuracy 0.9310552874067574 precision 0.9310952046743777 specificity 0.87649639887773 recall 0.9310552874067574 f1 0.9310750654741954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 33.695316553115845 s\n",
      "Accuracy 0.9346752961825362 precision 0.9348903350424086 specificity 0.8870319839507429 recall 0.9346752961825362 f1 0.9347772297238081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 34.83660674095154 s\n",
      "Accuracy 0.9354431768319439 precision 0.9354378852192922 specificity 0.8837366264031975 recall 0.9354431768319439 f1 0.9354405273031162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 35.55652213096619 s\n",
      "Accuracy 0.9319328652917946 precision 0.9318830128360385 specificity 0.8766046896380647 recall 0.9319328652917946 f1 0.9319076391598261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 35.926045179367065 s\n",
      "Accuracy 0.9327555945590171 precision 0.9329980504861229 specificity 0.882606274061983 recall 0.9327555945590171 f1 0.9328703367492617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 36.4775767326355 s\n",
      "Accuracy 0.9330846862659061 precision 0.9334108394668383 specificity 0.884488636097584 recall 0.9330846862659061 f1 0.9332362548509515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 33.7416718006134 s\n",
      "Accuracy 0.9344559017112769 precision 0.9345484584322289 specificity 0.8840845574401053 recall 0.9344559017112769 f1 0.9345011122307426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 33.93899917602539 s\n",
      "Accuracy 0.9365401491882405 precision 0.9365453483688005 specificity 0.8861075116954032 recall 0.9365401491882405 f1 0.936542745052689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 34.177597999572754 s\n",
      "Accuracy 0.9336880210618692 precision 0.9337585525791776 specificity 0.8832108971161315 recall 0.9336880210618692 f1 0.9337226652111457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 34.60700035095215 s\n",
      "Accuracy 0.9354980254497587 precision 0.9355411023662726 specificity 0.8839828339725627 recall 0.9354980254497587 f1 0.935519325327831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 34.012800455093384 s\n",
      "Accuracy 0.934730144800351 precision 0.9347518094069562 specificity 0.882353601440198 recall 0.934730144800351 f1 0.9347409175411368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 33.879565954208374 s\n",
      "Accuracy 0.9323168056164984 precision 0.932088004653637 specificity 0.8757379133666104 recall 0.9323168056164984 f1 0.9321952333137841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 33.782910108566284 s\n",
      "Accuracy 0.9343462044756472 precision 0.9342264177388325 specificity 0.8804487106396269 recall 0.9343462044756472 f1 0.9342843441603209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 34.531118631362915 s\n",
      "Accuracy 0.9337428696796841 precision 0.9334632414120179 specificity 0.8748658893800134 recall 0.9337428696796841 f1 0.933592089162748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 33.86290121078491 s\n",
      "Accuracy 0.9358271171566477 precision 0.9355116488957624 specificity 0.8799994366436253 recall 0.9358271171566477 f1 0.9356530633470489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 33.913105487823486 s\n",
      "Accuracy 0.9351689337428697 precision 0.935031948904172 specificity 0.8848771367838253 recall 0.9351689337428697 f1 0.9350975618069975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 34.079549074172974 s\n",
      "Accuracy 0.9354431768319439 precision 0.9353629665189037 specificity 0.8803141390903149 recall 0.9354431768319439 f1 0.9354022241195801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 33.87474274635315 s\n",
      "Accuracy 0.9355528740675735 precision 0.9358662541272115 specificity 0.8877413767967138 recall 0.9355528740675735 f1 0.9356983505335688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 33.844809770584106 s\n",
      "Accuracy 0.9339074155331286 precision 0.9340930341058207 specificity 0.8839097412211301 recall 0.9339074155331286 f1 0.933996205860221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 33.9505250453949 s\n",
      "Accuracy 0.9331395348837209 precision 0.9333272714409591 specificity 0.8824999153138683 recall 0.9331395348837209 f1 0.9332293899511855\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 33.6855685710907 s\n",
      "Accuracy 0.9329749890302764 precision 0.9329423248043525 specificity 0.8791625178918245 recall 0.9329749890302764 f1 0.9329585236401507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 33.88286757469177 s\n",
      "Accuracy 0.9323716542343133 precision 0.93227230491197 specificity 0.879814734534347 recall 0.9323716542343133 f1 0.9323206576792091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 34.19612979888916 s\n",
      "Accuracy 0.9326458973233874 precision 0.9327220533622618 specificity 0.8825578067493653 recall 0.9326458973233874 f1 0.932683259455355\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 35.04538893699646 s\n",
      "Accuracy 0.9339622641509434 precision 0.9345464322832108 specificity 0.888257990499746 recall 0.9339622641509434 f1 0.9342204918241184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 36.263936042785645 s\n",
      "Accuracy 0.93505923650724 precision 0.9350699175525304 specificity 0.8833216376057993 recall 0.93505923650724 f1 0.9350645621598931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 33.83969855308533 s\n",
      "Accuracy 0.9349495392716104 precision 0.934831268534488 specificity 0.8849221593398242 recall 0.9349495392716104 f1 0.934888291498168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 32.69505453109741 s\n",
      "Accuracy 0.9327007459412023 precision 0.9327283582289034 specificity 0.879783847659144 recall 0.9327007459412023 f1 0.9327144598115464\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 32.03599810600281 s\n",
      "Accuracy 0.9378565160157964 precision 0.9378408095439996 specificity 0.8855442014289745 recall 0.9378565160157964 f1 0.9378486287357715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 32.7049994468689 s\n",
      "Accuracy 0.9342365072400175 precision 0.9348072236234897 specificity 0.8893341045381414 recall 0.9342365072400175 f1 0.9344887877130356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 32.337000131607056 s\n",
      "Accuracy 0.9371434839842036 precision 0.9374426792600132 specificity 0.890845049969882 recall 0.9371434839842036 f1 0.9372822510810286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 29.48699975013733 s\n",
      "Accuracy 0.9306713470820536 precision 0.9312658126330909 specificity 0.8843963852184946 recall 0.9306713470820536 f1 0.9309352493098304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 28.75699806213379 s\n",
      "Accuracy 0.9345107503290917 precision 0.9344696268927608 specificity 0.8842658485961967 recall 0.9345107503290917 f1 0.9344899534405919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 29.105998277664185 s\n",
      "Accuracy 0.9346204475647214 precision 0.9349313294055687 specificity 0.8861123096923234 recall 0.9346204475647214 f1 0.9347651048643115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 28.742997884750366 s\n",
      "Accuracy 0.9365401491882405 precision 0.936202172200211 specificity 0.8814418726310395 recall 0.9365401491882405 f1 0.9363512099043563\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 28.510000467300415 s\n",
      "Accuracy 0.9368143922773147 precision 0.9367843049106857 specificity 0.887801713061306 recall 0.9368143922773147 f1 0.9367992153324185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 28.742000102996826 s\n",
      "Accuracy 0.9354980254497587 precision 0.9356939702402057 specificity 0.8880575206774639 recall 0.9354980254497587 f1 0.9355912242051281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 28.455000162124634 s\n",
      "Accuracy 0.9351140851250549 precision 0.9350986433143044 specificity 0.8853800536133564 recall 0.9351140851250549 f1 0.9351063310818962\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 28.55799889564514 s\n",
      "Accuracy 0.9351140851250549 precision 0.9350150595209802 specificity 0.8815149687946189 recall 0.9351140851250549 f1 0.9350632250109461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 29.05599808692932 s\n",
      "Accuracy 0.9356625713032032 precision 0.9361864840572015 specificity 0.8910045009087888 recall 0.9356625713032032 f1 0.9358953331122869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 29.11400008201599 s\n",
      "Accuracy 0.9336331724440544 precision 0.933814582947416 specificity 0.8829210748440515 recall 0.9336331724440544 f1 0.9337200934101543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 28.825000286102295 s\n",
      "Accuracy 0.9358271171566477 precision 0.9358166138210972 specificity 0.884375067894371 recall 0.9358271171566477 f1 0.9358218505870188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 28.491999864578247 s\n",
      "Accuracy 0.9366498464238702 precision 0.936754258768436 specificity 0.8849780905748124 recall 0.9366498464238702 f1 0.936700693636772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 28.320997714996338 s\n",
      "Accuracy 0.9329749890302764 precision 0.9326632930276708 specificity 0.8754859688010599 recall 0.9329749890302764 f1 0.932804846665644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 28.532000064849854 s\n",
      "Accuracy 0.9365949978060553 precision 0.9368620834614458 specificity 0.8891060910529284 recall 0.9365949978060553 f1 0.9367199753281662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 28.48199987411499 s\n",
      "Accuracy 0.9331395348837209 precision 0.9333869677215281 specificity 0.8832900228709422 recall 0.9331395348837209 f1 0.9332564460777378\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 28.957997798919678 s\n",
      "Accuracy 0.9334686265906099 precision 0.9336243147018759 specificity 0.8805127038211613 recall 0.9334686265906099 f1 0.933543755915617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 29.01799750328064 s\n",
      "Accuracy 0.937308029837648 precision 0.9373440855580494 specificity 0.8883464793550555 recall 0.937308029837648 f1 0.9373258753164685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 28.610000371932983 s\n",
      "Accuracy 0.9371434839842036 precision 0.9369075295623842 specificity 0.8845707916638985 recall 0.9371434839842036 f1 0.9370161757422633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 29.150997161865234 s\n",
      "Accuracy 0.9346204475647214 precision 0.9349696232630835 specificity 0.8862648586864706 recall 0.9346204475647214 f1 0.9347817131521339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 29.159001111984253 s\n",
      "Accuracy 0.9327007459412023 precision 0.9328857047086012 specificity 0.8834453216478213 recall 0.9327007459412023 f1 0.9327892453884462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 28.17699956893921 s\n",
      "Accuracy 0.9341268100043879 precision 0.9340897809138945 specificity 0.8819621304483258 recall 0.9341268100043879 f1 0.9341081142344002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 28.58799958229065 s\n",
      "Accuracy 0.9350043878894252 precision 0.9346685748472027 specificity 0.8776532469118412 recall 0.9350043878894252 f1 0.9348186190334364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 29.14400053024292 s\n",
      "Accuracy 0.9327555945590171 precision 0.932649471394862 specificity 0.878649224736313 recall 0.9327555945590171 f1 0.9327010561000574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 30.006999492645264 s\n",
      "Accuracy 0.9336880210618692 precision 0.9338646935869662 specificity 0.8823409476594708 recall 0.9336880210618692 f1 0.9337727957967674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 32.8629994392395 s\n",
      "Accuracy 0.9354431768319439 precision 0.9354591174837978 specificity 0.8841240183829198 recall 0.9354431768319439 f1 0.9354511136834184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 33.78600025177002 s\n",
      "Accuracy 0.9379113646336112 precision 0.9379011847040306 specificity 0.8879820030050396 recall 0.9379113646336112 f1 0.9379062596938755\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 34.81000018119812 s\n",
      "Accuracy 0.9309455901711277 precision 0.9309737304362296 specificity 0.8771989223234421 recall 0.9309455901711277 f1 0.9309595685693739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 36.3240008354187 s\n",
      "Accuracy 0.9324813514699429 precision 0.9325199811923969 specificity 0.8800708355884457 recall 0.9324813514699429 f1 0.9325004859985669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 36.736997842788696 s\n",
      "Accuracy 0.9372531812198333 precision 0.9379163466189742 specificity 0.8955758170814718 recall 0.9372531812198333 f1 0.9375384846599274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 35.661701679229736 s\n",
      "Accuracy 0.9345655989469065 precision 0.9345925408759813 specificity 0.8828587137242319 recall 0.9345655989469065 f1 0.9345789771796312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 33.34097123146057 s\n",
      "Accuracy 0.9329749890302764 precision 0.933669851042666 specificity 0.8867573160431761 recall 0.9329749890302764 f1 0.9332779715877261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 34.69705557823181 s\n",
      "Accuracy 0.9330846862659061 precision 0.9331289955691178 specificity 0.8802917074213684 recall 0.9330846862659061 f1 0.9331066041883865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 35.365999937057495 s\n",
      "Accuracy 0.9341816586222027 precision 0.9342595838394643 specificity 0.8815829337069389 recall 0.9341816586222027 f1 0.9342198915620813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 35.18899941444397 s\n",
      "Accuracy 0.9351140851250549 precision 0.9351195080591502 specificity 0.8819213212313722 recall 0.9351140851250549 f1 0.9351167928506418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 33.74499869346619 s\n",
      "Accuracy 0.9330846862659061 precision 0.9329586921272378 specificity 0.8789735145544328 recall 0.9330846862659061 f1 0.9330195604062674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 35.35255432128906 s\n",
      "Accuracy 0.9338525669153137 precision 0.9340561965309504 specificity 0.8839398758906134 recall 0.9338525669153137 f1 0.9339495989508401\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 34.21053624153137 s\n",
      "Accuracy 0.9313843791136464 precision 0.9310113389370916 specificity 0.87326637120023 recall 0.9313843791136464 f1 0.9311771079197977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 35.790175676345825 s\n",
      "Accuracy 0.9344559017112769 precision 0.9345142516681961 specificity 0.8851059432567172 recall 0.9344559017112769 f1 0.9344846321756769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 33.22949290275574 s\n",
      "Accuracy 0.9330846862659061 precision 0.9332204004755705 specificity 0.8813935095940635 recall 0.9330846862659061 f1 0.9331504157567998\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 33.987998723983765 s\n",
      "Accuracy 0.9356077226853883 precision 0.935466625387462 specificity 0.8828126701283815 recall 0.9356077226853883 f1 0.9355342558281969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 33.2260000705719 s\n",
      "Accuracy 0.9329201404124616 precision 0.9332008650047872 specificity 0.880700871310636 recall 0.9329201404124616 f1 0.9330522926675457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 34.48200178146362 s\n",
      "Accuracy 0.9386792452830188 precision 0.9387598743673651 specificity 0.8924028449328751 recall 0.9386792452830188 f1 0.9387186095441283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 35.36799907684326 s\n",
      "Accuracy 0.9323168056164984 precision 0.9323280560434437 specificity 0.8774806717040807 recall 0.9323168056164984 f1 0.9323224159875353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 35.415998220443726 s\n",
      "Accuracy 0.9338525669153137 precision 0.9339888852094703 specificity 0.8814831040449108 recall 0.9338525669153137 f1 0.9339185832125209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 36.45800042152405 s\n",
      "Accuracy 0.938021061869241 precision 0.9383732206439975 specificity 0.8908685808937492 recall 0.938021061869241 f1 0.9381827021239411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 34.67081689834595 s\n",
      "Accuracy 0.9347849934181659 precision 0.9349726646538228 specificity 0.8835460257749804 recall 0.9347849934181659 f1 0.9348747683106481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 33.73268175125122 s\n",
      "Accuracy 0.9359916630100922 precision 0.9361360038909663 specificity 0.8882092294529974 recall 0.9359916630100922 f1 0.9360611422201298\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 33.93523359298706 s\n",
      "Accuracy 0.9369240895129443 precision 0.93750042920308 specificity 0.891544125984471 recall 0.9369240895129443 f1 0.9371778586946562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 34.0910758972168 s\n",
      "Accuracy 0.9328652917946467 precision 0.9329877991107427 specificity 0.8821793571709523 recall 0.9328652917946467 f1 0.9329247681645854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 33.94847059249878 s\n",
      "Accuracy 0.9333589293549802 precision 0.9334544081729732 specificity 0.8808879117215229 recall 0.9333589293549802 f1 0.9334055976653709\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 33.92377233505249 s\n",
      "Accuracy 0.9345107503290917 precision 0.9345647425998586 specificity 0.8835539658057778 recall 0.9345107503290917 f1 0.9345373764650861\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 34.06729006767273 s\n",
      "Accuracy 0.9343462044756472 precision 0.9343189531305636 specificity 0.8799910080768919 recall 0.9343462044756472 f1 0.9343324853204724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 33.046295404434204 s\n",
      "Accuracy 0.9325362000877578 precision 0.9327649386037962 specificity 0.882902693549207 recall 0.9325362000877578 f1 0.9326447089872927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 33.58231544494629 s\n",
      "Accuracy 0.9309455901711277 precision 0.9311770899968609 specificity 0.8785881204055803 recall 0.9309455901711277 f1 0.931055753991598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 33.47599911689758 s\n",
      "Accuracy 0.9306164984642387 precision 0.9307018874664472 specificity 0.8777913945082791 recall 0.9306164984642387 f1 0.9306583703060715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 33.58306360244751 s\n",
      "Accuracy 0.9353334795963142 precision 0.9355230643056077 specificity 0.8881578604950728 recall 0.9353334795963142 f1 0.9354237703893239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 33.654030323028564 s\n",
      "Accuracy 0.9326458973233874 precision 0.9325675342150485 specificity 0.8751692527934337 recall 0.9326458973233874 f1 0.932605981578775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 35.515448570251465 s\n",
      "Accuracy 0.9375822729267222 precision 0.9372240721903844 specificity 0.8815148918174291 recall 0.9375822729267222 f1 0.9373801917066491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 31.435753345489502 s\n",
      "Accuracy 0.9339074155331286 precision 0.9337989498546242 specificity 0.8812526741542784 recall 0.9339074155331286 f1 0.93385155479801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 31.872999668121338 s\n",
      "Accuracy 0.9341268100043879 precision 0.9340888329205715 specificity 0.879891354251532 recall 0.9341268100043879 f1 0.9341076386278316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 32.62011671066284 s\n",
      "Accuracy 0.9322619569986836 precision 0.9323110470877016 specificity 0.8812486985926915 recall 0.9322619569986836 f1 0.9322862059176996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 33.345999002456665 s\n",
      "Accuracy 0.9342913558578324 precision 0.9346597349159792 specificity 0.8876160975053986 recall 0.9342913558578324 f1 0.9344605156186896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 33.951735973358154 s\n",
      "Accuracy 0.9340171127687582 precision 0.9340891955732357 specificity 0.8816265540824354 recall 0.9340171127687582 f1 0.9340525262863655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 33.66385841369629 s\n",
      "Accuracy 0.9361013602457218 precision 0.9357766692877869 specificity 0.8825750428287887 recall 0.9361013602457218 f1 0.9359203072315432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 33.4102144241333 s\n",
      "Accuracy 0.9340171127687582 precision 0.934044762952173 specificity 0.8804119631162831 recall 0.9340171127687582 f1 0.9340308446514868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 33.68492293357849 s\n",
      "Accuracy 0.9365401491882405 precision 0.9365452949787099 specificity 0.8869136952342923 recall 0.9365401491882405 f1 0.9365427183712064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 33.84683704376221 s\n",
      "Accuracy 0.9371983326020185 precision 0.9374999827110415 specificity 0.891843426672299 recall 0.9371983326020185 f1 0.9373379660090816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 33.59625506401062 s\n",
      "Accuracy 0.9362659060991663 precision 0.9360445152886927 specificity 0.8802624284437118 recall 0.9362659060991663 f1 0.9361479014257903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 33.71336269378662 s\n",
      "Accuracy 0.9333040807371654 precision 0.9333601503519559 specificity 0.8797484993448299 recall 0.9333040807371654 f1 0.9333317438671427\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 33.813737630844116 s\n",
      "Accuracy 0.9323716542343133 precision 0.9320778989884102 specificity 0.8741031883103608 recall 0.9323716542343133 f1 0.9322126837937098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 33.926910638809204 s\n",
      "Accuracy 0.934401053093462 precision 0.9346141823111975 specificity 0.8853221160208288 recall 0.934401053093462 f1 0.9345022897842594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 33.71430277824402 s\n",
      "Accuracy 0.9357722685388328 precision 0.9359306087605729 specificity 0.886762295208074 recall 0.9357722685388328 f1 0.9358483190009819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 33.68004131317139 s\n",
      "Accuracy 0.9366498464238702 precision 0.9369847149887682 specificity 0.8924208940122734 recall 0.9366498464238702 f1 0.9368036103820978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 33.328845500946045 s\n",
      "Accuracy 0.9325362000877578 precision 0.9326941447579389 specificity 0.8819600969627439 recall 0.9325362000877578 f1 0.9326122963877482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 33.81252312660217 s\n",
      "Accuracy 0.936375603334796 precision 0.9366032815312173 specificity 0.8899680795164743 recall 0.936375603334796 f1 0.9364829349179369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 33.46678900718689 s\n",
      "Accuracy 0.934401053093462 precision 0.9346164012091165 specificity 0.8844788239897632 recall 0.934401053093462 f1 0.9345033793715605\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 33.946643352508545 s\n",
      "Accuracy 0.9342913558578324 precision 0.9345541389581963 specificity 0.8851452171215328 recall 0.9342913558578324 f1 0.9344149286257827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 34.226189374923706 s\n",
      "Accuracy 0.9332492321193506 precision 0.9333463400083479 specificity 0.8793953271957491 recall 0.9332492321193506 f1 0.9332967093402298\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 34.76097393035889 s\n",
      "Accuracy 0.9356077226853883 precision 0.9356401361387474 specificity 0.8834182189070283 recall 0.9356077226853883 f1 0.9356237947877457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 33.95601558685303 s\n",
      "Accuracy 0.9330298376480912 precision 0.9331844850443285 specificity 0.8808157799128926 recall 0.9330298376480912 f1 0.9331044617229409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 33.80423641204834 s\n",
      "Accuracy 0.9339622641509434 precision 0.9339406083201244 specificity 0.8805197696209369 recall 0.9339622641509434 f1 0.9339513767521488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 33.812522649765015 s\n",
      "Accuracy 0.9323168056164984 precision 0.932487856743605 specificity 0.8812847913818188 recall 0.9323168056164984 f1 0.932399025747076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 33.976296186447144 s\n",
      "Accuracy 0.9332492321193506 precision 0.9336941742204601 specificity 0.8837122065522126 recall 0.9332492321193506 f1 0.9334519757171863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 33.56357431411743 s\n",
      "Accuracy 0.9339622641509434 precision 0.9338040436776246 specificity 0.877936541612025 recall 0.9339622641509434 f1 0.9338797891041134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 34.593528509140015 s\n",
      "Accuracy 0.9359368143922773 precision 0.9359368143922773 specificity 0.8858721883408301 recall 0.9359368143922773 f1 0.9359368143922773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 34.78591799736023 s\n",
      "Accuracy 0.9331395348837209 precision 0.9331884958593318 specificity 0.8819732338895164 recall 0.9331395348837209 f1 0.9331637176769836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 33.66138052940369 s\n",
      "Accuracy 0.9340171127687582 precision 0.9339583248832501 specificity 0.8803494898692374 recall 0.9340171127687582 f1 0.9339872690634358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 34.24775743484497 s\n",
      "Accuracy 0.9339622641509434 precision 0.9340488999973261 specificity 0.8840561104466326 recall 0.9339622641509434 f1 0.9340046408204902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 34.09895300865173 s\n",
      "Accuracy 0.9344559017112769 precision 0.9346255539407182 specificity 0.886110812376263 recall 0.9344559017112769 f1 0.9345371979294176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 33.61221647262573 s\n",
      "Accuracy 0.9363207547169812 precision 0.9360393250391458 specificity 0.8816937961945241 recall 0.9363207547169812 f1 0.936167012462948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 33.617883920669556 s\n",
      "Accuracy 0.93505923650724 precision 0.9350171857914336 specificity 0.8828011446611845 recall 0.93505923650724 f1 0.9350379731965247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 34.22727584838867 s\n",
      "Accuracy 0.9318780166739798 precision 0.9320284680573823 specificity 0.8790767584631319 recall 0.9318780166739798 f1 0.9319507490511424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 33.9097535610199 s\n",
      "Accuracy 0.9340171127687582 precision 0.9341667386690906 specificity 0.8841424848929107 recall 0.9340171127687582 f1 0.9340892386390419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 33.75006341934204 s\n",
      "Accuracy 0.9337977182974989 precision 0.9338254597140496 specificity 0.8800129451684291 recall 0.9337977182974989 f1 0.9338114958390228\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 35.16162729263306 s\n",
      "Accuracy 0.9378565160157964 precision 0.9380204589301041 specificity 0.8908989995643679 recall 0.9378565160157964 f1 0.9379349123977949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 34.20767951011658 s\n",
      "Accuracy 0.9369240895129443 precision 0.936853533157527 specificity 0.886036250061546 recall 0.9369240895129443 f1 0.9368880804536801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 33.6438250541687 s\n",
      "Accuracy 0.9372531812198333 precision 0.9371175754929327 specificity 0.8812081287000415 recall 0.9372531812198333 f1 0.937182801172332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 33.64148926734924 s\n",
      "Accuracy 0.9359916630100922 precision 0.9359864435061637 specificity 0.8851344059835021 recall 0.9359916630100922 f1 0.9359890495382782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 34.270538330078125 s\n",
      "Accuracy 0.9388437911364633 precision 0.938930628170874 specificity 0.8916638513957401 recall 0.9388437911364633 f1 0.9388861309282396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 33.92251539230347 s\n",
      "Accuracy 0.935388328214129 precision 0.9356540468745113 specificity 0.8887213314598585 recall 0.935388328214129 f1 0.9355127128903571\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 34.54573035240173 s\n",
      "Accuracy 0.9337977182974989 precision 0.9339730995132117 specificity 0.8830169161570647 recall 0.9337977182974989 f1 0.9338818539176624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 34.14732766151428 s\n",
      "Accuracy 0.9340171127687582 precision 0.9342894531078692 specificity 0.8839705510767538 recall 0.9340171127687582 f1 0.9341450989311656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 33.83002495765686 s\n",
      "Accuracy 0.934401053093462 precision 0.9342941251755404 specificity 0.8788698279486515 recall 0.934401053093462 f1 0.934346090138592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 33.87483620643616 s\n",
      "Accuracy 0.9359916630100922 precision 0.9362273530082775 specificity 0.8890327837730746 recall 0.9359916630100922 f1 0.9361026826755622\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 34.140610456466675 s\n",
      "Accuracy 0.9347849934181659 precision 0.9348787539320379 specificity 0.88322832964917 recall 0.9347849934181659 f1 0.9348307983245379\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 33.65812659263611 s\n",
      "Accuracy 0.9345107503290917 precision 0.9344371291764183 specificity 0.8813870469640545 recall 0.9345107503290917 f1 0.9344732113954661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 33.95253109931946 s\n",
      "Accuracy 0.9343462044756472 precision 0.9345828986179278 specificity 0.8876338776658312 recall 0.9343462044756472 f1 0.9344577955979907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 33.61021137237549 s\n",
      "Accuracy 0.9362110574813515 precision 0.9366203344293463 specificity 0.8900123787998317 recall 0.9362110574813515 f1 0.9363970051263338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 34.81540369987488 s\n",
      "Accuracy 0.9335783238262396 precision 0.9337997386643427 specificity 0.8839850274810576 recall 0.9335783238262396 f1 0.93368343077302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 33.4276819229126 s\n",
      "Accuracy 0.9361013602457218 precision 0.9361918839590135 specificity 0.8868293624691534 recall 0.9361013602457218 f1 0.9361455497387119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 35.64052987098694 s\n",
      "Accuracy 0.9325910487055726 precision 0.9324676616192383 specificity 0.877114114280416 recall 0.9325910487055726 f1 0.9325273937326309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 35.56153655052185 s\n",
      "Accuracy 0.936046511627907 precision 0.9361883602153326 specificity 0.8864631906201591 recall 0.936046511627907 f1 0.9361149196512886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 35.199559926986694 s\n",
      "Accuracy 0.9339622641509434 precision 0.9338788383357142 specificity 0.8814217632838637 recall 0.9339622641509434 f1 0.9339196054847382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 32.18677282333374 s\n",
      "Accuracy 0.9348946906537955 precision 0.9351044406337751 specificity 0.8845859522304962 recall 0.9348946906537955 f1 0.934994473964334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 32.41108679771423 s\n",
      "Accuracy 0.9348946906537955 precision 0.9348893282901367 specificity 0.8823588495472953 recall 0.9348946906537955 f1 0.9348920057473059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 34.219807624816895 s\n",
      "Accuracy 0.9329749890302764 precision 0.9332290378218899 specificity 0.8830760980311997 recall 0.9329749890302764 f1 0.9330948913820468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 34.0828754901886 s\n",
      "Accuracy 0.9371434839842036 precision 0.9371644759340731 specificity 0.8862493570050165 recall 0.9371434839842036 f1 0.9371539199752903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 33.39120817184448 s\n",
      "Accuracy 0.9337977182974989 precision 0.9338453270213919 specificity 0.8845892866873429 recall 0.9337977182974989 f1 0.9338212264432759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 34.00463628768921 s\n",
      "Accuracy 0.9320425625274243 precision 0.9323243588675766 specificity 0.8836486717973238 recall 0.9320425625274243 f1 0.93217471994651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 33.98466730117798 s\n",
      "Accuracy 0.9341268100043879 precision 0.9341655037827095 specificity 0.8808702211867178 recall 0.9341268100043879 f1 0.9341459742875972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 33.853187799453735 s\n",
      "Accuracy 0.9336880210618692 precision 0.933576152601106 specificity 0.8786246293113571 recall 0.9336880210618692 f1 0.9336304442002094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 33.464123487472534 s\n",
      "Accuracy 0.9342913558578324 precision 0.9347901764999765 specificity 0.888473379220769 recall 0.9342913558578324 f1 0.9345148560247766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 34.78602886199951 s\n",
      "Accuracy 0.9326458973233874 precision 0.932714212700013 specificity 0.8784387871133303 recall 0.9326458973233874 f1 0.9326795200519988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 34.27280569076538 s\n",
      "Accuracy 0.9375822729267222 precision 0.9373804368973615 specificity 0.8848767174590777 recall 0.9375822729267222 f1 0.9374747395942807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 33.75223731994629 s\n",
      "Accuracy 0.9322071083808688 precision 0.9321291068620734 specificity 0.8753429772274665 recall 0.9322071083808688 f1 0.9321673770041022\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 33.830827951431274 s\n",
      "Accuracy 0.9344559017112769 precision 0.9347568027819746 specificity 0.8869587388823932 recall 0.9344559017112769 f1 0.934596023082165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 33.41651463508606 s\n",
      "Accuracy 0.9347849934181659 precision 0.9348449075013249 specificity 0.8831801699628765 recall 0.9347849934181659 f1 0.9348145007162244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 33.809690952301025 s\n",
      "Accuracy 0.9327007459412023 precision 0.9323727804960376 specificity 0.8765955131077746 recall 0.9327007459412023 f1 0.9325202032308035\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "split_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "smote_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, (split_seed, smote_seed) in enumerate(zip(split_seeds, smote_seeds)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=split_seed)\n",
    "    smote = SMOTE(random_state=smote_seed, n_jobs=THREADS_TO_USE)\n",
    "    x_smote, y_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_smote, y_smote)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(split_seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.932207     0.878096   0.932132  0.932207  0.932169\n1  0.934895     0.887531   0.935170  0.934895  0.935023\n2  0.931713     0.880962   0.931878  0.931713  0.931793\n3  0.932920     0.885492   0.933314  0.932920  0.933101\n4  0.933853     0.880006   0.933661  0.933853  0.933751\n5  0.935114     0.885411   0.935172  0.935114  0.935143\n6  0.934401     0.884944   0.934521  0.934401  0.934459\n7  0.936760     0.887785   0.936952  0.936760  0.936851\n8  0.932536     0.880846   0.932453  0.932536  0.932494\n9  0.934840     0.882325   0.934873  0.934840  0.934856",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.932207</td>\n      <td>0.878096</td>\n      <td>0.932132</td>\n      <td>0.932207</td>\n      <td>0.932169</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.934895</td>\n      <td>0.887531</td>\n      <td>0.935170</td>\n      <td>0.934895</td>\n      <td>0.935023</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.931713</td>\n      <td>0.880962</td>\n      <td>0.931878</td>\n      <td>0.931713</td>\n      <td>0.931793</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.932920</td>\n      <td>0.885492</td>\n      <td>0.933314</td>\n      <td>0.932920</td>\n      <td>0.933101</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.933853</td>\n      <td>0.880006</td>\n      <td>0.933661</td>\n      <td>0.933853</td>\n      <td>0.933751</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.935114</td>\n      <td>0.885411</td>\n      <td>0.935172</td>\n      <td>0.935114</td>\n      <td>0.935143</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.934401</td>\n      <td>0.884944</td>\n      <td>0.934521</td>\n      <td>0.934401</td>\n      <td>0.934459</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.936760</td>\n      <td>0.887785</td>\n      <td>0.936952</td>\n      <td>0.936760</td>\n      <td>0.936851</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.932536</td>\n      <td>0.880846</td>\n      <td>0.932453</td>\n      <td>0.932536</td>\n      <td>0.932494</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.934840</td>\n      <td>0.882325</td>\n      <td>0.934873</td>\n      <td>0.934840</td>\n      <td>0.934856</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.934635366388767\n",
      "Precision 0.9346932937792626\n",
      "Specificity 0.883312612207144\n",
      "Recall 0.934635366388767\n",
      "F1 0.934658764494692\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_6beats_smote_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}