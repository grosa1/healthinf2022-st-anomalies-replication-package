{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 6 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3      dw_4      dw_5     mfw_1  \\\n0  e0106  21.861233  21.421103  21.536569  6.108208  0.880920  1.079942   \n1  e0106  26.408089  27.988299  27.611772  7.776970  1.129695  1.195165   \n2  e0106  25.977641  26.935251  26.561891  7.477219  1.098311  1.176663   \n3  e0106  25.189643  25.649484  25.620624  7.261496  1.066191  1.162694   \n4  e0106  24.659920  24.559022  24.462891  6.972141  1.008067  1.143318   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.914392 -1.844370 -1.138702  ... -0.068189  0.053454 -0.067161  0.067961   \n1 -0.806390 -1.774080 -1.792590  ... -0.031130  0.017521 -0.014034  0.023165   \n2 -0.849446 -1.805917 -1.623971  ... -0.025147  0.006059 -0.022267  0.043209   \n3 -0.825414 -1.684836 -1.477246  ... -0.040045  0.024580 -0.029490  0.040770   \n4 -0.881397 -1.797336 -1.316414  ... -0.064038  0.044904 -0.045340  0.042700   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.093129  0.027961 -0.038417 -0.011442  0.005966    NSR  \n1 -0.043346 -0.016159 -0.012820 -0.007157 -0.012377    NSR  \n2 -0.061407 -0.003576 -0.026326  0.004760 -0.015544    NSR  \n3 -0.057996 -0.012361 -0.019814  0.007333 -0.030823    NSR  \n4 -0.063328 -0.010253 -0.004272 -0.024278  0.001717    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>21.861233</td>\n      <td>21.421103</td>\n      <td>21.536569</td>\n      <td>6.108208</td>\n      <td>0.880920</td>\n      <td>1.079942</td>\n      <td>-0.914392</td>\n      <td>-1.844370</td>\n      <td>-1.138702</td>\n      <td>...</td>\n      <td>-0.068189</td>\n      <td>0.053454</td>\n      <td>-0.067161</td>\n      <td>0.067961</td>\n      <td>-0.093129</td>\n      <td>0.027961</td>\n      <td>-0.038417</td>\n      <td>-0.011442</td>\n      <td>0.005966</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>26.408089</td>\n      <td>27.988299</td>\n      <td>27.611772</td>\n      <td>7.776970</td>\n      <td>1.129695</td>\n      <td>1.195165</td>\n      <td>-0.806390</td>\n      <td>-1.774080</td>\n      <td>-1.792590</td>\n      <td>...</td>\n      <td>-0.031130</td>\n      <td>0.017521</td>\n      <td>-0.014034</td>\n      <td>0.023165</td>\n      <td>-0.043346</td>\n      <td>-0.016159</td>\n      <td>-0.012820</td>\n      <td>-0.007157</td>\n      <td>-0.012377</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>25.977641</td>\n      <td>26.935251</td>\n      <td>26.561891</td>\n      <td>7.477219</td>\n      <td>1.098311</td>\n      <td>1.176663</td>\n      <td>-0.849446</td>\n      <td>-1.805917</td>\n      <td>-1.623971</td>\n      <td>...</td>\n      <td>-0.025147</td>\n      <td>0.006059</td>\n      <td>-0.022267</td>\n      <td>0.043209</td>\n      <td>-0.061407</td>\n      <td>-0.003576</td>\n      <td>-0.026326</td>\n      <td>0.004760</td>\n      <td>-0.015544</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>25.189643</td>\n      <td>25.649484</td>\n      <td>25.620624</td>\n      <td>7.261496</td>\n      <td>1.066191</td>\n      <td>1.162694</td>\n      <td>-0.825414</td>\n      <td>-1.684836</td>\n      <td>-1.477246</td>\n      <td>...</td>\n      <td>-0.040045</td>\n      <td>0.024580</td>\n      <td>-0.029490</td>\n      <td>0.040770</td>\n      <td>-0.057996</td>\n      <td>-0.012361</td>\n      <td>-0.019814</td>\n      <td>0.007333</td>\n      <td>-0.030823</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>24.659920</td>\n      <td>24.559022</td>\n      <td>24.462891</td>\n      <td>6.972141</td>\n      <td>1.008067</td>\n      <td>1.143318</td>\n      <td>-0.881397</td>\n      <td>-1.797336</td>\n      <td>-1.316414</td>\n      <td>...</td>\n      <td>-0.064038</td>\n      <td>0.044904</td>\n      <td>-0.045340</td>\n      <td>0.042700</td>\n      <td>-0.063328</td>\n      <td>-0.010253</td>\n      <td>-0.004272</td>\n      <td>-0.024278</td>\n      <td>0.001717</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_6beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    69911\nST     21247\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.255941  0.126826  0.086712  0.088051  0.075713 -0.024569   \ndw_2    0.255941  1.000000  0.839774  0.443129  0.156197  0.418729 -0.461763   \ndw_3    0.126826  0.839774  1.000000  0.617379  0.233068  0.346060 -0.532862   \ndw_4    0.086712  0.443129  0.617379  1.000000  0.899451  0.053813 -0.237258   \ndw_5    0.088051  0.156197  0.233068  0.899451  1.000000 -0.086599 -0.014596   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.032264  0.028086  0.046009  0.039039  0.015851 -0.077794  0.050496   \ncfr_13 -0.023128  0.110780  0.046174  0.024440  0.009964  0.068140  0.004871   \ncfr_14 -0.040651 -0.007514 -0.030837 -0.029533 -0.028118  0.011829  0.019891   \ncfr_15 -0.060588 -0.119066 -0.133170 -0.087767 -0.040683 -0.021598  0.089608   \ncfr_16 -0.042833 -0.078764 -0.047183 -0.029773 -0.015438  0.032908 -0.030729   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.012953 -0.001384  0.002394  ... -0.045708 -0.051747 -0.019303   \ndw_2   -0.218036 -0.003468  0.007413  ... -0.141060  0.127367  0.228143   \ndw_3   -0.300954 -0.002069  0.003404  ... -0.206438  0.110265  0.261460   \ndw_4   -0.145344 -0.000228  0.000760  ... -0.142178  0.036774  0.117609   \ndw_5   -0.019561  0.000277 -0.000251  ... -0.064023 -0.004814  0.020295   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.076659 -0.000726  0.004327  ... -0.121386 -0.206635 -0.113087   \ncfr_13  0.004627  0.000306  0.000798  ...  0.120777  0.028507 -0.219328   \ncfr_14  0.024541  0.001952 -0.001142  ...  0.088392  0.207586  0.043674   \ncfr_15  0.046544  0.005107 -0.006644  ...  0.251295  0.160789 -0.072934   \ncfr_16  0.002356  0.007116 -0.004854  ...  0.229052  0.144069  0.166645   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.008486 -0.000878 -0.032264 -0.023128 -0.040651 -0.060588 -0.042833  \ndw_2    0.164508  0.044436  0.028086  0.110780 -0.007514 -0.119066 -0.078764  \ndw_3    0.116256 -0.047562  0.046009  0.046174 -0.030837 -0.133170 -0.047183  \ndw_4    0.038427 -0.043639  0.039039  0.024440 -0.029533 -0.087767 -0.029773  \ndw_5    0.008379 -0.014492  0.015851  0.009964 -0.028118 -0.040683 -0.015438  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.008140  0.053560  1.000000 -0.006207 -0.033331 -0.303526 -0.194998  \ncfr_13 -0.269074 -0.065839 -0.006207  1.000000  0.164767  0.075217 -0.175495  \ncfr_14 -0.179302 -0.289882 -0.033331  0.164767  1.000000  0.131088 -0.151555  \ncfr_15 -0.151000 -0.104688 -0.303526  0.075217  0.131088  1.000000  0.190121  \ncfr_16  0.094130 -0.009039 -0.194998 -0.175495 -0.151555  0.190121  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.255941</td>\n      <td>0.126826</td>\n      <td>0.086712</td>\n      <td>0.088051</td>\n      <td>0.075713</td>\n      <td>-0.024569</td>\n      <td>0.012953</td>\n      <td>-0.001384</td>\n      <td>0.002394</td>\n      <td>...</td>\n      <td>-0.045708</td>\n      <td>-0.051747</td>\n      <td>-0.019303</td>\n      <td>-0.008486</td>\n      <td>-0.000878</td>\n      <td>-0.032264</td>\n      <td>-0.023128</td>\n      <td>-0.040651</td>\n      <td>-0.060588</td>\n      <td>-0.042833</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.255941</td>\n      <td>1.000000</td>\n      <td>0.839774</td>\n      <td>0.443129</td>\n      <td>0.156197</td>\n      <td>0.418729</td>\n      <td>-0.461763</td>\n      <td>-0.218036</td>\n      <td>-0.003468</td>\n      <td>0.007413</td>\n      <td>...</td>\n      <td>-0.141060</td>\n      <td>0.127367</td>\n      <td>0.228143</td>\n      <td>0.164508</td>\n      <td>0.044436</td>\n      <td>0.028086</td>\n      <td>0.110780</td>\n      <td>-0.007514</td>\n      <td>-0.119066</td>\n      <td>-0.078764</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.126826</td>\n      <td>0.839774</td>\n      <td>1.000000</td>\n      <td>0.617379</td>\n      <td>0.233068</td>\n      <td>0.346060</td>\n      <td>-0.532862</td>\n      <td>-0.300954</td>\n      <td>-0.002069</td>\n      <td>0.003404</td>\n      <td>...</td>\n      <td>-0.206438</td>\n      <td>0.110265</td>\n      <td>0.261460</td>\n      <td>0.116256</td>\n      <td>-0.047562</td>\n      <td>0.046009</td>\n      <td>0.046174</td>\n      <td>-0.030837</td>\n      <td>-0.133170</td>\n      <td>-0.047183</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.086712</td>\n      <td>0.443129</td>\n      <td>0.617379</td>\n      <td>1.000000</td>\n      <td>0.899451</td>\n      <td>0.053813</td>\n      <td>-0.237258</td>\n      <td>-0.145344</td>\n      <td>-0.000228</td>\n      <td>0.000760</td>\n      <td>...</td>\n      <td>-0.142178</td>\n      <td>0.036774</td>\n      <td>0.117609</td>\n      <td>0.038427</td>\n      <td>-0.043639</td>\n      <td>0.039039</td>\n      <td>0.024440</td>\n      <td>-0.029533</td>\n      <td>-0.087767</td>\n      <td>-0.029773</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.088051</td>\n      <td>0.156197</td>\n      <td>0.233068</td>\n      <td>0.899451</td>\n      <td>1.000000</td>\n      <td>-0.086599</td>\n      <td>-0.014596</td>\n      <td>-0.019561</td>\n      <td>0.000277</td>\n      <td>-0.000251</td>\n      <td>...</td>\n      <td>-0.064023</td>\n      <td>-0.004814</td>\n      <td>0.020295</td>\n      <td>0.008379</td>\n      <td>-0.014492</td>\n      <td>0.015851</td>\n      <td>0.009964</td>\n      <td>-0.028118</td>\n      <td>-0.040683</td>\n      <td>-0.015438</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.032264</td>\n      <td>0.028086</td>\n      <td>0.046009</td>\n      <td>0.039039</td>\n      <td>0.015851</td>\n      <td>-0.077794</td>\n      <td>0.050496</td>\n      <td>0.076659</td>\n      <td>-0.000726</td>\n      <td>0.004327</td>\n      <td>...</td>\n      <td>-0.121386</td>\n      <td>-0.206635</td>\n      <td>-0.113087</td>\n      <td>0.008140</td>\n      <td>0.053560</td>\n      <td>1.000000</td>\n      <td>-0.006207</td>\n      <td>-0.033331</td>\n      <td>-0.303526</td>\n      <td>-0.194998</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.023128</td>\n      <td>0.110780</td>\n      <td>0.046174</td>\n      <td>0.024440</td>\n      <td>0.009964</td>\n      <td>0.068140</td>\n      <td>0.004871</td>\n      <td>0.004627</td>\n      <td>0.000306</td>\n      <td>0.000798</td>\n      <td>...</td>\n      <td>0.120777</td>\n      <td>0.028507</td>\n      <td>-0.219328</td>\n      <td>-0.269074</td>\n      <td>-0.065839</td>\n      <td>-0.006207</td>\n      <td>1.000000</td>\n      <td>0.164767</td>\n      <td>0.075217</td>\n      <td>-0.175495</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.040651</td>\n      <td>-0.007514</td>\n      <td>-0.030837</td>\n      <td>-0.029533</td>\n      <td>-0.028118</td>\n      <td>0.011829</td>\n      <td>0.019891</td>\n      <td>0.024541</td>\n      <td>0.001952</td>\n      <td>-0.001142</td>\n      <td>...</td>\n      <td>0.088392</td>\n      <td>0.207586</td>\n      <td>0.043674</td>\n      <td>-0.179302</td>\n      <td>-0.289882</td>\n      <td>-0.033331</td>\n      <td>0.164767</td>\n      <td>1.000000</td>\n      <td>0.131088</td>\n      <td>-0.151555</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.060588</td>\n      <td>-0.119066</td>\n      <td>-0.133170</td>\n      <td>-0.087767</td>\n      <td>-0.040683</td>\n      <td>-0.021598</td>\n      <td>0.089608</td>\n      <td>0.046544</td>\n      <td>0.005107</td>\n      <td>-0.006644</td>\n      <td>...</td>\n      <td>0.251295</td>\n      <td>0.160789</td>\n      <td>-0.072934</td>\n      <td>-0.151000</td>\n      <td>-0.104688</td>\n      <td>-0.303526</td>\n      <td>0.075217</td>\n      <td>0.131088</td>\n      <td>1.000000</td>\n      <td>0.190121</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.042833</td>\n      <td>-0.078764</td>\n      <td>-0.047183</td>\n      <td>-0.029773</td>\n      <td>-0.015438</td>\n      <td>0.032908</td>\n      <td>-0.030729</td>\n      <td>0.002356</td>\n      <td>0.007116</td>\n      <td>-0.004854</td>\n      <td>...</td>\n      <td>0.229052</td>\n      <td>0.144069</td>\n      <td>0.166645</td>\n      <td>0.094130</td>\n      <td>-0.009039</td>\n      <td>-0.194998</td>\n      <td>-0.175495</td>\n      <td>-0.151555</td>\n      <td>0.190121</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_246', 'fft_214', 'fft_149', 'fft_157', 'fft_211', 'fft_248', 'fft_226', 'fft_197', 'fft_139', 'fft_161', 'fft_225', 'fft_220', 'fft_171', 'mfw_14', 'fft_209', 'fft_176', 'fft_223', 'mfw_7', 'fft_240', 'fft_251', 'fft_254', 'fft_141', 'fft_198', 'fft_234', 'mfw_6', 'mfw_15', 'fft_219', 'fft_135', 'fft_168', 'fft_192', 'fft_137', 'fft_201', 'fft_131', 'fft_148', 'fft_202', 'fft_166', 'fft_217', 'fft_153', 'fft_183', 'fft_177', 'fft_145', 'fft_155', 'fft_190', 'fft_238', 'fft_175', 'fft_244', 'fft_221', 'fft_210', 'fft_163', 'mfw_11', 'fft_193', 'mfw_5', 'fft_182', 'fft_134', 'fft_191', 'fft_162', 'fft_250', 'fft_150', 'fft_233', 'fft_185', 'fft_136', 'fft_235', 'fft_167', 'fft_237', 'fft_143', 'fft_133', 'fft_159', 'fft_195', 'fft_213', 'fft_204', 'mfw_9', 'fft_189', 'fft_160', 'fft_165', 'fft_206', 'fft_151', 'fft_186', 'fft_174', 'fft_156', 'fft_152', 'cfr_16', 'fft_172', 'fft_187', 'mfw_12', 'fft_140', 'fft_164', 'fft_184', 'mfw_13', 'fft_255', 'fft_179', 'fft_199', 'fft_188', 'fft_216', 'mfw_8', 'fft_227', 'fft_130', 'fft_147', 'fft_180', 'fft_144', 'fft_232', 'fft_170', 'fft_256', 'fft_194', 'mfw_10', 'fft_169', 'mfw_16', 'fft_222', 'fft_236', 'fft_218', 'fft_231', 'fft_253', 'fft_207', 'fft_200', 'fft_205', 'fft_229', 'fft_203', 'fft_138', 'fft_142', 'fft_178', 'fft_132', 'fft_146', 'fft_249', 'fft_212', 'fft_241', 'fft_154', 'fft_215', 'fft_243', 'fft_173', 'fft_252', 'fft_224', 'fft_158', 'fft_181', 'fft_196', 'fft_228', 'fft_239', 'fft_242', 'fft_208', 'fft_230', 'fft_247', 'fft_245'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_24\n",
      "fft_25\n",
      "fft_27\n",
      "fft_28\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "fft_37\n",
      "fft_38\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 76\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\n0  21.861233  21.421103  21.536569  6.108208  0.880920  1.079942 -0.914392   \n1  26.408089  27.988299  27.611772  7.776970  1.129695  1.195165 -0.806390   \n2  25.977641  26.935251  26.561891  7.477219  1.098311  1.176663 -0.849446   \n3  25.189643  25.649484  25.620624  7.261496  1.066191  1.162694 -0.825414   \n4  24.659920  24.559022  24.462891  6.972141  1.008067  1.143318 -0.881397   \n\n      mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -1.844370 -1.138702 -0.004752  ...  0.006001  0.061446 -0.068189  0.053454   \n1 -1.774080 -1.792590  0.205786  ...  0.027369  0.028651 -0.031130  0.017521   \n2 -1.805917 -1.623971 -0.321053  ...  0.008456  0.040828 -0.025147  0.006059   \n3 -1.684836 -1.477246  3.056053  ...  0.029771  0.026605 -0.040045  0.024580   \n4 -1.797336 -1.316414  6.265323  ... -0.010154  0.059279 -0.064038  0.044904   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.067161  0.067961 -0.093129  0.027961 -0.038417 -0.011442  \n1 -0.014034  0.023165 -0.043346 -0.016159 -0.012820 -0.007157  \n2 -0.022267  0.043209 -0.061407 -0.003576 -0.026326  0.004760  \n3 -0.029490  0.040770 -0.057996 -0.012361 -0.019814  0.007333  \n4 -0.045340  0.042700 -0.063328 -0.010253 -0.004272 -0.024278  \n\n[5 rows x 76 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21.861233</td>\n      <td>21.421103</td>\n      <td>21.536569</td>\n      <td>6.108208</td>\n      <td>0.880920</td>\n      <td>1.079942</td>\n      <td>-0.914392</td>\n      <td>-1.844370</td>\n      <td>-1.138702</td>\n      <td>-0.004752</td>\n      <td>...</td>\n      <td>0.006001</td>\n      <td>0.061446</td>\n      <td>-0.068189</td>\n      <td>0.053454</td>\n      <td>-0.067161</td>\n      <td>0.067961</td>\n      <td>-0.093129</td>\n      <td>0.027961</td>\n      <td>-0.038417</td>\n      <td>-0.011442</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26.408089</td>\n      <td>27.988299</td>\n      <td>27.611772</td>\n      <td>7.776970</td>\n      <td>1.129695</td>\n      <td>1.195165</td>\n      <td>-0.806390</td>\n      <td>-1.774080</td>\n      <td>-1.792590</td>\n      <td>0.205786</td>\n      <td>...</td>\n      <td>0.027369</td>\n      <td>0.028651</td>\n      <td>-0.031130</td>\n      <td>0.017521</td>\n      <td>-0.014034</td>\n      <td>0.023165</td>\n      <td>-0.043346</td>\n      <td>-0.016159</td>\n      <td>-0.012820</td>\n      <td>-0.007157</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25.977641</td>\n      <td>26.935251</td>\n      <td>26.561891</td>\n      <td>7.477219</td>\n      <td>1.098311</td>\n      <td>1.176663</td>\n      <td>-0.849446</td>\n      <td>-1.805917</td>\n      <td>-1.623971</td>\n      <td>-0.321053</td>\n      <td>...</td>\n      <td>0.008456</td>\n      <td>0.040828</td>\n      <td>-0.025147</td>\n      <td>0.006059</td>\n      <td>-0.022267</td>\n      <td>0.043209</td>\n      <td>-0.061407</td>\n      <td>-0.003576</td>\n      <td>-0.026326</td>\n      <td>0.004760</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>25.189643</td>\n      <td>25.649484</td>\n      <td>25.620624</td>\n      <td>7.261496</td>\n      <td>1.066191</td>\n      <td>1.162694</td>\n      <td>-0.825414</td>\n      <td>-1.684836</td>\n      <td>-1.477246</td>\n      <td>3.056053</td>\n      <td>...</td>\n      <td>0.029771</td>\n      <td>0.026605</td>\n      <td>-0.040045</td>\n      <td>0.024580</td>\n      <td>-0.029490</td>\n      <td>0.040770</td>\n      <td>-0.057996</td>\n      <td>-0.012361</td>\n      <td>-0.019814</td>\n      <td>0.007333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24.659920</td>\n      <td>24.559022</td>\n      <td>24.462891</td>\n      <td>6.972141</td>\n      <td>1.008067</td>\n      <td>1.143318</td>\n      <td>-0.881397</td>\n      <td>-1.797336</td>\n      <td>-1.316414</td>\n      <td>6.265323</td>\n      <td>...</td>\n      <td>-0.010154</td>\n      <td>0.059279</td>\n      <td>-0.064038</td>\n      <td>0.044904</td>\n      <td>-0.045340</td>\n      <td>0.042700</td>\n      <td>-0.063328</td>\n      <td>-0.010253</td>\n      <td>-0.004272</td>\n      <td>-0.024278</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 76 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 23.70699977874756 s\n",
      "Accuracy 0.9268319438350153 precision 0.9268004465991043 specificity 0.8053797511318868 recall 0.9268319438350153 f1 0.9240477662443661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 22.99999976158142 s\n",
      "Accuracy 0.9277643703378675 precision 0.9276818617233508 specificity 0.8016571820969276 recall 0.9277643703378675 f1 0.9249235269869188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 23.20599913597107 s\n",
      "Accuracy 0.9274901272487933 precision 0.9272879544691521 specificity 0.806546570252536 recall 0.9274901272487933 f1 0.9247990849464844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 23.082998514175415 s\n",
      "Accuracy 0.928258007898201 precision 0.9279662475609368 specificity 0.8056672361596452 recall 0.928258007898201 f1 0.9255894530053526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 21.76200008392334 s\n",
      "Accuracy 0.9305068012286091 precision 0.930726880940693 specificity 0.8119901498442738 recall 0.9305068012286091 f1 0.9278851160083686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 21.689001083374023 s\n",
      "Accuracy 0.9272158841597192 precision 0.9265556898528535 specificity 0.8098944785665361 recall 0.9272158841597192 f1 0.9247578976164875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 21.734997272491455 s\n",
      "Accuracy 0.9226634488810882 precision 0.9225150033366729 specificity 0.7976292679584777 recall 0.9226634488810882 f1 0.9196296917437806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 22.06599998474121 s\n",
      "Accuracy 0.9279837648091268 precision 0.9274245150863359 specificity 0.8045365563533452 recall 0.9279837648091268 f1 0.925371961835257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 21.912998914718628 s\n",
      "Accuracy 0.9280934620447565 precision 0.9278210593853683 specificity 0.8096581690220662 recall 0.9280934620447565 f1 0.9255119307625096\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 21.991000175476074 s\n",
      "Accuracy 0.9315489249670909 precision 0.9310255014362671 specificity 0.8188791968350538 recall 0.9315489249670909 f1 0.9293328890653849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 21.98099994659424 s\n",
      "Accuracy 0.9287516454585344 precision 0.9283870134816845 specificity 0.8072910823976376 recall 0.9287516454585344 f1 0.926156052137361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 21.812997817993164 s\n",
      "Accuracy 0.9269964896884598 precision 0.9265099168573113 specificity 0.8053619814277143 recall 0.9269964896884598 f1 0.9243591315482288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 21.462000131607056 s\n",
      "Accuracy 0.9291355857832383 precision 0.9287681070680084 specificity 0.8132116570486724 recall 0.9291355857832383 f1 0.9266897246713871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 21.567997455596924 s\n",
      "Accuracy 0.9301228609039052 precision 0.9298941912309661 specificity 0.8112065947795686 recall 0.9301228609039052 f1 0.9276041683013567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 21.536001443862915 s\n",
      "Accuracy 0.9255704256252743 precision 0.925324999980353 specificity 0.7987649088515696 recall 0.9255704256252743 f1 0.922658400638132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 21.618998765945435 s\n",
      "Accuracy 0.9288064940763493 precision 0.9286776328413249 specificity 0.8010561582182563 recall 0.9288064940763493 f1 0.9259883889372248\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 21.035995721817017 s\n",
      "Accuracy 0.9291904344010531 precision 0.9286174814759537 specificity 0.8081065723403632 recall 0.9291904344010531 f1 0.9266951534289773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 21.483999729156494 s\n",
      "Accuracy 0.9252413339183853 precision 0.924877364893865 specificity 0.8058217094165292 recall 0.9252413339183853 f1 0.9225395958794438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 21.69200086593628 s\n",
      "Accuracy 0.9278192189556823 precision 0.9276174174645435 specificity 0.8096100004812579 recall 0.9278192189556823 f1 0.925209095330322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 21.53599977493286 s\n",
      "Accuracy 0.9286967968407196 precision 0.9285847620550834 specificity 0.8022154102003132 recall 0.9286967968407196 f1 0.9258991123649577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 21.62499976158142 s\n",
      "Accuracy 0.9296292233435718 precision 0.929535286248045 specificity 0.8043255907588819 recall 0.9296292233435718 f1 0.926897464033821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 21.56399941444397 s\n",
      "Accuracy 0.9261737604212373 precision 0.9254993490229049 specificity 0.8019527853245263 recall 0.9261737604212373 f1 0.9235014077327899\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 21.4399995803833 s\n",
      "Accuracy 0.9233216322948662 precision 0.9230014713949092 specificity 0.7905910591160997 recall 0.9233216322948662 f1 0.9201694002537827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 21.600997924804688 s\n",
      "Accuracy 0.9258446687143485 precision 0.9253223871824501 specificity 0.8023715966077716 recall 0.9258446687143485 f1 0.923121183135763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 21.7020001411438 s\n",
      "Accuracy 0.9308907415533129 precision 0.9304639205106694 specificity 0.818427172417362 recall 0.9308907415533129 f1 0.9286184936445527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 21.94400143623352 s\n",
      "Accuracy 0.9288064940763493 precision 0.9285020417309772 specificity 0.8082770044348209 recall 0.9288064940763493 f1 0.9262161048654844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 21.92600131034851 s\n",
      "Accuracy 0.9261737604212373 precision 0.9259138934633601 specificity 0.8023615772518014 recall 0.9261737604212373 f1 0.9233699990388637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 21.291998386383057 s\n",
      "Accuracy 0.9265577007459412 precision 0.9261992078190705 specificity 0.8067727040111147 recall 0.9265577007459412 f1 0.923903476031307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 21.29099941253662 s\n",
      "Accuracy 0.9263931548924967 precision 0.9263747056258196 specificity 0.8046915679706507 recall 0.9263931548924967 f1 0.9235791912484851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 21.573001623153687 s\n",
      "Accuracy 0.9258995173321632 precision 0.9254665495162991 specificity 0.8088415919105961 recall 0.9258995173321632 f1 0.9233093412845356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 21.057998418807983 s\n",
      "Accuracy 0.925954365949978 precision 0.9254455102905697 specificity 0.8055123368980724 recall 0.925954365949978 f1 0.9233077404162675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 21.614256620407104 s\n",
      "Accuracy 0.9255704256252743 precision 0.9257435132854649 specificity 0.7988113352674981 recall 0.9255704256252743 f1 0.9225372835941196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 21.770798683166504 s\n",
      "Accuracy 0.9260092145677928 precision 0.9260203869483469 specificity 0.8001196755937202 recall 0.9260092145677928 f1 0.9230642354131945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 21.740798234939575 s\n",
      "Accuracy 0.9290258885476086 precision 0.9288581846739561 specificity 0.808368729676025 recall 0.9290258885476086 f1 0.9263994017263881\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 21.88480043411255 s\n",
      "Accuracy 0.9281483106625713 precision 0.9278239172909634 specificity 0.8110297493589833 recall 0.9281483106625713 f1 0.9256176392065892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 21.63079261779785 s\n",
      "Accuracy 0.9251864853005705 precision 0.9248240931042236 specificity 0.8063616659756105 recall 0.9251864853005705 f1 0.9224968775873696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 21.807798624038696 s\n",
      "Accuracy 0.9261737604212373 precision 0.9258371777720082 specificity 0.8046920116785654 recall 0.9261737604212373 f1 0.9234528963447175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 21.17177700996399 s\n",
      "Accuracy 0.9251864853005705 precision 0.9254726996479601 specificity 0.7959712294512509 recall 0.9251864853005705 f1 0.9220416751022269\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 21.408786296844482 s\n",
      "Accuracy 0.9245831505046073 precision 0.9241334107877558 specificity 0.7961842828229326 recall 0.9245831505046073 f1 0.9216491146795183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 21.953803777694702 s\n",
      "Accuracy 0.9263383062746818 precision 0.925860080254253 specificity 0.8051059555857638 recall 0.9263383062746818 f1 0.9236784515046336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 21.632792949676514 s\n",
      "Accuracy 0.9288613426941641 precision 0.9286494979854214 specificity 0.8045748864004619 recall 0.9288613426941641 f1 0.926154249991336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 21.411784648895264 s\n",
      "Accuracy 0.9284225537516455 precision 0.9283567277283884 specificity 0.8152723535216092 recall 0.9284225537516455 f1 0.9259184987519953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 21.823798418045044 s\n",
      "Accuracy 0.9266673979815708 precision 0.9262221329717906 specificity 0.8052493627106808 recall 0.9266673979815708 f1 0.9240064512813333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 21.6977961063385 s\n",
      "Accuracy 0.9274901272487933 precision 0.9270157439961275 specificity 0.8080104886268098 recall 0.9274901272487933 f1 0.9249236890566754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 21.60979413986206 s\n",
      "Accuracy 0.9269964896884598 precision 0.92674540359039 specificity 0.80873678163592 recall 0.9269964896884598 f1 0.924364684047518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 21.604790687561035 s\n",
      "Accuracy 0.9274352786309785 precision 0.9270756551722031 specificity 0.8069180113593675 recall 0.9274352786309785 f1 0.9248023329882854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 21.704795837402344 s\n",
      "Accuracy 0.9289161913119789 precision 0.9286885843277478 specificity 0.8103232998294135 recall 0.9289161913119789 f1 0.9263525124513516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 21.72379732131958 s\n",
      "Accuracy 0.9251316366827556 precision 0.9244665775218595 specificity 0.8022637754247862 recall 0.9251316366827556 f1 0.9224421848483761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 21.861802101135254 s\n",
      "Accuracy 0.9274901272487933 precision 0.9268378351615371 specificity 0.8081371532361894 recall 0.9274901272487933 f1 0.924990922372594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 21.62679433822632 s\n",
      "Accuracy 0.927928916191312 precision 0.9273709590752368 specificity 0.8078234734046716 recall 0.927928916191312 f1 0.9253959667079652\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 21.593793869018555 s\n",
      "Accuracy 0.9268867924528302 precision 0.9264821559684597 specificity 0.805990271773276 recall 0.9268867924528302 f1 0.9242349516648628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 21.77079701423645 s\n",
      "Accuracy 0.9283677051338306 precision 0.9281475999829472 specificity 0.805832984113761 recall 0.9283677051338306 f1 0.925682926902394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 21.94780468940735 s\n",
      "Accuracy 0.9287516454585344 precision 0.928620028260217 specificity 0.8064622441913566 recall 0.9287516454585344 f1 0.926063047267742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 21.656794786453247 s\n",
      "Accuracy 0.9303971039929794 precision 0.930288622055144 specificity 0.8178709076384724 recall 0.9303971039929794 f1 0.9280014066031914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 21.67879557609558 s\n",
      "Accuracy 0.9261737604212373 precision 0.9261317373844703 specificity 0.802502686592811 recall 0.9261737604212373 f1 0.9233075066612392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 21.904801845550537 s\n",
      "Accuracy 0.9331395348837209 precision 0.9331099825798123 specificity 0.8115355521039725 recall 0.9331395348837209 f1 0.9306312797488221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 21.528791427612305 s\n",
      "Accuracy 0.9307810443176832 precision 0.9303020761754163 specificity 0.8088514067091769 recall 0.9307810443176832 f1 0.9283031147422083\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 21.855801343917847 s\n",
      "Accuracy 0.9264480035103115 precision 0.9260120684805309 specificity 0.8033377107754027 recall 0.9264480035103115 f1 0.9237317194726125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 21.686798334121704 s\n",
      "Accuracy 0.9313843791136464 precision 0.9313526048183164 specificity 0.8129094910496806 recall 0.9313843791136464 f1 0.9288711297882912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 21.72979497909546 s\n",
      "Accuracy 0.9278740675734971 precision 0.9280902076669071 specificity 0.80847776381234 recall 0.9278740675734971 f1 0.9251174611005053\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 21.913803577423096 s\n",
      "Accuracy 0.9295195261079421 precision 0.9292146029874131 specificity 0.8091913511592896 recall 0.9295195261079421 f1 0.9269654911611954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 21.50878882408142 s\n",
      "Accuracy 0.9275449758666081 precision 0.9270148223205732 specificity 0.8082888370629461 recall 0.9275449758666081 f1 0.9250059590920741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 21.64179301261902 s\n",
      "Accuracy 0.9261189118034225 precision 0.9258646121595929 specificity 0.8016131260660772 recall 0.9261189118034225 f1 0.9232934635164397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 21.771798133850098 s\n",
      "Accuracy 0.9273255813953488 precision 0.9269483351373642 specificity 0.8026261393389491 recall 0.9273255813953488 f1 0.9245905997749133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 21.460787534713745 s\n",
      "Accuracy 0.9264480035103115 precision 0.9264842800047348 specificity 0.8026564599742909 recall 0.9264480035103115 f1 0.9235688008097935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 21.709797382354736 s\n",
      "Accuracy 0.9260640631856077 precision 0.9260480883713422 specificity 0.8056313204922099 recall 0.9260640631856077 f1 0.9232661748886468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 21.738797664642334 s\n",
      "Accuracy 0.9296292233435718 precision 0.9290617701968444 specificity 0.8135442411772235 recall 0.9296292233435718 f1 0.9272701309046896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 21.727798223495483 s\n",
      "Accuracy 0.9286419482229048 precision 0.9279318248101743 specificity 0.8103676558778157 recall 0.9286419482229048 f1 0.9262419242833126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 21.76479721069336 s\n",
      "Accuracy 0.9260640631856077 precision 0.9260132462568381 specificity 0.8023655591907356 recall 0.9260640631856077 f1 0.9231946375946037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 21.972806215286255 s\n",
      "Accuracy 0.9280934620447565 precision 0.9277338697098382 specificity 0.8112262903122195 recall 0.9280934620447565 f1 0.925578040034524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 21.610793590545654 s\n",
      "Accuracy 0.9267770952172005 precision 0.9262390785206492 specificity 0.8061369492919417 recall 0.9267770952172005 f1 0.9241725897148043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 21.701794624328613 s\n",
      "Accuracy 0.9263383062746818 precision 0.9259682865415456 specificity 0.7993740183727385 recall 0.9263383062746818 f1 0.9234984095635118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 21.75979781150818 s\n",
      "Accuracy 0.9273255813953488 precision 0.9275904108250069 specificity 0.8053634755937319 recall 0.9273255813953488 f1 0.9244689119032989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 21.68279504776001 s\n",
      "Accuracy 0.9312198332602019 precision 0.9308587040423634 specificity 0.8154022611953445 recall 0.9312198332602019 f1 0.9288620109086503\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 21.8538019657135 s\n",
      "Accuracy 0.9273804300131636 precision 0.9268141742931997 specificity 0.8079026234594673 recall 0.9273804300131636 f1 0.9248416160253118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 21.798800468444824 s\n",
      "Accuracy 0.9301777095217201 precision 0.9302204525278288 specificity 0.8124118730861287 recall 0.9301777095217201 f1 0.9276077568909313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 21.44178533554077 s\n",
      "Accuracy 0.9265577007459412 precision 0.9266068246623996 specificity 0.8046507219906146 recall 0.9265577007459412 f1 0.9237267109253984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 21.726796865463257 s\n",
      "Accuracy 0.9267222465993857 precision 0.926488442188637 specificity 0.8060877045045702 recall 0.9267222465993857 f1 0.9240143410760079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 21.47775959968567 s\n",
      "Accuracy 0.9263383062746818 precision 0.9260887748909244 specificity 0.8051077327485862 recall 0.9263383062746818 f1 0.9236033156089899\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 21.340559005737305 s\n",
      "Accuracy 0.9295195261079421 precision 0.9294566078216373 specificity 0.8079031999939813 recall 0.9295195261079421 f1 0.9268609158629539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 21.53856897354126 s\n",
      "Accuracy 0.9289710399297938 precision 0.9287846444552665 specificity 0.8071709111332489 recall 0.9289710399297938 f1 0.9263205750873875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 21.77057123184204 s\n",
      "Accuracy 0.9255155770074595 precision 0.9252771156669617 specificity 0.8041724732523537 recall 0.9255155770074595 f1 0.9227371782679236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 21.708570957183838 s\n",
      "Accuracy 0.9288613426941641 precision 0.9286171043262945 specificity 0.812273945172931 recall 0.9288613426941641 f1 0.9263482439571794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 21.80357313156128 s\n",
      "Accuracy 0.9297937691970163 precision 0.9292517362711055 specificity 0.8114376090104095 recall 0.9297937691970163 f1 0.9273787397046265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 21.436563730239868 s\n",
      "Accuracy 0.9282031592803861 precision 0.9276752336607732 specificity 0.8034406285814597 recall 0.9282031592803861 f1 0.9255581685799701\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 21.55756688117981 s\n",
      "Accuracy 0.9300680122860904 precision 0.9297703434355081 specificity 0.8105177895658136 recall 0.9300680122860904 f1 0.9275539389036689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 21.470564365386963 s\n",
      "Accuracy 0.9279837648091268 precision 0.9278089939412915 specificity 0.8038927314313413 recall 0.9279837648091268 f1 0.9252298956227446\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 21.67857074737549 s\n",
      "Accuracy 0.9254058797718298 precision 0.9252143621583229 specificity 0.7997655555546792 recall 0.9254058797718298 f1 0.9224989995566516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 22.036579132080078 s\n",
      "Accuracy 0.9274901272487933 precision 0.9271036691874653 specificity 0.8065847941142041 recall 0.9274901272487933 f1 0.9248589702653297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 22.055577993392944 s\n",
      "Accuracy 0.9263383062746818 precision 0.9259919892910169 specificity 0.8071161330712789 recall 0.9263383062746818 f1 0.9236843751120427\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 21.631568908691406 s\n",
      "Accuracy 0.9271061869240895 precision 0.9266042254791962 specificity 0.8105477098891818 recall 0.9271061869240895 f1 0.9246044384461021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 22.051580905914307 s\n",
      "Accuracy 0.9294646774901273 precision 0.9289369263667676 specificity 0.8065849197317716 recall 0.9294646774901273 f1 0.9269225476632998\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 21.697569131851196 s\n",
      "Accuracy 0.9296292233435718 precision 0.9291374284202677 specificity 0.8126012710459304 recall 0.9296292233435718 f1 0.9272206728151137\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 21.26655888557434 s\n",
      "Accuracy 0.9323168056164984 precision 0.9319753659475561 specificity 0.8190843830537481 recall 0.9323168056164984 f1 0.9300562158952574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 21.771573781967163 s\n",
      "Accuracy 0.9326458973233874 precision 0.9322203978980109 specificity 0.806894758516349 recall 0.9326458973233874 f1 0.9301456881314168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 22.145581007003784 s\n",
      "Accuracy 0.926941641070645 precision 0.9263525600672708 specificity 0.806383780204204 recall 0.926941641070645 f1 0.9243648477095135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 21.832574129104614 s\n",
      "Accuracy 0.9274352786309785 precision 0.9269706685203765 specificity 0.8061498588662093 recall 0.9274352786309785 f1 0.9248186910982199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 21.57656741142273 s\n",
      "Accuracy 0.9273804300131636 precision 0.9270933124184159 specificity 0.8026838869245815 recall 0.9273804300131636 f1 0.9246189476061892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 21.854573011398315 s\n",
      "Accuracy 0.9277643703378675 precision 0.9276368218609047 specificity 0.8051785779329195 recall 0.9277643703378675 f1 0.9250228764032242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 21.711571216583252 s\n",
      "Accuracy 0.9295195261079421 precision 0.9291228038615313 specificity 0.809794996461705 recall 0.9295195261079421 f1 0.9270098601927693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 21.84757351875305 s\n",
      "Accuracy 0.9277643703378675 precision 0.9276692274572473 specificity 0.8107193785267767 recall 0.9277643703378675 f1 0.9251477058918792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 21.79557180404663 s\n",
      "Accuracy 0.9293001316366828 precision 0.9291969649718959 specificity 0.8113292840636889 recall 0.9293001316366828 f1 0.9267298873420639\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 21.655569553375244 s\n",
      "Accuracy 0.9273255813953488 precision 0.9272909687406845 specificity 0.8068111172193168 recall 0.9273255813953488 f1 0.9245874775112205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 21.659565687179565 s\n",
      "Accuracy 0.9297389205792014 precision 0.9296952879643195 specificity 0.8107995274408397 recall 0.9297389205792014 f1 0.9271473498907845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 21.378562211990356 s\n",
      "Accuracy 0.9248573935936815 precision 0.9240917901122385 specificity 0.7997882936659952 recall 0.9248573935936815 f1 0.9221363575071367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 21.793572425842285 s\n",
      "Accuracy 0.9283677051338306 precision 0.92779071060044 specificity 0.8106748882857409 recall 0.9283677051338306 f1 0.9259195603554176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 21.52856683731079 s\n",
      "Accuracy 0.925351031154015 precision 0.925055962025482 specificity 0.7985211026191058 recall 0.925351031154015 f1 0.9224436146947934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 21.399561166763306 s\n",
      "Accuracy 0.9281483106625713 precision 0.9277745243031882 specificity 0.8056688330849382 recall 0.9281483106625713 f1 0.9255040789341828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 21.67656970024109 s\n",
      "Accuracy 0.9242540587977183 precision 0.9243976078667003 specificity 0.7950587501830959 recall 0.9242540587977183 f1 0.9211029976331194\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 22.22958517074585 s\n",
      "Accuracy 0.9262286090390522 precision 0.9258357183456091 specificity 0.8007947961109897 recall 0.9262286090390522 f1 0.9234295467575688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 21.50156331062317 s\n",
      "Accuracy 0.9271610355419043 precision 0.9269700822726614 specificity 0.8086343915957968 recall 0.9271610355419043 f1 0.9245111264725994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 21.961578130722046 s\n",
      "Accuracy 0.9280386134269416 precision 0.9276689950414345 specificity 0.8104991440066026 recall 0.9280386134269416 f1 0.9255079013388564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 21.608567476272583 s\n",
      "Accuracy 0.9294646774901273 precision 0.9293728862253041 specificity 0.8078250075266202 recall 0.9294646774901273 f1 0.9268115672832222\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 21.8115713596344 s\n",
      "Accuracy 0.9291904344010531 precision 0.9290944866370943 specificity 0.8079266369129093 recall 0.9291904344010531 f1 0.9265352653390398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 21.823573350906372 s\n",
      "Accuracy 0.9290258885476086 precision 0.9285714401903481 specificity 0.8105412800133945 recall 0.9290258885476086 f1 0.9265437929805383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 21.547565460205078 s\n",
      "Accuracy 0.9263931548924967 precision 0.9263943669895298 specificity 0.7990084138022964 recall 0.9263931548924967 f1 0.9234316825346027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 21.543565034866333 s\n",
      "Accuracy 0.9261737604212373 precision 0.9259875270707774 specificity 0.8043273871443117 recall 0.9261737604212373 f1 0.9233963101330627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 21.768571615219116 s\n",
      "Accuracy 0.9283128565160158 precision 0.9277215228088819 specificity 0.8136664133887415 recall 0.9283128565160158 f1 0.9259414004102776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 21.8705735206604 s\n",
      "Accuracy 0.9278740675734971 precision 0.9277058181073956 specificity 0.8052953014471764 recall 0.9278740675734971 f1 0.9251500069507016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 21.66057014465332 s\n",
      "Accuracy 0.9319877139096094 precision 0.9316282661479409 specificity 0.8174094611491208 recall 0.9319877139096094 f1 0.9296893805665281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 21.618568420410156 s\n",
      "Accuracy 0.9257898200965335 precision 0.9251205533207951 specificity 0.8046164113013359 recall 0.9257898200965335 f1 0.9231753390437203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 21.781572580337524 s\n",
      "Accuracy 0.9250767880649408 precision 0.9246884821706575 specificity 0.8018577363430542 recall 0.9250767880649408 f1 0.9222789214678839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 21.853575468063354 s\n",
      "Accuracy 0.9283677051338306 precision 0.9284930687674741 specificity 0.8029784788725626 recall 0.9283677051338306 f1 0.9255131240427897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 21.440564393997192 s\n",
      "Accuracy 0.9296840719613866 precision 0.9293461076192476 specificity 0.8120105198982268 recall 0.9296840719613866 f1 0.9272105083626039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 21.433563232421875 s\n",
      "Accuracy 0.9258446687143485 precision 0.9255258877388806 specificity 0.8011228206304827 recall 0.9258446687143485 f1 0.9230215223186301\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 21.5115647315979 s\n",
      "Accuracy 0.9238152698551997 precision 0.9236088867497056 specificity 0.7987352325397721 recall 0.9238152698551997 f1 0.9208525157556807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 21.419416427612305 s\n",
      "Accuracy 0.9268867924528302 precision 0.9269705669396991 specificity 0.8029294632474676 recall 0.9268867924528302 f1 0.9240102917770386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 21.694405794143677 s\n",
      "Accuracy 0.9249122422114963 precision 0.9246872709881391 specificity 0.7967123505551428 recall 0.9249122422114963 f1 0.9219267716561266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 21.817410230636597 s\n",
      "Accuracy 0.9271061869240895 precision 0.9269625500403114 specificity 0.8060450423186097 recall 0.9271061869240895 f1 0.924377215792192\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 21.706408262252808 s\n",
      "Accuracy 0.9294098288723124 precision 0.9293951010147861 specificity 0.8047154512694039 recall 0.9294098288723124 f1 0.926659374415505\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 21.392400979995728 s\n",
      "Accuracy 0.9272158841597192 precision 0.927152581795917 specificity 0.8064969034631669 recall 0.9272158841597192 f1 0.9244762703501421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 21.364399194717407 s\n",
      "Accuracy 0.9277643703378675 precision 0.9275330464084617 specificity 0.80715442342835 recall 0.9277643703378675 f1 0.9251027242907999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 21.98041272163391 s\n",
      "Accuracy 0.9243089074155332 precision 0.9241293517477064 specificity 0.7944544649099197 recall 0.9243089074155332 f1 0.921237396707122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 21.592405080795288 s\n",
      "Accuracy 0.925680122860904 precision 0.9253078173263468 specificity 0.8023163870249391 recall 0.925680122860904 f1 0.9229010785027773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 21.412402391433716 s\n",
      "Accuracy 0.9294646774901273 precision 0.9293515160924862 specificity 0.8124077181594719 recall 0.9294646774901273 f1 0.9269260116646397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 21.71240782737732 s\n",
      "Accuracy 0.927928916191312 precision 0.9277268057052633 specificity 0.8062509312279879 recall 0.927928916191312 f1 0.9252395917167684\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 21.379401922225952 s\n",
      "Accuracy 0.9255704256252743 precision 0.9251737986336092 specificity 0.8057071113807853 recall 0.9255704256252743 f1 0.922882941808246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 21.39740228652954 s\n",
      "Accuracy 0.9308907415533129 precision 0.9307167448716358 specificity 0.8088463310154408 recall 0.9308907415533129 f1 0.9283161782980659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 22.094414710998535 s\n",
      "Accuracy 0.9265028521281263 precision 0.9260883189775704 specificity 0.7987246463021563 recall 0.9265028521281263 f1 0.923664958275217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 21.260401964187622 s\n",
      "Accuracy 0.9279837648091268 precision 0.9279352164503955 specificity 0.8044120552595244 recall 0.9279837648091268 f1 0.9252048850966592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 21.807408094406128 s\n",
      "Accuracy 0.9277095217200526 precision 0.9273380114565082 specificity 0.8082620861502823 recall 0.9277095217200526 f1 0.9251187676851331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 21.603400707244873 s\n",
      "Accuracy 0.927270732777534 precision 0.9267120222054726 specificity 0.8064739222873201 recall 0.927270732777534 f1 0.9246917778904182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 21.83841061592102 s\n",
      "Accuracy 0.9269964896884598 precision 0.9263645098993836 specificity 0.8038793163644158 recall 0.9269964896884598 f1 0.9243740864212644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 21.372400999069214 s\n",
      "Accuracy 0.9271610355419043 precision 0.926867476969171 specificity 0.7990287360028654 recall 0.9271610355419043 f1 0.9243064029058243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 21.61440634727478 s\n",
      "Accuracy 0.9293549802544976 precision 0.9292985810131729 specificity 0.808258342500915 recall 0.9293549802544976 f1 0.9266994430920928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 21.470404386520386 s\n",
      "Accuracy 0.9287516454585344 precision 0.9284462622616036 specificity 0.8094893253283063 recall 0.9287516454585344 f1 0.9261894711089366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 21.668405294418335 s\n",
      "Accuracy 0.9278192189556823 precision 0.9272002546929339 specificity 0.8097380805528237 recall 0.9278192189556823 f1 0.9253532652060871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 21.165398359298706 s\n",
      "Accuracy 0.9283677051338306 precision 0.9277975015116544 specificity 0.8103430546347089 recall 0.9283677051338306 f1 0.9259090469595602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 21.61240577697754 s\n",
      "Accuracy 0.9264480035103115 precision 0.9261693108373534 specificity 0.8019415075535284 recall 0.9264480035103115 f1 0.9236454712534679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 21.713406562805176 s\n",
      "Accuracy 0.9280934620447565 precision 0.9280523741243898 specificity 0.8069712055992913 recall 0.9280934620447565 f1 0.9253767154293732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 21.607405185699463 s\n",
      "Accuracy 0.9272158841597192 precision 0.9267676057410388 specificity 0.8009411153244032 recall 0.9272158841597192 f1 0.9244604660808768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 21.936411142349243 s\n",
      "Accuracy 0.926941641070645 precision 0.9264580165573928 specificity 0.8024374546209427 recall 0.926941641070645 f1 0.9242294819624532\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 21.798410177230835 s\n",
      "Accuracy 0.9322071083808688 precision 0.932060338424006 specificity 0.8182282690611563 recall 0.9322071083808688 f1 0.9298638476710298\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 21.78040838241577 s\n",
      "Accuracy 0.9265577007459412 precision 0.9264028627108795 specificity 0.8005434999401652 recall 0.9265577007459412 f1 0.9236843024719668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 21.934410572052002 s\n",
      "Accuracy 0.9298486178148311 precision 0.9296576095877475 specificity 0.8118495806275535 recall 0.9298486178148311 f1 0.9273278828620166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 22.519423961639404 s\n",
      "Accuracy 0.9280386134269416 precision 0.9278338504324005 specificity 0.8089485141879957 recall 0.9280386134269416 f1 0.9254176620161136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 21.77440881729126 s\n",
      "Accuracy 0.9278192189556823 precision 0.9277130828390789 specificity 0.8064925468850105 recall 0.9278192189556823 f1 0.9251044238658924\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 21.55240535736084 s\n",
      "Accuracy 0.9266673979815708 precision 0.9267462494539755 specificity 0.8066278413230014 recall 0.9266673979815708 f1 0.9238791828537087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 21.714409112930298 s\n",
      "Accuracy 0.928258007898201 precision 0.9275865404841159 specificity 0.8069279845278509 recall 0.928258007898201 f1 0.9257516185421535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 21.384401559829712 s\n",
      "Accuracy 0.9284225537516455 precision 0.9280873050865217 specificity 0.8019350778388257 recall 0.9284225537516455 f1 0.9256810336426006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 21.493402004241943 s\n",
      "Accuracy 0.9258995173321632 precision 0.925466563120825 specificity 0.803287149364102 recall 0.9258995173321632 f1 0.9231696763383896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 21.743410110473633 s\n",
      "Accuracy 0.9295195261079421 precision 0.9291665827713214 specificity 0.8082825052921534 recall 0.9295195261079421 f1 0.9269595476221166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 21.284398794174194 s\n",
      "Accuracy 0.9261737604212373 precision 0.9259404889460701 specificity 0.8020933164026544 recall 0.9261737604212373 f1 0.9233549450102254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 21.836411952972412 s\n",
      "Accuracy 0.9274352786309785 precision 0.9270440257729134 specificity 0.8053863614626615 recall 0.9274352786309785 f1 0.9247751903002375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 21.54040503501892 s\n",
      "Accuracy 0.9283128565160158 precision 0.9282513422771488 specificity 0.8053792072708481 recall 0.9283128565160158 f1 0.9255681839464406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 21.342400550842285 s\n",
      "Accuracy 0.9301777095217201 precision 0.9293964760269215 specificity 0.8167130707136271 recall 0.9301777095217201 f1 0.9279876138054549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 21.797409057617188 s\n",
      "Accuracy 0.9293549802544976 precision 0.9293085278999695 specificity 0.8087637790615859 recall 0.9293549802544976 f1 0.9267085039056125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 21.513405561447144 s\n",
      "Accuracy 0.9268867924528302 precision 0.9268440680768143 specificity 0.8034734417656965 recall 0.9268867924528302 f1 0.9240599252480335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 22.029414415359497 s\n",
      "Accuracy 0.9273255813953488 precision 0.926626379468035 specificity 0.8039309982407522 recall 0.9273255813953488 f1 0.9247364684113172\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 21.674407243728638 s\n",
      "Accuracy 0.9305068012286091 precision 0.930345554629175 specificity 0.8141185535127435 recall 0.9305068012286091 f1 0.9280424619064498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 21.676406860351562 s\n",
      "Accuracy 0.9267222465993857 precision 0.9266111644763451 specificity 0.8065925435154606 recall 0.9267222465993857 f1 0.9239892951641732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 21.418400526046753 s\n",
      "Accuracy 0.9262286090390522 precision 0.9262413641607682 specificity 0.8004392766233056 recall 0.9262286090390522 f1 0.9232960062484838\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 21.328409910202026 s\n",
      "Accuracy 0.9306713470820536 precision 0.9302287448056378 specificity 0.8159936203462179 recall 0.9306713470820536 f1 0.9283444834866589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 21.72140383720398 s\n",
      "Accuracy 0.9298486178148311 precision 0.9296562760327886 specificity 0.8125611915691867 recall 0.9298486178148311 f1 0.9273449500433782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 21.692408084869385 s\n",
      "Accuracy 0.9301228609039052 precision 0.9298812930235063 specificity 0.8073819515407635 recall 0.9301228609039052 f1 0.9275186958823911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 21.716407537460327 s\n",
      "Accuracy 0.9306164984642387 precision 0.9301350767536491 specificity 0.8123596385952612 recall 0.9306164984642387 f1 0.92821776376218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 21.568406105041504 s\n",
      "Accuracy 0.9255704256252743 precision 0.9252910907468472 specificity 0.8039900409422693 recall 0.9255704256252743 f1 0.922801412762829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 21.95741105079651 s\n",
      "Accuracy 0.926612549363756 precision 0.9261759818919889 specificity 0.8025693092013095 recall 0.926612549363756 f1 0.9238807086762886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 21.815409183502197 s\n",
      "Accuracy 0.9293001316366828 precision 0.9286891631825472 specificity 0.808020678755889 recall 0.9293001316366828 f1 0.9268189175375775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 21.551405668258667 s\n",
      "Accuracy 0.9270513383062747 precision 0.9268366650050006 specificity 0.8039160343325348 recall 0.9270513383062747 f1 0.9242905322240152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 22.047412395477295 s\n",
      "Accuracy 0.9274901272487933 precision 0.9268090693675854 specificity 0.8060982341387163 recall 0.9274901272487933 f1 0.924951356720902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 21.84641146659851 s\n",
      "Accuracy 0.9258446687143485 precision 0.925831484876997 specificity 0.8047072574548246 recall 0.9258446687143485 f1 0.9230184689812533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 21.62640690803528 s\n",
      "Accuracy 0.9263931548924967 precision 0.9260667068681475 specificity 0.8075781624142346 recall 0.9263931548924967 f1 0.9237452976993856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 21.657411575317383 s\n",
      "Accuracy 0.9306164984642387 precision 0.9305660051006399 specificity 0.8131225630969676 recall 0.9306164984642387 f1 0.9280983279345274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 21.50939917564392 s\n",
      "Accuracy 0.9285322509872751 precision 0.9282676950033895 specificity 0.8051695041269359 recall 0.9285322509872751 f1 0.9258488303715354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 21.830410480499268 s\n",
      "Accuracy 0.9269964896884598 precision 0.9265530638006061 specificity 0.8067281025800138 recall 0.9269964896884598 f1 0.9243781607196321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 21.689407110214233 s\n",
      "Accuracy 0.9274352786309785 precision 0.9268940752105251 specificity 0.80730734138702 recall 0.9274352786309785 f1 0.9248739072963146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 21.60340428352356 s\n",
      "Accuracy 0.92858709960509 precision 0.9280969111041945 specificity 0.804758910295665 recall 0.92858709960509 f1 0.9259692993525243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 21.596401929855347 s\n",
      "Accuracy 0.9266673979815708 precision 0.9264631883274009 specificity 0.8072533578806744 recall 0.9266673979815708 f1 0.9239780374488846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 21.731409072875977 s\n",
      "Accuracy 0.9300680122860904 precision 0.9296715977356219 specificity 0.8107356310510221 recall 0.9300680122860904 f1 0.9275913894289616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 21.630404233932495 s\n",
      "Accuracy 0.9317683194383501 precision 0.931529874574702 specificity 0.8183107790671786 recall 0.9317683194383501 f1 0.9294471277097979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 21.722405672073364 s\n",
      "Accuracy 0.9293549802544976 precision 0.9290420549355011 specificity 0.816175531027147 recall 0.9293549802544976 f1 0.9269651498723082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 21.748409271240234 s\n",
      "Accuracy 0.9280386134269416 precision 0.9278872951639079 specificity 0.807693643496663 recall 0.9280386134269416 f1 0.9253709611650613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 21.674403429031372 s\n",
      "Accuracy 0.9283128565160158 precision 0.9278938903135296 specificity 0.8063747961961524 recall 0.9283128565160158 f1 0.9257041861891057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 21.902412176132202 s\n",
      "Accuracy 0.9295195261079421 precision 0.929053604869341 specificity 0.8084925245539127 recall 0.9295195261079421 f1 0.9270024391488337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 21.360400676727295 s\n",
      "Accuracy 0.9295195261079421 precision 0.929074160856919 specificity 0.8109629648766532 recall 0.9295195261079421 f1 0.9270539830558182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 21.912413358688354 s\n",
      "Accuracy 0.9282031592803861 precision 0.9280833762314008 specificity 0.806850451176168 recall 0.9282031592803861 f1 0.9255089752852093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 21.85440969467163 s\n",
      "Accuracy 0.9284225537516455 precision 0.9281154912436443 specificity 0.8086815588355939 recall 0.9284225537516455 f1 0.9258350152654933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 21.456403493881226 s\n",
      "Accuracy 0.9235958753839403 precision 0.9232094746723059 specificity 0.799179774080089 recall 0.9235958753839403 f1 0.9206975828921964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 21.49140763282776 s\n",
      "Accuracy 0.9272158841597192 precision 0.9267458965375351 specificity 0.8049648223031576 recall 0.9272158841597192 f1 0.9245674607982294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 21.798408269882202 s\n",
      "Accuracy 0.9264480035103115 precision 0.9257069863687399 specificity 0.8068898245506521 recall 0.9264480035103115 f1 0.9239315269847265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 21.561404705047607 s\n",
      "Accuracy 0.9273255813953488 precision 0.9271452997776723 specificity 0.8060736648837703 recall 0.9273255813953488 f1 0.9246129041492265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 21.532405138015747 s\n",
      "Accuracy 0.9271061869240895 precision 0.9274374908921937 specificity 0.7992353338410252 recall 0.9271061869240895 f1 0.9240761450941032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 21.79040837287903 s\n",
      "Accuracy 0.9273804300131636 precision 0.9270893333306135 specificity 0.8070430968103985 recall 0.9273804300131636 f1 0.9247272605943149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 21.7244074344635 s\n",
      "Accuracy 0.9261189118034225 precision 0.9256081873880591 specificity 0.8067749124707504 recall 0.9261189118034225 f1 0.9235078819595683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 21.682406187057495 s\n",
      "Accuracy 0.9279837648091268 precision 0.927683175322227 specificity 0.806280712002779 recall 0.9279837648091268 f1 0.9253272288063537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 21.545403480529785 s\n",
      "Accuracy 0.9263383062746818 precision 0.9261504708638644 specificity 0.8011200074084494 recall 0.9263383062746818 f1 0.9234845869288706\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 21.849411010742188 s\n",
      "Accuracy 0.9257349714787187 precision 0.9254913803033961 specificity 0.7996021432558703 recall 0.9257349714787187 f1 0.922847207608208\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 21.782410621643066 s\n",
      "Accuracy 0.9302874067573497 precision 0.9300047297990921 specificity 0.8107488502252134 recall 0.9302874067573497 f1 0.9277783559338224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 21.886410236358643 s\n",
      "Accuracy 0.9261189118034225 precision 0.9256935988933883 specificity 0.8045783237970064 recall 0.9261189118034225 f1 0.92342342802061\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 21.744407892227173 s\n",
      "Accuracy 0.9257349714787187 precision 0.9253095961301941 specificity 0.7985963528412031 recall 0.9257349714787187 f1 0.9228803264235608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 21.676408052444458 s\n",
      "Accuracy 0.9296292233435718 precision 0.9296023917401541 specificity 0.808612953572968 recall 0.9296292233435718 f1 0.9269791450820032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 21.688406705856323 s\n",
      "Accuracy 0.924692847740237 precision 0.9242858387806414 specificity 0.8014951952334944 recall 0.924692847740237 f1 0.9218840291650707\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 21.17639660835266 s\n",
      "Accuracy 0.926612549363756 precision 0.9263508227943732 specificity 0.8079855196001092 recall 0.926612549363756 f1 0.9239582429490618\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 21.562405109405518 s\n",
      "Accuracy 0.9306713470820536 precision 0.9302653929580044 specificity 0.8121459400513797 recall 0.9306713470820536 f1 0.9282428360910445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 21.183398485183716 s\n",
      "Accuracy 0.9242540587977183 precision 0.923829469609012 specificity 0.795930727385069 recall 0.9242540587977183 f1 0.9212976877332785\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 21.98741316795349 s\n",
      "Accuracy 0.9297389205792014 precision 0.9295331865732658 specificity 0.8121457395106894 recall 0.9297389205792014 f1 0.9272275345486262\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 21.613406658172607 s\n",
      "Accuracy 0.9294646774901273 precision 0.9286011727940088 specificity 0.8129635069618155 recall 0.9294646774901273 f1 0.9272067267685878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 21.44240379333496 s\n",
      "Accuracy 0.9275449758666081 precision 0.927446974603533 specificity 0.8039604179643671 recall 0.9275449758666081 f1 0.9247602963124415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 21.660406827926636 s\n",
      "Accuracy 0.9280934620447565 precision 0.9279929326480905 specificity 0.801529934009049 recall 0.9280934620447565 f1 0.9252621953863248\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 21.48732328414917 s\n",
      "Accuracy 0.9293549802544976 precision 0.9294862988706961 specificity 0.8075413132889271 recall 0.9293549802544976 f1 0.9266293424627938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 21.675175189971924 s\n",
      "Accuracy 0.9277095217200526 precision 0.9268132460514992 specificity 0.81215014181443 recall 0.9277095217200526 f1 0.9254133380550184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 21.86417818069458 s\n",
      "Accuracy 0.9300680122860904 precision 0.9297519531873891 specificity 0.8080371656395537 recall 0.9300680122860904 f1 0.9275016832220186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 21.79717493057251 s\n",
      "Accuracy 0.9293549802544976 precision 0.9292014715760819 specificity 0.8033152258104407 recall 0.9293549802544976 f1 0.9266108646892736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 21.132172346115112 s\n",
      "Accuracy 0.9307810443176832 precision 0.930314527068128 specificity 0.8186676465263566 recall 0.9307810443176832 f1 0.928526237171031\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 21.74517512321472 s\n",
      "Accuracy 0.9297937691970163 precision 0.9294485047030436 specificity 0.8076184515028852 recall 0.9297937691970163 f1 0.927221280265933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 21.706174850463867 s\n",
      "Accuracy 0.9297937691970163 precision 0.9296768455256745 specificity 0.8089653450346876 recall 0.9297937691970163 f1 0.9271818349757952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 21.735174417495728 s\n",
      "Accuracy 0.9296292233435718 precision 0.9297013767510282 specificity 0.8094216352569982 recall 0.9296292233435718 f1 0.926970060302889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 21.478174686431885 s\n",
      "Accuracy 0.9295743747257569 precision 0.9294789627178087 specificity 0.8130372562003655 recall 0.9295743747257569 f1 0.9270473088103361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 21.95317554473877 s\n",
      "Accuracy 0.9284774023694603 precision 0.9281952059423696 specificity 0.8071352406065684 recall 0.9284774023694603 f1 0.9258457884349567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 21.632174015045166 s\n",
      "Accuracy 0.925625274243089 precision 0.9253343563800445 specificity 0.8007037764173341 recall 0.925625274243089 f1 0.9227779554093299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 21.535176992416382 s\n",
      "Accuracy 0.927599824484423 precision 0.9271605637205856 specificity 0.8108582771432936 recall 0.927599824484423 f1 0.9250930479579659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 21.96717619895935 s\n",
      "Accuracy 0.9285322509872751 precision 0.9283181043887135 specificity 0.8076755538970802 recall 0.9285322509872751 f1 0.925893394275133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 21.78717565536499 s\n",
      "Accuracy 0.9232667836770513 precision 0.9231229962153852 specificity 0.7920394088384435 recall 0.9232667836770513 f1 0.9200969160604889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 21.845180988311768 s\n",
      "Accuracy 0.9278740675734971 precision 0.9279105631934882 specificity 0.8038682045096438 recall 0.9278740675734971 f1 0.9250551365842086\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 21.8441743850708 s\n",
      "Accuracy 0.9252413339183853 precision 0.9252296305863333 specificity 0.8018691924208217 recall 0.9252413339183853 f1 0.9223307600727498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 21.893177032470703 s\n",
      "Accuracy 0.9249122422114963 precision 0.9244080247943119 specificity 0.8048454797366359 recall 0.9249122422114963 f1 0.9222268079024424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 21.475175619125366 s\n",
      "Accuracy 0.9268867924528302 precision 0.9267680305234862 specificity 0.808547122071628 recall 0.9268867924528302 f1 0.9242075175863487\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 21.553173303604126 s\n",
      "Accuracy 0.9266673979815708 precision 0.9263050198095422 specificity 0.804893489805538 recall 0.9266673979815708 f1 0.923969943502768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 21.96217966079712 s\n",
      "Accuracy 0.9295743747257569 precision 0.9292891731744123 specificity 0.8104364241368169 recall 0.9295743747257569 f1 0.9270445337211437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 21.834174633026123 s\n",
      "Accuracy 0.926283457656867 precision 0.9261142367393371 specificity 0.80175379914616 recall 0.926283457656867 f1 0.9234387340044694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 21.724173307418823 s\n",
      "Accuracy 0.9281483106625713 precision 0.9277593202464407 specificity 0.8056634714541674 recall 0.9281483106625713 f1 0.9255089717850674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 21.67417550086975 s\n",
      "Accuracy 0.9289161913119789 precision 0.9286412196918575 specificity 0.8071869530417819 recall 0.9289161913119789 f1 0.926292562435486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 21.889177560806274 s\n",
      "Accuracy 0.9257349714787187 precision 0.9254717434188481 specificity 0.7955346798857881 recall 0.9257349714787187 f1 0.9227501317673694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 21.486172914505005 s\n",
      "Accuracy 0.9299583150504608 precision 0.9293011014183084 specificity 0.8076349695559244 recall 0.9299583150504608 f1 0.9274988084851449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 21.793176651000977 s\n",
      "Accuracy 0.9245831505046073 precision 0.9245249029758086 specificity 0.7981542870782476 recall 0.9245831505046073 f1 0.9215771512206914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 21.491174459457397 s\n",
      "Accuracy 0.9274352786309785 precision 0.9272564182717599 specificity 0.8058735790202558 recall 0.9274352786309785 f1 0.9247194998053871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 21.40617346763611 s\n",
      "Accuracy 0.9288064940763493 precision 0.9285383695076078 specificity 0.8085659160528214 recall 0.9288064940763493 f1 0.926211434985966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 21.84817886352539 s\n",
      "Accuracy 0.9267770952172005 precision 0.9265150410662213 specificity 0.8079681012467556 recall 0.9267770952172005 f1 0.9241256206829961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 22.100177526474 s\n",
      "Accuracy 0.9228828433523475 precision 0.9225615830440668 specificity 0.7946545698659857 recall 0.9228828433523475 f1 0.9198287793531901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 22.543182134628296 s\n",
      "Accuracy 0.9296840719613866 precision 0.9292823180511596 specificity 0.8173558361637928 recall 0.9296840719613866 f1 0.9273572601908237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 22.01417827606201 s\n",
      "Accuracy 0.9295195261079421 precision 0.9291266614435688 specificity 0.8136009621677857 recall 0.9295195261079421 f1 0.9270984993193626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 23.416189193725586 s\n",
      "Accuracy 0.9297389205792014 precision 0.9295959735062368 specificity 0.8090012391345578 recall 0.9297389205792014 f1 0.9271345042116284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 22.735183238983154 s\n",
      "Accuracy 0.9307261956998684 precision 0.9303401420435669 specificity 0.8096903477351781 recall 0.9307261956998684 f1 0.9282351191470394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 22.176178216934204 s\n",
      "Accuracy 0.9263931548924967 precision 0.9259479301927946 specificity 0.8033787415071769 recall 0.9263931548924967 f1 0.9236799009169492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 21.994178295135498 s\n",
      "Accuracy 0.9283677051338306 precision 0.9280808117667873 specificity 0.8056370441428072 recall 0.9283677051338306 f1 0.9256991673507879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 21.878175497055054 s\n",
      "Accuracy 0.9271061869240895 precision 0.926714897478592 specificity 0.808989271194839 recall 0.9271061869240895 f1 0.9245281627634875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 22.062176942825317 s\n",
      "Accuracy 0.9278740675734971 precision 0.9274209860828905 specificity 0.8085598082746392 recall 0.9278740675734971 f1 0.9253212343590045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 21.818177938461304 s\n",
      "Accuracy 0.9258995173321632 precision 0.9253829081491268 specificity 0.8062773614433071 recall 0.9258995173321632 f1 0.9232738150266763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 21.61617398262024 s\n",
      "Accuracy 0.9261737604212373 precision 0.9259649732365518 specificity 0.8055425037974117 recall 0.9261737604212373 f1 0.9234336138027722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 21.487173080444336 s\n",
      "Accuracy 0.9278740675734971 precision 0.9281375377952922 specificity 0.8046198547603266 recall 0.9278740675734971 f1 0.9250111973878056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 21.539175271987915 s\n",
      "Accuracy 0.9274901272487933 precision 0.927206033076837 specificity 0.8071267837578968 recall 0.9274901272487933 f1 0.9248389569655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 24.76719903945923 s\n",
      "Accuracy 0.924692847740237 precision 0.924581362001002 specificity 0.8001844845708546 recall 0.924692847740237 f1 0.9217571903229167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 23.238189935684204 s\n",
      "Accuracy 0.9281483106625713 precision 0.9279061874187554 specificity 0.8068467759867441 recall 0.9281483106625713 f1 0.9254903578342102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 22.298179149627686 s\n",
      "Accuracy 0.928258007898201 precision 0.9281208204442681 specificity 0.8086373212561303 recall 0.928258007898201 f1 0.9256132470266754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 22.303179025650024 s\n",
      "Accuracy 0.9264480035103115 precision 0.9259103323907512 specificity 0.8068422935266718 recall 0.9264480035103115 f1 0.9238545179610298\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 22.05317711830139 s\n",
      "Accuracy 0.9291904344010531 precision 0.9292020270929618 specificity 0.810890885148474 recall 0.9291904344010531 f1 0.9265742357563319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 22.987186431884766 s\n",
      "Accuracy 0.9295195261079421 precision 0.929089401506236 specificity 0.8102952998756219 recall 0.9295195261079421 f1 0.9270329689669218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 22.308180570602417 s\n",
      "Accuracy 0.9306164984642387 precision 0.9302058834614687 specificity 0.8086906804624187 recall 0.9306164984642387 f1 0.9281080650386239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 21.872175931930542 s\n",
      "Accuracy 0.9264480035103115 precision 0.9261580777491405 specificity 0.8109722123255876 recall 0.9264480035103115 f1 0.9238735106149787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 21.4251708984375 s\n",
      "Accuracy 0.9283128565160158 precision 0.9281101890654282 specificity 0.804060952815011 recall 0.9283128565160158 f1 0.925578692219047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 21.82617497444153 s\n",
      "Accuracy 0.9296840719613866 precision 0.9294063860231614 specificity 0.809015548864103 recall 0.9296840719613866 f1 0.9271205375483788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 21.80917716026306 s\n",
      "Accuracy 0.9261737604212373 precision 0.9259148933615036 specificity 0.8068998902665895 recall 0.9261737604212373 f1 0.9234831486882584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 21.883175134658813 s\n",
      "Accuracy 0.925954365949978 precision 0.9254403921854433 specificity 0.8066243590904499 recall 0.925954365949978 f1 0.9233375315654773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 21.768176555633545 s\n",
      "Accuracy 0.9305068012286091 precision 0.930720052503683 specificity 0.8125331316932227 recall 0.9305068012286091 f1 0.9278994972574769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 21.527174711227417 s\n",
      "Accuracy 0.9291904344010531 precision 0.9290080258274862 specificity 0.8043697567167206 recall 0.9291904344010531 f1 0.9264765803860542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 21.888176918029785 s\n",
      "Accuracy 0.9245831505046073 precision 0.9239123386507453 specificity 0.7978835948456283 recall 0.9245831505046073 f1 0.9217708904693038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 21.790174961090088 s\n",
      "Accuracy 0.9289161913119789 precision 0.9289008982507642 specificity 0.8122786713034785 recall 0.9289161913119789 f1 0.9263352815321505\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 21.44317364692688 s\n",
      "Accuracy 0.9271061869240895 precision 0.9272198976213878 specificity 0.8029282111735196 recall 0.9271061869240895 f1 0.9242260108207776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 21.792174577713013 s\n",
      "Accuracy 0.927599824484423 precision 0.9271750459321311 specificity 0.8087738295212065 recall 0.927599824484423 f1 0.9250372404543289\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 21.521172523498535 s\n",
      "Accuracy 0.9271610355419043 precision 0.9266187609096801 specificity 0.8040672163447445 recall 0.9271610355419043 f1 0.924514404045479\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 21.32417345046997 s\n",
      "Accuracy 0.9280386134269416 precision 0.9275737192575786 specificity 0.8058398142904403 recall 0.9280386134269416 f1 0.9254268587249123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 22.08517837524414 s\n",
      "Accuracy 0.9263383062746818 precision 0.9260608074237305 specificity 0.8022659992862929 recall 0.9263383062746818 f1 0.9235411822364913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 21.57917547225952 s\n",
      "Accuracy 0.925351031154015 precision 0.9253803035883099 specificity 0.8010682586700891 recall 0.925351031154015 f1 0.9224106342577543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 21.748175144195557 s\n",
      "Accuracy 0.9281483106625713 precision 0.9276046884838128 specificity 0.8080529310025286 recall 0.9281483106625713 f1 0.9256201871474546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 21.666175842285156 s\n",
      "Accuracy 0.9288613426941641 precision 0.9283640451510107 specificity 0.8070045571048418 recall 0.9288613426941641 f1 0.9263059851237236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 21.842177391052246 s\n",
      "Accuracy 0.9287516454585344 precision 0.9284830072944628 specificity 0.8090533574072644 recall 0.9287516454585344 f1 0.9261673089694702\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 21.760175466537476 s\n",
      "Accuracy 0.9265028521281263 precision 0.9260855330625624 specificity 0.8030162099881952 recall 0.9265028521281263 f1 0.9237734187407464\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 21.805174350738525 s\n",
      "Accuracy 0.9303422553751646 precision 0.9299088002509519 specificity 0.8150663322564855 recall 0.9303422553751646 f1 0.927984645062246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 21.702176570892334 s\n",
      "Accuracy 0.9281483106625713 precision 0.9276187773329738 specificity 0.8080556817497014 recall 0.9281483106625713 f1 0.9256152460558076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 21.549175262451172 s\n",
      "Accuracy 0.9247476963580518 precision 0.9244841170212086 specificity 0.7995573977429514 recall 0.9247476963580518 f1 0.9218438024461605\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 21.887176752090454 s\n",
      "Accuracy 0.9242540587977183 precision 0.9242599168548873 specificity 0.7995426062745057 recall 0.9242540587977183 f1 0.9212581034775821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 21.798181772232056 s\n",
      "Accuracy 0.9296840719613866 precision 0.929386317200897 specificity 0.8079965677992423 recall 0.9296840719613866 f1 0.9271028828696595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 21.56616997718811 s\n",
      "Accuracy 0.9295195261079421 precision 0.9289863857637594 specificity 0.8100675552328142 recall 0.9295195261079421 f1 0.9270634133355443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 21.78717613220215 s\n",
      "Accuracy 0.9255704256252743 precision 0.9254557307366749 specificity 0.8017886870300939 recall 0.9255704256252743 f1 0.9226950317485935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 21.763175010681152 s\n",
      "Accuracy 0.9277643703378675 precision 0.92773464995415 specificity 0.8042659847594978 recall 0.9277643703378675 f1 0.9249717799385562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 21.407175302505493 s\n",
      "Accuracy 0.9286419482229048 precision 0.9283750716120216 specificity 0.8039869451484344 recall 0.9286419482229048 f1 0.9259331070835712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 21.491172790527344 s\n",
      "Accuracy 0.9282031592803861 precision 0.9277228384957404 specificity 0.8093088580028976 recall 0.9282031592803861 f1 0.9256843399077483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 21.462172031402588 s\n",
      "Accuracy 0.927928916191312 precision 0.9275756290133463 specificity 0.8086553186768146 recall 0.927928916191312 f1 0.9253460248393515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 21.90017604827881 s\n",
      "Accuracy 0.9261737604212373 precision 0.9258976726888972 specificity 0.8023514853370809 recall 0.9261737604212373 f1 0.9233748660295271\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 21.922176837921143 s\n",
      "Accuracy 0.927928916191312 precision 0.9276386610204211 specificity 0.8102691600845755 recall 0.927928916191312 f1 0.9253646963825126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 21.66817283630371 s\n",
      "Accuracy 0.9274352786309785 precision 0.9271866097075336 specificity 0.804031434777763 recall 0.9274352786309785 f1 0.9246959646393912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 21.66517472267151 s\n",
      "Accuracy 0.9268319438350153 precision 0.9262886165903913 specificity 0.8040512594182315 recall 0.9268319438350153 f1 0.924178467862382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 22.090179681777954 s\n",
      "Accuracy 0.9296292233435718 precision 0.9295042663776505 specificity 0.8044291028883037 recall 0.9296292233435718 f1 0.9269091271248513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 21.62517547607422 s\n",
      "Accuracy 0.9271610355419043 precision 0.9267803359652537 specificity 0.8039677413248597 recall 0.9271610355419043 f1 0.9244568305661827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 21.618174076080322 s\n",
      "Accuracy 0.9274901272487933 precision 0.9276570163305542 specificity 0.7995702049811538 recall 0.9274901272487933 f1 0.9245211367830241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 22.248180866241455 s\n",
      "Accuracy 0.9288064940763493 precision 0.9284432032880413 specificity 0.8105450704773833 recall 0.9288064940763493 f1 0.9262895137946985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 22.752183198928833 s\n",
      "Accuracy 0.9265577007459412 precision 0.9259635450926781 specificity 0.805275215513711 recall 0.9265577007459412 f1 0.923947431258852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 23.569189071655273 s\n",
      "Accuracy 0.925625274243089 precision 0.9254923104516594 specificity 0.7979874441882822 recall 0.925625274243089 f1 0.9226602770522792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 21.927175521850586 s\n",
      "Accuracy 0.9291904344010531 precision 0.9286441030315239 specificity 0.8108081684315299 recall 0.9291904344010531 f1 0.9267502197125369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 22.031177043914795 s\n",
      "Accuracy 0.9305616498464239 precision 0.9306532898302168 specificity 0.8126338935254159 recall 0.9305616498464239 f1 0.9279907655861483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 23.614192485809326 s\n",
      "Accuracy 0.928258007898201 precision 0.9278296442346725 specificity 0.809277726807345 recall 0.928258007898201 f1 0.9257216728347206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 22.18817925453186 s\n",
      "Accuracy 0.9252413339183853 precision 0.9250509342638777 specificity 0.8059207045528157 recall 0.9252413339183853 f1 0.9224868091038734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 22.243179321289062 s\n",
      "Accuracy 0.9257349714787187 precision 0.9256090915841221 specificity 0.8020340370152897 recall 0.9257349714787187 f1 0.9228725754369194\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 22.750394344329834 s\n",
      "Accuracy 0.92370557261957 precision 0.9236252102189534 specificity 0.799343825773264 recall 0.92370557261957 f1 0.9207181889484403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 22.17853021621704 s\n",
      "Accuracy 0.9291904344010531 precision 0.9285635584315102 specificity 0.8108105467408779 recall 0.9291904344010531 f1 0.9267798425918617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 21.88254714012146 s\n",
      "Accuracy 0.9269964896884598 precision 0.9263508896913688 specificity 0.8045619583748859 recall 0.9269964896884598 f1 0.9243961542638129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 22.12842845916748 s\n",
      "Accuracy 0.9294098288723124 precision 0.9286938625415496 specificity 0.8123414177494969 recall 0.9294098288723124 f1 0.9270744950568255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 21.767075777053833 s\n",
      "Accuracy 0.9248025449758666 precision 0.9243787165220347 specificity 0.8004757966605489 recall 0.9248025449758666 f1 0.921975393175642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 22.30876588821411 s\n",
      "Accuracy 0.927270732777534 precision 0.9275484945874201 specificity 0.7983971932113424 recall 0.927270732777534 f1 0.9242378598036668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 22.175644397735596 s\n",
      "Accuracy 0.9297389205792014 precision 0.929322564352227 specificity 0.818222108166538 recall 0.9297389205792014 f1 0.9274383214739991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 22.069713354110718 s\n",
      "Accuracy 0.9290807371654234 precision 0.9287236475914019 specificity 0.8120519746369494 recall 0.9290807371654234 f1 0.9266028798450342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 22.406910181045532 s\n",
      "Accuracy 0.9265028521281263 precision 0.9258800174845743 specificity 0.8050249122853789 recall 0.9265028521281263 f1 0.923895677024328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 22.146552085876465 s\n",
      "Accuracy 0.9277643703378675 precision 0.9272703207236601 specificity 0.8095755531806772 recall 0.9277643703378675 f1 0.9252483574816042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 22.04607629776001 s\n",
      "Accuracy 0.9283677051338306 precision 0.9281840348194598 specificity 0.809971921050452 recall 0.9283677051338306 f1 0.9257713297000579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 22.813079833984375 s\n",
      "Accuracy 0.9258995173321632 precision 0.9254331532166811 specificity 0.8002848455959187 recall 0.9258995173321632 f1 0.9231050906298555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 22.25307822227478 s\n",
      "Accuracy 0.9286967968407196 precision 0.9284735903627861 specificity 0.8072066164620463 recall 0.9286967968407196 f1 0.9260528651226928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 22.42307734489441 s\n",
      "Accuracy 0.9299034664326459 precision 0.9296936255062884 specificity 0.8111467937381437 recall 0.9299034664326459 f1 0.927373164421542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 22.696080446243286 s\n",
      "Accuracy 0.9293001316366828 precision 0.9291393330191822 specificity 0.8068044685712134 recall 0.9293001316366828 f1 0.9266400382494978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 22.79559326171875 s\n",
      "Accuracy 0.9284225537516455 precision 0.9280771194140124 specificity 0.8119189675519729 recall 0.9284225537516455 f1 0.9259252944610799\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 22.3365957736969 s\n",
      "Accuracy 0.9277095217200526 precision 0.9273221145161378 specificity 0.8096393987545861 recall 0.9277095217200526 f1 0.9251575977115315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 22.42869734764099 s\n",
      "Accuracy 0.9291904344010531 precision 0.9289338020729307 specificity 0.8070325796768127 recall 0.9291904344010531 f1 0.926563041449617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 22.506109476089478 s\n",
      "Accuracy 0.9306713470820536 precision 0.9302890033650559 specificity 0.8133617631749022 recall 0.9306713470820536 f1 0.928263098412436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 21.804587602615356 s\n",
      "Accuracy 0.9272158841597192 precision 0.9269088097304264 specificity 0.8032726732447077 recall 0.9272158841597192 f1 0.9244717570194917\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 21.74807572364807 s\n",
      "Accuracy 0.9299583150504608 precision 0.9299065593809486 specificity 0.8055657149438987 recall 0.9299583150504608 f1 0.9272507477635958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 21.605075359344482 s\n",
      "Accuracy 0.9273255813953488 precision 0.9269891050879069 specificity 0.8038518512498722 recall 0.9273255813953488 f1 0.9246075147250268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 22.270673751831055 s\n",
      "Accuracy 0.9248025449758666 precision 0.92478844101899 specificity 0.8036426325830207 recall 0.9248025449758666 f1 0.9219288530261874\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 23.085272073745728 s\n",
      "Accuracy 0.9285322509872751 precision 0.9283350622824669 specificity 0.8085177031461083 recall 0.9285322509872751 f1 0.925908374596299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 22.35459280014038 s\n",
      "Accuracy 0.9223343571741992 precision 0.9225616983589497 specificity 0.7926398822160697 recall 0.9223343571741992 f1 0.9190524294725955\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 21.98507523536682 s\n",
      "Accuracy 0.9273804300131636 precision 0.926980723432091 specificity 0.8040050988690035 recall 0.9273804300131636 f1 0.9246880321965062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 21.99207592010498 s\n",
      "Accuracy 0.9284774023694603 precision 0.9279163712310152 specificity 0.8078559883107316 recall 0.9284774023694603 f1 0.9259573133804316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 22.101078271865845 s\n",
      "Accuracy 0.9277095217200526 precision 0.9274252008422648 specificity 0.8088423973260377 recall 0.9277095217200526 f1 0.92510457464922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 21.80207633972168 s\n",
      "Accuracy 0.9261189118034225 precision 0.9260352656149766 specificity 0.8042668740809922 recall 0.9261189118034225 f1 0.9233078869440657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 21.912587881088257 s\n",
      "Accuracy 0.927270732777534 precision 0.9268509368792032 specificity 0.8090224118690674 recall 0.927270732777534 f1 0.9247062317454636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 21.765592336654663 s\n",
      "Accuracy 0.927599824484423 precision 0.9274194318294277 specificity 0.8018025776626023 recall 0.927599824484423 f1 0.9247882591267704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 21.454520225524902 s\n",
      "Accuracy 0.9261189118034225 precision 0.9254645274694 specificity 0.8072227115953652 recall 0.9261189118034225 f1 0.9235712548008982\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 21.419076204299927 s\n",
      "Accuracy 0.9255155770074595 precision 0.9250849615154477 specificity 0.8038903927711554 recall 0.9255155770074595 f1 0.9227924423913032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 22.141156673431396 s\n",
      "Accuracy 0.9265028521281263 precision 0.9263057022208795 specificity 0.804552579314624 recall 0.9265028521281263 f1 0.9237410699844809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 21.945076942443848 s\n",
      "Accuracy 0.9258995173321632 precision 0.9260619138369814 specificity 0.8042771802692673 recall 0.9258995173321632 f1 0.9230141349171795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 21.58007526397705 s\n",
      "Accuracy 0.9300131636682756 precision 0.9297982224583221 specificity 0.8113980670035089 recall 0.9300131636682756 f1 0.9274924951826655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 21.893077611923218 s\n",
      "Accuracy 0.9251316366827556 precision 0.9248577610183774 specificity 0.8015486595427995 recall 0.9251316366827556 f1 0.9222900088647952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 21.827078342437744 s\n",
      "Accuracy 0.9265577007459412 precision 0.9260040247481756 specificity 0.8051784149163329 recall 0.9265577007459412 f1 0.9239304626064628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 22.08507490158081 s\n",
      "Accuracy 0.9305616498464239 precision 0.9303034537704699 specificity 0.8093688532244805 recall 0.9305616498464239 f1 0.9280183347688102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 21.8400776386261 s\n",
      "Accuracy 0.9282031592803861 precision 0.9281388936917333 specificity 0.8079868892467502 recall 0.9282031592803861 f1 0.9255199369042085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 21.542584896087646 s\n",
      "Accuracy 0.9280934620447565 precision 0.9276361337229712 specificity 0.8071582405155528 recall 0.9280934620447565 f1 0.9255123363232723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 22.207078218460083 s\n",
      "Accuracy 0.9248573935936815 precision 0.9244032710530091 specificity 0.8014339281352618 recall 0.9248573935936815 f1 0.9220661956143706\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 21.946580410003662 s\n",
      "Accuracy 0.925625274243089 precision 0.9253184398398 specificity 0.7984344947153561 recall 0.925625274243089 f1 0.9227254484213324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 21.862077236175537 s\n",
      "Accuracy 0.927928916191312 precision 0.927682938609938 specificity 0.8048749563068012 recall 0.927928916191312 f1 0.9252197702691376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 21.896076440811157 s\n",
      "Accuracy 0.9292452830188679 precision 0.9288618563626729 specificity 0.8099989449471645 recall 0.9292452830188679 f1 0.9267305570977297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 21.7610764503479 s\n",
      "Accuracy 0.9279837648091268 precision 0.9274504258220854 specificity 0.8125889633739686 recall 0.9279837648091268 f1 0.9255590996086969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 22.304077863693237 s\n",
      "Accuracy 0.9300131636682756 precision 0.9297919657667864 specificity 0.8095057595955719 recall 0.9300131636682756 f1 0.927450151261416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 22.243587970733643 s\n",
      "Accuracy 0.9271061869240895 precision 0.9268533859287861 specificity 0.8076615223038379 recall 0.9271061869240895 f1 0.9244506237025487\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 22.320078134536743 s\n",
      "Accuracy 0.9276546731022378 precision 0.9273553712562935 specificity 0.8063750289516634 recall 0.9276546731022378 f1 0.9249933047711884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 22.6316077709198 s\n",
      "Accuracy 0.9271061869240895 precision 0.926749406899262 specificity 0.8033969776537946 recall 0.9271061869240895 f1 0.9243788763975589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 22.23507809638977 s\n",
      "Accuracy 0.927599824484423 precision 0.927161695867569 specificity 0.8109129954520392 recall 0.927599824484423 f1 0.925093995009929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 21.636080503463745 s\n",
      "Accuracy 0.9264480035103115 precision 0.9263375574552005 specificity 0.8029579598386862 recall 0.9264480035103115 f1 0.9236190991867268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 22.269079446792603 s\n",
      "Accuracy 0.9274352786309785 precision 0.9273840410725968 specificity 0.8024254823355498 recall 0.9274352786309785 f1 0.9245968386006913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 22.500586986541748 s\n",
      "Accuracy 0.9277095217200526 precision 0.9278835644828659 specificity 0.8072698657715801 recall 0.9277095217200526 f1 0.9249316682324824\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 21.837761163711548 s\n",
      "Accuracy 0.9278192189556823 precision 0.9277966572491272 specificity 0.8073648640722807 recall 0.9278192189556823 f1 0.9251010513449224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 21.658145427703857 s\n",
      "Accuracy 0.9289161913119789 precision 0.9285359214308953 specificity 0.8109044380238767 recall 0.9289161913119789 f1 0.926415544161674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 21.80171251296997 s\n",
      "Accuracy 0.9292452830188679 precision 0.9289343242308533 specificity 0.8121580828033819 recall 0.9292452830188679 f1 0.9267579970958182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 22.349080324172974 s\n",
      "Accuracy 0.9270513383062747 precision 0.9266701540882202 specificity 0.8078209176281516 recall 0.9270513383062747 f1 0.9244401411431723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 22.209588050842285 s\n",
      "Accuracy 0.9260092145677928 precision 0.925399656967041 specificity 0.7996297072570867 recall 0.9260092145677928 f1 0.9232505993208312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 21.9603910446167 s\n",
      "Accuracy 0.9265577007459412 precision 0.926464494410331 specificity 0.7986096278801254 recall 0.9265577007459412 f1 0.9236175442804746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 21.886773824691772 s\n",
      "Accuracy 0.9276546731022378 precision 0.927471814553755 specificity 0.8059185099097036 recall 0.9276546731022378 f1 0.9249457090478387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 22.027084589004517 s\n",
      "Accuracy 0.9241443615620887 precision 0.9238503586234661 specificity 0.7977233942556688 recall 0.9241443615620887 f1 0.9211897778800056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 21.50006937980652 s\n",
      "Accuracy 0.9266673979815708 precision 0.9264468245490001 specificity 0.8064714830750179 recall 0.9266673979815708 f1 0.9239637751141224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 21.716073989868164 s\n",
      "Accuracy 0.9242540587977183 precision 0.9237714570206131 specificity 0.8004006528986213 recall 0.9242540587977183 f1 0.921433484220699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 21.72107696533203 s\n",
      "Accuracy 0.9286419482229048 precision 0.9280306724405176 specificity 0.8094161020765396 recall 0.9286419482229048 f1 0.926181235014058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 22.02458691596985 s\n",
      "Accuracy 0.9279837648091268 precision 0.9277519477846111 specificity 0.8002646701971216 recall 0.9279837648091268 f1 0.925158956591095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 21.636075496673584 s\n",
      "Accuracy 0.925021939447126 precision 0.9252153858935094 specificity 0.7987093395188327 recall 0.925021939447126 f1 0.9219684775499449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 21.543618202209473 s\n",
      "Accuracy 0.9258995173321632 precision 0.9259164517133475 specificity 0.8047916100146625 recall 0.9258995173321632 f1 0.9230678466996695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 22.629108905792236 s\n",
      "Accuracy 0.924363756033348 precision 0.9240242399721666 specificity 0.8002986568371488 recall 0.924363756033348 f1 0.9214951574775041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 21.958586931228638 s\n",
      "Accuracy 0.9316586222027204 precision 0.9317366846900446 specificity 0.8184270816503479 recall 0.9316586222027204 f1 0.9292446573351749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 21.677505016326904 s\n",
      "Accuracy 0.9289161913119789 precision 0.9284116588790636 specificity 0.8075862839218784 recall 0.9289161913119789 f1 0.9263784773794747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 21.828870058059692 s\n",
      "Accuracy 0.9260092145677928 precision 0.9254783695405214 specificity 0.8005534378739109 recall 0.9260092145677928 f1 0.9232461405452551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 21.817073345184326 s\n",
      "Accuracy 0.9255155770074595 precision 0.9257096412657981 specificity 0.8046787098432374 recall 0.9255155770074595 f1 0.9226238617933926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 21.805076360702515 s\n",
      "Accuracy 0.9260640631856077 precision 0.9262948433954262 specificity 0.8058398148322181 recall 0.9260640631856077 f1 0.923202517451801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 22.139076948165894 s\n",
      "Accuracy 0.9276546731022378 precision 0.9273394030914807 specificity 0.804842602252473 recall 0.9276546731022378 f1 0.9249609758504164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 21.869077444076538 s\n",
      "Accuracy 0.9261189118034225 precision 0.9257087997939822 specificity 0.8024318127267357 recall 0.9261189118034225 f1 0.9233644055627328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 22.61609935760498 s\n",
      "Accuracy 0.925954365949978 precision 0.9253511763445181 specificity 0.8010798059971876 recall 0.925954365949978 f1 0.9232291122154146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 22.123554229736328 s\n",
      "Accuracy 0.9251316366827556 precision 0.9247274100776492 specificity 0.7999112623982774 recall 0.9251316366827556 f1 0.9222904133296183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 21.859076261520386 s\n",
      "Accuracy 0.9280386134269416 precision 0.927589696286129 specificity 0.8101547694176039 recall 0.9280386134269416 f1 0.925526292815753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 21.944002628326416 s\n",
      "Accuracy 0.9250767880649408 precision 0.9246195359418501 specificity 0.8022094966296428 recall 0.9250767880649408 f1 0.9223110151254887\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 22.43307900428772 s\n",
      "Accuracy 0.9248573935936815 precision 0.9246233089550921 specificity 0.7991366113848511 recall 0.9248573935936815 f1 0.9219358030026651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 22.395188093185425 s\n",
      "Accuracy 0.9291355857832383 precision 0.9287986397771132 specificity 0.8081288614199349 recall 0.9291355857832383 f1 0.9265588537671678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 22.16207790374756 s\n",
      "Accuracy 0.9303971039929794 precision 0.9301102407606192 specificity 0.8133236164286924 recall 0.9303971039929794 f1 0.927951450188042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 22.456588983535767 s\n",
      "Accuracy 0.9252413339183853 precision 0.9246968643435515 specificity 0.8022993081300288 recall 0.9252413339183853 f1 0.922511386322102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 22.67928433418274 s\n",
      "Accuracy 0.925625274243089 precision 0.9253474389194112 specificity 0.8028198159898506 recall 0.925625274243089 f1 0.922827337986244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 22.522599697113037 s\n",
      "Accuracy 0.9299034664326459 precision 0.9293591388264307 specificity 0.8089938407740983 recall 0.9299034664326459 f1 0.9274336346026255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 22.504671335220337 s\n",
      "Accuracy 0.9285322509872751 precision 0.928123999996592 specificity 0.8092993314954061 recall 0.9285322509872751 f1 0.9259950190522374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 22.22807812690735 s\n",
      "Accuracy 0.9291355857832383 precision 0.9287229620555956 specificity 0.8095184668405484 recall 0.9291355857832383 f1 0.9266170155944442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 21.883075952529907 s\n",
      "Accuracy 0.9291355857832383 precision 0.9287229620555956 specificity 0.8095184668405484 recall 0.9291355857832383 f1 0.9266170155944442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 21.76607847213745 s\n",
      "Accuracy 0.9280386134269416 precision 0.9278193130647869 specificity 0.8089990330809307 recall 0.9280386134269416 f1 0.9254233928903794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 22.041077136993408 s\n",
      "Accuracy 0.9285322509872751 precision 0.9282339123261423 specificity 0.8034880308506994 recall 0.9285322509872751 f1 0.9258189397042329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 21.908074617385864 s\n",
      "Accuracy 0.9249670908293111 precision 0.9247092002098438 specificity 0.8037807291962522 recall 0.9249670908293111 f1 0.9221739570399314\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 22.258070707321167 s\n",
      "Accuracy 0.9295195261079421 precision 0.929450323808256 specificity 0.8092431648208682 recall 0.9295195261079421 f1 0.9268943881018535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 21.826548099517822 s\n",
      "Accuracy 0.9266673979815708 precision 0.9262258651742082 specificity 0.8003771336853434 recall 0.9266673979815708 f1 0.9238836004386893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 21.438031435012817 s\n",
      "Accuracy 0.9287516454585344 precision 0.9284964497395598 specificity 0.8097220154783628 recall 0.9287516454585344 f1 0.9261790473851278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 21.92513918876648 s\n",
      "Accuracy 0.9268867924528302 precision 0.9267192990168315 specificity 0.7965873881919615 recall 0.9268867924528302 f1 0.9239260095893066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 21.997032165527344 s\n",
      "Accuracy 0.9285322509872751 precision 0.9278675214911462 specificity 0.8115539998505065 recall 0.9285322509872751 f1 0.926141345693184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 22.348035097122192 s\n",
      "Accuracy 0.9271061869240895 precision 0.9265996342492224 specificity 0.8076262194557315 recall 0.9271061869240895 f1 0.9245339936945547\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 22.317814111709595 s\n",
      "Accuracy 0.9274901272487933 precision 0.927697360429049 specificity 0.7988395921467593 recall 0.9274901272487933 f1 0.9244921838890663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 21.38103151321411 s\n",
      "Accuracy 0.9236507240017552 precision 0.9232264346564669 specificity 0.7962695491474959 recall 0.9236507240017552 f1 0.9206898102243679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 21.875031232833862 s\n",
      "Accuracy 0.9273255813953488 precision 0.9269928971091761 specificity 0.8032814403612353 recall 0.9273255813953488 f1 0.9245922371351274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 22.08703351020813 s\n",
      "Accuracy 0.9280934620447565 precision 0.9278334806413919 specificity 0.8041613763264515 recall 0.9280934620447565 f1 0.9253748454726893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 22.108997106552124 s\n",
      "Accuracy 0.9280934620447565 precision 0.9277966192604731 specificity 0.8077110578205694 recall 0.9280934620447565 f1 0.9254726446056221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 21.651368141174316 s\n",
      "Accuracy 0.9260640631856077 precision 0.9260930591792749 specificity 0.7970017855087503 recall 0.9260640631856077 f1 0.9230366810767899\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 22.03854513168335 s\n",
      "Accuracy 0.9294646774901273 precision 0.9291953763116003 specificity 0.8107406082278655 recall 0.9294646774901273 f1 0.9269347853006032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 21.887032747268677 s\n",
      "Accuracy 0.926612549363756 precision 0.9262573493028036 specificity 0.804264643789852 recall 0.926612549363756 f1 0.9238959875629372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 22.299033164978027 s\n",
      "Accuracy 0.9280386134269416 precision 0.9277350652035283 specificity 0.807136036070662 recall 0.9280386134269416 f1 0.9254049058966477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 21.963032722473145 s\n",
      "Accuracy 0.9254058797718298 precision 0.9250756495536347 specificity 0.8038160553415783 recall 0.9254058797718298 f1 0.9226455028111901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 21.468032121658325 s\n",
      "Accuracy 0.924363756033348 precision 0.9237825896077715 specificity 0.7970432783452353 recall 0.924363756033348 f1 0.9214924650300488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 22.064944982528687 s\n",
      "Accuracy 0.9274352786309785 precision 0.9273111646772161 specificity 0.8061790828661829 recall 0.9274352786309785 f1 0.924710386291808\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 22.118032932281494 s\n",
      "Accuracy 0.9265028521281263 precision 0.9263001391308631 specificity 0.8050539641343516 recall 0.9265028521281263 f1 0.9237552487605243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 21.65254306793213 s\n",
      "Accuracy 0.9294098288723124 precision 0.9292745363245839 specificity 0.8126062421192147 recall 0.9294098288723124 f1 0.9268814269386817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 22.306033849716187 s\n",
      "Accuracy 0.925351031154015 precision 0.9249759949744887 specificity 0.793232807244848 recall 0.925351031154015 f1 0.9223339256770968\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 21.9180326461792 s\n",
      "Accuracy 0.9260640631856077 precision 0.9260299077128958 specificity 0.7990534432279537 recall 0.9260640631856077 f1 0.9231065818319781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 22.02978229522705 s\n",
      "Accuracy 0.9278192189556823 precision 0.9274476701975032 specificity 0.8072850297516351 recall 0.9278192189556823 f1 0.9252068423653611\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 21.599387884140015 s\n",
      "Accuracy 0.9271061869240895 precision 0.9270399599757538 specificity 0.8050222176050894 recall 0.9271061869240895 f1 0.9243289814081999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 21.699034452438354 s\n",
      "Accuracy 0.927270732777534 precision 0.9271676415159007 specificity 0.8040188840897243 recall 0.927270732777534 f1 0.9244831974313048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 21.879031658172607 s\n",
      "Accuracy 0.9290807371654234 precision 0.9285132307395247 specificity 0.8106640018153207 recall 0.9290807371654234 f1 0.9266425937623078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 21.636032104492188 s\n",
      "Accuracy 0.9273255813953488 precision 0.9267760705408379 specificity 0.803698819495498 recall 0.9273255813953488 f1 0.9246758202575307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 21.54503321647644 s\n",
      "Accuracy 0.9310552874067574 precision 0.9304479061132129 specificity 0.8158612284429977 recall 0.9310552874067574 f1 0.9287919472954931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 22.02903175354004 s\n",
      "Accuracy 0.923376480912681 precision 0.9233654979225375 specificity 0.791236047710866 recall 0.923376480912681 f1 0.9201486357559774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 21.9030339717865 s\n",
      "Accuracy 0.9276546731022378 precision 0.9275102255845441 specificity 0.7997342350636486 recall 0.9276546731022378 f1 0.9247826760625426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 21.95754337310791 s\n",
      "Accuracy 0.9273804300131636 precision 0.9270989126960898 specificity 0.8052520421881024 recall 0.9273804300131636 f1 0.9246802953849742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 21.939520359039307 s\n",
      "Accuracy 0.9244186046511628 precision 0.9240709408923432 specificity 0.7919057461592167 recall 0.9244186046511628 f1 0.9213359775514101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 22.013151168823242 s\n",
      "Accuracy 0.9251316366827556 precision 0.9245989750084471 specificity 0.8023993285932577 recall 0.9251316366827556 f1 0.9223978652371203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 21.791032552719116 s\n",
      "Accuracy 0.9261737604212373 precision 0.9260419063359181 specificity 0.8061384201902413 recall 0.9261737604212373 f1 0.9234249568328424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 21.72803258895874 s\n",
      "Accuracy 0.9290807371654234 precision 0.9284828483751081 specificity 0.806414652562217 recall 0.9290807371654234 f1 0.9265515701944798\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 21.852032899856567 s\n",
      "Accuracy 0.9280934620447565 precision 0.927609925837571 specificity 0.807995044720442 recall 0.9280934620447565 f1 0.9255417097821176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 21.79003381729126 s\n",
      "Accuracy 0.9283128565160158 precision 0.9281368556454563 specificity 0.8053852261196851 recall 0.9283128565160158 f1 0.925602548802708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 22.011033535003662 s\n",
      "Accuracy 0.9297937691970163 precision 0.9292348835695647 specificity 0.8112715171755329 recall 0.9297937691970163 f1 0.9273808910741606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 22.152031421661377 s\n",
      "Accuracy 0.9265028521281263 precision 0.9262096271304476 specificity 0.8037663746489689 recall 0.9265028521281263 f1 0.9237516198142596\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 21.994032859802246 s\n",
      "Accuracy 0.9244734532689777 precision 0.9243893592601397 specificity 0.7956203968103706 recall 0.9244734532689777 f1 0.9214072300513497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 21.81954312324524 s\n",
      "Accuracy 0.9292452830188679 precision 0.9289304774134168 specificity 0.8097303630798139 recall 0.9292452830188679 f1 0.9267016875725874\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 21.85403275489807 s\n",
      "Accuracy 0.9274352786309785 precision 0.9270270864733023 specificity 0.8030942541590648 recall 0.9274352786309785 f1 0.9247244243578526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 22.221644401550293 s\n",
      "Accuracy 0.9284225537516455 precision 0.9280924459729083 specificity 0.8105007600136868 recall 0.9284225537516455 f1 0.9258862253307029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 21.884032011032104 s\n",
      "Accuracy 0.9271061869240895 precision 0.9268200202877843 specificity 0.8053042409067565 recall 0.9271061869240895 f1 0.9244031953284029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 22.280033349990845 s\n",
      "Accuracy 0.92858709960509 precision 0.9279739111152263 specificity 0.8117339251631182 recall 0.92858709960509 f1 0.9261820837135964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 22.771068334579468 s\n",
      "Accuracy 0.9291904344010531 precision 0.9293009667996688 specificity 0.807384991455365 recall 0.9291904344010531 f1 0.9264633491018948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 22.00003218650818 s\n",
      "Accuracy 0.9274901272487933 precision 0.9267750359360046 specificity 0.8120028816742675 recall 0.9274901272487933 f1 0.9251105916554557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 21.51554775238037 s\n",
      "Accuracy 0.9273255813953488 precision 0.9266995833103316 specificity 0.8041294699211177 recall 0.9273255813953488 f1 0.9247140605924484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 21.851033926010132 s\n",
      "Accuracy 0.9257349714787187 precision 0.9252184776405642 specificity 0.8014940370484596 recall 0.9257349714787187 f1 0.9229849287843559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 21.77259659767151 s\n",
      "Accuracy 0.9273804300131636 precision 0.9269382813362751 specificity 0.8055802168643799 recall 0.9273804300131636 f1 0.9247410579252436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 21.95207691192627 s\n",
      "Accuracy 0.9265577007459412 precision 0.9259320782343483 specificity 0.8090037898249917 recall 0.9265577007459412 f1 0.9240522724225732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 21.739030599594116 s\n",
      "Accuracy 0.9284774023694603 precision 0.9281032121143639 specificity 0.808567426147958 recall 0.9284774023694603 f1 0.9259101076163866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 21.986035108566284 s\n",
      "Accuracy 0.927599824484423 precision 0.9272453416278273 specificity 0.8034413964255533 recall 0.927599824484423 f1 0.924883329544663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 21.838030576705933 s\n",
      "Accuracy 0.9309455901711277 precision 0.930578850187344 specificity 0.8101513893787059 recall 0.9309455901711277 f1 0.9284633530065963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 22.005032777786255 s\n",
      "Accuracy 0.925351031154015 precision 0.9247272060564511 specificity 0.8030713752478142 recall 0.925351031154015 f1 0.9226715365105882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 21.758052110671997 s\n",
      "Accuracy 0.9294646774901273 precision 0.9289683598677297 specificity 0.8074496898799521 recall 0.9294646774901273 f1 0.9269321630729276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 21.469061136245728 s\n",
      "Accuracy 0.9274352786309785 precision 0.9273016021689191 specificity 0.801685283428797 recall 0.9274352786309785 f1 0.924603070869752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 21.746030569076538 s\n",
      "Accuracy 0.9277643703378675 precision 0.9276606848179604 specificity 0.8071508768739216 recall 0.9277643703378675 f1 0.9250637271036468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 22.264035940170288 s\n",
      "Accuracy 0.9288064940763493 precision 0.9284365289088742 specificity 0.8057675831256894 recall 0.9288064940763493 f1 0.9261771936525153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 21.992032289505005 s\n",
      "Accuracy 0.9283128565160158 precision 0.9283358151885817 specificity 0.8104049310483651 recall 0.9283128565160158 f1 0.9256647145131872\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 21.699542999267578 s\n",
      "Accuracy 0.9276546731022378 precision 0.9271683112939744 specificity 0.8017086403064151 recall 0.9276546731022378 f1 0.9249408322582802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 21.679659843444824 s\n",
      "Accuracy 0.9249670908293111 precision 0.9242468937975384 specificity 0.7957732202527296 recall 0.9249670908293111 f1 0.9221267291728783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 21.719032526016235 s\n",
      "Accuracy 0.926283457656867 precision 0.9263144612363966 specificity 0.8007474751636371 recall 0.926283457656867 f1 0.9233545510256898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 21.74956727027893 s\n",
      "Accuracy 0.9291904344010531 precision 0.9291737083033987 specificity 0.8077850585008489 recall 0.9291904344010531 f1 0.9265087543753151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 21.730032920837402 s\n",
      "Accuracy 0.9277095217200526 precision 0.927598599729064 specificity 0.803300390609819 recall 0.9277095217200526 f1 0.9249160694339035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 21.914035081863403 s\n",
      "Accuracy 0.92858709960509 precision 0.928601377738913 specificity 0.8020305832568917 recall 0.92858709960509 f1 0.925745694648317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 22.438546180725098 s\n",
      "Accuracy 0.9258995173321632 precision 0.9257020341816417 specificity 0.8048273396267128 recall 0.9258995173321632 f1 0.9231325251228073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 22.247034072875977 s\n",
      "Accuracy 0.926612549363756 precision 0.9260079083691111 specificity 0.8095726510450183 recall 0.926612549363756 f1 0.9241145587511402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 22.273032188415527 s\n",
      "Accuracy 0.9286967968407196 precision 0.9280735313405839 specificity 0.8049816273537375 recall 0.9286967968407196 f1 0.9261341269687493\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 22.36016058921814 s\n",
      "Accuracy 0.9268319438350153 precision 0.9264681883400638 specificity 0.8048147615929719 recall 0.9268319438350153 f1 0.9241363339016213\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 22.420034170150757 s\n",
      "Accuracy 0.9286419482229048 precision 0.9282006737913349 specificity 0.8037454078506912 recall 0.9286419482229048 f1 0.9259841006050237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 22.208032846450806 s\n",
      "Accuracy 0.9261737604212373 precision 0.9261253525269655 specificity 0.8054114311659234 recall 0.9261737604212373 f1 0.9233820271996472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 21.96503520011902 s\n",
      "Accuracy 0.9252413339183853 precision 0.9249808725045461 specificity 0.7988808161225952 recall 0.9252413339183853 f1 0.9223297602275955\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 22.412033319473267 s\n",
      "Accuracy 0.9303422553751646 precision 0.9296398565258963 specificity 0.8146526905219544 recall 0.9303422553751646 f1 0.9280741284243216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 21.835031747817993 s\n",
      "Accuracy 0.9274352786309785 precision 0.9268332790024374 specificity 0.8070664392280313 recall 0.9274352786309785 f1 0.9248898983733086\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 22.47903347015381 s\n",
      "Accuracy 0.9228279947345327 precision 0.9226910608563352 specificity 0.8011444458513449 recall 0.9228279947345327 f1 0.9198869612465108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 22.236032962799072 s\n",
      "Accuracy 0.9242540587977183 precision 0.9240405772637397 specificity 0.7973442161192047 recall 0.9242540587977183 f1 0.9212667655974618\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 22.027564525604248 s\n",
      "Accuracy 0.9301228609039052 precision 0.930047169672359 specificity 0.8077065309696673 recall 0.9301228609039052 f1 0.9274760919629693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 22.08803391456604 s\n",
      "Accuracy 0.9278192189556823 precision 0.9274871899684792 specificity 0.8077449167700085 recall 0.9278192189556823 f1 0.9252050978953698\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 22.18958854675293 s\n",
      "Accuracy 0.9286967968407196 precision 0.9281752277354925 specificity 0.8093273262975668 recall 0.9286967968407196 f1 0.9262025563846333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 22.1740665435791 s\n",
      "Accuracy 0.9294646774901273 precision 0.9292057866394614 specificity 0.8089611945208066 recall 0.9294646774901273 f1 0.9268894345045592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 22.3619441986084 s\n",
      "Accuracy 0.926941641070645 precision 0.9265341108334093 specificity 0.8046479329812748 recall 0.926941641070645 f1 0.9242586258022547\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 21.911139726638794 s\n",
      "Accuracy 0.926941641070645 precision 0.9266923496041477 specificity 0.799376106836377 recall 0.926941641070645 f1 0.9240767403921039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 22.669545888900757 s\n",
      "Accuracy 0.9273255813953488 precision 0.9266646811621878 specificity 0.805777489927015 recall 0.9273255813953488 f1 0.9247679187665149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 21.700491189956665 s\n",
      "Accuracy 0.9245831505046073 precision 0.924313340946307 specificity 0.8007835715295524 recall 0.9245831505046073 f1 0.9217092869666377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 22.193599939346313 s\n",
      "Accuracy 0.9296840719613866 precision 0.9292820509437622 specificity 0.8087716191530655 recall 0.9296840719613866 f1 0.9271552941067095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 21.95103120803833 s\n",
      "Accuracy 0.9251316366827556 precision 0.9251437968922559 specificity 0.7975259831947343 recall 0.9251316366827556 f1 0.9221011629536651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 22.32554340362549 s\n",
      "Accuracy 0.9239798157086442 precision 0.9239007875468181 specificity 0.79674134338429 recall 0.9239798157086442 f1 0.9209301475443361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 22.616542100906372 s\n",
      "Accuracy 0.9249122422114963 precision 0.9247070886418544 specificity 0.8037502201681681 recall 0.9249122422114963 f1 0.9221007587474463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 22.402544736862183 s\n",
      "Accuracy 0.9290258885476086 precision 0.9285651951097058 specificity 0.8088090841191296 recall 0.9290258885476086 f1 0.92650453089663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 22.5520339012146 s\n",
      "Accuracy 0.9252413339183853 precision 0.924824671009127 specificity 0.7998043873399994 recall 0.9252413339183853 f1 0.9224038480382308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 22.290547370910645 s\n",
      "Accuracy 0.9241443615620887 precision 0.9235007743095937 specificity 0.7967257977383606 recall 0.9241443615620887 f1 0.9212823308475202\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 22.26177453994751 s\n",
      "Accuracy 0.9280934620447565 precision 0.9277510341990686 specificity 0.8069675695512468 recall 0.9280934620447565 f1 0.9254693509134108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 22.38803195953369 s\n",
      "Accuracy 0.9296292233435718 precision 0.9294380836375782 specificity 0.8060173661153498 recall 0.9296292233435718 f1 0.9269667374326311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 22.610013008117676 s\n",
      "Accuracy 0.9302874067573497 precision 0.9300221763926921 specificity 0.8124118911092449 recall 0.9302874067573497 f1 0.9278115457693291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 21.920952081680298 s\n",
      "Accuracy 0.9308358929354981 precision 0.9305932848567218 specificity 0.8130180775146543 recall 0.9308358929354981 f1 0.9283776779816373\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 22.074012517929077 s\n",
      "Accuracy 0.9291904344010531 precision 0.9287480915968492 specificity 0.8060709400559368 recall 0.9291904344010531 f1 0.9266006911691453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 21.875013828277588 s\n",
      "Accuracy 0.9266673979815708 precision 0.9263023385309631 specificity 0.8010632637559982 recall 0.9266673979815708 f1 0.9238754179143869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 22.272013664245605 s\n",
      "Accuracy 0.9282031592803861 precision 0.9279127434133603 specificity 0.8054849493731443 recall 0.9282031592803861 f1 0.9255286134176668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 22.43114924430847 s\n",
      "Accuracy 0.9268867924528302 precision 0.9264486945797289 specificity 0.8093036965454335 recall 0.9268867924528302 f1 0.9243281732589443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 22.369524717330933 s\n",
      "Accuracy 0.9278740675734971 precision 0.9278527941170913 specificity 0.8068772359024454 recall 0.9278740675734971 f1 0.9251448100537739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 22.16195797920227 s\n",
      "Accuracy 0.9264480035103115 precision 0.9264049898858994 specificity 0.8021495987310122 recall 0.9264480035103115 f1 0.9235790385479319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 21.681013345718384 s\n",
      "Accuracy 0.9290258885476086 precision 0.9288196564725457 specificity 0.8095830748310728 recall 0.9290258885476086 f1 0.926440119886082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 21.56601309776306 s\n",
      "Accuracy 0.926283457656867 precision 0.9259789283194847 specificity 0.8059601091406504 recall 0.926283457656867 f1 0.923586103050909\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 21.7560133934021 s\n",
      "Accuracy 0.9308358929354981 precision 0.9303314694977196 specificity 0.8099537859473261 recall 0.9308358929354981 f1 0.9283936553300302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 21.526522159576416 s\n",
      "Accuracy 0.9287516454585344 precision 0.9288312170866448 specificity 0.8035394698533748 recall 0.9287516454585344 f1 0.9259318197823442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 21.816537857055664 s\n",
      "Accuracy 0.9297389205792014 precision 0.9291816523580362 specificity 0.8118114591453264 recall 0.9297389205792014 f1 0.9273371692277005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 21.726030588150024 s\n",
      "Accuracy 0.9305616498464239 precision 0.9300041790659108 specificity 0.8144598782852579 recall 0.9305616498464239 f1 0.9282379452132756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 21.917015552520752 s\n",
      "Accuracy 0.9278740675734971 precision 0.9278741009832849 specificity 0.8003304064952466 recall 0.9278740675734971 f1 0.9249792411209956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 22.00801181793213 s\n",
      "Accuracy 0.9271061869240895 precision 0.9271410399373182 specificity 0.8041800605637084 recall 0.9271061869240895 f1 0.9242790165048831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 22.23101282119751 s\n",
      "Accuracy 0.9305068012286091 precision 0.9301608830101014 specificity 0.8145091766266584 recall 0.9305068012286091 f1 0.9281099024118239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 21.69501280784607 s\n",
      "Accuracy 0.9222246599385695 precision 0.9218007811922591 specificity 0.7952436037667625 recall 0.9222246599385695 f1 0.9192055227395637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 22.144012689590454 s\n",
      "Accuracy 0.9266673979815708 precision 0.926558595475904 specificity 0.8095334401591474 recall 0.9266673979815708 f1 0.9240052569782032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 22.32801342010498 s\n",
      "Accuracy 0.9274901272487933 precision 0.9270857466412785 specificity 0.8042551806318848 recall 0.9274901272487933 f1 0.9248077390663091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 21.94703483581543 s\n",
      "Accuracy 0.9277643703378675 precision 0.9272054886173379 specificity 0.8064264108285084 recall 0.9277643703378675 f1 0.9251942397988813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 22.510666608810425 s\n",
      "Accuracy 0.9294098288723124 precision 0.9291898930543151 specificity 0.815233707041261 recall 0.9294098288723124 f1 0.9269691820768335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 21.950014114379883 s\n",
      "Accuracy 0.926283457656867 precision 0.9261563539791792 specificity 0.7997686066737755 recall 0.926283457656867 f1 0.9233762795976989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 21.883012294769287 s\n",
      "Accuracy 0.9287516454585344 precision 0.9284707917420861 specificity 0.8045812432551682 recall 0.9287516454585344 f1 0.9260639045678932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 21.462014198303223 s\n",
      "Accuracy 0.9283128565160158 precision 0.9276703415478837 specificity 0.8052273802095209 recall 0.9283128565160158 f1 0.9257551576548345\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 21.87801241874695 s\n",
      "Accuracy 0.9280934620447565 precision 0.9277240571412246 specificity 0.8078565909651003 recall 0.9280934620447565 f1 0.9254997528352796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 22.28601360321045 s\n",
      "Accuracy 0.927928916191312 precision 0.9278712327132258 specificity 0.8028542906750554 recall 0.927928916191312 f1 0.9251136286515284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 21.781012535095215 s\n",
      "Accuracy 0.9286419482229048 precision 0.9286561755975219 specificity 0.8066095858526873 recall 0.9286419482229048 f1 0.9259118997212807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 22.106013774871826 s\n",
      "Accuracy 0.9290258885476086 precision 0.9291168240495378 specificity 0.8072851582516196 recall 0.9290258885476086 f1 0.9262984087190621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 21.61305594444275 s\n",
      "Accuracy 0.9285322509872751 precision 0.928508808368452 specificity 0.8083548339901476 recall 0.9285322509872751 f1 0.9258526135983856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 22.44214940071106 s\n",
      "Accuracy 0.924363756033348 precision 0.9239153840170418 specificity 0.7982015269069019 recall 0.924363756033348 f1 0.9214767912684131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 22.66401505470276 s\n",
      "Accuracy 0.9274901272487933 precision 0.9272746339525474 specificity 0.8043434330642473 recall 0.9274901272487933 f1 0.9247492865420223\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 22.822930812835693 s\n",
      "Accuracy 0.9269964896884598 precision 0.9266020628543225 specificity 0.8055132572493563 recall 0.9269964896884598 f1 0.9243316468336673\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 21.960176944732666 s\n",
      "Accuracy 0.9282031592803861 precision 0.9275777097126907 specificity 0.8096244734649215 recall 0.9282031592803861 f1 0.9257442184352092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 22.393054246902466 s\n",
      "Accuracy 0.9280386134269416 precision 0.927647457436078 specificity 0.8163903497129624 recall 0.9280386134269416 f1 0.9256571865947976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 21.78401255607605 s\n",
      "Accuracy 0.9255155770074595 precision 0.9255687889473638 specificity 0.7996838995651331 recall 0.9255155770074595 f1 0.9225367921649841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 22.056013822555542 s\n",
      "Accuracy 0.9278192189556823 precision 0.9277004516449865 specificity 0.814409247667747 recall 0.9278192189556823 f1 0.9252996624754789\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 22.295012712478638 s\n",
      "Accuracy 0.9300680122860904 precision 0.9301565811110855 specificity 0.8099217082168775 recall 0.9300680122860904 f1 0.9274250046977868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 22.28703546524048 s\n",
      "Accuracy 0.9257898200965335 precision 0.925628375768521 specificity 0.798219620206305 recall 0.9257898200965335 f1 0.9228429940133317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 21.921013355255127 s\n",
      "Accuracy 0.9291904344010531 precision 0.9289031304111075 specificity 0.8101090623903545 recall 0.9291904344010531 f1 0.9266459066688809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 21.69401264190674 s\n",
      "Accuracy 0.9272158841597192 precision 0.9266145026934204 specificity 0.8062215219102118 recall 0.9272158841597192 f1 0.9246450036534319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 21.630369424819946 s\n",
      "Accuracy 0.9270513383062747 precision 0.9267666647151153 specificity 0.7989582241474633 recall 0.9270513383062747 f1 0.9241896466762809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 21.844013214111328 s\n",
      "Accuracy 0.9322071083808688 precision 0.9320862801444033 specificity 0.8163947347366748 recall 0.9322071083808688 f1 0.9298149811728929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 22.037013292312622 s\n",
      "Accuracy 0.9301777095217201 precision 0.929740622991694 specificity 0.8113269119394418 recall 0.9301777095217201 f1 0.9277308802740979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 21.86201286315918 s\n",
      "Accuracy 0.9317683194383501 precision 0.9314932391687859 specificity 0.8171421192043038 recall 0.9317683194383501 f1 0.9294323584386204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 22.06552267074585 s\n",
      "Accuracy 0.9289161913119789 precision 0.9288964261748273 specificity 0.8087782453124698 recall 0.9289161913119789 f1 0.9262533779282119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 21.747013568878174 s\n",
      "Accuracy 0.9291904344010531 precision 0.928791699666805 specificity 0.8060243447816126 recall 0.9291904344010531 f1 0.926584935218129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 21.95701241493225 s\n",
      "Accuracy 0.926612549363756 precision 0.9262256248151318 specificity 0.8056568781166449 recall 0.926612549363756 f1 0.9239410635290077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 21.979678630828857 s\n",
      "Accuracy 0.9271061869240895 precision 0.9272518246815108 specificity 0.8036274563672876 recall 0.9271061869240895 f1 0.9242344213218598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 22.61152696609497 s\n",
      "Accuracy 0.9263931548924967 precision 0.9262615022691445 specificity 0.8008792559600816 recall 0.9263931548924967 f1 0.9235175548003698\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 22.29001259803772 s\n",
      "Accuracy 0.9295743747257569 precision 0.9293808764138198 specificity 0.8072572218750574 recall 0.9295743747257569 f1 0.9269407687398762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 22.310526609420776 s\n",
      "Accuracy 0.9264480035103115 precision 0.9265507270446219 specificity 0.7990352680196078 recall 0.9264480035103115 f1 0.9234596700163453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 22.23319911956787 s\n",
      "Accuracy 0.9297937691970163 precision 0.9293465074810955 specificity 0.8113224549437232 recall 0.9297937691970163 f1 0.9273427465928439\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 22.752015352249146 s\n",
      "Accuracy 0.9262286090390522 precision 0.9256990665925717 specificity 0.8089991491918741 recall 0.9262286090390522 f1 0.9236820169078425\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 22.479012727737427 s\n",
      "Accuracy 0.9279837648091268 precision 0.9276602705151926 specificity 0.8043965511553199 recall 0.9279837648091268 f1 0.9252887487563839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 22.862043142318726 s\n",
      "Accuracy 0.9277095217200526 precision 0.9274896444564913 specificity 0.8027827858018995 recall 0.9277095217200526 f1 0.9249365047097885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 23.085015058517456 s\n",
      "Accuracy 0.9296840719613866 precision 0.9293084999666228 specificity 0.8108474744646965 recall 0.9296840719613866 f1 0.92719550349551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 22.498512506484985 s\n",
      "Accuracy 0.9282031592803861 precision 0.9276606480563865 specificity 0.8143284008621028 recall 0.9282031592803861 f1 0.9258278529451431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 22.40401530265808 s\n",
      "Accuracy 0.9285322509872751 precision 0.9283047807920913 specificity 0.8085642476904342 recall 0.9285322509872751 f1 0.9259188754147224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 22.927984952926636 s\n",
      "Accuracy 0.9270513383062747 precision 0.9270246656649684 specificity 0.8017446683417827 recall 0.9270513383062747 f1 0.9241805986483118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 22.41604256629944 s\n",
      "Accuracy 0.9251864853005705 precision 0.9247403915638309 specificity 0.8017818712650089 recall 0.9251864853005705 f1 0.9224082477374418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 22.628532648086548 s\n",
      "Accuracy 0.9290258885476086 precision 0.9286222305063653 specificity 0.8080300707845295 recall 0.9290258885476086 f1 0.9264665600029688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 22.38453459739685 s\n",
      "Accuracy 0.9261189118034225 precision 0.9257836955610456 specificity 0.8015611911125294 recall 0.9261189118034225 f1 0.9233179332263376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 22.765527486801147 s\n",
      "Accuracy 0.9293549802544976 precision 0.9293163814246156 specificity 0.8116304064933111 recall 0.9293549802544976 f1 0.9267739218126093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 22.82159686088562 s\n",
      "Accuracy 0.9254607283896445 precision 0.9251546616796296 specificity 0.8044560797328572 recall 0.9254607283896445 f1 0.9227098492853011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 22.998037338256836 s\n",
      "Accuracy 0.9278740675734971 precision 0.9276725828681535 specificity 0.8075810886960668 recall 0.9278740675734971 f1 0.9252157275670978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 22.258013486862183 s\n",
      "Accuracy 0.9268319438350153 precision 0.9268391742066182 specificity 0.8056240637711557 recall 0.9268319438350153 f1 0.9240425983418158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 22.483116149902344 s\n",
      "Accuracy 0.9286419482229048 precision 0.9286169483347313 specificity 0.8079908515775435 recall 0.9286419482229048 f1 0.9259562693335323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 22.71401333808899 s\n",
      "Accuracy 0.9254607283896445 precision 0.9251881692941232 specificity 0.7962070133133363 recall 0.9254607283896445 f1 0.922489610785485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 22.195037126541138 s\n",
      "Accuracy 0.9310552874067574 precision 0.9304818342778585 specificity 0.820204840727287 recall 0.9310552874067574 f1 0.9288795069682945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 22.234012603759766 s\n",
      "Accuracy 0.9251864853005705 precision 0.9250122670482425 specificity 0.8011181153213505 recall 0.9251864853005705 f1 0.9223040409851073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 23.205013751983643 s\n",
      "Accuracy 0.9282031592803861 precision 0.9279317237039508 specificity 0.8071859597625419 recall 0.9282031592803861 f1 0.925563759319198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 22.55901336669922 s\n",
      "Accuracy 0.9305616498464239 precision 0.9304185769512012 specificity 0.8129365877918096 recall 0.9305616498464239 f1 0.9280655496859936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 22.62152600288391 s\n",
      "Accuracy 0.9306164984642387 precision 0.9300999909379287 specificity 0.8133652220457849 recall 0.9306164984642387 f1 0.9282535543288825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 22.8316752910614 s\n",
      "Accuracy 0.9278740675734971 precision 0.9274615673684571 specificity 0.8091245410530185 recall 0.9278740675734971 f1 0.9253211922698457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 22.127013683319092 s\n",
      "Accuracy 0.9305616498464239 precision 0.9302674764462694 specificity 0.8090822101934486 recall 0.9305616498464239 f1 0.9280230762226659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 21.9470157623291 s\n",
      "Accuracy 0.9288613426941641 precision 0.9283438794339289 specificity 0.8142675750671877 recall 0.9288613426941641 f1 0.9264872741779853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 22.193011045455933 s\n",
      "Accuracy 0.9277095217200526 precision 0.9273157989723251 specificity 0.8049924058140626 recall 0.9277095217200526 f1 0.9250462580513683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 21.95491862297058 s\n",
      "Accuracy 0.9283128565160158 precision 0.9282508815510834 specificity 0.8019973902333525 recall 0.9283128565160158 f1 0.9254865091511852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 22.957014560699463 s\n",
      "Accuracy 0.9277095217200526 precision 0.9274996321622937 specificity 0.809470852866808 recall 0.9277095217200526 f1 0.9250964186767106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 22.52301335334778 s\n",
      "Accuracy 0.9297389205792014 precision 0.929448472708163 specificity 0.8078422057711243 recall 0.9297389205792014 f1 0.9271528987562321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 22.20152759552002 s\n",
      "Accuracy 0.9251864853005705 precision 0.9248687869904652 specificity 0.7997530996377341 recall 0.9251864853005705 f1 0.9223141698168843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 22.789555311203003 s\n",
      "Accuracy 0.9263931548924967 precision 0.9261222893463035 specificity 0.8058331158255061 recall 0.9263931548924967 f1 0.9236840593325766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 22.75801181793213 s\n",
      "Accuracy 0.9296840719613866 precision 0.929193550321824 specificity 0.8128934418325252 recall 0.9296840719613866 f1 0.9272830181556609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 22.15301275253296 s\n",
      "Accuracy 0.9283677051338306 precision 0.9280864319966755 specificity 0.8074463482211589 recall 0.9283677051338306 f1 0.9257410573132826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 22.441012620925903 s\n",
      "Accuracy 0.92858709960509 precision 0.9284720073974022 specificity 0.8023677344947245 recall 0.92858709960509 f1 0.9257915352701762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 22.949013710021973 s\n",
      "Accuracy 0.9278192189556823 precision 0.9269737309721091 specificity 0.8121758212502 recall 0.9278192189556823 f1 0.9255035449359791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 23.14517617225647 s\n",
      "Accuracy 0.9263383062746818 precision 0.9260672671086754 specificity 0.8040856063198857 recall 0.9263383062746818 f1 0.9235846062427372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 22.197535514831543 s\n",
      "Accuracy 0.9296840719613866 precision 0.9290908119406516 specificity 0.8137864978431182 recall 0.9296840719613866 f1 0.9273412651600398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 22.67801308631897 s\n",
      "Accuracy 0.9257898200965335 precision 0.9254686621625341 specificity 0.8007673237025671 recall 0.9257898200965335 f1 0.9229572868645126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 22.19345450401306 s\n",
      "Accuracy 0.9242540587977183 precision 0.9236933218009186 specificity 0.7940277128567694 recall 0.9242540587977183 f1 0.9212943148999433\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 22.807044744491577 s\n",
      "Accuracy 0.926941641070645 precision 0.9269064733830346 specificity 0.805733338584698 recall 0.926941641070645 f1 0.9241694829960991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 22.672013521194458 s\n",
      "Accuracy 0.9226086002632734 precision 0.9219050149686356 specificity 0.7940050247844058 recall 0.9226086002632734 f1 0.9196624973915607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 22.317005395889282 s\n",
      "Accuracy 0.9262286090390522 precision 0.9257227696501885 specificity 0.7990891975397929 recall 0.9262286090390522 f1 0.9234246221567833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 22.32207441329956 s\n",
      "Accuracy 0.9330298376480912 precision 0.9327888901600432 specificity 0.8178556624336201 recall 0.9330298376480912 f1 0.9307228133204756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 22.362013816833496 s\n",
      "Accuracy 0.9295195261079421 precision 0.9294766603928263 specificity 0.8130298386627023 recall 0.9295195261079421 f1 0.9269757981213986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 21.975011825561523 s\n",
      "Accuracy 0.9290258885476086 precision 0.9288904188968587 specificity 0.809987312818157 recall 0.9290258885476086 f1 0.926428139646558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 22.318013668060303 s\n",
      "Accuracy 0.9268319438350153 precision 0.9265881533555186 specificity 0.8061062125431067 recall 0.9268319438350153 f1 0.9241298118451584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 21.469524383544922 s\n",
      "Accuracy 0.9270513383062747 precision 0.9271137434921046 specificity 0.8001320150808533 recall 0.9270513383062747 f1 0.9241152291497013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 21.96856713294983 s\n",
      "Accuracy 0.9272158841597192 precision 0.9265290455481849 specificity 0.8086154546571959 recall 0.9272158841597192 f1 0.9247363573320501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 21.814040899276733 s\n",
      "Accuracy 0.925351031154015 precision 0.9251651327046172 specificity 0.8020995164311229 recall 0.925351031154015 f1 0.9225005273410716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 21.90401291847229 s\n",
      "Accuracy 0.9274352786309785 precision 0.92737633050394 specificity 0.8045268737007786 recall 0.9274352786309785 f1 0.9246506270307574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 21.84601354598999 s\n",
      "Accuracy 0.9292452830188679 precision 0.9289860138160285 specificity 0.8140047887583356 recall 0.9292452830188679 f1 0.9267850853839321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 21.57701325416565 s\n",
      "Accuracy 0.9283128565160158 precision 0.9280271457105453 specificity 0.8084929433766567 recall 0.9283128565160158 f1 0.9257117529974975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 22.16701316833496 s\n",
      "Accuracy 0.9268867924528302 precision 0.9264075003048685 specificity 0.808024519102135 recall 0.9268867924528302 f1 0.9243107098346508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 22.499014377593994 s\n",
      "Accuracy 0.9289710399297938 precision 0.9285524340252592 specificity 0.8055633656833843 recall 0.9289710399297938 f1 0.9263564678869065\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 21.870100021362305 s\n",
      "Accuracy 0.925954365949978 precision 0.9255825858455468 specificity 0.8013367541548708 recall 0.925954365949978 f1 0.9231561461463338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 22.27552342414856 s\n",
      "Accuracy 0.9292452830188679 precision 0.9290655619101301 specificity 0.8095904680944683 recall 0.9292452830188679 f1 0.9266559208926952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 22.253015995025635 s\n",
      "Accuracy 0.9267222465993857 precision 0.9262182643080363 specificity 0.8047836951681756 recall 0.9267222465993857 f1 0.9240709892303633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 21.79601240158081 s\n",
      "Accuracy 0.9293001316366828 precision 0.9287313399874758 specificity 0.8087620868440973 recall 0.9293001316366828 f1 0.9268212795217939\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 21.872012853622437 s\n",
      "Accuracy 0.9267222465993857 precision 0.9265626688616757 specificity 0.8018915990789689 recall 0.9267222465993857 f1 0.9238874323440495\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 22.230013847351074 s\n",
      "Accuracy 0.9278192189556823 precision 0.9278043523095215 specificity 0.8069241665646003 recall 0.9278192189556823 f1 0.9250881303263462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 22.14503240585327 s\n",
      "Accuracy 0.9271061869240895 precision 0.9269647121571607 specificity 0.8084776031289708 recall 0.9271061869240895 f1 0.9244362716595964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 22.13801336288452 s\n",
      "Accuracy 0.9286967968407196 precision 0.9284252252941614 specificity 0.8131427742277975 recall 0.9286967968407196 f1 0.9262099786911422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 21.842605590820312 s\n",
      "Accuracy 0.9283128565160158 precision 0.9283494464779237 specificity 0.8086041629499108 recall 0.9283128565160158 f1 0.9256175916220685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 22.000015258789062 s\n",
      "Accuracy 0.9277095217200526 precision 0.9270757906490856 specificity 0.8085916622694095 recall 0.9277095217200526 f1 0.9252188258699429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 21.773010730743408 s\n",
      "Accuracy 0.9284774023694603 precision 0.9284210661475693 specificity 0.8097084304190665 recall 0.9284774023694603 f1 0.9258386820635035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 21.668593168258667 s\n",
      "Accuracy 0.9286419482229048 precision 0.9279822136101074 specificity 0.8128533496813127 recall 0.9286419482229048 f1 0.9262826313613741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 21.60001301765442 s\n",
      "Accuracy 0.9264480035103115 precision 0.9262355786194948 specificity 0.8073667733167649 recall 0.9264480035103115 f1 0.9237597440870282\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 21.92801308631897 s\n",
      "Accuracy 0.9303971039929794 precision 0.9299112613928047 specificity 0.8126232751931598 recall 0.9303971039929794 f1 0.9280017676778083\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 21.933013200759888 s\n",
      "Accuracy 0.9297389205792014 precision 0.9293805614638424 specificity 0.8148588133060636 recall 0.9297389205792014 f1 0.9273400009705678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 21.811055660247803 s\n",
      "Accuracy 0.928258007898201 precision 0.9278159730585975 specificity 0.8086067397600569 recall 0.928258007898201 f1 0.9257100884828782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 22.01001262664795 s\n",
      "Accuracy 0.9277095217200526 precision 0.927378259021306 specificity 0.8058114219224126 recall 0.9277095217200526 f1 0.9250458039427367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 21.749536752700806 s\n",
      "Accuracy 0.927928916191312 precision 0.9273712034973304 specificity 0.8064679445777134 recall 0.927928916191312 f1 0.9253627268012526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 21.89207148551941 s\n",
      "Accuracy 0.927599824484423 precision 0.9273615139339692 specificity 0.8127866958603445 recall 0.927599824484423 f1 0.9250739814661593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 21.961013555526733 s\n",
      "Accuracy 0.9228279947345327 precision 0.9225275530423072 specificity 0.7938513071432693 recall 0.9228279947345327 f1 0.9197447075334749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 22.338012218475342 s\n",
      "Accuracy 0.9220052654673102 precision 0.9222017819285679 specificity 0.7955338272280168 recall 0.9220052654673102 f1 0.9188020279506486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 21.782012939453125 s\n",
      "Accuracy 0.9289710399297938 precision 0.9287308912480111 specificity 0.80994874829232 recall 0.9289710399297938 f1 0.926403444282066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 22.00452423095703 s\n",
      "Accuracy 0.9282031592803861 precision 0.9276430681471297 specificity 0.8121648231014924 recall 0.9282031592803861 f1 0.9257818785128966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 21.683013200759888 s\n",
      "Accuracy 0.9266673979815708 precision 0.9268751404074371 specificity 0.8008735527331693 recall 0.9266673979815708 f1 0.9237009775354773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 21.747546911239624 s\n",
      "Accuracy 0.9286967968407196 precision 0.9284660829249617 specificity 0.8091600335772231 recall 0.9286967968407196 f1 0.9261019931317674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 22.084012746810913 s\n",
      "Accuracy 0.9316037735849056 precision 0.9309154271739238 specificity 0.8157223540056612 recall 0.9316037735849056 f1 0.9293788566401245\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 22.39254117012024 s\n",
      "Accuracy 0.9269964896884598 precision 0.9271925022946097 specificity 0.8072507499738046 recall 0.9269964896884598 f1 0.9241978669890599\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 22.737013339996338 s\n",
      "Accuracy 0.9277643703378675 precision 0.9274941514416649 specificity 0.8060175577445786 recall 0.9277643703378675 f1 0.9250872638300484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 22.31401300430298 s\n",
      "Accuracy 0.926283457656867 precision 0.925829012419338 specificity 0.8060012688140754 recall 0.926283457656867 f1 0.9236367694843366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 21.873034238815308 s\n",
      "Accuracy 0.9278740675734971 precision 0.927574301123754 specificity 0.8050673602393832 recall 0.9278740675734971 f1 0.9251854706950653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 21.956011533737183 s\n",
      "Accuracy 0.9296292233435718 precision 0.9295344024595823 specificity 0.8109250359871716 recall 0.9296292233435718 f1 0.9270534455967545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 22.231622219085693 s\n",
      "Accuracy 0.9260092145677928 precision 0.9256670325199782 specificity 0.8058831956135515 recall 0.9260092145677928 f1 0.9233167434261554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 22.101011276245117 s\n",
      "Accuracy 0.9332492321193506 precision 0.9328472436419848 specificity 0.8147474518142304 recall 0.9332492321193506 f1 0.9309301149252919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 21.872013330459595 s\n",
      "Accuracy 0.9237604212373848 precision 0.923229946740099 specificity 0.7961864678390433 recall 0.9237604212373848 f1 0.9208357511447518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 21.925013065338135 s\n",
      "Accuracy 0.9268319438350153 precision 0.9267656063144433 specificity 0.8028821301449205 recall 0.9268319438350153 f1 0.9239962002013913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 21.980013847351074 s\n",
      "Accuracy 0.9311101360245722 precision 0.930843876921803 specificity 0.8107081199858766 recall 0.9311101360245722 f1 0.9286117031567505\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 22.310012817382812 s\n",
      "Accuracy 0.9271610355419043 precision 0.9270988268535965 specificity 0.8110140890959832 recall 0.9271610355419043 f1 0.9245305277727551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 23.48301362991333 s\n",
      "Accuracy 0.9261737604212373 precision 0.9258530193903225 specificity 0.8032342429276209 recall 0.9261737604212373 f1 0.9234112577667402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 22.439462661743164 s\n",
      "Accuracy 0.9257349714787187 precision 0.9255032528379599 specificity 0.8009348349507892 recall 0.9257349714787187 f1 0.9228772088104638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 22.10356044769287 s\n",
      "Accuracy 0.9277095217200526 precision 0.9279797177003016 specificity 0.7966090085963243 recall 0.9277095217200526 f1 0.9246449995901179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 22.165013074874878 s\n",
      "Accuracy 0.9258995173321632 precision 0.9254195546548661 specificity 0.8059598849261932 recall 0.9258995173321632 f1 0.9232530584867119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 21.897014379501343 s\n",
      "Accuracy 0.9257349714787187 precision 0.9254601105963426 specificity 0.8041918760150428 recall 0.9257349714787187 f1 0.9229729278213662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 21.575012683868408 s\n",
      "Accuracy 0.927599824484423 precision 0.9270291744994872 specificity 0.806551936694716 recall 0.927599824484423 f1 0.925033677476412\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 22.900246381759644 s\n",
      "Accuracy 0.9288064940763493 precision 0.9289406007076595 specificity 0.8100711266714122 recall 0.9288064940763493 f1 0.9261289684791163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 22.579535245895386 s\n",
      "Accuracy 0.9302874067573497 precision 0.9299247651356717 specificity 0.8089427548537299 recall 0.9302874067573497 f1 0.9277620481622778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 22.65104341506958 s\n",
      "Accuracy 0.9280386134269416 precision 0.9278588124479428 specificity 0.8030974232989174 recall 0.9280386134269416 f1 0.925268115805753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 21.877373456954956 s\n",
      "Accuracy 0.9283677051338306 precision 0.9279068698576562 specificity 0.8088553144645274 recall 0.9283677051338306 f1 0.9258343995798429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 22.267012119293213 s\n",
      "Accuracy 0.9290258885476086 precision 0.9283319754568962 specificity 0.808792545608134 recall 0.9290258885476086 f1 0.9265889575665108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 22.37909984588623 s\n",
      "Accuracy 0.9273255813953488 precision 0.9268921124801374 specificity 0.8140611648085792 recall 0.9273255813953488 f1 0.9248900333785188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 22.8865225315094 s\n",
      "Accuracy 0.927599824484423 precision 0.927453808210429 specificity 0.8034893693406199 recall 0.927599824484423 f1 0.9248191600045348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 21.772510528564453 s\n",
      "Accuracy 0.9287516454585344 precision 0.9282475468966565 specificity 0.8069177702356075 recall 0.9287516454585344 f1 0.9261943018251287\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 21.682013034820557 s\n",
      "Accuracy 0.9277095217200526 precision 0.9273299417316611 specificity 0.8027020205329276 recall 0.9277095217200526 f1 0.9249854574748666\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 22.049012899398804 s\n",
      "Accuracy 0.9255155770074595 precision 0.9257233335997316 specificity 0.7957507752241708 recall 0.9255155770074595 f1 0.9223939307515999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 22.382013082504272 s\n",
      "Accuracy 0.9267770952172005 precision 0.926441783166028 specificity 0.8066653187585168 recall 0.9267770952172005 f1 0.9241169330053828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 21.582013368606567 s\n",
      "Accuracy 0.9271061869240895 precision 0.9268727899516612 specificity 0.8063373195292519 recall 0.9271061869240895 f1 0.9244119859013081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 21.932522535324097 s\n",
      "Accuracy 0.9280934620447565 precision 0.9278343057107409 specificity 0.805756439718853 recall 0.9280934620447565 f1 0.9254133113488986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 21.81767749786377 s\n",
      "Accuracy 0.9277643703378675 precision 0.9276777841550483 specificity 0.8079893669500596 recall 0.9277643703378675 f1 0.9250790107031038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 22.325003147125244 s\n",
      "Accuracy 0.9264480035103115 precision 0.9264366608569672 specificity 0.8028514509829413 recall 0.9264480035103115 f1 0.9235873231720649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 21.81800103187561 s\n",
      "Accuracy 0.9254058797718298 precision 0.9248918634594427 specificity 0.8043837802178493 recall 0.9254058797718298 f1 0.9227217075406587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 21.763002634048462 s\n",
      "Accuracy 0.9263931548924967 precision 0.925971629740398 specificity 0.7994070453058645 recall 0.9263931548924967 f1 0.9235722854572003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 22.249001502990723 s\n",
      "Accuracy 0.926612549363756 precision 0.9263693084720594 specificity 0.8028500227229599 recall 0.926612549363756 f1 0.923825000771218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 21.913002252578735 s\n",
      "Accuracy 0.9308907415533129 precision 0.9304609355284761 specificity 0.8147597014050483 recall 0.9308907415533129 f1 0.9285350663759993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 22.100517511367798 s\n",
      "Accuracy 0.9245831505046073 precision 0.9244203645296439 specificity 0.7949096969116529 recall 0.9245831505046073 f1 0.9215246461236805\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 21.470000982284546 s\n",
      "Accuracy 0.9293001316366828 precision 0.9287016742846215 specificity 0.8086472157534031 recall 0.9293001316366828 f1 0.9268293349301564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 22.68052363395691 s\n",
      "Accuracy 0.9255155770074595 precision 0.9252210489550545 specificity 0.8007982136654151 recall 0.9255155770074595 f1 0.9226694700179048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 21.71769952774048 s\n",
      "Accuracy 0.9281483106625713 precision 0.9280775766061719 specificity 0.8106054840855638 recall 0.9281483106625713 f1 0.9255289681005763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 21.684000492095947 s\n",
      "Accuracy 0.927599824484423 precision 0.9275118426970264 specificity 0.8087218793672658 recall 0.927599824484423 f1 0.9249294307191432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 21.931002378463745 s\n",
      "Accuracy 0.9271610355419043 precision 0.9266600774644455 specificity 0.8067470202063858 recall 0.9271610355419043 f1 0.9245662441343152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 21.635002374649048 s\n",
      "Accuracy 0.9295743747257569 precision 0.9292238400970163 specificity 0.812361961172227 recall 0.9295743747257569 f1 0.9271111003654317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 21.851512670516968 s\n",
      "Accuracy 0.9263383062746818 precision 0.925879076351683 specificity 0.8046077049418766 recall 0.9263383062746818 f1 0.9236594655228436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 21.869001626968384 s\n",
      "Accuracy 0.9273255813953488 precision 0.9270119434418844 specificity 0.8042049735937089 recall 0.9273255813953488 f1 0.924608839595201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 21.842002630233765 s\n",
      "Accuracy 0.9281483106625713 precision 0.9275305613775894 specificity 0.8071353767007287 recall 0.9281483106625713 f1 0.9256246920014224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 21.90900206565857 s\n",
      "Accuracy 0.9275449758666081 precision 0.9273745338137805 specificity 0.8060129160084758 recall 0.9275449758666081 f1 0.9248322741185694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 21.92100238800049 s\n",
      "Accuracy 0.9273804300131636 precision 0.9270232029640683 specificity 0.8067942399904086 recall 0.9273804300131636 f1 0.9247425681965885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 22.167513132095337 s\n",
      "Accuracy 0.9254058797718298 precision 0.9252873053014227 specificity 0.798436198277506 recall 0.9254058797718298 f1 0.9224430825379344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 22.436092615127563 s\n",
      "Accuracy 0.9272158841597192 precision 0.9269466272434043 specificity 0.7988764417030059 recall 0.9272158841597192 f1 0.9243510584391088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 21.80700159072876 s\n",
      "Accuracy 0.9280386134269416 precision 0.9278156876445026 specificity 0.8080567580463958 recall 0.9280386134269416 f1 0.925401733124283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 22.244022607803345 s\n",
      "Accuracy 0.9294098288723124 precision 0.9291084469334353 specificity 0.8065617571846707 recall 0.9294098288723124 f1 0.9267900459279537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 20.6519992351532 s\n",
      "Accuracy 0.9272158841597192 precision 0.9268494565643521 specificity 0.8034143596951626 recall 0.9272158841597192 f1 0.9244944733748175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 19.95000147819519 s\n",
      "Accuracy 0.928258007898201 precision 0.9277206988579849 specificity 0.8060433051029102 recall 0.928258007898201 f1 0.9256809474920037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 20.089028358459473 s\n",
      "Accuracy 0.9279837648091268 precision 0.9279088038620619 specificity 0.8104005868955677 recall 0.9279837648091268 f1 0.9253575860926544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 20.246005296707153 s\n",
      "Accuracy 0.927599824484423 precision 0.9273291667828923 specificity 0.8037112307224625 recall 0.927599824484423 f1 0.924863058375717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 20.053001403808594 s\n",
      "Accuracy 0.9266673979815708 precision 0.9264296085674565 specificity 0.7994579673059752 recall 0.9266673979815708 f1 0.9237947937180896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 20.21300172805786 s\n",
      "Accuracy 0.9268319438350153 precision 0.9265628963151397 specificity 0.805647241662815 recall 0.9268319438350153 f1 0.9241264263947652\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 19.733002185821533 s\n",
      "Accuracy 0.9287516454585344 precision 0.9283275894703664 specificity 0.8087409443259002 recall 0.9287516454585344 f1 0.926210669959367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 19.854001760482788 s\n",
      "Accuracy 0.9267222465993857 precision 0.9264517704924208 specificity 0.8004937437302417 recall 0.9267222465993857 f1 0.9238869279032838\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 20.11800217628479 s\n",
      "Accuracy 0.9266673979815708 precision 0.9262964567685464 specificity 0.8030165117219448 recall 0.9266673979815708 f1 0.923926051727384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 20.072515726089478 s\n",
      "Accuracy 0.9263383062746818 precision 0.9266239233396203 specificity 0.7984130445443726 recall 0.9263383062746818 f1 0.923282124440714\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 19.94407820701599 s\n",
      "Accuracy 0.9287516454585344 precision 0.9286729332468892 specificity 0.8115168709947264 recall 0.9287516454585344 f1 0.9261680091879545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 20.154234409332275 s\n",
      "Accuracy 0.9248573935936815 precision 0.924595064959804 specificity 0.8030882686237659 recall 0.9248573935936815 f1 0.9220458140948442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 19.982344388961792 s\n",
      "Accuracy 0.9296292233435718 precision 0.929239682960476 specificity 0.8084190435608166 recall 0.9296292233435718 f1 0.9270868129390488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 20.170387744903564 s\n",
      "Accuracy 0.9244734532689777 precision 0.9240943671889508 specificity 0.8025490360801149 recall 0.9244734532689777 f1 0.9216780703419081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 19.984001398086548 s\n",
      "Accuracy 0.9275449758666081 precision 0.9272709661484415 specificity 0.8032975079351318 recall 0.9275449758666081 f1 0.9247979545787405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 20.197511196136475 s\n",
      "Accuracy 0.9236507240017552 precision 0.923821737378723 specificity 0.7967183268967022 recall 0.9236507240017552 f1 0.9205217418510038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 20.156861305236816 s\n",
      "Accuracy 0.9277643703378675 precision 0.9274696277196754 specificity 0.8048183154958851 recall 0.9277643703378675 f1 0.9250657986737134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 20.830512285232544 s\n",
      "Accuracy 0.926283457656867 precision 0.9259455784032362 specificity 0.802162175808686 recall 0.926283457656867 f1 0.923501909578949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 20.11000108718872 s\n",
      "Accuracy 0.925680122860904 precision 0.9254229975487746 specificity 0.7987133899759871 recall 0.925680122860904 f1 0.9227728712156181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 19.700002431869507 s\n",
      "Accuracy 0.9284225537516455 precision 0.9280128393977098 specificity 0.8065744598770672 recall 0.9284225537516455 f1 0.9258178752691532\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 19.76200222969055 s\n",
      "Accuracy 0.9277643703378675 precision 0.9274780461049069 specificity 0.8082469593259687 recall 0.9277643703378675 f1 0.9251466559711307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 19.68100070953369 s\n",
      "Accuracy 0.9271061869240895 precision 0.9268758579757025 specificity 0.8057237200319163 recall 0.9271061869240895 f1 0.9243959307812739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 20.0050048828125 s\n",
      "Accuracy 0.926283457656867 precision 0.9258330229261413 specificity 0.8102877050715012 recall 0.926283457656867 f1 0.9237423663857215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 19.938489198684692 s\n",
      "Accuracy 0.9288064940763493 precision 0.9282379450949532 specificity 0.8060604532918193 recall 0.9288064940763493 f1 0.9262524110551229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 20.46551275253296 s\n",
      "Accuracy 0.9300680122860904 precision 0.9299276168484282 specificity 0.8090865201015246 recall 0.9300680122860904 f1 0.9274716190971879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 20.166000604629517 s\n",
      "Accuracy 0.9251316366827556 precision 0.9247188976318588 specificity 0.803095645416407 recall 0.9251316366827556 f1 0.9223746031684085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 20.026001691818237 s\n",
      "Accuracy 0.9276546731022378 precision 0.9274845379319002 specificity 0.8073209714100975 recall 0.9276546731022378 f1 0.9249759959332418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 19.941599130630493 s\n",
      "Accuracy 0.9263931548924967 precision 0.9262361199476681 specificity 0.8012644353481306 recall 0.9263931548924967 f1 0.9235348444543939\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 19.963004112243652 s\n",
      "Accuracy 0.9308358929354981 precision 0.9303716513982351 specificity 0.8113078165582838 recall 0.9308358929354981 f1 0.9284111171654011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 19.662998914718628 s\n",
      "Accuracy 0.9276546731022378 precision 0.9272261774929627 specificity 0.8081205555581499 recall 0.9276546731022378 f1 0.925078454545492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 19.923002004623413 s\n",
      "Accuracy 0.9296840719613866 precision 0.9293624861202241 specificity 0.8098493588773598 recall 0.9296840719613866 f1 0.9271542749391668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 19.973002672195435 s\n",
      "Accuracy 0.927928916191312 precision 0.9275761109939585 specificity 0.8064745783449295 recall 0.927928916191312 f1 0.9252928667183786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 20.115001678466797 s\n",
      "Accuracy 0.9279837648091268 precision 0.9274521221361374 specificity 0.810678067557099 recall 0.9279837648091268 f1 0.9255120564822156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 20.01400399208069 s\n",
      "Accuracy 0.9287516454585344 precision 0.9283385935573208 specificity 0.8142275851944705 recall 0.9287516454585344 f1 0.9263382436582255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 20.059999704360962 s\n",
      "Accuracy 0.9287516454585344 precision 0.9288254972402661 specificity 0.807609016368713 recall 0.9287516454585344 f1 0.9260309534288882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 19.939003229141235 s\n",
      "Accuracy 0.9271610355419043 precision 0.9269246704222286 specificity 0.8018068528917645 recall 0.9271610355419043 f1 0.924357218428902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 19.308000087738037 s\n",
      "Accuracy 0.9257349714787187 precision 0.9252407554088503 specificity 0.8025377855313368 recall 0.9257349714787187 f1 0.9230036926816082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 19.661001920700073 s\n",
      "Accuracy 0.9290807371654234 precision 0.9288528347493235 specificity 0.8071842145731155 recall 0.9290807371654234 f1 0.9264456826075961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 19.866002321243286 s\n",
      "Accuracy 0.9273804300131636 precision 0.9270986259430297 specificity 0.8021678188734428 recall 0.9273804300131636 f1 0.9246045549115447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 19.880001544952393 s\n",
      "Accuracy 0.9280934620447565 precision 0.928043260683062 specificity 0.8015009809982523 recall 0.9280934620447565 f1 0.9252466922294147\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 19.89200258255005 s\n",
      "Accuracy 0.9248025449758666 precision 0.9246588502362767 specificity 0.7992021350275699 recall 0.9248025449758666 f1 0.9218537139910978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 19.977002143859863 s\n",
      "Accuracy 0.9293001316366828 precision 0.9287471402115988 specificity 0.809553169864668 recall 0.9293001316366828 f1 0.9268344930032221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 19.76100182533264 s\n",
      "Accuracy 0.9301228609039052 precision 0.9301115296482005 specificity 0.8135278365758579 recall 0.9301228609039052 f1 0.9275931733075622\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 19.90400218963623 s\n",
      "Accuracy 0.927270732777534 precision 0.9272261724086095 specificity 0.8002654816729156 recall 0.927270732777534 f1 0.9243735296618911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 20.04600191116333 s\n",
      "Accuracy 0.9289710399297938 precision 0.928438074367341 specificity 0.8159162371430004 recall 0.9289710399297938 f1 0.9266438463492952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 19.848003149032593 s\n",
      "Accuracy 0.9277643703378675 precision 0.9276557413541814 specificity 0.807703763330175 recall 0.9277643703378675 f1 0.9250786313233595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 19.520001888275146 s\n",
      "Accuracy 0.9274352786309785 precision 0.9267844646309116 specificity 0.8060352153214686 recall 0.9274352786309785 f1 0.924882450180354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 19.783003091812134 s\n",
      "Accuracy 0.9292452830188679 precision 0.9289820602285603 specificity 0.8045822418491746 recall 0.9292452830188679 f1 0.9265627230963835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 20.248002529144287 s\n",
      "Accuracy 0.9295195261079421 precision 0.929064046977535 specificity 0.806093710417512 recall 0.9295195261079421 f1 0.9269417994491166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 21.080000162124634 s\n",
      "Accuracy 0.9248573935936815 precision 0.9248216769488895 specificity 0.7988966340236561 recall 0.9248573935936815 f1 0.9218698276425997\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 22.023004055023193 s\n",
      "Accuracy 0.9281483106625713 precision 0.9277786867155966 specificity 0.8095380614108847 recall 0.9281483106625713 f1 0.9255964610919986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 21.672003269195557 s\n",
      "Accuracy 0.927599824484423 precision 0.9277222800767633 specificity 0.8041507325603057 recall 0.927599824484423 f1 0.9247578179337673\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 21.43100094795227 s\n",
      "Accuracy 0.9277095217200526 precision 0.9272180182924731 specificity 0.8087859069042392 recall 0.9277095217200526 f1 0.925172280975321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 21.236000537872314 s\n",
      "Accuracy 0.926612549363756 precision 0.9263943314844414 specificity 0.8017210844480835 recall 0.926612549363756 f1 0.923789104835991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 21.788002729415894 s\n",
      "Accuracy 0.9297389205792014 precision 0.9298836152198675 specificity 0.8048522764311822 recall 0.9297389205792014 f1 0.9269543264854995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 21.435001611709595 s\n",
      "Accuracy 0.9271610355419043 precision 0.9273913001113946 specificity 0.802786024180045 recall 0.9271610355419043 f1 0.9242467300778464\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 21.882002115249634 s\n",
      "Accuracy 0.9235410267661255 precision 0.9231642968109564 specificity 0.7986663185442799 recall 0.9235410267661255 f1 0.9206249602282643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 21.646003246307373 s\n",
      "Accuracy 0.9272158841597192 precision 0.9272347791105782 specificity 0.8022593688138306 recall 0.9272158841597192 f1 0.9243483117909588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 21.671003341674805 s\n",
      "Accuracy 0.9292452830188679 precision 0.9290512894527967 specificity 0.8080792602863697 recall 0.9292452830188679 f1 0.9266244488880091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 21.48200249671936 s\n",
      "Accuracy 0.927599824484423 precision 0.9270945784089869 specificity 0.8110656753451899 recall 0.927599824484423 f1 0.9251210355663506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 21.56600022315979 s\n",
      "Accuracy 0.9280934620447565 precision 0.9280428834898234 specificity 0.805677689527636 recall 0.9280934620447565 f1 0.9253481884632622\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 21.65900206565857 s\n",
      "Accuracy 0.9277095217200526 precision 0.9277266127371635 specificity 0.8063039849440934 recall 0.9277095217200526 f1 0.9249519348209319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 22.141003370285034 s\n",
      "Accuracy 0.927599824484423 precision 0.9271888015470617 specificity 0.8094398799208774 recall 0.927599824484423 f1 0.9250488592981292\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 22.625000953674316 s\n",
      "Accuracy 0.9270513383062747 precision 0.9267121724423448 specificity 0.806222881759093 recall 0.9270513383062747 f1 0.9243869442571496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 22.03100061416626 s\n",
      "Accuracy 0.9257898200965335 precision 0.9255450253299546 specificity 0.8013353413446974 recall 0.9257898200965335 f1 0.922947418171891\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 21.89300274848938 s\n",
      "Accuracy 0.9273255813953488 precision 0.9270688802671918 specificity 0.806207124348223 recall 0.9273255813953488 f1 0.9246399094652791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 22.019001483917236 s\n",
      "Accuracy 0.928258007898201 precision 0.9281214179474268 specificity 0.8070799613277025 recall 0.928258007898201 f1 0.9255755322274001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 21.59800124168396 s\n",
      "Accuracy 0.9288064940763493 precision 0.9287277011602555 specificity 0.8035858640645118 recall 0.9288064940763493 f1 0.9260343899466655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 21.70800232887268 s\n",
      "Accuracy 0.9273255813953488 precision 0.9270481166438244 specificity 0.8082001971512108 recall 0.9273255813953488 f1 0.9246953165101193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 21.332000732421875 s\n",
      "Accuracy 0.9299583150504608 precision 0.929938519156271 specificity 0.8131016177080275 recall 0.9299583150504608 f1 0.9274179801322675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 21.926002025604248 s\n",
      "Accuracy 0.9297389205792014 precision 0.9294492886006205 specificity 0.807102983833798 recall 0.9297389205792014 f1 0.9271351850339892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 22.344000577926636 s\n",
      "Accuracy 0.9252961825362 precision 0.9249373770249942 specificity 0.8005453060870015 recall 0.9252961825362 f1 0.9224597109765074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 22.512003421783447 s\n",
      "Accuracy 0.927928916191312 precision 0.9276715549401995 specificity 0.8089049419696318 recall 0.927928916191312 f1 0.9253212021586738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 21.869000673294067 s\n",
      "Accuracy 0.9261189118034225 precision 0.9258731576505339 specificity 0.8020187445742748 recall 0.9261189118034225 f1 0.9233009670498341\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 22.175002574920654 s\n",
      "Accuracy 0.9283128565160158 precision 0.928319063120704 specificity 0.8037054396532237 recall 0.9283128565160158 f1 0.9255081279543395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 21.771002054214478 s\n",
      "Accuracy 0.9276546731022378 precision 0.9274692124420623 specificity 0.8026181188285001 recall 0.9276546731022378 f1 0.9248658451557358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 22.22600245475769 s\n",
      "Accuracy 0.9250767880649408 precision 0.924681177504519 specificity 0.7956411458796581 recall 0.9250767880649408 f1 0.9221219194414598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 21.78900170326233 s\n",
      "Accuracy 0.9263383062746818 precision 0.9261237230805971 specificity 0.8021909059529265 recall 0.9263383062746818 f1 0.923519608998085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 21.93000364303589 s\n",
      "Accuracy 0.9289710399297938 precision 0.9283893105540184 specificity 0.8147977320350462 recall 0.9289710399297938 f1 0.9266350089548959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 21.984002113342285 s\n",
      "Accuracy 0.9323168056164984 precision 0.9319440802660656 specificity 0.8188843413385081 recall 0.9323168056164984 f1 0.9300621528908205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 21.983999729156494 s\n",
      "Accuracy 0.9278192189556823 precision 0.9276674795406328 specificity 0.8066404606379485 recall 0.9278192189556823 f1 0.9251217187623765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 21.870003700256348 s\n",
      "Accuracy 0.9280934620447565 precision 0.9279283633689469 specificity 0.8048891303106473 recall 0.9280934620447565 f1 0.9253631907855686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 22.614001750946045 s\n",
      "Accuracy 0.9274352786309785 precision 0.9269493089648158 specificity 0.8086047593911886 recall 0.9274352786309785 f1 0.924886371957877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 22.23500084877014 s\n",
      "Accuracy 0.9257349714787187 precision 0.9257409998408841 specificity 0.8034754881433029 recall 0.9257349714787187 f1 0.9228700604588251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 22.585002660751343 s\n",
      "Accuracy 0.9238701184730145 precision 0.9234440212606905 specificity 0.8027463335983753 recall 0.9238701184730145 f1 0.9210836052585638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 21.88200044631958 s\n",
      "Accuracy 0.925351031154015 precision 0.9251213623708935 specificity 0.800818268856552 recall 0.925351031154015 f1 0.9224815281024148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 22.019002437591553 s\n",
      "Accuracy 0.9284225537516455 precision 0.9284866753235975 specificity 0.8063049962660163 recall 0.9284225537516455 f1 0.9256664594911282\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 22.084002017974854 s\n",
      "Accuracy 0.927599824484423 precision 0.9272839900235523 specificity 0.8060748657019801 recall 0.927599824484423 f1 0.9249353165169667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 21.744000911712646 s\n",
      "Accuracy 0.9289710399297938 precision 0.9291117554084025 specificity 0.8069024115006649 recall 0.9289710399297938 f1 0.9262195455205049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 22.19100022315979 s\n",
      "Accuracy 0.9254058797718298 precision 0.9247431580166076 specificity 0.7994882591544004 recall 0.9254058797718298 f1 0.9226499361625649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 21.71800184249878 s\n",
      "Accuracy 0.9277643703378675 precision 0.927133070903065 specificity 0.8082710347253241 recall 0.9277643703378675 f1 0.925265958384762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 22.284002780914307 s\n",
      "Accuracy 0.9279837648091268 precision 0.9280478227529092 specificity 0.8083221857671251 recall 0.9279837648091268 f1 0.9252673583764133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 22.290003538131714 s\n",
      "Accuracy 0.925351031154015 precision 0.9248875514254001 specificity 0.8023696038869856 recall 0.925351031154015 f1 0.9225970610795751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 22.277000665664673 s\n",
      "Accuracy 0.927599824484423 precision 0.9276310581150214 specificity 0.8064557648359447 recall 0.927599824484423 f1 0.9248396520264476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 22.711002111434937 s\n",
      "Accuracy 0.9282031592803861 precision 0.9280367019644055 specificity 0.8085035683901661 recall 0.9282031592803861 f1 0.925562956307059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 22.560004234313965 s\n",
      "Accuracy 0.9291904344010531 precision 0.9291358227509287 specificity 0.8067027426863705 recall 0.9291904344010531 f1 0.9264940251456162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 21.974000453948975 s\n",
      "Accuracy 0.925680122860904 precision 0.9253787007428586 specificity 0.8027015253616278 recall 0.925680122860904 f1 0.92288783902149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 22.418002367019653 s\n",
      "Accuracy 0.9289161913119789 precision 0.9289888086275067 specificity 0.8057912125726611 recall 0.9289161913119789 f1 0.9261558557473134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 21.93300175666809 s\n",
      "Accuracy 0.9236507240017552 precision 0.9233179597469096 specificity 0.796760593512523 recall 0.9236507240017552 f1 0.9206727344478979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 21.884000778198242 s\n",
      "Accuracy 0.9282031592803861 precision 0.9280151397516406 specificity 0.8074393353174589 recall 0.9282031592803861 f1 0.925543873493037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 21.877002716064453 s\n",
      "Accuracy 0.9302325581395349 precision 0.9297924164777823 specificity 0.8128421189301398 recall 0.9302325581395349 f1 0.92782329996798\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 22.31879234313965 s\n",
      "Accuracy 0.924034664326459 precision 0.9235616124725273 specificity 0.7956845747842604 recall 0.924034664326459 f1 0.9210832287309351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 22.06399440765381 s\n",
      "Accuracy 0.9272158841597192 precision 0.9267733121564984 specificity 0.8026866980639901 recall 0.9272158841597192 f1 0.9245017975656481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 23.467003345489502 s\n",
      "Accuracy 0.9254058797718298 precision 0.9251224397467148 specificity 0.8023251402571133 recall 0.9254058797718298 f1 0.9225926920362602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 22.311001300811768 s\n",
      "Accuracy 0.9290258885476086 precision 0.9288669618387666 specificity 0.8064012943815801 recall 0.9290258885476086 f1 0.9263498377276318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 21.952000856399536 s\n",
      "Accuracy 0.9277095217200526 precision 0.9273675715393466 specificity 0.8104175000255383 recall 0.9277095217200526 f1 0.9251614968332003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 22.01300311088562 s\n",
      "Accuracy 0.9228828433523475 precision 0.9227277543948027 specificity 0.7960407631765715 recall 0.9228828433523475 f1 0.9198136814305632\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 20.407000064849854 s\n",
      "Accuracy 0.9267770952172005 precision 0.9262837719393284 specificity 0.8019950948610476 recall 0.9267770952172005 f1 0.9240537292592775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 20.326001167297363 s\n",
      "Accuracy 0.9252413339183853 precision 0.9245461445219615 specificity 0.801293027698582 recall 0.9252413339183853 f1 0.922540417833713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 20.34999918937683 s\n",
      "Accuracy 0.9283128565160158 precision 0.9282128850572496 specificity 0.8075533202506819 recall 0.9283128565160158 f1 0.9256319551564127\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 20.216001272201538 s\n",
      "Accuracy 0.9268867924528302 precision 0.9266374730984174 specificity 0.8098010599041535 recall 0.9268867924528302 f1 0.924278517432729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 20.450287342071533 s\n",
      "Accuracy 0.9263931548924967 precision 0.9262216950295987 specificity 0.805272604103201 recall 0.9263931548924967 f1 0.9236391762221221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 20.685409784317017 s\n",
      "Accuracy 0.9274352786309785 precision 0.9272111881681656 specificity 0.8020946843029751 recall 0.9274352786309785 f1 0.9246407182216294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 20.7010018825531 s\n",
      "Accuracy 0.926941641070645 precision 0.9263057418784854 specificity 0.8074364116319389 recall 0.926941641070645 f1 0.9244082522987426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 20.839004039764404 s\n",
      "Accuracy 0.9250767880649408 precision 0.9245032142016113 specificity 0.805622272267404 recall 0.9250767880649408 f1 0.9224389324468079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 20.594001054763794 s\n",
      "Accuracy 0.9274901272487933 precision 0.9272856366856759 specificity 0.8064337919566862 recall 0.9274901272487933 f1 0.9247970443309791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 20.525002241134644 s\n",
      "Accuracy 0.9269964896884598 precision 0.9267658353760966 specificity 0.8111840459035194 recall 0.9269964896884598 f1 0.9244182975497311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 20.60900115966797 s\n",
      "Accuracy 0.927599824484423 precision 0.9274253823411318 specificity 0.8012840750648326 recall 0.927599824484423 f1 0.9247737228799134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 20.590000867843628 s\n",
      "Accuracy 0.9264480035103115 precision 0.9260862045847903 specificity 0.8068574800928675 recall 0.9264480035103115 f1 0.9237948364472236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 20.441001415252686 s\n",
      "Accuracy 0.9283677051338306 precision 0.9283158421510743 specificity 0.8061288546659953 recall 0.9283677051338306 f1 0.925639445099382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 20.554000854492188 s\n",
      "Accuracy 0.9232119350592365 precision 0.9229086659355034 specificity 0.7924003617035081 recall 0.9232119350592365 f1 0.9200997362549403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 20.361999988555908 s\n",
      "Accuracy 0.9288613426941641 precision 0.9285441081175524 specificity 0.8048224225186573 recall 0.9288613426941641 f1 0.9261933684681424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 20.194003105163574 s\n",
      "Accuracy 0.9274352786309785 precision 0.9271438598263062 specificity 0.8094864419970416 recall 0.9274352786309785 f1 0.9248430176732385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 20.843000650405884 s\n",
      "Accuracy 0.9252961825362 precision 0.9247880576226888 specificity 0.8028427627492233 recall 0.9252961825362 f1 0.9225685152227739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 20.6940016746521 s\n",
      "Accuracy 0.9303971039929794 precision 0.9300024611144391 specificity 0.8100463636536877 recall 0.9303971039929794 f1 0.9279104085109033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 20.675001621246338 s\n",
      "Accuracy 0.9295195261079421 precision 0.9295228421463582 specificity 0.8129300037805517 recall 0.9295195261079421 f1 0.9269601230478065\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 20.13200283050537 s\n",
      "Accuracy 0.9297389205792014 precision 0.9296887262369299 specificity 0.8088008726514039 recall 0.9297389205792014 f1 0.9271023147556877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 20.688000917434692 s\n",
      "Accuracy 0.9327555945590171 precision 0.932676924078772 specificity 0.8205258346363108 recall 0.9327555945590171 f1 0.9304531690588053\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 20.499002695083618 s\n",
      "Accuracy 0.9252413339183853 precision 0.9247445085035498 specificity 0.8017590151488296 recall 0.9252413339183853 f1 0.9224809642340799\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 20.434001207351685 s\n",
      "Accuracy 0.9266673979815708 precision 0.9265664122937095 specificity 0.8012313963021188 recall 0.9266673979815708 f1 0.9237973811849901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 20.619003772735596 s\n",
      "Accuracy 0.9271061869240895 precision 0.9269245562036982 specificity 0.8018296923394219 recall 0.9271061869240895 f1 0.9242848605466825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 20.227001667022705 s\n",
      "Accuracy 0.923047389205792 precision 0.9225168611357077 specificity 0.7953408701934163 recall 0.923047389205792 f1 0.9200847997470358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 20.429001331329346 s\n",
      "Accuracy 0.9284225537516455 precision 0.9279917600925652 specificity 0.8119638815610652 recall 0.9284225537516455 f1 0.9259549543189813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 20.539002180099487 s\n",
      "Accuracy 0.9255155770074595 precision 0.9257022338834054 specificity 0.8017768216862685 recall 0.9255155770074595 f1 0.9225526248150802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 20.345001935958862 s\n",
      "Accuracy 0.9295743747257569 precision 0.9293383533453664 specificity 0.8144275277873155 recall 0.9295743747257569 f1 0.9271228443183455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 20.341002225875854 s\n",
      "Accuracy 0.9265028521281263 precision 0.9262137789236119 specificity 0.8054564102463988 recall 0.9265028521281263 f1 0.9237923616038064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 20.26099967956543 s\n",
      "Accuracy 0.9263931548924967 precision 0.9265050170300465 specificity 0.800936622720599 recall 0.9263931548924967 f1 0.9234485861387679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 20.101001501083374 s\n",
      "Accuracy 0.9283677051338306 precision 0.9282267234321213 specificity 0.8073828928558923 recall 0.9283677051338306 f1 0.9256960946785593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 20.157002449035645 s\n",
      "Accuracy 0.9291355857832383 precision 0.9289085417487816 specificity 0.8082676430320174 recall 0.9291355857832383 f1 0.9265271972614008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 20.315001010894775 s\n",
      "Accuracy 0.9311649846423871 precision 0.9306196975952203 specificity 0.8188493469949458 recall 0.9311649846423871 f1 0.9289494498725119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 20.2010018825531 s\n",
      "Accuracy 0.9284225537516455 precision 0.9284067913378046 specificity 0.804856022355781 recall 0.9284225537516455 f1 0.9256542966119026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 20.42100191116333 s\n",
      "Accuracy 0.9268867924528302 precision 0.9267221267419445 specificity 0.8000086449689231 recall 0.9268867924528302 f1 0.9240103388786419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 20.065001964569092 s\n",
      "Accuracy 0.9288064940763493 precision 0.9287800912724125 specificity 0.8053842462011364 recall 0.9288064940763493 f1 0.9260622406129353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 20.26200222969055 s\n",
      "Accuracy 0.9289161913119789 precision 0.9288161891155365 specificity 0.8080280753772217 recall 0.9289161913119789 f1 0.926258993214216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 20.314000844955444 s\n",
      "Accuracy 0.9293001316366828 precision 0.9289823807186455 specificity 0.8090744990375047 recall 0.9293001316366828 f1 0.9267430179168509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 20.295000553131104 s\n",
      "Accuracy 0.925021939447126 precision 0.9246608940587404 specificity 0.8028833363776061 recall 0.925021939447126 f1 0.9222401793572157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 20.36610174179077 s\n",
      "Accuracy 0.931494076349276 precision 0.9313188240326732 specificity 0.816488236370925 recall 0.931494076349276 f1 0.9291069646031962\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 20.21200156211853 s\n",
      "Accuracy 0.9271610355419043 precision 0.9265511627052767 specificity 0.8088922981688791 recall 0.9271610355419043 f1 0.924658351479638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 20.235002040863037 s\n",
      "Accuracy 0.9279837648091268 precision 0.9276711438159511 specificity 0.8064453956308021 recall 0.9279837648091268 f1 0.9253350915443459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 20.32600212097168 s\n",
      "Accuracy 0.9280386134269416 precision 0.9274765019901219 specificity 0.8100834497650649 recall 0.9280386134269416 f1 0.9255644244310316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 19.9990017414093 s\n",
      "Accuracy 0.9268319438350153 precision 0.9266623570383457 specificity 0.8042939628792452 recall 0.9268319438350153 f1 0.9240620594662826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 20.271002054214478 s\n",
      "Accuracy 0.9260640631856077 precision 0.9258252086962336 specificity 0.8013276308462665 recall 0.9260640631856077 f1 0.9232254405521699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 20.392000675201416 s\n",
      "Accuracy 0.9286967968407196 precision 0.9281937901195227 specificity 0.80955293695053 recall 0.9286967968407196 f1 0.9262014444855153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 20.61199975013733 s\n",
      "Accuracy 0.9270513383062747 precision 0.9267840868346409 specificity 0.8044553486407668 recall 0.9270513383062747 f1 0.9243202848726102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 20.103001356124878 s\n",
      "Accuracy 0.9284225537516455 precision 0.9284873239515021 specificity 0.8046118482576421 recall 0.9284225537516455 f1 0.9256254862568157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 20.174999952316284 s\n",
      "Accuracy 0.9248025449758666 precision 0.9245297874889588 specificity 0.7947699412266519 recall 0.9248025449758666 f1 0.9217794528034087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 21.67500114440918 s\n",
      "Accuracy 0.9302874067573497 precision 0.9298134367951153 specificity 0.8106334587410107 recall 0.9302874067573497 f1 0.9278392158157113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 21.927000284194946 s\n",
      "Accuracy 0.9292452830188679 precision 0.9291251959332971 specificity 0.8102129604375565 recall 0.9292452830188679 f1 0.9266526186968939\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 21.82800006866455 s\n",
      "Accuracy 0.9307261956998684 precision 0.9303048193718803 specificity 0.8137703292499064 recall 0.9307261956998684 f1 0.9283416297409043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 21.623003005981445 s\n",
      "Accuracy 0.9249122422114963 precision 0.9249672915121551 specificity 0.7984629362354759 recall 0.9249122422114963 f1 0.9218886129275637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 21.63500213623047 s\n",
      "Accuracy 0.9280934620447565 precision 0.9277102733862532 specificity 0.810785229417086 recall 0.9280934620447565 f1 0.9255752167107182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 21.50400185585022 s\n",
      "Accuracy 0.9271610355419043 precision 0.9267805104915848 specificity 0.8054428753137988 recall 0.9271610355419043 f1 0.9244931836090144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 21.475001096725464 s\n",
      "Accuracy 0.9289710399297938 precision 0.9286901680265846 specificity 0.807142078546059 recall 0.9289710399297938 f1 0.9263493469614954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 21.874001502990723 s\n",
      "Accuracy 0.9248025449758666 precision 0.9241811904100841 specificity 0.8023388598099972 recall 0.9248025449758666 f1 0.9220922781429195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 21.70000123977661 s\n",
      "Accuracy 0.9248025449758666 precision 0.9245758642874062 specificity 0.799995026314317 recall 0.9248025449758666 f1 0.9218994977543953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 21.39000415802002 s\n",
      "Accuracy 0.9270513383062747 precision 0.9265406282355889 specificity 0.8030234633205603 recall 0.9270513383062747 f1 0.9243654338161695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 21.781001806259155 s\n",
      "Accuracy 0.9278192189556823 precision 0.9272090103784508 specificity 0.8055146600938302 recall 0.9278192189556823 f1 0.9252463805959472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 21.708000898361206 s\n",
      "Accuracy 0.9297389205792014 precision 0.9293841385008011 specificity 0.8099167706488498 recall 0.9297389205792014 f1 0.9272226397102377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 21.90200138092041 s\n",
      "Accuracy 0.9273804300131636 precision 0.9271557617182711 specificity 0.8026027324296671 recall 0.9273804300131636 f1 0.9245973555861003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 21.84300136566162 s\n",
      "Accuracy 0.9286967968407196 precision 0.9284421862841915 specificity 0.8040614436850713 recall 0.9286967968407196 f1 0.9259870900194546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 21.50400161743164 s\n",
      "Accuracy 0.9295743747257569 precision 0.9294202288241928 specificity 0.8084524393484691 recall 0.9295743747257569 f1 0.9269570161177428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 21.461002588272095 s\n",
      "Accuracy 0.9265577007459412 precision 0.9258898810144792 specificity 0.8024414523707631 recall 0.9265577007459412 f1 0.9239033263584668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 21.574000358581543 s\n",
      "Accuracy 0.9316037735849056 precision 0.9311154727776163 specificity 0.8147470150333475 recall 0.9316037735849056 f1 0.9292818008615825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 21.611000061035156 s\n",
      "Accuracy 0.9285322509872751 precision 0.927954371916035 specificity 0.8065605973104308 recall 0.9285322509872751 f1 0.9259879317908981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 21.599998950958252 s\n",
      "Accuracy 0.9234313295304958 precision 0.9233914379987088 specificity 0.7975275885750743 recall 0.9234313295304958 f1 0.9203787430851608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 21.847999572753906 s\n",
      "Accuracy 0.927599824484423 precision 0.9276062108524487 specificity 0.8018563370493176 recall 0.927599824484423 f1 0.9247343585556769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 21.69700050354004 s\n",
      "Accuracy 0.9290807371654234 precision 0.9289871026878226 specificity 0.8139194321332704 recall 0.9290807371654234 f1 0.9265646690450176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 21.995999574661255 s\n",
      "Accuracy 0.9274352786309785 precision 0.927715136258555 specificity 0.803088578016815 recall 0.9274352786309785 f1 0.9245211706079512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 21.697996616363525 s\n",
      "Accuracy 0.9292452830188679 precision 0.9286153087780493 specificity 0.8102114696598653 recall 0.9292452830188679 f1 0.9268225618658277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 21.826002597808838 s\n",
      "Accuracy 0.9297937691970163 precision 0.9294406196247954 specificity 0.8131942898532191 recall 0.9297937691970163 f1 0.9273551082457671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 21.942999601364136 s\n",
      "Accuracy 0.9252961825362 precision 0.9250883789148239 specificity 0.7992763595809736 recall 0.9252961825362 f1 0.9223794923889284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 21.546998262405396 s\n",
      "Accuracy 0.9305068012286091 precision 0.9303254675683613 specificity 0.8130830808941656 recall 0.9305068012286091 f1 0.9280246501967261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 21.848000526428223 s\n",
      "Accuracy 0.9264480035103115 precision 0.9259794911144451 specificity 0.8080859414812436 recall 0.9264480035103115 f1 0.9238613524504762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 22.116999626159668 s\n",
      "Accuracy 0.9266673979815708 precision 0.9260352148140711 specificity 0.8052298159208447 recall 0.9266673979815708 f1 0.9240721097805348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 21.29499864578247 s\n",
      "Accuracy 0.9271610355419043 precision 0.9273764469494556 specificity 0.8029462729854007 recall 0.9271610355419043 f1 0.9242546726559122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 21.931999683380127 s\n",
      "Accuracy 0.9302325581395349 precision 0.930027411955326 specificity 0.8144676770778703 recall 0.9302325581395349 f1 0.9277845840300325\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 21.640000104904175 s\n",
      "Accuracy 0.9271610355419043 precision 0.9267660620696317 specificity 0.8083406496049078 recall 0.9271610355419043 f1 0.9245693424066758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 21.283998250961304 s\n",
      "Accuracy 0.9283128565160158 precision 0.927737828536296 specificity 0.8125254465538609 recall 0.9283128565160158 f1 0.9259077771913382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 21.855998039245605 s\n",
      "Accuracy 0.9285322509872751 precision 0.9283328150834882 specificity 0.8091825145815518 recall 0.9285322509872751 f1 0.9259250137384616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 21.78399968147278 s\n",
      "Accuracy 0.9263383062746818 precision 0.9259247000199335 specificity 0.7980503478736278 recall 0.9263383062746818 f1 0.9234794291201606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 21.591999769210815 s\n",
      "Accuracy 0.927928916191312 precision 0.927628811160802 specificity 0.8037646541460709 recall 0.927928916191312 f1 0.9252098287531502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 21.7479989528656 s\n",
      "Accuracy 0.9280386134269416 precision 0.9276212144963529 specificity 0.8116919334282601 recall 0.9280386134269416 f1 0.9255527701092361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 21.5910005569458 s\n",
      "Accuracy 0.9299583150504608 precision 0.929824726704936 specificity 0.8113377198278054 recall 0.9299583150504608 f1 0.9274103058930904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 21.64099907875061 s\n",
      "Accuracy 0.9245831505046073 precision 0.9240740483055808 specificity 0.8005498379482076 recall 0.9245831505046073 f1 0.9217823526876174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 21.774998426437378 s\n",
      "Accuracy 0.9255155770074595 precision 0.9252777062830553 specificity 0.8011811292785803 recall 0.9255155770074595 f1 0.9226613146487146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 21.726996183395386 s\n",
      "Accuracy 0.9263931548924967 precision 0.9260913799289371 specificity 0.8005922730568837 recall 0.9263931548924967 f1 0.9235630178321806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 21.573002576828003 s\n",
      "Accuracy 0.9291355857832383 precision 0.9288055974478326 specificity 0.8099761833119421 recall 0.9291355857832383 f1 0.9266005726915977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 22.029000282287598 s\n",
      "Accuracy 0.9268319438350153 precision 0.926790530563524 specificity 0.8057084422957964 recall 0.9268319438350153 f1 0.9240587699339957\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 21.91299867630005 s\n",
      "Accuracy 0.925954365949978 precision 0.9257928688257885 specificity 0.8021596084483505 recall 0.925954365949978 f1 0.9231105006638413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 21.90899896621704 s\n",
      "Accuracy 0.9242540587977183 precision 0.9239225822037445 specificity 0.797240673859805 recall 0.9242540587977183 f1 0.9213013075763925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 21.532999277114868 s\n",
      "Accuracy 0.9260640631856077 precision 0.9255775268281151 specificity 0.8014581474820991 recall 0.9260640631856077 f1 0.9233097071890217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 21.590999841690063 s\n",
      "Accuracy 0.9279837648091268 precision 0.9275437394615742 specificity 0.8053794567149347 recall 0.9279837648091268 f1 0.9253511815606947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 21.76699924468994 s\n",
      "Accuracy 0.9293001316366828 precision 0.928861865021771 specificity 0.8089435417074172 recall 0.9293001316366828 f1 0.9267798448678376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 21.380999088287354 s\n",
      "Accuracy 0.9287516454585344 precision 0.9281247279105048 specificity 0.8070676993898569 recall 0.9287516454585344 f1 0.9262420768844212\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 21.537999153137207 s\n",
      "Accuracy 0.9295743747257569 precision 0.929426550573813 specificity 0.8111754039024065 recall 0.9295743747257569 f1 0.9270192688829949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 21.56899905204773 s\n",
      "Accuracy 0.9278192189556823 precision 0.9278019097676623 specificity 0.8026277010512187 recall 0.9278192189556823 f1 0.9249842675231629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 21.903000354766846 s\n",
      "Accuracy 0.9291904344010531 precision 0.9289922139408513 specificity 0.8084010347358768 recall 0.9291904344010531 f1 0.9265774167245115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 21.621002435684204 s\n",
      "Accuracy 0.9268867924528302 precision 0.927022976503743 specificity 0.8029069256771064 recall 0.9268867924528302 f1 0.9239951556290295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 21.839998245239258 s\n",
      "Accuracy 0.9310004387889426 precision 0.931043024957852 specificity 0.8097018567354172 recall 0.9310004387889426 f1 0.928384601535636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 21.43695068359375 s\n",
      "Accuracy 0.9251864853005705 precision 0.9245499076037715 specificity 0.8031442091831725 recall 0.9251864853005705 f1 0.9225102271320641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 21.306003093719482 s\n",
      "Accuracy 0.9333589293549802 precision 0.9333230207816618 specificity 0.8149607516658217 recall 0.9333589293549802 f1 0.9309328563680936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 21.61699914932251 s\n",
      "Accuracy 0.927928916191312 precision 0.9277383815521364 specificity 0.8075978938472403 recall 0.927928916191312 f1 0.9252687099256675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 21.862000942230225 s\n",
      "Accuracy 0.9294098288723124 precision 0.9291469239161567 specificity 0.8160314308155534 recall 0.9294098288723124 f1 0.9270014733687397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 21.709999561309814 s\n",
      "Accuracy 0.9254058797718298 precision 0.9249507451065879 specificity 0.8036858878837976 recall 0.9254058797718298 f1 0.9226836657690023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 21.635000705718994 s\n",
      "Accuracy 0.9292452830188679 precision 0.9288750519752206 specificity 0.8076981672953096 recall 0.9292452830188679 f1 0.9266714396678979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 21.484034299850464 s\n",
      "Accuracy 0.9238152698551997 precision 0.9238666207176913 specificity 0.7954001067658222 recall 0.9238152698551997 f1 0.9206890667303285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 21.84502911567688 s\n",
      "Accuracy 0.9274352786309785 precision 0.9271805225699641 specificity 0.8052759457091284 recall 0.9274352786309785 f1 0.9247284016919711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 22.04699969291687 s\n",
      "Accuracy 0.9275449758666081 precision 0.927272733195986 specificity 0.805686590769487 recall 0.9275449758666081 f1 0.924855928109524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 21.879000902175903 s\n",
      "Accuracy 0.9249670908293111 precision 0.9246925294619469 specificity 0.8007824989991714 recall 0.9249670908293111 f1 0.9221026932015945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 21.812999725341797 s\n",
      "Accuracy 0.9320425625274243 precision 0.9319174224181128 specificity 0.8161778491363836 recall 0.9320425625274243 f1 0.929643692161858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 21.696999073028564 s\n",
      "Accuracy 0.9280934620447565 precision 0.92786376398694 specificity 0.8056551680167199 recall 0.9280934620447565 f1 0.925401633394153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 21.646000862121582 s\n",
      "Accuracy 0.9267222465993857 precision 0.9264166052153376 specificity 0.8107142657355689 recall 0.9267222465993857 f1 0.9241514044735694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 21.327998399734497 s\n",
      "Accuracy 0.9270513383062747 precision 0.9263532229860019 specificity 0.8035786178459211 recall 0.9270513383062747 f1 0.9244472725129999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 21.540000677108765 s\n",
      "Accuracy 0.9280934620447565 precision 0.9283387390564874 specificity 0.8039697551980799 recall 0.9280934620447565 f1 0.9252243688184469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 21.648998260498047 s\n",
      "Accuracy 0.9280386134269416 precision 0.9277680632617578 specificity 0.8049447603366436 recall 0.9280386134269416 f1 0.9253412015610407\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 21.686999559402466 s\n",
      "Accuracy 0.9273255813953488 precision 0.9268935810952603 specificity 0.805118455071007 recall 0.9273255813953488 f1 0.9246702832599829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 21.58899760246277 s\n",
      "Accuracy 0.9283677051338306 precision 0.9279481300285012 specificity 0.808751983610398 recall 0.9283677051338306 f1 0.9258178484040958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 21.939033269882202 s\n",
      "Accuracy 0.9268867924528302 precision 0.9265966901542968 specificity 0.8063754180208097 recall 0.9268867924528302 f1 0.9242070626363574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 21.525999546051025 s\n",
      "Accuracy 0.9291355857832383 precision 0.9288555429216276 specificity 0.8109789766569054 recall 0.9291355857832383 f1 0.9266083127757961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 22.041999101638794 s\n",
      "Accuracy 0.9271061869240895 precision 0.9268806134333449 specificity 0.808223713060983 recall 0.9271061869240895 f1 0.9244558865796627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 21.912999629974365 s\n",
      "Accuracy 0.9265028521281263 precision 0.9259552908208852 specificity 0.8011003058275341 recall 0.9265028521281263 f1 0.9237700523401553\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 22.16200041770935 s\n",
      "Accuracy 0.9248025449758666 precision 0.9244905084256579 specificity 0.7975597461121768 recall 0.9248025449758666 f1 0.9218638354664952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 21.95900058746338 s\n",
      "Accuracy 0.927599824484423 precision 0.9273226471871789 specificity 0.8026162434402953 recall 0.927599824484423 f1 0.9248382707802391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 21.840000867843628 s\n",
      "Accuracy 0.9275449758666081 precision 0.9271281952748933 specificity 0.8089278309117962 recall 0.9275449758666081 f1 0.9249823938046824\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 22.553999423980713 s\n",
      "Accuracy 0.9270513383062747 precision 0.9270604880549413 specificity 0.8043239129139378 recall 0.9270513383062747 f1 0.9242339053462865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 22.618876695632935 s\n",
      "Accuracy 0.9286419482229048 precision 0.9282538833245338 specificity 0.8121947238893173 recall 0.9286419482229048 f1 0.9261695323701228\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 21.73757791519165 s\n",
      "Accuracy 0.9301777095217201 precision 0.9301376161351473 specificity 0.8081252054729241 recall 0.9301777095217201 f1 0.927531512962831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 22.059855937957764 s\n",
      "Accuracy 0.9289161913119789 precision 0.9285618685775976 specificity 0.8107422884356584 recall 0.9289161913119789 f1 0.9264030892742137\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 22.310999870300293 s\n",
      "Accuracy 0.9277095217200526 precision 0.9273252404334039 specificity 0.8061864695909333 recall 0.9277095217200526 f1 0.9250723333527107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 22.02860164642334 s\n",
      "Accuracy 0.9268319438350153 precision 0.9265490863980279 specificity 0.8064780284635605 recall 0.9268319438350153 f1 0.9241513491823782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 21.89160180091858 s\n",
      "Accuracy 0.9272158841597192 precision 0.9271739095493554 specificity 0.8067293099746967 recall 0.9272158841597192 f1 0.9244757192776081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 22.038002490997314 s\n",
      "Accuracy 0.9280386134269416 precision 0.9279113092422657 specificity 0.8112113089090716 recall 0.9280386134269416 f1 0.9254486152702529\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 21.92365026473999 s\n",
      "Accuracy 0.9294646774901273 precision 0.9294025545087958 specificity 0.8085067256696825 recall 0.9294646774901273 f1 0.926818954286556\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 21.367795944213867 s\n",
      "Accuracy 0.9292452830188679 precision 0.9288691548844572 specificity 0.8081494293236715 recall 0.9292452830188679 f1 0.926684134549177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 21.469698667526245 s\n",
      "Accuracy 0.9313295304958316 precision 0.9306469522047296 specificity 0.8193755941165707 recall 0.9313295304958316 f1 0.9291817013597266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 21.586332321166992 s\n",
      "Accuracy 0.9297937691970163 precision 0.9293938695239431 specificity 0.810096438530165 recall 0.9297937691970163 f1 0.9272977889953844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 21.747999906539917 s\n",
      "Accuracy 0.925680122860904 precision 0.925947005358068 specificity 0.7939831416724878 recall 0.925680122860904 f1 0.9225014239016257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 22.15200114250183 s\n",
      "Accuracy 0.9261189118034225 precision 0.9257249749092112 specificity 0.8010060591603371 recall 0.9261189118034225 f1 0.9233231548578851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 21.911470651626587 s\n",
      "Accuracy 0.9258995173321632 precision 0.925325697734703 specificity 0.8022388419766496 recall 0.9258995173321632 f1 0.9231919885629174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 21.91330075263977 s\n",
      "Accuracy 0.9284225537516455 precision 0.9281273481461223 specificity 0.8070053156204517 recall 0.9284225537516455 f1 0.9257908321058481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 21.81730079650879 s\n",
      "Accuracy 0.9261737604212373 precision 0.9255288058708434 specificity 0.8046571595079037 recall 0.9261737604212373 f1 0.9235588920400565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 21.922029495239258 s\n",
      "Accuracy 0.925954365949978 precision 0.9254908635408452 specificity 0.8076393928455733 recall 0.925954365949978 f1 0.9233455034777507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 21.79715323448181 s\n",
      "Accuracy 0.9286419482229048 precision 0.9282829072060298 specificity 0.8078286867439707 recall 0.9286419482229048 f1 0.9260551946982283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 21.840546131134033 s\n",
      "Accuracy 0.9283128565160158 precision 0.9277298100566593 specificity 0.8061029368097887 recall 0.9283128565160158 f1 0.9257547409792748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 22.112350702285767 s\n",
      "Accuracy 0.9258446687143485 precision 0.925022050891621 specificity 0.8057006930394893 recall 0.9258446687143485 f1 0.9233189130659308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 22.24250888824463 s\n",
      "Accuracy 0.9263383062746818 precision 0.9261647679733818 specificity 0.8079637851102949 recall 0.9263383062746818 f1 0.9236507565901703\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 21.688521146774292 s\n",
      "Accuracy 0.928258007898201 precision 0.9277801262099464 specificity 0.8096573608783264 recall 0.928258007898201 f1 0.9257478468610387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 22.17249631881714 s\n",
      "Accuracy 0.9260092145677928 precision 0.9257349181701626 specificity 0.801695741974373 recall 0.9260092145677928 f1 0.9231898169016235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 21.767998218536377 s\n",
      "Accuracy 0.9271061869240895 precision 0.9266209720728927 specificity 0.8044788997401097 recall 0.9271061869240895 f1 0.9244487178963177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 21.631999254226685 s\n",
      "Accuracy 0.9288613426941641 precision 0.9287424528895788 specificity 0.8108275232706001 recall 0.9288613426941641 f1 0.9262753629017851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 22.139577865600586 s\n",
      "Accuracy 0.9286967968407196 precision 0.9281332372349166 specificity 0.8113253886587402 recall 0.9286967968407196 f1 0.9262657268060163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 21.789430856704712 s\n",
      "Accuracy 0.9270513383062747 precision 0.9268109131685829 specificity 0.8034472577735616 recall 0.9270513383062747 f1 0.9242869659147717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 21.71500039100647 s\n",
      "Accuracy 0.9263931548924967 precision 0.9260238712258722 specificity 0.8040996081584058 recall 0.9263931548924967 f1 0.9236726058909197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 21.29500150680542 s\n",
      "Accuracy 0.9251316366827556 precision 0.9247445891161332 specificity 0.7999813493361245 recall 0.9251316366827556 f1 0.9222865303343131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 21.680257320404053 s\n",
      "Accuracy 0.9297389205792014 precision 0.9295307044003874 specificity 0.8080866098845119 recall 0.9297389205792014 f1 0.9271328729912995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 22.154889583587646 s\n",
      "Accuracy 0.9268867924528302 precision 0.927064935270768 specificity 0.8032171018923909 recall 0.9268867924528302 f1 0.9239913202820252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 21.740076065063477 s\n",
      "Accuracy 0.924692847740237 precision 0.9248436339134943 specificity 0.8001727532291051 recall 0.924692847740237 f1 0.9216814570238175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 22.019787549972534 s\n",
      "Accuracy 0.927270732777534 precision 0.9269247786698284 specificity 0.8031490069920678 recall 0.927270732777534 f1 0.9245372569185293\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 22.521326780319214 s\n",
      "Accuracy 0.9295195261079421 precision 0.9295161217803823 specificity 0.8041095860554422 recall 0.9295195261079421 f1 0.926753871799601\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 21.97699999809265 s\n",
      "Accuracy 0.927270732777534 precision 0.9270638150155753 specificity 0.8076072459764138 recall 0.927270732777534 f1 0.9246027318805965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 21.70599937438965 s\n",
      "Accuracy 0.9280934620447565 precision 0.9278864735686896 specificity 0.8044142107923015 recall 0.9280934620447565 f1 0.92536448781624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 21.99100112915039 s\n",
      "Accuracy 0.9282031592803861 precision 0.9281901164208702 specificity 0.8097121425377969 recall 0.9282031592803861 f1 0.9255465680932116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 22.48299813270569 s\n",
      "Accuracy 0.9276546731022378 precision 0.9276838377016043 specificity 0.8041074653411554 recall 0.9276546731022378 f1 0.9248389549845712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 22.079001903533936 s\n",
      "Accuracy 0.9336331724440544 precision 0.9334860311789006 specificity 0.8178256862132395 recall 0.9336331724440544 f1 0.9313082352865754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 22.14799666404724 s\n",
      "Accuracy 0.9266673979815708 precision 0.9264220890368259 specificity 0.8037681835352277 recall 0.9266673979815708 f1 0.9239044708646684\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 22.27199959754944 s\n",
      "Accuracy 0.9249122422114963 precision 0.9248304910310329 specificity 0.7945428105069251 recall 0.9249122422114963 f1 0.9218276154720991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 22.542999029159546 s\n",
      "Accuracy 0.9287516454585344 precision 0.928545106982091 specificity 0.8113797382866905 recall 0.9287516454585344 f1 0.9262034003867868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 22.564001321792603 s\n",
      "Accuracy 0.9282031592803861 precision 0.9282034246370435 specificity 0.8103706708953818 recall 0.9282031592803861 f1 0.9255585682138182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 22.276999473571777 s\n",
      "Accuracy 0.9272158841597192 precision 0.9267492027027786 specificity 0.800050821918403 recall 0.9272158841597192 f1 0.9244445872672227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 21.572999715805054 s\n",
      "Accuracy 0.9305068012286091 precision 0.9303265289957074 specificity 0.8131378174828434 recall 0.9305068012286091 f1 0.9280255916368276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 22.47499966621399 s\n",
      "Accuracy 0.9261737604212373 precision 0.9259057771046098 specificity 0.8034915166047009 recall 0.9261737604212373 f1 0.9234008678515552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 22.32499885559082 s\n",
      "Accuracy 0.9283128565160158 precision 0.92814721499373 specificity 0.805899393751449 recall 0.9283128565160158 f1 0.9256118127879841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 21.952999591827393 s\n",
      "Accuracy 0.9271061869240895 precision 0.9267955332107923 specificity 0.8092891709750448 recall 0.9271061869240895 f1 0.9245090439068427\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 22.186999797821045 s\n",
      "Accuracy 0.9257349714787187 precision 0.9254667755353787 specificity 0.8030150923989746 recall 0.9257349714787187 f1 0.9229411619715149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 22.370998859405518 s\n",
      "Accuracy 0.9272158841597192 precision 0.9272396815056102 specificity 0.8033449866355914 recall 0.9272158841597192 f1 0.9243736379767561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 22.163997411727905 s\n",
      "Accuracy 0.9291904344010531 precision 0.9286546111432431 specificity 0.8126866743818336 recall 0.9291904344010531 f1 0.92679126856118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 22.202998876571655 s\n",
      "Accuracy 0.9265028521281263 precision 0.9258590884655702 specificity 0.7999935873920728 recall 0.9265028521281263 f1 0.9237766730697324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 21.077508687973022 s\n",
      "Accuracy 0.927928916191312 precision 0.9271695817696126 specificity 0.808414996873372 recall 0.927928916191312 f1 0.9254866374526733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 20.687707901000977 s\n",
      "Accuracy 0.9250767880649408 precision 0.9250000254548338 specificity 0.7955685098974705 recall 0.9250767880649408 f1 0.9220208636808648\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 22.066999912261963 s\n",
      "Accuracy 0.9300131636682756 precision 0.9298987043607917 specificity 0.8133772744411187 recall 0.9300131636682756 f1 0.9275080878335553\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 21.868999004364014 s\n",
      "Accuracy 0.926941641070645 precision 0.9263740586327419 specificity 0.8093944786152247 recall 0.926941641070645 f1 0.9244317883824921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 21.7579984664917 s\n",
      "Accuracy 0.9250767880649408 precision 0.9249425960143575 specificity 0.7985547334797201 recall 0.9250767880649408 f1 0.9221144599521416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 22.21099853515625 s\n",
      "Accuracy 0.9265577007459412 precision 0.9265648112136825 specificity 0.8083169231513098 recall 0.9265577007459412 f1 0.9238294631464635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 22.309998989105225 s\n",
      "Accuracy 0.9275449758666081 precision 0.9274659876394515 specificity 0.8024283415979072 recall 0.9275449758666081 f1 0.9247171437710665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 22.36900234222412 s\n",
      "Accuracy 0.9235958753839403 precision 0.9232088186027526 specificity 0.7984356540116219 recall 0.9235958753839403 f1 0.9206783049472219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 22.710999011993408 s\n",
      "Accuracy 0.9274352786309785 precision 0.9272750899008303 specificity 0.8028210868121478 recall 0.9274352786309785 f1 0.9246389799825049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 22.255001068115234 s\n",
      "Accuracy 0.925954365949978 precision 0.9254229302222112 specificity 0.8016989796301387 recall 0.925954365949978 f1 0.9232193363679907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 23.309001684188843 s\n",
      "Accuracy 0.9240895129442738 precision 0.9239707790051289 specificity 0.7954339883705538 recall 0.9240895129442738 f1 0.9210200907094734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 23.216000080108643 s\n",
      "Accuracy 0.9245831505046073 precision 0.9242305082872337 specificity 0.7999221837799985 recall 0.9245831505046073 f1 0.9217136754541415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 22.881998538970947 s\n",
      "Accuracy 0.9255704256252743 precision 0.9249508467003296 specificity 0.798078629588089 recall 0.9255704256252743 f1 0.9227661845100116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 21.98499870300293 s\n",
      "Accuracy 0.9278192189556823 precision 0.9272915617135987 specificity 0.8095290959267704 recall 0.9278192189556823 f1 0.9253149696559595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 21.875999927520752 s\n",
      "Accuracy 0.9283128565160158 precision 0.9281161784997891 specificity 0.809844625783085 recall 0.9283128565160158 f1 0.9257163600975004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 22.7860004901886 s\n",
      "Accuracy 0.9279837648091268 precision 0.9275355137101472 specificity 0.8049767103892489 recall 0.9279837648091268 f1 0.925344142214514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 22.311644315719604 s\n",
      "Accuracy 0.925021939447126 precision 0.9243498428913933 specificity 0.8028071502617643 recall 0.925021939447126 f1 0.9223468858427959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 22.389657258987427 s\n",
      "Accuracy 0.9288064940763493 precision 0.9284969736944789 specificity 0.8087791371255708 recall 0.9288064940763493 f1 0.9262297515014694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 22.235116720199585 s\n",
      "Accuracy 0.9235958753839403 precision 0.9237917924660369 specificity 0.7897343536593013 recall 0.9235958753839403 f1 0.9202752940747179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 22.000207901000977 s\n",
      "Accuracy 0.9284774023694603 precision 0.9282119097987339 specificity 0.8071968956593492 recall 0.9284774023694603 f1 0.9258419790146651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 21.99804162979126 s\n",
      "Accuracy 0.9263383062746818 precision 0.9259616189574724 specificity 0.8027783318042202 recall 0.9263383062746818 f1 0.9235860114918857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 21.795205116271973 s\n",
      "Accuracy 0.9306713470820536 precision 0.9302688505460079 specificity 0.8115879954056856 recall 0.9306713470820536 f1 0.928228722694517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 21.666940689086914 s\n",
      "Accuracy 0.9289161913119789 precision 0.9291242711016081 specificity 0.8064729933584726 recall 0.9289161913119789 f1 0.9261350250568519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 22.07442307472229 s\n",
      "Accuracy 0.9313295304958316 precision 0.9308017141997444 specificity 0.8197564435244803 recall 0.9313295304958316 f1 0.9291312793505452\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 22.985642671585083 s\n",
      "Accuracy 0.9267770952172005 precision 0.9266112893630607 specificity 0.8095894926457577 recall 0.9267770952172005 f1 0.924135631844101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 22.674811601638794 s\n",
      "Accuracy 0.9289161913119789 precision 0.9284465771647644 specificity 0.8107302823480941 recall 0.9289161913119789 f1 0.9264417199483873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 21.734999656677246 s\n",
      "Accuracy 0.9269964896884598 precision 0.9264895299764894 specificity 0.8098617274536688 recall 0.9269964896884598 f1 0.9244775607490404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 22.01795506477356 s\n",
      "Accuracy 0.9282031592803861 precision 0.9275320860703282 specificity 0.8137477860526892 recall 0.9282031592803861 f1 0.9258619699622201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 22.087260007858276 s\n",
      "Accuracy 0.9232119350592365 precision 0.9227586757585021 specificity 0.7952580232709778 recall 0.9232119350592365 f1 0.9202244161632132\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, seed in enumerate(seeds):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.926832     0.805380   0.926800  0.926832  0.924048\n1  0.927764     0.801657   0.927682  0.927764  0.924924\n2  0.927490     0.806547   0.927288  0.927490  0.924799\n3  0.928258     0.805667   0.927966  0.928258  0.925589\n4  0.930507     0.811990   0.930727  0.930507  0.927885\n5  0.927216     0.809894   0.926556  0.927216  0.924758\n6  0.922663     0.797629   0.922515  0.922663  0.919630\n7  0.927984     0.804537   0.927425  0.927984  0.925372\n8  0.928093     0.809658   0.927821  0.928093  0.925512\n9  0.931549     0.818879   0.931026  0.931549  0.929333",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.926832</td>\n      <td>0.805380</td>\n      <td>0.926800</td>\n      <td>0.926832</td>\n      <td>0.924048</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.927764</td>\n      <td>0.801657</td>\n      <td>0.927682</td>\n      <td>0.927764</td>\n      <td>0.924924</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.927490</td>\n      <td>0.806547</td>\n      <td>0.927288</td>\n      <td>0.927490</td>\n      <td>0.924799</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.928258</td>\n      <td>0.805667</td>\n      <td>0.927966</td>\n      <td>0.928258</td>\n      <td>0.925589</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.930507</td>\n      <td>0.811990</td>\n      <td>0.930727</td>\n      <td>0.930507</td>\n      <td>0.927885</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.927216</td>\n      <td>0.809894</td>\n      <td>0.926556</td>\n      <td>0.927216</td>\n      <td>0.924758</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.922663</td>\n      <td>0.797629</td>\n      <td>0.922515</td>\n      <td>0.922663</td>\n      <td>0.919630</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.927984</td>\n      <td>0.804537</td>\n      <td>0.927425</td>\n      <td>0.927984</td>\n      <td>0.925372</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.928093</td>\n      <td>0.809658</td>\n      <td>0.927821</td>\n      <td>0.928093</td>\n      <td>0.925512</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.931549</td>\n      <td>0.818879</td>\n      <td>0.931026</td>\n      <td>0.931549</td>\n      <td>0.929333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.9276100811759544\n",
      "Precision 0.9273246684250176\n",
      "Specificity 0.8060272920838404\n",
      "Recall 0.9276100811759544\n",
      "F1 0.9249356525151786\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_6beats_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}