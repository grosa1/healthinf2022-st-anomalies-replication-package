{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Paper CHF - 6 beats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sU5Wt4HhzLod"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3      dw_4      dw_5     mfw_1  \\\n0  e0106  21.861233  21.421103  21.536569  6.108208  0.880920  1.079942   \n1  e0106  26.408089  27.988299  27.611772  7.776970  1.129695  1.195165   \n2  e0106  25.977641  26.935251  26.561891  7.477219  1.098311  1.176663   \n3  e0106  25.189643  25.649484  25.620624  7.261496  1.066191  1.162694   \n4  e0106  24.659920  24.559022  24.462891  6.972141  1.008067  1.143318   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.914392 -1.844370 -1.138702  ... -0.068189  0.053454 -0.067161  0.067961   \n1 -0.806390 -1.774080 -1.792590  ... -0.031130  0.017521 -0.014034  0.023165   \n2 -0.849446 -1.805917 -1.623971  ... -0.025147  0.006059 -0.022267  0.043209   \n3 -0.825414 -1.684836 -1.477246  ... -0.040045  0.024580 -0.029490  0.040770   \n4 -0.881397 -1.797336 -1.316414  ... -0.064038  0.044904 -0.045340  0.042700   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.093129  0.027961 -0.038417 -0.011442  0.005966    NSR  \n1 -0.043346 -0.016159 -0.012820 -0.007157 -0.012377    NSR  \n2 -0.061407 -0.003576 -0.026326  0.004760 -0.015544    NSR  \n3 -0.057996 -0.012361 -0.019814  0.007333 -0.030823    NSR  \n4 -0.063328 -0.010253 -0.004272 -0.024278  0.001717    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>21.861233</td>\n      <td>21.421103</td>\n      <td>21.536569</td>\n      <td>6.108208</td>\n      <td>0.880920</td>\n      <td>1.079942</td>\n      <td>-0.914392</td>\n      <td>-1.844370</td>\n      <td>-1.138702</td>\n      <td>...</td>\n      <td>-0.068189</td>\n      <td>0.053454</td>\n      <td>-0.067161</td>\n      <td>0.067961</td>\n      <td>-0.093129</td>\n      <td>0.027961</td>\n      <td>-0.038417</td>\n      <td>-0.011442</td>\n      <td>0.005966</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>26.408089</td>\n      <td>27.988299</td>\n      <td>27.611772</td>\n      <td>7.776970</td>\n      <td>1.129695</td>\n      <td>1.195165</td>\n      <td>-0.806390</td>\n      <td>-1.774080</td>\n      <td>-1.792590</td>\n      <td>...</td>\n      <td>-0.031130</td>\n      <td>0.017521</td>\n      <td>-0.014034</td>\n      <td>0.023165</td>\n      <td>-0.043346</td>\n      <td>-0.016159</td>\n      <td>-0.012820</td>\n      <td>-0.007157</td>\n      <td>-0.012377</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>25.977641</td>\n      <td>26.935251</td>\n      <td>26.561891</td>\n      <td>7.477219</td>\n      <td>1.098311</td>\n      <td>1.176663</td>\n      <td>-0.849446</td>\n      <td>-1.805917</td>\n      <td>-1.623971</td>\n      <td>...</td>\n      <td>-0.025147</td>\n      <td>0.006059</td>\n      <td>-0.022267</td>\n      <td>0.043209</td>\n      <td>-0.061407</td>\n      <td>-0.003576</td>\n      <td>-0.026326</td>\n      <td>0.004760</td>\n      <td>-0.015544</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>25.189643</td>\n      <td>25.649484</td>\n      <td>25.620624</td>\n      <td>7.261496</td>\n      <td>1.066191</td>\n      <td>1.162694</td>\n      <td>-0.825414</td>\n      <td>-1.684836</td>\n      <td>-1.477246</td>\n      <td>...</td>\n      <td>-0.040045</td>\n      <td>0.024580</td>\n      <td>-0.029490</td>\n      <td>0.040770</td>\n      <td>-0.057996</td>\n      <td>-0.012361</td>\n      <td>-0.019814</td>\n      <td>0.007333</td>\n      <td>-0.030823</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>24.659920</td>\n      <td>24.559022</td>\n      <td>24.462891</td>\n      <td>6.972141</td>\n      <td>1.008067</td>\n      <td>1.143318</td>\n      <td>-0.881397</td>\n      <td>-1.797336</td>\n      <td>-1.316414</td>\n      <td>...</td>\n      <td>-0.064038</td>\n      <td>0.044904</td>\n      <td>-0.045340</td>\n      <td>0.042700</td>\n      <td>-0.063328</td>\n      <td>-0.010253</td>\n      <td>-0.004272</td>\n      <td>-0.024278</td>\n      <td>0.001717</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_6beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    69911\nST     21247\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.255941  0.126826  0.086712  0.088051  0.075713 -0.024569   \ndw_2    0.255941  1.000000  0.839774  0.443129  0.156197  0.418729 -0.461763   \ndw_3    0.126826  0.839774  1.000000  0.617379  0.233068  0.346060 -0.532862   \ndw_4    0.086712  0.443129  0.617379  1.000000  0.899451  0.053813 -0.237258   \ndw_5    0.088051  0.156197  0.233068  0.899451  1.000000 -0.086599 -0.014596   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.032264  0.028086  0.046009  0.039039  0.015851 -0.077794  0.050496   \ncfr_13 -0.023128  0.110780  0.046174  0.024440  0.009964  0.068140  0.004871   \ncfr_14 -0.040651 -0.007514 -0.030837 -0.029533 -0.028118  0.011829  0.019891   \ncfr_15 -0.060588 -0.119066 -0.133170 -0.087767 -0.040683 -0.021598  0.089608   \ncfr_16 -0.042833 -0.078764 -0.047183 -0.029773 -0.015438  0.032908 -0.030729   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.012953 -0.001384  0.002394  ... -0.045708 -0.051747 -0.019303   \ndw_2   -0.218036 -0.003468  0.007413  ... -0.141060  0.127367  0.228143   \ndw_3   -0.300954 -0.002069  0.003404  ... -0.206438  0.110265  0.261460   \ndw_4   -0.145344 -0.000228  0.000760  ... -0.142178  0.036774  0.117609   \ndw_5   -0.019561  0.000277 -0.000251  ... -0.064023 -0.004814  0.020295   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.076659 -0.000726  0.004327  ... -0.121386 -0.206635 -0.113087   \ncfr_13  0.004627  0.000306  0.000798  ...  0.120777  0.028507 -0.219328   \ncfr_14  0.024541  0.001952 -0.001142  ...  0.088392  0.207586  0.043674   \ncfr_15  0.046544  0.005107 -0.006644  ...  0.251295  0.160789 -0.072934   \ncfr_16  0.002356  0.007116 -0.004854  ...  0.229052  0.144069  0.166645   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.008486 -0.000878 -0.032264 -0.023128 -0.040651 -0.060588 -0.042833  \ndw_2    0.164508  0.044436  0.028086  0.110780 -0.007514 -0.119066 -0.078764  \ndw_3    0.116256 -0.047562  0.046009  0.046174 -0.030837 -0.133170 -0.047183  \ndw_4    0.038427 -0.043639  0.039039  0.024440 -0.029533 -0.087767 -0.029773  \ndw_5    0.008379 -0.014492  0.015851  0.009964 -0.028118 -0.040683 -0.015438  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.008140  0.053560  1.000000 -0.006207 -0.033331 -0.303526 -0.194998  \ncfr_13 -0.269074 -0.065839 -0.006207  1.000000  0.164767  0.075217 -0.175495  \ncfr_14 -0.179302 -0.289882 -0.033331  0.164767  1.000000  0.131088 -0.151555  \ncfr_15 -0.151000 -0.104688 -0.303526  0.075217  0.131088  1.000000  0.190121  \ncfr_16  0.094130 -0.009039 -0.194998 -0.175495 -0.151555  0.190121  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.255941</td>\n      <td>0.126826</td>\n      <td>0.086712</td>\n      <td>0.088051</td>\n      <td>0.075713</td>\n      <td>-0.024569</td>\n      <td>0.012953</td>\n      <td>-0.001384</td>\n      <td>0.002394</td>\n      <td>...</td>\n      <td>-0.045708</td>\n      <td>-0.051747</td>\n      <td>-0.019303</td>\n      <td>-0.008486</td>\n      <td>-0.000878</td>\n      <td>-0.032264</td>\n      <td>-0.023128</td>\n      <td>-0.040651</td>\n      <td>-0.060588</td>\n      <td>-0.042833</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.255941</td>\n      <td>1.000000</td>\n      <td>0.839774</td>\n      <td>0.443129</td>\n      <td>0.156197</td>\n      <td>0.418729</td>\n      <td>-0.461763</td>\n      <td>-0.218036</td>\n      <td>-0.003468</td>\n      <td>0.007413</td>\n      <td>...</td>\n      <td>-0.141060</td>\n      <td>0.127367</td>\n      <td>0.228143</td>\n      <td>0.164508</td>\n      <td>0.044436</td>\n      <td>0.028086</td>\n      <td>0.110780</td>\n      <td>-0.007514</td>\n      <td>-0.119066</td>\n      <td>-0.078764</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.126826</td>\n      <td>0.839774</td>\n      <td>1.000000</td>\n      <td>0.617379</td>\n      <td>0.233068</td>\n      <td>0.346060</td>\n      <td>-0.532862</td>\n      <td>-0.300954</td>\n      <td>-0.002069</td>\n      <td>0.003404</td>\n      <td>...</td>\n      <td>-0.206438</td>\n      <td>0.110265</td>\n      <td>0.261460</td>\n      <td>0.116256</td>\n      <td>-0.047562</td>\n      <td>0.046009</td>\n      <td>0.046174</td>\n      <td>-0.030837</td>\n      <td>-0.133170</td>\n      <td>-0.047183</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.086712</td>\n      <td>0.443129</td>\n      <td>0.617379</td>\n      <td>1.000000</td>\n      <td>0.899451</td>\n      <td>0.053813</td>\n      <td>-0.237258</td>\n      <td>-0.145344</td>\n      <td>-0.000228</td>\n      <td>0.000760</td>\n      <td>...</td>\n      <td>-0.142178</td>\n      <td>0.036774</td>\n      <td>0.117609</td>\n      <td>0.038427</td>\n      <td>-0.043639</td>\n      <td>0.039039</td>\n      <td>0.024440</td>\n      <td>-0.029533</td>\n      <td>-0.087767</td>\n      <td>-0.029773</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.088051</td>\n      <td>0.156197</td>\n      <td>0.233068</td>\n      <td>0.899451</td>\n      <td>1.000000</td>\n      <td>-0.086599</td>\n      <td>-0.014596</td>\n      <td>-0.019561</td>\n      <td>0.000277</td>\n      <td>-0.000251</td>\n      <td>...</td>\n      <td>-0.064023</td>\n      <td>-0.004814</td>\n      <td>0.020295</td>\n      <td>0.008379</td>\n      <td>-0.014492</td>\n      <td>0.015851</td>\n      <td>0.009964</td>\n      <td>-0.028118</td>\n      <td>-0.040683</td>\n      <td>-0.015438</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.032264</td>\n      <td>0.028086</td>\n      <td>0.046009</td>\n      <td>0.039039</td>\n      <td>0.015851</td>\n      <td>-0.077794</td>\n      <td>0.050496</td>\n      <td>0.076659</td>\n      <td>-0.000726</td>\n      <td>0.004327</td>\n      <td>...</td>\n      <td>-0.121386</td>\n      <td>-0.206635</td>\n      <td>-0.113087</td>\n      <td>0.008140</td>\n      <td>0.053560</td>\n      <td>1.000000</td>\n      <td>-0.006207</td>\n      <td>-0.033331</td>\n      <td>-0.303526</td>\n      <td>-0.194998</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.023128</td>\n      <td>0.110780</td>\n      <td>0.046174</td>\n      <td>0.024440</td>\n      <td>0.009964</td>\n      <td>0.068140</td>\n      <td>0.004871</td>\n      <td>0.004627</td>\n      <td>0.000306</td>\n      <td>0.000798</td>\n      <td>...</td>\n      <td>0.120777</td>\n      <td>0.028507</td>\n      <td>-0.219328</td>\n      <td>-0.269074</td>\n      <td>-0.065839</td>\n      <td>-0.006207</td>\n      <td>1.000000</td>\n      <td>0.164767</td>\n      <td>0.075217</td>\n      <td>-0.175495</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.040651</td>\n      <td>-0.007514</td>\n      <td>-0.030837</td>\n      <td>-0.029533</td>\n      <td>-0.028118</td>\n      <td>0.011829</td>\n      <td>0.019891</td>\n      <td>0.024541</td>\n      <td>0.001952</td>\n      <td>-0.001142</td>\n      <td>...</td>\n      <td>0.088392</td>\n      <td>0.207586</td>\n      <td>0.043674</td>\n      <td>-0.179302</td>\n      <td>-0.289882</td>\n      <td>-0.033331</td>\n      <td>0.164767</td>\n      <td>1.000000</td>\n      <td>0.131088</td>\n      <td>-0.151555</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.060588</td>\n      <td>-0.119066</td>\n      <td>-0.133170</td>\n      <td>-0.087767</td>\n      <td>-0.040683</td>\n      <td>-0.021598</td>\n      <td>0.089608</td>\n      <td>0.046544</td>\n      <td>0.005107</td>\n      <td>-0.006644</td>\n      <td>...</td>\n      <td>0.251295</td>\n      <td>0.160789</td>\n      <td>-0.072934</td>\n      <td>-0.151000</td>\n      <td>-0.104688</td>\n      <td>-0.303526</td>\n      <td>0.075217</td>\n      <td>0.131088</td>\n      <td>1.000000</td>\n      <td>0.190121</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.042833</td>\n      <td>-0.078764</td>\n      <td>-0.047183</td>\n      <td>-0.029773</td>\n      <td>-0.015438</td>\n      <td>0.032908</td>\n      <td>-0.030729</td>\n      <td>0.002356</td>\n      <td>0.007116</td>\n      <td>-0.004854</td>\n      <td>...</td>\n      <td>0.229052</td>\n      <td>0.144069</td>\n      <td>0.166645</td>\n      <td>0.094130</td>\n      <td>-0.009039</td>\n      <td>-0.194998</td>\n      <td>-0.175495</td>\n      <td>-0.151555</td>\n      <td>0.190121</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows Ã— 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()\n",
    "patient_ids = data[\"id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_150', 'fft_175', 'fft_204', 'fft_227', 'fft_203', 'fft_213', 'fft_217', 'fft_179', 'fft_224', 'fft_250', 'fft_158', 'fft_205', 'mfw_6', 'fft_208', 'fft_155', 'fft_244', 'fft_142', 'fft_173', 'fft_190', 'fft_145', 'fft_154', 'fft_197', 'fft_251', 'fft_202', 'fft_196', 'fft_186', 'fft_177', 'fft_148', 'fft_252', 'fft_147', 'fft_237', 'fft_184', 'fft_181', 'fft_195', 'fft_206', 'fft_216', 'fft_246', 'fft_165', 'mfw_16', 'fft_200', 'fft_178', 'fft_207', 'mfw_13', 'fft_193', 'fft_135', 'fft_156', 'fft_219', 'fft_160', 'fft_212', 'mfw_9', 'fft_170', 'fft_172', 'fft_254', 'fft_247', 'fft_131', 'fft_211', 'fft_185', 'fft_239', 'fft_243', 'cfr_16', 'fft_130', 'fft_240', 'fft_249', 'fft_255', 'fft_188', 'fft_229', 'fft_164', 'fft_226', 'fft_192', 'fft_230', 'fft_162', 'mfw_10', 'fft_149', 'fft_189', 'fft_169', 'fft_222', 'mfw_8', 'mfw_11', 'fft_220', 'fft_171', 'fft_194', 'mfw_12', 'fft_242', 'fft_218', 'fft_144', 'fft_182', 'fft_159', 'mfw_14', 'mfw_15', 'fft_138', 'fft_153', 'fft_134', 'fft_187', 'fft_166', 'fft_214', 'fft_151', 'fft_228', 'fft_183', 'fft_157', 'fft_221', 'fft_132', 'fft_141', 'fft_191', 'fft_234', 'fft_140', 'fft_235', 'fft_199', 'fft_180', 'fft_215', 'fft_253', 'fft_163', 'fft_248', 'fft_133', 'fft_238', 'mfw_5', 'fft_174', 'fft_210', 'fft_146', 'fft_256', 'fft_223', 'fft_167', 'fft_136', 'fft_168', 'fft_225', 'fft_143', 'fft_176', 'mfw_7', 'fft_233', 'fft_231', 'fft_209', 'fft_245', 'fft_198', 'fft_137', 'fft_232', 'fft_236', 'fft_241', 'fft_161', 'fft_139', 'fft_201', 'fft_152'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_24\n",
      "fft_25\n",
      "fft_27\n",
      "fft_28\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "fft_37\n",
      "fft_38\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 76\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization best features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\n0  21.861233  21.421103  21.536569  6.108208  0.880920  1.079942 -0.914392   \n1  26.408089  27.988299  27.611772  7.776970  1.129695  1.195165 -0.806390   \n2  25.977641  26.935251  26.561891  7.477219  1.098311  1.176663 -0.849446   \n3  25.189643  25.649484  25.620624  7.261496  1.066191  1.162694 -0.825414   \n4  24.659920  24.559022  24.462891  6.972141  1.008067  1.143318 -0.881397   \n\n      mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -1.844370 -1.138702 -0.004752  ...  0.006001  0.061446 -0.068189  0.053454   \n1 -1.774080 -1.792590  0.205786  ...  0.027369  0.028651 -0.031130  0.017521   \n2 -1.805917 -1.623971 -0.321053  ...  0.008456  0.040828 -0.025147  0.006059   \n3 -1.684836 -1.477246  3.056053  ...  0.029771  0.026605 -0.040045  0.024580   \n4 -1.797336 -1.316414  6.265323  ... -0.010154  0.059279 -0.064038  0.044904   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.067161  0.067961 -0.093129  0.027961 -0.038417 -0.011442  \n1 -0.014034  0.023165 -0.043346 -0.016159 -0.012820 -0.007157  \n2 -0.022267  0.043209 -0.061407 -0.003576 -0.026326  0.004760  \n3 -0.029490  0.040770 -0.057996 -0.012361 -0.019814  0.007333  \n4 -0.045340  0.042700 -0.063328 -0.010253 -0.004272 -0.024278  \n\n[5 rows x 76 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21.861233</td>\n      <td>21.421103</td>\n      <td>21.536569</td>\n      <td>6.108208</td>\n      <td>0.880920</td>\n      <td>1.079942</td>\n      <td>-0.914392</td>\n      <td>-1.844370</td>\n      <td>-1.138702</td>\n      <td>-0.004752</td>\n      <td>...</td>\n      <td>0.006001</td>\n      <td>0.061446</td>\n      <td>-0.068189</td>\n      <td>0.053454</td>\n      <td>-0.067161</td>\n      <td>0.067961</td>\n      <td>-0.093129</td>\n      <td>0.027961</td>\n      <td>-0.038417</td>\n      <td>-0.011442</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26.408089</td>\n      <td>27.988299</td>\n      <td>27.611772</td>\n      <td>7.776970</td>\n      <td>1.129695</td>\n      <td>1.195165</td>\n      <td>-0.806390</td>\n      <td>-1.774080</td>\n      <td>-1.792590</td>\n      <td>0.205786</td>\n      <td>...</td>\n      <td>0.027369</td>\n      <td>0.028651</td>\n      <td>-0.031130</td>\n      <td>0.017521</td>\n      <td>-0.014034</td>\n      <td>0.023165</td>\n      <td>-0.043346</td>\n      <td>-0.016159</td>\n      <td>-0.012820</td>\n      <td>-0.007157</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25.977641</td>\n      <td>26.935251</td>\n      <td>26.561891</td>\n      <td>7.477219</td>\n      <td>1.098311</td>\n      <td>1.176663</td>\n      <td>-0.849446</td>\n      <td>-1.805917</td>\n      <td>-1.623971</td>\n      <td>-0.321053</td>\n      <td>...</td>\n      <td>0.008456</td>\n      <td>0.040828</td>\n      <td>-0.025147</td>\n      <td>0.006059</td>\n      <td>-0.022267</td>\n      <td>0.043209</td>\n      <td>-0.061407</td>\n      <td>-0.003576</td>\n      <td>-0.026326</td>\n      <td>0.004760</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>25.189643</td>\n      <td>25.649484</td>\n      <td>25.620624</td>\n      <td>7.261496</td>\n      <td>1.066191</td>\n      <td>1.162694</td>\n      <td>-0.825414</td>\n      <td>-1.684836</td>\n      <td>-1.477246</td>\n      <td>3.056053</td>\n      <td>...</td>\n      <td>0.029771</td>\n      <td>0.026605</td>\n      <td>-0.040045</td>\n      <td>0.024580</td>\n      <td>-0.029490</td>\n      <td>0.040770</td>\n      <td>-0.057996</td>\n      <td>-0.012361</td>\n      <td>-0.019814</td>\n      <td>0.007333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24.659920</td>\n      <td>24.559022</td>\n      <td>24.462891</td>\n      <td>6.972141</td>\n      <td>1.008067</td>\n      <td>1.143318</td>\n      <td>-0.881397</td>\n      <td>-1.797336</td>\n      <td>-1.316414</td>\n      <td>6.265323</td>\n      <td>...</td>\n      <td>-0.010154</td>\n      <td>0.059279</td>\n      <td>-0.064038</td>\n      <td>0.044904</td>\n      <td>-0.045340</td>\n      <td>0.042700</td>\n      <td>-0.063328</td>\n      <td>-0.010253</td>\n      <td>-0.004272</td>\n      <td>-0.024278</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 76 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest - L1SO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['e0106', 'e0110', 'e0115', 'e0129', 'e0133', 'e0151', 'e0202',\n       'e0203', 'e0204', 'e0205', 'e0206', 'e0207', 'e0208', 'e0210',\n       'e0211', 'e0212', 'e0213', 'e0302', 'e0303', 'e0304', 'e0305',\n       'e0306', 'e0403', 'e0404', 'e0405', 'e0406', 'e0408', 'e0409',\n       'e0410', 'e0411', 'e0413', 'e0415', 'e0417', 'e0418', 'e0515',\n       'e0601', 'e0602', 'e0603', 'e0605', 'e0606', 'e0607', 'e0609',\n       'e0610', 'e0611', 'e0612', 'e0613', 'e0614', 'e0615', 'e0704',\n       'e0801', 'e0808', 'e0817', 'e0818', 'e1301', 'e1302', 'e1304'],\n      dtype=object)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvds = X_fsel.copy()\n",
    "cvds[\"patient_id\"] = patient_ids\n",
    "cvds[\"label\"] = y\n",
    "\n",
    "patients = np.unique(cvds[\"patient_id\"].values)\n",
    "patients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 56 - 24.76992440223694 s\n",
      "Accuracy 0.8194675540765392 precision 0.8520595181076464 specificity 0.1805324459234609 recall 0.8194675540765392 f1 0.7381577876226711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 56 - 23.83852791786194 s\n",
      "Accuracy 0.8020304568527918 precision 0.8412223968667062 specificity 0.19796954314720813 recall 0.8020304568527918 f1 0.7139200686351611\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 56 - 23.944045543670654 s\n",
      "Accuracy 0.9123548046462513 precision 0.8508104737453515 specificity 0.085613350529288 recall 0.9123548046462513 f1 0.878525742267013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 56 - 24.718892097473145 s\n",
      "Accuracy 0.8658280922431866 precision 0.8838301930742893 specificity 0.13417190775681342 recall 0.8658280922431866 f1 0.8035662968459238\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "5 of 56 - 24.87054443359375 s\n",
      "Accuracy 0.9991023339317774 precision 1.0 specificity 0.0 recall 0.9991023339317774 f1 0.9995509654243375\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "6 of 56 - 25.17591905593872 s\n",
      "Accuracy 0.9843871975019516 precision 1.0 specificity 0.0 recall 0.9843871975019516 f1 0.9921321793863098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 56 - 26.17879366874695 s\n",
      "Accuracy 0.7206937799043063 precision 0.7993170498167167 specificity 0.3063895534290271 recall 0.7206937799043063 f1 0.611281225723361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 56 - 26.158597946166992 s\n",
      "Accuracy 0.7693661971830986 precision 0.7636668512958508 specificity 0.379714842034978 recall 0.7693661971830986 f1 0.7106733601109128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 56 - 25.454649209976196 s\n",
      "Accuracy 0.8027950310559007 precision 0.9823062471280245 specificity 0.6272364154849799 recall 0.8027950310559007 f1 0.8795162143482055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 56 - 25.58722186088562 s\n",
      "Accuracy 0.6507699950322902 precision 0.7727315914020368 specificity 0.3492300049677099 recall 0.6507699950322902 f1 0.5130958131160397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 56 - 25.705589532852173 s\n",
      "Accuracy 0.6964577656675749 precision 0.7525007687904327 specificity 0.6340053131809857 recall 0.6964577656675749 f1 0.7149678027743992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 56 - 26.259312868118286 s\n",
      "Accuracy 0.7574503311258278 precision 0.8162806729967984 specificity 0.24254966887417218 recall 0.7574503311258278 f1 0.6529129090721927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 56 - 26.505123138427734 s\n",
      "Accuracy 0.9055064581917063 precision 0.9144354876351821 specificity 0.09449354180829368 recall 0.9055064581917063 f1 0.8606026416777401\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 56 - 26.504016876220703 s\n",
      "Accuracy 0.8104976141785958 precision 0.8464087684106002 specificity 0.18950238582140422 recall 0.8104976141785958 f1 0.7256639030559867\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 56 - 26.4780433177948 s\n",
      "Accuracy 0.7394059405940594 precision 0.6712894518998374 specificity 0.18310295148005004 recall 0.7394059405940594 f1 0.7026474483676656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 56 - 25.476954698562622 s\n",
      "Accuracy 0.9468784227820373 precision 0.8975888610481778 specificity 0.05254354253588184 recall 0.9468784227820373 f1 0.921575061273094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 56 - 26.71099853515625 s\n",
      "Accuracy 0.7416089504528502 precision 0.7655632586689357 specificity 0.3713588916087226 recall 0.7416089504528502 f1 0.6644011795565741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 56 - 25.341103553771973 s\n",
      "Accuracy 0.9692174913693901 precision 0.9701650542069836 specificity 0.030782508630609898 recall 0.9692174913693901 f1 0.9540668308030607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 56 - 26.472962856292725 s\n",
      "Accuracy 0.8592493297587132 precision 0.8790600809320847 specificity 0.14075067024128687 recall 0.8592493297587132 f1 0.7942016155376138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 56 - 25.978622913360596 s\n",
      "Accuracy 0.9885509838998211 precision 0.9786406983469406 specificity 0.010725688794573104 recall 0.9885509838998211 f1 0.9835708781874795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 56 - 27.296940565109253 s\n",
      "Accuracy 0.8172652804032766 precision 0.8507839829225997 specificity 0.20300498986699364 recall 0.8172652804032766 f1 0.7387542245157407\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 56 - 25.364724159240723 s\n",
      "Accuracy 0.6731780616078137 precision 0.7799906410222396 specificity 0.3268219383921863 recall 0.6731780616078137 f1 0.5416861636287391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 56 - 26.4991397857666 s\n",
      "Accuracy 0.3815028901734104 precision 0.5514175834391436 specificity 0.6137470726297438 recall 0.3815028901734104 f1 0.32282042178467624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 56 - 26.567612886428833 s\n",
      "Accuracy 0.8373287671232876 precision 0.7278118863415903 specificity 0.1590379493245647 recall 0.8373287671232876 f1 0.7709906695120289\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 56 - 25.558948755264282 s\n",
      "Accuracy 0.7146680942184154 precision 0.7765583359276501 specificity 0.4066253070230714 recall 0.7146680942184154 f1 0.6305208251382098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 56 - 26.026853561401367 s\n",
      "Accuracy 0.6973509933774834 precision 0.5301974929044465 specificity 0.2538685188176385 recall 0.6973509933774834 f1 0.6023937180404793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 56 - 26.120489597320557 s\n",
      "Accuracy 0.5409511228533685 precision 0.7939084454947403 specificity 0.24227851871737274 recall 0.5409511228533685 f1 0.6353587910199812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 56 - 26.697920560836792 s\n",
      "Accuracy 0.32558139534883723 precision 0.9544604800717864 specificity 0.9653721498834366 recall 0.32558139534883723 f1 0.4349220348624944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 56 - 26.43618416786194 s\n",
      "Accuracy 0.14624505928853754 precision 0.8768752779639571 specificity 0.8565250238139556 recall 0.14624505928853754 f1 0.040997266211743044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 56 - 25.446236610412598 s\n",
      "Accuracy 0.9090365050867744 precision 0.8597570995484867 specificity 0.08871353343996317 recall 0.9090365050867744 f1 0.8824181855554523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 56 - 25.808444261550903 s\n",
      "Accuracy 0.8889700511322133 precision 0.9044370654591297 specificity 0.6508786580749448 recall 0.8889700511322133 f1 0.8954036304485022\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 56 - 25.86398196220398 s\n",
      "Accuracy 0.5704834605597965 precision 0.7491740726144221 specificity 0.6013652789360019 recall 0.5704834605597965 f1 0.48967600651821974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 56 - 25.722227334976196 s\n",
      "Accuracy 0.8496435515230071 precision 0.8295513725580965 specificity 0.17010399223390613 recall 0.8496435515230071 f1 0.7848414269998215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 56 - 25.694894790649414 s\n",
      "Accuracy 0.5329586101175269 precision 0.9319286548175912 specificity 0.8865666731434199 recall 0.5329586101175269 f1 0.6398407097165051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 56 - 28.381521940231323 s\n",
      "Accuracy 0.9232456140350878 precision 0.9176149040606872 specificity 0.22979082321187586 recall 0.9232456140350878 f1 0.9203476295210167\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "36 of 56 - 26.94578981399536 s\n",
      "Accuracy 0.9772270596115205 precision 1.0 specificity 0.0 recall 0.9772270596115205 f1 0.9884823848238482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 56 - 26.12070608139038 s\n",
      "Accuracy 0.8281750266808965 precision 0.8774762027120745 specificity 0.5900694211940555 recall 0.8281750266808965 f1 0.8476685086555583\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 56 - 24.81793189048767 s\n",
      "Accuracy 0.09220389805097451 precision 0.9003774792445673 specificity 0.8943806018475849 recall 0.09220389805097451 f1 0.09649977942402488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 56 - 24.60975956916809 s\n",
      "Accuracy 0.8152507676560901 precision 0.8036941003776485 specificity 0.5953340437501156 recall 0.8152507676560901 f1 0.806115669405949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 56 - 24.534438133239746 s\n",
      "Accuracy 0.8905961893054702 precision 0.8937760483631757 specificity 0.5578361233117292 recall 0.8905961893054702 f1 0.8752158811733807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 56 - 25.037583827972412 s\n",
      "Accuracy 0.3995381062355658 precision 0.7642152809055598 specificity 0.6577463486707391 recall 0.3995381062355658 f1 0.26902929152798777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 56 - 24.755320072174072 s\n",
      "Accuracy 0.9263024142312579 precision 0.9351846745372944 specificity 0.5154166633368762 recall 0.9263024142312579 f1 0.9303371685672223\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 56 - 25.54350447654724 s\n",
      "Accuracy 0.8565055762081785 precision 0.8770962258675252 specificity 0.14349442379182156 recall 0.8565055762081785 f1 0.7903039037179189\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "44 of 56 - 26.383677005767822 s\n",
      "Accuracy 0.9969758064516129 precision 1.0 specificity 0.0 recall 0.9969758064516129 f1 0.9984856133266027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 56 - 26.98117709159851 s\n",
      "Accuracy 0.6094674556213018 precision 0.5237251384477652 specificity 0.3901316787500626 recall 0.6094674556213018 f1 0.47645174143090274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 56 - 25.48865246772766 s\n",
      "Accuracy 0.7548291233283804 precision 0.814937882096311 specificity 0.2451708766716196 recall 0.7548291233283804 f1 0.6493703550394873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 56 - 25.900259971618652 s\n",
      "Accuracy 0.6223739495798319 precision 0.6319922687384812 specificity 0.6218171782340844 recall 0.6223739495798319 f1 0.6248512411074927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 56 - 25.9301598072052 s\n",
      "Accuracy 0.9745065789473685 precision 0.9817369888238696 specificity 0.3413413255766393 recall 0.9745065789473685 f1 0.9778677857809748\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "49 of 56 - 25.073403358459473 s\n",
      "Accuracy 0.9432580841976815 precision 1.0 specificity 0.0 recall 0.9432580841976815 f1 0.9708006279434852\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "50 of 56 - 25.230950593948364 s\n",
      "Accuracy 0.9944203347799132 precision 1.0 specificity 0.0 recall 0.9944203347799132 f1 0.9972023624494872\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 56 - 25.010018825531006 s\n",
      "Accuracy 0.14534883720930233 precision 0.7910852713178295 specificity 0.8559535914525311 recall 0.14534883720930233 f1 0.0801490999563588\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "52 of 56 - 25.865463972091675 s\n",
      "Accuracy 0.8079268292682927 precision 1.0 specificity 0.0 recall 0.8079268292682927 f1 0.8937605396290049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 56 - 25.59718132019043 s\n",
      "Accuracy 0.8028985507246377 precision 0.8037023329123758 specificity 0.5513362372695818 recall 0.8028985507246377 f1 0.777602416465719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 56 - 25.662191152572632 s\n",
      "Accuracy 0.8791808873720136 precision 0.8756011118872675 specificity 0.2568665434580259 recall 0.8791808873720136 f1 0.8396236500211305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 56 - 26.50881814956665 s\n",
      "Accuracy 0.9056737588652483 precision 0.9145711986318595 specificity 0.09432624113475177 recall 0.9056737588652483 f1 0.8608450986757885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 56 - 25.737027406692505 s\n",
      "Accuracy 0.7765237020316027 precision 0.7313779508928114 specificity 0.2339893204460856 recall 0.7765237020316027 f1 0.6837333873669403\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "tot = len(patients)\n",
    "for i, patient in enumerate(patients):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    df1 = cvds.loc[cvds[\"patient_id\"] != patient]\n",
    "    df2 = cvds.loc[cvds[\"patient_id\"] == patient]\n",
    "\n",
    "    y_train = df1[\"label\"].values\n",
    "    x_train = df1.loc[:, ~df1.columns.isin(['patient_id', 'label'])]\n",
    "    y_test = df2[\"label\"].values\n",
    "    x_test = df2.loc[:, ~df2.columns.isin(['patient_id', 'label'])]\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, zero_division=1, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(patients), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.819468     0.180532   0.852060  0.819468  0.738158\n1  0.802030     0.197970   0.841222  0.802030  0.713920\n2  0.912355     0.085613   0.850810  0.912355  0.878526\n3  0.865828     0.134172   0.883830  0.865828  0.803566\n4  0.999102     0.000000   1.000000  0.999102  0.999551\n5  0.984387     0.000000   1.000000  0.984387  0.992132\n6  0.720694     0.306390   0.799317  0.720694  0.611281\n7  0.769366     0.379715   0.763667  0.769366  0.710673\n8  0.802795     0.627236   0.982306  0.802795  0.879516\n9  0.650770     0.349230   0.772732  0.650770  0.513096",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.819468</td>\n      <td>0.180532</td>\n      <td>0.852060</td>\n      <td>0.819468</td>\n      <td>0.738158</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.802030</td>\n      <td>0.197970</td>\n      <td>0.841222</td>\n      <td>0.802030</td>\n      <td>0.713920</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.912355</td>\n      <td>0.085613</td>\n      <td>0.850810</td>\n      <td>0.912355</td>\n      <td>0.878526</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.865828</td>\n      <td>0.134172</td>\n      <td>0.883830</td>\n      <td>0.865828</td>\n      <td>0.803566</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.999102</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.999102</td>\n      <td>0.999551</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.984387</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.984387</td>\n      <td>0.992132</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.720694</td>\n      <td>0.306390</td>\n      <td>0.799317</td>\n      <td>0.720694</td>\n      <td>0.611281</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.769366</td>\n      <td>0.379715</td>\n      <td>0.763667</td>\n      <td>0.769366</td>\n      <td>0.710673</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.802795</td>\n      <td>0.627236</td>\n      <td>0.982306</td>\n      <td>0.802795</td>\n      <td>0.879516</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.650770</td>\n      <td>0.349230</td>\n      <td>0.772732</td>\n      <td>0.650770</td>\n      <td>0.513096</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.759807341493833\n",
      "Precision 0.8463016942013495\n",
      "Specificity 0.3287604334402648\n",
      "Recall 0.759807341493833\n",
      "F1 0.7246499666740824\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_6beats_l1so.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}