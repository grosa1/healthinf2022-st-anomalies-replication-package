{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Paper ST Sloping - 10 beats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sU5Wt4HhzLod"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1  \\\n0  e0106  39.341333  39.831764  39.826684  11.282887  1.634628  0.913825   \n1  e0106  43.320409  45.006516  44.365681  12.474802  1.826689  0.901002   \n2  e0106  41.841597  41.778007  41.593833  11.837152  1.721631  0.911361   \n3  e0106  43.146961  41.264063  41.075821  11.843259  1.752020  0.906516   \n4  e0106  41.647822  43.131905  43.437246  12.388259  1.809692  0.915806   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.771782 -1.359522 -0.634856  ... -0.049375  0.037769 -0.045755  0.051531   \n1 -0.707731 -1.281504 -0.731562  ... -0.033106  0.009999 -0.014494  0.028882   \n2 -0.728350 -1.293684 -0.729167  ... -0.049280  0.038759 -0.048515  0.056363   \n3 -0.728333 -1.275260 -0.678176  ... -0.065776  0.050750 -0.050526  0.048861   \n4 -0.758906 -1.398698 -0.864005  ... -0.049441  0.035196 -0.047893  0.061977   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.078515  0.013704 -0.024545 -0.017430  0.001676    NSR  \n1 -0.048873 -0.010926 -0.026088  0.009880 -0.021702    NSR  \n2 -0.076889 -0.002209 -0.011804 -0.015943 -0.006355    NSR  \n3 -0.084336  0.026353 -0.035720 -0.018588  0.013943    NSR  \n4 -0.082722  0.004341 -0.018094 -0.013906 -0.001004    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>39.341333</td>\n      <td>39.831764</td>\n      <td>39.826684</td>\n      <td>11.282887</td>\n      <td>1.634628</td>\n      <td>0.913825</td>\n      <td>-0.771782</td>\n      <td>-1.359522</td>\n      <td>-0.634856</td>\n      <td>...</td>\n      <td>-0.049375</td>\n      <td>0.037769</td>\n      <td>-0.045755</td>\n      <td>0.051531</td>\n      <td>-0.078515</td>\n      <td>0.013704</td>\n      <td>-0.024545</td>\n      <td>-0.017430</td>\n      <td>0.001676</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>43.320409</td>\n      <td>45.006516</td>\n      <td>44.365681</td>\n      <td>12.474802</td>\n      <td>1.826689</td>\n      <td>0.901002</td>\n      <td>-0.707731</td>\n      <td>-1.281504</td>\n      <td>-0.731562</td>\n      <td>...</td>\n      <td>-0.033106</td>\n      <td>0.009999</td>\n      <td>-0.014494</td>\n      <td>0.028882</td>\n      <td>-0.048873</td>\n      <td>-0.010926</td>\n      <td>-0.026088</td>\n      <td>0.009880</td>\n      <td>-0.021702</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>41.841597</td>\n      <td>41.778007</td>\n      <td>41.593833</td>\n      <td>11.837152</td>\n      <td>1.721631</td>\n      <td>0.911361</td>\n      <td>-0.728350</td>\n      <td>-1.293684</td>\n      <td>-0.729167</td>\n      <td>...</td>\n      <td>-0.049280</td>\n      <td>0.038759</td>\n      <td>-0.048515</td>\n      <td>0.056363</td>\n      <td>-0.076889</td>\n      <td>-0.002209</td>\n      <td>-0.011804</td>\n      <td>-0.015943</td>\n      <td>-0.006355</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>43.146961</td>\n      <td>41.264063</td>\n      <td>41.075821</td>\n      <td>11.843259</td>\n      <td>1.752020</td>\n      <td>0.906516</td>\n      <td>-0.728333</td>\n      <td>-1.275260</td>\n      <td>-0.678176</td>\n      <td>...</td>\n      <td>-0.065776</td>\n      <td>0.050750</td>\n      <td>-0.050526</td>\n      <td>0.048861</td>\n      <td>-0.084336</td>\n      <td>0.026353</td>\n      <td>-0.035720</td>\n      <td>-0.018588</td>\n      <td>0.013943</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>41.647822</td>\n      <td>43.131905</td>\n      <td>43.437246</td>\n      <td>12.388259</td>\n      <td>1.809692</td>\n      <td>0.915806</td>\n      <td>-0.758906</td>\n      <td>-1.398698</td>\n      <td>-0.864005</td>\n      <td>...</td>\n      <td>-0.049441</td>\n      <td>0.035196</td>\n      <td>-0.047893</td>\n      <td>0.061977</td>\n      <td>-0.082722</td>\n      <td>0.004341</td>\n      <td>-0.018094</td>\n      <td>-0.013906</td>\n      <td>-0.001004</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_10beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    41933\nST     12752\nName: label, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAHsCAYAAABxBMHTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfCklEQVR4nO3de7DndX3f8dc7LKjxBsqGEJYGErdN0ETULeCYJikmsKiTJamxkAtbh4qp0DGJTcRMG41Ko80YUyZoQuLGJU1E4qVsDYZQNbFpw2VVRNEYTlGH3aJsXECpEQt594/z3faX9ezuYS98zjk8HjO/2e/v8738Pj/G2Xn6vfy2ujsAADz8vmn0BAAAHqmEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiwLJRVT9RVVur6r6qurOq3l9V37eI/bqqnvJwzBHgoRBiwLJQVT+f5DeS/PskxyT5B0nekmTDwGntVVWtGj0HYGkTYsCSV1VPTPLaJBd293u6+3939//p7v/S3b9QVadU1V9W1T3TmbLfrKojpn0/PB3m49OZtH8+jb+gqm6e9vkfVfW9M5/3zKr6WFV9par+qKreWVWvn1n/kqqaq6qdVbWlqr5tZl1X1YVVdVuS26rqsqp6027fZ0tV/dyh+y8GLBdCDFgOnp3k0Uneu4f1Dyb5uSRHT9s+N8nLkqS7v3/a5und/bjufmdVPSPJpiQvTfLkJL+dZEtVPWoKuPcmeXuSJyV5R5If3fVBVXV6kl9N8qIkxyb5fJIrd5vP2UlOTXJSks1Jzq2qb5r2PzrJDyX5w/347wCsMEIMWA6enORvuvuBhVZ290e6+/rufqC7P5f5sPqBvRzvgiS/3d03dPeD3b05yf1JTpteq5JcOp11e0+SG2f2/ckkm7r7o919f5JXJXl2VZ0ws82vdvfO7v7b7r4xyb2Zj8MkOSfJn3X3Fx/afwJgJRJiwHLwpSRH7+meq6r6h1X1vqr6QlV9OfP3kR29l+N9e5JXTJcl76mqe5Icn+Tbptf27u6Z7e+YWf62zJ8FS5J0933T/I7bw/bJ/Fmxn5qWfyrJ7+9lbsAjiBADloO/zPwZq7P3sP6tSf4qydrufkKSX0pSezneHUku6e4jZ17f3N3vSHJnkuOqanb/42eW/1fmQy5JUlWPzfwZu+0z28xGXJL8pyQbqurpSb47yX/ey9yARxAhBix53X1vkl9OcllVnV1V31xVh1fVWVX1H5I8PsmXk9xXVd+V5F/tdogvJvmOmfe/k+RnqurUmvfYqnp+VT0+89H3YJKLqmpVVW1IcsrMvu9I8uKqOrmqHpX5s283TJdE9zT/bUluyvyZsHd399/u/38NYCURYsCy0N1vSvLzSf5tkh2ZP6t1UebPLv2bJD+R5CuZj6x37rb7a5Jsni5Dvqi7tyZ5SZLfTHJ3krkk/2L6nK8n+bEk5ye5J/OXEt+X+TNy6e7/muTfJXl35s+efWfm7/val81JvicuSwIz6u/fBgHA7qrqhiS/1d2/dwDH+P7MX6L89vYXLzBxRgxgN1X1A1X1rdOlyY1JvjfJnxzA8Q5P8vIkvyvCgFl+9RngG/2jJFcleWyS25O8sLvv3J8DVdV3J9ma5ONJXnzQZgisCC5NAgAM4tIkAMAgy/bS5NFHH90nnHDC6GkAAOzTRz7ykb/p7tW7jy/bEDvhhBOydevW0dMAANinqvr8QuMuTQIADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYBAhBgAwiBADABhEiAEADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYBAhBgAwiBADABhEiAEADCLEAAAGEWIAAIOsGj0BDp4TLv7j0VNgGfncG54/egoAj3jOiAEADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYBAhBgAwiBADABhEiAEADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYBAhBgAwyKJDrKoOq6qPVdX7pvcnVtUNVTVXVe+sqiOm8UdN7+em9SfMHONV0/hnqurMmfH109hcVV18EL8fAMCS9VDOiL08yadn3r8xyZu7+ylJ7k5y/jR+fpK7p/E3T9ulqk5Kck6SpyZZn+QtU9wdluSyJGclOSnJudO2AAAr2qJCrKrWJHl+kt+d3leS05O8a9pkc5Kzp+UN0/tM6587bb8hyZXdfX93fzbJXJJTptdcd9/e3V9PcuW0LQDAirbYM2K/keQXk/zd9P7JSe7p7gem99uSHDctH5fkjiSZ1t87bf//xnfbZ0/j36CqLqiqrVW1dceOHYucOgDA0rTPEKuqFyS5q7s/8jDMZ6+6+/LuXtfd61avXj16OgAAB2TVIrZ5TpIfqarnJXl0kick+Y9JjqyqVdNZrzVJtk/bb09yfJJtVbUqyROTfGlmfJfZffY0DgCwYu3zjFh3v6q713T3CZm/2f6D3f2TST6U5IXTZhuTXD0tb5neZ1r/we7uafyc6anKE5OsTXJjkpuSrJ2ewjxi+owtB+XbAQAsYYs5I7Ynr0xyZVW9PsnHkrxtGn9bkt+vqrkkOzMfVunuW6vqqiSfSvJAkgu7+8EkqaqLklyb5LAkm7r71gOYFwDAsvCQQqy7/yzJn03Lt2f+icfdt/lakh/fw/6XJLlkgfFrklzzUOYCALDc+WV9AIBBhBgAwCBCDABgECEGADCIEAMAGESIAQAMIsQAAAYRYgAAgwgxAIBBhBgAwCBCDABgECEGADCIEAMAGESIAQAMIsQAAAYRYgAAgwgxAIBBhBgAwCBCDABgECEGADCIEAMAGESIAQAMIsQAAAYRYgAAgwgxAIBBhBgAwCBCDABgECEGADCIEAMAGESIAQAMIsQAAAYRYgAAgwgxAIBBhBgAwCBCDABgECEGADCIEAMAGESIAQAMIsQAAAYRYgAAg+wzxKrq0VV1Y1V9vKpurapfmcbfXlWfraqbp9fJ03hV1aVVNVdVt1TVM2eOtbGqbpteG2fGn1VVn5j2ubSq6hB8VwCAJWXVIra5P8np3X1fVR2e5C+q6v3Tul/o7nfttv1ZSdZOr1OTvDXJqVX1pCSvTrIuSSf5SFVt6e67p21ekuSGJNckWZ/k/QEAWMH2eUas5903vT18evVedtmQ5Ippv+uTHFlVxyY5M8l13b1ziq/rkqyf1j2hu6/v7k5yRZKz9/8rAQAsD4u6R6yqDquqm5PclfmYumFadcl0+fHNVfWoaey4JHfM7L5tGtvb+LYFxheaxwVVtbWqtu7YsWMxUwcAWLIWFWLd/WB3n5xkTZJTquppSV6V5LuS/OMkT0ryykM1yZl5XN7d67p73erVqw/1xwEAHFIP6anJ7r4nyYeSrO/uO6fLj/cn+b0kp0ybbU9y/Mxua6axvY2vWWAcAGBFW8xTk6ur6shp+TFJfjjJX033dmV6wvHsJJ+cdtmS5Lzp6cnTktzb3XcmuTbJGVV1VFUdleSMJNdO675cVadNxzovydUH80sCACxFi3lq8tgkm6vqsMyH21Xd/b6q+mBVrU5SSW5O8jPT9tckeV6SuSRfTfLiJOnunVX1uiQ3Tdu9trt3TssvS/L2JI/J/NOSnpgEAFa8fYZYd9+S5BkLjJ++h+07yYV7WLcpyaYFxrcmedq+5gIAsJL4ZX0AgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEH2GWJV9eiqurGqPl5Vt1bVr0zjJ1bVDVU1V1XvrKojpvFHTe/npvUnzBzrVdP4Z6rqzJnx9dPYXFVdfAi+JwDAkrOYM2L3Jzm9u5+e5OQk66vqtCRvTPLm7n5KkruTnD9tf36Su6fxN0/bpapOSnJOkqcmWZ/kLVV1WFUdluSyJGclOSnJudO2AAAr2j5DrOfdN709fHp1ktOTvGsa35zk7Gl5w/Q+0/rnVlVN41d29/3d/dkkc0lOmV5z3X17d389yZXTtgAAK9qi7hGbzlzdnOSuJNcl+Z9J7unuB6ZNtiU5blo+LskdSTKtvzfJk2fHd9tnT+MLzeOCqtpaVVt37NixmKkDACxZiwqx7n6wu09OsibzZ7C+61BOai/zuLy713X3utWrV4+YAgDAQfOQnprs7nuSfCjJs5McWVWrplVrkmyflrcnOT5JpvVPTPKl2fHd9tnTOADAiraYpyZXV9WR0/Jjkvxwkk9nPsheOG22McnV0/KW6X2m9R/s7p7Gz5meqjwxydokNya5Kcna6SnMIzJ/Q/+Wg/DdAACWtFX73iTHJtk8Pd34TUmu6u73VdWnklxZVa9P8rEkb5u2f1uS36+quSQ7Mx9W6e5bq+qqJJ9K8kCSC7v7wSSpqouSXJvksCSbuvvWg/YNAQCWqH2GWHffkuQZC4zfnvn7xXYf/1qSH9/DsS5JcskC49ckuWYR8wUAWDH8sj4AwCBCDABgECEGADCIEAMAGESIAQAMIsQAAAYRYgAAgwgxAIBBhBgAwCBCDABgECEGADCIEAMAGESIAQAMIsQAAAYRYgAAgwgxAIBBhBgAwCBCDABgECEGADCIEAMAGESIAQAMIsQAAAYRYgAAgwgxAIBBhBgAwCBCDABgECEGADCIEAMAGESIAQAMIsQAAAYRYgAAgwgxAIBBhBgAwCBCDABgECEGADCIEAMAGESIAQAMIsQAAAYRYgAAgwgxAIBB9hliVXV8VX2oqj5VVbdW1cun8ddU1faqunl6PW9mn1dV1VxVfaaqzpwZXz+NzVXVxTPjJ1bVDdP4O6vqiIP9RQEAlprFnBF7IMkruvukJKclubCqTprWvbm7T55e1yTJtO6cJE9Nsj7JW6rqsKo6LMllSc5KclKSc2eO88bpWE9JcneS8w/S9wMAWLL2GWLdfWd3f3Ra/kqSTyc5bi+7bEhyZXff392fTTKX5JTpNdfdt3f315NcmWRDVVWS05O8a9p/c5Kz9/P7AAAsGw/pHrGqOiHJM5LcMA1dVFW3VNWmqjpqGjsuyR0zu22bxvY0/uQk93T3A7uNL/T5F1TV1qraumPHjocydQCAJWfRIVZVj0vy7iQ/291fTvLWJN+Z5OQkdyZ506GY4Kzuvry713X3utWrVx/qjwMAOKRWLWajqjo88xH2B939niTp7i/OrP+dJO+b3m5PcvzM7mumsexh/EtJjqyqVdNZsdntAQBWrMU8NVlJ3pbk09396zPjx85s9qNJPjktb0lyTlU9qqpOTLI2yY1JbkqydnpC8ojM39C/pbs7yYeSvHDaf2OSqw/sawEALH2LOSP2nCQ/neQTVXXzNPZLmX/q8eQkneRzSV6aJN19a1VdleRTmX/i8sLufjBJquqiJNcmOSzJpu6+dTreK5NcWVWvT/KxzIcfAMCKts8Q6+6/SFILrLpmL/tckuSSBcavWWi/7r49809VAgA8YvhlfQCAQYQYAMAgQgwAYBAhBgAwiBADABhEiAEADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYBAhBgAwiBADABhEiAEADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYBAhBgAwiBADABhEiAEADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYBAhBgAwiBADABhEiAEADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYBAhBgAwiBADABhEiAEADCLEAAAGEWIAAIMIMQCAQfYZYlV1fFV9qKo+VVW3VtXLp/EnVdV1VXXb9OdR03hV1aVVNVdVt1TVM2eOtXHa/raq2jgz/qyq+sS0z6VVVYfiywIALCWLOSP2QJJXdPdJSU5LcmFVnZTk4iQf6O61ST4wvU+Ss5KsnV4XJHlrMh9uSV6d5NQkpyR59a54m7Z5ycx+6w/8qwEALG37DLHuvrO7PzotfyXJp5Mcl2RDks3TZpuTnD0tb0hyRc+7PsmRVXVskjOTXNfdO7v77iTXJVk/rXtCd1/f3Z3kipljAQCsWA/pHrGqOiHJM5LckOSY7r5zWvWFJMdMy8cluWNmt23T2N7Gty0wvtDnX1BVW6tq644dOx7K1AEAlpxFh1hVPS7Ju5P8bHd/eXbddCarD/LcvkF3X97d67p73erVqw/1xwEAHFKLCrGqOjzzEfYH3f2eafiL02XFTH/eNY1vT3L8zO5rprG9ja9ZYBwAYEVbzFOTleRtST7d3b8+s2pLkl1PPm5McvXM+HnT05OnJbl3uoR5bZIzquqo6Sb9M5JcO637clWdNn3WeTPHAgBYsVYtYpvnJPnpJJ+oqpunsV9K8oYkV1XV+Uk+n+RF07prkjwvyVySryZ5cZJ0986qel2Sm6btXtvdO6fllyV5e5LHJHn/9AIAWNH2GWLd/RdJ9vS7Xs9dYPtOcuEejrUpyaYFxrcmedq+5gIAsJL4ZX0AgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACD7DPEqmpTVd1VVZ+cGXtNVW2vqpun1/Nm1r2qquaq6jNVdebM+PppbK6qLp4ZP7GqbpjG31lVRxzMLwgAsFQt5ozY25OsX2D8zd198vS6Jkmq6qQk5yR56rTPW6rqsKo6LMllSc5KclKSc6dtk+SN07GekuTuJOcfyBcCAFgu9hli3f3hJDsXebwNSa7s7vu7+7NJ5pKcMr3muvv27v56kiuTbKiqSnJ6kndN+29OcvZD+woAAMvTgdwjdlFV3TJdujxqGjsuyR0z22ybxvY0/uQk93T3A7uNL6iqLqiqrVW1dceOHQcwdQCA8fY3xN6a5DuTnJzkziRvOlgT2pvuvry713X3utWrVz8cHwkAcMis2p+duvuLu5ar6neSvG96uz3J8TObrpnGsofxLyU5sqpWTWfFZrcHAFjR9uuMWFUdO/P2R5PseqJyS5JzqupRVXVikrVJbkxyU5K10xOSR2T+hv4t3d1JPpTkhdP+G5NcvT9zAgBYbvZ5Rqyq3pHkB5McXVXbkrw6yQ9W1clJOsnnkrw0Sbr71qq6KsmnkjyQ5MLufnA6zkVJrk1yWJJN3X3r9BGvTHJlVb0+yceSvO1gfTkAgKVsnyHW3ecuMLzHWOruS5JcssD4NUmuWWD89sw/VQkA8Ijil/UBAAYRYgAAgwgxAIBBhBgAwCBCDABgECEGADCIEAMAGESIAQAMIsQAAAYRYgAAgwgxAIBBhBgAwCBCDABgECEGADCIEAMAGESIAQAMsmr0BABY2k64+I9HT4Fl5HNveP7oKSwrzogBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMMg+Q6yqNlXVXVX1yZmxJ1XVdVV12/TnUdN4VdWlVTVXVbdU1TNn9tk4bX9bVW2cGX9WVX1i2ufSqqqD/SUBAJaixZwRe3uS9buNXZzkA929NskHpvdJclaStdPrgiRvTebDLcmrk5ya5JQkr94Vb9M2L5nZb/fPAgBYkfYZYt394SQ7dxvekGTztLw5ydkz41f0vOuTHFlVxyY5M8l13b2zu+9Ocl2S9dO6J3T39d3dSa6YORYAwIq2v/eIHdPdd07LX0hyzLR8XJI7ZrbbNo3tbXzbAuMLqqoLqmprVW3dsWPHfk4dAGBpOOCb9aczWX0Q5rKYz7q8u9d197rVq1c/HB8JAHDI7G+IfXG6rJjpz7um8e1Jjp/Zbs00trfxNQuMAwCsePsbYluS7HrycWOSq2fGz5uenjwtyb3TJcxrk5xRVUdNN+mfkeTaad2Xq+q06WnJ82aOBQCwoq3a1wZV9Y4kP5jk6KralvmnH9+Q5KqqOj/J55O8aNr8miTPSzKX5KtJXpwk3b2zql6X5KZpu9d2964HAF6W+SczH5Pk/dMLAGDF22eIdfe5e1j13AW27SQX7uE4m5JsWmB8a5Kn7WseAAArjV/WBwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAYRIgBAAwixAAABhFiAACDCDEAgEGEGADAIEIMAGAQIQYAMIgQAwAY5IBCrKo+V1WfqKqbq2rrNPakqrquqm6b/jxqGq+qurSq5qrqlqp65sxxNk7b31ZVGw/sKwEALA8H44zYP+3uk7t73fT+4iQf6O61ST4wvU+Ss5KsnV4XJHlrMh9uSV6d5NQkpyR59a54AwBYyQ7FpckNSTZPy5uTnD0zfkXPuz7JkVV1bJIzk1zX3Tu7++4k1yVZfwjmBQCwpBxoiHWSP62qj1TVBdPYMd1957T8hSTHTMvHJbljZt9t09iexr9BVV1QVVurauuOHTsOcOoAAGOtOsD9v6+7t1fVtyS5rqr+anZld3dV9QF+xuzxLk9yeZKsW7fuoB0XAGCEAzoj1t3bpz/vSvLezN/j9cXpkmOmP++aNt+e5PiZ3ddMY3saBwBY0fY7xKrqsVX1+F3LSc5I8skkW5LsevJxY5Krp+UtSc6bnp48Lcm90yXMa5OcUVVHTTfpnzGNAQCsaAdyafKYJO+tql3H+cPu/pOquinJVVV1fpLPJ3nRtP01SZ6XZC7JV5O8OEm6e2dVvS7JTdN2r+3unQcwLwCAZWG/Q6y7b0/y9AXGv5TkuQuMd5IL93CsTUk27e9cAACWI7+sDwAwiBADABhEiAEADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYBAhBgAwiBADABhEiAEADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYBAhBgAwiBADABhEiAEADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYBAhBgAwiBADABhEiAEADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYBAhBgAwiBADABhEiAEADCLEAAAGEWIAAIMIMQCAQYQYAMAgQgwAYJAlE2JVtb6qPlNVc1V18ej5AAAcaksixKrqsCSXJTkryUlJzq2qk8bOCgDg0FoSIZbklCRz3X17d389yZVJNgyeEwDAIbVq9AQmxyW5Y+b9tiSn7r5RVV2Q5ILp7X1V9ZmHYW4sf0cn+ZvRk1hq6o2jZwDLnr9bFuDvlj369oUGl0qILUp3X57k8tHzYHmpqq3dvW70PICVxd8tHAxL5dLk9iTHz7xfM40BAKxYSyXEbkqytqpOrKojkpyTZMvgOQEAHFJL4tJkdz9QVRcluTbJYUk2dfetg6fFyuFyNnAo+LuFA1bdPXoOAACPSEvl0iQAwCOOEAMAGESIAQAMIsQAYB+q6rTRc2BlEmI8YlTVPxg9B2DZesvoCbAyCTFWnKp6dlW9sKq+ZXr/vVX1h0n+++CpAcDf4+crWFGq6teSvCDJzUmekvnfpvuXSX41yW9399fGzQ5YrqrqniQf3tP67v6Rh282rCRL4gdd4SB6fpJndPfXquqozP9j8k/r7s+NnRawzO1I8qbRk2DlEWKsNF/bddaru++uqttEGHAQ3Nfdfz56Eqw8QoyV5juqavbfKT1x9r3LB8B+uruqvrW7v5AkVXVekn+W5PNJXtPdO4fOjmXLPWKsKFX1A3tb7//RAvujqj6a5Ie6e2dVfX+SK5P86yQnJ/nu7n7hyPmxfAkxVrSqOjzJ05Js7+67Rs8HWJ6q6ubuPnlavizJju5+ze7r4KHy8xWsKFX1W1X11Gn5iUk+nuSKJB+rqnOHTg5YzlZV1a7beZ6b5IOz6wbMhxVCiLHS/JPuvnVafnGSv+7u70nyrCS/OG5awDL3jiR/XlVXJ/nbJP8tSarqKUnuHTkxljcVz0rz9ZnlH07yR0nS3V+oqjEzApa97r6kqj6Q5Ngkf9r//76eb8r8vWKwX4QYK809VfWCJNuTPCfJ+UkyXVJ4zMiJActbd1+/wNhfj5gLK4cQY6V5aZJLk3xrkp/d9ah55u/p+ONhswKABXhqEgBgEGfEWFGq6pf3srq7+3UP22QAYB+cEWNFqapXLDD8zZn/h7+f3N2Pe5inBAB7JMRYsarq8Ulenvkb9q9K8iY/6grAUuLSJCtOVT0pyc8n+ckkm5M8s7vvHjsrAPhGQowVpap+LcmPJbk8yfd0932DpwQAe+TSJCtKVf1dkvuTPJBk9n/clfmb9Z8wZGIAsAAhBgAwiH9rEgBgECEGADCIEAMAGESIAQAM8n8BC/SUhWtNZhQAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.231317  0.109459  0.074913  0.064543  0.101660 -0.029506   \ndw_2    0.231317  1.000000  0.839064  0.449006  0.157026  0.490259 -0.520594   \ndw_3    0.109459  0.839064  1.000000  0.626999  0.236381  0.373744 -0.580056   \ndw_4    0.074913  0.449006  0.626999  1.000000  0.896524  0.070236 -0.268424   \ndw_5    0.064543  0.157026  0.236381  0.896524  1.000000 -0.079160 -0.026334   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.046809  0.030436  0.054751  0.044048  0.016599 -0.081643  0.054039   \ncfr_13 -0.035437  0.119758  0.045877  0.026303  0.014533  0.076890 -0.003660   \ncfr_14 -0.049050  0.004610 -0.023444 -0.031429 -0.033413  0.021208  0.025601   \ncfr_15 -0.071846 -0.117053 -0.131465 -0.089388 -0.041393 -0.006682  0.103513   \ncfr_16 -0.053104 -0.076826 -0.047859 -0.036217 -0.021446  0.052559 -0.032448   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.023452 -0.001861  0.003290  ... -0.062028 -0.061241 -0.032516   \ndw_2   -0.307376 -0.002765  0.011760  ... -0.133566  0.150743  0.235204   \ndw_3   -0.413234 -0.000351  0.005808  ... -0.207216  0.129536  0.268782   \ndw_4   -0.208628  0.000763  0.001641  ... -0.143689  0.054827  0.109764   \ndw_5   -0.035523  0.000409 -0.000153  ... -0.061473  0.009140  0.005657   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.087235 -0.001785  0.005388  ... -0.130493 -0.207093 -0.090454   \ncfr_13  0.006739  0.002726 -0.000638  ...  0.133437  0.032750 -0.215151   \ncfr_14  0.029224  0.003070 -0.002968  ...  0.098660  0.217327  0.047811   \ncfr_15  0.057917  0.004848 -0.008763  ...  0.266212  0.164693 -0.079613   \ncfr_16 -0.005212  0.008240 -0.005231  ...  0.248016  0.141547  0.178786   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.026775 -0.017739 -0.046809 -0.035437 -0.049050 -0.071846 -0.053104  \ndw_2    0.167194  0.046752  0.030436  0.119758  0.004610 -0.117053 -0.076826  \ndw_3    0.117633 -0.049634  0.054751  0.045877 -0.023444 -0.131465 -0.047859  \ndw_4    0.050373 -0.044638  0.044048  0.026303 -0.031429 -0.089388 -0.036217  \ndw_5    0.023553 -0.012439  0.016599  0.014533 -0.033413 -0.041393 -0.021446  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.024675  0.059365  1.000000  0.008142 -0.011310 -0.326522 -0.216222  \ncfr_13 -0.269635 -0.033375  0.008142  1.000000  0.199386  0.109416 -0.168514  \ncfr_14 -0.175074 -0.289421 -0.011310  0.199386  1.000000  0.171805 -0.139323  \ncfr_15 -0.147027 -0.089111 -0.326522  0.109416  0.171805  1.000000  0.253573  \ncfr_16  0.127395 -0.003147 -0.216222 -0.168514 -0.139323  0.253573  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.231317</td>\n      <td>0.109459</td>\n      <td>0.074913</td>\n      <td>0.064543</td>\n      <td>0.101660</td>\n      <td>-0.029506</td>\n      <td>0.023452</td>\n      <td>-0.001861</td>\n      <td>0.003290</td>\n      <td>...</td>\n      <td>-0.062028</td>\n      <td>-0.061241</td>\n      <td>-0.032516</td>\n      <td>-0.026775</td>\n      <td>-0.017739</td>\n      <td>-0.046809</td>\n      <td>-0.035437</td>\n      <td>-0.049050</td>\n      <td>-0.071846</td>\n      <td>-0.053104</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.231317</td>\n      <td>1.000000</td>\n      <td>0.839064</td>\n      <td>0.449006</td>\n      <td>0.157026</td>\n      <td>0.490259</td>\n      <td>-0.520594</td>\n      <td>-0.307376</td>\n      <td>-0.002765</td>\n      <td>0.011760</td>\n      <td>...</td>\n      <td>-0.133566</td>\n      <td>0.150743</td>\n      <td>0.235204</td>\n      <td>0.167194</td>\n      <td>0.046752</td>\n      <td>0.030436</td>\n      <td>0.119758</td>\n      <td>0.004610</td>\n      <td>-0.117053</td>\n      <td>-0.076826</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.109459</td>\n      <td>0.839064</td>\n      <td>1.000000</td>\n      <td>0.626999</td>\n      <td>0.236381</td>\n      <td>0.373744</td>\n      <td>-0.580056</td>\n      <td>-0.413234</td>\n      <td>-0.000351</td>\n      <td>0.005808</td>\n      <td>...</td>\n      <td>-0.207216</td>\n      <td>0.129536</td>\n      <td>0.268782</td>\n      <td>0.117633</td>\n      <td>-0.049634</td>\n      <td>0.054751</td>\n      <td>0.045877</td>\n      <td>-0.023444</td>\n      <td>-0.131465</td>\n      <td>-0.047859</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.074913</td>\n      <td>0.449006</td>\n      <td>0.626999</td>\n      <td>1.000000</td>\n      <td>0.896524</td>\n      <td>0.070236</td>\n      <td>-0.268424</td>\n      <td>-0.208628</td>\n      <td>0.000763</td>\n      <td>0.001641</td>\n      <td>...</td>\n      <td>-0.143689</td>\n      <td>0.054827</td>\n      <td>0.109764</td>\n      <td>0.050373</td>\n      <td>-0.044638</td>\n      <td>0.044048</td>\n      <td>0.026303</td>\n      <td>-0.031429</td>\n      <td>-0.089388</td>\n      <td>-0.036217</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.064543</td>\n      <td>0.157026</td>\n      <td>0.236381</td>\n      <td>0.896524</td>\n      <td>1.000000</td>\n      <td>-0.079160</td>\n      <td>-0.026334</td>\n      <td>-0.035523</td>\n      <td>0.000409</td>\n      <td>-0.000153</td>\n      <td>...</td>\n      <td>-0.061473</td>\n      <td>0.009140</td>\n      <td>0.005657</td>\n      <td>0.023553</td>\n      <td>-0.012439</td>\n      <td>0.016599</td>\n      <td>0.014533</td>\n      <td>-0.033413</td>\n      <td>-0.041393</td>\n      <td>-0.021446</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.046809</td>\n      <td>0.030436</td>\n      <td>0.054751</td>\n      <td>0.044048</td>\n      <td>0.016599</td>\n      <td>-0.081643</td>\n      <td>0.054039</td>\n      <td>0.087235</td>\n      <td>-0.001785</td>\n      <td>0.005388</td>\n      <td>...</td>\n      <td>-0.130493</td>\n      <td>-0.207093</td>\n      <td>-0.090454</td>\n      <td>0.024675</td>\n      <td>0.059365</td>\n      <td>1.000000</td>\n      <td>0.008142</td>\n      <td>-0.011310</td>\n      <td>-0.326522</td>\n      <td>-0.216222</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.035437</td>\n      <td>0.119758</td>\n      <td>0.045877</td>\n      <td>0.026303</td>\n      <td>0.014533</td>\n      <td>0.076890</td>\n      <td>-0.003660</td>\n      <td>0.006739</td>\n      <td>0.002726</td>\n      <td>-0.000638</td>\n      <td>...</td>\n      <td>0.133437</td>\n      <td>0.032750</td>\n      <td>-0.215151</td>\n      <td>-0.269635</td>\n      <td>-0.033375</td>\n      <td>0.008142</td>\n      <td>1.000000</td>\n      <td>0.199386</td>\n      <td>0.109416</td>\n      <td>-0.168514</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.049050</td>\n      <td>0.004610</td>\n      <td>-0.023444</td>\n      <td>-0.031429</td>\n      <td>-0.033413</td>\n      <td>0.021208</td>\n      <td>0.025601</td>\n      <td>0.029224</td>\n      <td>0.003070</td>\n      <td>-0.002968</td>\n      <td>...</td>\n      <td>0.098660</td>\n      <td>0.217327</td>\n      <td>0.047811</td>\n      <td>-0.175074</td>\n      <td>-0.289421</td>\n      <td>-0.011310</td>\n      <td>0.199386</td>\n      <td>1.000000</td>\n      <td>0.171805</td>\n      <td>-0.139323</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.071846</td>\n      <td>-0.117053</td>\n      <td>-0.131465</td>\n      <td>-0.089388</td>\n      <td>-0.041393</td>\n      <td>-0.006682</td>\n      <td>0.103513</td>\n      <td>0.057917</td>\n      <td>0.004848</td>\n      <td>-0.008763</td>\n      <td>...</td>\n      <td>0.266212</td>\n      <td>0.164693</td>\n      <td>-0.079613</td>\n      <td>-0.147027</td>\n      <td>-0.089111</td>\n      <td>-0.326522</td>\n      <td>0.109416</td>\n      <td>0.171805</td>\n      <td>1.000000</td>\n      <td>0.253573</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.053104</td>\n      <td>-0.076826</td>\n      <td>-0.047859</td>\n      <td>-0.036217</td>\n      <td>-0.021446</td>\n      <td>0.052559</td>\n      <td>-0.032448</td>\n      <td>-0.005212</td>\n      <td>0.008240</td>\n      <td>-0.005231</td>\n      <td>...</td>\n      <td>0.248016</td>\n      <td>0.141547</td>\n      <td>0.178786</td>\n      <td>0.127395</td>\n      <td>-0.003147</td>\n      <td>-0.216222</td>\n      <td>-0.168514</td>\n      <td>-0.139323</td>\n      <td>0.253573</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 310 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()\n",
    "patient_ids = data[\"id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_172', 'fft_231', 'mfw_12', 'fft_252', 'fft_148', 'fft_157', 'fft_239', 'fft_205', 'fft_159', 'fft_171', 'fft_160', 'fft_135', 'cfr_16', 'fft_250', 'fft_144', 'fft_211', 'fft_147', 'fft_221', 'fft_247', 'fft_251', 'fft_253', 'fft_130', 'fft_230', 'mfw_15', 'fft_209', 'fft_152', 'fft_174', 'fft_155', 'fft_222', 'fft_137', 'mfw_11', 'fft_235', 'fft_142', 'mfw_7', 'fft_168', 'fft_146', 'fft_170', 'fft_156', 'fft_225', 'fft_149', 'fft_139', 'fft_133', 'fft_217', 'fft_132', 'fft_167', 'fft_243', 'fft_138', 'fft_242', 'fft_201', 'fft_233', 'fft_158', 'fft_229', 'fft_189', 'fft_249', 'mfw_10', 'fft_255', 'fft_254', 'fft_216', 'fft_212', 'fft_131', 'fft_150', 'fft_162', 'mfw_14', 'fft_194', 'fft_190', 'fft_184', 'fft_181', 'fft_232', 'fft_141', 'fft_191', 'fft_219', 'mfw_9', 'fft_199', 'fft_163', 'fft_202', 'fft_224', 'fft_236', 'fft_241', 'fft_240', 'fft_164', 'fft_185', 'fft_204', 'fft_180', 'fft_193', 'fft_228', 'fft_213', 'fft_226', 'fft_234', 'fft_207', 'fft_246', 'fft_151', 'fft_187', 'fft_210', 'fft_153', 'fft_161', 'fft_166', 'fft_203', 'fft_178', 'fft_208', 'fft_223', 'fft_188', 'fft_175', 'fft_192', 'fft_169', 'mfw_16', 'mfw_6', 'mfw_5', 'fft_182', 'fft_165', 'fft_143', 'fft_179', 'fft_186', 'fft_145', 'fft_214', 'fft_195', 'fft_244', 'fft_177', 'fft_197', 'fft_227', 'fft_176', 'fft_200', 'fft_220', 'fft_136', 'fft_218', 'fft_198', 'fft_248', 'fft_245', 'fft_256', 'fft_134', 'fft_140', 'fft_238', 'mfw_13', 'fft_154', 'fft_173', 'fft_206', 'fft_215', 'fft_237', 'fft_183', 'mfw_8', 'fft_196'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_24\n",
      "fft_25\n",
      "fft_27\n",
      "fft_28\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "fft_37\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 75\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization best features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1     mfw_2  \\\n0  39.341333  39.831764  39.826684  11.282887  1.634628  0.913825 -0.771782   \n1  43.320409  45.006516  44.365681  12.474802  1.826689  0.901002 -0.707731   \n2  41.841597  41.778007  41.593833  11.837152  1.721631  0.911361 -0.728350   \n3  43.146961  41.264063  41.075821  11.843259  1.752020  0.906516 -0.728333   \n4  41.647822  43.131905  43.437246  12.388259  1.809692  0.915806 -0.758906   \n\n      mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -1.359522 -0.634856  0.232364  ...  0.019450  0.044698 -0.049375  0.037769   \n1 -1.281504 -0.731562 -1.393341  ...  0.013422  0.040336 -0.033106  0.009999   \n2 -1.293684 -0.729167 -1.923488  ...  0.010183  0.036844 -0.049280  0.038759   \n3 -1.275260 -0.678176 -1.560684  ...  0.001683  0.048352 -0.065776  0.050750   \n4 -1.398698 -0.864005  4.788369  ...  0.015460  0.047792 -0.049441  0.035196   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.045755  0.051531 -0.078515  0.013704 -0.024545 -0.017430  \n1 -0.014494  0.028882 -0.048873 -0.010926 -0.026088  0.009880  \n2 -0.048515  0.056363 -0.076889 -0.002209 -0.011804 -0.015943  \n3 -0.050526  0.048861 -0.084336  0.026353 -0.035720 -0.018588  \n4 -0.047893  0.061977 -0.082722  0.004341 -0.018094 -0.013906  \n\n[5 rows x 75 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39.341333</td>\n      <td>39.831764</td>\n      <td>39.826684</td>\n      <td>11.282887</td>\n      <td>1.634628</td>\n      <td>0.913825</td>\n      <td>-0.771782</td>\n      <td>-1.359522</td>\n      <td>-0.634856</td>\n      <td>0.232364</td>\n      <td>...</td>\n      <td>0.019450</td>\n      <td>0.044698</td>\n      <td>-0.049375</td>\n      <td>0.037769</td>\n      <td>-0.045755</td>\n      <td>0.051531</td>\n      <td>-0.078515</td>\n      <td>0.013704</td>\n      <td>-0.024545</td>\n      <td>-0.017430</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>43.320409</td>\n      <td>45.006516</td>\n      <td>44.365681</td>\n      <td>12.474802</td>\n      <td>1.826689</td>\n      <td>0.901002</td>\n      <td>-0.707731</td>\n      <td>-1.281504</td>\n      <td>-0.731562</td>\n      <td>-1.393341</td>\n      <td>...</td>\n      <td>0.013422</td>\n      <td>0.040336</td>\n      <td>-0.033106</td>\n      <td>0.009999</td>\n      <td>-0.014494</td>\n      <td>0.028882</td>\n      <td>-0.048873</td>\n      <td>-0.010926</td>\n      <td>-0.026088</td>\n      <td>0.009880</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41.841597</td>\n      <td>41.778007</td>\n      <td>41.593833</td>\n      <td>11.837152</td>\n      <td>1.721631</td>\n      <td>0.911361</td>\n      <td>-0.728350</td>\n      <td>-1.293684</td>\n      <td>-0.729167</td>\n      <td>-1.923488</td>\n      <td>...</td>\n      <td>0.010183</td>\n      <td>0.036844</td>\n      <td>-0.049280</td>\n      <td>0.038759</td>\n      <td>-0.048515</td>\n      <td>0.056363</td>\n      <td>-0.076889</td>\n      <td>-0.002209</td>\n      <td>-0.011804</td>\n      <td>-0.015943</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>43.146961</td>\n      <td>41.264063</td>\n      <td>41.075821</td>\n      <td>11.843259</td>\n      <td>1.752020</td>\n      <td>0.906516</td>\n      <td>-0.728333</td>\n      <td>-1.275260</td>\n      <td>-0.678176</td>\n      <td>-1.560684</td>\n      <td>...</td>\n      <td>0.001683</td>\n      <td>0.048352</td>\n      <td>-0.065776</td>\n      <td>0.050750</td>\n      <td>-0.050526</td>\n      <td>0.048861</td>\n      <td>-0.084336</td>\n      <td>0.026353</td>\n      <td>-0.035720</td>\n      <td>-0.018588</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.647822</td>\n      <td>43.131905</td>\n      <td>43.437246</td>\n      <td>12.388259</td>\n      <td>1.809692</td>\n      <td>0.915806</td>\n      <td>-0.758906</td>\n      <td>-1.398698</td>\n      <td>-0.864005</td>\n      <td>4.788369</td>\n      <td>...</td>\n      <td>0.015460</td>\n      <td>0.047792</td>\n      <td>-0.049441</td>\n      <td>0.035196</td>\n      <td>-0.047893</td>\n      <td>0.061977</td>\n      <td>-0.082722</td>\n      <td>0.004341</td>\n      <td>-0.018094</td>\n      <td>-0.013906</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 75 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest - L1SO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['e0106', 'e0110', 'e0115', 'e0129', 'e0133', 'e0151', 'e0202',\n       'e0203', 'e0204', 'e0205', 'e0206', 'e0207', 'e0208', 'e0210',\n       'e0211', 'e0212', 'e0213', 'e0302', 'e0303', 'e0304', 'e0305',\n       'e0306', 'e0403', 'e0404', 'e0405', 'e0406', 'e0408', 'e0409',\n       'e0410', 'e0411', 'e0413', 'e0415', 'e0417', 'e0418', 'e0515',\n       'e0601', 'e0602', 'e0603', 'e0605', 'e0606', 'e0607', 'e0609',\n       'e0610', 'e0611', 'e0612', 'e0613', 'e0614', 'e0615', 'e0704',\n       'e0801', 'e0808', 'e0817', 'e0818', 'e1301', 'e1302', 'e1304'],\n      dtype=object)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvds = X_fsel.copy()\n",
    "cvds[\"patient_id\"] = patient_ids\n",
    "cvds[\"label\"] = y\n",
    "\n",
    "patients = np.unique(cvds[\"patient_id\"].values)\n",
    "patients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 56 - 13.291216611862183 s\n",
      "Accuracy 0.8224687933425797 precision 0.8539861226798194 specificity 0.17753120665742025 recall 0.8224687933425797 f1 0.7423500676592841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 56 - 13.05249571800232 s\n",
      "Accuracy 0.8025387870239774 precision 0.8415297176539395 specificity 0.19746121297602257 recall 0.8025387870239774 f1 0.714623739932149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 56 - 13.157115697860718 s\n",
      "Accuracy 0.9163732394366197 precision 0.8443898163917308 specificity 0.08075319734498947 recall 0.9163732394366197 f1 0.8789101166484437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 56 - 13.293891906738281 s\n",
      "Accuracy 0.8636363636363636 precision 0.7486865148861647 specificity 0.13434343434343435 recall 0.8636363636363636 f1 0.802063789868668\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "5 of 56 - 13.266520738601685 s\n",
      "Accuracy 0.9985029940119761 precision 1.0 specificity 0.0 recall 0.9985029940119761 f1 0.9992509363295881\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "6 of 56 - 12.974029541015625 s\n",
      "Accuracy 0.9791666666666666 precision 1.0 specificity 0.0 recall 0.9791666666666666 f1 0.9894736842105264\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 56 - 13.023027896881104 s\n",
      "Accuracy 0.7198404785643071 precision 0.798802189219703 specificity 0.3010654447806407 recall 0.7198404785643071 f1 0.608476414318328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 56 - 13.328911781311035 s\n",
      "Accuracy 0.7681017612524462 precision 0.7606926887748805 specificity 0.37679991118842016 recall 0.7681017612524462 f1 0.7087921808283278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 56 - 12.80536675453186 s\n",
      "Accuracy 0.7920621225194133 precision 0.9840766797194752 specificity 0.7152366922029822 recall 0.7920621225194134 f1 0.8731005612246905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 56 - 12.412490844726562 s\n",
      "Accuracy 0.6512013256006628 precision 0.7728618408633977 specificity 0.3487986743993372 recall 0.6512013256006628 f1 0.5136419888832122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 56 - 12.890530109405518 s\n",
      "Accuracy 0.7611262488646685 precision 0.7729908325033282 specificity 0.6156919961638394 recall 0.7611262488646685 f1 0.7662737002630657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 56 - 13.245978116989136 s\n",
      "Accuracy 0.7572413793103449 precision 0.8161731272294886 specificity 0.24275862068965517 recall 0.7572413793103449 f1 0.6526303253396849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 56 - 13.063360929489136 s\n",
      "Accuracy 0.9048697621744054 precision 0.9139195243231596 specificity 0.09513023782559456 recall 0.9048697621744054 f1 0.8596800713167062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 56 - 12.947701215744019 s\n",
      "Accuracy 0.8102272727272727 precision 0.8462409607438016 specificity 0.18977272727272726 recall 0.8102272727272727 f1 0.725288192661074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 56 - 12.83357572555542 s\n",
      "Accuracy 0.8125412541254126 precision 0.6852038865670855 specificity 0.18145991378879886 recall 0.8125412541254126 f1 0.7362137963067444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 56 - 12.566605806350708 s\n",
      "Accuracy 0.9470319634703196 precision 0.949837576364129 specificity 0.052968036529680365 recall 0.9470319634703196 f1 0.9212684297548982\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 56 - 13.245052099227905 s\n",
      "Accuracy 0.7522202486678508 precision 0.7745424761584596 specificity 0.40250911374631587 recall 0.7522202486678508 f1 0.6865119512750725\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 56 - 12.860489845275879 s\n",
      "Accuracy 0.9688398849472675 precision 0.969810837717367 specificity 0.0311601150527325 recall 0.9688398849472675 f1 0.953506407342794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 56 - 12.923446893692017 s\n",
      "Accuracy 0.8592178770949721 precision 0.8790374832246185 specificity 0.14078212290502792 recall 0.8592178770949721 f1 0.7941569080360981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 56 - 12.837742328643799 s\n",
      "Accuracy 0.9844961240310077 precision 0.9785974054927753 specificity 0.010681693931620335 recall 0.9844961240310077 f1 0.9815379025044723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 56 - 13.101982593536377 s\n",
      "Accuracy 0.8151260504201681 precision 0.8493763821318001 specificity 0.1961099046360117 recall 0.8151260504201681 f1 0.7341799519498441\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 56 - 12.97792363166809 s\n",
      "Accuracy 0.6716791979949874 precision 0.779473747024202 specificity 0.3283208020050125 recall 0.6716791979949874 f1 0.5397601950904247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 56 - 13.293888807296753 s\n",
      "Accuracy 0.35653104925053536 precision 0.5626290279259678 specificity 0.6462398357784143 recall 0.35653104925053536 f1 0.24804535788840226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 56 - 12.975353717803955 s\n",
      "Accuracy 0.8459343794579173 precision 0.8697045037701242 specificity 0.16323993246868826 recall 0.8459343794579173 f1 0.7767414408992341\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 56 - 12.825332880020142 s\n",
      "Accuracy 0.6975914362176628 precision 0.7281908498177507 specificity 0.3800087440450264 recall 0.6975914362176628 f1 0.6029602515855238\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 56 - 12.939788818359375 s\n",
      "Accuracy 0.7052980132450332 precision 0.5507497559488207 specificity 0.26230379896247463 recall 0.7052980132450332 f1 0.609850534087293\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 56 - 12.765540361404419 s\n",
      "Accuracy 0.3039647577092511 precision 0.7421074721178101 specificity 0.3441425245857752 recall 0.3039647577092511 f1 0.4044762957933244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 56 - 13.041984796524048 s\n",
      "Accuracy 0.15271317829457365 precision 0.9399638207785643 specificity 0.9263802357621655 recall 0.15271317829457365 f1 0.1944395541294766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 56 - 13.060538053512573 s\n",
      "Accuracy 0.14756258234519104 precision 0.8770956633275474 specificity 0.8570528022701936 recall 0.14756258234519104 f1 0.04406186448878422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 56 - 12.908063888549805 s\n",
      "Accuracy 0.9011976047904192 precision 0.8626629506695225 specificity 0.11019832564040953 recall 0.9011976047904192 f1 0.8803073609044605\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 56 - 12.874976873397827 s\n",
      "Accuracy 0.9013398294762485 precision 0.9148123333895547 specificity 0.6972375362526517 recall 0.9013398294762485 f1 0.9068119173280257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 56 - 12.990984678268433 s\n",
      "Accuracy 0.5351993214588634 precision 0.7348310887689029 specificity 0.5688571159309073 recall 0.5351993214588634 f1 0.4266932207807543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 56 - 13.070570707321167 s\n",
      "Accuracy 0.8542116630669546 precision 0.8756045168560428 specificity 0.18834152842240706 recall 0.8542116630669546 f1 0.7930397179931872\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 56 - 12.694029092788696 s\n",
      "Accuracy 0.692504258943782 precision 0.9324426098391673 specificity 0.8423577368099336 recall 0.692504258943782 f1 0.7710533431088835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 56 - 13.021015405654907 s\n",
      "Accuracy 0.9241316270566727 precision 0.9052126943082149 specificity 0.11684161219242856 recall 0.9241316270566727 f1 0.9141623907769328\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "36 of 56 - 13.297799110412598 s\n",
      "Accuracy 0.9654017857142857 precision 1.0 specificity 0.0 recall 0.9654017857142857 f1 0.9823963657013062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 56 - 12.863338470458984 s\n",
      "Accuracy 0.7944839857651246 precision 0.8525452953605082 specificity 0.47189838807993584 recall 0.7944839857651246 f1 0.8187016774354055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 56 - 13.2770516872406 s\n",
      "Accuracy 0.05625 precision 0.9559106691919191 specificity 0.9542349279161206 recall 0.05625 f1 0.023920945335980562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 56 - 12.794463396072388 s\n",
      "Accuracy 0.7969283276450512 precision 0.7817256187158724 specificity 0.4316244999587847 recall 0.7969283276450512 f1 0.7597590118225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 56 - 12.70682144165039 s\n",
      "Accuracy 0.8411885245901639 precision 0.8459248323219489 specificity 0.3372809527923569 recall 0.8411885245901639 f1 0.7962162345792891\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 56 - 12.937840461730957 s\n",
      "Accuracy 0.3897978825794033 precision 0.7728356473760947 specificity 0.6539426905729345 recall 0.3897978825794033 f1 0.24983169987259066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 56 - 12.754503965377808 s\n",
      "Accuracy 0.9057203389830508 precision 0.9236086589767734 specificity 0.4483444938219394 recall 0.9057203389830508 f1 0.9137776635444073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 56 - 12.544392585754395 s\n",
      "Accuracy 0.8574969021065675 precision 0.8778040350157927 specificity 0.14250309789343246 recall 0.8574969021065675 f1 0.7917116160877182\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "44 of 56 - 12.674804449081421 s\n",
      "Accuracy 0.9932773109243698 precision 1.0 specificity 0.0 recall 0.9932773109243698 f1 0.9966273187183813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 56 - 13.047660112380981 s\n",
      "Accuracy 0.6126760563380281 precision 0.5716580182851495 specificity 0.40471161346343476 recall 0.6126760563380281 f1 0.49556432052004024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 56 - 12.935253143310547 s\n",
      "Accuracy 0.7534076827757125 precision 0.814215453689756 specificity 0.24659231722428748 recall 0.7534076827757125 f1 0.6474514079542518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 56 - 12.79205584526062 s\n",
      "Accuracy 0.5367775831873906 precision 0.574677302893146 specificity 0.5773990127251795 recall 0.5367775831873906 f1 0.5343203631169751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 56 - 12.865001678466797 s\n",
      "Accuracy 0.9657534246575342 precision 0.9772587348006772 specificity 0.12177932306938821 recall 0.9657534246575342 f1 0.9713536438865998\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "49 of 56 - 12.681514978408813 s\n",
      "Accuracy 0.9125127161749745 precision 1.0 specificity 0.0 recall 0.9125127161749745 f1 0.9542553191489362\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "50 of 56 - 12.734583616256714 s\n",
      "Accuracy 0.9752066115702479 precision 1.0 specificity 0.0 recall 0.9752066115702479 f1 0.9874476987447699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 56 - 12.775984525680542 s\n",
      "Accuracy 0.14273127753303966 precision 0.7171661336069036 specificity 0.8313939968408065 recall 0.14273127753303966 f1 0.07985118686873306\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "52 of 56 - 12.981098890304565 s\n",
      "Accuracy 0.8221092757306226 precision 1.0 specificity 0.0 recall 0.8221092757306226 f1 0.902370990237099\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 56 - 13.058012247085571 s\n",
      "Accuracy 0.7874396135265701 precision 0.797248835578355 specificity 0.4897415945271212 recall 0.7874396135265701 f1 0.7490615490061365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 56 - 13.124330043792725 s\n",
      "Accuracy 0.8896473265073948 precision 0.8903865031948992 specificity 0.32306677098931147 recall 0.8896473265073948 f1 0.8590696276569112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 56 - 13.1394202709198 s\n",
      "Accuracy 0.9066193853427896 precision 0.9153393245365481 specificity 0.0933806146572104 recall 0.9066193853427896 f1 0.8622158320618967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 56 - 13.125892162322998 s\n",
      "Accuracy 0.7766624843161857 precision 0.8266047930997522 specificity 0.22892410786258524 recall 0.7766624843161857 f1 0.6802918022578383\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "tot = len(patients)\n",
    "for i, patient in enumerate(patients):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    df1 = cvds.loc[cvds[\"patient_id\"] != patient]\n",
    "    df2 = cvds.loc[cvds[\"patient_id\"] == patient]\n",
    "\n",
    "    y_train = df1[\"label\"].values\n",
    "    x_train = df1.loc[:, ~df1.columns.isin(['patient_id', 'label'])]\n",
    "    y_test = df2[\"label\"].values\n",
    "    x_test = df2.loc[:, ~df2.columns.isin(['patient_id', 'label'])]\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, zero_division=1, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(patients), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.822469     0.177531   0.853986  0.822469  0.742350\n1  0.802539     0.197461   0.841530  0.802539  0.714624\n2  0.916373     0.080753   0.844390  0.916373  0.878910\n3  0.863636     0.134343   0.748687  0.863636  0.802064\n4  0.998503     0.000000   1.000000  0.998503  0.999251\n5  0.979167     0.000000   1.000000  0.979167  0.989474\n6  0.719840     0.301065   0.798802  0.719840  0.608476\n7  0.768102     0.376800   0.760693  0.768102  0.708792\n8  0.792062     0.715237   0.984077  0.792062  0.873101\n9  0.651201     0.348799   0.772862  0.651201  0.513642",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.822469</td>\n      <td>0.177531</td>\n      <td>0.853986</td>\n      <td>0.822469</td>\n      <td>0.742350</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.802539</td>\n      <td>0.197461</td>\n      <td>0.841530</td>\n      <td>0.802539</td>\n      <td>0.714624</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.916373</td>\n      <td>0.080753</td>\n      <td>0.844390</td>\n      <td>0.916373</td>\n      <td>0.878910</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.863636</td>\n      <td>0.134343</td>\n      <td>0.748687</td>\n      <td>0.863636</td>\n      <td>0.802064</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.998503</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.998503</td>\n      <td>0.999251</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.979167</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.979167</td>\n      <td>0.989474</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.719840</td>\n      <td>0.301065</td>\n      <td>0.798802</td>\n      <td>0.719840</td>\n      <td>0.608476</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.768102</td>\n      <td>0.376800</td>\n      <td>0.760693</td>\n      <td>0.768102</td>\n      <td>0.708792</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.792062</td>\n      <td>0.715237</td>\n      <td>0.984077</td>\n      <td>0.792062</td>\n      <td>0.873101</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.651201</td>\n      <td>0.348799</td>\n      <td>0.772862</td>\n      <td>0.651201</td>\n      <td>0.513642</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.7510496070208089\n",
      "Precision 0.8466276241755609\n",
      "Specificity 0.3157027712492244\n",
      "Recall 0.7510496070208089\n",
      "F1 0.7109023363583241\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_10beats_l1so.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}