{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 10 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1  \\\n0  e0106  39.341333  39.831764  39.826684  11.282887  1.634628  0.913825   \n1  e0106  43.320409  45.006516  44.365681  12.474802  1.826689  0.901002   \n2  e0106  41.841597  41.778007  41.593833  11.837152  1.721631  0.911361   \n3  e0106  43.146961  41.264063  41.075821  11.843259  1.752020  0.906516   \n4  e0106  41.647822  43.131905  43.437246  12.388259  1.809692  0.915806   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.771782 -1.359522 -0.634856  ... -0.049375  0.037769 -0.045755  0.051531   \n1 -0.707731 -1.281504 -0.731562  ... -0.033106  0.009999 -0.014494  0.028882   \n2 -0.728350 -1.293684 -0.729167  ... -0.049280  0.038759 -0.048515  0.056363   \n3 -0.728333 -1.275260 -0.678176  ... -0.065776  0.050750 -0.050526  0.048861   \n4 -0.758906 -1.398698 -0.864005  ... -0.049441  0.035196 -0.047893  0.061977   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.078515  0.013704 -0.024545 -0.017430  0.001676    NSR  \n1 -0.048873 -0.010926 -0.026088  0.009880 -0.021702    NSR  \n2 -0.076889 -0.002209 -0.011804 -0.015943 -0.006355    NSR  \n3 -0.084336  0.026353 -0.035720 -0.018588  0.013943    NSR  \n4 -0.082722  0.004341 -0.018094 -0.013906 -0.001004    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>39.341333</td>\n      <td>39.831764</td>\n      <td>39.826684</td>\n      <td>11.282887</td>\n      <td>1.634628</td>\n      <td>0.913825</td>\n      <td>-0.771782</td>\n      <td>-1.359522</td>\n      <td>-0.634856</td>\n      <td>...</td>\n      <td>-0.049375</td>\n      <td>0.037769</td>\n      <td>-0.045755</td>\n      <td>0.051531</td>\n      <td>-0.078515</td>\n      <td>0.013704</td>\n      <td>-0.024545</td>\n      <td>-0.017430</td>\n      <td>0.001676</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>43.320409</td>\n      <td>45.006516</td>\n      <td>44.365681</td>\n      <td>12.474802</td>\n      <td>1.826689</td>\n      <td>0.901002</td>\n      <td>-0.707731</td>\n      <td>-1.281504</td>\n      <td>-0.731562</td>\n      <td>...</td>\n      <td>-0.033106</td>\n      <td>0.009999</td>\n      <td>-0.014494</td>\n      <td>0.028882</td>\n      <td>-0.048873</td>\n      <td>-0.010926</td>\n      <td>-0.026088</td>\n      <td>0.009880</td>\n      <td>-0.021702</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>41.841597</td>\n      <td>41.778007</td>\n      <td>41.593833</td>\n      <td>11.837152</td>\n      <td>1.721631</td>\n      <td>0.911361</td>\n      <td>-0.728350</td>\n      <td>-1.293684</td>\n      <td>-0.729167</td>\n      <td>...</td>\n      <td>-0.049280</td>\n      <td>0.038759</td>\n      <td>-0.048515</td>\n      <td>0.056363</td>\n      <td>-0.076889</td>\n      <td>-0.002209</td>\n      <td>-0.011804</td>\n      <td>-0.015943</td>\n      <td>-0.006355</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>43.146961</td>\n      <td>41.264063</td>\n      <td>41.075821</td>\n      <td>11.843259</td>\n      <td>1.752020</td>\n      <td>0.906516</td>\n      <td>-0.728333</td>\n      <td>-1.275260</td>\n      <td>-0.678176</td>\n      <td>...</td>\n      <td>-0.065776</td>\n      <td>0.050750</td>\n      <td>-0.050526</td>\n      <td>0.048861</td>\n      <td>-0.084336</td>\n      <td>0.026353</td>\n      <td>-0.035720</td>\n      <td>-0.018588</td>\n      <td>0.013943</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>41.647822</td>\n      <td>43.131905</td>\n      <td>43.437246</td>\n      <td>12.388259</td>\n      <td>1.809692</td>\n      <td>0.915806</td>\n      <td>-0.758906</td>\n      <td>-1.398698</td>\n      <td>-0.864005</td>\n      <td>...</td>\n      <td>-0.049441</td>\n      <td>0.035196</td>\n      <td>-0.047893</td>\n      <td>0.061977</td>\n      <td>-0.082722</td>\n      <td>0.004341</td>\n      <td>-0.018094</td>\n      <td>-0.013906</td>\n      <td>-0.001004</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_10beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    41933\nST     12752\nName: label, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.231317  0.109459  0.074913  0.064543  0.101660 -0.029506   \ndw_2    0.231317  1.000000  0.839064  0.449006  0.157026  0.490259 -0.520594   \ndw_3    0.109459  0.839064  1.000000  0.626999  0.236381  0.373744 -0.580056   \ndw_4    0.074913  0.449006  0.626999  1.000000  0.896524  0.070236 -0.268424   \ndw_5    0.064543  0.157026  0.236381  0.896524  1.000000 -0.079160 -0.026334   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.046809  0.030436  0.054751  0.044048  0.016599 -0.081643  0.054039   \ncfr_13 -0.035437  0.119758  0.045877  0.026303  0.014533  0.076890 -0.003660   \ncfr_14 -0.049050  0.004610 -0.023444 -0.031429 -0.033413  0.021208  0.025601   \ncfr_15 -0.071846 -0.117053 -0.131465 -0.089388 -0.041393 -0.006682  0.103513   \ncfr_16 -0.053104 -0.076826 -0.047859 -0.036217 -0.021446  0.052559 -0.032448   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.023452 -0.001861  0.003290  ... -0.062028 -0.061241 -0.032516   \ndw_2   -0.307376 -0.002765  0.011760  ... -0.133566  0.150743  0.235204   \ndw_3   -0.413234 -0.000351  0.005808  ... -0.207216  0.129536  0.268782   \ndw_4   -0.208628  0.000763  0.001641  ... -0.143689  0.054827  0.109764   \ndw_5   -0.035523  0.000409 -0.000153  ... -0.061473  0.009140  0.005657   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.087235 -0.001785  0.005388  ... -0.130493 -0.207093 -0.090454   \ncfr_13  0.006739  0.002726 -0.000638  ...  0.133437  0.032750 -0.215151   \ncfr_14  0.029224  0.003070 -0.002968  ...  0.098660  0.217327  0.047811   \ncfr_15  0.057917  0.004848 -0.008763  ...  0.266212  0.164693 -0.079613   \ncfr_16 -0.005212  0.008240 -0.005231  ...  0.248016  0.141547  0.178786   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.026775 -0.017739 -0.046809 -0.035437 -0.049050 -0.071846 -0.053104  \ndw_2    0.167194  0.046752  0.030436  0.119758  0.004610 -0.117053 -0.076826  \ndw_3    0.117633 -0.049634  0.054751  0.045877 -0.023444 -0.131465 -0.047859  \ndw_4    0.050373 -0.044638  0.044048  0.026303 -0.031429 -0.089388 -0.036217  \ndw_5    0.023553 -0.012439  0.016599  0.014533 -0.033413 -0.041393 -0.021446  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.024675  0.059365  1.000000  0.008142 -0.011310 -0.326522 -0.216222  \ncfr_13 -0.269635 -0.033375  0.008142  1.000000  0.199386  0.109416 -0.168514  \ncfr_14 -0.175074 -0.289421 -0.011310  0.199386  1.000000  0.171805 -0.139323  \ncfr_15 -0.147027 -0.089111 -0.326522  0.109416  0.171805  1.000000  0.253573  \ncfr_16  0.127395 -0.003147 -0.216222 -0.168514 -0.139323  0.253573  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.231317</td>\n      <td>0.109459</td>\n      <td>0.074913</td>\n      <td>0.064543</td>\n      <td>0.101660</td>\n      <td>-0.029506</td>\n      <td>0.023452</td>\n      <td>-0.001861</td>\n      <td>0.003290</td>\n      <td>...</td>\n      <td>-0.062028</td>\n      <td>-0.061241</td>\n      <td>-0.032516</td>\n      <td>-0.026775</td>\n      <td>-0.017739</td>\n      <td>-0.046809</td>\n      <td>-0.035437</td>\n      <td>-0.049050</td>\n      <td>-0.071846</td>\n      <td>-0.053104</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.231317</td>\n      <td>1.000000</td>\n      <td>0.839064</td>\n      <td>0.449006</td>\n      <td>0.157026</td>\n      <td>0.490259</td>\n      <td>-0.520594</td>\n      <td>-0.307376</td>\n      <td>-0.002765</td>\n      <td>0.011760</td>\n      <td>...</td>\n      <td>-0.133566</td>\n      <td>0.150743</td>\n      <td>0.235204</td>\n      <td>0.167194</td>\n      <td>0.046752</td>\n      <td>0.030436</td>\n      <td>0.119758</td>\n      <td>0.004610</td>\n      <td>-0.117053</td>\n      <td>-0.076826</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.109459</td>\n      <td>0.839064</td>\n      <td>1.000000</td>\n      <td>0.626999</td>\n      <td>0.236381</td>\n      <td>0.373744</td>\n      <td>-0.580056</td>\n      <td>-0.413234</td>\n      <td>-0.000351</td>\n      <td>0.005808</td>\n      <td>...</td>\n      <td>-0.207216</td>\n      <td>0.129536</td>\n      <td>0.268782</td>\n      <td>0.117633</td>\n      <td>-0.049634</td>\n      <td>0.054751</td>\n      <td>0.045877</td>\n      <td>-0.023444</td>\n      <td>-0.131465</td>\n      <td>-0.047859</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.074913</td>\n      <td>0.449006</td>\n      <td>0.626999</td>\n      <td>1.000000</td>\n      <td>0.896524</td>\n      <td>0.070236</td>\n      <td>-0.268424</td>\n      <td>-0.208628</td>\n      <td>0.000763</td>\n      <td>0.001641</td>\n      <td>...</td>\n      <td>-0.143689</td>\n      <td>0.054827</td>\n      <td>0.109764</td>\n      <td>0.050373</td>\n      <td>-0.044638</td>\n      <td>0.044048</td>\n      <td>0.026303</td>\n      <td>-0.031429</td>\n      <td>-0.089388</td>\n      <td>-0.036217</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.064543</td>\n      <td>0.157026</td>\n      <td>0.236381</td>\n      <td>0.896524</td>\n      <td>1.000000</td>\n      <td>-0.079160</td>\n      <td>-0.026334</td>\n      <td>-0.035523</td>\n      <td>0.000409</td>\n      <td>-0.000153</td>\n      <td>...</td>\n      <td>-0.061473</td>\n      <td>0.009140</td>\n      <td>0.005657</td>\n      <td>0.023553</td>\n      <td>-0.012439</td>\n      <td>0.016599</td>\n      <td>0.014533</td>\n      <td>-0.033413</td>\n      <td>-0.041393</td>\n      <td>-0.021446</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.046809</td>\n      <td>0.030436</td>\n      <td>0.054751</td>\n      <td>0.044048</td>\n      <td>0.016599</td>\n      <td>-0.081643</td>\n      <td>0.054039</td>\n      <td>0.087235</td>\n      <td>-0.001785</td>\n      <td>0.005388</td>\n      <td>...</td>\n      <td>-0.130493</td>\n      <td>-0.207093</td>\n      <td>-0.090454</td>\n      <td>0.024675</td>\n      <td>0.059365</td>\n      <td>1.000000</td>\n      <td>0.008142</td>\n      <td>-0.011310</td>\n      <td>-0.326522</td>\n      <td>-0.216222</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.035437</td>\n      <td>0.119758</td>\n      <td>0.045877</td>\n      <td>0.026303</td>\n      <td>0.014533</td>\n      <td>0.076890</td>\n      <td>-0.003660</td>\n      <td>0.006739</td>\n      <td>0.002726</td>\n      <td>-0.000638</td>\n      <td>...</td>\n      <td>0.133437</td>\n      <td>0.032750</td>\n      <td>-0.215151</td>\n      <td>-0.269635</td>\n      <td>-0.033375</td>\n      <td>0.008142</td>\n      <td>1.000000</td>\n      <td>0.199386</td>\n      <td>0.109416</td>\n      <td>-0.168514</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.049050</td>\n      <td>0.004610</td>\n      <td>-0.023444</td>\n      <td>-0.031429</td>\n      <td>-0.033413</td>\n      <td>0.021208</td>\n      <td>0.025601</td>\n      <td>0.029224</td>\n      <td>0.003070</td>\n      <td>-0.002968</td>\n      <td>...</td>\n      <td>0.098660</td>\n      <td>0.217327</td>\n      <td>0.047811</td>\n      <td>-0.175074</td>\n      <td>-0.289421</td>\n      <td>-0.011310</td>\n      <td>0.199386</td>\n      <td>1.000000</td>\n      <td>0.171805</td>\n      <td>-0.139323</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.071846</td>\n      <td>-0.117053</td>\n      <td>-0.131465</td>\n      <td>-0.089388</td>\n      <td>-0.041393</td>\n      <td>-0.006682</td>\n      <td>0.103513</td>\n      <td>0.057917</td>\n      <td>0.004848</td>\n      <td>-0.008763</td>\n      <td>...</td>\n      <td>0.266212</td>\n      <td>0.164693</td>\n      <td>-0.079613</td>\n      <td>-0.147027</td>\n      <td>-0.089111</td>\n      <td>-0.326522</td>\n      <td>0.109416</td>\n      <td>0.171805</td>\n      <td>1.000000</td>\n      <td>0.253573</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.053104</td>\n      <td>-0.076826</td>\n      <td>-0.047859</td>\n      <td>-0.036217</td>\n      <td>-0.021446</td>\n      <td>0.052559</td>\n      <td>-0.032448</td>\n      <td>-0.005212</td>\n      <td>0.008240</td>\n      <td>-0.005231</td>\n      <td>...</td>\n      <td>0.248016</td>\n      <td>0.141547</td>\n      <td>0.178786</td>\n      <td>0.127395</td>\n      <td>-0.003147</td>\n      <td>-0.216222</td>\n      <td>-0.168514</td>\n      <td>-0.139323</td>\n      <td>0.253573</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 310 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_192', 'fft_172', 'fft_254', 'mfw_6', 'fft_132', 'fft_244', 'fft_133', 'fft_248', 'fft_243', 'fft_143', 'fft_170', 'fft_236', 'fft_206', 'mfw_13', 'fft_135', 'fft_146', 'fft_198', 'fft_223', 'fft_173', 'fft_211', 'fft_171', 'fft_253', 'mfw_12', 'fft_200', 'fft_144', 'fft_139', 'fft_137', 'fft_184', 'fft_233', 'fft_212', 'fft_130', 'fft_256', 'mfw_5', 'fft_180', 'fft_177', 'fft_255', 'fft_221', 'fft_141', 'fft_158', 'fft_205', 'fft_231', 'fft_152', 'fft_161', 'fft_156', 'fft_193', 'fft_136', 'fft_234', 'fft_138', 'fft_213', 'fft_181', 'fft_226', 'fft_247', 'fft_149', 'mfw_11', 'fft_204', 'fft_218', 'fft_219', 'fft_207', 'fft_154', 'fft_228', 'fft_188', 'fft_237', 'fft_242', 'fft_165', 'fft_169', 'fft_249', 'fft_147', 'fft_224', 'fft_238', 'mfw_9', 'fft_250', 'fft_197', 'cfr_16', 'fft_194', 'fft_148', 'fft_150', 'mfw_16', 'fft_235', 'fft_252', 'fft_183', 'fft_140', 'fft_208', 'fft_134', 'fft_160', 'fft_182', 'fft_195', 'fft_142', 'mfw_7', 'fft_175', 'fft_239', 'fft_225', 'fft_222', 'fft_191', 'fft_145', 'fft_240', 'fft_187', 'fft_214', 'fft_201', 'fft_151', 'fft_199', 'fft_178', 'fft_174', 'fft_210', 'fft_179', 'fft_216', 'fft_168', 'fft_164', 'fft_159', 'fft_203', 'fft_186', 'fft_220', 'fft_162', 'fft_189', 'fft_155', 'fft_227', 'fft_167', 'fft_153', 'fft_176', 'fft_196', 'fft_241', 'fft_217', 'mfw_14', 'fft_251', 'fft_190', 'fft_246', 'mfw_15', 'fft_230', 'fft_166', 'mfw_10', 'mfw_8', 'fft_185', 'fft_245', 'fft_157', 'fft_229', 'fft_215', 'fft_202', 'fft_209', 'fft_131', 'fft_163', 'fft_232'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_24\n",
      "fft_25\n",
      "fft_27\n",
      "fft_28\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "fft_37\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 75\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1     mfw_2  \\\n0  39.341333  39.831764  39.826684  11.282887  1.634628  0.913825 -0.771782   \n1  43.320409  45.006516  44.365681  12.474802  1.826689  0.901002 -0.707731   \n2  41.841597  41.778007  41.593833  11.837152  1.721631  0.911361 -0.728350   \n3  43.146961  41.264063  41.075821  11.843259  1.752020  0.906516 -0.728333   \n4  41.647822  43.131905  43.437246  12.388259  1.809692  0.915806 -0.758906   \n\n      mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -1.359522 -0.634856  0.232364  ...  0.019450  0.044698 -0.049375  0.037769   \n1 -1.281504 -0.731562 -1.393341  ...  0.013422  0.040336 -0.033106  0.009999   \n2 -1.293684 -0.729167 -1.923488  ...  0.010183  0.036844 -0.049280  0.038759   \n3 -1.275260 -0.678176 -1.560684  ...  0.001683  0.048352 -0.065776  0.050750   \n4 -1.398698 -0.864005  4.788369  ...  0.015460  0.047792 -0.049441  0.035196   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.045755  0.051531 -0.078515  0.013704 -0.024545 -0.017430  \n1 -0.014494  0.028882 -0.048873 -0.010926 -0.026088  0.009880  \n2 -0.048515  0.056363 -0.076889 -0.002209 -0.011804 -0.015943  \n3 -0.050526  0.048861 -0.084336  0.026353 -0.035720 -0.018588  \n4 -0.047893  0.061977 -0.082722  0.004341 -0.018094 -0.013906  \n\n[5 rows x 75 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39.341333</td>\n      <td>39.831764</td>\n      <td>39.826684</td>\n      <td>11.282887</td>\n      <td>1.634628</td>\n      <td>0.913825</td>\n      <td>-0.771782</td>\n      <td>-1.359522</td>\n      <td>-0.634856</td>\n      <td>0.232364</td>\n      <td>...</td>\n      <td>0.019450</td>\n      <td>0.044698</td>\n      <td>-0.049375</td>\n      <td>0.037769</td>\n      <td>-0.045755</td>\n      <td>0.051531</td>\n      <td>-0.078515</td>\n      <td>0.013704</td>\n      <td>-0.024545</td>\n      <td>-0.017430</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>43.320409</td>\n      <td>45.006516</td>\n      <td>44.365681</td>\n      <td>12.474802</td>\n      <td>1.826689</td>\n      <td>0.901002</td>\n      <td>-0.707731</td>\n      <td>-1.281504</td>\n      <td>-0.731562</td>\n      <td>-1.393341</td>\n      <td>...</td>\n      <td>0.013422</td>\n      <td>0.040336</td>\n      <td>-0.033106</td>\n      <td>0.009999</td>\n      <td>-0.014494</td>\n      <td>0.028882</td>\n      <td>-0.048873</td>\n      <td>-0.010926</td>\n      <td>-0.026088</td>\n      <td>0.009880</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41.841597</td>\n      <td>41.778007</td>\n      <td>41.593833</td>\n      <td>11.837152</td>\n      <td>1.721631</td>\n      <td>0.911361</td>\n      <td>-0.728350</td>\n      <td>-1.293684</td>\n      <td>-0.729167</td>\n      <td>-1.923488</td>\n      <td>...</td>\n      <td>0.010183</td>\n      <td>0.036844</td>\n      <td>-0.049280</td>\n      <td>0.038759</td>\n      <td>-0.048515</td>\n      <td>0.056363</td>\n      <td>-0.076889</td>\n      <td>-0.002209</td>\n      <td>-0.011804</td>\n      <td>-0.015943</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>43.146961</td>\n      <td>41.264063</td>\n      <td>41.075821</td>\n      <td>11.843259</td>\n      <td>1.752020</td>\n      <td>0.906516</td>\n      <td>-0.728333</td>\n      <td>-1.275260</td>\n      <td>-0.678176</td>\n      <td>-1.560684</td>\n      <td>...</td>\n      <td>0.001683</td>\n      <td>0.048352</td>\n      <td>-0.065776</td>\n      <td>0.050750</td>\n      <td>-0.050526</td>\n      <td>0.048861</td>\n      <td>-0.084336</td>\n      <td>0.026353</td>\n      <td>-0.035720</td>\n      <td>-0.018588</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.647822</td>\n      <td>43.131905</td>\n      <td>43.437246</td>\n      <td>12.388259</td>\n      <td>1.809692</td>\n      <td>0.915806</td>\n      <td>-0.758906</td>\n      <td>-1.398698</td>\n      <td>-0.864005</td>\n      <td>4.788369</td>\n      <td>...</td>\n      <td>0.015460</td>\n      <td>0.047792</td>\n      <td>-0.049441</td>\n      <td>0.035196</td>\n      <td>-0.047893</td>\n      <td>0.061977</td>\n      <td>-0.082722</td>\n      <td>0.004341</td>\n      <td>-0.018094</td>\n      <td>-0.013906</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 75 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 11.073221445083618 s\n",
      "Accuracy 0.923105056231142 precision 0.922773966906288 specificity 0.7939910788565798 recall 0.923105056231142 f1 0.9200414800151417\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 11.032973289489746 s\n",
      "Accuracy 0.9282252902989852 precision 0.9277620348853434 specificity 0.8109690799310297 recall 0.9282252902989852 f1 0.9257411624829992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 11.068762302398682 s\n",
      "Accuracy 0.9244765474993143 precision 0.9240189737374475 specificity 0.8025079751365165 recall 0.9244765474993143 f1 0.9217064609657055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 10.849858283996582 s\n",
      "Accuracy 0.9277681265429277 precision 0.9273410100308592 specificity 0.7973615461864787 recall 0.9277681265429277 f1 0.9249296614841942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 11.24741506576538 s\n",
      "Accuracy 0.9303282435768492 precision 0.9307338437809936 specificity 0.8076682182707254 recall 0.9303282435768492 f1 0.9275543415271997\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 11.409051656723022 s\n",
      "Accuracy 0.9198134771875286 precision 0.9196863495540384 specificity 0.7907223162153468 recall 0.9198134771875286 f1 0.9165245205839191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 11.04498839378357 s\n",
      "Accuracy 0.9275852610405048 precision 0.9274862220723682 specificity 0.8019557242034783 recall 0.9275852610405048 f1 0.924752655863326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 11.053028345108032 s\n",
      "Accuracy 0.9244765474993143 precision 0.9242816230862994 specificity 0.8012888876619908 recall 0.9244765474993143 f1 0.9215901091891152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 11.470913648605347 s\n",
      "Accuracy 0.9228307579775076 precision 0.922119319423975 specificity 0.8049857090676473 recall 0.9228307579775076 f1 0.9201859034478266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 10.997783422470093 s\n",
      "Accuracy 0.9221907287190272 precision 0.9220870067830627 specificity 0.7949302294442596 recall 0.9221907287190272 f1 0.919061507527621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 10.799564599990845 s\n",
      "Accuracy 0.9266709335283899 precision 0.9267859662286824 specificity 0.7993559868166222 recall 0.9266709335283899 f1 0.9236922239100323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 10.947502374649048 s\n",
      "Accuracy 0.9291396178110999 precision 0.9292078856364859 specificity 0.8052990403657095 recall 0.9291396178110999 f1 0.9263735758099484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 10.822525262832642 s\n",
      "Accuracy 0.9220992959678157 precision 0.9216656335594475 specificity 0.7862940441640032 recall 0.9220992959678157 f1 0.9188387258832719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 11.305978059768677 s\n",
      "Accuracy 0.9302368108256377 precision 0.9303797581470908 specificity 0.8089530289250908 recall 0.9302368108256377 f1 0.9275597428714186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 10.841365575790405 s\n",
      "Accuracy 0.9210935357044894 precision 0.9209565373561999 specificity 0.7935679706643861 recall 0.9210935357044894 f1 0.9179138047248565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 10.982567071914673 s\n",
      "Accuracy 0.9237450854896224 precision 0.9231613207636571 specificity 0.7994530568171341 recall 0.9237450854896224 f1 0.9209246211778607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 10.906667947769165 s\n",
      "Accuracy 0.9233793544847765 precision 0.9235058215237718 specificity 0.7947745936697533 recall 0.9233793544847765 f1 0.9202057152863914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 10.828056573867798 s\n",
      "Accuracy 0.9270366645332359 precision 0.9269232948394478 specificity 0.8027115926277729 recall 0.9270366645332359 f1 0.9242150115030325\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 10.750583171844482 s\n",
      "Accuracy 0.9235622199871995 precision 0.9236797002871421 specificity 0.7924271133818208 recall 0.9235622199871995 f1 0.920333543746076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 10.96505880355835 s\n",
      "Accuracy 0.9271280972844473 precision 0.926392176357418 specificity 0.8023163358694037 recall 0.9271280972844473 f1 0.9245084977560825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 10.947489976882935 s\n",
      "Accuracy 0.9258480387674866 precision 0.9261713747564799 specificity 0.7945551082239465 recall 0.9258480387674866 f1 0.9226729544059169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 11.134601354598999 s\n",
      "Accuracy 0.9256651732650636 precision 0.9254619114338988 specificity 0.802510358503626 recall 0.9256651732650636 f1 0.9228369085088095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 11.069836854934692 s\n",
      "Accuracy 0.9199049099387401 precision 0.9193467952465721 specificity 0.7838618550994294 recall 0.9199049099387401 f1 0.9165648061665115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 10.996757507324219 s\n",
      "Accuracy 0.926305202523544 precision 0.9260545560851746 specificity 0.7966775365971119 recall 0.926305202523544 f1 0.9233586280576555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 10.851973056793213 s\n",
      "Accuracy 0.9267623662796014 precision 0.9268602416304088 specificity 0.796022184321622 recall 0.9267623662796014 f1 0.923707361626233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 10.890919208526611 s\n",
      "Accuracy 0.9244765474993143 precision 0.9248998070030816 specificity 0.7981289339617977 recall 0.9244765474993143 f1 0.9213352067516853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 11.025893211364746 s\n",
      "Accuracy 0.9262137697723325 precision 0.9259618888458991 specificity 0.801432517503499 recall 0.9262137697723325 f1 0.923385052054095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 11.058349609375 s\n",
      "Accuracy 0.9252994422602177 precision 0.9251379454662338 specificity 0.8040636935676514 recall 0.9252994422602177 f1 0.922490200996184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 10.705337047576904 s\n",
      "Accuracy 0.9253908750114291 precision 0.925341089695109 specificity 0.8019132393550394 recall 0.9253908750114291 f1 0.9224956400090166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 10.708996057510376 s\n",
      "Accuracy 0.9253908750114291 precision 0.9250673459786352 specificity 0.8019106564090954 recall 0.9253908750114291 f1 0.9225796884072721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 10.698314905166626 s\n",
      "Accuracy 0.9256651732650636 precision 0.9260333204885047 specificity 0.8018926891484293 recall 0.9256651732650636 f1 0.9226600187624013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 10.83301305770874 s\n",
      "Accuracy 0.9248422785041602 precision 0.9247151797762813 specificity 0.7929526236020343 recall 0.9248422785041602 f1 0.9217284942361724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 10.750977993011475 s\n",
      "Accuracy 0.9228307579775076 precision 0.9222274611939034 specificity 0.7937861000764043 recall 0.9228307579775076 f1 0.9198473921152297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 10.800030708312988 s\n",
      "Accuracy 0.9282252902989852 precision 0.9283508638858768 specificity 0.8078444032006242 recall 0.9282252902989852 f1 0.9254850902720925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 10.577562093734741 s\n",
      "Accuracy 0.9291396178110999 precision 0.9284002619176628 specificity 0.8009943861586185 recall 0.9291396178110999 f1 0.926533439851106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 10.9080069065094 s\n",
      "Accuracy 0.9193563134314712 precision 0.9191830318612164 specificity 0.7854326709132005 recall 0.9193563134314712 f1 0.9159227639632778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 10.746980667114258 s\n",
      "Accuracy 0.9241108164944684 precision 0.9243927177696752 specificity 0.7910380087017035 recall 0.9241108164944684 f1 0.9208138204970825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 10.998506546020508 s\n",
      "Accuracy 0.9273109627868703 precision 0.9271089868014321 specificity 0.7983369223073364 recall 0.9273109627868703 f1 0.9244140819479973\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 11.164056539535522 s\n",
      "Accuracy 0.9295053488159458 precision 0.9294294684254444 specificity 0.8137343933228375 recall 0.9295053488159458 f1 0.9269875609465579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 10.775702714920044 s\n",
      "Accuracy 0.9250251440065832 precision 0.9245598635803689 specificity 0.794950512635189 recall 0.9250251440065832 f1 0.9220744478411469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 10.785339832305908 s\n",
      "Accuracy 0.9274938282892933 precision 0.9273988827913447 specificity 0.8110431513947677 recall 0.9274938282892933 f1 0.9248798844179673\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 11.075027704238892 s\n",
      "Accuracy 0.9295053488159458 precision 0.929601525335839 specificity 0.8056714437955885 recall 0.9295053488159458 f1 0.9267483367288539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 11.067622900009155 s\n",
      "Accuracy 0.9271280972844473 precision 0.9270407182992834 specificity 0.8016922834343173 recall 0.9271280972844473 f1 0.9242755243076552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 10.835491180419922 s\n",
      "Accuracy 0.9253908750114291 precision 0.9250362858894469 specificity 0.800460477572051 recall 0.9253908750114291 f1 0.9225528756614404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 11.135056018829346 s\n",
      "Accuracy 0.9249337112553717 precision 0.9251332261492121 specificity 0.7944693113513122 recall 0.9249337112553717 f1 0.9217678215595991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 10.953464984893799 s\n",
      "Accuracy 0.9279509920453507 precision 0.9278281330877918 specificity 0.7997679784671077 recall 0.9279509920453507 f1 0.9250801477324231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 10.864589929580688 s\n",
      "Accuracy 0.923287921733565 precision 0.9231215814777114 specificity 0.7971748655494241 recall 0.923287921733565 f1 0.920260827225972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 10.862219095230103 s\n",
      "Accuracy 0.9288653195574654 precision 0.9287886420537527 specificity 0.8079063577978781 recall 0.9288653195574654 f1 0.9261972772237759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 10.749852180480957 s\n",
      "Accuracy 0.9262137697723325 precision 0.9264355248614918 specificity 0.803637718912198 recall 0.9262137697723325 f1 0.9233027240738484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 10.645017862319946 s\n",
      "Accuracy 0.9283167230501966 precision 0.9278703648125545 specificity 0.8038568634430794 recall 0.9283167230501966 f1 0.9256562523773564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 10.722877502441406 s\n",
      "Accuracy 0.9228307579775076 precision 0.9225844460546413 specificity 0.7978121130054138 recall 0.9228307579775076 f1 0.9198355437264116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 10.78580641746521 s\n",
      "Accuracy 0.9205449391972205 precision 0.9206196245591519 specificity 0.785548084830253 recall 0.9205449391972205 f1 0.9170700551235259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 10.992996454238892 s\n",
      "Accuracy 0.9284995885526196 precision 0.9280328511226156 specificity 0.8084545169983721 recall 0.9284995885526196 f1 0.925961248868314\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 10.708198070526123 s\n",
      "Accuracy 0.928773886806254 precision 0.9283783858454111 specificity 0.8071316467767828 recall 0.928773886806254 f1 0.9261851332836956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 10.643710613250732 s\n",
      "Accuracy 0.9233793544847765 precision 0.9228929053152184 specificity 0.791870910459446 recall 0.9233793544847765 f1 0.9203169986845898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 10.803064823150635 s\n",
      "Accuracy 0.9242936819968913 precision 0.9246371851211203 specificity 0.8008639509781685 recall 0.9242936819968913 f1 0.9212397252776593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 10.616999387741089 s\n",
      "Accuracy 0.9277681265429277 precision 0.9274173653802301 specificity 0.7985091520475025 recall 0.9277681265429277 f1 0.9249329370645244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 10.644519090652466 s\n",
      "Accuracy 0.9265795007771784 precision 0.9262736313033559 specificity 0.8127023473839474 recall 0.9265795007771784 f1 0.9240551747768382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 10.774023532867432 s\n",
      "Accuracy 0.9274023955380818 precision 0.9272091198150142 specificity 0.8045381311899349 recall 0.9274023955380818 f1 0.924657637945168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 10.584554672241211 s\n",
      "Accuracy 0.9263966352747555 precision 0.925964315722508 specificity 0.8011594329244341 recall 0.9263966352747555 f1 0.9236234688800171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 10.764986515045166 s\n",
      "Accuracy 0.9227393252262961 precision 0.9226112432450108 specificity 0.8026596884333901 recall 0.9227393252262961 f1 0.919833783225846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 10.897091388702393 s\n",
      "Accuracy 0.9284995885526196 precision 0.9280607764383367 specificity 0.80864668793537 recall 0.9284995885526196 f1 0.9259563250718253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 10.95527195930481 s\n",
      "Accuracy 0.9282252902989852 precision 0.92777138505917 specificity 0.8114266349362675 recall 0.9282252902989852 f1 0.9257489893594458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 11.229077339172363 s\n",
      "Accuracy 0.9284995885526196 precision 0.928258785593989 specificity 0.8059806115840252 recall 0.9284995885526196 f1 0.9258275749941944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 10.743494987487793 s\n",
      "Accuracy 0.926488068025967 precision 0.926148419738455 specificity 0.8059622335339411 recall 0.926488068025967 f1 0.9238061655106182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 11.039819240570068 s\n",
      "Accuracy 0.9205449391972205 precision 0.9206668777013283 specificity 0.7930757789793073 recall 0.9205449391972205 f1 0.9172642399233873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 10.402068614959717 s\n",
      "Accuracy 0.9257566060162751 precision 0.925512994580169 specificity 0.8060422361127023 recall 0.9257566060162751 f1 0.9230316520075534\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 10.193901538848877 s\n",
      "Accuracy 0.9300539453232147 precision 0.9297936406017475 specificity 0.8108643469368086 recall 0.9300539453232147 f1 0.9275358091028394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 10.084000587463379 s\n",
      "Accuracy 0.9243851147481028 precision 0.9238766477639422 specificity 0.7998035674598257 recall 0.9243851147481028 f1 0.9215606588664383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 10.068676948547363 s\n",
      "Accuracy 0.9274023955380818 precision 0.9269990384279603 specificity 0.8056693677614444 recall 0.9274023955380818 f1 0.9247526165770357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 10.328525066375732 s\n",
      "Accuracy 0.9242936819968913 precision 0.9245858384218378 specificity 0.7984663395040689 recall 0.9242936819968913 f1 0.9211913861625096\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 10.242327213287354 s\n",
      "Accuracy 0.926488068025967 precision 0.9269323342177593 specificity 0.7976605690579208 recall 0.926488068025967 f1 0.9233752524685026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 10.070002794265747 s\n",
      "Accuracy 0.9233793544847765 precision 0.9227182339049979 specificity 0.8000007431784683 recall 0.9233793544847765 f1 0.9205938946188023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 10.195981740951538 s\n",
      "Accuracy 0.9258480387674866 precision 0.925930873033281 specificity 0.7890554741679753 recall 0.9258480387674866 f1 0.9225983560147906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 9.943986177444458 s\n",
      "Accuracy 0.926305202523544 precision 0.9261065899557599 specificity 0.7991698105815775 recall 0.926305202523544 f1 0.9234051873531934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 10.109523296356201 s\n",
      "Accuracy 0.9274938282892933 precision 0.927148165677162 specificity 0.8014118276040181 recall 0.9274938282892933 f1 0.9247222620701205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 10.116249084472656 s\n",
      "Accuracy 0.9252994422602177 precision 0.9246338927081599 specificity 0.7974030883471735 recall 0.9252994422602177 f1 0.9224885258797685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 10.133193731307983 s\n",
      "Accuracy 0.9225564597238731 precision 0.9223805747369617 specificity 0.7946899855833698 recall 0.9225564597238731 f1 0.9194506449060997\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 9.67611575126648 s\n",
      "Accuracy 0.9288653195574654 precision 0.9281953212926018 specificity 0.8078687452463779 recall 0.9288653195574654 f1 0.9263936354058173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 9.861525535583496 s\n",
      "Accuracy 0.9198134771875286 precision 0.9194698862242987 specificity 0.7994213308259176 recall 0.9198134771875286 f1 0.9168334707778244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 9.88884425163269 s\n",
      "Accuracy 0.9295053488159458 precision 0.9294661955113778 specificity 0.8001750376367044 recall 0.9295053488159458 f1 0.9266560712865649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 10.026607513427734 s\n",
      "Accuracy 0.9267623662796014 precision 0.926839624660026 specificity 0.7994367353405106 recall 0.9267623662796014 f1 0.9237982947208926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 9.908985137939453 s\n",
      "Accuracy 0.9278595592941392 precision 0.9275083587247388 specificity 0.8002057176973506 recall 0.9278595592941392 f1 0.9250683120403624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 9.968996047973633 s\n",
      "Accuracy 0.9226478924750846 precision 0.9221638485356468 specificity 0.7936941795325699 recall 0.9226478924750846 f1 0.9196166610881885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 9.729086637496948 s\n",
      "Accuracy 0.9263966352747555 precision 0.9268888716403763 specificity 0.7995236880970378 recall 0.9263966352747555 f1 0.9233162948630161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 9.442507982254028 s\n",
      "Accuracy 0.928773886806254 precision 0.9283846277258013 specificity 0.803690099599889 recall 0.928773886806254 f1 0.9261002204416506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 9.64499020576477 s\n",
      "Accuracy 0.9256651732650636 precision 0.9250123805539087 specificity 0.8060114502552373 recall 0.9256651732650636 f1 0.923077558576816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 9.784900426864624 s\n",
      "Accuracy 0.9242936819968913 precision 0.9243271305880925 specificity 0.7964051261175674 recall 0.9242936819968913 f1 0.9212094848743331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 9.631011724472046 s\n",
      "Accuracy 0.9273109627868703 precision 0.9271100502700989 specificity 0.8024234987482406 recall 0.9273109627868703 f1 0.9245146378349619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 10.009010791778564 s\n",
      "Accuracy 0.9221907287190272 precision 0.922487449539772 specificity 0.7964977707485181 recall 0.9221907287190272 f1 0.9189900518600042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 9.91852331161499 s\n",
      "Accuracy 0.9262137697723325 precision 0.9258669115168316 specificity 0.8080167198673385 recall 0.9262137697723325 f1 0.9235800765067541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 10.023318767547607 s\n",
      "Accuracy 0.9274023955380818 precision 0.926750474711259 specificity 0.808499128272069 recall 0.9274023955380818 f1 0.9249102934558125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 10.006508350372314 s\n",
      "Accuracy 0.9274023955380818 precision 0.9271722434134956 specificity 0.804046327829025 recall 0.9274023955380818 f1 0.9246569719420438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 9.846048593521118 s\n",
      "Accuracy 0.9268537990308129 precision 0.9268709294755448 specificity 0.8026659933015639 recall 0.9268537990308129 f1 0.9239889525065856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 9.403602361679077 s\n",
      "Accuracy 0.9246594130017373 precision 0.9240609848973167 specificity 0.8046046604624811 recall 0.9246594130017373 f1 0.9219964309370254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 9.662991046905518 s\n",
      "Accuracy 0.9269452317820244 precision 0.9267683930362713 specificity 0.8005449404148081 recall 0.9269452317820244 f1 0.9240870954132316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 9.71722936630249 s\n",
      "Accuracy 0.9301453780744262 precision 0.9297618378381806 specificity 0.8100431901764082 recall 0.9301453780744262 f1 0.9276497837161539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 9.741983413696289 s\n",
      "Accuracy 0.9294139160647343 precision 0.9293482908557532 specificity 0.8070072412827137 recall 0.9294139160647343 f1 0.926732682605075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 9.98701000213623 s\n",
      "Accuracy 0.9237450854896224 precision 0.9234830869030638 specificity 0.7923339711031813 recall 0.9237450854896224 f1 0.9206305303776923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 9.730941772460938 s\n",
      "Accuracy 0.9276766937917162 precision 0.927373250741682 specificity 0.8030143983725073 recall 0.9276766937917162 f1 0.9249349101326173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 9.78691554069519 s\n",
      "Accuracy 0.9221907287190272 precision 0.9223786602146471 specificity 0.7999371507714425 recall 0.9221907287190272 f1 0.9191113058290193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 9.79900574684143 s\n",
      "Accuracy 0.9309682728353296 precision 0.9306537756961768 specificity 0.8122452980677674 recall 0.9309682728353296 f1 0.9285177782859579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 9.749128580093384 s\n",
      "Accuracy 0.926488068025967 precision 0.9259396321992176 specificity 0.8031293777858517 recall 0.926488068025967 f1 0.9238062195635875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 10.02904224395752 s\n",
      "Accuracy 0.9251165767577947 precision 0.9251667726172212 specificity 0.7956206852670835 recall 0.9251165767577947 f1 0.9220261201254215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 9.820151329040527 s\n",
      "Accuracy 0.9296882143183688 precision 0.9300774862099261 specificity 0.8127263668362336 recall 0.9296882143183688 f1 0.9270236343366397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 9.913058996200562 s\n",
      "Accuracy 0.9241108164944684 precision 0.9236155825173904 specificity 0.8026972453889483 recall 0.9241108164944684 f1 0.9213513111842354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 10.108640670776367 s\n",
      "Accuracy 0.9220078632166042 precision 0.9222949915453552 specificity 0.7937108437683291 recall 0.9220078632166042 f1 0.9187310765835048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 10.038988828659058 s\n",
      "Accuracy 0.9265795007771784 precision 0.9263861454482569 specificity 0.8071599551316853 recall 0.9265795007771784 f1 0.9238827642242906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 9.825956106185913 s\n",
      "Accuracy 0.9247508457529487 precision 0.9241601011902367 specificity 0.7998035918558242 recall 0.9247508457529487 f1 0.9219629651131758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 9.886977910995483 s\n",
      "Accuracy 0.9294139160647343 precision 0.9290224162383882 specificity 0.8089001330165143 recall 0.9294139160647343 f1 0.9268791589232418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 9.580047130584717 s\n",
      "Accuracy 0.9210021029532779 precision 0.9206855028633173 specificity 0.7940308896575936 recall 0.9210021029532779 f1 0.9178890096729975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 9.843982696533203 s\n",
      "Accuracy 0.9268537990308129 precision 0.9265991169424866 specificity 0.8016376327547063 recall 0.9268537990308129 f1 0.924044845417428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 9.862913370132446 s\n",
      "Accuracy 0.9181676876657219 precision 0.9186595248781929 specificity 0.7828514922302674 recall 0.9181676876657219 f1 0.9144445439259126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 9.744580030441284 s\n",
      "Accuracy 0.9295053488159458 precision 0.9293503547649378 specificity 0.8056695629284341 recall 0.9295053488159458 f1 0.9268209560100006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 9.73800802230835 s\n",
      "Accuracy 0.9242936819968913 precision 0.9245628177811555 specificity 0.7929212228857484 recall 0.9242936819968913 f1 0.9210536799168305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 9.808500528335571 s\n",
      "Accuracy 0.9277681265429277 precision 0.9275915852632772 specificity 0.8044311193095983 recall 0.9277681265429277 f1 0.9250233167310856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 10.676217555999756 s\n",
      "Accuracy 0.9292310505623114 precision 0.9286498381065549 specificity 0.8034416393690639 recall 0.9292310505623114 f1 0.9266274831862571\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 11.131497144699097 s\n",
      "Accuracy 0.9260309042699095 precision 0.9259367207610568 specificity 0.7988206197318624 recall 0.9260309042699095 f1 0.9230844664798524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 11.684978723526001 s\n",
      "Accuracy 0.9257566060162751 precision 0.9258315885902303 specificity 0.801399264653676 recall 0.9257566060162751 f1 0.9228202224415255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 11.61297869682312 s\n",
      "Accuracy 0.9274938282892933 precision 0.9271812958985055 specificity 0.8092514661530341 recall 0.9274938282892933 f1 0.9249037466249567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 11.634980916976929 s\n",
      "Accuracy 0.9237450854896224 precision 0.9235754788417552 specificity 0.7965468682054765 recall 0.9237450854896224 f1 0.9207124237514015\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 11.281314849853516 s\n",
      "Accuracy 0.9255737405138521 precision 0.9250469156056055 specificity 0.7992116853362107 recall 0.9255737405138521 f1 0.9227657421057475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 10.361029624938965 s\n",
      "Accuracy 0.9242022492456798 precision 0.9241480179578362 specificity 0.7960230563349491 recall 0.9242022492456798 f1 0.9211315304961135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 10.190552949905396 s\n",
      "Accuracy 0.9240193837432569 precision 0.9237879078028239 specificity 0.8000617637613476 recall 0.9240193837432569 f1 0.9211031706048218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 9.902961492538452 s\n",
      "Accuracy 0.9273109627868703 precision 0.9272966279964909 specificity 0.8033889881323164 recall 0.9273109627868703 f1 0.9244827812142369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 9.825011968612671 s\n",
      "Accuracy 0.9270366645332359 precision 0.9269264995660244 specificity 0.8055388260743892 recall 0.9270366645332359 f1 0.9242837714869603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 10.010559558868408 s\n",
      "Accuracy 0.9229221907287191 precision 0.9230038342333959 specificity 0.7960437723600788 recall 0.9229221907287191 f1 0.9197845034052727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 9.8525390625 s\n",
      "Accuracy 0.9278595592941392 precision 0.9275723653214983 specificity 0.8059127912442138 recall 0.9278595592941392 f1 0.9251872447441557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 9.918914556503296 s\n",
      "Accuracy 0.926305202523544 precision 0.9258661934869323 specificity 0.8028632761059902 recall 0.926305202523544 f1 0.9235751045782851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 9.759563446044922 s\n",
      "Accuracy 0.9300539453232147 precision 0.929725798743657 specificity 0.8047807256603076 recall 0.9300539453232147 f1 0.9274145652164738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 9.81927490234375 s\n",
      "Accuracy 0.9263966352747555 precision 0.9263328473129862 specificity 0.803385991367905 recall 0.9263966352747555 f1 0.9235634878835758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 9.801410913467407 s\n",
      "Accuracy 0.9253908750114291 precision 0.9254717753747732 specificity 0.8012571998356381 recall 0.9253908750114291 f1 0.9224414556832417\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 9.926636695861816 s\n",
      "Accuracy 0.9274938282892933 precision 0.9270230356509673 specificity 0.8051915881941017 recall 0.9274938282892933 f1 0.924856985542636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 9.830982446670532 s\n",
      "Accuracy 0.923105056231142 precision 0.923059955475436 specificity 0.7952562749422522 recall 0.923105056231142 f1 0.9199871438359393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 9.929439544677734 s\n",
      "Accuracy 0.9251165767577947 precision 0.9248170161170282 specificity 0.7955030217239083 recall 0.9251165767577947 f1 0.9221280656438857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 9.777873277664185 s\n",
      "Accuracy 0.9272195300356588 precision 0.9267874710587896 specificity 0.8058985905288648 recall 0.9272195300356588 f1 0.9245813210321826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 10.004998207092285 s\n",
      "Accuracy 0.9243851147481028 precision 0.924538742644264 specificity 0.7864153998187633 recall 0.9243851147481028 f1 0.9210090548485491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 9.91584825515747 s\n",
      "Accuracy 0.9275852610405048 precision 0.9270738834788568 specificity 0.8024140410462559 recall 0.9275852610405048 f1 0.9248959272723903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 9.779983758926392 s\n",
      "Accuracy 0.9253908750114291 precision 0.9245675490328996 specificity 0.8012241214745665 recall 0.9253908750114291 f1 0.9227410189262087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 9.74408745765686 s\n",
      "Accuracy 0.9262137697723325 precision 0.9256553840076595 specificity 0.8026855866397711 recall 0.9262137697723325 f1 0.9235185798048299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 9.901003360748291 s\n",
      "Accuracy 0.926488068025967 precision 0.9258743514301202 specificity 0.8089093057762764 recall 0.926488068025967 f1 0.923974561510676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 9.740513324737549 s\n",
      "Accuracy 0.926488068025967 precision 0.9264919316458478 specificity 0.8002131277946655 recall 0.926488068025967 f1 0.9235580765693183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 9.869574308395386 s\n",
      "Accuracy 0.9273109627868703 precision 0.9272164259679848 specificity 0.7966287314172308 recall 0.9273109627868703 f1 0.9243394363761537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 10.122017860412598 s\n",
      "Accuracy 0.9274023955380818 precision 0.9270713112301551 specificity 0.8067286120585714 recall 0.9274023955380818 f1 0.9247548350719527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 9.774881839752197 s\n",
      "Accuracy 0.9257566060162751 precision 0.9254799591806736 specificity 0.8020048210404788 recall 0.9257566060162751 f1 0.922940430180277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 9.748640060424805 s\n",
      "Accuracy 0.9249337112553717 precision 0.9251558687724784 specificity 0.7970266230996575 recall 0.9249337112553717 f1 0.9218273689135287\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 10.033533334732056 s\n",
      "Accuracy 0.9239279509920454 precision 0.9240523906255441 specificity 0.7931453224760763 recall 0.9239279509920454 f1 0.9207247727727617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 9.693988561630249 s\n",
      "Accuracy 0.9269452317820244 precision 0.9274156678471865 specificity 0.7966505270724383 recall 0.9269452317820244 f1 0.9238113717784665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 9.952025651931763 s\n",
      "Accuracy 0.9289567523086769 precision 0.9286439589564077 specificity 0.8057764316510434 recall 0.9289567523086769 f1 0.9263122762522245\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 9.817760944366455 s\n",
      "Accuracy 0.9238365182408339 precision 0.9234573281422828 specificity 0.7925195130333296 recall 0.9238365182408339 f1 0.920766395725904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 9.804017543792725 s\n",
      "Accuracy 0.9298710798207918 precision 0.9300208080944647 specificity 0.8088687277435639 recall 0.9298710798207918 f1 0.9271825282215195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 9.721792697906494 s\n",
      "Accuracy 0.9271280972844473 precision 0.9266364327393601 specificity 0.8118341128580636 recall 0.9271280972844473 f1 0.9246547694470363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 9.704407691955566 s\n",
      "Accuracy 0.9268537990308129 precision 0.9267560412068934 specificity 0.8025937827981106 recall 0.9268537990308129 f1 0.924020668069199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 9.832738161087036 s\n",
      "Accuracy 0.9211849684557009 precision 0.9208946062054922 specificity 0.7885830808266242 recall 0.9211849684557009 f1 0.9179185654021768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 9.83863353729248 s\n",
      "Accuracy 0.926305202523544 precision 0.9259160647320099 specificity 0.8040269747832018 recall 0.926305202523544 f1 0.9235875929649733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 9.750428199768066 s\n",
      "Accuracy 0.9238365182408339 precision 0.9240417295016512 specificity 0.793519352092725 recall 0.9238365182408339 f1 0.9206186598465685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 9.78958511352539 s\n",
      "Accuracy 0.9295967815671573 precision 0.929188516192496 specificity 0.80885395572165 recall 0.9295967815671573 f1 0.927070258600912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 9.910887241363525 s\n",
      "Accuracy 0.9222821614702387 precision 0.9217368677167554 specificity 0.7997360499136769 recall 0.9222821614702387 f1 0.9194260947308214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 9.712997198104858 s\n",
      "Accuracy 0.928773886806254 precision 0.9287404703419916 specificity 0.8068745836604669 recall 0.928773886806254 f1 0.9260666538570623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 9.867865800857544 s\n",
      "Accuracy 0.9263966352747555 precision 0.9262744336479032 specificity 0.803255439028846 recall 0.9263966352747555 f1 0.9235775873848614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 9.681696653366089 s\n",
      "Accuracy 0.9274938282892933 precision 0.9279425421203018 specificity 0.8019159909618491 recall 0.9274938282892933 f1 0.9245085897775043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 9.625691175460815 s\n",
      "Accuracy 0.9251165767577947 precision 0.9247221070924658 specificity 0.789758415412331 recall 0.9251165767577947 f1 0.9220104071608839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 9.764575719833374 s\n",
      "Accuracy 0.926122337021121 precision 0.9258280193087742 specificity 0.792397865622998 recall 0.926122337021121 f1 0.923076830054071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 9.738829135894775 s\n",
      "Accuracy 0.9265795007771784 precision 0.9263342384173135 specificity 0.7955210402251239 recall 0.9265795007771784 f1 0.9236086078218263\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 9.767004489898682 s\n",
      "Accuracy 0.923470787235988 precision 0.9230201185932173 specificity 0.8009347688346905 recall 0.923470787235988 f1 0.9206373999620096\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 9.791038036346436 s\n",
      "Accuracy 0.9284995885526196 precision 0.9287054112750714 specificity 0.8074773960564019 recall 0.9284995885526196 f1 0.9257343439755752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 9.614729642868042 s\n",
      "Accuracy 0.9256651732650636 precision 0.9253160514683789 specificity 0.7981855922323299 recall 0.9256651732650636 f1 0.9227734964209442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 9.65203595161438 s\n",
      "Accuracy 0.9271280972844473 precision 0.9266540568010211 specificity 0.811566997463472 recall 0.9271280972844473 f1 0.9246420410156878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 9.847845792770386 s\n",
      "Accuracy 0.9271280972844473 precision 0.926848221026661 specificity 0.8016718388546791 recall 0.9271280972844473 f1 0.9243338807641276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 9.799461126327515 s\n",
      "Accuracy 0.9223735942214502 precision 0.9222088484983586 specificity 0.7864336894327849 recall 0.9223735942214502 f1 0.9190386487186286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 9.7049560546875 s\n",
      "Accuracy 0.9245679802505258 precision 0.9244978799707028 specificity 0.8036313414415776 recall 0.9245679802505258 f1 0.9217057714638227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 10.00118637084961 s\n",
      "Accuracy 0.9245679802505258 precision 0.9245887453596541 specificity 0.8025887638715697 recall 0.9245679802505258 f1 0.9216525741577993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 9.83225679397583 s\n",
      "Accuracy 0.9267623662796014 precision 0.926432336970111 specificity 0.8051853872398687 recall 0.9267623662796014 f1 0.9240635366721092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 9.67360782623291 s\n",
      "Accuracy 0.9252080095090062 precision 0.9250976544374369 specificity 0.7954835672191127 recall 0.9252080095090062 f1 0.9221629100159284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 9.630043506622314 s\n",
      "Accuracy 0.9270366645332359 precision 0.9273362141048299 specificity 0.8028817232336599 recall 0.9270366645332359 f1 0.9241036133777265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 9.643863201141357 s\n",
      "Accuracy 0.9260309042699095 precision 0.9250913808829068 specificity 0.8020844970229941 recall 0.9260309042699095 f1 0.9234648703313745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 9.86465048789978 s\n",
      "Accuracy 0.9266709335283899 precision 0.9267576527063031 specificity 0.7979726544659933 recall 0.9266709335283899 f1 0.923665619771989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 9.617953538894653 s\n",
      "Accuracy 0.9241108164944684 precision 0.9237020057666251 specificity 0.7911027151105974 recall 0.9241108164944684 f1 0.9210196579642214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 9.728474378585815 s\n",
      "Accuracy 0.9284081558014081 precision 0.9279730008916756 specificity 0.808436778709664 recall 0.9284081558014081 f1 0.9258567646303465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 9.8428795337677 s\n",
      "Accuracy 0.9238365182408339 precision 0.9238615684773404 specificity 0.7965473517485884 recall 0.9238365182408339 f1 0.9207482649409482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 9.627276420593262 s\n",
      "Accuracy 0.9255737405138521 precision 0.9253516626278799 specificity 0.8024821883365262 recall 0.9255737405138521 f1 0.9227487035740078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 9.681845903396606 s\n",
      "Accuracy 0.9256651732650636 precision 0.9263273241628286 specificity 0.7988316104741264 recall 0.9256651732650636 f1 0.9225088506156781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 9.729557514190674 s\n",
      "Accuracy 0.9281338575477737 precision 0.9278122386211899 specificity 0.8067152478140321 recall 0.9281338575477737 f1 0.9254977015309562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 9.629221200942993 s\n",
      "Accuracy 0.9240193837432569 precision 0.9239238071228225 specificity 0.7946003072576394 recall 0.9240193837432569 f1 0.9209197287568932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 9.756102323532104 s\n",
      "Accuracy 0.9281338575477737 precision 0.9279218142108865 specificity 0.8043944967828661 recall 0.9281338575477737 f1 0.9254068264856588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 9.740010023117065 s\n",
      "Accuracy 0.9273109627868703 precision 0.9265928917498274 specificity 0.8016807055552677 recall 0.9273109627868703 f1 0.924672568433435\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 9.693989515304565 s\n",
      "Accuracy 0.923470787235988 precision 0.9232092444314449 specificity 0.7937002122355137 recall 0.923470787235988 f1 0.9203857170776483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 9.861746788024902 s\n",
      "Accuracy 0.9238365182408339 precision 0.9233741343661392 specificity 0.7960926135077789 recall 0.9238365182408339 f1 0.9208877886447516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 9.743358850479126 s\n",
      "Accuracy 0.9275852610405048 precision 0.927205194084747 specificity 0.8063782789445657 recall 0.9275852610405048 f1 0.9249488466976484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 9.799063920974731 s\n",
      "Accuracy 0.9251165767577947 precision 0.9247479461149021 specificity 0.8046427085454945 recall 0.9251165767577947 f1 0.9223840171356958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 9.79343056678772 s\n",
      "Accuracy 0.9295967815671573 precision 0.9293929972846415 specificity 0.8063425671258817 recall 0.9295967815671573 f1 0.9269451747071685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 9.503252267837524 s\n",
      "Accuracy 0.9236536527384109 precision 0.9238368645458493 specificity 0.7959153285865089 recall 0.9236536527384109 f1 0.9205003685152122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 9.659286260604858 s\n",
      "Accuracy 0.9221907287190272 precision 0.9219599936245269 specificity 0.7944091909958552 recall 0.9221907287190272 f1 0.9190863347622011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 10.016250848770142 s\n",
      "Accuracy 0.9251165767577947 precision 0.9246159364756934 specificity 0.8020305006216094 recall 0.9251165767577947 f1 0.9223619068406802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 9.530144214630127 s\n",
      "Accuracy 0.9265795007771784 precision 0.9260471426986799 specificity 0.8076669313128214 recall 0.9265795007771784 f1 0.9240072452382551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 9.653143644332886 s\n",
      "Accuracy 0.9260309042699095 precision 0.925663400079467 specificity 0.8014222372440402 recall 0.9260309042699095 f1 0.923235062893231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 10.029170274734497 s\n",
      "Accuracy 0.9302368108256377 precision 0.9301495558767072 specificity 0.8126777582738015 recall 0.9302368108256377 f1 0.9277117007712088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 9.748741388320923 s\n",
      "Accuracy 0.9221907287190272 precision 0.9221813775818568 specificity 0.7925131985341487 recall 0.9221907287190272 f1 0.9189688544095784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 9.807681560516357 s\n",
      "Accuracy 0.9295053488159458 precision 0.9291987438945598 specificity 0.8020235774444379 recall 0.9295053488159458 f1 0.9267812928305578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 9.876839399337769 s\n",
      "Accuracy 0.9284995885526196 precision 0.9282375134488946 specificity 0.8087815026946185 recall 0.9284995885526196 f1 0.9259016387241584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 9.696016311645508 s\n",
      "Accuracy 0.9295053488159458 precision 0.9291501614575878 specificity 0.808648745469878 recall 0.9295053488159458 f1 0.9269544926959483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 9.743041276931763 s\n",
      "Accuracy 0.9279509920453507 precision 0.9278308903921895 specificity 0.8026826083640576 recall 0.9279509920453507 f1 0.9251504588356216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 9.648417234420776 s\n",
      "Accuracy 0.9263966352747555 precision 0.9264130832306312 specificity 0.7989543561809224 recall 0.9263966352747555 f1 0.9234295128405101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 9.857540607452393 s\n",
      "Accuracy 0.923470787235988 precision 0.9231098895385781 specificity 0.799119426176149 recall 0.923470787235988 f1 0.920559959942404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 9.73445725440979 s\n",
      "Accuracy 0.9263966352747555 precision 0.9261745929151913 specificity 0.8099219939813117 recall 0.9263966352747555 f1 0.9237737171623843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 9.9015371799469 s\n",
      "Accuracy 0.9249337112553717 precision 0.9249615258848523 specificity 0.7922118699218597 recall 0.9249337112553717 f1 0.9217576494787797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 9.846461534500122 s\n",
      "Accuracy 0.9265795007771784 precision 0.9263229435708672 specificity 0.8015882667491582 recall 0.9265795007771784 f1 0.9237639875509633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 9.880717992782593 s\n",
      "Accuracy 0.9250251440065832 precision 0.9247478622031602 specificity 0.8024450620542791 recall 0.9250251440065832 f1 0.9222052648065929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 9.648936986923218 s\n",
      "Accuracy 0.9278595592941392 precision 0.9270991712262692 specificity 0.8081446165604125 recall 0.9278595592941392 f1 0.9254096586483839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 9.732924222946167 s\n",
      "Accuracy 0.9192648806802597 precision 0.918714737367358 specificity 0.785097604421455 recall 0.9192648806802597 f1 0.9159415957424698\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 9.93000316619873 s\n",
      "Accuracy 0.9250251440065832 precision 0.9250688327363438 specificity 0.8018344877043218 recall 0.9250251440065832 f1 0.9220932684758625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 9.6484055519104 s\n",
      "Accuracy 0.926488068025967 precision 0.9260741846460873 specificity 0.8060214219946561 recall 0.926488068025967 f1 0.9238321789309359\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 9.581801652908325 s\n",
      "Accuracy 0.9243851147481028 precision 0.9241140209895303 specificity 0.8011225537100027 recall 0.9243851147481028 f1 0.9215163089932619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 9.792199850082397 s\n",
      "Accuracy 0.9311511383377525 precision 0.9313262423758293 specificity 0.8094646046300678 recall 0.9311511383377525 f1 0.9284965919698475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 9.666385173797607 s\n",
      "Accuracy 0.9277681265429277 precision 0.9276412281135498 specificity 0.8028367905523408 recall 0.9277681265429277 f1 0.9249693923740056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 9.748558759689331 s\n",
      "Accuracy 0.9266709335283899 precision 0.9264341207375354 specificity 0.8029525637975934 recall 0.9266709335283899 f1 0.9238851571081383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 9.688541889190674 s\n",
      "Accuracy 0.9274938282892933 precision 0.927542692343944 specificity 0.798834242341003 recall 0.9274938282892933 f1 0.9245396144141624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 9.75412654876709 s\n",
      "Accuracy 0.9272195300356588 precision 0.9269863200767957 specificity 0.7990895233709463 recall 0.9272195300356588 f1 0.9243488137817594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 9.888867139816284 s\n",
      "Accuracy 0.9268537990308129 precision 0.9268485182280161 specificity 0.8043476877164326 recall 0.9268537990308129 f1 0.9240369859964498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 9.925034046173096 s\n",
      "Accuracy 0.9250251440065832 precision 0.9246186310266816 specificity 0.7952006682370805 recall 0.9250251440065832 f1 0.9220613321584274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 9.586479902267456 s\n",
      "Accuracy 0.9263966352747555 precision 0.9259108587778206 specificity 0.8010310008737258 recall 0.9263966352747555 f1 0.9236383622751277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 9.81412672996521 s\n",
      "Accuracy 0.9286824540550425 precision 0.9285511079975761 specificity 0.8109729701147728 recall 0.9286824540550425 f1 0.9261002191961668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 10.112491369247437 s\n",
      "Accuracy 0.9253908750114291 precision 0.9251544853136665 specificity 0.805972378665759 recall 0.9253908750114291 f1 0.9226548309743076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 9.805691242218018 s\n",
      "Accuracy 0.9284995885526196 precision 0.928433262485841 specificity 0.8038694560979737 recall 0.9284995885526196 f1 0.9257239101527802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 9.803217649459839 s\n",
      "Accuracy 0.9239279509920454 precision 0.9239568036297303 specificity 0.7901505243402817 recall 0.9239279509920454 f1 0.9206733602767155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 9.889836311340332 s\n",
      "Accuracy 0.9262137697723325 precision 0.9259129731426075 specificity 0.7978107839266091 recall 0.9262137697723325 f1 0.9233094365799533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 9.725883483886719 s\n",
      "Accuracy 0.9277681265429277 precision 0.927297138470455 specificity 0.8075166919611034 recall 0.9277681265429277 f1 0.9251939083385797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 9.847304344177246 s\n",
      "Accuracy 0.9278595592941392 precision 0.9275899724491447 specificity 0.804215772245407 recall 0.9278595592941392 f1 0.9251403090591602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 9.95044469833374 s\n",
      "Accuracy 0.9282252902989852 precision 0.9277788401717013 specificity 0.811791348907462 recall 0.9282252902989852 f1 0.9257552288949423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 9.726483821868896 s\n",
      "Accuracy 0.9244765474993143 precision 0.9249745539897077 specificity 0.7922786805421698 recall 0.9244765474993143 f1 0.9211644658696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 9.945064544677734 s\n",
      "Accuracy 0.9271280972844473 precision 0.9266571330688245 specificity 0.8048245715577702 recall 0.9271280972844473 f1 0.9244747389245422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 9.594584703445435 s\n",
      "Accuracy 0.9255737405138521 precision 0.9256185023201254 specificity 0.7947698004612728 recall 0.9255737405138521 f1 0.9224737985788627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 9.919421672821045 s\n",
      "Accuracy 0.9230136234799305 precision 0.9229360918992003 specificity 0.8011768013176414 recall 0.9230136234799305 f1 0.9200592640182266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 9.695043087005615 s\n",
      "Accuracy 0.9315168693425985 precision 0.930947401627246 specificity 0.8211956721329904 recall 0.9315168693425985 f1 0.929370181062842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 9.443994522094727 s\n",
      "Accuracy 0.9263966352747555 precision 0.9262962970112172 specificity 0.8043010080702322 recall 0.9263966352747555 f1 0.9235970940903646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 9.776766300201416 s\n",
      "Accuracy 0.9254823077626406 precision 0.9253507496626376 specificity 0.7957892917031826 recall 0.9254823077626406 f1 0.922457715647381\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 9.844560146331787 s\n",
      "Accuracy 0.9262137697723325 precision 0.9259846433471804 specificity 0.7945899624788809 recall 0.9262137697723325 f1 0.9232056807312591\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 9.78208041191101 s\n",
      "Accuracy 0.9263966352747555 precision 0.925920312805367 specificity 0.8026702866531881 recall 0.9263966352747555 f1 0.9236762834191996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 9.6045241355896 s\n",
      "Accuracy 0.9238365182408339 precision 0.9236070855541191 specificity 0.7955291929326171 recall 0.9238365182408339 f1 0.9207976863252045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 9.737863302230835 s\n",
      "Accuracy 0.9247508457529487 precision 0.9243342566473391 specificity 0.7897110137453213 recall 0.9247508457529487 f1 0.9216415227344364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 9.80751919746399 s\n",
      "Accuracy 0.9281338575477737 precision 0.9278818584382615 specificity 0.8050425316661243 recall 0.9281338575477737 f1 0.9254349862525354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 9.820110559463501 s\n",
      "Accuracy 0.9243851147481028 precision 0.9245165766256422 specificity 0.7986158212929604 recall 0.9243851147481028 f1 0.9213324256368508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 9.764971733093262 s\n",
      "Accuracy 0.9271280972844473 precision 0.9271053960104377 specificity 0.8006759671238235 recall 0.9271280972844473 f1 0.9242314865014208\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 9.819991111755371 s\n",
      "Accuracy 0.9214592667093353 precision 0.9207342445597303 specificity 0.7897602630053202 recall 0.9214592667093353 f1 0.9183795860650433\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 9.97153377532959 s\n",
      "Accuracy 0.9249337112553717 precision 0.9246192196171276 specificity 0.7978193485346451 recall 0.9249337112553717 f1 0.9220053505312222\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 9.595489740371704 s\n",
      "Accuracy 0.9280424247965622 precision 0.9281109807028887 specificity 0.8026138475339226 recall 0.9280424247965622 f1 0.9251876008575465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 9.811523675918579 s\n",
      "Accuracy 0.9263966352747555 precision 0.9257612499105836 specificity 0.803164067476205 recall 0.9263966352747555 f1 0.9237451008828365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 9.993958473205566 s\n",
      "Accuracy 0.9262137697723325 precision 0.9259379800650431 specificity 0.7990032561456134 recall 0.9262137697723325 f1 0.923331548267225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 9.662009954452515 s\n",
      "Accuracy 0.9262137697723325 precision 0.9265064620355608 specificity 0.7934562439888319 recall 0.9262137697723325 f1 0.9230278850983322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 9.764484405517578 s\n",
      "Accuracy 0.9268537990308129 precision 0.926863013491145 specificity 0.8022812711713998 recall 0.9268537990308129 f1 0.9239816941594594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 9.76900029182434 s\n",
      "Accuracy 0.9254823077626406 precision 0.9252708901701389 specificity 0.8000035312819327 recall 0.9254823077626406 f1 0.9225892494651374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 9.726951599121094 s\n",
      "Accuracy 0.9258480387674866 precision 0.9257346472757578 specificity 0.7983931049651434 recall 0.9258480387674866 f1 0.9228924411686834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 9.794048070907593 s\n",
      "Accuracy 0.9256651732650636 precision 0.9252716353776826 specificity 0.8010543451716091 recall 0.9256651732650636 f1 0.9228608479192633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 9.658116102218628 s\n",
      "Accuracy 0.9252080095090062 precision 0.9252275761721668 specificity 0.7974551553082988 recall 0.9252080095090062 f1 0.9221753125428397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 10.08498740196228 s\n",
      "Accuracy 0.9276766937917162 precision 0.9274872222897185 specificity 0.8046902545403091 recall 0.9276766937917162 f1 0.9249402372522249\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 9.953555583953857 s\n",
      "Accuracy 0.9274938282892933 precision 0.9273481091377437 specificity 0.8085774996150783 recall 0.9274938282892933 f1 0.9248351559586144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 9.546107053756714 s\n",
      "Accuracy 0.9302368108256377 precision 0.929754032282052 specificity 0.8137798353616925 recall 0.9302368108256377 f1 0.9278643430967404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 9.803926467895508 s\n",
      "Accuracy 0.9254823077626406 precision 0.9256199225172609 specificity 0.8015959940390703 recall 0.9254823077626406 f1 0.9225275632049227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 9.667991399765015 s\n",
      "Accuracy 0.9205449391972205 precision 0.9198092215098612 specificity 0.7943877080302976 recall 0.9205449391972205 f1 0.9175771475262021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 9.581459760665894 s\n",
      "Accuracy 0.9225564597238731 precision 0.9219919804481811 specificity 0.8010722750949785 recall 0.9225564597238731 f1 0.9197482006371029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 9.792051315307617 s\n",
      "Accuracy 0.9284081558014081 precision 0.9282916565739194 specificity 0.8050649443590354 recall 0.9284081558014081 f1 0.9256741827738462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 9.791075229644775 s\n",
      "Accuracy 0.9238365182408339 precision 0.923498121469189 specificity 0.8005152738218219 recall 0.9238365182408339 f1 0.9209623425800135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 9.660412788391113 s\n",
      "Accuracy 0.9263966352747555 precision 0.9258575087127393 specificity 0.8054797330880411 recall 0.9263966352747555 f1 0.9237685609571236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 10.008925199508667 s\n",
      "Accuracy 0.931425436591387 precision 0.9313621301804785 specificity 0.8156593269445632 recall 0.931425436591387 f1 0.928984730990046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 9.819141626358032 s\n",
      "Accuracy 0.9235622199871995 precision 0.9232531676545581 specificity 0.7982239537908986 recall 0.9235622199871995 f1 0.920613071203151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 10.160919189453125 s\n",
      "Accuracy 0.9235622199871995 precision 0.9232527763655625 specificity 0.7969758955203137 recall 0.9235622199871995 f1 0.9205804785204575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 9.907617092132568 s\n",
      "Accuracy 0.9271280972844473 precision 0.9267538992230127 specificity 0.8009396719849803 recall 0.9271280972844473 f1 0.9243460997307726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 9.894054174423218 s\n",
      "Accuracy 0.9258480387674866 precision 0.9253857834794444 specificity 0.7961525347278172 recall 0.9258480387674866 f1 0.9229461273580654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 9.736412763595581 s\n",
      "Accuracy 0.9251165767577947 precision 0.9248676715799341 specificity 0.7991534555275785 recall 0.9251165767577947 f1 0.9222056345002051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 9.96273159980774 s\n",
      "Accuracy 0.926305202523544 precision 0.9259961456934215 specificity 0.8041641608264606 recall 0.926305202523544 f1 0.9235649085069257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 9.722488403320312 s\n",
      "Accuracy 0.9270366645332359 precision 0.9267304530286752 specificity 0.8099585366848546 recall 0.9270366645332359 f1 0.9244532089935242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 9.993546962738037 s\n",
      "Accuracy 0.9245679802505258 precision 0.9251127627523364 specificity 0.7901336494432739 recall 0.9245679802505258 f1 0.9211905024801134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 9.800121545791626 s\n",
      "Accuracy 0.9253908750114291 precision 0.9251023842966564 specificity 0.8023121737764274 recall 0.9253908750114291 f1 0.9225786562035616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 9.830856561660767 s\n",
      "Accuracy 0.9238365182408339 precision 0.923884987081834 specificity 0.7934548629648491 recall 0.9238365182408339 f1 0.9206607518606897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 9.863527536392212 s\n",
      "Accuracy 0.9257566060162751 precision 0.9256274470671256 specificity 0.7985626638106164 recall 0.9257566060162751 f1 0.9228079771009653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 9.738941192626953 s\n",
      "Accuracy 0.9228307579775076 precision 0.922600054684015 specificity 0.7934850488883326 recall 0.9228307579775076 f1 0.9197158639564846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 9.873009443283081 s\n",
      "Accuracy 0.923105056231142 precision 0.9231101341973965 specificity 0.790694400241939 recall 0.923105056231142 f1 0.9198517338510651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 9.807990550994873 s\n",
      "Accuracy 0.9263966352747555 precision 0.9262545221776669 specificity 0.8036197975995035 recall 0.9263966352747555 f1 0.9235926618532283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 9.597532510757446 s\n",
      "Accuracy 0.9241108164944684 precision 0.9235213632523466 specificity 0.7972851498821302 recall 0.9241108164944684 f1 0.921243277792677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 9.622977256774902 s\n",
      "Accuracy 0.9272195300356588 precision 0.9266650121908417 specificity 0.7987882695823624 recall 0.9272195300356588 f1 0.9244471832445138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 9.830717325210571 s\n",
      "Accuracy 0.9299625125720032 precision 0.9293352120591891 specificity 0.8153615397257482 recall 0.9299625125720032 f1 0.9276748871464304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 9.764508247375488 s\n",
      "Accuracy 0.9265795007771784 precision 0.9259287455154102 specificity 0.8020414782438007 recall 0.9265795007771784 f1 0.9239091848416772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 9.716622591018677 s\n",
      "Accuracy 0.9220078632166042 precision 0.9222379209123355 specificity 0.78824297267447 recall 0.9220078632166042 f1 0.918599119718788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 9.893216609954834 s\n",
      "Accuracy 0.925939471518698 precision 0.9256708904823638 specificity 0.8019467394105387 recall 0.925939471518698 f1 0.9231231135052642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 9.869194746017456 s\n",
      "Accuracy 0.9236536527384109 precision 0.9232076073209371 specificity 0.7972498216416563 recall 0.9236536527384109 f1 0.9207258197594363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 9.9368577003479 s\n",
      "Accuracy 0.9229221907287191 precision 0.9226074661640946 specificity 0.7951617772778884 recall 0.9229221907287191 f1 0.9198803667128961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 9.808104276657104 s\n",
      "Accuracy 0.9274023955380818 precision 0.9270460880380428 specificity 0.8042702434631899 recall 0.9274023955380818 f1 0.9247026875194904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 9.786699533462524 s\n",
      "Accuracy 0.9246594130017373 precision 0.924241077683033 specificity 0.8027546379951367 recall 0.9246594130017373 f1 0.9218860736958596\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 9.871393918991089 s\n",
      "Accuracy 0.9254823077626406 precision 0.9256199225172609 specificity 0.8015959940390703 recall 0.9254823077626406 f1 0.9225275632049227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 9.612238883972168 s\n",
      "Accuracy 0.9274938282892933 precision 0.9273149181653388 specificity 0.7961885850093614 recall 0.9274938282892933 f1 0.9245410725150148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 9.684898853302002 s\n",
      "Accuracy 0.9290481850598884 precision 0.9285793757532488 specificity 0.8141207390030312 recall 0.9290481850598884 f1 0.926656803344702\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 9.770789384841919 s\n",
      "Accuracy 0.9249337112553717 precision 0.9244352149040511 specificity 0.8081082281901418 recall 0.9249337112553717 f1 0.9223300239952937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 9.778739213943481 s\n",
      "Accuracy 0.9269452317820244 precision 0.9272868332629605 specificity 0.7998525101991526 recall 0.9269452317820244 f1 0.9239241216844752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 9.820302963256836 s\n",
      "Accuracy 0.926122337021121 precision 0.9262782531913947 specificity 0.7999888314618523 recall 0.926122337021121 f1 0.9231358783372107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 10.027600526809692 s\n",
      "Accuracy 0.9288653195574654 precision 0.9287298748712015 specificity 0.8090010108710889 recall 0.9288653195574654 f1 0.9262408850862746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 9.786003112792969 s\n",
      "Accuracy 0.9231964889823535 precision 0.9233426600381535 specificity 0.7975610055355516 recall 0.9231964889823535 f1 0.9200866182525648\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 9.850104808807373 s\n",
      "Accuracy 0.9286824540550425 precision 0.9284629189499044 specificity 0.8025793177960007 recall 0.9286824540550425 f1 0.9259258017682676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 9.845389366149902 s\n",
      "Accuracy 0.9266709335283899 precision 0.9266825194046748 specificity 0.8014915853663944 recall 0.9266709335283899 f1 0.9237745905662876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 9.562860012054443 s\n",
      "Accuracy 0.9256651732650636 precision 0.9253819132399907 specificity 0.797454315801178 recall 0.9256651732650636 f1 0.9227338467261028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 10.011230707168579 s\n",
      "Accuracy 0.9252994422602177 precision 0.9252404333267669 specificity 0.80104318751695 recall 0.9252994422602177 f1 0.9223829297580185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 10.018933057785034 s\n",
      "Accuracy 0.9244765474993143 precision 0.9246371991033185 specificity 0.7976005232334651 recall 0.9244765474993143 f1 0.9213915670216192\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 9.685257196426392 s\n",
      "Accuracy 0.926305202523544 precision 0.9261856123293367 specificity 0.8094047600649312 recall 0.926305202523544 f1 0.9236363803024112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 9.757156133651733 s\n",
      "Accuracy 0.9268537990308129 precision 0.9259813376692964 specificity 0.8031755558086365 recall 0.9268537990308129 f1 0.9243046490667919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 9.813560485839844 s\n",
      "Accuracy 0.9246594130017373 precision 0.92443367247862 specificity 0.801951735680514 recall 0.9246594130017373 f1 0.9218032790256807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 9.775168895721436 s\n",
      "Accuracy 0.9306025418304836 precision 0.9300554250220833 specificity 0.8176343537960455 recall 0.9306025418304836 f1 0.9283496573477724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 9.901515007019043 s\n",
      "Accuracy 0.925939471518698 precision 0.925602915230714 specificity 0.7948689778842538 recall 0.925939471518698 f1 0.9229657529229964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 9.962966680526733 s\n",
      "Accuracy 0.9296882143183688 precision 0.9299563337346466 specificity 0.8016544095605782 recall 0.9296882143183688 f1 0.9267936170104673\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 9.856846809387207 s\n",
      "Accuracy 0.9250251440065832 precision 0.9248876216491385 specificity 0.7919510904951852 recall 0.9250251440065832 f1 0.9218930494193333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 9.633788824081421 s\n",
      "Accuracy 0.9297796470695803 precision 0.9296381961533319 specificity 0.8117216828367106 recall 0.9297796470695803 f1 0.9272394715379476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 9.85678768157959 s\n",
      "Accuracy 0.9308768400841181 precision 0.9306952777453538 specificity 0.8122161150044895 recall 0.9308768400841181 f1 0.9283820447796858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 9.831594467163086 s\n",
      "Accuracy 0.9268537990308129 precision 0.9266197436645237 specificity 0.8064619421689427 recall 0.9268537990308129 f1 0.9241578387094074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 9.957020282745361 s\n",
      "Accuracy 0.9292310505623114 precision 0.9287569055145115 specificity 0.8076122349657198 recall 0.9292310505623114 f1 0.9266898846991597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 9.971901416778564 s\n",
      "Accuracy 0.9281338575477737 precision 0.9276847536688195 specificity 0.8065805016056395 recall 0.9281338575477737 f1 0.9255366986870857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 10.042574405670166 s\n",
      "Accuracy 0.9291396178110999 precision 0.9285197822441061 specificity 0.8125270888960369 recall 0.9291396178110999 f1 0.9267665493539774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 9.8712158203125 s\n",
      "Accuracy 0.9275852610405048 precision 0.9269694445610938 specificity 0.7997156119337182 recall 0.9275852610405048 f1 0.9248661122394619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 9.707016229629517 s\n",
      "Accuracy 0.923287921733565 precision 0.9231335772015399 specificity 0.7898188946673389 recall 0.923287921733565 f1 0.920062919053552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 9.958489894866943 s\n",
      "Accuracy 0.9231964889823535 precision 0.9224764711640312 specificity 0.7955823498194933 recall 0.9231964889823535 f1 0.9203116723997751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 9.8424711227417 s\n",
      "Accuracy 0.9238365182408339 precision 0.9239261428352284 specificity 0.7953533985332507 recall 0.9238365182408339 f1 0.9206987177378874\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 9.798757314682007 s\n",
      "Accuracy 0.9302368108256377 precision 0.9298014919961259 specificity 0.811469678248829 recall 0.9302368108256377 f1 0.9277938919908072\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 10.19294548034668 s\n",
      "Accuracy 0.9281338575477737 precision 0.9280172215841492 specificity 0.8091054853025175 recall 0.9281338575477737 f1 0.9254917481866042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 9.963627815246582 s\n",
      "Accuracy 0.9257566060162751 precision 0.9252502488244875 specificity 0.80553813958053 recall 0.9257566060162751 f1 0.9231058937181286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 9.827738523483276 s\n",
      "Accuracy 0.9299625125720032 precision 0.9294052245594354 specificity 0.808853291703213 recall 0.9299625125720032 f1 0.9274952148290594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 9.767118692398071 s\n",
      "Accuracy 0.9226478924750846 precision 0.9222056364675212 specificity 0.7919617582969957 recall 0.9226478924750846 f1 0.9195562250331509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 9.695270776748657 s\n",
      "Accuracy 0.928591021303831 precision 0.9279653140055456 specificity 0.8067516278532328 recall 0.928591021303831 f1 0.9260700293721178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 9.865609169006348 s\n",
      "Accuracy 0.9281338575477737 precision 0.9274034721986018 specificity 0.8064221295818189 recall 0.9281338575477737 f1 0.9256351648851499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 9.996410131454468 s\n",
      "Accuracy 0.9262137697723325 precision 0.9261383253072926 specificity 0.8005956861784853 recall 0.9262137697723325 f1 0.9233104282830797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 9.759786605834961 s\n",
      "Accuracy 0.9269452317820244 precision 0.92692116561638 specificity 0.8038839236901416 recall 0.9269452317820244 f1 0.924124307606271\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 9.944746732711792 s\n",
      "Accuracy 0.9257566060162751 precision 0.9250230709751557 specificity 0.8036466300576706 recall 0.9257566060162751 f1 0.9231412099750426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 9.889126062393188 s\n",
      "Accuracy 0.926488068025967 precision 0.9265210637986406 specificity 0.7987849452439382 recall 0.926488068025967 f1 0.9235140465541356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 9.700104713439941 s\n",
      "Accuracy 0.9242936819968913 precision 0.9238324162773963 specificity 0.7992509465310185 recall 0.9242936819968913 f1 0.921436822244575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 9.655005693435669 s\n",
      "Accuracy 0.9227393252262961 precision 0.9224409257963463 specificity 0.7963186425660812 recall 0.9227393252262961 f1 0.9197190490317209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 9.80883502960205 s\n",
      "Accuracy 0.9300539453232147 precision 0.9296025942006554 specificity 0.8134417111760982 recall 0.9300539453232147 f1 0.9276591554346528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 9.92399287223816 s\n",
      "Accuracy 0.9227393252262961 precision 0.9224822411742334 specificity 0.7956857952046572 recall 0.9227393252262961 f1 0.9196891634855938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 10.016430377960205 s\n",
      "Accuracy 0.9253908750114291 precision 0.9253965906893323 specificity 0.796293428388993 recall 0.9253908750114291 f1 0.9223366737382509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 9.768193244934082 s\n",
      "Accuracy 0.9252080095090062 precision 0.9249606894287263 specificity 0.7957565970532817 recall 0.9252080095090062 f1 0.9222116706322037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 9.70226526260376 s\n",
      "Accuracy 0.9265795007771784 precision 0.9262258166663386 specificity 0.7994943408681027 recall 0.9265795007771784 f1 0.9237426617989287\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 9.781034469604492 s\n",
      "Accuracy 0.9272195300356588 precision 0.9273129544068929 specificity 0.8054053942109392 recall 0.9272195300356588 f1 0.9244083263561769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 9.765823364257812 s\n",
      "Accuracy 0.9297796470695803 precision 0.9298305689976206 specificity 0.8076951732851126 recall 0.9297796470695803 f1 0.9270889455259426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 9.925148963928223 s\n",
      "Accuracy 0.9243851147481028 precision 0.9243268584852212 specificity 0.7911859074458273 recall 0.9243851147481028 f1 0.921194055540226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 9.986839294433594 s\n",
      "Accuracy 0.9262137697723325 precision 0.9263428487699638 specificity 0.7932021569489008 recall 0.9262137697723325 f1 0.9230658524316717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 9.72250509262085 s\n",
      "Accuracy 0.9241108164944684 precision 0.9239167474207757 specificity 0.7983933182744161 recall 0.9241108164944684 f1 0.9211416517309823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 9.752877235412598 s\n",
      "Accuracy 0.9276766937917162 precision 0.9278505390010647 specificity 0.7922336027019383 recall 0.9276766937917162 f1 0.9245292404745987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 9.888158321380615 s\n",
      "Accuracy 0.9269452317820244 precision 0.9273413710296775 specificity 0.8025583287936751 recall 0.9269452317820244 f1 0.923977102353728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 9.770867824554443 s\n",
      "Accuracy 0.9260309042699095 precision 0.9259842632249121 specificity 0.7955255200219611 recall 0.9260309042699095 f1 0.9229873037763269\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 9.744076251983643 s\n",
      "Accuracy 0.9256651732650636 precision 0.9254309379885045 specificity 0.7984683989987466 recall 0.9256651732650636 f1 0.9227442287855036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 9.677768230438232 s\n",
      "Accuracy 0.9260309042699095 precision 0.9256044352557083 specificity 0.8034799668754904 recall 0.9260309042699095 f1 0.9233064232875191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 9.634008169174194 s\n",
      "Accuracy 0.9272195300356588 precision 0.9268393409891089 specificity 0.8023078703063 recall 0.9272195300356588 f1 0.9244753717203635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 9.797910451889038 s\n",
      "Accuracy 0.9258480387674866 precision 0.9256488999704942 specificity 0.8022609999379335 recall 0.9258480387674866 f1 0.9230160184782878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 10.089992046356201 s\n",
      "Accuracy 0.9239279509920454 precision 0.9233836656858503 specificity 0.7915544111202333 recall 0.9239279509920454 f1 0.920889873164234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 10.137799978256226 s\n",
      "Accuracy 0.9271280972844473 precision 0.9266906846855075 specificity 0.8064377187706187 recall 0.9271280972844473 f1 0.9245031651395014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 9.924546957015991 s\n",
      "Accuracy 0.925939471518698 precision 0.9256216955004157 specificity 0.7983466071351398 recall 0.925939471518698 f1 0.9230479036961047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 10.001447677612305 s\n",
      "Accuracy 0.9227393252262961 precision 0.9227463960824214 specificity 0.7998255966419253 recall 0.9227393252262961 f1 0.919719074454235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 9.584886074066162 s\n",
      "Accuracy 0.9244765474993143 precision 0.9240357581063757 specificity 0.8066738219707494 recall 0.9244765474993143 f1 0.921807926661577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 9.901562452316284 s\n",
      "Accuracy 0.9260309042699095 precision 0.9255792491961072 specificity 0.8058100938967858 recall 0.9260309042699095 f1 0.9233735252185076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 9.808111906051636 s\n",
      "Accuracy 0.920270640943586 precision 0.9196219224288592 specificity 0.7883940872753947 recall 0.920270640943586 f1 0.9170980973531334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 9.889864921569824 s\n",
      "Accuracy 0.9262137697723325 precision 0.9253857449471907 specificity 0.8039997872894327 recall 0.9262137697723325 f1 0.923654084333017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 10.098472118377686 s\n",
      "Accuracy 0.9239279509920454 precision 0.9240009952627638 specificity 0.7922004938612431 recall 0.9239279509920454 f1 0.920714508058333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 9.729929685592651 s\n",
      "Accuracy 0.9284995885526196 precision 0.9285221776930916 specificity 0.8083222096335549 recall 0.9284995885526196 f1 0.9258052934650555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 9.556289672851562 s\n",
      "Accuracy 0.9221907287190272 precision 0.9216084310294118 specificity 0.7988426003379562 recall 0.9221907287190272 f1 0.9193219773728478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 9.905481576919556 s\n",
      "Accuracy 0.9255737405138521 precision 0.9258833986347198 specificity 0.7970682826368781 recall 0.9255737405138521 f1 0.9224596519343636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 9.644991636276245 s\n",
      "Accuracy 0.9275852610405048 precision 0.9275590246123845 specificity 0.8069004156085982 recall 0.9275852610405048 f1 0.9248521397557767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 9.69730257987976 s\n",
      "Accuracy 0.9280424247965622 precision 0.9272730835804858 specificity 0.8083848424264752 recall 0.9280424247965622 f1 0.9256056444709525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 9.62039852142334 s\n",
      "Accuracy 0.9275852610405048 precision 0.9272272155166897 specificity 0.8024875908986425 recall 0.9275852610405048 f1 0.9248461885465078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 9.820165872573853 s\n",
      "Accuracy 0.923287921733565 precision 0.9229711194590616 specificity 0.7978962708532563 recall 0.923287921733565 f1 0.9203268748653717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 9.708953142166138 s\n",
      "Accuracy 0.9288653195574654 precision 0.9288305452094072 specificity 0.8058594286041876 recall 0.9288653195574654 f1 0.926136123325383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 9.629925012588501 s\n",
      "Accuracy 0.9272195300356588 precision 0.9269841580536972 specificity 0.8093008229516405 recall 0.9272195300356588 f1 0.9246008619817538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 9.63699984550476 s\n",
      "Accuracy 0.9263966352747555 precision 0.9265510293516653 specificity 0.7923295989836542 recall 0.9263966352747555 f1 0.9232242382361616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 10.011897802352905 s\n",
      "Accuracy 0.9272195300356588 precision 0.9266816310506436 specificity 0.8054819383993445 recall 0.9272195300356588 f1 0.9246076072769787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 9.835062265396118 s\n",
      "Accuracy 0.9242022492456798 precision 0.9243907577668086 specificity 0.8003453287052077 recall 0.9242022492456798 f1 0.92117455848643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 9.581998348236084 s\n",
      "Accuracy 0.9250251440065832 precision 0.9246622232068513 specificity 0.7984719921348297 recall 0.9250251440065832 f1 0.9221311744240458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 9.880029439926147 s\n",
      "Accuracy 0.9262137697723325 precision 0.9260469260840627 specificity 0.8015840381973486 recall 0.9262137697723325 f1 0.9233625841857447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 9.660557508468628 s\n",
      "Accuracy 0.9274938282892933 precision 0.9273996162538038 specificity 0.8017503108326545 recall 0.9274938282892933 f1 0.9246527375178472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 9.925819396972656 s\n",
      "Accuracy 0.9245679802505258 precision 0.924880314719619 specificity 0.7964026663374427 recall 0.9245679802505258 f1 0.9214131026635494\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 9.722540140151978 s\n",
      "Accuracy 0.9242022492456798 precision 0.9240832623835031 specificity 0.7983741197265072 recall 0.9242022492456798 f1 0.9212117309511235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 9.66651701927185 s\n",
      "Accuracy 0.9278595592941392 precision 0.9275772311294809 specificity 0.8074121369742134 recall 0.9278595592941392 f1 0.9252221673907166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 9.847121238708496 s\n",
      "Accuracy 0.9279509920453507 precision 0.9281336414400491 specificity 0.7973148236561405 recall 0.9279509920453507 f1 0.9249331814588363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 9.692081451416016 s\n",
      "Accuracy 0.9252994422602177 precision 0.9251454148348099 specificity 0.8031377576183827 recall 0.9252994422602177 f1 0.9224644719422399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 9.58066463470459 s\n",
      "Accuracy 0.9251165767577947 precision 0.9252270942892941 specificity 0.805408483495694 recall 0.9251165767577947 f1 0.9222584381539042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 9.872537612915039 s\n",
      "Accuracy 0.9269452317820244 precision 0.9269448435119559 specificity 0.7965577979719434 recall 0.9269452317820244 f1 0.9239357908504933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 9.935277700424194 s\n",
      "Accuracy 0.9266709335283899 precision 0.9271330371191975 specificity 0.7963243476768254 recall 0.9266709335283899 f1 0.9235244290439697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 9.882837772369385 s\n",
      "Accuracy 0.9288653195574654 precision 0.9288473498207926 specificity 0.8038691189012281 recall 0.9288653195574654 f1 0.9260835987907042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 9.707008123397827 s\n",
      "Accuracy 0.9263966352747555 precision 0.926172149046725 specificity 0.8035708885142787 recall 0.9263966352747555 f1 0.9236166883722335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 9.754616975784302 s\n",
      "Accuracy 0.9282252902989852 precision 0.9280643275515473 specificity 0.7991973110484173 recall 0.9282252902989852 f1 0.9253583189744319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 9.70916199684143 s\n",
      "Accuracy 0.9273109627868703 precision 0.9273157041729367 specificity 0.8029259835170113 recall 0.9273109627868703 f1 0.9244659094550574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 9.752341747283936 s\n",
      "Accuracy 0.9251165767577947 precision 0.9253005577623814 specificity 0.793179404742052 recall 0.9251165767577947 f1 0.9219261288744306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 9.791993141174316 s\n",
      "Accuracy 0.926305202523544 precision 0.9258650818362546 specificity 0.8040004738827823 recall 0.926305202523544 f1 0.9236039907371625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 9.815578699111938 s\n",
      "Accuracy 0.9240193837432569 precision 0.9237696596042957 specificity 0.7954307075279013 recall 0.9240193837432569 f1 0.9209883929325124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 9.742180824279785 s\n",
      "Accuracy 0.9260309042699095 precision 0.9261414172521076 specificity 0.8030652974231214 recall 0.9260309042699095 f1 0.9231322164309559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 9.640264987945557 s\n",
      "Accuracy 0.9250251440065832 precision 0.924824468350562 specificity 0.7957774537372838 recall 0.9250251440065832 f1 0.9220107133044863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 9.930848598480225 s\n",
      "Accuracy 0.9263966352747555 precision 0.9263740989013477 specificity 0.7970680612263306 recall 0.9263966352747555 f1 0.9233934545131607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 9.738991975784302 s\n",
      "Accuracy 0.9293224833135229 precision 0.9291845561548203 specificity 0.8110491817331862 recall 0.9293224833135229 f1 0.9267564705282618\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 9.60608696937561 s\n",
      "Accuracy 0.9238365182408339 precision 0.9236031175664396 specificity 0.7940552021158491 recall 0.9238365182408339 f1 0.9207603377575783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 9.927560329437256 s\n",
      "Accuracy 0.9279509920453507 precision 0.9279257185587376 specificity 0.8087301081181241 recall 0.9279509920453507 f1 0.9252693056001158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 9.950947523117065 s\n",
      "Accuracy 0.9257566060162751 precision 0.9255838631594958 specificity 0.792377315259306 recall 0.9257566060162751 f1 0.922663974289161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 9.87964677810669 s\n",
      "Accuracy 0.9238365182408339 precision 0.9231483017381541 specificity 0.7917025437278468 recall 0.9238365182408339 f1 0.9208512404328609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 9.696038961410522 s\n",
      "Accuracy 0.9272195300356588 precision 0.927464066865669 specificity 0.7980638346057528 recall 0.9272195300356588 f1 0.9241860545198878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 9.70672082901001 s\n",
      "Accuracy 0.9230136234799305 precision 0.9229719900663526 specificity 0.7963108974043458 recall 0.9230136234799305 f1 0.9199205392030539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 9.877615690231323 s\n",
      "Accuracy 0.9255737405138521 precision 0.926265838411316 specificity 0.7930156728285074 recall 0.9255737405138521 f1 0.9222596147786156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 9.875354051589966 s\n",
      "Accuracy 0.9214592667093353 precision 0.9214687632980699 specificity 0.789855998772582 recall 0.9214592667093353 f1 0.9181432847275522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 9.877619743347168 s\n",
      "Accuracy 0.9233793544847765 precision 0.923379119760625 specificity 0.7945473910273937 recall 0.9233793544847765 f1 0.9202357932386265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 9.69829773902893 s\n",
      "Accuracy 0.9284995885526196 precision 0.9286563403686486 specificity 0.7973636460492249 recall 0.9284995885526196 f1 0.9255033420205426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 9.809380531311035 s\n",
      "Accuracy 0.9300539453232147 precision 0.9293381521237534 specificity 0.8122917673443285 recall 0.9300539453232147 f1 0.9277297424265954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 9.562838077545166 s\n",
      "Accuracy 0.9258480387674866 precision 0.9262486253800227 specificity 0.7919330585310425 recall 0.9258480387674866 f1 0.9225860676284132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 9.940573930740356 s\n",
      "Accuracy 0.926122337021121 precision 0.9259409425000094 specificity 0.803075591100849 recall 0.926122337021121 f1 0.9233110307407792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 9.857468843460083 s\n",
      "Accuracy 0.9235622199871995 precision 0.9230757761604688 specificity 0.7973954654079792 recall 0.9235622199871995 f1 0.920649934815658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 9.804428577423096 s\n",
      "Accuracy 0.9192648806802597 precision 0.9186969704711392 specificity 0.7900378010610575 recall 0.9192648806802597 f1 0.9160875959048457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 9.897252321243286 s\n",
      "Accuracy 0.9271280972844473 precision 0.9270682627773841 specificity 0.8002642577655743 recall 0.9271280972844473 f1 0.9242321235280982\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 9.720392227172852 s\n",
      "Accuracy 0.9223735942214502 precision 0.9215907113744172 specificity 0.7885348760035915 recall 0.9223735942214502 f1 0.919303388282209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 9.619993925094604 s\n",
      "Accuracy 0.9267623662796014 precision 0.9267166933966343 specificity 0.8019449964200962 recall 0.9267623662796014 f1 0.9238958408471709\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 9.860055208206177 s\n",
      "Accuracy 0.9252080095090062 precision 0.9254537306396513 specificity 0.7995675937429845 recall 0.9252080095090062 f1 0.9221663664463736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 9.91502594947815 s\n",
      "Accuracy 0.9253908750114291 precision 0.9252411662420237 specificity 0.8011792345146881 recall 0.9253908750114291 f1 0.9225068215347537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 9.710954666137695 s\n",
      "Accuracy 0.9274023955380818 precision 0.9275685496470615 specificity 0.8041726635635731 recall 0.9274023955380818 f1 0.9245447096136746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 10.028048753738403 s\n",
      "Accuracy 0.9273109627868703 precision 0.9275674363933991 specificity 0.7975931790185552 recall 0.9273109627868703 f1 0.9242648065006014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 9.635796308517456 s\n",
      "Accuracy 0.9253908750114291 precision 0.9251401110684201 specificity 0.7977370926839497 recall 0.9253908750114291 f1 0.9224503806031262\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 9.823484897613525 s\n",
      "Accuracy 0.926305202523544 precision 0.9261225498110187 specificity 0.8038605821083414 recall 0.926305202523544 f1 0.9235176820438601\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 9.774719476699829 s\n",
      "Accuracy 0.9253908750114291 precision 0.9254133603297043 specificity 0.7970892043725986 recall 0.9253908750114291 f1 0.9223521402336855\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 9.981059789657593 s\n",
      "Accuracy 0.9253908750114291 precision 0.9254797222648462 specificity 0.7944978392847197 recall 0.9253908750114291 f1 0.9222671885618665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 9.998342990875244 s\n",
      "Accuracy 0.9223735942214502 precision 0.9216917230373093 specificity 0.7918769965142303 recall 0.9223735942214502 f1 0.9193567910127134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 10.013890981674194 s\n",
      "Accuracy 0.9269452317820244 precision 0.9273110355956384 specificity 0.7994858298158435 recall 0.9269452317820244 f1 0.9239087248315125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 9.763015031814575 s\n",
      "Accuracy 0.9220992959678157 precision 0.9222728050828672 specificity 0.7919361455966121 recall 0.9220992959678157 f1 0.9188079012556186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 9.98053789138794 s\n",
      "Accuracy 0.9279509920453507 precision 0.9277451419398692 specificity 0.798431703598914 recall 0.9279509920453507 f1 0.9250725546013692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 9.964179515838623 s\n",
      "Accuracy 0.9301453780744262 precision 0.9294087844507912 specificity 0.8115789975452149 recall 0.9301453780744262 f1 0.9278143109155678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 9.80125093460083 s\n",
      "Accuracy 0.9249337112553717 precision 0.9246830028278122 specificity 0.8044951355558955 recall 0.9249337112553717 f1 0.9221558539954141\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 9.961116075515747 s\n",
      "Accuracy 0.9297796470695803 precision 0.9293602890238903 specificity 0.8115164739833238 recall 0.9297796470695803 f1 0.9273234049965502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 9.957544565200806 s\n",
      "Accuracy 0.9248422785041602 precision 0.9240622737873513 specificity 0.7991079035169504 recall 0.9248422785041602 f1 0.9221087926964855\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 9.816075563430786 s\n",
      "Accuracy 0.9302368108256377 precision 0.9300225877442255 specificity 0.8114749543653664 recall 0.9302368108256377 f1 0.9277221509451854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 9.934566020965576 s\n",
      "Accuracy 0.9283167230501966 precision 0.9279953326842508 specificity 0.8062875099177188 recall 0.9283167230501966 f1 0.9256738979942568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 9.938991785049438 s\n",
      "Accuracy 0.9282252902989852 precision 0.9277223787868448 specificity 0.8090269402764575 recall 0.9282252902989852 f1 0.9257079520200049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 9.96869158744812 s\n",
      "Accuracy 0.9270366645332359 precision 0.9270111431376479 specificity 0.8069708983881269 recall 0.9270366645332359 f1 0.9242940551724056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 9.93300175666809 s\n",
      "Accuracy 0.9260309042699095 precision 0.9254197593163179 specificity 0.8005982588657188 recall 0.9260309042699095 f1 0.923297930253028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 9.900996923446655 s\n",
      "Accuracy 0.9220992959678157 precision 0.9219539087130708 specificity 0.7873724898195318 recall 0.9220992959678157 f1 0.9187770677218902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 10.01562762260437 s\n",
      "Accuracy 0.9251165767577947 precision 0.9249687109325996 specificity 0.7946495909049904 recall 0.9251165767577947 f1 0.9220592204070249\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 9.970510959625244 s\n",
      "Accuracy 0.9227393252262961 precision 0.9225647698538557 specificity 0.790374854748782 recall 0.9227393252262961 f1 0.9195221174484929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 9.8864164352417 s\n",
      "Accuracy 0.9211849684557009 precision 0.9210482060690758 specificity 0.7914397257819781 recall 0.9211849684557009 f1 0.9179491637536095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 10.013991117477417 s\n",
      "Accuracy 0.9271280972844473 precision 0.9270174423487328 specificity 0.8046210909562377 recall 0.9271280972844473 f1 0.9243546425416097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 9.746999263763428 s\n",
      "Accuracy 0.9222821614702387 precision 0.9226260597751101 specificity 0.791844976051091 recall 0.9222821614702387 f1 0.9189463371484995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 9.89839768409729 s\n",
      "Accuracy 0.9254823077626406 precision 0.9252781994610377 specificity 0.7990471456761953 recall 0.9254823077626406 f1 0.9225627026820141\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 9.916318893432617 s\n",
      "Accuracy 0.9290481850598884 precision 0.9289110708495597 specificity 0.802981635753892 recall 0.9290481850598884 f1 0.926284290591092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 9.904036521911621 s\n",
      "Accuracy 0.925939471518698 precision 0.9257287493602167 specificity 0.800840960503887 recall 0.925939471518698 f1 0.9230772015557877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 9.958698034286499 s\n",
      "Accuracy 0.9276766937917162 precision 0.9276071705153984 specificity 0.8052203325873684 recall 0.9276766937917162 f1 0.9249171481439216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 10.086186647415161 s\n",
      "Accuracy 0.9256651732650636 precision 0.9250778139734153 specificity 0.7990881981963865 recall 0.9256651732650636 f1 0.9228773046817014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 9.934764623641968 s\n",
      "Accuracy 0.9231964889823535 precision 0.9227929669338063 specificity 0.7886159392920274 recall 0.9231964889823535 f1 0.9200155955301578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 9.960171699523926 s\n",
      "Accuracy 0.9246594130017373 precision 0.9245382758195455 specificity 0.7990985562261208 recall 0.9246594130017373 f1 0.9216980512584427\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 10.162872791290283 s\n",
      "Accuracy 0.9210021029532779 precision 0.9207816847517413 specificity 0.7957598373461865 recall 0.9210021029532779 f1 0.9179057508224456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 9.944990873336792 s\n",
      "Accuracy 0.9262137697723325 precision 0.9265334104284139 specificity 0.796355585709405 recall 0.9262137697723325 f1 0.9230939546895998\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 9.862942934036255 s\n",
      "Accuracy 0.9244765474993143 precision 0.9245127526001379 specificity 0.7960367468511198 recall 0.9244765474993143 f1 0.9213861423359507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 9.945040702819824 s\n",
      "Accuracy 0.9245679802505258 precision 0.9244589447477692 specificity 0.7952252110542936 recall 0.9245679802505258 f1 0.9215011083521608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 9.833021402359009 s\n",
      "Accuracy 0.9270366645332359 precision 0.9267879946072567 specificity 0.8065878019962848 recall 0.9270366645332359 f1 0.9243520250335622\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 9.677451848983765 s\n",
      "Accuracy 0.928591021303831 precision 0.9285557751829866 specificity 0.8044749828020622 recall 0.928591021303831 f1 0.9258228534621599\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 10.01323652267456 s\n",
      "Accuracy 0.9252994422602177 precision 0.9253134872132406 specificity 0.7948161188145759 recall 0.9252994422602177 f1 0.9222029850800938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 9.618351697921753 s\n",
      "Accuracy 0.926488068025967 precision 0.9263046689581974 specificity 0.8109432338995245 recall 0.926488068025967 f1 0.9238800548296856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 9.949079990386963 s\n",
      "Accuracy 0.9270366645332359 precision 0.9270552694515585 specificity 0.8036433186546948 recall 0.9270366645332359 f1 0.9241994388052907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 9.787881135940552 s\n",
      "Accuracy 0.9268537990308129 precision 0.9264364800264651 specificity 0.803841297046152 recall 0.9268537990308129 f1 0.9241522298371442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 9.65711522102356 s\n",
      "Accuracy 0.9268537990308129 precision 0.9265019469206885 specificity 0.8020610089431632 recall 0.9268537990308129 f1 0.9240863920850676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 9.714442253112793 s\n",
      "Accuracy 0.9294139160647343 precision 0.929186584786228 specificity 0.8121551473117627 recall 0.9294139160647343 f1 0.9269032016780825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 9.895841836929321 s\n",
      "Accuracy 0.9222821614702387 precision 0.9218870399694065 specificity 0.7887907114010521 recall 0.9222821614702387 f1 0.9190810665815768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 9.774601697921753 s\n",
      "Accuracy 0.9266709335283899 precision 0.9264030622556153 specificity 0.802744354643958 recall 0.9266709335283899 f1 0.9238897248344056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 9.784101724624634 s\n",
      "Accuracy 0.9221907287190272 precision 0.9212660536459688 specificity 0.8047204219090156 recall 0.9221907287190272 f1 0.9196137506385514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 9.748771905899048 s\n",
      "Accuracy 0.9219164304653927 precision 0.9216836559730875 specificity 0.7866505163543511 recall 0.9219164304653927 f1 0.9185968599963851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 10.089500904083252 s\n",
      "Accuracy 0.9214592667093353 precision 0.9212566263545623 specificity 0.7973311404317834 recall 0.9214592667093353 f1 0.9184093471073005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 9.8678560256958 s\n",
      "Accuracy 0.9273109627868703 precision 0.927161522855836 specificity 0.8022615598332256 recall 0.9273109627868703 f1 0.9244949619957478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 9.700416088104248 s\n",
      "Accuracy 0.9253908750114291 precision 0.9248437415397022 specificity 0.7998460187626958 recall 0.9253908750114291 f1 0.9226022308123809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 9.780638933181763 s\n",
      "Accuracy 0.926305202523544 precision 0.9254975580571405 specificity 0.8063044410208713 recall 0.926305202523544 f1 0.9237977305909887\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 10.007054328918457 s\n",
      "Accuracy 0.9233793544847765 precision 0.9229503221779954 specificity 0.8003734917225845 recall 0.9233793544847765 f1 0.9205221169895496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 9.752647638320923 s\n",
      "Accuracy 0.9236536527384109 precision 0.9235881019296117 specificity 0.796924445626563 recall 0.9236536527384109 f1 0.9205976336302905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 9.852214097976685 s\n",
      "Accuracy 0.9303282435768492 precision 0.9302738966551974 specificity 0.8064647119476821 recall 0.9303282435768492 f1 0.9276506218523335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 9.812814474105835 s\n",
      "Accuracy 0.9276766937917162 precision 0.9275822402836397 specificity 0.7998403235072777 recall 0.9276766937917162 f1 0.9247928878230235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 9.820589542388916 s\n",
      "Accuracy 0.9237450854896224 precision 0.9234201891499574 specificity 0.7970797376235301 recall 0.9237450854896224 f1 0.9207749657140747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 9.629724740982056 s\n",
      "Accuracy 0.923287921733565 precision 0.9235719372230818 specificity 0.7957977956352504 recall 0.923287921733565 f1 0.9200960256426329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 9.632652759552002 s\n",
      "Accuracy 0.9247508457529487 precision 0.9244324408275784 specificity 0.7980824840735569 recall 0.9247508457529487 f1 0.9218265029764511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 9.650559425354004 s\n",
      "Accuracy 0.9243851147481028 precision 0.9247867550391643 specificity 0.7903747912998198 recall 0.9243851147481028 f1 0.921045953394593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 9.774534702301025 s\n",
      "Accuracy 0.9284081558014081 precision 0.927770570145436 specificity 0.8120230930747165 recall 0.9284081558014081 f1 0.9260159672664136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 9.721922397613525 s\n",
      "Accuracy 0.923470787235988 precision 0.9227686463728643 specificity 0.8027192675442858 recall 0.923470787235988 f1 0.9207742740714511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 9.528043746948242 s\n",
      "Accuracy 0.926488068025967 precision 0.9264312748779474 specificity 0.8000731968848537 recall 0.926488068025967 f1 0.9235721922704697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 9.956565618515015 s\n",
      "Accuracy 0.926122337021121 precision 0.9258369606685972 specificity 0.7968243027957287 recall 0.926122337021121 f1 0.923186135471351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 9.702769041061401 s\n",
      "Accuracy 0.9288653195574654 precision 0.9285695528927376 specificity 0.8022888715855908 recall 0.9288653195574654 f1 0.9261296429949226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 9.807148933410645 s\n",
      "Accuracy 0.9225564597238731 precision 0.9220836333211221 specificity 0.7914242745968739 recall 0.9225564597238731 f1 0.9194585012490178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 9.768455743789673 s\n",
      "Accuracy 0.9262137697723325 precision 0.9261057838409971 specificity 0.7976645443348559 recall 0.9262137697723325 f1 0.9232464626754537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 9.736985206604004 s\n",
      "Accuracy 0.9242022492456798 precision 0.9239605719926058 specificity 0.7966269549886745 recall 0.9242022492456798 f1 0.9212039597740483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 9.803569793701172 s\n",
      "Accuracy 0.925939471518698 precision 0.9261953058027234 specificity 0.7979302302992813 recall 0.925939471518698 f1 0.9228699413796417\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 9.824760913848877 s\n",
      "Accuracy 0.9239279509920454 precision 0.923178946824949 specificity 0.8033418359048519 recall 0.9239279509920454 f1 0.9212746019459507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 9.69503378868103 s\n",
      "Accuracy 0.9253908750114291 precision 0.9251632397507709 specificity 0.798822929265498 recall 0.9253908750114291 f1 0.9224708408109413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 9.896929025650024 s\n",
      "Accuracy 0.920453506446009 precision 0.9198421540922621 specificity 0.7950913202025345 recall 0.920453506446009 f1 0.9174577922243159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 9.824548721313477 s\n",
      "Accuracy 0.9316997348450214 precision 0.9314192698086546 specificity 0.8082128699936041 recall 0.9316997348450214 f1 0.9291610756771852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 9.63469123840332 s\n",
      "Accuracy 0.9278595592941392 precision 0.9276048114086982 specificity 0.7996716462109246 recall 0.9278595592941392 f1 0.9250245307663908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 9.928530216217041 s\n",
      "Accuracy 0.9276766937917162 precision 0.9272271842661433 specificity 0.8021707461936884 recall 0.9276766937917162 f1 0.9249621707740601\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 10.033919334411621 s\n",
      "Accuracy 0.9290481850598884 precision 0.9288846022269771 specificity 0.8097780603094803 recall 0.9290481850598884 f1 0.9264544153341149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 10.26471495628357 s\n",
      "Accuracy 0.9238365182408339 precision 0.9237074803813613 specificity 0.7962076018307799 recall 0.9238365182408339 f1 0.9207847128590919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 10.20208477973938 s\n",
      "Accuracy 0.9235622199871995 precision 0.9232633511387552 specificity 0.7962124582542981 recall 0.9235622199871995 f1 0.9205570689276257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 9.927730560302734 s\n",
      "Accuracy 0.9254823077626406 precision 0.9252920892642251 specificity 0.8048201430886118 recall 0.9254823077626406 f1 0.9227046144553595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 9.96361780166626 s\n",
      "Accuracy 0.9253908750114291 precision 0.9252599701090843 specificity 0.7953852371538076 recall 0.9253908750114291 f1 0.9223536522616329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 9.823393821716309 s\n",
      "Accuracy 0.9307854073329066 precision 0.9309603563803556 specificity 0.812048542165996 recall 0.9307854073329066 f1 0.9281827575173597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 10.092000007629395 s\n",
      "Accuracy 0.9251165767577947 precision 0.9250721725807576 specificity 0.7995076300298124 recall 0.9251165767577947 f1 0.9221527870300036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 9.856078386306763 s\n",
      "Accuracy 0.9267623662796014 precision 0.9264146384072124 specificity 0.8018541878767709 recall 0.9267623662796014 f1 0.923986511641884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 9.79535961151123 s\n",
      "Accuracy 0.9284995885526196 precision 0.9284378262996503 specificity 0.8012657160269415 recall 0.9284995885526196 f1 0.9256596813731569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 10.061526775360107 s\n",
      "Accuracy 0.9299625125720032 precision 0.9297526842495132 specificity 0.815561309281142 recall 0.9299625125720032 f1 0.9275364095005623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 9.898073196411133 s\n",
      "Accuracy 0.9276766937917162 precision 0.92726376482668 specificity 0.8063879379912658 recall 0.9276766937917162 f1 0.9250533112209585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 9.656416177749634 s\n",
      "Accuracy 0.9239279509920454 precision 0.9238479770014589 specificity 0.793526612659735 recall 0.9239279509920454 f1 0.9207935173548817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 9.788574695587158 s\n",
      "Accuracy 0.9242022492456798 precision 0.9244011684844473 specificity 0.7951007142127918 recall 0.9242022492456798 f1 0.9210358300331116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 9.957119226455688 s\n",
      "Accuracy 0.9284995885526196 precision 0.9278283004323701 specificity 0.8117784076957424 recall 0.9284995885526196 f1 0.9261160355280169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 9.836991310119629 s\n",
      "Accuracy 0.9251165767577947 precision 0.9250808675653897 specificity 0.7985561955086675 recall 0.9251165767577947 f1 0.9221259608092357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 9.817991733551025 s\n",
      "Accuracy 0.9255737405138521 precision 0.9249668779350673 specificity 0.7930794876695804 recall 0.9255737405138521 f1 0.922636598086473\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 9.887885093688965 s\n",
      "Accuracy 0.9221907287190272 precision 0.9218252098679947 specificity 0.7958114424315206 recall 0.9221907287190272 f1 0.9191668794065101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 9.96711778640747 s\n",
      "Accuracy 0.9250251440065832 precision 0.9249951737927429 specificity 0.7899295664340763 recall 0.9250251440065832 f1 0.9218090830250557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 9.96807599067688 s\n",
      "Accuracy 0.9302368108256377 precision 0.9300451854131058 specificity 0.8099942801091803 recall 0.9302368108256377 f1 0.9276806661419057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 9.843052625656128 s\n",
      "Accuracy 0.9286824540550425 precision 0.928749496206194 specificity 0.8043526882433633 recall 0.9286824540550425 f1 0.9258841528884567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 9.846636533737183 s\n",
      "Accuracy 0.9247508457529487 precision 0.9247932505778976 specificity 0.8017940737554468 recall 0.9247508457529487 f1 0.9218126328482135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 9.900815486907959 s\n",
      "Accuracy 0.926122337021121 precision 0.9261424781245683 specificity 0.8019819758972433 recall 0.926122337021121 f1 0.9232239742591719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 9.997280836105347 s\n",
      "Accuracy 0.923287921733565 precision 0.9230533566992619 specificity 0.7953734321768425 recall 0.923287921733565 f1 0.9202344289442679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 9.818546295166016 s\n",
      "Accuracy 0.9239279509920454 precision 0.9233205167150471 specificity 0.8024008797001579 recall 0.9239279509920454 f1 0.9211968573455803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 9.7895348072052 s\n",
      "Accuracy 0.9255737405138521 precision 0.9255918808875693 specificity 0.797786396311879 recall 0.9255737405138521 f1 0.9225581213965776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 9.590052604675293 s\n",
      "Accuracy 0.9263966352747555 precision 0.9262706022661761 specificity 0.7976741023051604 recall 0.9263966352747555 f1 0.9234391468728218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 9.577272176742554 s\n",
      "Accuracy 0.9248422785041602 precision 0.9246286508293281 specificity 0.8020838551389701 recall 0.9248422785041602 f1 0.9219894845199408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 9.612220287322998 s\n",
      "Accuracy 0.9268537990308129 precision 0.9268831917931161 specificity 0.7975580053614426 recall 0.9268537990308129 f1 0.9238585963057275\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 9.53181004524231 s\n",
      "Accuracy 0.9224650269726616 precision 0.9223900512567245 specificity 0.7839701116173837 recall 0.9224650269726616 f1 0.9190390090266035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 9.494015216827393 s\n",
      "Accuracy 0.9240193837432569 precision 0.9240634221881022 specificity 0.794150850533611 recall 0.9240193837432569 f1 0.9208673097398645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 9.842017412185669 s\n",
      "Accuracy 0.9239279509920454 precision 0.9236433245350975 specificity 0.795973881885398 recall 0.9239279509920454 f1 0.9209200796411756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 9.622326135635376 s\n",
      "Accuracy 0.9269452317820244 precision 0.9266313060133016 specificity 0.8042902876327435 recall 0.9269452317820244 f1 0.9242227761844961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 10.011999607086182 s\n",
      "Accuracy 0.9266709335283899 precision 0.9262814766805998 specificity 0.8043849301790825 recall 0.9266709335283899 f1 0.9239698322514871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 9.782512903213501 s\n",
      "Accuracy 0.923287921733565 precision 0.9234865072622316 specificity 0.7889159562924133 recall 0.923287921733565 f1 0.9199373313186568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 9.727749586105347 s\n",
      "Accuracy 0.9280424247965622 precision 0.9279867016762023 specificity 0.7978501489202475 recall 0.9280424247965622 f1 0.9251070071693046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 10.077991247177124 s\n",
      "Accuracy 0.9274938282892933 precision 0.9268475146800708 specificity 0.8101904082814054 recall 0.9274938282892933 f1 0.9250430896253292\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 9.922993659973145 s\n",
      "Accuracy 0.9221907287190272 precision 0.9220807125235531 specificity 0.7880246606440627 recall 0.9221907287190272 f1 0.9188777318517506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 9.815510034561157 s\n",
      "Accuracy 0.9246594130017373 precision 0.9241396863467843 specificity 0.7992626101430117 recall 0.9246594130017373 f1 0.9218306153233753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 9.805248975753784 s\n",
      "Accuracy 0.9225564597238731 precision 0.9222790581432168 specificity 0.7914437585494948 recall 0.9225564597238731 f1 0.9193954326489558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 9.640999794006348 s\n",
      "Accuracy 0.9224650269726616 precision 0.9221911638367334 specificity 0.7949674014642805 recall 0.9224650269726616 f1 0.9193950680087225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 9.705500841140747 s\n",
      "Accuracy 0.9279509920453507 precision 0.9281095393384624 specificity 0.8080770680296742 recall 0.9279509920453507 f1 0.9252018155564207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 9.874511241912842 s\n",
      "Accuracy 0.928773886806254 precision 0.929121905661373 specificity 0.8101597305386323 recall 0.928773886806254 f1 0.9260410401123955\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 9.705045938491821 s\n",
      "Accuracy 0.9266709335283899 precision 0.9263110547550023 specificity 0.7983280121875922 recall 0.9266709335283899 f1 0.9238089583254828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 9.870126008987427 s\n",
      "Accuracy 0.9239279509920454 precision 0.9235224343814171 specificity 0.8071200797853144 recall 0.9239279509920454 f1 0.9212489417260119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 9.99351453781128 s\n",
      "Accuracy 0.9245679802505258 precision 0.923996686644772 specificity 0.7988232836241581 recall 0.9245679802505258 f1 0.9217439132242163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 9.78346037864685 s\n",
      "Accuracy 0.9258480387674866 precision 0.9252431999825476 specificity 0.8035378452171195 recall 0.9258480387674866 f1 0.9231835570249058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 9.643990278244019 s\n",
      "Accuracy 0.9236536527384109 precision 0.923217236488803 specificity 0.800031381862389 recall 0.9236536527384109 f1 0.920795485664908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 9.826712131500244 s\n",
      "Accuracy 0.9255737405138521 precision 0.9251372461275293 specificity 0.7974199685522804 recall 0.9255737405138521 f1 0.9226892560015335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 9.754036664962769 s\n",
      "Accuracy 0.9252080095090062 precision 0.9247397790309047 specificity 0.7980279746070809 recall 0.9252080095090062 f1 0.9223416267189108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 10.059631586074829 s\n",
      "Accuracy 0.9224650269726616 precision 0.9224949246203051 specificity 0.7914906347632368 recall 0.9224650269726616 f1 0.9192106842424007\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 9.9679536819458 s\n",
      "Accuracy 0.9246594130017373 precision 0.9243201462930475 specificity 0.7889643935795639 recall 0.9246594130017373 f1 0.9215033023824586\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 9.482645034790039 s\n",
      "Accuracy 0.9242022492456798 precision 0.923612031179606 specificity 0.7987516302250506 recall 0.9242022492456798 f1 0.9213752718179976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 9.906096458435059 s\n",
      "Accuracy 0.9253908750114291 precision 0.9249012607437733 specificity 0.8048164570169816 recall 0.9253908750114291 f1 0.9227089216590557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 9.904946088790894 s\n",
      "Accuracy 0.9260309042699095 precision 0.9260847445697548 specificity 0.8045171858417938 recall 0.9260309042699095 f1 0.9231844903582076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 9.73543119430542 s\n",
      "Accuracy 0.9300539453232147 precision 0.9305864671363516 specificity 0.8009875955713898 recall 0.9300539453232147 f1 0.9270850669077406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 9.929003953933716 s\n",
      "Accuracy 0.9271280972844473 precision 0.9272981577608106 specificity 0.7890917152114751 recall 0.9271280972844473 f1 0.9238889527642052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 9.707182168960571 s\n",
      "Accuracy 0.9244765474993143 precision 0.9246497330581913 specificity 0.7981861378099415 recall 0.9244765474993143 f1 0.9214032203831395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 9.79285478591919 s\n",
      "Accuracy 0.9203620736947975 precision 0.9195474841353879 specificity 0.7871739083557121 recall 0.9203620736947975 f1 0.9172184928666787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 9.990010261535645 s\n",
      "Accuracy 0.9306939745816951 precision 0.9307394854386896 specificity 0.8031974477811615 recall 0.9306939745816951 f1 0.9279197954768845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 9.692032098770142 s\n",
      "Accuracy 0.9276766937917162 precision 0.9271486311420111 specificity 0.8089673952815137 recall 0.9276766937917162 f1 0.9251561191072357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 9.823029041290283 s\n",
      "Accuracy 0.9272195300356588 precision 0.9270026032695478 specificity 0.7998833351044661 recall 0.9272195300356588 f1 0.924363423918972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 9.961465835571289 s\n",
      "Accuracy 0.926305202523544 precision 0.9261271256431157 specificity 0.8001526048586185 recall 0.926305202523544 f1 0.9234235507444754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 9.821188688278198 s\n",
      "Accuracy 0.9266709335283899 precision 0.9264573716952912 specificity 0.802776236841449 recall 0.9266709335283899 f1 0.9238735497063875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 9.73651671409607 s\n",
      "Accuracy 0.9270366645332359 precision 0.9274734849029272 specificity 0.7971215940268991 recall 0.9270366645332359 f1 0.9239252665588744\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 9.861202239990234 s\n",
      "Accuracy 0.9246594130017373 precision 0.924390754289957 specificity 0.7961670689859207 recall 0.9246594130017373 f1 0.9216678504696336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 9.881006956100464 s\n",
      "Accuracy 0.9248422785041602 precision 0.9243198833496622 specificity 0.7951769938736012 recall 0.9248422785041602 f1 0.9219126755886823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 10.191818952560425 s\n",
      "Accuracy 0.9280424247965622 precision 0.9279379607988256 specificity 0.8092709904846195 recall 0.9280424247965622 f1 0.9253988789681711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 10.031016111373901 s\n",
      "Accuracy 0.9272195300356588 precision 0.9269310159065398 specificity 0.8054898416081694 recall 0.9272195300356588 f1 0.9245241680919767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 9.999998092651367 s\n",
      "Accuracy 0.9253908750114291 precision 0.9254051370874112 specificity 0.7994950253446877 recall 0.9253908750114291 f1 0.9224157025220296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 9.995628356933594 s\n",
      "Accuracy 0.9276766937917162 precision 0.927250009752011 specificity 0.7995385449683108 recall 0.9276766937917162 f1 0.9248896775121136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 9.737557172775269 s\n",
      "Accuracy 0.9306939745816951 precision 0.9312798997727582 specificity 0.8128541883561731 recall 0.9306939745816951 f1 0.9280041459943018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 10.116608142852783 s\n",
      "Accuracy 0.923105056231142 precision 0.9228024464558747 specificity 0.7940202340040143 recall 0.923105056231142 f1 0.9200331481046281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 9.807234525680542 s\n",
      "Accuracy 0.9284995885526196 precision 0.9280904398508522 specificity 0.805256049870945 recall 0.9284995885526196 f1 0.9258644461597286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 9.838518619537354 s\n",
      "Accuracy 0.9249337112553717 precision 0.9243459990086593 specificity 0.7995472265132336 recall 0.9249337112553717 f1 0.922141993279809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 10.022007465362549 s\n",
      "Accuracy 0.9272195300356588 precision 0.9267802002903694 specificity 0.8031429552124953 recall 0.9272195300356588 f1 0.9245157180367382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 9.86500597000122 s\n",
      "Accuracy 0.9305111090792721 precision 0.9303479537065235 specificity 0.8045466105730907 recall 0.9305111090792721 f1 0.9278250049212048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 9.895578622817993 s\n",
      "Accuracy 0.926488068025967 precision 0.926226954028758 specificity 0.8022386060798602 recall 0.926488068025967 f1 0.9236882577734016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 9.883004665374756 s\n",
      "Accuracy 0.9228307579775076 precision 0.922410243562012 specificity 0.7924949279294075 recall 0.9228307579775076 f1 0.9197503174367767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 9.925369262695312 s\n",
      "Accuracy 0.923105056231142 precision 0.9227466451494954 specificity 0.7952335085561626 recall 0.923105056231142 f1 0.9200832231672421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 10.042704820632935 s\n",
      "Accuracy 0.9273109627868703 precision 0.9271966253792117 specificity 0.8053116734845436 recall 0.9273109627868703 f1 0.9245593560251204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 10.046601295471191 s\n",
      "Accuracy 0.9262137697723325 precision 0.9256141538701269 specificity 0.8007365515963155 recall 0.9262137697723325 f1 0.9234840768794055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 10.118006944656372 s\n",
      "Accuracy 0.9276766937917162 precision 0.9271432298193533 specificity 0.8075705045698237 recall 0.9276766937917162 f1 0.9251238150494236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 9.94746732711792 s\n",
      "Accuracy 0.9284995885526196 precision 0.9283176636572766 specificity 0.8075979546419565 recall 0.9284995885526196 f1 0.9258482791313362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 9.966718673706055 s\n",
      "Accuracy 0.9245679802505258 precision 0.9242608410810141 specificity 0.8015013793520618 recall 0.9245679802505258 f1 0.921724148420706\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 10.031005859375 s\n",
      "Accuracy 0.9224650269726616 precision 0.9224237763755713 specificity 0.7923935878110001 recall 0.9224650269726616 f1 0.9192555201985081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 9.873687744140625 s\n",
      "Accuracy 0.9294139160647343 precision 0.9292082356874432 specificity 0.8132444807976319 recall 0.9294139160647343 f1 0.9269221284603719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 9.795722961425781 s\n",
      "Accuracy 0.9242022492456798 precision 0.9237203581181724 specificity 0.7943451675127617 recall 0.9242022492456798 f1 0.9212225407144354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 9.809375524520874 s\n",
      "Accuracy 0.9211849684557009 precision 0.9208926235523813 specificity 0.7922320479546291 recall 0.9211849684557009 f1 0.9180189893222069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 9.853007078170776 s\n",
      "Accuracy 0.925939471518698 precision 0.925469510398646 specificity 0.804567826058359 recall 0.925939471518698 f1 0.9232552968505998\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 10.118780851364136 s\n",
      "Accuracy 0.9220078632166042 precision 0.9218765222822628 specificity 0.8004443960864485 recall 0.9220078632166042 f1 0.9190305305429187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 9.914045333862305 s\n",
      "Accuracy 0.926488068025967 precision 0.9267676790999718 specificity 0.7974245050909007 recall 0.926488068025967 f1 0.9234121597038083\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 9.761531114578247 s\n",
      "Accuracy 0.9252994422602177 precision 0.9248542556578301 specificity 0.8030440798225607 recall 0.9252994422602177 f1 0.9225553885135314\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 10.190208911895752 s\n",
      "Accuracy 0.9243851147481028 precision 0.9236287786322503 specificity 0.8005861886369128 recall 0.9243851147481028 f1 0.921671473399721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 9.860811710357666 s\n",
      "Accuracy 0.9266709335283899 precision 0.9262116105321958 specificity 0.804634794972973 recall 0.9266709335283899 f1 0.9239995394919678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 9.666508913040161 s\n",
      "Accuracy 0.928591021303831 precision 0.9280876568678373 specificity 0.8105179814174164 recall 0.928591021303831 f1 0.9261169694691862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 10.007338523864746 s\n",
      "Accuracy 0.9247508457529487 precision 0.9245717903123069 specificity 0.7994455303636955 recall 0.9247508457529487 f1 0.9218179085195001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 9.751421928405762 s\n",
      "Accuracy 0.9244765474993143 precision 0.9239168717527096 specificity 0.7966768815963745 recall 0.9244765474993143 f1 0.9215906228454609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 9.861408948898315 s\n",
      "Accuracy 0.9240193837432569 precision 0.9236723382342913 specificity 0.8009133869735238 recall 0.9240193837432569 f1 0.921162084001558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 9.747892379760742 s\n",
      "Accuracy 0.9249337112553717 precision 0.9251542611928621 specificity 0.8013057979030723 recall 0.9249337112553717 f1 0.9219373062192684\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 9.749868392944336 s\n",
      "Accuracy 0.9251165767577947 precision 0.9253504748053112 specificity 0.7970544178545059 recall 0.9251165767577947 f1 0.9220119179657615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 10.130021810531616 s\n",
      "Accuracy 0.9242022492456798 precision 0.9242552361746741 specificity 0.7911944758086655 recall 0.9242022492456798 f1 0.9209748004524498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 9.858928203582764 s\n",
      "Accuracy 0.931059705586541 precision 0.9306931641654036 specificity 0.8149447072562389 recall 0.931059705586541 f1 0.928690150401399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 9.71953797340393 s\n",
      "Accuracy 0.923287921733565 precision 0.9229683903114224 specificity 0.7965496968709479 recall 0.923287921733565 f1 0.9202922897644087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 9.852877378463745 s\n",
      "Accuracy 0.9263966352747555 precision 0.9260430309916942 specificity 0.8012075798495828 recall 0.9263966352747555 f1 0.9235986800878567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 9.578997373580933 s\n",
      "Accuracy 0.9289567523086769 precision 0.9287678369654392 specificity 0.7985029372212616 recall 0.9289567523086769 f1 0.9260987386730088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 9.704009294509888 s\n",
      "Accuracy 0.9278595592941392 precision 0.9274292398078816 specificity 0.8001621310787911 recall 0.9278595592941392 f1 0.9250932675209101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 10.096928119659424 s\n",
      "Accuracy 0.9220078632166042 precision 0.9217457738247443 specificity 0.7831042041257132 recall 0.9220078632166042 f1 0.9186031893664983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 9.77751874923706 s\n",
      "Accuracy 0.9239279509920454 precision 0.9239724481917899 specificity 0.799246122272728 recall 0.9239279509920454 f1 0.9209063230204572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 9.776284456253052 s\n",
      "Accuracy 0.9281338575477737 precision 0.928348999838166 specificity 0.806017313829635 recall 0.9281338575477737 f1 0.9253232946567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 9.83687710762024 s\n",
      "Accuracy 0.9248422785041602 precision 0.9244435557100046 specificity 0.8055854717472677 recall 0.9248422785041602 f1 0.9221384452195465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 9.713000297546387 s\n",
      "Accuracy 0.9236536527384109 precision 0.9230271632096011 specificity 0.8026176086577922 recall 0.9236536527384109 f1 0.9209298260126167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 9.932823896408081 s\n",
      "Accuracy 0.9324311968547133 precision 0.9322184469609598 specificity 0.8179119853939897 recall 0.9324311968547133 f1 0.9301052774642135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 10.087997913360596 s\n",
      "Accuracy 0.928773886806254 precision 0.9283914171335895 specificity 0.8001612975138478 recall 0.928773886806254 f1 0.926012716366819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 10.045019626617432 s\n",
      "Accuracy 0.9231964889823535 precision 0.9230776454387578 specificity 0.7923498451020442 recall 0.9231964889823535 f1 0.9200256936569712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 9.89824891090393 s\n",
      "Accuracy 0.9263966352747555 precision 0.9265238087852946 specificity 0.8000032151660397 recall 0.9263966352747555 f1 0.9234245595291177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 9.969584465026855 s\n",
      "Accuracy 0.923470787235988 precision 0.9227711050654189 specificity 0.8007462138585439 recall 0.923470787235988 f1 0.9207212379726349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 9.82800030708313 s\n",
      "Accuracy 0.9239279509920454 precision 0.9240530232047499 specificity 0.7902573196574727 recall 0.9239279509920454 f1 0.9206489312160027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 9.888812780380249 s\n",
      "Accuracy 0.9272195300356588 precision 0.9267829737199649 specificity 0.8008237554923726 recall 0.9272195300356588 f1 0.9244573392943386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 9.75202226638794 s\n",
      "Accuracy 0.9308768400841181 precision 0.9305126502049773 specificity 0.8166881385742991 recall 0.9308768400841181 f1 0.9285431498668918\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 9.857684850692749 s\n",
      "Accuracy 0.9278595592941392 precision 0.9270402982529766 specificity 0.8113148622403762 recall 0.9278595592941392 f1 0.9255121597175137\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 9.823582172393799 s\n",
      "Accuracy 0.9298710798207918 precision 0.9294206365626628 specificity 0.8103351790710229 recall 0.9298710798207918 f1 0.9273994069783865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 9.722545862197876 s\n",
      "Accuracy 0.9276766937917162 precision 0.9271620229263926 specificity 0.8096161286669441 recall 0.9276766937917162 f1 0.9251672473914283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 9.98600149154663 s\n",
      "Accuracy 0.9274938282892933 precision 0.9278419607399764 specificity 0.8031731572751267 recall 0.9274938282892933 f1 0.9245651997832308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 10.112454175949097 s\n",
      "Accuracy 0.9231964889823535 precision 0.9225443044642957 specificity 0.796424903898014 recall 0.9231964889823535 f1 0.9203091025721867\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 9.88480019569397 s\n",
      "Accuracy 0.9272195300356588 precision 0.9265648864978363 specificity 0.8010038932584098 recall 0.9272195300356588 f1 0.9245384596182454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 10.080866575241089 s\n",
      "Accuracy 0.9254823077626406 precision 0.9252560920701506 specificity 0.7966926772177967 recall 0.9254823077626406 f1 0.9225096068079226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 9.916378498077393 s\n",
      "Accuracy 0.9224650269726616 precision 0.9224334956568049 specificity 0.7887297557714504 recall 0.9224650269726616 f1 0.9191544739257596\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 9.653535604476929 s\n",
      "Accuracy 0.926122337021121 precision 0.9260837058735681 specificity 0.7991659860767397 recall 0.926122337021121 f1 0.9231702904422978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 9.989052057266235 s\n",
      "Accuracy 0.9306939745816951 precision 0.9302893496559753 specificity 0.8150111706192159 recall 0.9306939745816951 f1 0.9283318175978138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 9.947999238967896 s\n",
      "Accuracy 0.9262137697723325 precision 0.9265314772596088 specificity 0.7978173572813537 recall 0.9262137697723325 f1 0.9231312729787435\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 9.580010175704956 s\n",
      "Accuracy 0.9269452317820244 precision 0.9267708800581891 specificity 0.803324225507172 recall 0.9269452317820244 f1 0.924155181730177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 9.782007694244385 s\n",
      "Accuracy 0.9274023955380818 precision 0.92707647252075 specificity 0.803235890520641 recall 0.9274023955380818 f1 0.9246673824977927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 9.80414080619812 s\n",
      "Accuracy 0.9289567523086769 precision 0.9284365263035619 specificity 0.8077209594638137 recall 0.9289567523086769 f1 0.9264286139963704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 9.785409450531006 s\n",
      "Accuracy 0.9260309042699095 precision 0.9263904992906928 specificity 0.801934420190108 recall 0.9260309042699095 f1 0.9230368542325388\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 9.863005638122559 s\n",
      "Accuracy 0.926305202523544 precision 0.9265213871696593 specificity 0.800917865403961 recall 0.926305202523544 f1 0.9233296272260142\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 9.789000034332275 s\n",
      "Accuracy 0.9251165767577947 precision 0.9250325325034658 specificity 0.8003337837001859 recall 0.9251165767577947 f1 0.9221855338070749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 9.7549409866333 s\n",
      "Accuracy 0.9271280972844473 precision 0.926314039979612 specificity 0.8089612033547042 recall 0.9271280972844473 f1 0.924706142467369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 10.045323848724365 s\n",
      "Accuracy 0.9284995885526196 precision 0.9279613040508495 specificity 0.8095624805641621 recall 0.9284995885526196 f1 0.9260130943459501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 9.716396808624268 s\n",
      "Accuracy 0.928591021303831 precision 0.9280508892831247 specificity 0.8063869124592238 recall 0.928591021303831 f1 0.9260302027111191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 9.682821989059448 s\n",
      "Accuracy 0.9247508457529487 precision 0.9242429194403569 specificity 0.7966590501100063 recall 0.9247508457529487 f1 0.9218525953210421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 9.91550588607788 s\n",
      "Accuracy 0.9247508457529487 precision 0.9244627279206992 specificity 0.7943846782257704 recall 0.9247508457529487 f1 0.9217214432134351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 9.743978023529053 s\n",
      "Accuracy 0.9300539453232147 precision 0.9296187213634831 specificity 0.8142597901720517 recall 0.9300539453232147 f1 0.9276727553561972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 9.941999197006226 s\n",
      "Accuracy 0.9223735942214502 precision 0.9218980526075807 specificity 0.7868629305524774 recall 0.9223735942214502 f1 0.9191491479438787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 9.780004024505615 s\n",
      "Accuracy 0.926488068025967 precision 0.9261146192738048 specificity 0.8043550801338092 recall 0.926488068025967 f1 0.9237772019154324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 9.943022966384888 s\n",
      "Accuracy 0.9273109627868703 precision 0.9267417980769576 specificity 0.8054926449758861 recall 0.9273109627868703 f1 0.9247122990581739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 9.849518060684204 s\n",
      "Accuracy 0.9284995885526196 precision 0.928032144040111 specificity 0.8072334254186223 recall 0.9284995885526196 f1 0.9259319977693975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 9.689032554626465 s\n",
      "Accuracy 0.9289567523086769 precision 0.9288043136241559 specificity 0.8072476751664855 recall 0.9289567523086769 f1 0.9262974879760157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 9.832036256790161 s\n",
      "Accuracy 0.9208192374508549 precision 0.9216081213614837 specificity 0.7948164893524149 recall 0.9208192374508549 f1 0.917418729517715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 9.794569253921509 s\n",
      "Accuracy 0.9237450854896224 precision 0.9234396691825351 specificity 0.7979630229218222 recall 0.9237450854896224 f1 0.9207918211518362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 9.789047718048096 s\n",
      "Accuracy 0.9248422785041602 precision 0.9245773863192939 specificity 0.7971683521578957 recall 0.9248422785041602 f1 0.9218794320600856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 9.983999729156494 s\n",
      "Accuracy 0.9243851147481028 precision 0.9237329512072079 specificity 0.7999860491687845 recall 0.9243851147481028 f1 0.9216165755492671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 9.726580381393433 s\n",
      "Accuracy 0.9236536527384109 precision 0.9234562066894367 specificity 0.7948594958045885 recall 0.9236536527384109 f1 0.9205833010255856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 9.767827987670898 s\n",
      "Accuracy 0.9257566060162751 precision 0.9250442532712084 specificity 0.8025120081625636 recall 0.9257566060162751 f1 0.9231041024021853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 9.642800092697144 s\n",
      "Accuracy 0.9304196763280607 precision 0.9304956071602118 specificity 0.8108322728333335 recall 0.9304196763280607 f1 0.9278085829932176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 9.824360370635986 s\n",
      "Accuracy 0.9252994422602177 precision 0.9252493100622493 specificity 0.7987595505701685 recall 0.9252994422602177 f1 0.9223222514144269\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 9.899001359939575 s\n",
      "Accuracy 0.9262137697723325 precision 0.925954753234668 specificity 0.8061286424268486 recall 0.9262137697723325 f1 0.9235047503925569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 9.811865329742432 s\n",
      "Accuracy 0.9265795007771784 precision 0.9266458531444137 specificity 0.8036877064988698 recall 0.9265795007771784 f1 0.9237201891204911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 9.955316305160522 s\n",
      "Accuracy 0.9239279509920454 precision 0.9235447476482629 specificity 0.798878006121264 recall 0.9239279509920454 f1 0.9210276479740486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 9.915102243423462 s\n",
      "Accuracy 0.9223735942214502 precision 0.9222955407169691 specificity 0.7916593583048545 recall 0.9223735942214502 f1 0.9191531922287083\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 9.892002820968628 s\n",
      "Accuracy 0.9238365182408339 precision 0.9232922356672448 specificity 0.8027071977226193 recall 0.9238365182408339 f1 0.9210890457339488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 9.703126668930054 s\n",
      "Accuracy 0.9299625125720032 precision 0.9299524213272203 specificity 0.8097718180912188 recall 0.9299625125720032 f1 0.9273416889249889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 9.865629196166992 s\n",
      "Accuracy 0.9229221907287191 precision 0.922524106197339 specificity 0.7914322901428152 recall 0.9229221907287191 f1 0.9198081083595386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 9.98552942276001 s\n",
      "Accuracy 0.931059705586541 precision 0.9309902621986272 specificity 0.816259211137884 recall 0.931059705586541 f1 0.9286275493348479\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 9.843542575836182 s\n",
      "Accuracy 0.925939471518698 precision 0.9255218001145947 specificity 0.8046883562457919 recall 0.925939471518698 f1 0.923240596042695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 9.788026809692383 s\n",
      "Accuracy 0.9252080095090062 precision 0.9247530367269742 specificity 0.8010300296515676 recall 0.9252080095090062 f1 0.9224140123852702\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 9.976545572280884 s\n",
      "Accuracy 0.9270366645332359 precision 0.9269497641766408 specificity 0.8066638349873188 recall 0.9270366645332359 f1 0.9243045208393577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 9.7240891456604 s\n",
      "Accuracy 0.9297796470695803 precision 0.9296475496623241 specificity 0.8067877531147729 recall 0.9297796470695803 f1 0.9271207022775406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 9.726946115493774 s\n",
      "Accuracy 0.9236536527384109 precision 0.9230543997209039 specificity 0.7926802354624172 recall 0.9236536527384109 f1 0.9206580844946024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 9.941075563430786 s\n",
      "Accuracy 0.9290481850598884 precision 0.9285550300253834 specificity 0.8162686501768319 recall 0.9290481850598884 f1 0.926716441740514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 9.767346143722534 s\n",
      "Accuracy 0.925939471518698 precision 0.925897274293628 specificity 0.796703876675311 recall 0.925939471518698 f1 0.9229222342255756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 9.822959184646606 s\n",
      "Accuracy 0.9274938282892933 precision 0.9270839858250703 specificity 0.8033097555288131 recall 0.9274938282892933 f1 0.9247900799900207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 9.899324417114258 s\n",
      "Accuracy 0.9248422785041602 precision 0.9244036832945101 specificity 0.7966307719386776 recall 0.9248422785041602 f1 0.921921857555367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 9.83599853515625 s\n",
      "Accuracy 0.9235622199871995 precision 0.9228814708361484 specificity 0.7998257059067408 recall 0.9235622199871995 f1 0.9207831150020973\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 9.988000392913818 s\n",
      "Accuracy 0.925939471518698 precision 0.9259459488930871 specificity 0.7976251020393528 recall 0.925939471518698 f1 0.9229314131071266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 9.814208507537842 s\n",
      "Accuracy 0.9251165767577947 precision 0.9247424850773345 specificity 0.805563447234924 recall 0.9251165767577947 f1 0.9224092323026813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 9.85583758354187 s\n",
      "Accuracy 0.9299625125720032 precision 0.9295663211744811 specificity 0.815846324123711 recall 0.9299625125720032 f1 0.9276034353535182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 9.793541431427002 s\n",
      "Accuracy 0.9231964889823535 precision 0.9230270677783862 specificity 0.799156913396558 recall 0.9231964889823535 f1 0.9202204997753644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 9.922982931137085 s\n",
      "Accuracy 0.9265795007771784 precision 0.926773545052115 specificity 0.7967746713129964 recall 0.9265795007771784 f1 0.9235124660300764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 9.653997898101807 s\n",
      "Accuracy 0.9237450854896224 precision 0.9236740034561205 specificity 0.7957699735107655 recall 0.9237450854896224 f1 0.9206625278876654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 9.702555656433105 s\n",
      "Accuracy 0.9283167230501966 precision 0.9282453802576015 specificity 0.8108956036614029 recall 0.9283167230501966 f1 0.9257077496261775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 9.832741260528564 s\n",
      "Accuracy 0.9278595592941392 precision 0.9275072598472112 specificity 0.8039876676400349 recall 0.9278595592941392 f1 0.9251612638043019\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 9.672883749008179 s\n",
      "Accuracy 0.9269452317820244 precision 0.9266845797123049 specificity 0.8093164059704114 recall 0.9269452317820244 f1 0.9243297224035095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 9.91952109336853 s\n",
      "Accuracy 0.9273109627868703 precision 0.9272640499148962 specificity 0.8031801911936168 recall 0.9273109627868703 f1 0.9244871120333614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 9.766370058059692 s\n",
      "Accuracy 0.9291396178110999 precision 0.9288518620178102 specificity 0.8128866707731153 recall 0.9291396178110999 f1 0.9266601126356665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 9.617536544799805 s\n",
      "Accuracy 0.9249337112553717 precision 0.9245649335169062 specificity 0.7990338900345735 recall 0.9249337112553717 f1 0.9220540955743988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 9.672227144241333 s\n",
      "Accuracy 0.9305111090792721 precision 0.9301724535556302 specificity 0.808925689179648 recall 0.9305111090792721 f1 0.9279821713674158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 9.78690218925476 s\n",
      "Accuracy 0.9219164304653927 precision 0.9216664928285115 specificity 0.7935921580784319 recall 0.9219164304653927 f1 0.9187900650117518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 9.905038595199585 s\n",
      "Accuracy 0.9258480387674866 precision 0.9253669511351914 specificity 0.7977218670755635 recall 0.9258480387674866 f1 0.9229924338928477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 9.748305320739746 s\n",
      "Accuracy 0.9282252902989852 precision 0.9280955830247236 specificity 0.8021497798143874 recall 0.9282252902989852 f1 0.9254207338759981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 9.894999265670776 s\n",
      "Accuracy 0.9225564597238731 precision 0.9222248260134401 specificity 0.8000558505320028 recall 0.9225564597238731 f1 0.9196423032185214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 9.947452545166016 s\n",
      "Accuracy 0.9238365182408339 precision 0.9238793001986809 specificity 0.7959854479376259 recall 0.9238365182408339 f1 0.9207285223285812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 9.759279727935791 s\n",
      "Accuracy 0.9247508457529487 precision 0.9242337367492384 specificity 0.799760297358444 recall 0.9247508457529487 f1 0.9219359327037647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 9.790528297424316 s\n",
      "Accuracy 0.9262137697723325 precision 0.9256793755712394 specificity 0.8094072329714247 recall 0.9262137697723325 f1 0.9236788395869117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 9.711055755615234 s\n",
      "Accuracy 0.9236536527384109 precision 0.9232910142221952 specificity 0.7974204205873352 recall 0.9236536527384109 f1 0.920702701600942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 9.953035354614258 s\n",
      "Accuracy 0.9286824540550425 precision 0.9286575080238919 specificity 0.8054470789247343 recall 0.9286824540550425 f1 0.9259366304076445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 9.63500452041626 s\n",
      "Accuracy 0.9257566060162751 precision 0.9254811539123183 specificity 0.7943000370448504 recall 0.9257566060162751 f1 0.9227446786967043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 9.951030492782593 s\n",
      "Accuracy 0.9229221907287191 precision 0.9224501506560733 specificity 0.7988529636827655 recall 0.9229221907287191 f1 0.920030118920053\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 9.826582193374634 s\n",
      "Accuracy 0.923287921733565 precision 0.9237785571931634 specificity 0.7917422462934326 recall 0.923287921733565 f1 0.919934886017705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 9.990380048751831 s\n",
      "Accuracy 0.9219164304653927 precision 0.9217416097322814 specificity 0.7918212521902838 recall 0.9219164304653927 f1 0.9187190624490454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 10.071043014526367 s\n",
      "Accuracy 0.9308768400841181 precision 0.9306988820224258 specificity 0.8150421730045719 recall 0.9308768400841181 f1 0.9284459127745074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 9.878091096878052 s\n",
      "Accuracy 0.9260309042699095 precision 0.9257852170627735 specificity 0.7929422175017649 recall 0.9260309042699095 f1 0.9229817615099877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 9.94401502609253 s\n",
      "Accuracy 0.9275852610405048 precision 0.9275437267339885 specificity 0.8061505561721216 recall 0.9275852610405048 f1 0.9248383111152901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 9.891053199768066 s\n",
      "Accuracy 0.9253908750114291 precision 0.9250611620268883 specificity 0.8016220230276495 recall 0.9253908750114291 f1 0.9225743511996588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 9.961999654769897 s\n",
      "Accuracy 0.9221907287190272 precision 0.9222962392517615 specificity 0.7921548444807093 recall 0.9221907287190272 f1 0.9189263209657412\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 10.12987732887268 s\n",
      "Accuracy 0.9277681265429277 precision 0.9272999501765625 specificity 0.8111132209588816 recall 0.9277681265429277 f1 0.9252806444471703\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 9.73547077178955 s\n",
      "Accuracy 0.9229221907287191 precision 0.9226195894221784 specificity 0.7981505525777798 recall 0.9229221907287191 f1 0.9199556545199693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 9.792047500610352 s\n",
      "Accuracy 0.9241108164944684 precision 0.9241613179842266 specificity 0.7891680506448131 recall 0.9241108164944684 f1 0.9208288037645744\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 9.882033348083496 s\n",
      "Accuracy 0.9262137697723325 precision 0.9260453159911205 specificity 0.8028168028664323 recall 0.9262137697723325 f1 0.9233939359236787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 9.661959886550903 s\n",
      "Accuracy 0.9263966352747555 precision 0.9262582715129202 specificity 0.799808279926457 recall 0.9263966352747555 f1 0.9234963384560199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 9.676000356674194 s\n",
      "Accuracy 0.9260309042699095 precision 0.9252724163346676 specificity 0.8035066737053 recall 0.9260309042699095 f1 0.9234271975006453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 9.951299667358398 s\n",
      "Accuracy 0.9225564597238731 precision 0.9223730199054627 specificity 0.7968915809453594 recall 0.9225564597238731 f1 0.9195115623055846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 9.715129375457764 s\n",
      "Accuracy 0.9284081558014081 precision 0.9280566373649352 specificity 0.802657244366376 recall 0.9284081558014081 f1 0.9256891071027471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 9.663940906524658 s\n",
      "Accuracy 0.9215506994605468 precision 0.9211056555257573 specificity 0.789603276065732 recall 0.9215506994605468 f1 0.9183708767920272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 9.540038108825684 s\n",
      "Accuracy 0.9281338575477737 precision 0.927747823582883 specificity 0.808470467649205 recall 0.9281338575477737 f1 0.9255613339767063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 9.619064807891846 s\n",
      "Accuracy 0.9256651732650636 precision 0.924838851619253 specificity 0.8000143177844041 recall 0.9256651732650636 f1 0.9229910784547074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 9.700037717819214 s\n",
      "Accuracy 0.9262137697723325 precision 0.9258581174335437 specificity 0.799044144161127 recall 0.9262137697723325 f1 0.9233581310467026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 9.688883066177368 s\n",
      "Accuracy 0.9243851147481028 precision 0.9243312610866417 specificity 0.792792741577714 recall 0.9243851147481028 f1 0.9212345785951666\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 9.744012355804443 s\n",
      "Accuracy 0.9242936819968913 precision 0.9243329601952617 specificity 0.7938709239671562 recall 0.9242936819968913 f1 0.9211420493696841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 9.862518548965454 s\n",
      "Accuracy 0.9231964889823535 precision 0.9226303999348923 specificity 0.7980461060695745 recall 0.9231964889823535 f1 0.9203212875911714\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 9.855616569519043 s\n",
      "Accuracy 0.9283167230501966 precision 0.928196390463344 specificity 0.8097895144426243 recall 0.9283167230501966 f1 0.9256957619590986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 9.622074127197266 s\n",
      "Accuracy 0.9236536527384109 precision 0.9234052874069166 specificity 0.7925406135871204 recall 0.9236536527384109 f1 0.9205381350026276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 9.864379405975342 s\n",
      "Accuracy 0.9256651732650636 precision 0.9257451609780357 specificity 0.7997742467778207 recall 0.9256651732650636 f1 0.9226843757932849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 9.679181814193726 s\n",
      "Accuracy 0.9210935357044894 precision 0.9204151604021342 specificity 0.7936342773124282 recall 0.9210935357044894 f1 0.9180952205016935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 9.640885591506958 s\n",
      "Accuracy 0.9238365182408339 precision 0.9236316378355939 specificity 0.795357646526615 recall 0.9238365182408339 f1 0.9207856034945262\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 9.810003519058228 s\n",
      "Accuracy 0.9291396178110999 precision 0.9289997622951038 specificity 0.8100835637052061 recall 0.9291396178110999 f1 0.9265477294153377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 9.426000595092773 s\n",
      "Accuracy 0.9220992959678157 precision 0.9220096207923956 specificity 0.7898519638550955 recall 0.9220992959678157 f1 0.9188273494676994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 9.658085346221924 s\n",
      "Accuracy 0.9262137697723325 precision 0.926497690988425 specificity 0.79142931994842 recall 0.9262137697723325 f1 0.9229788998570726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 9.728009223937988 s\n",
      "Accuracy 0.9226478924750846 precision 0.9223031480434184 specificity 0.7913738627012492 recall 0.9226478924750846 f1 0.9195085556752662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 9.499011993408203 s\n",
      "Accuracy 0.9267623662796014 precision 0.926286930018296 specificity 0.7994468377277013 recall 0.9267623662796014 f1 0.9239688470344538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 9.86102557182312 s\n",
      "Accuracy 0.9273109627868703 precision 0.9269997339946751 specificity 0.8022661128098199 recall 0.9273109627868703 f1 0.924545372630497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 9.698293924331665 s\n",
      "Accuracy 0.9281338575477737 precision 0.9278689690066478 specificity 0.8119735187075604 recall 0.9281338575477737 f1 0.9256065198525026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 9.949519157409668 s\n",
      "Accuracy 0.9242022492456798 precision 0.9239213731613842 specificity 0.7961047753140225 recall 0.9242022492456798 f1 0.9212026945238184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 10.261290311813354 s\n",
      "Accuracy 0.9265795007771784 precision 0.9264537813274728 specificity 0.8026236111346242 recall 0.9265795007771784 f1 0.9237496211394792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 9.696022272109985 s\n",
      "Accuracy 0.9277681265429277 precision 0.927559166834046 specificity 0.8067669564969434 recall 0.9277681265429277 f1 0.9250901799575496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 9.598018407821655 s\n",
      "Accuracy 0.9297796470695803 precision 0.9292645189451767 specificity 0.8148165669888713 recall 0.9297796470695803 f1 0.9274344456917397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 9.961095571517944 s\n",
      "Accuracy 0.9233793544847765 precision 0.9229140173006511 specificity 0.7975828959678954 recall 0.9233793544847765 f1 0.9204609459916491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 9.698006868362427 s\n",
      "Accuracy 0.9281338575477737 precision 0.9280831578140872 specificity 0.8070069285402439 recall 0.9281338575477737 f1 0.9254216050549038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 9.592255353927612 s\n",
      "Accuracy 0.9279509920453507 precision 0.927841196219386 specificity 0.8137391396381709 recall 0.9279509920453507 f1 0.92541495463444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 9.690982580184937 s\n",
      "Accuracy 0.9251165767577947 precision 0.9249093291599895 specificity 0.8010946810936813 recall 0.9251165767577947 f1 0.9222422232734034\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 9.58899974822998 s\n",
      "Accuracy 0.9247508457529487 precision 0.9241299779576718 specificity 0.7949808690027588 recall 0.9247508457529487 f1 0.9218486092225125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 9.534524917602539 s\n",
      "Accuracy 0.9207278046996434 precision 0.9203044301311397 specificity 0.8009220327857891 recall 0.9207278046996434 f1 0.9178322489524257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 9.887407541275024 s\n",
      "Accuracy 0.9299625125720032 precision 0.9299200104116132 specificity 0.803790623667086 recall 0.9299625125720032 f1 0.9272105450603167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 9.66401720046997 s\n",
      "Accuracy 0.9242936819968913 precision 0.9240895125273326 specificity 0.7961848490232948 recall 0.9242936819968913 f1 0.9212743146032171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 9.822454690933228 s\n",
      "Accuracy 0.9220078632166042 precision 0.9213327064894105 specificity 0.7918532602158985 recall 0.9220078632166042 f1 0.9189796983421531\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 9.593549251556396 s\n",
      "Accuracy 0.9217335649629698 precision 0.9218014161837513 specificity 0.7910170445994844 recall 0.9217335649629698 f1 0.9184386649383945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 9.669957637786865 s\n",
      "Accuracy 0.9252994422602177 precision 0.9248930101947225 specificity 0.8048429466301391 recall 0.9252994422602177 f1 0.9225880835684832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 9.809524774551392 s\n",
      "Accuracy 0.9244765474993143 precision 0.9244154581699182 specificity 0.7996960009116101 recall 0.9244765474993143 f1 0.9215087926886569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 9.707045793533325 s\n",
      "Accuracy 0.9199963426899516 precision 0.919872772341656 specificity 0.79170006923527 recall 0.9199963426899516 f1 0.9167374638197904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 9.775009155273438 s\n",
      "Accuracy 0.9246594130017373 precision 0.9247338803235813 specificity 0.7930404788462257 recall 0.9246594130017373 f1 0.9214848792680091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 9.74038314819336 s\n",
      "Accuracy 0.9316997348450214 precision 0.9312476326940281 specificity 0.8095602841973523 recall 0.9316997348450214 f1 0.929248398913038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 9.556271076202393 s\n",
      "Accuracy 0.9250251440065832 precision 0.9247389584955538 specificity 0.794414158958145 recall 0.9250251440065832 f1 0.9220022771258305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 9.840006113052368 s\n",
      "Accuracy 0.928773886806254 precision 0.9279265475271083 specificity 0.8082235194487396 recall 0.928773886806254 f1 0.9263798195386026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 9.82653284072876 s\n",
      "Accuracy 0.9260309042699095 precision 0.9255768408529629 specificity 0.8009836736160506 recall 0.9260309042699095 f1 0.923252800234122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 9.743050813674927 s\n",
      "Accuracy 0.9258480387674866 precision 0.92550503172874 specificity 0.7967425602233483 recall 0.9258480387674866 f1 0.9229218548017434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 9.644892930984497 s\n",
      "Accuracy 0.9235622199871995 precision 0.9232764441245164 specificity 0.7968048396222123 recall 0.9235622199871995 f1 0.9205684553693819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 9.779017448425293 s\n",
      "Accuracy 0.9278595592941392 precision 0.9275548630735397 specificity 0.8050555378161985 recall 0.9278595592941392 f1 0.9251719481024847\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 9.635519742965698 s\n",
      "Accuracy 0.9268537990308129 precision 0.9266391892669265 specificity 0.8035684411530497 recall 0.9268537990308129 f1 0.9240802436755827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 9.66482925415039 s\n",
      "Accuracy 0.9228307579775076 precision 0.9225954874661504 specificity 0.7945540828303078 recall 0.9228307579775076 f1 0.9197457033456476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 9.686999797821045 s\n",
      "Accuracy 0.9252994422602177 precision 0.9244341808791516 specificity 0.7989410198783362 recall 0.9252994422602177 f1 0.9226053174251058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 9.712512016296387 s\n",
      "Accuracy 0.928591021303831 precision 0.9285455509480011 specificity 0.8081324379883473 recall 0.928591021303831 f1 0.9259136419563039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 10.041592597961426 s\n",
      "Accuracy 0.9289567523086769 precision 0.9288721745439413 specificity 0.8051945420434503 recall 0.9289567523086769 f1 0.9262281794016458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 10.141339540481567 s\n",
      "Accuracy 0.9286824540550425 precision 0.9282443535861116 specificity 0.8106426129764335 recall 0.9286824540550425 f1 0.9261905330375179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 10.141232252120972 s\n",
      "Accuracy 0.9279509920453507 precision 0.9274125016505156 specificity 0.8049887830464504 recall 0.9279509920453507 f1 0.9253422164471656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 10.245057821273804 s\n",
      "Accuracy 0.9245679802505258 precision 0.9246412234063458 specificity 0.7953977085612273 recall 0.9245679802505258 f1 0.9214526065063087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 9.638052701950073 s\n",
      "Accuracy 0.9242022492456798 precision 0.9242892433189083 specificity 0.7913311811426383 recall 0.9242022492456798 f1 0.920968733368152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 9.857006549835205 s\n",
      "Accuracy 0.9267623662796014 precision 0.9263275132929739 specificity 0.80381371051624 recall 0.9267623662796014 f1 0.9240641056056593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 10.116283178329468 s\n",
      "Accuracy 0.9242936819968913 precision 0.9239326924171515 specificity 0.7953560491885547 recall 0.9242936819968913 f1 0.9213023501995634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 9.82000470161438 s\n",
      "Accuracy 0.9298710798207918 precision 0.9293330721385844 specificity 0.8106166290804763 recall 0.9298710798207918 f1 0.9274367203157038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 9.973047256469727 s\n",
      "Accuracy 0.925939471518698 precision 0.9257532321991709 specificity 0.8020008555532878 recall 0.925939471518698 f1 0.9230988573731358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 9.989999532699585 s\n",
      "Accuracy 0.9218249977141812 precision 0.921237677376319 specificity 0.7971765011006975 recall 0.9218249977141812 f1 0.9189057446715726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 9.773561477661133 s\n",
      "Accuracy 0.9273109627868703 precision 0.9266971365280512 specificity 0.8162354622187197 recall 0.9273109627868703 f1 0.9249933395697153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 10.454942226409912 s\n",
      "Accuracy 0.9280424247965622 precision 0.9276281779083584 specificity 0.809088633359151 recall 0.9280424247965622 f1 0.9254925351745958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 10.594658136367798 s\n",
      "Accuracy 0.925939471518698 precision 0.9255420291824558 specificity 0.8020558968834288 recall 0.925939471518698 f1 0.9231675361488951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 10.80985975265503 s\n",
      "Accuracy 0.9255737405138521 precision 0.9255500462895114 specificity 0.799967694038666 recall 0.9255737405138521 f1 0.9226255038287129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 10.079217433929443 s\n",
      "Accuracy 0.9271280972844473 precision 0.9268086854974871 specificity 0.8023230103017785 recall 0.9271280972844473 f1 0.9243625919195921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 9.962841033935547 s\n",
      "Accuracy 0.9293224833135229 precision 0.9289900255640922 specificity 0.8089786404740594 recall 0.9293224833135229 f1 0.9267683106466055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 10.895930051803589 s\n",
      "Accuracy 0.9280424247965622 precision 0.9279382725779715 specificity 0.8052781039129 recall 0.9280424247965622 f1 0.925302188556988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 10.821028232574463 s\n",
      "Accuracy 0.9270366645332359 precision 0.9264678752899999 specificity 0.799735526922204 recall 0.9270366645332359 f1 0.9242888620710425\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 10.33259129524231 s\n",
      "Accuracy 0.9251165767577947 precision 0.9247557739622431 specificity 0.7989705162599717 recall 0.9251165767577947 f1 0.9222366801083934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 9.780061721801758 s\n",
      "Accuracy 0.928773886806254 precision 0.9289776467035495 specificity 0.8102835637758402 recall 0.928773886806254 f1 0.9260818747615125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 9.697567224502563 s\n",
      "Accuracy 0.9278595592941392 precision 0.9274835054778746 specificity 0.8028236380735161 recall 0.9278595592941392 f1 0.9251405701643078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 9.62905216217041 s\n",
      "Accuracy 0.9295053488159458 precision 0.9293402555418534 specificity 0.8065230215833404 recall 0.9295053488159458 f1 0.9268442376708005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 9.743639707565308 s\n",
      "Accuracy 0.9254823077626406 precision 0.9253065108292818 specificity 0.7950576808432549 recall 0.9254823077626406 f1 0.9224524202897647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 9.749040603637695 s\n",
      "Accuracy 0.9299625125720032 precision 0.9297526191527025 specificity 0.8077593614005674 recall 0.9299625125720032 f1 0.9273539735102818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 9.670517683029175 s\n",
      "Accuracy 0.9304196763280607 precision 0.9301243135829818 specificity 0.8081469372552126 recall 0.9304196763280607 f1 0.9278566984734549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 9.855000019073486 s\n",
      "Accuracy 0.9252080095090062 precision 0.92494984047526 specificity 0.8004056047883426 recall 0.9252080095090062 f1 0.9223338918855203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 9.795481443405151 s\n",
      "Accuracy 0.926488068025967 precision 0.9263409641675806 specificity 0.8011642239770103 recall 0.926488068025967 f1 0.9236263025795115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 10.000997304916382 s\n",
      "Accuracy 0.9183505531681448 precision 0.9182189026989072 specificity 0.7839190313469276 recall 0.9183505531681448 f1 0.914837409487545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 10.099105834960938 s\n",
      "Accuracy 0.9286824540550425 precision 0.9287721711369031 specificity 0.8054999806982095 recall 0.9286824540550425 f1 0.9259053614765002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 9.699592590332031 s\n",
      "Accuracy 0.9245679802505258 precision 0.9245503077903056 specificity 0.7911377942285962 recall 0.9245679802505258 f1 0.9213682910790602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 9.859055042266846 s\n",
      "Accuracy 0.9253908750114291 precision 0.9248073771760597 specificity 0.7969849638039531 recall 0.9253908750114291 f1 0.9225416791091928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 9.794018745422363 s\n",
      "Accuracy 0.925939471518698 precision 0.9254916200848197 specificity 0.8056059626213137 recall 0.925939471518698 f1 0.9232738772923019\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 9.685525894165039 s\n",
      "Accuracy 0.9246594130017373 precision 0.9241437263853004 specificity 0.8028791181838131 recall 0.9246594130017373 f1 0.9219225427178636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 9.685039043426514 s\n",
      "Accuracy 0.9268537990308129 precision 0.9268238792046449 specificity 0.804520476033725 recall 0.9268537990308129 f1 0.9240483900978036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 9.816205501556396 s\n",
      "Accuracy 0.925939471518698 precision 0.9250099837147108 specificity 0.8041864044929794 recall 0.925939471518698 f1 0.9234215179814224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 9.882051467895508 s\n",
      "Accuracy 0.9228307579775076 precision 0.9228196825268475 specificity 0.7994459701129157 recall 0.9228307579775076 f1 0.9198076210949814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 9.675997734069824 s\n",
      "Accuracy 0.9280424247965622 precision 0.9281308957697271 specificity 0.8021461166340454 recall 0.9280424247965622 f1 0.925170647809837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 9.80471158027649 s\n",
      "Accuracy 0.9305111090792721 precision 0.9299493003851474 specificity 0.8085379960997456 recall 0.9305111090792721 f1 0.9280494211176569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 9.856401443481445 s\n",
      "Accuracy 0.9270366645332359 precision 0.9275053361779089 specificity 0.8003447301603508 recall 0.9270366645332359 f1 0.9239972763862915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 9.831000089645386 s\n",
      "Accuracy 0.9242022492456798 precision 0.9240028510277617 specificity 0.7959846993798398 recall 0.9242022492456798 f1 0.9211741733397584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 9.791048049926758 s\n",
      "Accuracy 0.9257566060162751 precision 0.9255749554985553 specificity 0.8000665213757936 recall 0.9257566060162751 f1 0.9228619162380941\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 9.557368278503418 s\n",
      "Accuracy 0.9274023955380818 precision 0.9274850985216503 specificity 0.7970736916360462 recall 0.9274023955380818 f1 0.9243930606923709\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 9.550583362579346 s\n",
      "Accuracy 0.9244765474993143 precision 0.9238989884406684 specificity 0.7946862100964796 recall 0.9244765474993143 f1 0.921545006009795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 9.58900785446167 s\n",
      "Accuracy 0.9278595592941392 precision 0.9277461301807265 specificity 0.7983797868828241 recall 0.9278595592941392 f1 0.924949787740839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 9.686105012893677 s\n",
      "Accuracy 0.9255737405138521 precision 0.9254587938861154 specificity 0.801042737636263 recall 0.9255737405138521 f1 0.9226796280545195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 9.647574424743652 s\n",
      "Accuracy 0.9244765474993143 precision 0.9241629655019775 specificity 0.7983392419326365 recall 0.9244765474993143 f1 0.9215513397814481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 9.765533685684204 s\n",
      "Accuracy 0.9257566060162751 precision 0.9258817528469131 specificity 0.7936655836691209 recall 0.9257566060162751 f1 0.9226103349304147\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 9.560025691986084 s\n",
      "Accuracy 0.9283167230501966 precision 0.9281521786657271 specificity 0.8035939844256865 recall 0.9283167230501966 f1 0.9255596921997906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 9.821987867355347 s\n",
      "Accuracy 0.9274938282892933 precision 0.9275788690961433 specificity 0.7991535505367616 recall 0.9274938282892933 f1 0.9245372984915917\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 9.865025281906128 s\n",
      "Accuracy 0.9241108164944684 precision 0.923338723601081 specificity 0.8019528787682056 recall 0.9241108164944684 f1 0.9214335751793932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 9.680577278137207 s\n",
      "Accuracy 0.9249337112553717 precision 0.9248160452957962 specificity 0.8056813791596191 recall 0.9249337112553717 f1 0.9221450703481016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 9.83650255203247 s\n",
      "Accuracy 0.9284995885526196 precision 0.9280146463573977 specificity 0.8087315078898195 recall 0.9284995885526196 f1 0.9259742337715066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 9.73103642463684 s\n",
      "Accuracy 0.9318826003474444 precision 0.9315260082835619 specificity 0.8154059516947412 recall 0.9318826003474444 f1 0.9295360321012854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 9.812288999557495 s\n",
      "Accuracy 0.9223735942214502 precision 0.921908721620616 specificity 0.7933955664517286 recall 0.9223735942214502 f1 0.9193217867554067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 9.905065774917603 s\n",
      "Accuracy 0.9243851147481028 precision 0.924541962902709 specificity 0.7911132654070073 recall 0.9243851147481028 f1 0.9211308684942263\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 9.72564148902893 s\n",
      "Accuracy 0.9270366645332359 precision 0.9267629354679039 specificity 0.8078705710108423 recall 0.9270366645332359 f1 0.9243915087347291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 9.595231771469116 s\n",
      "Accuracy 0.9263966352747555 precision 0.9261602913769611 specificity 0.7977864730329328 recall 0.9263966352747555 f1 0.9234756060344379\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 9.871078252792358 s\n",
      "Accuracy 0.9247508457529487 precision 0.9240889155621695 specificity 0.8020507168110272 recall 0.9247508457529487 f1 0.9220470157867\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 9.992462873458862 s\n",
      "Accuracy 0.923470787235988 precision 0.9228541652657635 specificity 0.7990974837562836 recall 0.923470787235988 f1 0.920647093040519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 9.523530721664429 s\n",
      "Accuracy 0.9249337112553717 precision 0.9248897298709687 specificity 0.7959089200284203 recall 0.9249337112553717 f1 0.9218736042409741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 9.672000169754028 s\n",
      "Accuracy 0.9250251440065832 precision 0.924605560300405 specificity 0.7945923831087458 recall 0.9250251440065832 f1 0.9220499607360397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 9.727525234222412 s\n",
      "Accuracy 0.9255737405138521 precision 0.924951306104605 specificity 0.8060026419635252 recall 0.9255737405138521 f1 0.9229728768514318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 14.741069555282593 s\n",
      "Accuracy 0.9222821614702387 precision 0.9224027483302358 specificity 0.7918819990484145 recall 0.9222821614702387 f1 0.9190082891797682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 16.69857358932495 s\n",
      "Accuracy 0.9240193837432569 precision 0.9233761496928108 specificity 0.7944725223875555 recall 0.9240193837432569 f1 0.9210952232995461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 16.928550958633423 s\n",
      "Accuracy 0.9230136234799305 precision 0.9226640685450493 specificity 0.795233126803433 recall 0.9230136234799305 f1 0.9199869043505512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 17.246065616607666 s\n",
      "Accuracy 0.9241108164944684 precision 0.9233835974510168 specificity 0.7954999167371323 recall 0.9241108164944684 f1 0.9212466610720008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 15.391999959945679 s\n",
      "Accuracy 0.9325226296059248 precision 0.9320025483528128 specificity 0.8167127941533366 recall 0.9325226296059248 f1 0.9302742861238195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 16.531553745269775 s\n",
      "Accuracy 0.9242936819968913 precision 0.9246507955219909 specificity 0.800034525350781 recall 0.9242936819968913 f1 0.9212147521224607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 16.51955485343933 s\n",
      "Accuracy 0.9257566060162751 precision 0.9255756696126772 specificity 0.8052477445139535 recall 0.9257566060162751 f1 0.9229922363545103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 17.403064966201782 s\n",
      "Accuracy 0.9248422785041602 precision 0.9247478843793724 specificity 0.7958538724445969 recall 0.9248422785041602 f1 0.9217935301335761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 15.900562524795532 s\n",
      "Accuracy 0.9274023955380818 precision 0.9273264140120873 specificity 0.8062820443129024 recall 0.9274023955380818 f1 0.9246650292860719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 15.442550420761108 s\n",
      "Accuracy 0.9252994422602177 precision 0.9250325235579776 specificity 0.7952551420938202 recall 0.9252994422602177 f1 0.9222984946037683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 16.294999599456787 s\n",
      "Accuracy 0.9325226296059248 precision 0.9318203055492955 specificity 0.8148693661674717 recall 0.9325226296059248 f1 0.9303015743512819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 16.164600133895874 s\n",
      "Accuracy 0.931242571088964 precision 0.9310780133796626 specificity 0.8094288701496186 recall 0.931242571088964 f1 0.9286860291266655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 16.028120040893555 s\n",
      "Accuracy 0.9243851147481028 precision 0.9242869415724698 specificity 0.7975498468935328 recall 0.9243851147481028 f1 0.9213710111085586\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 15.553555965423584 s\n",
      "Accuracy 0.9260309042699095 precision 0.9262193182910189 specificity 0.795138635036206 recall 0.9260309042699095 f1 0.9229111886620343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 16.779067277908325 s\n",
      "Accuracy 0.9269452317820244 precision 0.926257218245774 specificity 0.8113070676631722 recall 0.9269452317820244 f1 0.9245280239147401\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 16.425066471099854 s\n",
      "Accuracy 0.926122337021121 precision 0.9255223563384205 specificity 0.8014927350693458 recall 0.926122337021121 f1 0.9234099595112972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 16.169071674346924 s\n",
      "Accuracy 0.9245679802505258 precision 0.9244873351482394 specificity 0.8005439321017307 recall 0.9245679802505258 f1 0.9216297378346403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 16.912020921707153 s\n",
      "Accuracy 0.9221907287190272 precision 0.9216391341506711 specificity 0.7934831549992389 recall 0.9221907287190272 f1 0.919166894329234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 15.866105318069458 s\n",
      "Accuracy 0.9263966352747555 precision 0.9267201294154109 specificity 0.8036434999715778 recall 0.9263966352747555 f1 0.9234625343783048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 15.970083713531494 s\n",
      "Accuracy 0.9274938282892933 precision 0.9273309512574867 specificity 0.8102999503877154 recall 0.9274938282892933 f1 0.9248822983318552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 16.411102056503296 s\n",
      "Accuracy 0.9257566060162751 precision 0.9261515941172149 specificity 0.7975483256889353 recall 0.9257566060162751 f1 0.9226366103805426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 16.162086009979248 s\n",
      "Accuracy 0.9215506994605468 precision 0.9210624845449078 specificity 0.7970511466837579 recall 0.9215506994605468 f1 0.9185879295574692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 17.577574968338013 s\n",
      "Accuracy 0.9222821614702387 precision 0.9224416686521022 specificity 0.7922200130867897 recall 0.9222821614702387 f1 0.9190064776368597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 17.323509693145752 s\n",
      "Accuracy 0.9270366645332359 precision 0.9270138345701091 specificity 0.8084359290404297 recall 0.9270366645332359 f1 0.9243292293083157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 16.09100103378296 s\n",
      "Accuracy 0.9242022492456798 precision 0.9237414639855533 specificity 0.7891153116982986 recall 0.9242022492456798 f1 0.9210782944748042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 16.340017318725586 s\n",
      "Accuracy 0.9262137697723325 precision 0.9261834811142127 specificity 0.801391613391709 recall 0.9262137697723325 f1 0.9233171369949598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 16.55109453201294 s\n",
      "Accuracy 0.9286824540550425 precision 0.9284403295584545 specificity 0.8118573877178733 recall 0.9286824540550425 f1 0.9261553951546897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 16.47753643989563 s\n",
      "Accuracy 0.9271280972844473 precision 0.926829429958224 specificity 0.8058402090318106 recall 0.9271280972844473 f1 0.9244427449783656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 15.860557794570923 s\n",
      "Accuracy 0.9277681265429277 precision 0.9281718996677526 specificity 0.8027792151807851 recall 0.9277681265429277 f1 0.9248215738368866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 15.87799859046936 s\n",
      "Accuracy 0.9215506994605468 precision 0.9211136411189603 specificity 0.7862809406330703 recall 0.9215506994605468 f1 0.9182773747598922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 16.372028350830078 s\n",
      "Accuracy 0.9252080095090062 precision 0.9246724422767253 specificity 0.8041937821126407 recall 0.9252080095090062 f1 0.9225226624222441\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 16.524072885513306 s\n",
      "Accuracy 0.9284081558014081 precision 0.9283880492366156 specificity 0.8014682187316138 recall 0.9284081558014081 f1 0.9255589700131338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 16.078047037124634 s\n",
      "Accuracy 0.9295053488159458 precision 0.9290913482492347 specificity 0.8093910755351218 recall 0.9295053488159458 f1 0.9269916256239326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 16.273120164871216 s\n",
      "Accuracy 0.925939471518698 precision 0.9256285524653268 specificity 0.7960869210116358 recall 0.925939471518698 f1 0.9229884767300288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 17.559526443481445 s\n",
      "Accuracy 0.9295053488159458 precision 0.9296768789110321 specificity 0.8035086723633035 recall 0.9295053488159458 f1 0.9266763780354986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 17.0116069316864 s\n",
      "Accuracy 0.9245679802505258 precision 0.9243579517931393 specificity 0.8010085855267306 recall 0.9245679802505258 f1 0.921680882965982\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 14.23800253868103 s\n",
      "Accuracy 0.9201792081923745 precision 0.9199755976537187 specificity 0.7852750691055717 recall 0.9201792081923745 f1 0.9167702927049469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 9.981897592544556 s\n",
      "Accuracy 0.9258480387674866 precision 0.9251004393184875 specificity 0.7968369521085351 recall 0.9258480387674866 f1 0.9230655403567575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 9.561565160751343 s\n",
      "Accuracy 0.9248422785041602 precision 0.9246542756317836 specificity 0.7994509283052982 recall 0.9248422785041602 f1 0.9219141757412936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 9.692846298217773 s\n",
      "Accuracy 0.9265795007771784 precision 0.9260234923940226 specificity 0.8065446074658034 recall 0.9265795007771784 f1 0.9239876702618853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 9.620548009872437 s\n",
      "Accuracy 0.9295967815671573 precision 0.9294949229667592 specificity 0.8088204903882832 recall 0.9295967815671573 f1 0.9269728973593426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 9.905519485473633 s\n",
      "Accuracy 0.9199963426899516 precision 0.9201446591235151 specificity 0.7860645579562632 recall 0.9199963426899516 f1 0.9165016435494167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 9.884868621826172 s\n",
      "Accuracy 0.9242936819968913 precision 0.9238676893052729 specificity 0.8020283431717519 recall 0.9242936819968913 f1 0.921496884984561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 9.887008666992188 s\n",
      "Accuracy 0.9306939745816951 precision 0.9304825930721399 specificity 0.8070883135622384 recall 0.9306939745816951 f1 0.9280858830046561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 10.12169075012207 s\n",
      "Accuracy 0.9309682728353296 precision 0.9309005640715883 specificity 0.8117884235817264 recall 0.9309682728353296 f1 0.9284314105737631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 10.736062288284302 s\n",
      "Accuracy 0.9297796470695803 precision 0.929256648126652 specificity 0.8074689517302126 recall 0.9297796470695803 f1 0.9272635283445297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 10.683062314987183 s\n",
      "Accuracy 0.9296882143183688 precision 0.929524235519791 specificity 0.8060904339267312 recall 0.9296882143183688 f1 0.9270204554227431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 10.961521863937378 s\n",
      "Accuracy 0.9278595592941392 precision 0.9282074631371252 specificity 0.8004582282905499 recall 0.9278595592941392 f1 0.9248726851860692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 10.79290509223938 s\n",
      "Accuracy 0.9256651732650636 precision 0.925421475657686 specificity 0.8031428041872984 recall 0.9256651732650636 f1 0.9228654455392828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 10.982096672058105 s\n",
      "Accuracy 0.9247508457529487 precision 0.9244386331274014 specificity 0.7919580862178018 recall 0.9247508457529487 f1 0.9216662320802376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 11.003054141998291 s\n",
      "Accuracy 0.9245679802505258 precision 0.924260394546531 specificity 0.7952379118171132 recall 0.9245679802505258 f1 0.9215626310545968\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 10.760000228881836 s\n",
      "Accuracy 0.9252080095090062 precision 0.9247320882130508 specificity 0.800057184450536 recall 0.9252080095090062 f1 0.9223962451238675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 10.646917819976807 s\n",
      "Accuracy 0.9230136234799305 precision 0.9226817814021823 specificity 0.7960256288224712 recall 0.9230136234799305 f1 0.9200021832031808\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 10.66845703125 s\n",
      "Accuracy 0.9236536527384109 precision 0.9233521673445797 specificity 0.7952466466170713 recall 0.9236536527384109 f1 0.9206259962197403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 10.663710117340088 s\n",
      "Accuracy 0.9252994422602177 precision 0.9256159926713143 specificity 0.7989713258055281 recall 0.9252994422602177 f1 0.9222257537766719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 10.771035432815552 s\n",
      "Accuracy 0.9274023955380818 precision 0.927812254677007 specificity 0.8026342161173018 recall 0.9274023955380818 f1 0.9244426494020888\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 10.674136638641357 s\n",
      "Accuracy 0.9228307579775076 precision 0.9235269665345887 specificity 0.7940029965827476 recall 0.9228307579775076 f1 0.9194756923721406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 10.986523389816284 s\n",
      "Accuracy 0.926488068025967 precision 0.9269495252670045 specificity 0.8016955980290621 recall 0.926488068025967 f1 0.9234718634366941\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 10.69158673286438 s\n",
      "Accuracy 0.9219164304653927 precision 0.9211295306815557 specificity 0.7972858551314052 recall 0.9219164304653927 f1 0.919075993389708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 10.550909042358398 s\n",
      "Accuracy 0.9277681265429277 precision 0.9272557439631723 specificity 0.8101012214306704 recall 0.9277681265429277 f1 0.9252714557997741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 10.591565132141113 s\n",
      "Accuracy 0.9270366645332359 precision 0.9264175241408221 specificity 0.8031185469715411 recall 0.9270366645332359 f1 0.9243914151384013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 10.448490619659424 s\n",
      "Accuracy 0.9335283898692511 precision 0.9334401545665229 specificity 0.8232950343582147 recall 0.9335283898692511 f1 0.9313032618186341\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 10.925188779830933 s\n",
      "Accuracy 0.9212764012069123 precision 0.9211511349916573 specificity 0.7802835425411894 recall 0.9212764012069123 f1 0.9177331877714034\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 10.777644395828247 s\n",
      "Accuracy 0.9302368108256377 precision 0.93014860717763 specificity 0.8070996076145641 recall 0.9302368108256377 f1 0.9275819628339113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 10.695566177368164 s\n",
      "Accuracy 0.9256651732650636 precision 0.925499122435887 specificity 0.8016849640825869 recall 0.9256651732650636 f1 0.9228046588127398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 10.739526510238647 s\n",
      "Accuracy 0.9279509920453507 precision 0.9278921330888711 specificity 0.804336809495793 recall 0.9279509920453507 f1 0.9251725982518068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 10.651018381118774 s\n",
      "Accuracy 0.926122337021121 precision 0.9255242688936295 specificity 0.80604730957933 recall 0.926122337021121 f1 0.9235242861333575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 10.667998313903809 s\n",
      "Accuracy 0.9221907287190272 precision 0.9218912267070624 specificity 0.790105536771119 recall 0.9221907287190272 f1 0.918992201961497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 10.817007064819336 s\n",
      "Accuracy 0.9252080095090062 precision 0.9250350366114846 specificity 0.803109315039937 recall 0.9252080095090062 f1 0.9223762419695137\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 10.629584789276123 s\n",
      "Accuracy 0.9291396178110999 precision 0.9293306946797528 specificity 0.8086241822214425 recall 0.9291396178110999 f1 0.926418930311353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 10.824035882949829 s\n",
      "Accuracy 0.9274023955380818 precision 0.926775538782121 specificity 0.8097066062572009 recall 0.9274023955380818 f1 0.9249307054789511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 10.78846025466919 s\n",
      "Accuracy 0.9267623662796014 precision 0.9263782471952787 specificity 0.8097742850408046 recall 0.9267623662796014 f1 0.9241948431747865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 10.51406192779541 s\n",
      "Accuracy 0.9277681265429277 precision 0.9272933622942946 specificity 0.8049680141998867 recall 0.9277681265429277 f1 0.925132837726071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 10.674555778503418 s\n",
      "Accuracy 0.9260309042699095 precision 0.9263895709821236 specificity 0.792504673934569 recall 0.9260309042699095 f1 0.9227989750523476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 10.801095008850098 s\n",
      "Accuracy 0.9253908750114291 precision 0.9252269317451169 specificity 0.7965381024241563 recall 0.9253908750114291 f1 0.9223930558030495\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 10.666985034942627 s\n",
      "Accuracy 0.9292310505623114 precision 0.9296601269961179 specificity 0.7975485561425874 recall 0.9292310505623114 f1 0.9261856778268364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 10.568016052246094 s\n",
      "Accuracy 0.9276766937917162 precision 0.9277265304481842 specificity 0.8055623795825035 recall 0.9276766937917162 f1 0.9248910604133167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 10.510998725891113 s\n",
      "Accuracy 0.926122337021121 precision 0.9256990099983736 specificity 0.7991778683956305 recall 0.926122337021121 f1 0.9232903009261301\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 10.82151746749878 s\n",
      "Accuracy 0.9272195300356588 precision 0.9272411631089783 specificity 0.8032995492396224 recall 0.9272195300356588 f1 0.9243768619336453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 10.630959749221802 s\n",
      "Accuracy 0.9254823077626406 precision 0.9244621187908456 specificity 0.8012453945409624 recall 0.9254823077626406 f1 0.9229182999124674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 10.54056715965271 s\n",
      "Accuracy 0.9235622199871995 precision 0.9238588505531414 specificity 0.7888317749292396 recall 0.9235622199871995 f1 0.9201896515818326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 10.713354349136353 s\n",
      "Accuracy 0.9256651732650636 precision 0.9253391368678957 specificity 0.799272182441902 recall 0.9256651732650636 f1 0.9227936449088079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 10.645037412643433 s\n",
      "Accuracy 0.9253908750114291 precision 0.9256918311809471 specificity 0.8002041403677115 recall 0.9253908750114291 f1 0.9223546693430443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 10.73427152633667 s\n",
      "Accuracy 0.9289567523086769 precision 0.9286105220036803 specificity 0.8053836356923643 recall 0.9289567523086769 f1 0.9263136667635324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 10.655041217803955 s\n",
      "Accuracy 0.9289567523086769 precision 0.9287303868375806 specificity 0.8088134786358422 recall 0.9289567523086769 f1 0.9263575199629684\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 10.65804648399353 s\n",
      "Accuracy 0.9270366645332359 precision 0.9271336639304214 specificity 0.8017971833262099 recall 0.9270366645332359 f1 0.9241317119930517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 10.582367420196533 s\n",
      "Accuracy 0.9249337112553717 precision 0.9251433626795375 specificity 0.7964340787338785 recall 0.9249337112553717 f1 0.9218155588941995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 10.731173515319824 s\n",
      "Accuracy 0.9277681265429277 precision 0.9273463804329086 specificity 0.802686890159344 recall 0.9277681265429277 f1 0.9250589414719678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 10.689903259277344 s\n",
      "Accuracy 0.9284995885526196 precision 0.928046740740784 specificity 0.8103131094299759 recall 0.9284995885526196 f1 0.9260012779940243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 10.749654769897461 s\n",
      "Accuracy 0.9255737405138521 precision 0.9255138572989728 specificity 0.8023109361438959 recall 0.9255737405138521 f1 0.9226953401484888\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 10.704512357711792 s\n",
      "Accuracy 0.9283167230501966 precision 0.9280090866389129 specificity 0.8094620942227038 recall 0.9283167230501966 f1 0.9257460782413538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 10.683025598526001 s\n",
      "Accuracy 0.9257566060162751 precision 0.9258875873372873 specificity 0.8026630464361292 recall 0.9257566060162751 f1 0.9228363957931389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 10.666008710861206 s\n",
      "Accuracy 0.9302368108256377 precision 0.9300919517281113 specificity 0.8123986791482447 recall 0.9302368108256377 f1 0.927722420091116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 10.567016363143921 s\n",
      "Accuracy 0.9270366645332359 precision 0.9270004930581341 specificity 0.807791203511064 recall 0.9270366645332359 f1 0.9243172946166763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 10.468010187149048 s\n",
      "Accuracy 0.9276766937917162 precision 0.9272343959496405 specificity 0.8049593252453309 recall 0.9276766937917162 f1 0.9250282195921177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 10.640048265457153 s\n",
      "Accuracy 0.9269452317820244 precision 0.9274301406820763 specificity 0.8022451128413516 recall 0.9269452317820244 f1 0.9239468341509376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 10.644078493118286 s\n",
      "Accuracy 0.926305202523544 precision 0.925678737220934 specificity 0.7986820481890731 recall 0.926305202523544 f1 0.9235351736973237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 10.579538106918335 s\n",
      "Accuracy 0.9268537990308129 precision 0.9266907698547554 specificity 0.8086059504358684 recall 0.9268537990308129 f1 0.9241887379064642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 10.657007694244385 s\n",
      "Accuracy 0.9284081558014081 precision 0.9285795891229223 specificity 0.8022570300524597 recall 0.9284081558014081 f1 0.9255244105780522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 10.577007293701172 s\n",
      "Accuracy 0.9279509920453507 precision 0.9277896554773548 specificity 0.8124844285294586 recall 0.9279509920453507 f1 0.9254003457924466\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 10.637015104293823 s\n",
      "Accuracy 0.9239279509920454 precision 0.9230904844490171 specificity 0.8003514621894314 recall 0.9239279509920454 f1 0.9212307366853353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 10.434857845306396 s\n",
      "Accuracy 0.9295967815671573 precision 0.9294951580669509 specificity 0.8003564477210916 recall 0.9295967815671573 f1 0.9267722700212455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 10.537067174911499 s\n",
      "Accuracy 0.9209106702020664 precision 0.9205078907863737 specificity 0.7899252357618288 recall 0.9209106702020664 f1 0.9177110000912602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 10.562950611114502 s\n",
      "Accuracy 0.9237450854896224 precision 0.9236441649140774 specificity 0.795741080687118 recall 0.9237450854896224 f1 0.9206706355663554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 10.604532718658447 s\n",
      "Accuracy 0.9250251440065832 precision 0.9247707993418278 specificity 0.797199951517428 recall 0.9250251440065832 f1 0.9220638717664758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 10.721627712249756 s\n",
      "Accuracy 0.9282252902989852 precision 0.9277054280330248 specificity 0.811603305323516 recall 0.9282252902989852 f1 0.9257763541448589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 10.642549276351929 s\n",
      "Accuracy 0.923105056231142 precision 0.9224481107327038 specificity 0.8023083774453145 recall 0.923105056231142 f1 0.92037372220684\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 10.560245513916016 s\n",
      "Accuracy 0.9271280972844473 precision 0.9267700126163109 specificity 0.8029734195502883 recall 0.9271280972844473 f1 0.9243912012195242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 10.516510486602783 s\n",
      "Accuracy 0.926305202523544 precision 0.9255696666488177 specificity 0.8013612829239961 recall 0.926305202523544 f1 0.9236437512457452\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 10.834143161773682 s\n",
      "Accuracy 0.9245679802505258 precision 0.9245692479616143 specificity 0.8043262542914659 recall 0.9245679802505258 f1 0.9217026584097627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 10.725096940994263 s\n",
      "Accuracy 0.9265795007771784 precision 0.9263520226692017 specificity 0.8042628284496656 recall 0.9265795007771784 f1 0.9238214795546742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 10.945070266723633 s\n",
      "Accuracy 0.9223735942214502 precision 0.9225564227208694 specificity 0.7908749131730802 recall 0.9223735942214499 f1 0.9190574998597446\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 11.226013660430908 s\n",
      "Accuracy 0.9216421322117583 precision 0.9213125746738532 specificity 0.7950291053072754 recall 0.9216421322117583 f1 0.9185739210918524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 10.787535190582275 s\n",
      "Accuracy 0.9252994422602177 precision 0.9252386372466466 specificity 0.7996144655474096 recall 0.9252994422602177 f1 0.922347144556578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 10.913893222808838 s\n",
      "Accuracy 0.9286824540550425 precision 0.9286243300777783 specificity 0.8119860190028922 recall 0.9286824540550425 f1 0.9261026143272051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 10.781364440917969 s\n",
      "Accuracy 0.9284995885526196 precision 0.9277158299884742 specificity 0.8083289672259174 recall 0.9284995885526196 f1 0.926076334516431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 10.875969409942627 s\n",
      "Accuracy 0.9222821614702387 precision 0.9219381497274668 specificity 0.7910546319331846 recall 0.9222821614702387 f1 0.9191255569642685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 10.579615831375122 s\n",
      "Accuracy 0.9270366645332359 precision 0.9269098571920745 specificity 0.7993294884872018 recall 0.9270366645332359 f1 0.9241353121032113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 10.780049324035645 s\n",
      "Accuracy 0.9220992959678157 precision 0.9219235654351036 specificity 0.7926144544777726 recall 0.9220992959678157 f1 0.918927708018651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 10.64707636833191 s\n",
      "Accuracy 0.926305202523544 precision 0.9260476744127876 specificity 0.800290842674196 recall 0.926305202523544 f1 0.9234515982516796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 10.7737877368927 s\n",
      "Accuracy 0.9292310505623114 precision 0.9287948463480684 specificity 0.810707293684037 recall 0.9292310505623114 f1 0.9267506643269784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 10.74754023551941 s\n",
      "Accuracy 0.9255737405138521 precision 0.9256129289284594 specificity 0.8029430761211296 recall 0.9255737405138521 f1 0.9226825980150247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 10.646008014678955 s\n",
      "Accuracy 0.920636371948432 precision 0.9202106180472176 specificity 0.7936870795790499 recall 0.920636371948432 f1 0.9175417646501028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 10.813002824783325 s\n",
      "Accuracy 0.9274023955380818 precision 0.927246492847553 specificity 0.7996592655488104 recall 0.9274023955380818 f1 0.9245262561391695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 10.966135740280151 s\n",
      "Accuracy 0.9274938282892933 precision 0.9274291938637892 specificity 0.8032030142960819 recall 0.9274938282892933 f1 0.9246796539949459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 10.767081260681152 s\n",
      "Accuracy 0.926305202523544 precision 0.9258051769575305 specificity 0.7987643939331946 recall 0.926305202523544 f1 0.9234927193043784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 11.6642165184021 s\n",
      "Accuracy 0.9189905824266252 precision 0.9182883653574938 specificity 0.7855828493641619 recall 0.9189905824266252 f1 0.9157282664078367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 10.885599851608276 s\n",
      "Accuracy 0.9247508457529487 precision 0.9240471693761946 specificity 0.8054067088115056 recall 0.9247508457529487 f1 0.9221495231600036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 10.895999670028687 s\n",
      "Accuracy 0.9275852610405048 precision 0.9271591575899986 specificity 0.8016783334705397 recall 0.9275852610405048 f1 0.9248487459782131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 10.612856388092041 s\n",
      "Accuracy 0.9250251440065832 precision 0.924905439826961 specificity 0.7941711893276899 recall 0.9250251440065832 f1 0.9219448891821238\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 10.717731714248657 s\n",
      "Accuracy 0.9211849684557009 precision 0.9213182087598124 specificity 0.7870227507021283 recall 0.9211849684557009 f1 0.9177497777596487\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 10.767013788223267 s\n",
      "Accuracy 0.9291396178110999 precision 0.9290551427444674 specificity 0.8018570235569904 recall 0.9291396178110999 f1 0.9263352274575688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 10.515889883041382 s\n",
      "Accuracy 0.9284081558014081 precision 0.9284491362812946 specificity 0.8073844011084091 recall 0.9284081558014081 f1 0.9256842550583\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 10.569067239761353 s\n",
      "Accuracy 0.9274023955380818 precision 0.9271938179042856 specificity 0.8050960950771168 recall 0.9274023955380818 f1 0.9246760351748083\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 10.703036785125732 s\n",
      "Accuracy 0.9275852610405048 precision 0.927610005361512 specificity 0.8093962380696315 recall 0.9275852610405048 f1 0.9248981824714112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 10.715152978897095 s\n",
      "Accuracy 0.9210021029532779 precision 0.9208496321934704 specificity 0.7924829890491646 recall 0.9210021029532779 f1 0.9177954826214849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 10.822545766830444 s\n",
      "Accuracy 0.9250251440065832 precision 0.9250451750521932 specificity 0.7993574784562607 recall 0.9250251440065832 f1 0.9220368612291604\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 10.672899007797241 s\n",
      "Accuracy 0.928591021303831 precision 0.9279887922772663 specificity 0.8101415324281286 recall 0.928591021303831 f1 0.9261435180851934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 11.005201578140259 s\n",
      "Accuracy 0.923105056231142 precision 0.922623169763652 specificity 0.7956971294178325 recall 0.923105056231142 f1 0.9201365125719836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 10.743566274642944 s\n",
      "Accuracy 0.9272195300356588 precision 0.9268493902505889 specificity 0.8040352368839346 recall 0.9272195300356588 f1 0.9245147389122257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 10.703262329101562 s\n",
      "Accuracy 0.9279509920453507 precision 0.9275440474108629 specificity 0.8078603845702119 recall 0.9279509920453507 f1 0.9253670207551311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 10.690215349197388 s\n",
      "Accuracy 0.9250251440065832 precision 0.9247237099666606 specificity 0.7937016581588333 recall 0.9250251440065832 f1 0.9219887429732714\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 10.616641759872437 s\n",
      "Accuracy 0.9203620736947975 precision 0.9198390016054674 specificity 0.7860498601280401 recall 0.9203620736947975 f1 0.9170824239119956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 10.589061498641968 s\n",
      "Accuracy 0.9248422785041602 precision 0.9247712579355338 specificity 0.8009676650996503 recall 0.9248422785041602 f1 0.9219177778571481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 10.690997838973999 s\n",
      "Accuracy 0.9231964889823535 precision 0.9230219664084565 specificity 0.79248777822985 recall 0.9231964889823535 f1 0.9200461826772676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 10.626801252365112 s\n",
      "Accuracy 0.9209106702020664 precision 0.9206783125580692 specificity 0.7923842111752323 recall 0.9209106702020664 f1 0.9177239493970099\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 10.689041376113892 s\n",
      "Accuracy 0.9296882143183688 precision 0.9296904668395648 specificity 0.8047163875499609 recall 0.9296882143183688 f1 0.9269390700903716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 10.67117190361023 s\n",
      "Accuracy 0.9274938282892933 precision 0.927238345393153 specificity 0.7979315621561158 recall 0.9274938282892933 f1 0.9246077355341059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 10.603999614715576 s\n",
      "Accuracy 0.9262137697723325 precision 0.9263069703262152 specificity 0.7929670333304345 recall 0.9262137697723325 f1 0.9230699074017749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 10.53856372833252 s\n",
      "Accuracy 0.9306025418304836 precision 0.9300781648019054 specificity 0.8108412463124772 recall 0.9306025418304836 f1 0.9281832733228935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 10.589020252227783 s\n",
      "Accuracy 0.9229221907287191 precision 0.9223897761571989 specificity 0.7926812339033039 recall 0.9229221907287191 f1 0.9198865629757177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 10.357073068618774 s\n",
      "Accuracy 0.9238365182408339 precision 0.9241028307942842 specificity 0.7992475608845032 recall 0.9238365182408339 f1 0.9207515595764719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 10.73810338973999 s\n",
      "Accuracy 0.9252994422602177 precision 0.9250608630213016 specificity 0.8029875546346296 recall 0.9252994422602177 f1 0.922486736221705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 10.63245940208435 s\n",
      "Accuracy 0.9247508457529487 precision 0.9245349165385964 specificity 0.8028155993002302 recall 0.9247508457529487 f1 0.9219156269011061\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 10.540009498596191 s\n",
      "Accuracy 0.9265795007771784 precision 0.9269457530815078 specificity 0.8037010768831966 recall 0.9265795007771784 f1 0.9236395624934165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 10.8430495262146 s\n",
      "Accuracy 0.9242022492456798 precision 0.9238798451548432 specificity 0.7941992608010935 recall 0.9242022492456798 f1 0.9211662662539063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 10.733987808227539 s\n",
      "Accuracy 0.9281338575477737 precision 0.9280172215841492 specificity 0.8091054853025175 recall 0.9281338575477737 f1 0.9254917481866042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 10.428945302963257 s\n",
      "Accuracy 0.9306939745816951 precision 0.930088172841063 specificity 0.8093617572838695 recall 0.9306939745816951 f1 0.9282714730862548\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 11.120100736618042 s\n",
      "Accuracy 0.925939471518698 precision 0.9255230168523964 specificity 0.8035618221396446 recall 0.925939471518698 f1 0.9232118282427588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 10.61600112915039 s\n",
      "Accuracy 0.9240193837432569 precision 0.9237168194178669 specificity 0.7930112530676434 recall 0.9240193837432569 f1 0.9209418024696139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 10.709007024765015 s\n",
      "Accuracy 0.9240193837432569 precision 0.923949548249736 specificity 0.7944295425852878 recall 0.9240193837432569 f1 0.9209076443319949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 10.599005937576294 s\n",
      "Accuracy 0.9273109627868703 precision 0.9272688385867486 specificity 0.8047873435867018 recall 0.9273109627868703 f1 0.9245251745746639\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 10.650017261505127 s\n",
      "Accuracy 0.9251165767577947 precision 0.9244481434597298 specificity 0.8063399347318922 recall 0.9251165767577947 f1 0.9225327883092458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 11.003530025482178 s\n",
      "Accuracy 0.9278595592941392 precision 0.9274777135086614 specificity 0.7999916376148659 recall 0.9278595592941392 f1 0.9250730416346499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 10.659818410873413 s\n",
      "Accuracy 0.9286824540550425 precision 0.9283885799832846 specificity 0.8067604992454447 recall 0.9286824540550425 f1 0.9260497723920248\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 11.36622428894043 s\n",
      "Accuracy 0.9266709335283899 precision 0.9264540838713348 specificity 0.8039100258433696 recall 0.9266709335283899 f1 0.9239027324290763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 10.947520732879639 s\n",
      "Accuracy 0.923105056231142 precision 0.9227596711955417 specificity 0.7882720531076982 recall 0.923105056231142 f1 0.9198939202649344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 11.008046627044678 s\n",
      "Accuracy 0.9239279509920454 precision 0.923735659892316 specificity 0.7963513098463327 recall 0.9239279509920454 f1 0.920901145243912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 10.691963911056519 s\n",
      "Accuracy 0.9266709335283899 precision 0.9262323829466141 specificity 0.8067965477973668 recall 0.9266709335283899 f1 0.9240462465923023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 10.882532119750977 s\n",
      "Accuracy 0.9256651732650636 precision 0.9258563140137807 specificity 0.8022255965246342 recall 0.9256651732650636 f1 0.9227154880713058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 10.731791734695435 s\n",
      "Accuracy 0.926122337021121 precision 0.9258322780387594 specificity 0.8091088717279095 recall 0.926122337021121 f1 0.9234957287319275\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 10.661408185958862 s\n",
      "Accuracy 0.9249337112553717 precision 0.9247024237671162 specificity 0.7952475169122447 recall 0.9249337112553717 f1 0.921913004978901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 10.852511644363403 s\n",
      "Accuracy 0.9284081558014081 precision 0.9278273255363022 specificity 0.8059494463499498 recall 0.9284081558014081 f1 0.9258474795837836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 10.69165849685669 s\n",
      "Accuracy 0.9240193837432569 precision 0.9236648484127785 specificity 0.7944469154895266 recall 0.9240193837432569 f1 0.9209960257247154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 10.514856338500977 s\n",
      "Accuracy 0.9283167230501966 precision 0.9284981822623779 specificity 0.8052864747404938 recall 0.9283167230501966 f1 0.9255014606025773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 10.616008043289185 s\n",
      "Accuracy 0.9280424247965622 precision 0.9278581167523327 specificity 0.8040074629019057 recall 0.9280424247965622 f1 0.9252955151418868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 10.77577018737793 s\n",
      "Accuracy 0.9321568986010789 precision 0.9315658190854309 specificity 0.8182544692189934 recall 0.9321568986010789 f1 0.9299627074086178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 10.751842021942139 s\n",
      "Accuracy 0.9249337112553717 precision 0.9251052340422042 specificity 0.7989972821844379 recall 0.9249337112553717 f1 0.9218916846939967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 10.694923877716064 s\n",
      "Accuracy 0.9290481850598884 precision 0.9288697843317811 specificity 0.8022817099825063 recall 0.9290481850598884 f1 0.9262799873291278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 10.760497570037842 s\n",
      "Accuracy 0.9272195300356588 precision 0.9270627692708744 specificity 0.8067618207998349 recall 0.9272195300356588 f1 0.9245144125494484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 10.55258584022522 s\n",
      "Accuracy 0.9296882143183688 precision 0.9291861576720801 specificity 0.8116754284349217 recall 0.9296882143183688 f1 0.9272625224964486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 10.69100046157837 s\n",
      "Accuracy 0.9266709335283899 precision 0.926415092810331 specificity 0.8033210793108683 recall 0.9266709335283899 f1 0.9239002759954296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 10.96282172203064 s\n",
      "Accuracy 0.9260309042699095 precision 0.9259836053134259 specificity 0.7969065734409225 recall 0.9260309042699095 f1 0.9230223906588411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 10.89655065536499 s\n",
      "Accuracy 0.9283167230501966 precision 0.9282966116049154 specificity 0.8052796097600522 recall 0.9283167230501966 f1 0.9255576824957846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 10.853789329528809 s\n",
      "Accuracy 0.9252080095090062 precision 0.9253521876941945 specificity 0.7962042525514313 recall 0.9252080095090062 f1 0.9221082329138369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 10.911706686019897 s\n",
      "Accuracy 0.9244765474993143 precision 0.9240356396521204 specificity 0.7997734172658538 recall 0.9244765474993143 f1 0.9216301935280624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 11.06009578704834 s\n",
      "Accuracy 0.9220078632166042 precision 0.9218552767005279 specificity 0.7932199114458779 recall 0.9220078632166042 f1 0.9188434647076321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 11.01328992843628 s\n",
      "Accuracy 0.9251165767577947 precision 0.9247621013760313 specificity 0.7992647679076674 recall 0.9251165767577947 f1 0.9222421541816574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 10.602907419204712 s\n",
      "Accuracy 0.9253908750114291 precision 0.9247863993034536 specificity 0.8017324990427946 recall 0.9253908750114291 f1 0.9226709071999759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 10.757800340652466 s\n",
      "Accuracy 0.9242936819968913 precision 0.9244933035500442 specificity 0.7896443751240668 recall 0.9242936819968913 f1 0.9209870777488501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 10.820772409439087 s\n",
      "Accuracy 0.9296882143183688 precision 0.929159931321291 specificity 0.8056150382365288 recall 0.9296882143183688 f1 0.9271279238871138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 10.779189825057983 s\n",
      "Accuracy 0.9274938282892933 precision 0.9271702697301911 specificity 0.8074968828841578 recall 0.9274938282892933 f1 0.9248644571447201\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, seed in enumerate(seeds):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.923105     0.793991   0.922774  0.923105  0.920041\n1  0.928225     0.810969   0.927762  0.928225  0.925741\n2  0.924477     0.802508   0.924019  0.924477  0.921706\n3  0.927768     0.797362   0.927341  0.927768  0.924930\n4  0.930328     0.807668   0.930734  0.930328  0.927554\n5  0.919813     0.790722   0.919686  0.919813  0.916525\n6  0.927585     0.801956   0.927486  0.927585  0.924753\n7  0.924477     0.801289   0.924282  0.924477  0.921590\n8  0.922831     0.804986   0.922119  0.922831  0.920186\n9  0.922191     0.794930   0.922087  0.922191  0.919062",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.923105</td>\n      <td>0.793991</td>\n      <td>0.922774</td>\n      <td>0.923105</td>\n      <td>0.920041</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.928225</td>\n      <td>0.810969</td>\n      <td>0.927762</td>\n      <td>0.928225</td>\n      <td>0.925741</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.924477</td>\n      <td>0.802508</td>\n      <td>0.924019</td>\n      <td>0.924477</td>\n      <td>0.921706</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.927768</td>\n      <td>0.797362</td>\n      <td>0.927341</td>\n      <td>0.927768</td>\n      <td>0.924930</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.930328</td>\n      <td>0.807668</td>\n      <td>0.930734</td>\n      <td>0.930328</td>\n      <td>0.927554</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.919813</td>\n      <td>0.790722</td>\n      <td>0.919686</td>\n      <td>0.919813</td>\n      <td>0.916525</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.927585</td>\n      <td>0.801956</td>\n      <td>0.927486</td>\n      <td>0.927585</td>\n      <td>0.924753</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.924477</td>\n      <td>0.801289</td>\n      <td>0.924282</td>\n      <td>0.924477</td>\n      <td>0.921590</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.922831</td>\n      <td>0.804986</td>\n      <td>0.922119</td>\n      <td>0.922831</td>\n      <td>0.920186</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.922191</td>\n      <td>0.794930</td>\n      <td>0.922087</td>\n      <td>0.922191</td>\n      <td>0.919062</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.9259773246776996\n",
      "Precision 0.9257564145657217\n",
      "Specificity 0.8008768300116696\n",
      "Recall 0.9259773246776996\n",
      "F1 0.9231208314768237\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_10beats_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}