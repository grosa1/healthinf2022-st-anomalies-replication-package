{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 10 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1  \\\n0  e0106  39.341333  39.831764  39.826684  11.282887  1.634628  0.913825   \n1  e0106  43.320409  45.006516  44.365681  12.474802  1.826689  0.901002   \n2  e0106  41.841597  41.778007  41.593833  11.837152  1.721631  0.911361   \n3  e0106  43.146961  41.264063  41.075821  11.843259  1.752020  0.906516   \n4  e0106  41.647822  43.131905  43.437246  12.388259  1.809692  0.915806   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.771782 -1.359522 -0.634856  ... -0.049375  0.037769 -0.045755  0.051531   \n1 -0.707731 -1.281504 -0.731562  ... -0.033106  0.009999 -0.014494  0.028882   \n2 -0.728350 -1.293684 -0.729167  ... -0.049280  0.038759 -0.048515  0.056363   \n3 -0.728333 -1.275260 -0.678176  ... -0.065776  0.050750 -0.050526  0.048861   \n4 -0.758906 -1.398698 -0.864005  ... -0.049441  0.035196 -0.047893  0.061977   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.078515  0.013704 -0.024545 -0.017430  0.001676    NSR  \n1 -0.048873 -0.010926 -0.026088  0.009880 -0.021702    NSR  \n2 -0.076889 -0.002209 -0.011804 -0.015943 -0.006355    NSR  \n3 -0.084336  0.026353 -0.035720 -0.018588  0.013943    NSR  \n4 -0.082722  0.004341 -0.018094 -0.013906 -0.001004    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>39.341333</td>\n      <td>39.831764</td>\n      <td>39.826684</td>\n      <td>11.282887</td>\n      <td>1.634628</td>\n      <td>0.913825</td>\n      <td>-0.771782</td>\n      <td>-1.359522</td>\n      <td>-0.634856</td>\n      <td>...</td>\n      <td>-0.049375</td>\n      <td>0.037769</td>\n      <td>-0.045755</td>\n      <td>0.051531</td>\n      <td>-0.078515</td>\n      <td>0.013704</td>\n      <td>-0.024545</td>\n      <td>-0.017430</td>\n      <td>0.001676</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>43.320409</td>\n      <td>45.006516</td>\n      <td>44.365681</td>\n      <td>12.474802</td>\n      <td>1.826689</td>\n      <td>0.901002</td>\n      <td>-0.707731</td>\n      <td>-1.281504</td>\n      <td>-0.731562</td>\n      <td>...</td>\n      <td>-0.033106</td>\n      <td>0.009999</td>\n      <td>-0.014494</td>\n      <td>0.028882</td>\n      <td>-0.048873</td>\n      <td>-0.010926</td>\n      <td>-0.026088</td>\n      <td>0.009880</td>\n      <td>-0.021702</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>41.841597</td>\n      <td>41.778007</td>\n      <td>41.593833</td>\n      <td>11.837152</td>\n      <td>1.721631</td>\n      <td>0.911361</td>\n      <td>-0.728350</td>\n      <td>-1.293684</td>\n      <td>-0.729167</td>\n      <td>...</td>\n      <td>-0.049280</td>\n      <td>0.038759</td>\n      <td>-0.048515</td>\n      <td>0.056363</td>\n      <td>-0.076889</td>\n      <td>-0.002209</td>\n      <td>-0.011804</td>\n      <td>-0.015943</td>\n      <td>-0.006355</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>43.146961</td>\n      <td>41.264063</td>\n      <td>41.075821</td>\n      <td>11.843259</td>\n      <td>1.752020</td>\n      <td>0.906516</td>\n      <td>-0.728333</td>\n      <td>-1.275260</td>\n      <td>-0.678176</td>\n      <td>...</td>\n      <td>-0.065776</td>\n      <td>0.050750</td>\n      <td>-0.050526</td>\n      <td>0.048861</td>\n      <td>-0.084336</td>\n      <td>0.026353</td>\n      <td>-0.035720</td>\n      <td>-0.018588</td>\n      <td>0.013943</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>41.647822</td>\n      <td>43.131905</td>\n      <td>43.437246</td>\n      <td>12.388259</td>\n      <td>1.809692</td>\n      <td>0.915806</td>\n      <td>-0.758906</td>\n      <td>-1.398698</td>\n      <td>-0.864005</td>\n      <td>...</td>\n      <td>-0.049441</td>\n      <td>0.035196</td>\n      <td>-0.047893</td>\n      <td>0.061977</td>\n      <td>-0.082722</td>\n      <td>0.004341</td>\n      <td>-0.018094</td>\n      <td>-0.013906</td>\n      <td>-0.001004</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_10beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    41933\nST     12752\nName: label, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.231317  0.109459  0.074913  0.064543  0.101660 -0.029506   \ndw_2    0.231317  1.000000  0.839064  0.449006  0.157026  0.490259 -0.520594   \ndw_3    0.109459  0.839064  1.000000  0.626999  0.236381  0.373744 -0.580056   \ndw_4    0.074913  0.449006  0.626999  1.000000  0.896524  0.070236 -0.268424   \ndw_5    0.064543  0.157026  0.236381  0.896524  1.000000 -0.079160 -0.026334   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.046809  0.030436  0.054751  0.044048  0.016599 -0.081643  0.054039   \ncfr_13 -0.035437  0.119758  0.045877  0.026303  0.014533  0.076890 -0.003660   \ncfr_14 -0.049050  0.004610 -0.023444 -0.031429 -0.033413  0.021208  0.025601   \ncfr_15 -0.071846 -0.117053 -0.131465 -0.089388 -0.041393 -0.006682  0.103513   \ncfr_16 -0.053104 -0.076826 -0.047859 -0.036217 -0.021446  0.052559 -0.032448   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.023452 -0.001861  0.003290  ... -0.062028 -0.061241 -0.032516   \ndw_2   -0.307376 -0.002765  0.011760  ... -0.133566  0.150743  0.235204   \ndw_3   -0.413234 -0.000351  0.005808  ... -0.207216  0.129536  0.268782   \ndw_4   -0.208628  0.000763  0.001641  ... -0.143689  0.054827  0.109764   \ndw_5   -0.035523  0.000409 -0.000153  ... -0.061473  0.009140  0.005657   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.087235 -0.001785  0.005388  ... -0.130493 -0.207093 -0.090454   \ncfr_13  0.006739  0.002726 -0.000638  ...  0.133437  0.032750 -0.215151   \ncfr_14  0.029224  0.003070 -0.002968  ...  0.098660  0.217327  0.047811   \ncfr_15  0.057917  0.004848 -0.008763  ...  0.266212  0.164693 -0.079613   \ncfr_16 -0.005212  0.008240 -0.005231  ...  0.248016  0.141547  0.178786   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.026775 -0.017739 -0.046809 -0.035437 -0.049050 -0.071846 -0.053104  \ndw_2    0.167194  0.046752  0.030436  0.119758  0.004610 -0.117053 -0.076826  \ndw_3    0.117633 -0.049634  0.054751  0.045877 -0.023444 -0.131465 -0.047859  \ndw_4    0.050373 -0.044638  0.044048  0.026303 -0.031429 -0.089388 -0.036217  \ndw_5    0.023553 -0.012439  0.016599  0.014533 -0.033413 -0.041393 -0.021446  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.024675  0.059365  1.000000  0.008142 -0.011310 -0.326522 -0.216222  \ncfr_13 -0.269635 -0.033375  0.008142  1.000000  0.199386  0.109416 -0.168514  \ncfr_14 -0.175074 -0.289421 -0.011310  0.199386  1.000000  0.171805 -0.139323  \ncfr_15 -0.147027 -0.089111 -0.326522  0.109416  0.171805  1.000000  0.253573  \ncfr_16  0.127395 -0.003147 -0.216222 -0.168514 -0.139323  0.253573  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.231317</td>\n      <td>0.109459</td>\n      <td>0.074913</td>\n      <td>0.064543</td>\n      <td>0.101660</td>\n      <td>-0.029506</td>\n      <td>0.023452</td>\n      <td>-0.001861</td>\n      <td>0.003290</td>\n      <td>...</td>\n      <td>-0.062028</td>\n      <td>-0.061241</td>\n      <td>-0.032516</td>\n      <td>-0.026775</td>\n      <td>-0.017739</td>\n      <td>-0.046809</td>\n      <td>-0.035437</td>\n      <td>-0.049050</td>\n      <td>-0.071846</td>\n      <td>-0.053104</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.231317</td>\n      <td>1.000000</td>\n      <td>0.839064</td>\n      <td>0.449006</td>\n      <td>0.157026</td>\n      <td>0.490259</td>\n      <td>-0.520594</td>\n      <td>-0.307376</td>\n      <td>-0.002765</td>\n      <td>0.011760</td>\n      <td>...</td>\n      <td>-0.133566</td>\n      <td>0.150743</td>\n      <td>0.235204</td>\n      <td>0.167194</td>\n      <td>0.046752</td>\n      <td>0.030436</td>\n      <td>0.119758</td>\n      <td>0.004610</td>\n      <td>-0.117053</td>\n      <td>-0.076826</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.109459</td>\n      <td>0.839064</td>\n      <td>1.000000</td>\n      <td>0.626999</td>\n      <td>0.236381</td>\n      <td>0.373744</td>\n      <td>-0.580056</td>\n      <td>-0.413234</td>\n      <td>-0.000351</td>\n      <td>0.005808</td>\n      <td>...</td>\n      <td>-0.207216</td>\n      <td>0.129536</td>\n      <td>0.268782</td>\n      <td>0.117633</td>\n      <td>-0.049634</td>\n      <td>0.054751</td>\n      <td>0.045877</td>\n      <td>-0.023444</td>\n      <td>-0.131465</td>\n      <td>-0.047859</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.074913</td>\n      <td>0.449006</td>\n      <td>0.626999</td>\n      <td>1.000000</td>\n      <td>0.896524</td>\n      <td>0.070236</td>\n      <td>-0.268424</td>\n      <td>-0.208628</td>\n      <td>0.000763</td>\n      <td>0.001641</td>\n      <td>...</td>\n      <td>-0.143689</td>\n      <td>0.054827</td>\n      <td>0.109764</td>\n      <td>0.050373</td>\n      <td>-0.044638</td>\n      <td>0.044048</td>\n      <td>0.026303</td>\n      <td>-0.031429</td>\n      <td>-0.089388</td>\n      <td>-0.036217</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.064543</td>\n      <td>0.157026</td>\n      <td>0.236381</td>\n      <td>0.896524</td>\n      <td>1.000000</td>\n      <td>-0.079160</td>\n      <td>-0.026334</td>\n      <td>-0.035523</td>\n      <td>0.000409</td>\n      <td>-0.000153</td>\n      <td>...</td>\n      <td>-0.061473</td>\n      <td>0.009140</td>\n      <td>0.005657</td>\n      <td>0.023553</td>\n      <td>-0.012439</td>\n      <td>0.016599</td>\n      <td>0.014533</td>\n      <td>-0.033413</td>\n      <td>-0.041393</td>\n      <td>-0.021446</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.046809</td>\n      <td>0.030436</td>\n      <td>0.054751</td>\n      <td>0.044048</td>\n      <td>0.016599</td>\n      <td>-0.081643</td>\n      <td>0.054039</td>\n      <td>0.087235</td>\n      <td>-0.001785</td>\n      <td>0.005388</td>\n      <td>...</td>\n      <td>-0.130493</td>\n      <td>-0.207093</td>\n      <td>-0.090454</td>\n      <td>0.024675</td>\n      <td>0.059365</td>\n      <td>1.000000</td>\n      <td>0.008142</td>\n      <td>-0.011310</td>\n      <td>-0.326522</td>\n      <td>-0.216222</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.035437</td>\n      <td>0.119758</td>\n      <td>0.045877</td>\n      <td>0.026303</td>\n      <td>0.014533</td>\n      <td>0.076890</td>\n      <td>-0.003660</td>\n      <td>0.006739</td>\n      <td>0.002726</td>\n      <td>-0.000638</td>\n      <td>...</td>\n      <td>0.133437</td>\n      <td>0.032750</td>\n      <td>-0.215151</td>\n      <td>-0.269635</td>\n      <td>-0.033375</td>\n      <td>0.008142</td>\n      <td>1.000000</td>\n      <td>0.199386</td>\n      <td>0.109416</td>\n      <td>-0.168514</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.049050</td>\n      <td>0.004610</td>\n      <td>-0.023444</td>\n      <td>-0.031429</td>\n      <td>-0.033413</td>\n      <td>0.021208</td>\n      <td>0.025601</td>\n      <td>0.029224</td>\n      <td>0.003070</td>\n      <td>-0.002968</td>\n      <td>...</td>\n      <td>0.098660</td>\n      <td>0.217327</td>\n      <td>0.047811</td>\n      <td>-0.175074</td>\n      <td>-0.289421</td>\n      <td>-0.011310</td>\n      <td>0.199386</td>\n      <td>1.000000</td>\n      <td>0.171805</td>\n      <td>-0.139323</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.071846</td>\n      <td>-0.117053</td>\n      <td>-0.131465</td>\n      <td>-0.089388</td>\n      <td>-0.041393</td>\n      <td>-0.006682</td>\n      <td>0.103513</td>\n      <td>0.057917</td>\n      <td>0.004848</td>\n      <td>-0.008763</td>\n      <td>...</td>\n      <td>0.266212</td>\n      <td>0.164693</td>\n      <td>-0.079613</td>\n      <td>-0.147027</td>\n      <td>-0.089111</td>\n      <td>-0.326522</td>\n      <td>0.109416</td>\n      <td>0.171805</td>\n      <td>1.000000</td>\n      <td>0.253573</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.053104</td>\n      <td>-0.076826</td>\n      <td>-0.047859</td>\n      <td>-0.036217</td>\n      <td>-0.021446</td>\n      <td>0.052559</td>\n      <td>-0.032448</td>\n      <td>-0.005212</td>\n      <td>0.008240</td>\n      <td>-0.005231</td>\n      <td>...</td>\n      <td>0.248016</td>\n      <td>0.141547</td>\n      <td>0.178786</td>\n      <td>0.127395</td>\n      <td>-0.003147</td>\n      <td>-0.216222</td>\n      <td>-0.168514</td>\n      <td>-0.139323</td>\n      <td>0.253573</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 310 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_133', 'fft_157', 'fft_165', 'fft_166', 'fft_227', 'mfw_6', 'fft_248', 'fft_189', 'fft_202', 'fft_132', 'fft_167', 'fft_250', 'fft_149', 'mfw_5', 'mfw_9', 'fft_226', 'fft_148', 'fft_233', 'fft_153', 'fft_208', 'fft_244', 'fft_187', 'fft_245', 'fft_138', 'fft_256', 'fft_140', 'fft_229', 'fft_172', 'fft_217', 'fft_131', 'fft_225', 'fft_155', 'fft_161', 'fft_200', 'fft_152', 'mfw_7', 'fft_249', 'fft_207', 'fft_219', 'fft_162', 'fft_183', 'fft_177', 'fft_144', 'fft_181', 'fft_146', 'fft_193', 'fft_243', 'mfw_15', 'fft_197', 'fft_246', 'mfw_10', 'fft_134', 'fft_178', 'fft_199', 'fft_236', 'fft_215', 'fft_218', 'fft_238', 'fft_237', 'fft_184', 'fft_143', 'fft_234', 'fft_159', 'fft_209', 'fft_170', 'fft_206', 'fft_239', 'fft_210', 'mfw_14', 'fft_253', 'fft_247', 'fft_205', 'fft_158', 'fft_211', 'fft_173', 'fft_195', 'fft_232', 'fft_203', 'fft_213', 'fft_255', 'fft_241', 'fft_154', 'fft_223', 'fft_147', 'fft_180', 'fft_174', 'cfr_16', 'fft_188', 'fft_130', 'fft_179', 'fft_222', 'fft_176', 'fft_216', 'fft_164', 'fft_137', 'fft_192', 'mfw_8', 'fft_151', 'fft_196', 'fft_252', 'fft_190', 'fft_135', 'fft_175', 'fft_156', 'mfw_12', 'fft_163', 'fft_171', 'fft_136', 'mfw_13', 'fft_169', 'fft_185', 'fft_228', 'fft_240', 'fft_198', 'fft_251', 'fft_204', 'fft_201', 'fft_214', 'fft_230', 'fft_141', 'fft_235', 'fft_168', 'fft_142', 'fft_254', 'fft_221', 'fft_212', 'fft_224', 'fft_194', 'fft_191', 'fft_242', 'mfw_16', 'mfw_11', 'fft_160', 'fft_182', 'fft_220', 'fft_145', 'fft_139', 'fft_150', 'fft_231', 'fft_186'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_24\n",
      "fft_25\n",
      "fft_27\n",
      "fft_28\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "fft_37\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 75\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYM0lEQVR4nO3debxfdX3n8dfbhFW2eUBmtGwXBdtHwJUIti6tUhwcK6EVRtBa9EHFtmJ1HDtGbREZZ0a66Gilo7QwUlxAcZlU0wdVUMClmLAoBkwNSIegVrZBorIEPvPHObE/bs5NDvfec383yev5eNxHzvI953zu7/fL733P9j2pKiRJmuwx4y5AkjQ/GRCSpE4GhCSpkwEhSepkQEiSOi0cdwGzZZ999qmJiYlxlyFJW5Wrr776jqpa1DVvmwmIiYkJVq1aNe4yJGmrkuSfp5rnISZJUicDQpLUyYCQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSp23mTuqZmlj2+bFt+5Z3v3hs25akqbgHIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSeo0aEAkOSbJmiRrkyzrmL9Tkova+VclmWinTyT5WZLr2p8PDlmnJGlTg3W1kWQBcDZwNLAOWJlkeVXdMNLsFODuqjo4yYnAWcDL2nk3VdXThqpPkrR5Q+5BHAGsraqbq+oB4EJg6aQ2S4Hz2+GLgaOSZMCaJEk9DRkQ+wK3joyva6d1tqmqDcA9wN7tvIOSXJvk8iTP7dpAklOTrEqy6vbbb5/d6iVpOzdfT1L/ADigqp4OvAn4WJI9JjeqqnOqaklVLVm0aNGcFylJ27IhA+I2YP+R8f3aaZ1tkiwE9gTurKr7q+pOgKq6GrgJeNKAtUqSJhkyIFYChyQ5KMmOwInA8kltlgMnt8PHA5dVVSVZ1J7kJskTgEOAmwesVZI0yWBXMVXVhiSnAZcAC4Dzqmp1kjOBVVW1HDgXuCDJWuAumhABeB5wZpIHgYeB36uqu4aqVZK0qUGfKFdVK4AVk6adPjJ8H3BCx3KfAj41ZG2SpM2bryepJUljZkBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6DRoQSY5JsibJ2iTLOubvlOSidv5VSSYmzT8gyfokbx6yTknSpgYLiCQLgLOBFwGLgZOSLJ7U7BTg7qo6GHgvcNak+e8B/n6oGiVJUxtyD+IIYG1V3VxVDwAXAksntVkKnN8OXwwclSQASY4DvgesHrBGSdIUhgyIfYFbR8bXtdM621TVBuAeYO8kuwFvAd65uQ0kOTXJqiSrbr/99lkrXJI0f09SnwG8t6rWb65RVZ1TVUuqasmiRYvmpjJJ2k4sHHDdtwH7j4zv107rarMuyUJgT+BO4Ejg+CR/CuwFPJzkvqr6wID1SpJGDBkQK4FDkhxEEwQnAi+f1GY5cDLwdeB44LKqKuC5GxskOQNYbzhI0twaLCCqakOS04BLgAXAeVW1OsmZwKqqWg6cC1yQZC1wF02ISJLmgSH3IKiqFcCKSdNOHxm+DzhhC+s4Y5DiJEmbNV9PUkuSxmzKPYgk9wK1cbT9t9rhqqo9Bq5NkjRGUwZEVe0+l4VIkuaXXoeYkjwnyavb4X3aK5MkSduwLQZEknfQ3NX81nbSjsBHhixKkjR+ffYgfhM4FvgJQFV9H/DwkyRt4/oExAPtzWsFkOSxw5YkSZoP+gTEJ5J8CNgryWuALwJ/PWxZkqRx2+KNclX150mOBn4M/CJwelV9YfDKJEljtcWASPIm4CJDQZK2L30OMe0O/EOSK5OcluTfDV2UJGn8thgQVfXOqjoUeB3weODyJF8cvDJJ0lg9mr6YfgT8kOZ5Df92mHIkSfNFnxvl/iDJl4FLgb2B11TVU4YuTJI0Xn26+94feGNVXTdwLZKkeaTPOYi3AruN9MW0yL6YJGnbN52+mHbAvpgkaZtnX0ySpE72xSRJ6mRfTJKkTvbFJEnq1OcyV9pAMBQkaTsyZUAkuZf2vMPkWUBV1R6DVSVJGrspA6KqvFJJkrZjj6YvJknSdsSAkCR1MiAkSZ16BUSSA5P8eju8SxLPT0jSNq5PX0yvAS4GPtRO2g/47IA1SZLmgT73QbwOOAK4CqCqvpvEBwbNoYllnx/btm9594vHtm1J49XnENP9VfXAxpEkC+m+P2ITSY5JsibJ2iTLOubvlOSidv5VSSba6Uckua79+WaS3+z5+0iSZkmfgLg8yduAXdouNz4J/N2WFkqyADgbeBGwGDgpyeJJzU4B7q6qg4H3Ame1078NLKmqpwHHAB9qg0mSNEf6BMQy4HbgeuC1wArgj3ssdwSwtqpubvdALgSWTmqzFDi/Hb4YOCpJquqnVbWhnb4zPfdYJEmzp89f5bsA51XVX8PP9wx2AX66heX2BW4dGV8HHDlVm6rakOQemude35HkSOA84EDglSOB8XNJTgVOBTjggAN6/CqSpL767EFcShMIG+1C0+X3oKrqqqo6FHgm8NYkO3e0OaeqllTVkkWLFg1dkiRtV/oExM5VtX7jSDu8a4/lbgP2Hxnfr53W2aY9x7AncOdog6q6EVgPHNZjm5KkWdInIH6S5BkbR5IcDvysx3IrgUOSHJRkR+BEYPmkNsuBk9vh44HLqqraZRa22zsQ+CXglh7blCTNkj7nIN4IfDLJ92m6+n4c8LItLdSeUzgNuARYQHMeY3WSM4FVVbUcOBe4IMla4C6aEAF4DrAsyYPAw8AfVNUdj+5XkyTNRJ8nyq1M8ks0T5MDWFNVD/ZZeVWtoLnqaXTa6SPD9wEndCx3AXBBn21IkobR996CZwITbftnJKGq/nawqiRJY7fFgEhyAfBE4DrgoXZyAQaEJG3D+uxBLAEWV5U3q0nSdqTPVUzfpjkxLUnajvTZg9gHuCHJN4D7N06sqmMHq0qSNHZ9AuKMoYuQJM0/fS5zvXwuCpEkzS99nij3rCQrk6xP8kCSh5L8eC6KkySNT5+T1B8ATgK+S9NR3+/SPOdBkrQN6xMQVNVaYEFVPVRV/5vmIT6SpG1Yn5PUP20727suyZ8CP6BnsEiStl59vuhf2bY7DfgJTffcvzVkUZKk8euzB3FcVb0PuA94J0CSNwDvG7IwbR0mln1+bNu+5d0vHtu2pe1Bnz2IkzumvWqW65AkzTNT7kEkOQl4OfCEJKMP+tmd5tkNkqRt2OYOMX2N5oT0PsBfjEy/F/jWkEVJksZvyoCoqn9Osg64z7upJWn7s9lzEFX1EPBwkj3nqB5J0jzR5yqm9cD1Sb5Ac5krAFX1h4NVJUkauz4B8en2R5K0HenTm+v57Z3UT2onramqB4ctS5I0bn2eSf1rwPnALUCA/ZOcXFVXDFqZJGms+hxi+gvghVW1BiDJk4CPA4cPWZgkabz63Em9w8ZwAKiqfwJ2GK4kSdJ80GcPYlWSvwE+0o6/Alg1XEmSpPmgT0D8PvA6YONlrVcCfzVYRdIssSNBaWb6XMV0f5IPAJcCD9NcxfTA4JVJksaqz1VMLwY+CNxEcxXTQUleW1V/P3RxkqTx6XsV0/Pbx46S5InA5wEDQpK2YX2uYrp3Yzi0bqbp0XWLkhyTZE2StUmWdczfKclF7fyrkky0049OcnWS69t/X9Bne5Kk2dP3KqYVwCeAAk4AVib5LYCq6uyGI8kC4GzgaGBdu8zyqrphpNkpwN1VdXCSE4GzgJcBdwAvqarvJzkMuATYd1q/oTQPeQJdW4M+exA7A/8C/Crwa8DtwC7AS4Df2MxyRwBrq+rm9qT2hcDSSW2W0tylDXAxcFSSVNW1VfX9dvpqYJckO/WoVZI0S/pcxfTqaa57X+DWkfF1wJFTtamqDUnuAfam2YPY6KXANVV1/zTrkCRNQ5+rmA4CXg9MjLavqmOHK+vn2z6U5rDTC6eYfypwKsABBxwwdDmStF3pcw7is8C5wN/R3AfR123A/iPj+7XTutqsS7IQ2BO4EyDJfsBngN+pqpu6NlBV5wDnACxZsqQeRW2SpuD5EW3UJyDuq6r3T2PdK4FD2j2Q24ATgZdParMcOBn4OnA8cFlVVZK9aC6lXVZVX53GtiVtg+ZzeM3n2qarT0C8L8k7gH8Afn4eoKqu2dxC7TmF02iuQFoAnFdVq5OcCayqquU0eyYXJFkL3EUTIgCnAQcDpyc5vZ32wqr60aP43SRJM9AnIJ4MvBJ4Af96iKna8c2qqhXAiknTTh8Zvo/mstnJy70LeFeP2iRJA+kTECcAT7D/JUnavvS5D+LbwF4D1yFJmmf67EHsBXwnyUoeeQ5i8MtcJUnj0ycg3jF4FZKkeafPndSXz0UhkqT5ZcqASHIvzdVKm8wCqqr2GKwqSdLYTRkQVbX7XBYiSZpf+lzFJEnaDhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSp06ABkeSYJGuSrE2yrGP+TkkuaudflWSinb53ki8lWZ/kA0PWKEnqNlhAJFkAnA28CFgMnJRk8aRmpwB3V9XBwHuBs9rp9wF/Arx5qPokSZs35B7EEcDaqrq5qh4ALgSWTmqzFDi/Hb4YOCpJquonVfUVmqCQJI3BkAGxL3DryPi6dlpnm6raANwD7N13A0lOTbIqyarbb799huVKkkZt1Sepq+qcqlpSVUsWLVo07nIkaZsyZEDcBuw/Mr5fO62zTZKFwJ7AnQPWJEnqaciAWAkckuSgJDsCJwLLJ7VZDpzcDh8PXFZVNWBNkqSeFg614qrakOQ04BJgAXBeVa1OciawqqqWA+cCFyRZC9xFEyIAJLkF2APYMclxwAur6oah6pUkPdJgAQFQVSuAFZOmnT4yfB9wwhTLTgxZmyRp87bqk9SSpOEYEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE6DBkSSY5KsSbI2ybKO+Tsluaidf1WSiZF5b22nr0ny74esU5K0qcECIskC4GzgRcBi4KQkiyc1OwW4u6oOBt4LnNUuuxg4ETgUOAb4q3Z9kqQ5MuQexBHA2qq6uaoeAC4Elk5qsxQ4vx2+GDgqSdrpF1bV/VX1PWBtuz5J0hxZOOC69wVuHRlfBxw5VZuq2pDkHmDvdvo/Tlp238kbSHIqcGo7uj7Jmtkp/VHbB7hjugvnrFmsZFPWNj3WNj3WNj3jrO3AqWYMGRCDq6pzgHPGXUeSVVW1ZNx1dLG26bG26bG26ZmvtQ15iOk2YP+R8f3aaZ1tkiwE9gTu7LmsJGlAQwbESuCQJAcl2ZHmpPPySW2WAye3w8cDl1VVtdNPbK9yOgg4BPjGgLVKkiYZ7BBTe07hNOASYAFwXlWtTnImsKqqlgPnAhckWQvcRRMitO0+AdwAbABeV1UPDVXrLBj7Ya7NsLbpsbbpsbbpmZe1pfmDXZKkR/JOaklSJwNCktTJgJAkdTIgNiPJHya5McnHk3wxyXVJXpbkbVtYbuck30jyzSSrk7xzDmrdabTGGa7r/UnWz2D56b5u+yf5UpIb2tftDdOtYShpDPL/Zrqv28jyC5Jcm+RzQ9TXbuOMJG+e4TpemqSSzOp1/zOpLcnzklyTZEOS42expmm/p0n2SnJxku+06/jl2aqrt6ryZ4of4Ds092A8C/jiyPT1W1guwG7t8A7AVcCzBq71ETXOYD1LgAu29DsO9Lo9HnhGO7w78E/A4oFer3fTXB23cfwM4I+BS4FrgOuBpe28CWAN8LfAauDA+fR5G2n3JuBjwOcG/JydAbx5BsvvDlxB01PCkvlSW/seP6V9j4+fD+8pTTdEv9sO7wjsNdT7OmUNc73BreUH+CDwAHAj8BBwD3Ad8Ml2/Drgoz3Ws2v7hXPkDGqZaD9oH26/ND8K/DrwVeC7tP1ejdT4FuA97bJvAG5uh58AfHUz21kAfKn9op5WQMzW69au6/8ARw/0/j4duHxk/AaamzP3aMf3aV/TtK//wwwY8jN93dovoUuBF8x2QABvbz93XwE+DvwX4Op23lOBAg5ox28Cdt3Muv4n8GLgy8xCQMxmbW2bDzNLATGT95TmpuHv0V5pOq6fsW14a/gBbmm/KH5t9D9dny/P9sv2OmA9cNYM65iguR/kyTSHBa8Gzmu/vJYCnx2tEXgcsLIdvpjmpsV9aW5K/B+b2c4bgP/U93cc4nWb9Dv/X9ov7IHe3xuBX2i/SL5Ks7f3AeBb7Xv3s/a1nAC+N88/bxcDh09edhZqOpxmb2pXYA+a0HwzzZ7UHsBp7efrFTR9+nx9M+t6BvCpdvjLzDAgZrO2kXV+mNndg5jWewo8jebm4A8D1wJ/Azx26M/g5B/PQQykqh6qqqfR/GV3RJLDZrjK71XV9VX1MM1/gEur+SRdT/MFNrrtHwK7Jdmd5q/ijwHPA54LXNm18iS/AJwA/OUM65yxJLsBnwLeWFU/HnBTn6S5g/9lwEU0XySLgMPb9+5fgJ3btj8ZsI4ZSfIbwI+q6uoBVv9c4DNV9dP2vdjYG8LXgGfTfK7+O1v+fD0GeA/wn+dbbfPUQppA/V9V9XSaz98mz9QZmgExsKr6fzSHbY6Z4aruHxl+eGT8YbrviP8a8GqaY+dX0vwH+WWav5S7PB04GFib5BZg1/YO9zmVZAeacPhoVX164M1dRHP3/vE0YbEnzRftg0mez2Z6uZxnng0c275vFwIvSPKRgbd5Bc1n6kCaQ4FPBZ7D1F/CuwOHAV9u63wWsHy2T1RPs7b5aB2wrqquascvpgmMOWVATM+D7RdZpySLkuzVDu8CHE1zDmEuXUmzu30FzS7q84H7q+qersZV9fmqelxVTVTVBPDTah7kNJu29LqFpvuVG6vqPbO87U1U1WqaL67bquoHNOd2liS5Hvgd5v49m8pmX7eqemtV7de+byfS9Gn227O07SuA45Ls0u6RvqSdfiXw28B3273au4D/QHMuoKvGe6pqn5HP1z8Cx1bVqnHXNiZbek9/CNya5BfbSUfRnCebU1t1d99jdA7wrSTXVNUrOuY/Hji/fQreY4BPVNVglx5O4Uqaw0tXVNVDSW5l/F94W3rdng28Erg+yXXttLdV1YqhCqqqJ48M30Gzl9VlpocIZ2JLr9tgquqaJBcB3wR+RHNMn6q6pQ30K9qmXwH2q6q7t8bakjwT+Azwb4CXJHlnVR06YPl93tPXAx9tOzu9meaIwJyyLyZJUicPMUmSOnmIaQaS7E1z7flkR1XVnXNdT19JPgMcNGnyW6rqkjna/lb5uo3b1vK6JXk7zRVxoz5ZVf9tHPWMmm+1zff31ENMkqROHmKSJHUyICRJnQwIaZIkD7W9bm78mZjGOo5LsniA8qQ540lqaVM/a7vamInjgM/xKG5uSrKwqjbMcLvSrHEPQuohyeFJLk9ydZJLkjy+nf6aJCvTPPvjU0l2TfIrwLHAn7V7IE9M8uWN3Uok2aftboIkr0qyPMllwKVJHpvkvDTPE7k2ydK23aHttOuSfCvJIeN5JbQ9MSCkTe0ycnjpM22XCH9J08vn4TQ96W68LPLTVfXMqnoqTe+wp1TV12g6jvujqnpaVd20he09o133r9J0X31ZVR1B0z3KnyV5LPB7wPvaPZslNH31SIPyEJO0qUccYmp74j0M+ELTgwMLgB+0sw9L8i5gL2A3YDr3knyhqu5qh19I0/Hexiej7QwcAHwdeHuS/WhC6bvT2I70qBgQ0pYFWF1VXf00fRg4rqq+meRVNP3+d9nAv+6x7zxp3mhX4gFeWlVrJrW5MclVNA/bWZHktVV1Wf9fQXr0PMQkbdkaYNHGZwIn2SHJxo7cdgd+0B6GGu107d523ka30DzgBpruxadyCfD6trM5kjy9/fcJNE8GfD9NF9ZPmdFvJPVgQEhbUFUP0Hypn5XkmzRPm/uVdvaf0Dxz/Ks8srfcC4E/ak80PxH4c+D3k1xL84SxqfxXmifbfSvJ6nYc4D8C3257uT2M5tnJ0qDsakOS1Mk9CElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHX6/+fM0ttlZ9LGAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1     mfw_2  \\\n0  39.341333  39.831764  39.826684  11.282887  1.634628  0.913825 -0.771782   \n1  43.320409  45.006516  44.365681  12.474802  1.826689  0.901002 -0.707731   \n2  41.841597  41.778007  41.593833  11.837152  1.721631  0.911361 -0.728350   \n3  43.146961  41.264063  41.075821  11.843259  1.752020  0.906516 -0.728333   \n4  41.647822  43.131905  43.437246  12.388259  1.809692  0.915806 -0.758906   \n\n      mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -1.359522 -0.634856  0.232364  ...  0.019450  0.044698 -0.049375  0.037769   \n1 -1.281504 -0.731562 -1.393341  ...  0.013422  0.040336 -0.033106  0.009999   \n2 -1.293684 -0.729167 -1.923488  ...  0.010183  0.036844 -0.049280  0.038759   \n3 -1.275260 -0.678176 -1.560684  ...  0.001683  0.048352 -0.065776  0.050750   \n4 -1.398698 -0.864005  4.788369  ...  0.015460  0.047792 -0.049441  0.035196   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.045755  0.051531 -0.078515  0.013704 -0.024545 -0.017430  \n1 -0.014494  0.028882 -0.048873 -0.010926 -0.026088  0.009880  \n2 -0.048515  0.056363 -0.076889 -0.002209 -0.011804 -0.015943  \n3 -0.050526  0.048861 -0.084336  0.026353 -0.035720 -0.018588  \n4 -0.047893  0.061977 -0.082722  0.004341 -0.018094 -0.013906  \n\n[5 rows x 75 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39.341333</td>\n      <td>39.831764</td>\n      <td>39.826684</td>\n      <td>11.282887</td>\n      <td>1.634628</td>\n      <td>0.913825</td>\n      <td>-0.771782</td>\n      <td>-1.359522</td>\n      <td>-0.634856</td>\n      <td>0.232364</td>\n      <td>...</td>\n      <td>0.019450</td>\n      <td>0.044698</td>\n      <td>-0.049375</td>\n      <td>0.037769</td>\n      <td>-0.045755</td>\n      <td>0.051531</td>\n      <td>-0.078515</td>\n      <td>0.013704</td>\n      <td>-0.024545</td>\n      <td>-0.017430</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>43.320409</td>\n      <td>45.006516</td>\n      <td>44.365681</td>\n      <td>12.474802</td>\n      <td>1.826689</td>\n      <td>0.901002</td>\n      <td>-0.707731</td>\n      <td>-1.281504</td>\n      <td>-0.731562</td>\n      <td>-1.393341</td>\n      <td>...</td>\n      <td>0.013422</td>\n      <td>0.040336</td>\n      <td>-0.033106</td>\n      <td>0.009999</td>\n      <td>-0.014494</td>\n      <td>0.028882</td>\n      <td>-0.048873</td>\n      <td>-0.010926</td>\n      <td>-0.026088</td>\n      <td>0.009880</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41.841597</td>\n      <td>41.778007</td>\n      <td>41.593833</td>\n      <td>11.837152</td>\n      <td>1.721631</td>\n      <td>0.911361</td>\n      <td>-0.728350</td>\n      <td>-1.293684</td>\n      <td>-0.729167</td>\n      <td>-1.923488</td>\n      <td>...</td>\n      <td>0.010183</td>\n      <td>0.036844</td>\n      <td>-0.049280</td>\n      <td>0.038759</td>\n      <td>-0.048515</td>\n      <td>0.056363</td>\n      <td>-0.076889</td>\n      <td>-0.002209</td>\n      <td>-0.011804</td>\n      <td>-0.015943</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>43.146961</td>\n      <td>41.264063</td>\n      <td>41.075821</td>\n      <td>11.843259</td>\n      <td>1.752020</td>\n      <td>0.906516</td>\n      <td>-0.728333</td>\n      <td>-1.275260</td>\n      <td>-0.678176</td>\n      <td>-1.560684</td>\n      <td>...</td>\n      <td>0.001683</td>\n      <td>0.048352</td>\n      <td>-0.065776</td>\n      <td>0.050750</td>\n      <td>-0.050526</td>\n      <td>0.048861</td>\n      <td>-0.084336</td>\n      <td>0.026353</td>\n      <td>-0.035720</td>\n      <td>-0.018588</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.647822</td>\n      <td>43.131905</td>\n      <td>43.437246</td>\n      <td>12.388259</td>\n      <td>1.809692</td>\n      <td>0.915806</td>\n      <td>-0.758906</td>\n      <td>-1.398698</td>\n      <td>-0.864005</td>\n      <td>4.788369</td>\n      <td>...</td>\n      <td>0.015460</td>\n      <td>0.047792</td>\n      <td>-0.049441</td>\n      <td>0.035196</td>\n      <td>-0.047893</td>\n      <td>0.061977</td>\n      <td>-0.082722</td>\n      <td>0.004341</td>\n      <td>-0.018094</td>\n      <td>-0.013906</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 75 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 17.029202222824097 s\n",
      "Accuracy 0.9315168693425985 precision 0.9316384356345231 specificity 0.8807036341587247 recall 0.9315168693425985 f1 0.9315759394010865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 16.908761262893677 s\n",
      "Accuracy 0.9322483313522903 precision 0.9317796376677904 specificity 0.8705036868271049 recall 0.9322483313522903 f1 0.9319801638821711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 17.03975486755371 s\n",
      "Accuracy 0.9335283898692511 precision 0.9334656502344605 specificity 0.8794722985004825 recall 0.9335283898692511 f1 0.933496514496158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 17.141559600830078 s\n",
      "Accuracy 0.9295967815671573 precision 0.929395203764048 specificity 0.8710696637593319 recall 0.9295967815671573 f1 0.9294910352087361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 16.803027629852295 s\n",
      "Accuracy 0.9353570448934808 precision 0.9356614919400418 specificity 0.8842701199422135 recall 0.9353570448934808 f1 0.935499241643118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 17.110904216766357 s\n",
      "Accuracy 0.9353570448934808 precision 0.9359842731680327 specificity 0.8891360946870366 recall 0.9353570448934808 f1 0.935632218677791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 16.356361627578735 s\n",
      "Accuracy 0.9329797933619822 precision 0.9331484144607276 specificity 0.8777378670824173 recall 0.9329797933619822 f1 0.9330610919014153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 16.448036432266235 s\n",
      "Accuracy 0.9327969278595593 precision 0.9325277324327348 specificity 0.8743870956052778 recall 0.9327969278595593 f1 0.9326523525676095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 16.736971616744995 s\n",
      "Accuracy 0.9336198226204626 precision 0.9338259517033046 specificity 0.8844273027041777 recall 0.9336198226204626 f1 0.9337179447994243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 16.558355569839478 s\n",
      "Accuracy 0.9357227758983268 precision 0.93585635589325 specificity 0.8877526782481473 recall 0.9357227758983268 f1 0.9357872601864079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 16.540730953216553 s\n",
      "Accuracy 0.9329797933619822 precision 0.9328321009133356 specificity 0.878730519015538 recall 0.9329797933619822 f1 0.9329029814526613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 16.55456566810608 s\n",
      "Accuracy 0.931242571088964 precision 0.9312235613297141 specificity 0.8747635653721612 recall 0.931242571088964 f1 0.9312330249693606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 16.83664059638977 s\n",
      "Accuracy 0.9355399103959038 precision 0.9353464117057901 specificity 0.8807492329228397 recall 0.9355399103959038 f1 0.9354376556530476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 16.49954581260681 s\n",
      "Accuracy 0.93160830209381 precision 0.9316457777066041 specificity 0.8779884103448438 recall 0.93160830209381 f1 0.9316268762141284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 16.657382249832153 s\n",
      "Accuracy 0.9350827466398464 precision 0.9349127778447863 specificity 0.8806449084379233 recall 0.9350827466398464 f1 0.9349936117986324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 16.602734565734863 s\n",
      "Accuracy 0.931059705586541 precision 0.9314047625638746 specificity 0.879528186298225 recall 0.931059705586541 f1 0.931220427219731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 16.544921875 s\n",
      "Accuracy 0.9343512846301545 precision 0.9342169270627202 specificity 0.882442612372401 recall 0.9343512846301545 f1 0.9342814850550591\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 16.348243713378906 s\n",
      "Accuracy 0.9343512846301545 precision 0.9341813568226941 specificity 0.8803065585165863 recall 0.9343512846301545 f1 0.9342621936059371\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 16.30633521080017 s\n",
      "Accuracy 0.9323397641035018 precision 0.9320267732699395 specificity 0.8763618803835334 recall 0.9323397641035018 f1 0.9321684907896782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 16.377787113189697 s\n",
      "Accuracy 0.934259851878943 precision 0.9340570144722913 specificity 0.8762564543302245 recall 0.934259851878943 f1 0.9341528919525207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 16.641533851623535 s\n",
      "Accuracy 0.93160830209381 precision 0.9310144364739578 specificity 0.8651166294964884 recall 0.93160830209381 f1 0.9312568237882304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 16.308984518051147 s\n",
      "Accuracy 0.9267623662796014 precision 0.9268351862520736 specificity 0.8667842759433104 recall 0.9267623662796014 f1 0.9267982748403921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 16.35458755493164 s\n",
      "Accuracy 0.9329797933619822 precision 0.9331030854831339 specificity 0.8804108695320975 recall 0.9329797933619822 f1 0.9330397000696247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 16.377995252609253 s\n",
      "Accuracy 0.9265795007771784 precision 0.9264205958205105 specificity 0.8692998519509196 recall 0.9265795007771784 f1 0.926497142057156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 16.284497022628784 s\n",
      "Accuracy 0.9300539453232147 precision 0.9300075576463378 specificity 0.875302760685956 recall 0.9300539453232147 f1 0.9300304973347421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 16.76371479034424 s\n",
      "Accuracy 0.9352656121422693 precision 0.93547029225859 specificity 0.8860348132614962 recall 0.9352656121422693 f1 0.93536296365752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 16.447378396987915 s\n",
      "Accuracy 0.9302368108256377 precision 0.930227567841072 specificity 0.8768845228717101 recall 0.9302368108256377 f1 0.9302321792026196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 16.88480830192566 s\n",
      "Accuracy 0.931425436591387 precision 0.9316842367592824 specificity 0.8791349152760022 recall 0.931425436591387 f1 0.9315479155076041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 16.683340072631836 s\n",
      "Accuracy 0.931059705586541 precision 0.9311324731992662 specificity 0.8812502661675478 recall 0.931059705586541 f1 0.9310954459346227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 16.692062377929688 s\n",
      "Accuracy 0.934259851878943 precision 0.9345707845059408 specificity 0.8875245722610952 recall 0.934259851878943 f1 0.9344042353298746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 16.395036935806274 s\n",
      "Accuracy 0.9346255828837889 precision 0.9345487819018942 specificity 0.8834131443795239 recall 0.9346255828837889 f1 0.9345863524803623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 16.621082067489624 s\n",
      "Accuracy 0.9331626588644052 precision 0.9331907267627375 specificity 0.8786862916683594 recall 0.9331626588644052 f1 0.9331765996647907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 16.384904146194458 s\n",
      "Accuracy 0.9356313431471153 precision 0.9361882412192903 specificity 0.8906505014191536 recall 0.9356313431471153 f1 0.9358775953197521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 16.2747962474823 s\n",
      "Accuracy 0.9317911675962329 precision 0.9320109839405637 specificity 0.8856156289276781 recall 0.9317911675962329 f1 0.9318953225812849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 16.177655935287476 s\n",
      "Accuracy 0.9317911675962329 precision 0.9315947323976681 specificity 0.8743506496485594 recall 0.9317911675962329 f1 0.931687957199903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 16.534247875213623 s\n",
      "Accuracy 0.9338026881228856 precision 0.9335611919622212 specificity 0.8763478746625305 recall 0.9338026881228856 f1 0.9336737801730624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 16.633063793182373 s\n",
      "Accuracy 0.9323397641035018 precision 0.9323029787497482 specificity 0.8775877586074725 recall 0.9323397641035018 f1 0.9323212067609273\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 16.378519773483276 s\n",
      "Accuracy 0.9332540916156167 precision 0.9330310896885154 specificity 0.8771750740315573 recall 0.9332540916156167 f1 0.9331356107488613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 16.450578689575195 s\n",
      "Accuracy 0.9335283898692511 precision 0.933828494496559 specificity 0.8842799819546822 recall 0.9335283898692511 f1 0.9336685995418611\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 16.340986013412476 s\n",
      "Accuracy 0.9352656121422693 precision 0.9355146217453603 specificity 0.8848355138503822 recall 0.9352656121422693 f1 0.9353831014959717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 16.74160647392273 s\n",
      "Accuracy 0.9390143549419402 precision 0.9387233693771957 specificity 0.8831606399913443 recall 0.9390143549419402 f1 0.9388543375357075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 16.55384063720703 s\n",
      "Accuracy 0.9350827466398464 precision 0.9348490051879627 specificity 0.8796050863886944 recall 0.9350827466398464 f1 0.9349577269786814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 16.84441113471985 s\n",
      "Accuracy 0.9354484776446923 precision 0.9352529185118608 specificity 0.8829202387053598 recall 0.9354484776446923 f1 0.9353447670100118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 16.128969192504883 s\n",
      "Accuracy 0.9311511383377525 precision 0.9310880235767124 specificity 0.8776999109062936 recall 0.9311511383377525 f1 0.9311190829454936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 15.545912504196167 s\n",
      "Accuracy 0.9354484776446923 precision 0.9355926070526989 specificity 0.886975941067685 recall 0.9354484776446923 f1 0.9355179159943615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 15.103665828704834 s\n",
      "Accuracy 0.9335283898692511 precision 0.9335193702135769 specificity 0.8807493405736484 recall 0.9335283898692511 f1 0.9335238697587382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 15.370815515518188 s\n",
      "Accuracy 0.9343512846301545 precision 0.9346168167893321 specificity 0.8856417014862891 recall 0.9343512846301545 f1 0.9344760120640588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 15.217040300369263 s\n",
      "Accuracy 0.9317911675962329 precision 0.9319626477605065 specificity 0.8807698785649741 recall 0.9317911675962329 f1 0.9318736103349221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 15.71597409248352 s\n",
      "Accuracy 0.9348084483862119 precision 0.9350024273648339 specificity 0.886034265562303 recall 0.9348084483862119 f1 0.9349009150855732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 14.784388065338135 s\n",
      "Accuracy 0.9349913138886349 precision 0.935092951770182 specificity 0.8831803651473182 recall 0.9349913138886349 f1 0.9350408784687608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 15.42758059501648 s\n",
      "Accuracy 0.9354484776446923 precision 0.9350571809026517 specificity 0.8779520913411628 recall 0.9354484776446923 f1 0.9352267594014894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 15.059131145477295 s\n",
      "Accuracy 0.9306939745816951 precision 0.9308295655959663 specificity 0.8775550207628029 recall 0.9306939745816951 f1 0.9307597721162626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 15.282831907272339 s\n",
      "Accuracy 0.9356313431471153 precision 0.9357791997097749 specificity 0.8850410265297269 recall 0.9356313431471153 f1 0.9357026172974949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 15.672546863555908 s\n",
      "Accuracy 0.937277132668922 precision 0.9374038962960378 specificity 0.8870825919047012 recall 0.937277132668922 f1 0.9373384682215147\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 15.437556743621826 s\n",
      "Accuracy 0.934442717381366 precision 0.9341855399521706 specificity 0.8788822290134373 recall 0.934442717381366 f1 0.9343041807781656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 15.209601163864136 s\n",
      "Accuracy 0.9339855536253086 precision 0.9337377810554826 specificity 0.8793375747255726 recall 0.9339855536253086 f1 0.933852406081591\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 14.862981081008911 s\n",
      "Accuracy 0.9375514309225564 precision 0.9374918938641662 specificity 0.8858312030260187 recall 0.9375514309225564 f1 0.9375211506363398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 15.38389778137207 s\n",
      "Accuracy 0.9350827466398464 precision 0.9353262653530088 specificity 0.8865419044276984 recall 0.9350827466398464 f1 0.9351975567015546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 15.081026315689087 s\n",
      "Accuracy 0.9359970741519612 precision 0.9365528007096011 specificity 0.8910886659786161 recall 0.9359970741519612 f1 0.9362426822243488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 15.02898645401001 s\n",
      "Accuracy 0.9341684191277315 precision 0.9344125302816199 specificity 0.8857580256764943 recall 0.9341684191277315 f1 0.9342835647405621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 15.447364330291748 s\n",
      "Accuracy 0.9308768400841181 precision 0.9314367785067827 specificity 0.8831870823729056 recall 0.9308768400841181 f1 0.9311273297700319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 15.28765606880188 s\n",
      "Accuracy 0.9286824540550425 precision 0.9281713509214684 specificity 0.8674097553812252 recall 0.9286824540550425 f1 0.9283877220959204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 15.203220844268799 s\n",
      "Accuracy 0.9328883606107707 precision 0.9327272594695011 specificity 0.875911477280766 recall 0.9328883606107707 f1 0.9328044502480318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 15.153984069824219 s\n",
      "Accuracy 0.9348998811374234 precision 0.9348448078470124 specificity 0.878494518721899 recall 0.9348998811374234 f1 0.9348719663661014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 15.257518768310547 s\n",
      "Accuracy 0.9301453780744262 precision 0.930282336395435 specificity 0.8763623307281319 recall 0.9301453780744262 f1 0.930211859822513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 15.267348051071167 s\n",
      "Accuracy 0.931425436591387 precision 0.9316931594071296 specificity 0.8830689397291858 recall 0.931425436591387 f1 0.9315513974627831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 15.340137720108032 s\n",
      "Accuracy 0.9333455243668282 precision 0.933336672556009 specificity 0.8821685183715748 recall 0.9333455243668282 f1 0.9333410882587769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 15.175039052963257 s\n",
      "Accuracy 0.9327969278595593 precision 0.9328792831840168 specificity 0.8820901442193407 recall 0.9327969278595593 f1 0.9328372803788791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 15.557141780853271 s\n",
      "Accuracy 0.937094267166499 precision 0.937367316929619 specificity 0.8912634273173684 recall 0.937094267166499 f1 0.9372215350502154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 15.664706945419312 s\n",
      "Accuracy 0.9330712261131937 precision 0.9336197099319482 specificity 0.8827276733039531 recall 0.9330712261131937 f1 0.933317497061349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 15.139434099197388 s\n",
      "Accuracy 0.9382828929322483 precision 0.9379530115212424 specificity 0.8828482738060363 recall 0.9382828929322483 f1 0.9380984961788694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 15.0515456199646 s\n",
      "Accuracy 0.9364542379080186 precision 0.9366219409237307 specificity 0.8900471571874704 recall 0.9364542379080186 f1 0.9365343959446575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 15.125977277755737 s\n",
      "Accuracy 0.9296882143183688 precision 0.9307707411483059 specificity 0.8829107696199153 recall 0.9296882143183688 f1 0.9301417238001832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 15.381426572799683 s\n",
      "Accuracy 0.9339855536253086 precision 0.9339299038547779 specificity 0.877124776431215 recall 0.9339855536253086 f1 0.9339573518521146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 15.310075283050537 s\n",
      "Accuracy 0.9330712261131937 precision 0.9329844243095572 specificity 0.8809355186114352 recall 0.9330712261131937 f1 0.9330268052977172\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 15.828669786453247 s\n",
      "Accuracy 0.9337112553716741 precision 0.9334740647002624 specificity 0.8750734468069141 recall 0.9337112553716741 f1 0.9335850369853704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 17.697542428970337 s\n",
      "Accuracy 0.9305111090792721 precision 0.9312105677435054 specificity 0.8811561865199444 recall 0.9305111090792721 f1 0.9308190737167414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 18.144967555999756 s\n",
      "Accuracy 0.9338941208740971 precision 0.9341757234913594 specificity 0.8836866110137807 recall 0.9338941208740971 f1 0.9340262611106598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 17.7449688911438 s\n",
      "Accuracy 0.9334369571180396 precision 0.9334552734728302 specificity 0.8803348127106237 recall 0.9334369571180396 f1 0.9334460740867188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 16.547355890274048 s\n",
      "Accuracy 0.9325226296059248 precision 0.9326563676279633 specificity 0.8798232294242252 recall 0.9325226296059248 f1 0.9325874846185602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 15.30209732055664 s\n",
      "Accuracy 0.9303282435768492 precision 0.9299579892039772 specificity 0.868588764747236 recall 0.9303282435768492 f1 0.9301248583903086\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 15.28542947769165 s\n",
      "Accuracy 0.9356313431471153 precision 0.9355649219900848 specificity 0.8863670626495999 recall 0.9356313431471153 f1 0.9355974787332662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 15.4190993309021 s\n",
      "Accuracy 0.9332540916156167 precision 0.9330054306621204 specificity 0.8787128001712833 recall 0.9332540916156167 f1 0.9331205392371816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 15.030987977981567 s\n",
      "Accuracy 0.9357227758983268 precision 0.9359486399480438 specificity 0.8895081157299383 recall 0.9357227758983268 f1 0.9358293302394214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 14.992773294448853 s\n",
      "Accuracy 0.9343512846301545 precision 0.9344246278553822 specificity 0.8825553680155551 recall 0.9343512846301545 f1 0.9343872959057451\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 15.503399848937988 s\n",
      "Accuracy 0.9304196763280607 precision 0.9302714951869187 specificity 0.8771437602961131 recall 0.9304196763280607 f1 0.9303426702713194\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 15.488628149032593 s\n",
      "Accuracy 0.9365456706592301 precision 0.9368033917908686 specificity 0.8894533293449873 recall 0.9365456706592301 f1 0.9366664516361208\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 15.505430936813354 s\n",
      "Accuracy 0.9349913138886349 precision 0.9352279878529288 specificity 0.8853227899382826 recall 0.9349913138886349 f1 0.9351031991853642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 15.515876293182373 s\n",
      "Accuracy 0.9364542379080186 precision 0.9365913792799377 specificity 0.8861078032009119 recall 0.9364542379080186 f1 0.9365204682664675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 15.474841833114624 s\n",
      "Accuracy 0.9319740330986559 precision 0.931524189692604 specificity 0.8726462716110357 recall 0.9319740330986559 f1 0.9317168135315375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 15.285077571868896 s\n",
      "Accuracy 0.931425436591387 precision 0.93148146056137 specificity 0.8787517532288202 recall 0.931425436591387 f1 0.9314530818333934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 15.086001873016357 s\n",
      "Accuracy 0.9334369571180396 precision 0.9336415447058382 specificity 0.8849164165525348 recall 0.9334369571180396 f1 0.9335343279526375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 15.261088371276855 s\n",
      "Accuracy 0.9325226296059248 precision 0.9325606665132091 specificity 0.8772370737191397 recall 0.9325226296059248 f1 0.9325414824330025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 14.986908912658691 s\n",
      "Accuracy 0.9297796470695803 precision 0.929933308590802 specificity 0.8782849717582385 recall 0.9297796470695803 f1 0.9298538963150456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 15.193628787994385 s\n",
      "Accuracy 0.9290481850598884 precision 0.929604094047724 specificity 0.8824696672345557 recall 0.9290481850598884 f1 0.9292970800831934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 15.381531476974487 s\n",
      "Accuracy 0.9349913138886349 precision 0.9348768868626732 specificity 0.8798941880528252 recall 0.9349913138886349 f1 0.9349323385068931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 15.506018161773682 s\n",
      "Accuracy 0.9338941208740971 precision 0.9340174910297803 specificity 0.8809000326737951 recall 0.9338941208740971 f1 0.9339540545994268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 15.247756481170654 s\n",
      "Accuracy 0.9356313431471153 precision 0.9361327244128683 specificity 0.8882695569178378 recall 0.9356313431471153 f1 0.9358561465052226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 15.338858604431152 s\n",
      "Accuracy 0.9319740330986559 precision 0.9321675323154147 specificity 0.88016571692971 recall 0.9319740330986559 f1 0.9320666916881339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 15.075109243392944 s\n",
      "Accuracy 0.9408430099661699 precision 0.9408832645575969 specificity 0.8954233309098997 recall 0.9408430099661699 f1 0.9408628777196476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 15.036888122558594 s\n",
      "Accuracy 0.9359970741519612 precision 0.9360332829855513 specificity 0.8833350396091313 recall 0.9359970741519612 f1 0.93601501155853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 15.283759593963623 s\n",
      "Accuracy 0.9309682728353296 precision 0.9313738256749247 specificity 0.8787770868896911 recall 0.9309682728353296 f1 0.9311554533493973\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 15.0848867893219 s\n",
      "Accuracy 0.9350827466398464 precision 0.9351933519073647 specificity 0.8837348876793898 recall 0.9350827466398464 f1 0.9351365581912964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 15.400861978530884 s\n",
      "Accuracy 0.9361799396543842 precision 0.9365356226373462 specificity 0.8907579446667383 recall 0.9361799396543842 f1 0.9363429869973926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 15.294388055801392 s\n",
      "Accuracy 0.9308768400841181 precision 0.9313034474310891 specificity 0.8815987415235397 recall 0.9308768400841181 f1 0.9310722648054782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 15.150571584701538 s\n",
      "Accuracy 0.9392886531955746 precision 0.939321417615707 specificity 0.8929720788648737 recall 0.9392886531955746 f1 0.9393048701309324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 15.166615009307861 s\n",
      "Accuracy 0.9295053488159458 precision 0.9301654691174875 specificity 0.8804474296288031 recall 0.9295053488159458 f1 0.929797763282972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 15.313254356384277 s\n",
      "Accuracy 0.9318826003474444 precision 0.9316065319356385 specificity 0.8764266123874956 recall 0.9318826003474444 f1 0.9317334540613272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 15.254776954650879 s\n",
      "Accuracy 0.9332540916156167 precision 0.9331443682081907 specificity 0.8761202643956187 recall 0.9332540916156167 f1 0.9331977298105091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 15.073461771011353 s\n",
      "Accuracy 0.9358142086495382 precision 0.9360164047657157 specificity 0.8873593950265141 recall 0.9358142086495382 f1 0.9359103201341485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 15.068362951278687 s\n",
      "Accuracy 0.9382828929322483 precision 0.938192910147983 specificity 0.8880051082427358 recall 0.9382828929322483 f1 0.9382366428137241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 15.193768739700317 s\n",
      "Accuracy 0.9315168693425985 precision 0.9319018003743701 specificity 0.8835968621763777 recall 0.9315168693425985 f1 0.9316939708423261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 15.142720460891724 s\n",
      "Accuracy 0.9302368108256377 precision 0.9306176926349272 specificity 0.8786033352053626 recall 0.9302368108256377 f1 0.9304133116522192\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 15.171896696090698 s\n",
      "Accuracy 0.9321568986010789 precision 0.9324186588268529 specificity 0.8786080743961545 recall 0.9321568986010789 f1 0.932280793243779\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 15.157116413116455 s\n",
      "Accuracy 0.9316997348450214 precision 0.9317088632283492 specificity 0.8793273952781879 recall 0.9316997348450214 f1 0.9317042888638807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 15.265978813171387 s\n",
      "Accuracy 0.9324311968547133 precision 0.9323326607562105 specificity 0.8777360931589187 recall 0.9324311968547133 f1 0.9323806860184343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 15.249386310577393 s\n",
      "Accuracy 0.9324311968547133 precision 0.932536469287724 specificity 0.8787275357221471 recall 0.9324311968547133 f1 0.9324825863982007\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 15.090614557266235 s\n",
      "Accuracy 0.9380085946786139 precision 0.938229779718918 specificity 0.889112889957694 recall 0.9380085946786139 f1 0.9381131592804774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 15.114559173583984 s\n",
      "Accuracy 0.9297796470695803 precision 0.9302877653011103 specificity 0.8829904867913574 recall 0.9297796470695803 f1 0.9300087092000863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 15.026310920715332 s\n",
      "Accuracy 0.9338941208740971 precision 0.933796013773267 specificity 0.8788576133498066 recall 0.9338941208740971 f1 0.9338438129427004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 15.056882858276367 s\n",
      "Accuracy 0.9347170156350004 precision 0.9351435148566599 specificity 0.8886753008746203 recall 0.9347170156350004 f1 0.9349104912287987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 14.864720821380615 s\n",
      "Accuracy 0.9343512846301545 precision 0.9346715932191609 specificity 0.8822883875953852 recall 0.9343512846301545 f1 0.934500768160073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 15.227057933807373 s\n",
      "Accuracy 0.9325226296059248 precision 0.9325788914660407 specificity 0.8790298687336242 recall 0.9325226296059248 f1 0.9325503903873168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 15.259941339492798 s\n",
      "Accuracy 0.9311511383377525 precision 0.9308290870184661 specificity 0.8715948541159289 recall 0.9311511383377525 f1 0.9309759824156593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 15.458741188049316 s\n",
      "Accuracy 0.9365456706592301 precision 0.9367081330051614 specificity 0.8880819668062163 recall 0.9365456706592301 f1 0.9366235548507088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 15.219052076339722 s\n",
      "Accuracy 0.93160830209381 precision 0.9320712967522099 specificity 0.8839863709111885 recall 0.93160830209381 f1 0.9318183895605996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 15.16329312324524 s\n",
      "Accuracy 0.9345341501325775 precision 0.9345705249970917 specificity 0.8821346627589736 recall 0.9345341501325775 f1 0.9345521721162845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 15.137172222137451 s\n",
      "Accuracy 0.9357227758983268 precision 0.9356265600362661 specificity 0.8814005167485769 recall 0.9357227758983268 f1 0.9356734046592313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 15.11263632774353 s\n",
      "Accuracy 0.9315168693425985 precision 0.9322442257758363 specificity 0.8863838500246762 recall 0.9315168693425985 f1 0.9318325187191613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 15.185615301132202 s\n",
      "Accuracy 0.931059705586541 precision 0.9313703097169533 specificity 0.8827156097040537 recall 0.931059705586541 f1 0.9312046949279352\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 15.222062587738037 s\n",
      "Accuracy 0.9331626588644052 precision 0.9331906406691807 specificity 0.8789468700043498 recall 0.9331626588644052 f1 0.9331765567194387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 15.119122982025146 s\n",
      "Accuracy 0.9335283898692511 precision 0.9336485814288779 specificity 0.8828499283681848 recall 0.9335283898692511 f1 0.9335867551117321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 15.145292520523071 s\n",
      "Accuracy 0.9338941208740971 precision 0.933921713912418 specificity 0.8805327815857448 recall 0.9338941208740971 f1 0.9339078243067762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 15.311999559402466 s\n",
      "Accuracy 0.9388314894395172 precision 0.939098287638562 specificity 0.8968725447376035 recall 0.9388314894395172 f1 0.9389550873021117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 14.86074185371399 s\n",
      "Accuracy 0.9324311968547133 precision 0.9323135943224482 specificity 0.8763075821805439 recall 0.9324311968547133 f1 0.9323706506987226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 15.12091326713562 s\n",
      "Accuracy 0.9343512846301545 precision 0.9349887564634586 specificity 0.8917679227240457 recall 0.9343512846301545 f1 0.9346286055776313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 14.977450609207153 s\n",
      "Accuracy 0.9311511383377525 precision 0.930591745464367 specificity 0.8655785162279304 recall 0.9311511383377525 f1 0.930824421329734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 15.145512104034424 s\n",
      "Accuracy 0.9319740330986559 precision 0.9315916785896041 specificity 0.8698654328892623 recall 0.9319740330986559 f1 0.9317626266945969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 15.14579153060913 s\n",
      "Accuracy 0.9330712261131937 precision 0.9332053656150373 specificity 0.8798964676057559 recall 0.9330712261131937 f1 0.9331362717473024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 15.33453106880188 s\n",
      "Accuracy 0.934442717381366 precision 0.9347105380809281 specificity 0.8880979432382669 recall 0.934442717381366 f1 0.9345680880718179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 14.90861177444458 s\n",
      "Accuracy 0.934259851878943 precision 0.9340952536202607 specificity 0.8789915604615293 recall 0.934259851878943 f1 0.9341738092688157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 14.87592601776123 s\n",
      "Accuracy 0.9321568986010789 precision 0.9322117299368022 specificity 0.8809516420023701 recall 0.9321568986010789 f1 0.9321839483667756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 15.096448183059692 s\n",
      "Accuracy 0.9357227758983268 precision 0.9353133074094941 specificity 0.875668482346552 recall 0.9357227758983268 f1 0.9354905944769776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 15.171736240386963 s\n",
      "Accuracy 0.9305111090792721 precision 0.9298418679576956 specificity 0.8623953768643933 recall 0.9305111090792721 f1 0.9301059016966265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 15.319536924362183 s\n",
      "Accuracy 0.9319740330986559 precision 0.9321695123273446 specificity 0.8792996703321622 recall 0.9319740330986559 f1 0.9320676668687542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 15.409318208694458 s\n",
      "Accuracy 0.9313340038401755 precision 0.9314795553465729 specificity 0.8780692695241064 recall 0.9313340038401755 f1 0.9314044762468812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 15.363720893859863 s\n",
      "Accuracy 0.9327969278595593 precision 0.9327704719919611 specificity 0.881576246145742 recall 0.9327969278595593 f1 0.9327836084098323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 15.115343570709229 s\n",
      "Accuracy 0.9338941208740971 precision 0.9336114535476898 specificity 0.8753900700271613 recall 0.9338941208740971 f1 0.9337414165468777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 15.117318153381348 s\n",
      "Accuracy 0.9373685654201335 precision 0.937775015881298 specificity 0.8877958846027973 recall 0.9373685654201335 f1 0.9375540864749597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 15.21081256866455 s\n",
      "Accuracy 0.9354484776446923 precision 0.9356523682389604 specificity 0.8864612566279626 recall 0.9354484776446923 f1 0.9355454346954006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 15.194670677185059 s\n",
      "Accuracy 0.9343512846301545 precision 0.9341109543567282 specificity 0.8818850869934141 recall 0.9343512846301545 f1 0.9342219263285845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 15.150818347930908 s\n",
      "Accuracy 0.9381914601810368 precision 0.9380538790633559 specificity 0.8824392177094663 recall 0.9381914601810368 f1 0.9381199463406705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 15.203505516052246 s\n",
      "Accuracy 0.9349913138886349 precision 0.9355893327115115 specificity 0.8926773633699474 recall 0.9349913138886349 f1 0.935252657603093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 15.343274116516113 s\n",
      "Accuracy 0.9361799396543842 precision 0.9358590161508346 specificity 0.8794687759789612 recall 0.9361799396543842 f1 0.9360027271149315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 14.869530439376831 s\n",
      "Accuracy 0.9338026881228856 precision 0.9339850435792104 specificity 0.8861455898602972 recall 0.9338026881228856 f1 0.9338898076800825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 15.259865760803223 s\n",
      "Accuracy 0.9348084483862119 precision 0.9349096861779399 specificity 0.88339701844902 recall 0.9348084483862119 f1 0.9348578163964651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 15.068203926086426 s\n",
      "Accuracy 0.9338941208740971 precision 0.9342354770842747 specificity 0.8850560199599811 recall 0.9338941208740971 f1 0.9340522309036251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 15.390393733978271 s\n",
      "Accuracy 0.931242571088964 precision 0.9309675064231637 specificity 0.8742235165920822 recall 0.931242571088964 f1 0.9310945548481973\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 15.0989990234375 s\n",
      "Accuracy 0.9336198226204626 precision 0.9335842724212768 specificity 0.8811108404220892 recall 0.9336198226204626 f1 0.9336018832731239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 15.31253957748413 s\n",
      "Accuracy 0.9373685654201335 precision 0.9370959406693038 specificity 0.8838599316662823 recall 0.9373685654201335 f1 0.937219501252947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 15.351457357406616 s\n",
      "Accuracy 0.9327054951083478 precision 0.9326163359692821 specificity 0.8785680783474262 recall 0.9327054951083478 f1 0.9326598889928449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 15.39299488067627 s\n",
      "Accuracy 0.9320654658498674 precision 0.9318446765529881 specificity 0.8744879844732513 recall 0.9320654658498674 f1 0.931948616963466\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 15.316599130630493 s\n",
      "Accuracy 0.9330712261131937 precision 0.9330891964548625 specificity 0.8816891669505679 recall 0.9330712261131937 f1 0.9330801704557038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 15.555402040481567 s\n",
      "Accuracy 0.928591021303831 precision 0.9283446444371738 specificity 0.8694308668959075 recall 0.928591021303831 f1 0.9284603962390449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 15.335119247436523 s\n",
      "Accuracy 0.9327054951083478 precision 0.9324180663081026 specificity 0.8756449969719802 recall 0.9327054951083478 f1 0.9325498609271893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 15.402549028396606 s\n",
      "Accuracy 0.9282252902989852 precision 0.9280822903152478 specificity 0.8690075887832547 recall 0.9282252902989852 f1 0.9281514911702239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 15.274376153945923 s\n",
      "Accuracy 0.937094267166499 precision 0.9367585248920659 specificity 0.8794777009750745 recall 0.937094267166499 f1 0.9369077745827442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 15.48409128189087 s\n",
      "Accuracy 0.931059705586541 precision 0.9308306153422288 specificity 0.8739000920792234 recall 0.931059705586541 f1 0.9309382297321499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 15.295073509216309 s\n",
      "Accuracy 0.9289567523086769 precision 0.9291412665918856 specificity 0.8776858388349343 recall 0.9289567523086769 f1 0.9290453842288716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 15.60150957107544 s\n",
      "Accuracy 0.9368199689128646 precision 0.9368628692897002 specificity 0.8883593095149748 recall 0.9368199689128646 f1 0.9368411617431146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 15.287473440170288 s\n",
      "Accuracy 0.9320654658498674 precision 0.9317646021738129 specificity 0.8736685081386513 recall 0.9320654658498674 f1 0.9319023805964656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 15.360242366790771 s\n",
      "Accuracy 0.9370028344152875 precision 0.9371359999697585 specificity 0.8887768598954763 recall 0.9370028344152875 f1 0.9370670921073784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 15.396864891052246 s\n",
      "Accuracy 0.9328883606107707 precision 0.9328527022740872 specificity 0.8804626102965983 recall 0.9328883606107707 f1 0.9328703678902843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 15.172470569610596 s\n",
      "Accuracy 0.9348998811374234 precision 0.9352773586229511 specificity 0.8850688938241762 recall 0.9348998811374234 f1 0.9350736367590745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 15.401726961135864 s\n",
      "Accuracy 0.9357227758983268 precision 0.9358216103979302 specificity 0.8858804751160942 recall 0.9357227758983268 f1 0.9357709445402862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 15.30403757095337 s\n",
      "Accuracy 0.9307854073329066 precision 0.9307947202089883 specificity 0.8771459561923635 recall 0.9307854073329066 f1 0.9307900535934791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 15.436115980148315 s\n",
      "Accuracy 0.9356313431471153 precision 0.9353261652413685 specificity 0.879798719653635 recall 0.9356313431471153 f1 0.9354637281687348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 15.225389957427979 s\n",
      "Accuracy 0.9311511383377525 precision 0.93092775125216 specificity 0.8730630700624831 recall 0.9311511383377525 f1 0.9310330082958769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 15.117512941360474 s\n",
      "Accuracy 0.9346255828837889 precision 0.9350465192577448 specificity 0.8875337221525095 recall 0.9346255828837889 f1 0.9348170926338266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 15.146424531936646 s\n",
      "Accuracy 0.937277132668922 precision 0.9373297138927686 specificity 0.8872756940638304 recall 0.937277132668922 f1 0.9373030489457335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 15.388693571090698 s\n",
      "Accuracy 0.9355399103959038 precision 0.9358104829088045 specificity 0.8880123956427038 recall 0.9355399103959038 f1 0.9356665585416596\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 15.343941688537598 s\n",
      "Accuracy 0.9332540916156167 precision 0.933422457461598 specificity 0.8831841323019194 recall 0.9332540916156167 f1 0.933334964657903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 15.045725107192993 s\n",
      "Accuracy 0.9354484776446923 precision 0.9354133996625452 specificity 0.8831869324417304 recall 0.9354484776446923 f1 0.9354307729367766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 14.99215316772461 s\n",
      "Accuracy 0.9355399103959038 precision 0.9355667228223741 specificity 0.8838160981555578 recall 0.9355399103959038 f1 0.9355532233299451\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 14.99985146522522 s\n",
      "Accuracy 0.9324311968547133 precision 0.932635628208802 specificity 0.8802170237448074 recall 0.9324311968547133 f1 0.9325288816884655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 15.243390798568726 s\n",
      "Accuracy 0.9348084483862119 precision 0.9349680638136388 specificity 0.8835327453400484 recall 0.9348084483862119 f1 0.9348852636624817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 15.393553018569946 s\n",
      "Accuracy 0.9306025418304836 precision 0.9302795643699713 specificity 0.8711118426070129 recall 0.9306025418304836 f1 0.9304269663031243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 15.309660911560059 s\n",
      "Accuracy 0.9359970741519612 precision 0.9363719027508043 specificity 0.8911081204105329 recall 0.9359970741519612 f1 0.9361681408119891\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 15.289793729782104 s\n",
      "Accuracy 0.9341684191277315 precision 0.934204176574945 specificity 0.8833157709684449 recall 0.9341684191277315 f1 0.9341861338373978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 15.298471450805664 s\n",
      "Accuracy 0.9303282435768492 precision 0.9305453285482219 specificity 0.8780396628706533 recall 0.9303282435768492 f1 0.9304318662247231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 15.035175800323486 s\n",
      "Accuracy 0.931425436591387 precision 0.9316190266408925 specificity 0.8797856620212864 recall 0.931425436591387 f1 0.9315181554960702\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 15.102105855941772 s\n",
      "Accuracy 0.9336198226204626 precision 0.9335320163059014 specificity 0.8803010818895429 recall 0.9336198226204626 f1 0.9335748914502288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 15.343472480773926 s\n",
      "Accuracy 0.9351741793910578 precision 0.9353660959148492 specificity 0.8871150535389075 recall 0.9351741793910578 f1 0.935265620189057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 15.142006158828735 s\n",
      "Accuracy 0.93160830209381 precision 0.9317980866609091 specificity 0.8815533175982678 recall 0.93160830209381 f1 0.9316991413319967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 15.316989421844482 s\n",
      "Accuracy 0.9320654658498674 precision 0.9320198394084233 specificity 0.877791601865305 recall 0.9320654658498674 f1 0.9320423963027934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 15.041359663009644 s\n",
      "Accuracy 0.9316997348450214 precision 0.9317446761681903 specificity 0.8817311281642823 recall 0.9316997348450214 f1 0.931721953410477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 15.127214908599854 s\n",
      "Accuracy 0.9311511383377525 precision 0.9307570577164468 specificity 0.871625077886083 recall 0.9311511383377525 f1 0.9309313659715343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 15.149418115615845 s\n",
      "Accuracy 0.9378257291761909 precision 0.9375767169457658 specificity 0.885076933448204 recall 0.9378257291761909 f1 0.9376905615362312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 15.563582181930542 s\n",
      "Accuracy 0.9338026881228856 precision 0.9335807978937888 specificity 0.8778418880002815 recall 0.9338026881228856 f1 0.9336847461240431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 15.220629692077637 s\n",
      "Accuracy 0.9353570448934808 precision 0.935348132202366 specificity 0.8827331876484769 recall 0.9353570448934808 f1 0.935352578168306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 15.406388998031616 s\n",
      "Accuracy 0.9328883606107707 precision 0.9326387048236254 specificity 0.8782238050516662 recall 0.9328883606107707 f1 0.9327543234675284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 15.406015634536743 s\n",
      "Accuracy 0.9336198226204626 precision 0.9337133104284705 specificity 0.8811051548239878 recall 0.9336198226204626 f1 0.9336655350037598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 15.22848129272461 s\n",
      "Accuracy 0.9275852610405048 precision 0.9278581567102793 specificity 0.8720018698958837 recall 0.9275852610405048 f1 0.927714838096544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 15.240212678909302 s\n",
      "Accuracy 0.9356313431471153 precision 0.9350755162199312 specificity 0.87182976561851 recall 0.9356313431471153 f1 0.935298275683453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 15.478510618209839 s\n",
      "Accuracy 0.9360885069031727 precision 0.9357708589420242 specificity 0.8785432073381516 recall 0.9360885069031727 f1 0.935913705073134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 15.591231107711792 s\n",
      "Accuracy 0.9327054951083478 precision 0.9328604522681975 specificity 0.8793533228621299 recall 0.9327054951083478 f1 0.9327803315024457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 15.533947706222534 s\n",
      "Accuracy 0.9334369571180396 precision 0.9339290939253219 specificity 0.884280628453434 recall 0.9334369571180396 f1 0.9336593002877245\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 15.492359399795532 s\n",
      "Accuracy 0.9354484776446923 precision 0.9352572942018995 specificity 0.8783623275496298 recall 0.9354484776446923 f1 0.9353478001003179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 15.112121343612671 s\n",
      "Accuracy 0.93407698637652 precision 0.9339108556947356 specificity 0.8781380106915583 recall 0.93407698637652 f1 0.9339901707285024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 15.332884788513184 s\n",
      "Accuracy 0.9347170156350004 precision 0.935113766707069 specificity 0.8856527835742877 recall 0.9347170156350004 f1 0.934898850632885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 15.435405254364014 s\n",
      "Accuracy 0.9298710798207918 precision 0.9299192778275789 specificity 0.8748526511288768 recall 0.9298710798207918 f1 0.9298949238700581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 15.162537336349487 s\n",
      "Accuracy 0.9362713724055957 precision 0.936892485662366 specificity 0.8937586321538977 recall 0.9362713724055957 f1 0.9365413834035635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 15.26112151145935 s\n",
      "Accuracy 0.9327054951083478 precision 0.9326524355082916 specificity 0.8804230231142888 recall 0.9327054951083478 f1 0.9326785981327489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 15.26311445236206 s\n",
      "Accuracy 0.934259851878943 precision 0.9339196938857582 specificity 0.8756540079927385 recall 0.934259851878943 f1 0.9340722237411062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 15.273831367492676 s\n",
      "Accuracy 0.934259851878943 precision 0.9347772903650133 specificity 0.8866037891584346 recall 0.934259851878943 f1 0.9344918073091437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 15.290337085723877 s\n",
      "Accuracy 0.9309682728353296 precision 0.9317218759281223 specificity 0.8829500890104754 recall 0.9309682728353296 f1 0.9312965909363331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 14.985551118850708 s\n",
      "Accuracy 0.9350827466398464 precision 0.9356081254125159 specificity 0.8878269428877992 recall 0.9350827466398464 f1 0.935317517827074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 14.962724208831787 s\n",
      "Accuracy 0.9306939745816951 precision 0.931059779053693 specificity 0.8797500725681068 recall 0.9306939745816951 f1 0.930863689476814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 15.039745807647705 s\n",
      "Accuracy 0.9324311968547133 precision 0.9321617643618925 specificity 0.8786098152616763 recall 0.9324311968547133 f1 0.9322854123360047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 15.329887866973877 s\n",
      "Accuracy 0.9357227758983268 precision 0.9360190731172102 specificity 0.8867657732606772 recall 0.9357227758983268 f1 0.9358609714621394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 15.454877853393555 s\n",
      "Accuracy 0.9338941208740971 precision 0.9340130975027361 specificity 0.8838942030434611 recall 0.9338941208740971 f1 0.9339518803098061\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 15.236637830734253 s\n",
      "Accuracy 0.9292310505623114 precision 0.9298626069046305 specificity 0.8823553885484827 recall 0.9292310505623114 f1 0.9295108016095417\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 15.240463018417358 s\n",
      "Accuracy 0.9346255828837889 precision 0.9347978725098791 specificity 0.8868100222504588 recall 0.9346255828837889 f1 0.934708047626518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 15.08977222442627 s\n",
      "Accuracy 0.9313340038401755 precision 0.9316973912875157 specificity 0.8779986991362315 recall 0.9313340038401755 f1 0.9315030691483392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 15.374919652938843 s\n",
      "Accuracy 0.9354484776446923 precision 0.9351208266893531 specificity 0.8807310469681935 recall 0.9354484776446923 f1 0.9352664258061753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 15.426860570907593 s\n",
      "Accuracy 0.9354484776446923 precision 0.9355011675768087 specificity 0.8860556452598944 recall 0.9354484776446923 f1 0.935474453118562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 15.35547423362732 s\n",
      "Accuracy 0.9333455243668282 precision 0.9336677170232374 specificity 0.8840300230162266 recall 0.9333455243668282 f1 0.9334954670070041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 15.452027082443237 s\n",
      "Accuracy 0.9345341501325775 precision 0.9346585315326703 specificity 0.8869179578284967 recall 0.9345341501325775 f1 0.9345943491861958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 15.246679544448853 s\n",
      "Accuracy 0.9366371034104416 precision 0.937306557008442 specificity 0.894097588755421 recall 0.9366371034104416 f1 0.936925787387361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 15.126172542572021 s\n",
      "Accuracy 0.9375514309225564 precision 0.9374250119817849 specificity 0.8840735795318512 recall 0.9375514309225564 f1 0.9374858600339037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 15.295043706893921 s\n",
      "Accuracy 0.9362713724055957 precision 0.9362803929139971 specificity 0.8828577258703945 recall 0.9362713724055957 f1 0.936275872182237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 15.13460397720337 s\n",
      "Accuracy 0.9358142086495382 precision 0.9356625941725365 specificity 0.8823328407725715 recall 0.9358142086495382 f1 0.9357350376392656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 14.98952054977417 s\n",
      "Accuracy 0.9284081558014081 precision 0.9286874794803592 specificity 0.874117140865268 recall 0.9284081558014081 f1 0.9285404112075476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 15.379582643508911 s\n",
      "Accuracy 0.9333455243668282 precision 0.9332094605101087 specificity 0.8759211978501102 recall 0.9333455243668282 f1 0.9332751468644281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 15.294394254684448 s\n",
      "Accuracy 0.937277132668922 precision 0.9374367548447721 specificity 0.8899116558540849 recall 0.937277132668922 f1 0.937353599800481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 15.057849645614624 s\n",
      "Accuracy 0.9317911675962329 precision 0.9320027924517766 specificity 0.8811118772499508 recall 0.9317911675962329 f1 0.9318920548301891\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 15.312912464141846 s\n",
      "Accuracy 0.93407698637652 precision 0.933738008056803 specificity 0.8758647067242419 recall 0.93407698637652 f1 0.9338899936995406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 15.055904865264893 s\n",
      "Accuracy 0.931425436591387 precision 0.9317072867107259 specificity 0.87874397118712 recall 0.931425436591387 f1 0.9315583163106675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 15.199049472808838 s\n",
      "Accuracy 0.9330712261131937 precision 0.9330881223989067 specificity 0.8864690377081361 recall 0.9330712261131937 f1 0.9330796342657961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 15.156035423278809 s\n",
      "Accuracy 0.9347170156350004 precision 0.934899786290066 specificity 0.886542428584233 recall 0.9347170156350004 f1 0.9348043132143025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 15.122379064559937 s\n",
      "Accuracy 0.9322483313522903 precision 0.9320309728339045 specificity 0.8758843947011771 recall 0.9322483313522903 f1 0.9321332233141468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 15.093538284301758 s\n",
      "Accuracy 0.9359056414007497 precision 0.9359325000248563 specificity 0.8838820569193925 recall 0.9359056414007497 f1 0.9359189771172963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 14.940641403198242 s\n",
      "Accuracy 0.9351741793910578 precision 0.9348629038429915 specificity 0.8797784249799702 recall 0.9351741793910578 f1 0.9350027877395455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 14.990167140960693 s\n",
      "Accuracy 0.934442717381366 precision 0.9343622577591028 specificity 0.8795561602318234 recall 0.934442717381366 f1 0.9344016452834839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 15.378117084503174 s\n",
      "Accuracy 0.9360885069031727 precision 0.936044042882429 specificity 0.8820859280598231 recall 0.9360885069031727 f1 0.9360660131335441\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 15.459731578826904 s\n",
      "Accuracy 0.9345341501325775 precision 0.934776131980478 specificity 0.8866956681736355 recall 0.9345341501325775 f1 0.9346482347662879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 15.146389484405518 s\n",
      "Accuracy 0.9334369571180396 precision 0.933271766913718 specificity 0.8740154823940293 recall 0.9334369571180396 f1 0.9333509583916566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 15.159588813781738 s\n",
      "Accuracy 0.9339855536253086 precision 0.9338634810702456 specificity 0.8798523549470694 recall 0.9339855536253086 f1 0.9339224942158018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 15.124512434005737 s\n",
      "Accuracy 0.9354484776446923 precision 0.9353625660730329 specificity 0.8830162543885769 recall 0.9354484776446923 f1 0.9354044875661848\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 15.187570095062256 s\n",
      "Accuracy 0.9320654658498674 precision 0.9316975808849336 specificity 0.8746940732947998 recall 0.9320654658498674 f1 0.9318607544501786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 15.254318237304688 s\n",
      "Accuracy 0.931425436591387 precision 0.9309718903578653 specificity 0.8693778181843925 recall 0.931425436591387 f1 0.9311683768547165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 15.029001474380493 s\n",
      "Accuracy 0.9356313431471153 precision 0.9360925556700688 specificity 0.8871235993289333 recall 0.9356313431471153 f1 0.9358399595337273\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 14.850913763046265 s\n",
      "Accuracy 0.93160830209381 precision 0.9319855332038464 specificity 0.8776465732091003 recall 0.93160830209381 f1 0.9317834976236516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 15.23823595046997 s\n",
      "Accuracy 0.9371856999177105 precision 0.9374895411435291 specificity 0.891292764793544 recall 0.9371856999177105 f1 0.9373263965696134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 15.119039535522461 s\n",
      "Accuracy 0.9338026881228856 precision 0.9335819325569413 specificity 0.8782598660381844 recall 0.9338026881228856 f1 0.9336853256492711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 15.225030422210693 s\n",
      "Accuracy 0.934259851878943 precision 0.9344892876252123 specificity 0.8798267222439343 recall 0.934259851878943 f1 0.9343690224990272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 15.130364656448364 s\n",
      "Accuracy 0.9379171619274024 precision 0.9377642465843223 specificity 0.8866033552704602 recall 0.9379171619274024 f1 0.9378369501726214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 15.253392219543457 s\n",
      "Accuracy 0.9348998811374234 precision 0.934673573679366 specificity 0.882068578396557 recall 0.9348998811374234 f1 0.9347786782803716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 15.42090892791748 s\n",
      "Accuracy 0.9313340038401755 precision 0.9313057559191109 specificity 0.8753280052833727 recall 0.9313340038401755 f1 0.9313197872499296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 15.363373756408691 s\n",
      "Accuracy 0.9306939745816951 precision 0.9305640438689531 specificity 0.872926779924803 recall 0.9306939745816951 f1 0.9306269914608699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 15.268418312072754 s\n",
      "Accuracy 0.9332540916156167 precision 0.9331134599181666 specificity 0.8782184170899862 recall 0.9332540916156167 f1 0.9331811354118728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 15.10290265083313 s\n",
      "Accuracy 0.9317911675962329 precision 0.932909842393405 specificity 0.8899580289437983 recall 0.9317911675962329 f1 0.9322497459323975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 15.413245677947998 s\n",
      "Accuracy 0.9332540916156167 precision 0.933593760976053 specificity 0.8875731793273888 recall 0.9332540916156167 f1 0.9334108560111817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 15.18138575553894 s\n",
      "Accuracy 0.9298710798207918 precision 0.9295033880873401 specificity 0.8672088162205238 recall 0.9298710798207918 f1 0.9296698101540803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 15.315052270889282 s\n",
      "Accuracy 0.9308768400841181 precision 0.9305831539155008 specificity 0.873041377319095 recall 0.9308768400841181 f1 0.9307181522060167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 15.223047494888306 s\n",
      "Accuracy 0.9350827466398464 precision 0.9352470983992285 specificity 0.8862610639002542 recall 0.9350827466398464 f1 0.935161597589573\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 15.24739122390747 s\n",
      "Accuracy 0.9348998811374234 precision 0.9348828066015041 specificity 0.885591452270059 recall 0.9348998811374234 f1 0.9348913030691363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 15.098865032196045 s\n",
      "Accuracy 0.9338026881228856 precision 0.933857764015091 specificity 0.8815420270459272 recall 0.9338026881228856 f1 0.9338298552683545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 15.134730339050293 s\n",
      "Accuracy 0.9343512846301545 precision 0.9347781697453575 specificity 0.8923352504811124 recall 0.9343512846301545 f1 0.9345435396367128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 15.451399326324463 s\n",
      "Accuracy 0.9327969278595593 precision 0.9333139693359718 specificity 0.8816317568800461 recall 0.9327969278595593 f1 0.9330305919531022\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 15.245893478393555 s\n",
      "Accuracy 0.931242571088964 precision 0.9313370032891479 specificity 0.8788634178364 recall 0.931242571088964 f1 0.9312887693600505\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 15.36354947090149 s\n",
      "Accuracy 0.9335283898692511 precision 0.9337639701024083 specificity 0.8847658585534434 recall 0.9335283898692511 f1 0.9336398061282039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 15.301421880722046 s\n",
      "Accuracy 0.928591021303831 precision 0.9283367007020539 specificity 0.872206632629348 recall 0.928591021303831 f1 0.9284553774309557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 15.481125831604004 s\n",
      "Accuracy 0.9336198226204626 precision 0.9331803548815479 specificity 0.8728225794747738 recall 0.9336198226204626 f1 0.9333696024649568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 15.291590690612793 s\n",
      "Accuracy 0.9378257291761909 precision 0.9377586004185684 specificity 0.8867269091395181 recall 0.9378257291761909 f1 0.9377914974752947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 15.120594024658203 s\n",
      "Accuracy 0.9305111090792721 precision 0.9305302499305299 specificity 0.874956262707559 recall 0.9305111090792721 f1 0.9305206385254592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 15.341687679290771 s\n",
      "Accuracy 0.9389229221907287 precision 0.9387414905670156 specificity 0.8842332928067755 recall 0.9389229221907287 f1 0.9388270716835405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 15.13399600982666 s\n",
      "Accuracy 0.9332540916156167 precision 0.9333725886754219 specificity 0.8767740451215303 recall 0.9332540916156167 f1 0.933311831907195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 15.30399227142334 s\n",
      "Accuracy 0.9358142086495382 precision 0.9361305911783739 specificity 0.8898329332747117 recall 0.9358142086495382 f1 0.9359605690391323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 15.428539514541626 s\n",
      "Accuracy 0.937459998171345 precision 0.9373792919577126 specificity 0.8888881561129952 recall 0.937459998171345 f1 0.9374186173031012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 15.429013013839722 s\n",
      "Accuracy 0.9339855536253086 precision 0.9337991572515132 specificity 0.8797434870775702 recall 0.9339855536253086 f1 0.9338873704865094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 15.335890054702759 s\n",
      "Accuracy 0.9320654658498674 precision 0.931830404745421 specificity 0.8750754820233458 recall 0.9320654658498674 f1 0.931940429506825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 15.128827333450317 s\n",
      "Accuracy 0.9305111090792721 precision 0.930417750232376 specificity 0.8735264624876238 recall 0.9305111090792721 f1 0.9304634031079181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 15.203625440597534 s\n",
      "Accuracy 0.9327054951083478 precision 0.9326883125184732 specificity 0.8838573112499785 recall 0.9327054951083478 f1 0.9326968635567653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 15.404296398162842 s\n",
      "Accuracy 0.934259851878943 precision 0.9350057335696922 specificity 0.8921210895118883 recall 0.934259851878943 f1 0.9345788538308167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 15.190757751464844 s\n",
      "Accuracy 0.9357227758983268 precision 0.9356804574698978 specificity 0.8858340000638857 recall 0.9357227758983268 f1 0.9357013601631149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 14.923051118850708 s\n",
      "Accuracy 0.9331626588644052 precision 0.9329474702446222 specificity 0.8771471037976941 recall 0.9331626588644052 f1 0.93304861400258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 15.413923978805542 s\n",
      "Accuracy 0.9367285361616531 precision 0.936614053226664 specificity 0.8863168552819669 recall 0.9367285361616531 f1 0.9366692743679903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 15.414074182510376 s\n",
      "Accuracy 0.9338941208740971 precision 0.9338849890445382 specificity 0.8799279209317129 recall 0.9338941208740971 f1 0.9338895446040943\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 15.376781940460205 s\n",
      "Accuracy 0.9329797933619822 precision 0.9329533449525889 specificity 0.8817010086236058 recall 0.9329797933619822 f1 0.9329664775313053\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 15.353904724121094 s\n",
      "Accuracy 0.93407698637652 precision 0.9340172720792882 specificity 0.8837314964376647 recall 0.93407698637652 f1 0.9340466301832112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 15.234437465667725 s\n",
      "Accuracy 0.9322483313522903 precision 0.9325733031497553 specificity 0.8825891909509517 recall 0.9322483313522903 f1 0.9323997142412865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 15.376951932907104 s\n",
      "Accuracy 0.9378257291761909 precision 0.9372823112962766 specificity 0.8818125766315797 recall 0.9378257291761909 f1 0.9374807977694932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 15.389487743377686 s\n",
      "Accuracy 0.9378257291761909 precision 0.9378094161454223 specificity 0.8906763045486916 recall 0.9378257291761909 f1 0.937817531615322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 15.392430782318115 s\n",
      "Accuracy 0.9333455243668282 precision 0.9335556889756066 specificity 0.886528761135348 recall 0.9333455243668282 f1 0.9334452669871743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 15.409102439880371 s\n",
      "Accuracy 0.9303282435768492 precision 0.9303090392694715 specificity 0.8733744837601962 recall 0.9303282435768492 f1 0.9303186003057929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 15.395278692245483 s\n",
      "Accuracy 0.9325226296059248 precision 0.9325975168718987 specificity 0.8797647756135513 recall 0.9325226296059248 f1 0.9325594167763933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 15.44325065612793 s\n",
      "Accuracy 0.9354484776446923 precision 0.9354308666570936 specificity 0.8834608672945989 recall 0.9354484776446923 f1 0.9354396307416767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 15.381661176681519 s\n",
      "Accuracy 0.9327054951083478 precision 0.9328781593684601 specificity 0.8807563318165083 recall 0.9327054951083478 f1 0.9327885006119956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 15.042047500610352 s\n",
      "Accuracy 0.9292310505623114 precision 0.9292117819602929 specificity 0.8724800187100201 recall 0.9292310505623114 f1 0.9292213754117205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 15.245821714401245 s\n",
      "Accuracy 0.9315168693425985 precision 0.9316011654062054 specificity 0.879419321361618 recall 0.9315168693425985 f1 0.9315581929740483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 15.09630537033081 s\n",
      "Accuracy 0.9365456706592301 precision 0.9368522535973255 specificity 0.887403670649302 recall 0.9365456706592301 f1 0.9366882920683677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 15.16786789894104 s\n",
      "Accuracy 0.9360885069031727 precision 0.9364259444418453 specificity 0.8874685293127983 recall 0.9360885069031727 f1 0.9362445105833718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 15.292648553848267 s\n",
      "Accuracy 0.9353570448934808 precision 0.9358105797841555 specificity 0.8903260413725448 recall 0.9353570448934808 f1 0.9355612462222582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 15.122619152069092 s\n",
      "Accuracy 0.9348998811374234 precision 0.9348117985028713 specificity 0.880712859212008 recall 0.9348998811374234 f1 0.9348548007875307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 15.209379196166992 s\n",
      "Accuracy 0.9315168693425985 precision 0.9318791520965714 specificity 0.8783892555160259 recall 0.9315168693425985 f1 0.9316853801904048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 15.109638214111328 s\n",
      "Accuracy 0.9359970741519612 precision 0.9364041951259974 specificity 0.8889959799598156 recall 0.9359970741519612 f1 0.936182418767499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 15.02592134475708 s\n",
      "Accuracy 0.9341684191277315 precision 0.9342963582309344 specificity 0.8844698995005339 recall 0.9341684191277315 f1 0.934230382527578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 15.291226148605347 s\n",
      "Accuracy 0.93407698637652 precision 0.934050357290162 specificity 0.8817614793743508 recall 0.93407698637652 f1 0.9340635792613264\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 15.414781332015991 s\n",
      "Accuracy 0.9375514309225564 precision 0.9377731032310366 specificity 0.8921239335233699 recall 0.9375514309225564 f1 0.9376558471595396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 15.371797323226929 s\n",
      "Accuracy 0.9294139160647343 precision 0.9294139160647343 specificity 0.8745746369702453 recall 0.9294139160647343 f1 0.9294139160647343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 15.329931259155273 s\n",
      "Accuracy 0.9346255828837889 precision 0.9341521543152745 specificity 0.8766562377305254 recall 0.9346255828837889 f1 0.9343477464532232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 15.175721168518066 s\n",
      "Accuracy 0.9337112553716741 precision 0.9338356328289791 specificity 0.880101019953246 recall 0.9337112553716741 f1 0.9337716899576436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 15.277057886123657 s\n",
      "Accuracy 0.9322483313522903 precision 0.9321483391278461 specificity 0.8764113661208874 recall 0.9322483313522903 f1 0.9321970878247435\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 15.700629711151123 s\n",
      "Accuracy 0.9332540916156167 precision 0.9335133192322171 specificity 0.8868405972539574 recall 0.9332540916156167 f1 0.9333757956998888\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 15.543216466903687 s\n",
      "Accuracy 0.9317911675962329 precision 0.9314062365766267 specificity 0.8751931411573036 recall 0.9317911675962329 f1 0.931575198278849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 15.490683555603027 s\n",
      "Accuracy 0.9335283898692511 precision 0.9336099185607077 specificity 0.8833380248426704 recall 0.9335283898692511 f1 0.9335683276866826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 15.57992172241211 s\n",
      "Accuracy 0.9302368108256377 precision 0.9299916860622993 specificity 0.870649831382192 recall 0.9302368108256377 f1 0.9301067368762308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 15.422083854675293 s\n",
      "Accuracy 0.9349913138886349 precision 0.9347304710854409 specificity 0.877979008056904 recall 0.9349913138886349 f1 0.9348508538579021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 15.425848484039307 s\n",
      "Accuracy 0.9354484776446923 precision 0.93532868555753 specificity 0.8821207296018165 recall 0.9354484776446923 f1 0.9353865493235833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 15.416108131408691 s\n",
      "Accuracy 0.9360885069031727 precision 0.9359254399743945 specificity 0.8806413972719204 recall 0.9360885069031727 f1 0.9360031889777054\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 15.07795763015747 s\n",
      "Accuracy 0.9305111090792721 precision 0.9308100226788519 specificity 0.8796074479633541 recall 0.9305111090792721 f1 0.9306514367325541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 15.17315125465393 s\n",
      "Accuracy 0.9337112553716741 precision 0.9337390946314158 specificity 0.8796854537815036 recall 0.9337112553716741 f1 0.9337250817468855\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 15.306986331939697 s\n",
      "Accuracy 0.9338026881228856 precision 0.9335803707573278 specificity 0.8776843870289339 recall 0.9338026881228856 f1 0.9336845279643636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 15.446539402008057 s\n",
      "Accuracy 0.9358142086495382 precision 0.935761751875608 specificity 0.8830217074718433 recall 0.9358142086495382 f1 0.9357876060374835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 15.397026300430298 s\n",
      "Accuracy 0.9330712261131937 precision 0.9328184321940738 specificity 0.8773058268768694 recall 0.9330712261131937 f1 0.9329355690651352\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 15.205719947814941 s\n",
      "Accuracy 0.934442717381366 precision 0.9341608194592599 specificity 0.8799891576751049 recall 0.934442717381366 f1 0.9342891633569258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 15.365296840667725 s\n",
      "Accuracy 0.934259851878943 precision 0.9341322432976872 specificity 0.8816714873709423 recall 0.934259851878943 f1 0.9341937377467392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 15.505282402038574 s\n",
      "Accuracy 0.931242571088964 precision 0.931242571088964 specificity 0.87694558727552 recall 0.931242571088964 f1 0.931242571088964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 15.000077962875366 s\n",
      "Accuracy 0.9292310505623114 precision 0.9293068941869107 specificity 0.8767656593521681 recall 0.9292310505623114 f1 0.9292683278446332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 14.98172402381897 s\n",
      "Accuracy 0.937094267166499 precision 0.9373694117421918 specificity 0.8906706924036492 recall 0.937094267166499 f1 0.9372225565532336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 15.321869373321533 s\n",
      "Accuracy 0.934442717381366 precision 0.9346315646031286 specificity 0.8879102708897201 recall 0.934442717381366 f1 0.9345326724152936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 15.27878189086914 s\n",
      "Accuracy 0.9304196763280607 precision 0.9302634471795813 specificity 0.8727314567274144 recall 0.9304196763280607 f1 0.9303385944317732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 14.92801308631897 s\n",
      "Accuracy 0.9348998811374234 precision 0.9355170919268891 specificity 0.8916838910136027 recall 0.9348998811374234 f1 0.9351694144184614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 15.652330160140991 s\n",
      "Accuracy 0.9324311968547133 precision 0.9328045834590967 specificity 0.8817860913193213 recall 0.9324311968547133 f1 0.9326038395418954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 15.00121259689331 s\n",
      "Accuracy 0.93160830209381 precision 0.9314205924115316 specificity 0.8780025905574298 recall 0.93160830209381 f1 0.9315095362555392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 15.175040483474731 s\n",
      "Accuracy 0.9359970741519612 precision 0.9360855106822695 specificity 0.8870019228922873 recall 0.9359970741519612 f1 0.9360402632480557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 15.356507301330566 s\n",
      "Accuracy 0.9396543842004206 precision 0.9397571892718996 specificity 0.8922238701111894 recall 0.9396543842004206 f1 0.9397042830018025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 15.4502432346344 s\n",
      "Accuracy 0.9357227758983268 precision 0.9360662730868375 specificity 0.8907988276130445 recall 0.9357227758983268 f1 0.9358805730936978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 15.197546005249023 s\n",
      "Accuracy 0.9313340038401755 precision 0.9319528797967528 specificity 0.8839259086896543 recall 0.9313340038401755 f1 0.9316081420239556\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 15.266466856002808 s\n",
      "Accuracy 0.9370028344152875 precision 0.9368131627340545 specificity 0.8830310920445356 recall 0.9370028344152875 f1 0.9369024680284067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 15.133171319961548 s\n",
      "Accuracy 0.9331626588644052 precision 0.9330694433827039 specificity 0.8825808280919447 recall 0.9331626588644052 f1 0.9331148249996589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 15.221513509750366 s\n",
      "Accuracy 0.9366371034104416 precision 0.9374028877817681 specificity 0.8971741681008543 recall 0.9366371034104416 f1 0.9369598296565582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 15.053454637527466 s\n",
      "Accuracy 0.93407698637652 precision 0.9337824546108369 specificity 0.8763098960035193 recall 0.93407698637652 f1 0.9339169641192445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 15.306704759597778 s\n",
      "Accuracy 0.9358142086495382 precision 0.9361592231722186 specificity 0.8880612057534242 recall 0.9358142086495382 f1 0.9359733330780077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 15.227041482925415 s\n",
      "Accuracy 0.9318826003474444 precision 0.9319302707523552 specificity 0.876950815901614 recall 0.9318826003474444 f1 0.9319061779487723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 15.083608865737915 s\n",
      "Accuracy 0.9325226296059248 precision 0.9324318143515142 specificity 0.8769372451231258 recall 0.9325226296059248 f1 0.9324761902764004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 15.289718389511108 s\n",
      "Accuracy 0.9397458169516321 precision 0.9400605815878722 specificity 0.8953951796533127 recall 0.9397458169516321 f1 0.9398904645720788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 15.463948965072632 s\n",
      "Accuracy 0.9320654658498674 precision 0.9321499686921102 specificity 0.879538227693898 recall 0.9320654658498674 f1 0.9321068889924778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 15.22343397140503 s\n",
      "Accuracy 0.9341684191277315 precision 0.934782876795538 specificity 0.8914812290652264 recall 0.9341684191277315 f1 0.9344368330897737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 15.158360719680786 s\n",
      "Accuracy 0.9337112553716741 precision 0.933971764726676 specificity 0.8835209502518968 recall 0.9337112553716741 f1 0.933834016142116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 15.30968713760376 s\n",
      "Accuracy 0.9319740330986559 precision 0.9325462421158212 specificity 0.8857606145483574 recall 0.9319740330986559 f1 0.9322284240605345\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 15.253062009811401 s\n",
      "Accuracy 0.9333455243668282 precision 0.9333898253292554 specificity 0.8838357928720652 recall 0.9333455243668282 f1 0.9333674210941383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 14.823580503463745 s\n",
      "Accuracy 0.9363628051568071 precision 0.9363266237530072 specificity 0.8811247755609983 recall 0.9363628051568071 f1 0.9363445456959467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 15.306591510772705 s\n",
      "Accuracy 0.9364542379080186 precision 0.9368299569411468 specificity 0.8889414502835739 recall 0.9364542379080186 f1 0.936626330605833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 15.171210289001465 s\n",
      "Accuracy 0.9320654658498674 precision 0.9322925415686418 specificity 0.879368739159224 recall 0.9320654658498674 f1 0.9321735649621067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 15.862821102142334 s\n",
      "Accuracy 0.9348084483862119 precision 0.9351086398065341 specificity 0.8850932901813483 recall 0.9348084483862119 f1 0.9349486097475183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 15.662013292312622 s\n",
      "Accuracy 0.9334369571180396 precision 0.933998410885923 specificity 0.8883810108728656 recall 0.9334369571180396 f1 0.9336858773065444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 15.417628526687622 s\n",
      "Accuracy 0.9353570448934808 precision 0.935604101900648 specificity 0.8888529994964082 recall 0.9353570448934808 f1 0.9354731339435347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 15.385164976119995 s\n",
      "Accuracy 0.9306939745816951 precision 0.9302874647718835 specificity 0.8702914868724976 recall 0.9306939745816951 f1 0.93046699065258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 15.351234197616577 s\n",
      "Accuracy 0.9352656121422693 precision 0.9355999890111886 specificity 0.8901685304638428 recall 0.9352656121422693 f1 0.9354196213193869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 15.316524505615234 s\n",
      "Accuracy 0.9288653195574654 precision 0.9286100545706136 specificity 0.8693392146951732 recall 0.9288653195574654 f1 0.9287296693751275\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 15.46800708770752 s\n",
      "Accuracy 0.9362713724055957 precision 0.9367561430956194 specificity 0.889544429397593 recall 0.9362713724055957 f1 0.9364888838881629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 15.319583177566528 s\n",
      "Accuracy 0.9348084483862119 precision 0.9353053457986424 specificity 0.8864634018540003 recall 0.9348084483862119 f1 0.9350320550369544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 15.353400468826294 s\n",
      "Accuracy 0.9297796470695803 precision 0.9297607397192618 specificity 0.8744281862129927 recall 0.9297796470695803 f1 0.9297701526537409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 15.248244762420654 s\n",
      "Accuracy 0.9328883606107707 precision 0.9334837633700921 specificity 0.8865996619045841 recall 0.9328883606107707 f1 0.9331518330321489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 15.133595943450928 s\n",
      "Accuracy 0.9323397641035018 precision 0.9324153087180493 specificity 0.8789230874630333 recall 0.9323397641035018 f1 0.932376878788651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 15.621623277664185 s\n",
      "Accuracy 0.9345341501325775 precision 0.9347401539051072 specificity 0.8850528702013107 recall 0.9345341501325775 f1 0.9346321783704422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 15.363167762756348 s\n",
      "Accuracy 0.9329797933619822 precision 0.933177742723436 specificity 0.8832464369530656 recall 0.9329797933619822 f1 0.9330742714187754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 15.49825143814087 s\n",
      "Accuracy 0.9295053488159458 precision 0.9298400849035371 specificity 0.8782642427044612 recall 0.9295053488159458 f1 0.9296617030369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 15.128374576568604 s\n",
      "Accuracy 0.93407698637652 precision 0.933739662096461 specificity 0.8794123243466707 recall 0.93407698637652 f1 0.9338893658319929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 15.131792545318604 s\n",
      "Accuracy 0.9321568986010789 precision 0.9324622172003386 specificity 0.8848380967063585 recall 0.9321568986010789 f1 0.9322992311241692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 15.40796947479248 s\n",
      "Accuracy 0.931425436591387 precision 0.931695058125728 specificity 0.8824922035002639 recall 0.931425436591387 f1 0.9315523273917428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 15.109806060791016 s\n",
      "Accuracy 0.9362713724055957 precision 0.9361473611020997 specificity 0.8849400151606929 recall 0.9362713724055957 f1 0.9362070445583287\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 15.39232087135315 s\n",
      "Accuracy 0.9338941208740971 precision 0.9332181753994785 specificity 0.8710942998608889 recall 0.9338941208740971 f1 0.9334580825379567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 15.491244316101074 s\n",
      "Accuracy 0.934259851878943 precision 0.9342341985489003 specificity 0.8848146093647552 recall 0.934259851878943 f1 0.9342469337000481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 15.353925228118896 s\n",
      "Accuracy 0.9318826003474444 precision 0.9318733965667186 specificity 0.8781616059313773 recall 0.9318826003474444 f1 0.9318779882240934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 15.191336154937744 s\n",
      "Accuracy 0.9360885069031727 precision 0.9356890285250091 specificity 0.8777954551607173 recall 0.9360885069031727 f1 0.9358614677897115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 15.204447031021118 s\n",
      "Accuracy 0.9365456706592301 precision 0.9363297831929034 specificity 0.8813299177323515 recall 0.9365456706592301 f1 0.9364306466875437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 15.05692720413208 s\n",
      "Accuracy 0.9293224833135229 precision 0.9298496836789708 specificity 0.8774755389966854 recall 0.9293224833135229 f1 0.9295616372857424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 15.109418392181396 s\n",
      "Accuracy 0.9320654658498674 precision 0.9318608654859674 specificity 0.8744913327551396 recall 0.9320654658498674 f1 0.9319576995038502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 15.220999956130981 s\n",
      "Accuracy 0.9315168693425985 precision 0.9315835543656437 specificity 0.8774040613609991 recall 0.9315168693425985 f1 0.9315497093074497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 15.353937149047852 s\n",
      "Accuracy 0.9373685654201335 precision 0.9370991211081481 specificity 0.8847481313651681 recall 0.9373685654201335 f1 0.9372211419117581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 15.462805271148682 s\n",
      "Accuracy 0.9307854073329066 precision 0.9306860292337824 specificity 0.8761614583710073 recall 0.9307854073329066 f1 0.9307344864541154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 15.347878217697144 s\n",
      "Accuracy 0.9318826003474444 precision 0.9321063489607125 specificity 0.8805127766698665 recall 0.9318826003474444 f1 0.9319890713991903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 15.190079689025879 s\n",
      "Accuracy 0.9334369571180396 precision 0.9334551167739151 specificity 0.881043718793376 recall 0.9334369571180396 f1 0.9334459958610822\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 15.304743766784668 s\n",
      "Accuracy 0.9332540916156167 precision 0.9336664728445057 specificity 0.8860568818103389 recall 0.9332540916156167 f1 0.9334423321851884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 15.450268268585205 s\n",
      "Accuracy 0.9332540916156167 precision 0.932944171178303 specificity 0.8775518614573388 recall 0.9332540916156167 f1 0.9330843009518986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 15.287585496902466 s\n",
      "Accuracy 0.9329797933619822 precision 0.9328810969617217 specificity 0.8778863733301016 recall 0.9329797933619822 f1 0.9329291966805667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 15.5248122215271 s\n",
      "Accuracy 0.9311511383377525 precision 0.9313772921984484 specificity 0.8791450185375111 recall 0.9311511383377525 f1 0.9312588189346872\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 15.431543350219727 s\n",
      "Accuracy 0.9323397641035018 precision 0.9323955599070216 specificity 0.879621924666994 recall 0.9323397641035018 f1 0.9323672934149869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 15.391747951507568 s\n",
      "Accuracy 0.9349913138886349 precision 0.9351240269818083 specificity 0.8878063906462745 recall 0.9349913138886349 f1 0.9350553820907646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 15.68754506111145 s\n",
      "Accuracy 0.9338941208740971 precision 0.9338500670579973 specificity 0.881664857651363 recall 0.9338941208740971 f1 0.9338718373453115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 15.577298402786255 s\n",
      "Accuracy 0.9359970741519612 precision 0.936361446459649 specificity 0.8887199578724105 recall 0.9359970741519612 f1 0.9361643539802806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 15.428817987442017 s\n",
      "Accuracy 0.9339855536253086 precision 0.9339315110205704 specificity 0.879609145951944 recall 0.9339855536253086 f1 0.9339581593382816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 15.260403394699097 s\n",
      "Accuracy 0.9339855536253086 precision 0.9339023328135142 specificity 0.8847072078401804 recall 0.9339855536253086 f1 0.933942931003959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 15.153568267822266 s\n",
      "Accuracy 0.937459998171345 precision 0.9373913168260966 specificity 0.8847325020620096 recall 0.937459998171345 f1 0.9374249866456025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 15.287008047103882 s\n",
      "Accuracy 0.9349913138886349 precision 0.9352776415363949 specificity 0.8890145585681566 recall 0.9349913138886349 f1 0.935124699187539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 15.243544578552246 s\n",
      "Accuracy 0.9319740330986559 precision 0.9323832390908721 specificity 0.8857940878123809 recall 0.9319740330986559 f1 0.9321608896223982\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 15.32544732093811 s\n",
      "Accuracy 0.9338941208740971 precision 0.9338852825328621 specificity 0.882598481994222 recall 0.9338941208740971 f1 0.9338896914658096\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 14.741572141647339 s\n",
      "Accuracy 0.9305111090792721 precision 0.9305511705081893 specificity 0.8715057772629784 recall 0.9305111090792721 f1 0.9305309735232842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 15.186941146850586 s\n",
      "Accuracy 0.93407698637652 precision 0.9336874180810366 specificity 0.8764923919379042 recall 0.93407698637652 f1 0.9338573289015446\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 15.0463547706604 s\n",
      "Accuracy 0.9345341501325775 precision 0.9349218428687621 specificity 0.8874259144321905 recall 0.9345341501325775 f1 0.9347116174081216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 15.399188756942749 s\n",
      "Accuracy 0.9330712261131937 precision 0.9332985578149962 specificity 0.8837665763081328 recall 0.9330712261131937 f1 0.9331790206164792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 15.231464147567749 s\n",
      "Accuracy 0.9359970741519612 precision 0.9358074923119916 specificity 0.8793166770267279 recall 0.9359970741519612 f1 0.9358971904034475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 15.053019523620605 s\n",
      "Accuracy 0.9354484776446923 precision 0.9358163280056948 specificity 0.8875783105692677 recall 0.9354484776446923 f1 0.9356175035340198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 15.356004476547241 s\n",
      "Accuracy 0.9336198226204626 precision 0.9336755566421997 specificity 0.880450319225751 recall 0.9336198226204626 f1 0.9336473177650456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 15.085540771484375 s\n",
      "Accuracy 0.9365456706592301 precision 0.9367633069524043 specificity 0.8894627677557259 recall 0.9365456706592301 f1 0.936648562453058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 15.342058897018433 s\n",
      "Accuracy 0.9300539453232147 precision 0.9299501686189613 specificity 0.8720735992044947 recall 0.9300539453232147 f1 0.9300008133255321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 15.422577857971191 s\n",
      "Accuracy 0.9321568986010789 precision 0.9324412611581194 specificity 0.8848084989088307 recall 0.9321568986010789 f1 0.932290008759121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 15.302047491073608 s\n",
      "Accuracy 0.9338941208740971 precision 0.933885178562306 specificity 0.8816555129507393 recall 0.9338941208740971 f1 0.9338896394389216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 15.135581970214844 s\n",
      "Accuracy 0.9367285361616531 precision 0.9362891443806197 specificity 0.8821054233127178 recall 0.9367285361616531 f1 0.9364691331913995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 15.37162709236145 s\n",
      "Accuracy 0.9381000274298253 precision 0.938247881046217 specificity 0.8916161677049698 recall 0.9381000274298253 f1 0.9381709710350237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 15.349361181259155 s\n",
      "Accuracy 0.9361799396543842 precision 0.9364162309989641 specificity 0.8896324235380314 recall 0.9361799396543842 f1 0.9362911562386437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 15.334867238998413 s\n",
      "Accuracy 0.9341684191277315 precision 0.9346945329376406 specificity 0.8870537736939056 recall 0.9341684191277315 f1 0.9344037235877546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 15.383365869522095 s\n",
      "Accuracy 0.9330712261131937 precision 0.9334003732785557 specificity 0.8848324071300899 recall 0.9330712261131937 f1 0.9332240288299419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 15.059048414230347 s\n",
      "Accuracy 0.9373685654201335 precision 0.9375307686642459 specificity 0.883715501821106 recall 0.9373685654201335 f1 0.9374465970075658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 15.416748046875 s\n",
      "Accuracy 0.9324311968547133 precision 0.9322333882092402 specificity 0.8774714874897545 recall 0.9324311968547133 f1 0.9323268738811988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 15.371535778045654 s\n",
      "Accuracy 0.9347170156350004 precision 0.9348941159607735 specificity 0.8889845029114749 recall 0.9347170156350004 f1 0.9348015229101234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 15.380568265914917 s\n",
      "Accuracy 0.9338026881228856 precision 0.9339099625623501 specificity 0.8854171155249755 recall 0.9338026881228856 f1 0.9338548638389507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 15.297593116760254 s\n",
      "Accuracy 0.9329797933619822 precision 0.9331790452727369 specificity 0.8827082362943355 recall 0.9329797933619822 f1 0.9330749122570788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 15.028987884521484 s\n",
      "Accuracy 0.9326140623571363 precision 0.9329289627267985 specificity 0.8795890061995388 recall 0.9326140623571363 f1 0.9327615607745323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 15.13807487487793 s\n",
      "Accuracy 0.9337112553716741 precision 0.9334766454516749 specificity 0.875997492999661 recall 0.9337112553716741 f1 0.9335863561941782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 15.35230541229248 s\n",
      "Accuracy 0.9281338575477737 precision 0.9278861200287116 specificity 0.8656668477067953 recall 0.9281338575477737 f1 0.9280030209731106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 15.335325717926025 s\n",
      "Accuracy 0.9350827466398464 precision 0.9349955752661679 specificity 0.8816557229015773 recall 0.9350827466398464 f1 0.9350381242662843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 15.151997804641724 s\n",
      "Accuracy 0.9338026881228856 precision 0.9340284833767706 specificity 0.8847844095354244 recall 0.9338026881228856 f1 0.933909698306163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 15.181459188461304 s\n",
      "Accuracy 0.937459998171345 precision 0.9373242105114341 specificity 0.8831573354514339 recall 0.937459998171345 f1 0.9373894101093233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 15.313127279281616 s\n",
      "Accuracy 0.9362713724055957 precision 0.9363540134334077 specificity 0.8838365453429119 recall 0.9362713724055957 f1 0.9363118453490231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 15.345983982086182 s\n",
      "Accuracy 0.93407698637652 precision 0.9340012867683983 specificity 0.8842366894803213 recall 0.93407698637652 f1 0.9340383139945163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 15.432556390762329 s\n",
      "Accuracy 0.9330712261131937 precision 0.9328171261142255 specificity 0.876887031501892 recall 0.9330712261131937 f1 0.932934900016204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 15.43962812423706 s\n",
      "Accuracy 0.9298710798207918 precision 0.9295561117717148 specificity 0.868781737482228 recall 0.9298710798207918 f1 0.9297009530910285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 15.122887134552002 s\n",
      "Accuracy 0.9333455243668282 precision 0.933336672556009 specificity 0.8821685183715748 recall 0.9333455243668282 f1 0.9333410882587769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 15.528540849685669 s\n",
      "Accuracy 0.9323397641035018 precision 0.9318003007540904 specificity 0.8732419221712663 recall 0.9323397641035018 f1 0.9320168352663376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 15.196130752563477 s\n",
      "Accuracy 0.9327969278595593 precision 0.9327359188567976 specificity 0.8813442562219518 recall 0.9327969278595593 f1 0.9327659252677146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 15.123039484024048 s\n",
      "Accuracy 0.9327969278595593 precision 0.9332351708937798 specificity 0.8872292119975599 recall 0.9327969278595593 f1 0.932995620385151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 15.077303886413574 s\n",
      "Accuracy 0.9356313431471153 precision 0.9358935973789079 specificity 0.8874742666283351 recall 0.9356313431471153 f1 0.9357543934550964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 15.214452743530273 s\n",
      "Accuracy 0.93160830209381 precision 0.93160830209381 specificity 0.8786267020225824 recall 0.93160830209381 f1 0.93160830209381\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 15.097806215286255 s\n",
      "Accuracy 0.9353570448934808 precision 0.9357456530433833 specificity 0.8900550377833217 recall 0.9353570448934808 f1 0.9355341960277539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 15.068063974380493 s\n",
      "Accuracy 0.9313340038401755 precision 0.9310231712021039 specificity 0.8746244350522616 recall 0.9313340038401755 f1 0.9311646028735835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 15.316028118133545 s\n",
      "Accuracy 0.9327969278595593 precision 0.9327011791372204 specificity 0.8802706477186631 recall 0.9327969278595593 f1 0.9327478195321249\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 15.309036016464233 s\n",
      "Accuracy 0.9305111090792721 precision 0.930274989669994 specificity 0.8710583959651803 recall 0.9305111090792721 f1 0.9303860755910349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 15.400957345962524 s\n",
      "Accuracy 0.9326140623571363 precision 0.9329425909598373 specificity 0.8819126173197049 recall 0.9326140623571363 f1 0.9327671516568131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 15.219127893447876 s\n",
      "Accuracy 0.9386486239370943 precision 0.9387275288785127 specificity 0.8889410119627218 recall 0.9386486239370943 f1 0.938687227513426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 15.572029113769531 s\n",
      "Accuracy 0.9334369571180396 precision 0.9336805631370815 specificity 0.8854519610338858 recall 0.9334369571180396 f1 0.9335518906140556\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 15.342056035995483 s\n",
      "Accuracy 0.937277132668922 precision 0.9373610142719947 specificity 0.891784728445717 recall 0.937277132668922 f1 0.9373180536641114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 15.789876461029053 s\n",
      "Accuracy 0.9289567523086769 precision 0.9292878198770188 specificity 0.8788438130184794 recall 0.9289567523086769 f1 0.9291113538512092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 15.11449384689331 s\n",
      "Accuracy 0.9352656121422693 precision 0.9350997672151059 specificity 0.8826847062209445 recall 0.9352656121422693 f1 0.9351785683186757\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 14.856056928634644 s\n",
      "Accuracy 0.937094267166499 precision 0.9370259908496118 specificity 0.8850128627014705 recall 0.937094267166499 f1 0.9370594614980324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 15.194961309432983 s\n",
      "Accuracy 0.9327969278595593 precision 0.9328997584120273 specificity 0.8809196004427223 recall 0.9327969278595593 f1 0.9328471035214462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 15.026297807693481 s\n",
      "Accuracy 0.9348084483862119 precision 0.9351448861587582 specificity 0.8868555346812763 recall 0.9348084483862119 f1 0.9349640838537985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 14.890066862106323 s\n",
      "Accuracy 0.9311511383377525 precision 0.9313739516890213 specificity 0.8804031190344904 recall 0.9311511383377525 f1 0.9312571768223109\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 15.16905164718628 s\n",
      "Accuracy 0.9353570448934808 precision 0.9358137178581852 specificity 0.8897788841490591 recall 0.9353570448934808 f1 0.9355627579764749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 15.118095397949219 s\n",
      "Accuracy 0.9336198226204626 precision 0.9334351695431089 specificity 0.8803126009593161 recall 0.9336198226204626 f1 0.9335225403527391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 15.166889905929565 s\n",
      "Accuracy 0.9322483313522903 precision 0.9322389310178458 specificity 0.8765707913227192 recall 0.9322483313522903 f1 0.9322436208492875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 15.197527170181274 s\n",
      "Accuracy 0.9381914601810368 precision 0.938503062903418 specificity 0.8926140191050204 recall 0.9381914601810368 f1 0.9383352894395471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 15.165690422058105 s\n",
      "Accuracy 0.9338026881228856 precision 0.9335659607617601 specificity 0.8779892819435917 recall 0.9338026881228856 f1 0.9336762199442623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 15.224380493164062 s\n",
      "Accuracy 0.9331626588644052 precision 0.9333384079616894 specificity 0.8843160289088693 recall 0.9331626588644052 f1 0.9332468655923405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 15.192096710205078 s\n",
      "Accuracy 0.93407698637652 precision 0.933912742068058 specificity 0.8790782224883921 recall 0.93407698637652 f1 0.9339911286894795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 15.108974695205688 s\n",
      "Accuracy 0.9319740330986559 precision 0.9322315007693123 specificity 0.8799269895361448 recall 0.9319740330986559 f1 0.932095832043904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 15.147084951400757 s\n",
      "Accuracy 0.9306939745816951 precision 0.9311734652508549 specificity 0.8803763781502706 recall 0.9306939745816951 f1 0.9309121715267761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 15.228014945983887 s\n",
      "Accuracy 0.9350827466398464 precision 0.9356048175781821 specificity 0.8883478256327068 recall 0.9350827466398464 f1 0.9353159300294634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 15.316032409667969 s\n",
      "Accuracy 0.9370028344152875 precision 0.9370283932389376 specificity 0.8884156212428793 recall 0.9370028344152875 f1 0.9370155211003646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 15.265293598175049 s\n",
      "Accuracy 0.9366371034104416 precision 0.9366458376563782 specificity 0.8856718197646621 recall 0.9366371034104416 f1 0.9366414601476015\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 15.311808586120605 s\n",
      "Accuracy 0.9246594130017373 precision 0.9247236093795365 specificity 0.862612070059851 recall 0.9246594130017373 f1 0.9246911441131623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 15.286032438278198 s\n",
      "Accuracy 0.9357227758983268 precision 0.9358398330870332 specificity 0.8862979985495233 recall 0.9357227758983268 f1 0.9357795625304777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 14.947104454040527 s\n",
      "Accuracy 0.931059705586541 precision 0.9313604788614647 specificity 0.8794331456060602 recall 0.931059705586541 f1 0.9312009088113044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 15.136262655258179 s\n",
      "Accuracy 0.9359056414007497 precision 0.9357764052359399 specificity 0.8814857702380562 recall 0.9359056414007497 f1 0.9358386741287914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 15.113984107971191 s\n",
      "Accuracy 0.9343512846301545 precision 0.9342268960255022 specificity 0.8784850690126186 recall 0.9343512846301545 f1 0.9342870482798303\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 15.398516178131104 s\n",
      "Accuracy 0.931425436591387 precision 0.9313357756908556 specificity 0.8774263486366192 recall 0.931425436591387 f1 0.9313795870224261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 15.179417371749878 s\n",
      "Accuracy 0.93160830209381 precision 0.9317424068881539 specificity 0.8790426820389631 recall 0.93160830209381 f1 0.9316733515205404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 15.166474103927612 s\n",
      "Accuracy 0.9349913138886349 precision 0.9357460167788141 specificity 0.8917594892844519 recall 0.9349913138886349 f1 0.935314218562614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 15.262506008148193 s\n",
      "Accuracy 0.9327054951083478 precision 0.9329411771186974 specificity 0.8805219425387741 recall 0.9327054951083478 f1 0.932817403909155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 15.213527917861938 s\n",
      "Accuracy 0.9327969278595593 precision 0.9334342110590327 specificity 0.8859021752799201 recall 0.9327969278595593 f1 0.9330775826952155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 15.297057628631592 s\n",
      "Accuracy 0.9347170156350004 precision 0.9348654499975746 specificity 0.8841683629284768 recall 0.9347170156350004 f1 0.9347885928446676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 15.089383840560913 s\n",
      "Accuracy 0.9363628051568071 precision 0.9362369131521135 specificity 0.8784512236863631 recall 0.9363628051568071 f1 0.9362977755787405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 15.01127004623413 s\n",
      "Accuracy 0.9348084483862119 precision 0.9346124873743678 specificity 0.8793797940441292 recall 0.9348084483862119 f1 0.9347049695298241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 15.242587327957153 s\n",
      "Accuracy 0.9313340038401755 precision 0.9311968229195667 specificity 0.8742156411462111 recall 0.9313340038401755 f1 0.9312630959432611\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 15.307893514633179 s\n",
      "Accuracy 0.9309682728353296 precision 0.9308855392863328 specificity 0.8753921498754722 recall 0.9309682728353296 f1 0.930926076988124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 15.203535795211792 s\n",
      "Accuracy 0.9352656121422693 precision 0.9351650091217439 specificity 0.884240969167128 recall 0.9352656121422693 f1 0.9352138329295998\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 15.005828380584717 s\n",
      "Accuracy 0.9335283898692511 precision 0.9335017521320198 specificity 0.8814329586259061 recall 0.9335283898692511 f1 0.9335149787880512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 15.230509996414185 s\n",
      "Accuracy 0.9336198226204626 precision 0.9336022815352879 specificity 0.8827643889588135 recall 0.9336198226204626 f1 0.9336110112783762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 15.498592853546143 s\n",
      "Accuracy 0.9323397641035018 precision 0.9321611988941266 specificity 0.875235252878592 recall 0.9323397641035018 f1 0.9322463462568932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 15.419572830200195 s\n",
      "Accuracy 0.9328883606107707 precision 0.9334580428108301 specificity 0.8867938936936922 recall 0.9328883606107707 f1 0.933141344288863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 15.535064935684204 s\n",
      "Accuracy 0.9332540916156167 precision 0.9336058463735496 specificity 0.8847614288257803 recall 0.9332540916156167 f1 0.9334167350252244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 15.419056177139282 s\n",
      "Accuracy 0.9315168693425985 precision 0.9319351623608073 specificity 0.8813783015836092 recall 0.9315168693425985 f1 0.9317088626791251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 15.743327856063843 s\n",
      "Accuracy 0.9309682728353296 precision 0.9311324872358437 specificity 0.8788125537583197 recall 0.9309682728353296 f1 0.9310474387935115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 15.577005624771118 s\n",
      "Accuracy 0.9335283898692511 precision 0.9335195461136425 specificity 0.8823441993384634 recall 0.9335283898692511 f1 0.9335239577786076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 15.375999927520752 s\n",
      "Accuracy 0.9319740330986559 precision 0.9319180398929368 specificity 0.8755379076761187 recall 0.9319740330986559 f1 0.9319456644112196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 15.625503778457642 s\n",
      "Accuracy 0.9350827466398464 precision 0.9353750311063413 specificity 0.8844691400538739 recall 0.9350827466398464 f1 0.9352195368062114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 16.74825358390808 s\n",
      "Accuracy 0.9329797933619822 precision 0.9330644607901665 specificity 0.8799098298123675 recall 0.9329797933619822 f1 0.9330212928022833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 15.851261138916016 s\n",
      "Accuracy 0.9347170156350004 precision 0.9350282265151003 specificity 0.8849680708418343 recall 0.9347170156350004 f1 0.9348620354094065\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 16.032987594604492 s\n",
      "Accuracy 0.9397458169516321 precision 0.9398398296829077 specificity 0.892159354169434 recall 0.9397458169516321 f1 0.9397915586572211\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 16.469547271728516 s\n",
      "Accuracy 0.9350827466398464 precision 0.9350652202531523 specificity 0.8836454431230618 recall 0.9350827466398464 f1 0.9350739422204075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 15.41713285446167 s\n",
      "Accuracy 0.9343512846301545 precision 0.9343869437831741 specificity 0.8836413906172979 recall 0.9343512846301545 f1 0.9343689501322938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 15.230567932128906 s\n",
      "Accuracy 0.9291396178110999 precision 0.9294356420460604 specificity 0.8763438282621852 recall 0.9291396178110999 f1 0.9292790980833207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 15.034691333770752 s\n",
      "Accuracy 0.9333455243668282 precision 0.9331490635795409 specificity 0.8784719125500612 recall 0.9333455243668282 f1 0.9332418513088169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 14.958036184310913 s\n",
      "Accuracy 0.9351741793910578 precision 0.9354885966892105 specificity 0.8872415653344907 recall 0.9351741793910578 f1 0.9353201880166186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 14.97451901435852 s\n",
      "Accuracy 0.9350827466398464 precision 0.9353256890930483 specificity 0.8867323822206775 recall 0.9350827466398464 f1 0.935197274516382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 14.803481340408325 s\n",
      "Accuracy 0.9353570448934808 precision 0.9354007916885244 specificity 0.8859974246919663 recall 0.9353570448934808 f1 0.9353786619592339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 15.4101083278656 s\n",
      "Accuracy 0.9307854073329066 precision 0.9308917456744276 specificity 0.876894841983029 recall 0.9307854073329066 f1 0.9308373398730226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 15.504639148712158 s\n",
      "Accuracy 0.9316997348450214 precision 0.9322261852731409 specificity 0.8870418166603566 recall 0.9316997348450214 f1 0.9319348194986482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 14.982545137405396 s\n",
      "Accuracy 0.9333455243668282 precision 0.9335967670470381 specificity 0.886221373375963 recall 0.9333455243668282 f1 0.9334637666943029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 14.930046081542969 s\n",
      "Accuracy 0.9306939745816951 precision 0.9301530043084976 specificity 0.8653426881868602 recall 0.9306939745816951 f1 0.9303806880630703\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 15.199204921722412 s\n",
      "Accuracy 0.9352656121422693 precision 0.9353001210560762 specificity 0.8867423767288265 recall 0.9352656121422693 f1 0.9352827033009404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 15.068053245544434 s\n",
      "Accuracy 0.9339855536253086 precision 0.9338454720373439 specificity 0.8789084179907506 recall 0.9339855536253086 f1 0.933912861601641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 14.923308372497559 s\n",
      "Accuracy 0.9348084483862119 precision 0.9344712398619771 specificity 0.8765908421143792 recall 0.9348084483862119 f1 0.9346222710908091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 14.968803405761719 s\n",
      "Accuracy 0.9339855536253086 precision 0.9337517952218828 specificity 0.8790921412060557 recall 0.9339855536253086 f1 0.933860593266837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 15.147049903869629 s\n",
      "Accuracy 0.937459998171345 precision 0.937459998171345 specificity 0.8871655008117002 recall 0.937459998171345 f1 0.937459998171345\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 15.028951644897461 s\n",
      "Accuracy 0.9335283898692511 precision 0.9336510014990834 specificity 0.8812021281461705 recall 0.9335283898692511 f1 0.9335879528670933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 14.819116115570068 s\n",
      "Accuracy 0.9361799396543842 precision 0.936064642030244 specificity 0.8854917570073264 recall 0.9361799396543842 f1 0.9361202740322768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 15.1655752658844 s\n",
      "Accuracy 0.9356313431471153 precision 0.9354942125216572 specificity 0.8814653146414835 recall 0.9356313431471153 f1 0.9355601129418816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 15.342561721801758 s\n",
      "Accuracy 0.9331626588644052 precision 0.9333561420835517 specificity 0.885198723665743 recall 0.9331626588644052 f1 0.9332549339601376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 14.905988693237305 s\n",
      "Accuracy 0.9338026881228856 precision 0.9338556916192576 specificity 0.8846260267906594 recall 0.9338026881228856 f1 0.9338288239900447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 15.158602952957153 s\n",
      "Accuracy 0.9349913138886349 precision 0.9349471054155754 specificity 0.8819744746799032 recall 0.9349913138886349 f1 0.9349689506158942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 15.208503007888794 s\n",
      "Accuracy 0.9338941208740971 precision 0.9338849437897572 specificity 0.8795137630050477 recall 0.9338941208740971 f1 0.9338895219585537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 15.407325744628906 s\n",
      "Accuracy 0.9329797933619822 precision 0.9333030445188806 specificity 0.8835156785838599 recall 0.9329797933619822 f1 0.933130280639382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 15.227578401565552 s\n",
      "Accuracy 0.9321568986010789 precision 0.9321198064880137 specificity 0.8767849472166024 recall 0.9321568986010789 f1 0.9321381876208437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 15.0273597240448 s\n",
      "Accuracy 0.9351741793910578 precision 0.9355864257566199 specificity 0.889589430745465 recall 0.9351741793910578 f1 0.9353614153107707\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 15.119516372680664 s\n",
      "Accuracy 0.9345341501325775 precision 0.9345522437415147 specificity 0.8819599712297209 recall 0.9345341501325775 f1 0.9345431555729593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 15.16655683517456 s\n",
      "Accuracy 0.9322483313522903 precision 0.9320452239702552 specificity 0.8751970263741775 recall 0.9322483313522903 f1 0.9321413177513053\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 15.440000057220459 s\n",
      "Accuracy 0.9318826003474444 precision 0.9325215508809978 specificity 0.8850032904333889 recall 0.9318826003474444 f1 0.9321642861310682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 20.83859348297119 s\n",
      "Accuracy 0.9295967815671573 precision 0.9305505627960813 specificity 0.8825928118902328 recall 0.9295967815671573 f1 0.9300022845799018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 26.678125619888306 s\n",
      "Accuracy 0.9322483313522903 precision 0.932974784472604 specificity 0.8839951145775192 recall 0.9322483313522903 f1 0.9325654978174643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 26.185065746307373 s\n",
      "Accuracy 0.9328883606107707 precision 0.9330387817069026 specificity 0.8819633310811825 recall 0.9328883606107707 f1 0.9329609533318773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 26.07055377960205 s\n",
      "Accuracy 0.9380085946786139 precision 0.938249359637476 specificity 0.8955446390081567 recall 0.9380085946786139 f1 0.9381210084157163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 25.950617790222168 s\n",
      "Accuracy 0.9338941208740971 precision 0.9335195504805929 specificity 0.8768584648829179 recall 0.9338941208740971 f1 0.9336840108851733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 25.721565008163452 s\n",
      "Accuracy 0.9330712261131937 precision 0.9334827764431635 specificity 0.8814128197293537 recall 0.9330712261131937 f1 0.9332604309855574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 25.35154914855957 s\n",
      "Accuracy 0.9341684191277315 precision 0.9345336230265905 specificity 0.887292181627666 recall 0.9341684191277315 f1 0.9343362958131762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 25.324639558792114 s\n",
      "Accuracy 0.931059705586541 precision 0.9314847986255897 specificity 0.8820251287499528 recall 0.931059705586541 f1 0.9312543739343916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 23.756632804870605 s\n",
      "Accuracy 0.9371856999177105 precision 0.937321651438237 specificity 0.8872495131916974 recall 0.9371856999177105 f1 0.937251329754851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 25.20009469985962 s\n",
      "Accuracy 0.9336198226204626 precision 0.9337509055966661 specificity 0.8821593411041148 recall 0.9336198226204626 f1 0.9336833486092277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 24.828112840652466 s\n",
      "Accuracy 0.93407698637652 precision 0.9346904556935909 specificity 0.8899817803045401 recall 0.93407698637652 f1 0.934345936919346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 25.850042581558228 s\n",
      "Accuracy 0.9354484776446923 precision 0.9353786376145494 specificity 0.882337018039388 recall 0.9354484776446923 f1 0.9354128932469392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 26.42416501045227 s\n",
      "Accuracy 0.9306939745816951 precision 0.9308035314484151 specificity 0.881854937207927 recall 0.9306939745816951 f1 0.930747311941203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 23.617104291915894 s\n",
      "Accuracy 0.9352656121422693 precision 0.9353713497867031 specificity 0.8874286977704909 recall 0.9352656121422693 f1 0.935317011536509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 24.910661458969116 s\n",
      "Accuracy 0.9325226296059248 precision 0.9328192120394794 specificity 0.8815801578882614 recall 0.9325226296059248 f1 0.9326616902831065\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 25.367511749267578 s\n",
      "Accuracy 0.93407698637652 precision 0.9341584478524237 specificity 0.8837291456417266 recall 0.93407698637652 f1 0.9341168875713416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 24.771018743515015 s\n",
      "Accuracy 0.9319740330986559 precision 0.9321851206461004 specificity 0.8814385967635199 recall 0.9319740330986559 f1 0.932074649857454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 24.935120105743408 s\n",
      "Accuracy 0.9356313431471153 precision 0.9360706846973864 specificity 0.8868863609094522 recall 0.9356313431471153 f1 0.9358308892560484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 25.193066358566284 s\n",
      "Accuracy 0.9308768400841181 precision 0.9306611887315651 specificity 0.87276172777112 recall 0.9308768400841181 f1 0.930763088589634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 25.679028034210205 s\n",
      "Accuracy 0.9361799396543842 precision 0.9364465080588956 specificity 0.8865034902730475 recall 0.9361799396543842 f1 0.936305065413594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 25.448070764541626 s\n",
      "Accuracy 0.9346255828837889 precision 0.9344113472320011 specificity 0.8781978794162598 recall 0.9346255828837889 f1 0.9345119523288912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 26.428070783615112 s\n",
      "Accuracy 0.9352656121422693 precision 0.9355833549464262 specificity 0.8891277659927678 recall 0.9352656121422693 f1 0.9354126805937049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 25.254181385040283 s\n",
      "Accuracy 0.9351741793910578 precision 0.9352004258776091 specificity 0.8853091431469757 recall 0.9351741793910578 f1 0.9351872103058952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 24.177051067352295 s\n",
      "Accuracy 0.9322483313522903 precision 0.9320783289534329 specificity 0.8753149516361108 recall 0.9322483313522903 f1 0.9321596013293701\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 15.217899084091187 s\n",
      "Accuracy 0.931059705586541 precision 0.9306377916812489 specificity 0.8701141328395865 recall 0.931059705586541 f1 0.9308229130151883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 14.960590124130249 s\n",
      "Accuracy 0.9308768400841181 precision 0.9306460697243546 specificity 0.8731971548678943 recall 0.9308768400841181 f1 0.9307545163764321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 15.331371545791626 s\n",
      "Accuracy 0.9313340038401755 precision 0.9313614384716494 specificity 0.8795498158033558 recall 0.9313340038401755 f1 0.9313476299384964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 15.512388229370117 s\n",
      "Accuracy 0.9309682728353296 precision 0.9308255510190502 specificity 0.8705537840635101 recall 0.9309682728353296 f1 0.9308945687345311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 15.267056465148926 s\n",
      "Accuracy 0.9337112553716741 precision 0.9337982491517557 specificity 0.8780047231665804 recall 0.9337112553716741 f1 0.933753905266486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 16.383703231811523 s\n",
      "Accuracy 0.934442717381366 precision 0.9342170603450203 specificity 0.87952536767751 recall 0.934442717381366 f1 0.9343223531180682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 16.64912176132202 s\n",
      "Accuracy 0.9336198226204626 precision 0.9339218765537068 specificity 0.8866727739236157 recall 0.9336198226204626 f1 0.9337604586024665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 16.80937695503235 s\n",
      "Accuracy 0.9335283898692511 precision 0.9335193032383854 specificity 0.8801395214704621 recall 0.9335283898692511 f1 0.9335238362445235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 17.11608862876892 s\n",
      "Accuracy 0.9336198226204626 precision 0.9337092677342402 specificity 0.8846900948373891 recall 0.9336198226204626 f1 0.9336635295115571\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 16.569052696228027 s\n",
      "Accuracy 0.937277132668922 precision 0.9372432275131571 specificity 0.8868669202842729 recall 0.937277132668922 f1 0.9372600140480586\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 16.848363161087036 s\n",
      "Accuracy 0.9324311968547133 precision 0.9325938212888844 specificity 0.8805278394005227 recall 0.9324311968547133 f1 0.9325095478216255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 16.560720443725586 s\n",
      "Accuracy 0.9362713724055957 precision 0.9365929737403463 specificity 0.8861083888095367 recall 0.9362713724055957 f1 0.9364207870441209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 16.76817011833191 s\n",
      "Accuracy 0.9339855536253086 precision 0.9340037980704381 specificity 0.8809685020921083 recall 0.9339855536253086 f1 0.9339946345302744\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 16.55552339553833 s\n",
      "Accuracy 0.9353570448934808 precision 0.9355005737353087 specificity 0.8816668898147192 recall 0.9353570448934808 f1 0.9354264492392103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 16.58449697494507 s\n",
      "Accuracy 0.9326140623571363 precision 0.9327924591182352 specificity 0.8827639653827782 recall 0.9326140623571363 f1 0.9326995877575739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 16.38953733444214 s\n",
      "Accuracy 0.9327054951083478 precision 0.9323723191901512 specificity 0.8749980551641517 recall 0.9327054951083478 f1 0.9325223960716907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 16.910708904266357 s\n",
      "Accuracy 0.9295053488159458 precision 0.9299089388155962 specificity 0.878219614946525 recall 0.9295053488159458 f1 0.9296917281718218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 16.486156702041626 s\n",
      "Accuracy 0.9319740330986559 precision 0.9317164188046714 specificity 0.8752542369838232 recall 0.9319740330986559 f1 0.9318359825136849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 16.514583826065063 s\n",
      "Accuracy 0.9345341501325775 precision 0.9342343627837206 specificity 0.8770505245337431 recall 0.9345341501325775 f1 0.9343707476560303\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 16.359016180038452 s\n",
      "Accuracy 0.9337112553716741 precision 0.9340651344565529 specificity 0.8870867968026784 recall 0.9337112553716741 f1 0.933874290549128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 16.83400821685791 s\n",
      "Accuracy 0.9348998811374234 precision 0.9347264545303697 specificity 0.8789127809028261 recall 0.9348998811374234 f1 0.934808994110222\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 16.5096218585968 s\n",
      "Accuracy 0.9316997348450214 precision 0.9318862674913551 specificity 0.8784564050867399 recall 0.9316997348450214 f1 0.9317892936845064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 16.507469177246094 s\n",
      "Accuracy 0.9357227758983268 precision 0.9356341806350903 specificity 0.8878081010605836 recall 0.9357227758983268 f1 0.9356772503229623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 16.7466139793396 s\n",
      "Accuracy 0.9331626588644052 precision 0.9329990510529612 specificity 0.8789407020551102 recall 0.9331626588644052 f1 0.9330771496664106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 16.320124864578247 s\n",
      "Accuracy 0.9327054951083478 precision 0.9328408330041381 specificity 0.8789179381777642 recall 0.9327054951083478 f1 0.9327711388374236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 16.702970266342163 s\n",
      "Accuracy 0.9359056414007497 precision 0.9357306132506958 specificity 0.8822901005515273 recall 0.9359056414007497 f1 0.935813548697766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 16.72899866104126 s\n",
      "Accuracy 0.9300539453232147 precision 0.9300635137056823 specificity 0.8744228960910271 recall 0.9300539453232147 f1 0.9300587192941749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 16.911486387252808 s\n",
      "Accuracy 0.9355399103959038 precision 0.9358298999434244 specificity 0.8883791819276962 recall 0.9355399103959038 f1 0.935675043376332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 16.477915048599243 s\n",
      "Accuracy 0.9373685654201335 precision 0.9373946391922263 specificity 0.8870755687719767 recall 0.9373685654201335 f1 0.9373815086573645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 16.54504132270813 s\n",
      "Accuracy 0.93407698637652 precision 0.9340142683536632 specificity 0.8797917779361466 recall 0.93407698637652 f1 0.9340451198058364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 16.400280237197876 s\n",
      "Accuracy 0.9339855536253086 precision 0.934149881436648 specificity 0.8855908191743329 recall 0.9339855536253086 f1 0.9340644187780316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 16.57059621810913 s\n",
      "Accuracy 0.9353570448934808 precision 0.9354553494489453 specificity 0.8860894084751694 recall 0.9353570448934808 f1 0.9354049543063628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 16.317022562026978 s\n",
      "Accuracy 0.9359970741519612 precision 0.9359629795482108 specificity 0.8857351475428195 recall 0.9359970741519612 f1 0.9359798620964483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 16.29294991493225 s\n",
      "Accuracy 0.9325226296059248 precision 0.9330505601985061 specificity 0.8816725142940173 recall 0.9325226296059248 f1 0.9327607793962265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 16.750607013702393 s\n",
      "Accuracy 0.9337112553716741 precision 0.9336659684084926 specificity 0.879302278474218 recall 0.9337112553716741 f1 0.933688353138635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 16.393603801727295 s\n",
      "Accuracy 0.9357227758983268 precision 0.9359334741737532 specificity 0.8878507929765198 recall 0.9357227758983268 f1 0.9358226899771169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 16.475964069366455 s\n",
      "Accuracy 0.9360885069031727 precision 0.9358339402875346 specificity 0.8804345951795921 recall 0.9360885069031727 f1 0.935951182406721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 16.635945796966553 s\n",
      "Accuracy 0.936911401664076 precision 0.936766048086143 specificity 0.8861550781892733 recall 0.936911401664076 f1 0.9368353814750574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 16.48919177055359 s\n",
      "Accuracy 0.9348084483862119 precision 0.9346818687631286 specificity 0.8825927740361036 recall 0.9348084483862119 f1 0.9347428456888103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 16.755537748336792 s\n",
      "Accuracy 0.9292310505623114 precision 0.9291934055091831 specificity 0.8739245920637932 recall 0.9292310505623114 f1 0.929212065655064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 16.577013731002808 s\n",
      "Accuracy 0.9343512846301545 precision 0.9342255542390674 specificity 0.8775813154924328 recall 0.9343512846301545 f1 0.9342863696382923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 16.929351329803467 s\n",
      "Accuracy 0.9325226296059248 precision 0.9327284020858464 specificity 0.8838716452671664 recall 0.9325226296059248 f1 0.9326206140876281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 16.697026014328003 s\n",
      "Accuracy 0.9327969278595593 precision 0.9326276208346904 specificity 0.8759297916199078 recall 0.9327969278595593 f1 0.9327085355904199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 16.46904444694519 s\n",
      "Accuracy 0.9365456706592301 precision 0.9368682409769504 specificity 0.8887857318664214 recall 0.9365456706592301 f1 0.9366949768428561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 16.469144821166992 s\n",
      "Accuracy 0.9355399103959038 precision 0.936005252629712 specificity 0.888389114730172 recall 0.9355399103959038 f1 0.9357497696897319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 16.249276876449585 s\n",
      "Accuracy 0.9339855536253086 precision 0.9336057515858105 specificity 0.877149475450317 recall 0.9339855536253086 f1 0.9337718619693941\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 16.95106840133667 s\n",
      "Accuracy 0.9351741793910578 precision 0.9353505928297868 specificity 0.8852623414115562 recall 0.9351741793910578 f1 0.9352586601235546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 16.45368266105652 s\n",
      "Accuracy 0.9378257291761909 precision 0.93806452504183 specificity 0.889865229614876 recall 0.9378257291761909 f1 0.9379380854472207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 17.118075609207153 s\n",
      "Accuracy 0.9334369571180396 precision 0.9332006490186883 specificity 0.8779628910382553 recall 0.9334369571180396 f1 0.9333107256627676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 16.53906273841858 s\n",
      "Accuracy 0.9330712261131937 precision 0.9331861952928253 specificity 0.8793067286743456 recall 0.9330712261131937 f1 0.9331272209351456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 16.646729230880737 s\n",
      "Accuracy 0.9316997348450214 precision 0.9321093242688809 specificity 0.8832795111776266 recall 0.9316997348450214 f1 0.9318874842680169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 16.755569219589233 s\n",
      "Accuracy 0.925939471518698 precision 0.9260016703608114 specificity 0.8663504678889374 recall 0.925939471518698 f1 0.9259702047215953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 16.678069829940796 s\n",
      "Accuracy 0.9335283898692511 precision 0.9336665183836899 specificity 0.8837549518560525 recall 0.9335283898692511 f1 0.9335951575621959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 16.593316793441772 s\n",
      "Accuracy 0.9313340038401755 precision 0.9310600498915095 specificity 0.8722438341173084 recall 0.9313340038401755 f1 0.9311870990743017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 16.761088848114014 s\n",
      "Accuracy 0.9302368108256377 precision 0.9299234331407155 specificity 0.8693844177011303 recall 0.9302368108256377 f1 0.9300674668834722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 17.06501293182373 s\n",
      "Accuracy 0.9373685654201335 precision 0.9370274726082484 specificity 0.8827667212328946 recall 0.9373685654201335 f1 0.9371769114908937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 16.6561439037323 s\n",
      "Accuracy 0.9358142086495382 precision 0.9364270374497216 specificity 0.8897457137426671 recall 0.9358142086495382 f1 0.9360833725050549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 17.522765636444092 s\n",
      "Accuracy 0.9313340038401755 precision 0.9315387513822575 specificity 0.8794037530302722 recall 0.9313340038401755 f1 0.9314318789624534\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 16.6781222820282 s\n",
      "Accuracy 0.9382828929322483 precision 0.9382241767120172 specificity 0.8873027106870522 recall 0.9382828929322483 f1 0.9382530226415634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 16.687856674194336 s\n",
      "Accuracy 0.9325226296059248 precision 0.9322249386734983 specificity 0.8767381740059432 recall 0.9325226296059248 f1 0.9323605109604278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 16.87573790550232 s\n",
      "Accuracy 0.9348084483862119 precision 0.9343882032095921 specificity 0.8757030507308227 recall 0.9348084483862119 f1 0.9345689654660767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 16.79789686203003 s\n",
      "Accuracy 0.9306939745816951 precision 0.9307717457075145 specificity 0.8754742174920572 recall 0.9306939745816951 f1 0.9307322034847096\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 16.652097463607788 s\n",
      "Accuracy 0.9387400566883057 precision 0.9385240364099954 specificity 0.8873860400741695 recall 0.9387400566883057 f1 0.93862388213469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 16.608160257339478 s\n",
      "Accuracy 0.937094267166499 precision 0.9374525529152006 specificity 0.8908104739941529 recall 0.937094267166499 f1 0.9372584768478106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 16.828445196151733 s\n",
      "Accuracy 0.9318826003474444 precision 0.9320394781881794 specificity 0.8831381950471029 recall 0.9318826003474444 f1 0.9319581259654065\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 16.625728130340576 s\n",
      "Accuracy 0.9333455243668282 precision 0.9336089353854082 specificity 0.8823596853308552 recall 0.9333455243668282 f1 0.9334697254967923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 16.624304056167603 s\n",
      "Accuracy 0.9352656121422693 precision 0.9353905145632739 specificity 0.8870409442144219 recall 0.9352656121422693 f1 0.9353260583146458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 16.577220678329468 s\n",
      "Accuracy 0.9354484776446923 precision 0.9355941728258125 specificity 0.8861186657682355 recall 0.9354484776446923 f1 0.9355186887354167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 16.63669443130493 s\n",
      "Accuracy 0.934259851878943 precision 0.934325016120759 specificity 0.8809343494856642 recall 0.934259851878943 f1 0.9342919255296248\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 16.574609518051147 s\n",
      "Accuracy 0.9327054951083478 precision 0.9327054951083478 specificity 0.8811714220123644 recall 0.9327054951083478 f1 0.9327054951083478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 16.6452317237854 s\n",
      "Accuracy 0.9334369571180396 precision 0.9331000332685457 specificity 0.8777072473992102 recall 0.9334369571180396 f1 0.9332503815495093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 16.636169910430908 s\n",
      "Accuracy 0.9333455243668282 precision 0.9328628185141037 specificity 0.8727634865476745 recall 0.9333455243668282 f1 0.9330654402712456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 16.5515615940094 s\n",
      "Accuracy 0.931242571088964 precision 0.93117027490383 specificity 0.8772667765650073 recall 0.931242571088964 f1 0.9312057710321232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 16.51401925086975 s\n",
      "Accuracy 0.9337112553716741 precision 0.933534317522266 specificity 0.8803546709782167 recall 0.9337112553716741 f1 0.9336182664249012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 16.418177366256714 s\n",
      "Accuracy 0.9328883606107707 precision 0.9335320130537681 specificity 0.8867760252700645 recall 0.9328883606107707 f1 0.9331710448460317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 16.772472381591797 s\n",
      "Accuracy 0.934259851878943 precision 0.9341154738006565 specificity 0.8812042018447371 recall 0.934259851878943 f1 0.9341846920231401\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 16.42705011367798 s\n",
      "Accuracy 0.9337112553716741 precision 0.9339781899617908 specificity 0.8814619886927271 recall 0.9337112553716741 f1 0.9338371619118037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 16.521793603897095 s\n",
      "Accuracy 0.9329797933619822 precision 0.9332914404810286 specificity 0.8807305850423571 recall 0.9329797933619822 f1 0.9331256770430865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 16.611241579055786 s\n",
      "Accuracy 0.9345341501325775 precision 0.934588793287008 specificity 0.8826106260992734 recall 0.9345341501325775 f1 0.9345610999528785\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 16.62500834465027 s\n",
      "Accuracy 0.9308768400841181 precision 0.9307095189809375 specificity 0.871656126051795 recall 0.9308768400841181 f1 0.9307898257199538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 16.405016660690308 s\n",
      "Accuracy 0.9322483313522903 precision 0.9319897428892457 specificity 0.8774323674349402 recall 0.9322483313522903 f1 0.9321092326954108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 17.313430547714233 s\n",
      "Accuracy 0.9294139160647343 precision 0.9299192017025621 specificity 0.8791891187920241 recall 0.9294139160647343 f1 0.9296432506989208\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 17.072757482528687 s\n",
      "Accuracy 0.9301453780744262 precision 0.9298461766053104 specificity 0.8711433144380218 recall 0.9301453780744262 f1 0.9299839224005013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 16.78395938873291 s\n",
      "Accuracy 0.9352656121422693 precision 0.9350914467640562 specificity 0.8787342865991432 recall 0.9352656121422693 f1 0.9351743375732039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 16.77595853805542 s\n",
      "Accuracy 0.9353570448934808 precision 0.9354020375864148 specificity 0.8837609534235407 recall 0.9353570448934808 f1 0.935379282353154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 16.820119619369507 s\n",
      "Accuracy 0.9331626588644052 precision 0.9329421707112129 specificity 0.875116185871206 recall 0.9331626588644052 f1 0.9330459102763524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 16.64362359046936 s\n",
      "Accuracy 0.931242571088964 precision 0.9312794707487798 specificity 0.8790701531089883 recall 0.931242571088964 f1 0.9312608585184389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 16.676066398620605 s\n",
      "Accuracy 0.9320654658498674 precision 0.9324484818616767 specificity 0.8843812810116938 recall 0.9320654658498674 f1 0.9322415803079132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 16.778958559036255 s\n",
      "Accuracy 0.9326140623571363 precision 0.9322097876720858 specificity 0.8729155262338666 recall 0.9326140623571363 f1 0.9323870279429173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 16.52877712249756 s\n",
      "Accuracy 0.9338026881228856 precision 0.9333855822739662 specificity 0.8770812079256485 recall 0.9338026881228856 f1 0.9335641232868293\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 16.617841482162476 s\n",
      "Accuracy 0.9368199689128646 precision 0.9375647392560056 specificity 0.8942591799782632 recall 0.9368199689128646 f1 0.9371374839633807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 16.574446439743042 s\n",
      "Accuracy 0.9301453780744262 precision 0.9303716482279332 specificity 0.8822634067689876 recall 0.9301453780744262 f1 0.9302527657850842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 16.54656744003296 s\n",
      "Accuracy 0.9338026881228856 precision 0.933681260837578 specificity 0.8801889568376993 recall 0.9338026881228856 f1 0.9337399577728177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 16.740617275238037 s\n",
      "Accuracy 0.9336198226204626 precision 0.9337310121077437 specificity 0.8824331498767731 recall 0.9336198226204626 f1 0.9336739393704319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 16.52395009994507 s\n",
      "Accuracy 0.9348998811374234 precision 0.934987911064829 specificity 0.8867056303480229 recall 0.9348998811374234 f1 0.9349428767889585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 17.063591480255127 s\n",
      "Accuracy 0.9359970741519612 precision 0.9356512436435058 specificity 0.8797435884376381 recall 0.9359970741519612 f1 0.9358039774792258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 16.87208390235901 s\n",
      "Accuracy 0.9335283898692511 precision 0.9334275323373443 specificity 0.8763313476660076 recall 0.9335283898692511 f1 0.9334766979439463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 16.516908884048462 s\n",
      "Accuracy 0.9334369571180396 precision 0.9335478389511093 specificity 0.8825507361193962 recall 0.9334369571180396 f1 0.9334909234191252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 16.887807369232178 s\n",
      "Accuracy 0.9338941208740971 precision 0.9344973548096946 specificity 0.8879529813380432 recall 0.9338941208740971 f1 0.9341601574255233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 16.999958515167236 s\n",
      "Accuracy 0.9329797933619822 precision 0.9331202801076321 specificity 0.8820407898545013 recall 0.9329797933619822 f1 0.9330477354299084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 15.544957637786865 s\n",
      "Accuracy 0.9327054951083478 precision 0.9328018663323892 specificity 0.8779900622572593 recall 0.9327054951083478 f1 0.9327526448627572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 15.346315383911133 s\n",
      "Accuracy 0.9326140623571363 precision 0.9325344946389628 specificity 0.8795095582954646 recall 0.9326140623571363 f1 0.9325734507012625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 15.373918056488037 s\n",
      "Accuracy 0.9319740330986559 precision 0.9320303316219571 specificity 0.8786594235883631 recall 0.9319740330986559 f1 0.9320018135743942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 15.435008525848389 s\n",
      "Accuracy 0.9362713724055957 precision 0.9364061853932882 specificity 0.8873666331146645 recall 0.9362713724055957 f1 0.9363364562439255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 15.539905071258545 s\n",
      "Accuracy 0.9293224833135229 precision 0.929901694267766 specificity 0.8810221079034999 recall 0.9293224833135229 f1 0.9295816722182143\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 15.353728294372559 s\n",
      "Accuracy 0.9347170156350004 precision 0.934540395128197 specificity 0.8773007518891697 recall 0.9347170156350004 f1 0.9346245107670305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 15.644811391830444 s\n",
      "Accuracy 0.9327054951083478 precision 0.9325332691779341 specificity 0.8784076641554499 recall 0.9327054951083478 f1 0.9326152863734845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 15.552459716796875 s\n",
      "Accuracy 0.9358142086495382 precision 0.9359965467270323 specificity 0.8874174968143332 recall 0.9358142086495382 f1 0.9359012607966668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 15.486589431762695 s\n",
      "Accuracy 0.9350827466398464 precision 0.934982039142979 specificity 0.8840641845637468 recall 0.9350827466398464 f1 0.9350309166736098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 15.243191957473755 s\n",
      "Accuracy 0.9341684191277315 precision 0.934445284712711 specificity 0.88825026393043 recall 0.9341684191277315 f1 0.9342977409663046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 15.562590837478638 s\n",
      "Accuracy 0.9348084483862119 precision 0.9354919211989339 specificity 0.8910436845003428 recall 0.9348084483862119 f1 0.9351043695684519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 15.120602369308472 s\n",
      "Accuracy 0.931059705586541 precision 0.9306148302658791 specificity 0.8708586841511848 recall 0.931059705586541 f1 0.9308072543598684\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 15.244300365447998 s\n",
      "Accuracy 0.9345341501325775 precision 0.9346635686542892 specificity 0.8837597177316461 recall 0.9345341501325775 f1 0.934596839696615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 15.492409229278564 s\n",
      "Accuracy 0.9326140623571363 precision 0.9328285490399443 specificity 0.8844509360725233 recall 0.9326140623571363 f1 0.9327159550773342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 15.32193660736084 s\n",
      "Accuracy 0.9364542379080186 precision 0.9363149037381467 specificity 0.8850936415558015 recall 0.9364542379080186 f1 0.936381586865205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 15.639741659164429 s\n",
      "Accuracy 0.9321568986010789 precision 0.9322102519694279 specificity 0.8831352716859555 recall 0.9321568986010789 f1 0.932183212763519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 15.564940690994263 s\n",
      "Accuracy 0.9335283898692511 precision 0.9336315598175556 specificity 0.8810776390798978 recall 0.9335283898692511 f1 0.9335787272373495\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 16.877835035324097 s\n",
      "Accuracy 0.928773886806254 precision 0.9282821379473534 specificity 0.8674568577550149 recall 0.928773886806254 f1 0.9284924828690296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 16.744953870773315 s\n",
      "Accuracy 0.9367285361616531 precision 0.936870690393274 specificity 0.8888418714330165 recall 0.9367285361616531 f1 0.9367969750758297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 16.88224506378174 s\n",
      "Accuracy 0.9320654658498674 precision 0.9318207233793515 specificity 0.8770144837364112 recall 0.9320654658498674 f1 0.9319345089451669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 16.405599117279053 s\n",
      "Accuracy 0.9370028344152875 precision 0.9368009815246403 specificity 0.8840607459718068 recall 0.9370028344152875 f1 0.9368954082109525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 17.066333770751953 s\n",
      "Accuracy 0.937277132668922 precision 0.9370047582212659 specificity 0.8819621271908588 recall 0.937277132668922 f1 0.9371288173067635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 16.702157735824585 s\n",
      "Accuracy 0.9306025418304836 precision 0.9307315432304443 specificity 0.8750941732841471 recall 0.9306025418304836 f1 0.9306653046239378\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 16.613847732543945 s\n",
      "Accuracy 0.9349913138886349 precision 0.9350724060079014 specificity 0.884633152638553 recall 0.9349913138886349 f1 0.9350310262028481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 16.625324964523315 s\n",
      "Accuracy 0.9311511383377525 precision 0.9308590942776803 specificity 0.8714192050090063 recall 0.9311511383377525 f1 0.9309938551658337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 16.597113847732544 s\n",
      "Accuracy 0.9352656121422693 precision 0.9353559586954946 specificity 0.8848726836396081 recall 0.9352656121422693 f1 0.9353097539991113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 16.45564103126526 s\n",
      "Accuracy 0.9348084483862119 precision 0.9354435044903612 specificity 0.8876926742426912 recall 0.9348084483862119 f1 0.9350875047754432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 16.626057863235474 s\n",
      "Accuracy 0.9330712261131937 precision 0.9333626291421468 specificity 0.883415429420194 recall 0.9330712261131937 f1 0.9332077200537309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 16.59193181991577 s\n",
      "Accuracy 0.9377342964249794 precision 0.9378309420157175 specificity 0.8888405885817466 recall 0.9377342964249794 f1 0.9377813616690679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 16.575003623962402 s\n",
      "Accuracy 0.9338941208740971 precision 0.9334735851624613 specificity 0.8753103327163424 recall 0.9338941208740971 f1 0.9336546971150974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 16.436416149139404 s\n",
      "Accuracy 0.9338026881228856 precision 0.9336475628679887 specificity 0.8794961945339774 recall 0.9338026881228856 f1 0.9337217864063112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 16.758729696273804 s\n",
      "Accuracy 0.9359056414007497 precision 0.9362549069832087 specificity 0.8844618405549223 recall 0.9359056414007497 f1 0.9360674105683282\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 17.165903091430664 s\n",
      "Accuracy 0.9311511383377525 precision 0.9317437234443178 specificity 0.8839936473977728 recall 0.9311511383377525 f1 0.9314145757882566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 15.661801099777222 s\n",
      "Accuracy 0.9346255828837889 precision 0.934931036544947 specificity 0.8835166820812569 recall 0.9346255828837889 f1 0.934768324749419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 21.331082820892334 s\n",
      "Accuracy 0.9309682728353296 precision 0.931317487306638 specificity 0.8812044835351903 recall 0.9309682728353296 f1 0.9311304623143626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 22.82910466194153 s\n",
      "Accuracy 0.9354484776446923 precision 0.9355216382760722 specificity 0.8833951454894545 recall 0.9354484776446923 f1 0.9354843928035619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 22.508853912353516 s\n",
      "Accuracy 0.9348084483862119 precision 0.934910922823477 specificity 0.8823937526589015 recall 0.9348084483862119 f1 0.9348584292410296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 22.656155824661255 s\n",
      "Accuracy 0.9333455243668282 precision 0.9330506815827091 specificity 0.875906000886978 recall 0.9333455243668282 f1 0.9331854134495127\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 22.664875984191895 s\n",
      "Accuracy 0.9338026881228856 precision 0.9334274597755031 specificity 0.8780236772832366 recall 0.9338026881228856 f1 0.9335914099483139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 20.55969476699829 s\n",
      "Accuracy 0.9354484776446923 precision 0.9356170241961322 specificity 0.8844434690276054 recall 0.9354484776446923 f1 0.9355293865786249\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 21.682552099227905 s\n",
      "Accuracy 0.9322483313522903 precision 0.9324891674159614 specificity 0.8821383030633264 recall 0.9322483313522903 f1 0.9323623826081657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 21.54907464981079 s\n",
      "Accuracy 0.9355399103959038 precision 0.9355670374935874 specificity 0.8828646940363958 recall 0.9355399103959038 f1 0.9355533802751422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 21.01112985610962 s\n",
      "Accuracy 0.9360885069031727 precision 0.9360624562801297 specificity 0.8846243558772702 recall 0.9360885069031727 f1 0.9360753883379831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 22.232697248458862 s\n",
      "Accuracy 0.9295053488159458 precision 0.9295560126645861 specificity 0.8701800139490092 recall 0.9295053488159458 f1 0.9295304219597981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 22.758023738861084 s\n",
      "Accuracy 0.931425436591387 precision 0.9314629425320075 specificity 0.877815694486481 recall 0.931425436591387 f1 0.931444026040641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 22.262596368789673 s\n",
      "Accuracy 0.9330712261131937 precision 0.9331261258222021 specificity 0.8813827032329427 recall 0.9330712261131937 f1 0.9330983075349614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 22.51579761505127 s\n",
      "Accuracy 0.9331626588644052 precision 0.9326866596564843 specificity 0.8717613436184755 recall 0.9331626588644052 f1 0.9328883205124363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 18.734594583511353 s\n",
      "Accuracy 0.93407698637652 precision 0.9337362198756958 specificity 0.8754323622003526 recall 0.93407698637652 f1 0.9338890684557745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 19.505157470703125 s\n",
      "Accuracy 0.936911401664076 precision 0.9369481014510427 specificity 0.8827234112347194 recall 0.936911401664076 f1 0.9369295825200746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 20.613038778305054 s\n",
      "Accuracy 0.9377342964249794 precision 0.9374950684711282 specificity 0.8859745482295412 recall 0.9377342964249794 f1 0.9376047228358834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 20.243097066879272 s\n",
      "Accuracy 0.9289567523086769 precision 0.9288533921390557 specificity 0.8718523268884343 recall 0.9289567523086769 f1 0.9289038398009173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 21.022047758102417 s\n",
      "Accuracy 0.9348998811374234 precision 0.9350666609878239 specificity 0.8849694101218375 recall 0.9348998811374234 f1 0.9349799330815316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 19.943151235580444 s\n",
      "Accuracy 0.9295967815671573 precision 0.9290539134229794 specificity 0.8666704134591023 recall 0.9295967815671573 f1 0.9292805172801912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 20.204652070999146 s\n",
      "Accuracy 0.9306939745816951 precision 0.9308331355947629 specificity 0.8752937039908308 recall 0.9306939745816951 f1 0.9307615387622817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 20.691646099090576 s\n",
      "Accuracy 0.9343512846301545 precision 0.9342996711004443 specificity 0.8835226811826229 recall 0.9343512846301545 f1 0.9343251097894936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 20.923240184783936 s\n",
      "Accuracy 0.936911401664076 precision 0.9372334013595441 specificity 0.889171585111216 recall 0.936911401664076 f1 0.9370603978122639\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 21.295550107955933 s\n",
      "Accuracy 0.9359056414007497 precision 0.935880027117341 specificity 0.8858509470771927 recall 0.9359056414007497 f1 0.9358927416838132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 21.062583923339844 s\n",
      "Accuracy 0.9345341501325775 precision 0.9346238464322193 specificity 0.8850158290297713 recall 0.9345341501325775 f1 0.9345779749758443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 20.835633754730225 s\n",
      "Accuracy 0.9323397641035018 precision 0.9324480909030912 specificity 0.8837577655724685 recall 0.9323397641035018 f1 0.932392475904304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 21.409626722335815 s\n",
      "Accuracy 0.9327054951083478 precision 0.9325659625775925 specificity 0.878582985979476 recall 0.9327054951083478 f1 0.9326331061205907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 15.529380559921265 s\n",
      "Accuracy 0.9307854073329066 precision 0.9307573342833343 specificity 0.875562097148035 recall 0.9307854073329066 f1 0.9307712787369756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 13.823637247085571 s\n",
      "Accuracy 0.9368199689128646 precision 0.9365740519788961 specificity 0.8834718667442705 recall 0.9368199689128646 f1 0.9366870297844446\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 13.789784669876099 s\n",
      "Accuracy 0.937277132668922 precision 0.9376168923390964 specificity 0.894984701869266 recall 0.937277132668922 f1 0.93743234705585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 13.96554684638977 s\n",
      "Accuracy 0.9345341501325775 precision 0.9352117183565287 specificity 0.8900439901013784 recall 0.9345341501325775 f1 0.9348284158788388\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 13.861861228942871 s\n",
      "Accuracy 0.9328883606107707 precision 0.9322767205028436 specificity 0.8729205055918485 recall 0.9328883606107707 f1 0.9325064708553578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 13.85774302482605 s\n",
      "Accuracy 0.9309682728353296 precision 0.9308847096385633 specificity 0.8745400604020455 recall 0.9309682728353296 f1 0.9309256593265095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 14.031076431274414 s\n",
      "Accuracy 0.9326140623571363 precision 0.9323583120221537 specificity 0.8736200303816668 recall 0.9326140623571363 f1 0.9324774380423598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 14.420687675476074 s\n",
      "Accuracy 0.93160830209381 precision 0.9313308399811664 specificity 0.8686779367335404 recall 0.93160830209381 f1 0.9314601162346285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 14.186117887496948 s\n",
      "Accuracy 0.9323397641035018 precision 0.9318193279526731 specificity 0.8691975395993353 recall 0.9323397641035018 f1 0.9320367403719282\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 14.041307926177979 s\n",
      "Accuracy 0.931242571088964 precision 0.9321773597258028 specificity 0.8856612979940334 recall 0.931242571088964 f1 0.9316383509541829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 14.117080450057983 s\n",
      "Accuracy 0.9349913138886349 precision 0.9351853549546254 specificity 0.8861234353298597 recall 0.9349913138886349 f1 0.9350838051316909\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 14.364395380020142 s\n",
      "Accuracy 0.9308768400841181 precision 0.9306812580321333 specificity 0.8742729204957631 recall 0.9308768400841181 f1 0.930774096549359\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 14.17256498336792 s\n",
      "Accuracy 0.9379171619274024 precision 0.9384123077635537 specificity 0.8928133209960617 recall 0.9379171619274024 f1 0.9381377049288906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 14.247857809066772 s\n",
      "Accuracy 0.9349913138886349 precision 0.9352112355088797 specificity 0.8839098121040165 recall 0.9349913138886349 f1 0.9350957839110932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 14.211830139160156 s\n",
      "Accuracy 0.93160830209381 precision 0.9316463557826908 specificity 0.8766842638547847 recall 0.93160830209381 f1 0.9316271643757722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 13.871896982192993 s\n",
      "Accuracy 0.9346255828837889 precision 0.9345979034897006 specificity 0.878840536174798 recall 0.9346255828837889 f1 0.9346116489504974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 14.007071495056152 s\n",
      "Accuracy 0.9332540916156167 precision 0.9334756610671998 specificity 0.88594342282874 recall 0.9332540916156167 f1 0.9333590502775556\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 14.213395595550537 s\n",
      "Accuracy 0.9358142086495382 precision 0.9359766960489303 specificity 0.8876172293652643 recall 0.9358142086495382 f1 0.9358921232318368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 14.633098602294922 s\n",
      "Accuracy 0.9357227758983268 precision 0.9359880702658205 specificity 0.8896795746333119 recall 0.9357227758983268 f1 0.9358468347938526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 16.15352177619934 s\n",
      "Accuracy 0.9296882143183688 precision 0.9296786839840246 specificity 0.8739747182839959 recall 0.9296882143183688 f1 0.9296834389531737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 14.108272314071655 s\n",
      "Accuracy 0.93407698637652 precision 0.9340681236052295 specificity 0.8824794054496683 recall 0.93407698637652 f1 0.9340725447297813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 14.12334418296814 s\n",
      "Accuracy 0.9349913138886349 precision 0.9351860506049533 specificity 0.8858357999685141 recall 0.9349913138886349 f1 0.9350841471349443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 14.078899145126343 s\n",
      "Accuracy 0.9335283898692511 precision 0.9334182102061267 specificity 0.8821796930060318 recall 0.9335283898692511 f1 0.9334715797637358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 14.098242044448853 s\n",
      "Accuracy 0.9313340038401755 precision 0.9312881646696345 specificity 0.8770043868823173 recall 0.9313340038401755 f1 0.9313108288533253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 14.06191873550415 s\n",
      "Accuracy 0.9304196763280607 precision 0.9300561286453498 specificity 0.8684332752771474 recall 0.9304196763280607 f1 0.930220473944637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 14.059867858886719 s\n",
      "Accuracy 0.9282252902989852 precision 0.9283167722620567 specificity 0.8703619088995543 recall 0.9282252902989852 f1 0.9282702021798438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 14.01224136352539 s\n",
      "Accuracy 0.9337112553716741 precision 0.9335762237005477 specificity 0.8767518879019149 recall 0.9337112553716741 f1 0.9336413937317781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 14.118948459625244 s\n",
      "Accuracy 0.931059705586541 precision 0.9310411102295826 specificity 0.8765559928561705 recall 0.931059705586541 f1 0.931050367035003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 13.844999313354492 s\n",
      "Accuracy 0.934442717381366 precision 0.9345090705914381 specificity 0.8795019319316904 recall 0.934442717381366 f1 0.9344753814768988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 14.09201455116272 s\n",
      "Accuracy 0.9364542379080186 precision 0.9365881948363256 specificity 0.8879794145128029 recall 0.9364542379080186 f1 0.9365188958692838\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 14.097034692764282 s\n",
      "Accuracy 0.9334369571180396 precision 0.9332244250883047 specificity 0.8752102566187161 recall 0.9334369571180396 f1 0.9333246812623514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 13.943983793258667 s\n",
      "Accuracy 0.9356313431471153 precision 0.935491937954402 specificity 0.8801211919835145 recall 0.9356313431471153 f1 0.9355589601778803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 13.73497748374939 s\n",
      "Accuracy 0.9358142086495382 precision 0.9355518109765456 specificity 0.8801143809074282 recall 0.9358142086495382 f1 0.9356723280519121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 14.249915599822998 s\n",
      "Accuracy 0.936911401664076 precision 0.9367986869233623 specificity 0.887585030364419 recall 0.936911401664076 f1 0.9368530318959125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 14.319999694824219 s\n",
      "Accuracy 0.9346255828837889 precision 0.9348225297181719 specificity 0.8846916924714261 recall 0.9346255828837889 f1 0.9347195148133659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 13.854258060455322 s\n",
      "Accuracy 0.9348084483862119 precision 0.9349270430892295 specificity 0.884704024241115 recall 0.9348084483862119 f1 0.9348660073718998\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 14.112224102020264 s\n",
      "Accuracy 0.9356313431471153 precision 0.9355094704396472 specificity 0.8808164472766218 recall 0.9356313431471153 f1 0.9355683593161569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 13.975420951843262 s\n",
      "Accuracy 0.9348084483862119 precision 0.9345790433152948 specificity 0.8783585896196268 recall 0.9348084483862119 f1 0.9346861461674592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 14.842352151870728 s\n",
      "Accuracy 0.9331626588644052 precision 0.9333901802631459 specificity 0.8798817876420436 recall 0.9331626588644052 f1 0.9332709340273574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 14.487160682678223 s\n",
      "Accuracy 0.936911401664076 precision 0.9366488333291588 specificity 0.8805378871435815 recall 0.936911401664076 f1 0.9367693390320238\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 13.833012819290161 s\n",
      "Accuracy 0.9341684191277315 precision 0.9341506774390038 specificity 0.882160038381762 recall 0.9341684191277315 f1 0.9341595071600818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 14.073014497756958 s\n",
      "Accuracy 0.9338941208740971 precision 0.9339219865058584 specificity 0.8797077238026121 recall 0.9338941208740971 f1 0.9339079602772128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 17.589609146118164 s\n",
      "Accuracy 0.9329797933619822 precision 0.9329530498166535 specificity 0.880808617034349 recall 0.9329797933619822 f1 0.9329663296153718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 21.008599042892456 s\n",
      "Accuracy 0.9341684191277315 precision 0.9340767117741956 specificity 0.8769484001028437 recall 0.9341684191277315 f1 0.9341215173248167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 20.373141765594482 s\n",
      "Accuracy 0.9338026881228856 precision 0.9339927084902735 specificity 0.8828180368423348 recall 0.9338026881228856 f1 0.9338935805525179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 20.27058696746826 s\n",
      "Accuracy 0.9363628051568071 precision 0.93686537583241 specificity 0.8923258247344457 recall 0.9363628051568071 f1 0.936586379832733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 20.850043058395386 s\n",
      "Accuracy 0.9311511383377525 precision 0.9312181324982389 specificity 0.8767966128730244 recall 0.9311511383377525 f1 0.9311841333559023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 21.168641328811646 s\n",
      "Accuracy 0.9306025418304836 precision 0.9307910273756671 specificity 0.8768814342086818 recall 0.9306025418304836 f1 0.930693091800548\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 20.578068733215332 s\n",
      "Accuracy 0.9311511383377525 precision 0.9311235745027561 specificity 0.8773102137407184 recall 0.9311511383377525 f1 0.9311372646885698\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 21.058593034744263 s\n",
      "Accuracy 0.9331626588644052 precision 0.9330493970641787 specificity 0.8797946977095096 recall 0.9331626588644052 f1 0.9331042961870336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 21.587060928344727 s\n",
      "Accuracy 0.9347170156350004 precision 0.9348916503866888 specificity 0.8810096315984457 recall 0.9347170156350004 f1 0.9348009431439037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 21.61605143547058 s\n",
      "Accuracy 0.9323397641035018 precision 0.9327289158559663 specificity 0.8807467545560904 recall 0.9323397641035018 f1 0.9325194622900435\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 20.1080002784729 s\n",
      "Accuracy 0.9345341501325775 precision 0.9345156350593737 specificity 0.878813639734198 recall 0.9345341501325775 f1 0.9345248507316724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 21.207000732421875 s\n",
      "Accuracy 0.9301453780744262 precision 0.9299804324301404 specificity 0.8725391962647944 recall 0.9301453780744262 f1 0.930059585336047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 19.597023963928223 s\n",
      "Accuracy 0.9306939745816951 precision 0.9302502487589811 specificity 0.8709307566903913 recall 0.9306939745816951 f1 0.9304422042705638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 15.735850811004639 s\n",
      "Accuracy 0.9330712261131937 precision 0.9332389251829006 specificity 0.883393766903276 recall 0.9330712261131937 f1 0.9331517746359446\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 13.751924276351929 s\n",
      "Accuracy 0.9318826003474444 precision 0.9319286673365529 specificity 0.8798339850152417 recall 0.9318826003474444 f1 0.9319053792922622\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 13.775966167449951 s\n",
      "Accuracy 0.9336198226204626 precision 0.9337477084934114 specificity 0.8841695832988851 recall 0.9336198226204626 f1 0.9336817675260151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 14.0138578414917 s\n",
      "Accuracy 0.9334369571180396 precision 0.9337260288306718 specificity 0.8843178325263095 recall 0.9334369571180396 f1 0.9335722883086082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 13.83501648902893 s\n",
      "Accuracy 0.9354484776446923 precision 0.9353118065582009 specificity 0.8816449967068252 recall 0.9354484776446923 f1 0.9353774840768393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 14.134528636932373 s\n",
      "Accuracy 0.9325226296059248 precision 0.9326542864300866 specificity 0.8811364158238191 recall 0.9325226296059248 f1 0.9325864551350933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 13.760676622390747 s\n",
      "Accuracy 0.9346255828837889 precision 0.9348206579430143 specificity 0.8854666673366836 recall 0.9346255828837889 f1 0.9347185944713909\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 13.83507490158081 s\n",
      "Accuracy 0.9332540916156167 precision 0.9334244873090867 specificity 0.8821981381337192 recall 0.9332540916156167 f1 0.933335965501111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 13.72295331954956 s\n",
      "Accuracy 0.9320654658498674 precision 0.9317349727871759 specificity 0.8736159839003419 recall 0.9320654658498674 f1 0.9318845239618228\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 13.715931177139282 s\n",
      "Accuracy 0.9296882143183688 precision 0.9294902341842454 specificity 0.868903777577129 recall 0.9296882143183688 f1 0.9295846643842762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 13.976072549819946 s\n",
      "Accuracy 0.9323397641035018 precision 0.931779114238573 specificity 0.8717311458800396 recall 0.9323397641035018 f1 0.9320029385822092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 13.786174058914185 s\n",
      "Accuracy 0.9330712261131937 precision 0.9329127069768639 specificity 0.8773566462914215 recall 0.9330712261131937 f1 0.932988620861247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 13.711021423339844 s\n",
      "Accuracy 0.9333455243668282 precision 0.9333549288381292 specificity 0.8777395164283475 recall 0.9333455243668282 f1 0.9333502162003215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 13.96321702003479 s\n",
      "Accuracy 0.9348998811374234 precision 0.9352253050315326 specificity 0.8869781163526079 recall 0.9348998811374234 f1 0.9350507185057679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 13.808703184127808 s\n",
      "Accuracy 0.9332540916156167 precision 0.9334595766194649 specificity 0.88444870262993 recall 0.9332540916156167 f1 0.9333519098737962\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 14.06373381614685 s\n",
      "Accuracy 0.9359056414007497 precision 0.9359327154766912 specificity 0.8832295724463916 recall 0.9359056414007497 f1 0.9359190845736304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 14.053591012954712 s\n",
      "Accuracy 0.9367285361616531 precision 0.9369299233949081 specificity 0.8882537361534674 recall 0.9367285361616531 f1 0.9368242165863164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 13.856035709381104 s\n",
      "Accuracy 0.9345341501325775 precision 0.9347632481237915 specificity 0.8840576206007824 recall 0.9345341501325775 f1 0.934642749673254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 14.054311275482178 s\n",
      "Accuracy 0.9333455243668282 precision 0.9336699983423219 specificity 0.8834417677489395 recall 0.9333455243668282 f1 0.9334965791223818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 18.243916273117065 s\n",
      "Accuracy 0.9327054951083478 precision 0.932779146651161 specificity 0.8812496583331022 recall 0.9327054951083478 f1 0.9327416673716664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 17.75806188583374 s\n",
      "Accuracy 0.936911401664076 precision 0.936911401664076 specificity 0.8865147422533982 recall 0.936911401664076 f1 0.936911401664076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 20.957191228866577 s\n",
      "Accuracy 0.9328883606107707 precision 0.9330183856303401 specificity 0.8823835448151753 recall 0.9328883606107707 f1 0.9329513738235856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 19.22517681121826 s\n",
      "Accuracy 0.9326140623571363 precision 0.9326604546326129 specificity 0.8796723891899018 recall 0.9326140623571363 f1 0.9326370019979059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 14.793174982070923 s\n",
      "Accuracy 0.9348084483862119 precision 0.934909624802702 specificity 0.8834467103671122 recall 0.9348084483862119 f1 0.9348577859806155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 14.33263635635376 s\n",
      "Accuracy 0.93160830209381 precision 0.9316638397409119 specificity 0.8795819525856193 recall 0.93160830209381 f1 0.9316357048068695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 13.948027610778809 s\n",
      "Accuracy 0.9338941208740971 precision 0.9340897419024126 specificity 0.8847818830632299 recall 0.9338941208740971 f1 0.9339874245779349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 13.859545946121216 s\n",
      "Accuracy 0.9343512846301545 precision 0.9345747882634808 specificity 0.8859567009682097 recall 0.9343512846301545 f1 0.9344571474768777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 13.874695301055908 s\n",
      "Accuracy 0.9378257291761909 precision 0.9377261012248602 specificity 0.8863241724772474 recall 0.9378257291761909 f1 0.937774413258932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 13.841984748840332 s\n",
      "Accuracy 0.9367285361616531 precision 0.9365347822234578 specificity 0.8842505033992352 recall 0.9367285361616531 f1 0.9366256882412665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 13.92270278930664 s\n",
      "Accuracy 0.9333455243668282 precision 0.9333726874990362 specificity 0.881516670600171 recall 0.9333455243668282 f1 0.9333590137279925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 13.937549829483032 s\n",
      "Accuracy 0.9338026881228856 precision 0.9337125747430426 specificity 0.8782536404282884 recall 0.9338026881228856 f1 0.933756592696251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 13.993319749832153 s\n",
      "Accuracy 0.9305111090792721 precision 0.9302512027385789 specificity 0.873838235001441 recall 0.9305111090792721 f1 0.9303719828703996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 13.961999654769897 s\n",
      "Accuracy 0.9343512846301545 precision 0.9337167639888599 specificity 0.873652332610547 recall 0.9343512846301545 f1 0.9339462242189338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 13.858687400817871 s\n",
      "Accuracy 0.9324311968547133 precision 0.9326914287682703 specificity 0.8827858781721459 recall 0.9324311968547133 f1 0.9325538888781802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 13.911872863769531 s\n",
      "Accuracy 0.9326140623571363 precision 0.932681362153335 specificity 0.8772412379047082 recall 0.9326140623571363 f1 0.932647204076697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 13.99488115310669 s\n",
      "Accuracy 0.9368199689128646 precision 0.9369196112725758 specificity 0.8858735774878836 recall 0.9368199689128646 f1 0.9368685273816901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 13.933860778808594 s\n",
      "Accuracy 0.9348998811374234 precision 0.9348296103350134 specificity 0.8815496277446853 recall 0.9348998811374234 f1 0.9348640826811122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 13.97512412071228 s\n",
      "Accuracy 0.9345341501325775 precision 0.9348801390477265 specificity 0.8869715955496699 recall 0.9345341501325775 f1 0.9346938706805672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 13.91096830368042 s\n",
      "Accuracy 0.93407698637652 precision 0.9341229426838872 specificity 0.8812935044762349 recall 0.93407698637652 f1 0.9340997061529693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 13.898190259933472 s\n",
      "Accuracy 0.9319740330986559 precision 0.9318499066134229 specificity 0.8774507818223173 recall 0.9319740330986559 f1 0.9319099648986964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 13.82823634147644 s\n",
      "Accuracy 0.9378257291761909 precision 0.9377254732292329 specificity 0.8858343706428001 recall 0.9378257291761909 f1 0.937774095913842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 14.105743885040283 s\n",
      "Accuracy 0.9345341501325775 precision 0.9342912856760089 specificity 0.8811630862294442 recall 0.9345341501325775 f1 0.9344034802176991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 14.269213676452637 s\n",
      "Accuracy 0.9355399103959038 precision 0.9351399114183806 specificity 0.8798443860243449 recall 0.9355399103959038 f1 0.9353108557320381\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 13.93062448501587 s\n",
      "Accuracy 0.9357227758983268 precision 0.9363237205764706 specificity 0.8896216712864382 recall 0.9357227758983268 f1 0.9359872584098173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 14.107885837554932 s\n",
      "Accuracy 0.9326140623571363 precision 0.9327337434143127 specificity 0.8826426732736691 recall 0.9326140623571363 f1 0.9326721860328445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 14.21440052986145 s\n",
      "Accuracy 0.9332540916156167 precision 0.9332347367912135 specificity 0.8742449360210719 recall 0.9332540916156167 f1 0.9332443720742608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 14.118787050247192 s\n",
      "Accuracy 0.9346255828837889 precision 0.9351079106298398 specificity 0.8887796171360907 recall 0.9346255828837889 f1 0.934842209924251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 14.170004606246948 s\n",
      "Accuracy 0.93407698637652 precision 0.934178463435137 specificity 0.8827712200878366 recall 0.93407698637652 f1 0.9341264796623825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 17.42107319831848 s\n",
      "Accuracy 0.9345341501325775 precision 0.9344482849504666 specificity 0.882577594956039 recall 0.9345341501325775 f1 0.934490190495326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 20.89209294319153 s\n",
      "Accuracy 0.9389229221907287 precision 0.9388562591598292 specificity 0.8878407729780604 recall 0.9389229221907287 f1 0.9388889191602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 16.36701798439026 s\n",
      "Accuracy 0.9357227758983268 precision 0.9356449046027527 specificity 0.8828958897211715 recall 0.9357227758983268 f1 0.9356829994538675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 13.714999914169312 s\n",
      "Accuracy 0.9327969278595593 precision 0.9325175936046957 specificity 0.8758893114638564 recall 0.9327969278595593 f1 0.9326460299756726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 14.279046773910522 s\n",
      "Accuracy 0.9368199689128646 precision 0.9366622117705709 specificity 0.883652705034257 recall 0.9368199689128646 f1 0.9367373280093056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 13.827070236206055 s\n",
      "Accuracy 0.9353570448934808 precision 0.9354776268028319 specificity 0.8836761140336444 recall 0.9353570448934808 f1 0.9354155799573486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 13.770146369934082 s\n",
      "Accuracy 0.9346255828837889 precision 0.9349727314171332 specificity 0.8841354626092117 recall 0.9346255828837889 f1 0.9347864443740179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 14.398288011550903 s\n",
      "Accuracy 0.9348998811374234 precision 0.934813165375129 specificity 0.8819833682721977 recall 0.9348998811374234 f1 0.9348554898915599\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 13.931539535522461 s\n",
      "Accuracy 0.9366371034104416 precision 0.9364602894752018 specificity 0.881828470182028 recall 0.9366371034104416 f1 0.9365440751199375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 14.217998743057251 s\n",
      "Accuracy 0.9341684191277315 precision 0.9342225973539641 specificity 0.8830947995961506 recall 0.9341684191277315 f1 0.9341951385957905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 14.34212613105774 s\n",
      "Accuracy 0.9306939745816951 precision 0.930566949316786 specificity 0.8748632301145745 recall 0.9306939745816951 f1 0.9306284596516294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 14.048628568649292 s\n",
      "Accuracy 0.9318826003474444 precision 0.9317665136921409 specificity 0.8771115529609502 recall 0.9318826003474444 f1 0.9318228267794963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 14.003071308135986 s\n",
      "Accuracy 0.9336198226204626 precision 0.9333825430382945 specificity 0.8777150455793942 recall 0.9336198226204626 f1 0.933493083119632\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 13.97035551071167 s\n",
      "Accuracy 0.934259851878943 precision 0.9347156273531391 specificity 0.8850284234843068 recall 0.934259851878943 f1 0.9344668051048142\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 13.859070062637329 s\n",
      "Accuracy 0.9350827466398464 precision 0.9352692734111395 specificity 0.8851374162114571 recall 0.9350827466398464 f1 0.9351718814810603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 14.145746231079102 s\n",
      "Accuracy 0.9349913138886349 precision 0.9349654272334095 specificity 0.8845191798973541 recall 0.9349913138886349 f1 0.9349782782737246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 14.362510681152344 s\n",
      "Accuracy 0.9337112553716741 precision 0.9332315421791454 specificity 0.8753147876435768 recall 0.9337112553716741 f1 0.9334303974469585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 13.992515087127686 s\n",
      "Accuracy 0.9309682728353296 precision 0.9307817070836628 specificity 0.8746757915754259 recall 0.9309682728353296 f1 0.9308704795928693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 14.22571611404419 s\n",
      "Accuracy 0.9335283898692511 precision 0.933519573250178 specificity 0.8825893550439471 recall 0.9335283898692511 f1 0.9335239713576384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 13.991042613983154 s\n",
      "Accuracy 0.934259851878943 precision 0.934362165714481 specificity 0.8822020768644089 recall 0.934259851878943 f1 0.9343097582314749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 13.684464931488037 s\n",
      "Accuracy 0.9375514309225564 precision 0.9377372358828869 specificity 0.8911318779141393 recall 0.9375514309225564 f1 0.9376397895067103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 14.682964324951172 s\n",
      "Accuracy 0.934259851878943 precision 0.9343951305083453 specificity 0.885864919557677 recall 0.934259851878943 f1 0.9343251994673406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 15.230751991271973 s\n",
      "Accuracy 0.9341684191277315 precision 0.9339712463885581 specificity 0.8816596596408106 recall 0.9341684191277315 f1 0.934063942078366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 13.792548418045044 s\n",
      "Accuracy 0.9319740330986559 precision 0.9320860541539495 specificity 0.8808347269367267 recall 0.9319740330986559 f1 0.9320285789251105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 14.2560133934021 s\n",
      "Accuracy 0.9319740330986559 precision 0.9319370239549839 specificity 0.8768764734753806 recall 0.9319740330986559 f1 0.9319553639493972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 14.322909355163574 s\n",
      "Accuracy 0.93160830209381 precision 0.9314657708527775 specificity 0.8762727501931191 recall 0.93160830209381 f1 0.9315344156743766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 14.226016283035278 s\n",
      "Accuracy 0.9321568986010789 precision 0.9320535867108278 specificity 0.8805090108606799 recall 0.9321568986010789 f1 0.9321037848195678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 14.00401520729065 s\n",
      "Accuracy 0.9341684191277315 precision 0.9341164667892677 specificity 0.8829072832840197 recall 0.9341684191277315 f1 0.9341420745489717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 13.923845052719116 s\n",
      "Accuracy 0.9359056414007497 precision 0.9356306707481403 specificity 0.8825638033208256 recall 0.9359056414007497 f1 0.9357555139654183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 13.871858358383179 s\n",
      "Accuracy 0.9295053488159458 precision 0.929630748538434 specificity 0.8768935775815332 recall 0.9295053488159458 f1 0.9295663407377517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 14.43503737449646 s\n",
      "Accuracy 0.9321568986010789 precision 0.9320479467149256 specificity 0.8761626560292772 recall 0.9321568986010789 f1 0.9321009383737274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 13.954031705856323 s\n",
      "Accuracy 0.9346255828837889 precision 0.9353694789223324 specificity 0.8868634383136635 recall 0.9346255828837889 f1 0.9349480553068616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 14.153521060943604 s\n",
      "Accuracy 0.9321568986010789 precision 0.9323112908039132 specificity 0.8793346861665511 recall 0.9321568986010789 f1 0.9322314662776597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 14.216553926467896 s\n",
      "Accuracy 0.9322483313522903 precision 0.9322199038706367 specificity 0.8752700553186459 recall 0.9322483313522903 f1 0.9322340241563292\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 14.277293920516968 s\n",
      "Accuracy 0.9355399103959038 precision 0.9356777793919294 specificity 0.8851283821515986 recall 0.9355399103959038 f1 0.9356065161057419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 14.05912709236145 s\n",
      "Accuracy 0.9334369571180396 precision 0.933621473542805 specificity 0.8849820966682608 recall 0.9334369571180396 f1 0.9335251508251146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 13.995575666427612 s\n",
      "Accuracy 0.9348084483862119 precision 0.9348522136255968 specificity 0.8856452197423397 recall 0.9348084483862119 f1 0.9348300756593464\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 14.077524900436401 s\n",
      "Accuracy 0.9325226296059248 precision 0.9328260734218939 specificity 0.8855751177539051 recall 0.9325226296059248 f1 0.9326640214827647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 13.834699869155884 s\n",
      "Accuracy 0.9281338575477737 precision 0.9280769961053645 specificity 0.8721400509972067 recall 0.9281338575477737 f1 0.9281050627182753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 13.98300576210022 s\n",
      "Accuracy 0.9357227758983268 precision 0.9359514617463957 specificity 0.8885424725841237 recall 0.9357227758983268 f1 0.9358307127661376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 14.068585395812988 s\n",
      "Accuracy 0.9361799396543842 precision 0.9362643284949667 specificity 0.8906738372183951 recall 0.9361799396543842 f1 0.9362211202556994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 14.122479915618896 s\n",
      "Accuracy 0.9306025418304836 precision 0.9306501267891026 specificity 0.8763743282523905 recall 0.9306025418304836 f1 0.9306260791890449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 14.02522325515747 s\n",
      "Accuracy 0.934259851878943 precision 0.9344039668224282 specificity 0.8806685733815646 recall 0.934259851878943 f1 0.9343295651982395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 14.092925071716309 s\n",
      "Accuracy 0.9335283898692511 precision 0.9333385151607133 specificity 0.8812660553390536 recall 0.9335283898692511 f1 0.9334280642928943\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 14.11675500869751 s\n",
      "Accuracy 0.9328883606107707 precision 0.932728175367018 specificity 0.8763926428277531 recall 0.9328883606107707 f1 0.9328049148105644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 14.31302547454834 s\n",
      "Accuracy 0.9320654658498674 precision 0.9319327577027879 specificity 0.8773754669382777 recall 0.9320654658498674 f1 0.9319968082175456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 14.017425298690796 s\n",
      "Accuracy 0.9308768400841181 precision 0.9312658398780046 specificity 0.8798011328941849 recall 0.9308768400841181 f1 0.9310566141416577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 14.227073907852173 s\n",
      "Accuracy 0.9335283898692511 precision 0.9334126161091132 specificity 0.8781824680502486 recall 0.9335283898692511 f1 0.9334687533870435\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 14.042205333709717 s\n",
      "Accuracy 0.9368199689128646 precision 0.9366935338058671 specificity 0.8837010209707313 recall 0.9368199689128646 f1 0.9367544035024628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 13.829871654510498 s\n",
      "Accuracy 0.9282252902989852 precision 0.928157200013676 specificity 0.8695989673871115 recall 0.9282252902989852 f1 0.9281907444538288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 14.248412132263184 s\n",
      "Accuracy 0.9319740330986559 precision 0.9322670923474002 specificity 0.8822278442878623 recall 0.9319740330986559 f1 0.932111406485553\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 14.230045795440674 s\n",
      "Accuracy 0.9345341501325775 precision 0.9342728909325372 specificity 0.8798877672818542 recall 0.9345341501325775 f1 0.9343929597206687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 14.15462875366211 s\n",
      "Accuracy 0.9358142086495382 precision 0.9356286155476872 specificity 0.8809699393995335 recall 0.9358142086495382 f1 0.9357163644738326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 14.704678058624268 s\n",
      "Accuracy 0.931425436591387 precision 0.9315991437830216 specificity 0.8794629528674227 recall 0.931425436591387 f1 0.9315089862881033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 16.620595693588257 s\n",
      "Accuracy 0.9329797933619822 precision 0.9332922469683493 specificity 0.8862796466588997 recall 0.9329797933619822 f1 0.9331250157095801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 17.588789224624634 s\n",
      "Accuracy 0.9322483313522903 precision 0.9318759569528912 specificity 0.8737843497867631 recall 0.9322483313522903 f1 0.9320412643140166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 18.050021409988403 s\n",
      "Accuracy 0.9323397641035018 precision 0.9327479216199844 specificity 0.8816369908402778 recall 0.9323397641035018 f1 0.932527408164093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 17.87351131439209 s\n",
      "Accuracy 0.9355399103959038 precision 0.9356021739145187 specificity 0.8853932139349121 recall 0.9355399103959038 f1 0.9355705370986139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 17.459079027175903 s\n",
      "Accuracy 0.9348998811374234 precision 0.9347692672129948 specificity 0.8848997781296163 recall 0.9348998811374234 f1 0.9348319676401591\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 16.26120948791504 s\n",
      "Accuracy 0.9362713724055957 precision 0.9370697969154765 specificity 0.8936379131164078 recall 0.9362713724055957 f1 0.9366096103202276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 16.542106866836548 s\n",
      "Accuracy 0.9376428636737679 precision 0.9374141011311204 specificity 0.8824801100809471 recall 0.9376428636737679 f1 0.9375202277574815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 16.909599781036377 s\n",
      "Accuracy 0.9358142086495382 precision 0.9356155644620578 specificity 0.8818703876120378 recall 0.9358142086495382 f1 0.9357089070105461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 17.31582546234131 s\n",
      "Accuracy 0.9333455243668282 precision 0.9331168336470673 specificity 0.8779347208711555 recall 0.9333455243668282 f1 0.9332236714488177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 18.388087272644043 s\n",
      "Accuracy 0.9377342964249794 precision 0.9377086058575868 specificity 0.8866182019434149 recall 0.9377342964249794 f1 0.9377213571602354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 18.047406435012817 s\n",
      "Accuracy 0.931242571088964 precision 0.9309412132664582 specificity 0.875174513211909 recall 0.931242571088964 f1 0.9310786894900999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 17.096874475479126 s\n",
      "Accuracy 0.9327054951083478 precision 0.9325199192552068 specificity 0.8794630847529978 recall 0.9327054951083478 f1 0.9326077761672453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 16.702979803085327 s\n",
      "Accuracy 0.9315168693425985 precision 0.931416648739893 specificity 0.8758380634872112 recall 0.9315168693425985 f1 0.9314655172449801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 16.908955812454224 s\n",
      "Accuracy 0.9309682728353296 precision 0.9309775384092038 specificity 0.8776761537373899 recall 0.9309682728353296 f1 0.9309728954495591\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 16.589442014694214 s\n",
      "Accuracy 0.9356313431471153 precision 0.9359626243086714 specificity 0.8859995754996705 recall 0.9356313431471153 f1 0.9357849669098721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 17.16428780555725 s\n",
      "Accuracy 0.9281338575477737 precision 0.9284372346281574 specificity 0.8767873278943216 recall 0.9281338575477737 f1 0.9282765126461933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 17.225427865982056 s\n",
      "Accuracy 0.9348998811374234 precision 0.9353063781817836 specificity 0.8883599253070164 recall 0.9348998811374234 f1 0.935085066843784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 16.84696078300476 s\n",
      "Accuracy 0.93160830209381 precision 0.931724364403644 specificity 0.8776323999267797 recall 0.93160830209381 f1 0.9316648540687095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 16.97334933280945 s\n",
      "Accuracy 0.9343512846301545 precision 0.9341910391542997 specificity 0.8770726053035415 recall 0.9343512846301545 f1 0.934267770840181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 17.478639125823975 s\n",
      "Accuracy 0.9364542379080186 precision 0.9363959996740209 specificity 0.886954090214861 recall 0.9364542379080186 f1 0.936424615254517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 18.003699779510498 s\n",
      "Accuracy 0.9332540916156167 precision 0.9335778384633254 specificity 0.8862922487911848 recall 0.9332540916156167 f1 0.933404248508864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 18.682631254196167 s\n",
      "Accuracy 0.9331626588644052 precision 0.9330652810009062 specificity 0.8790948898849006 recall 0.9331626588644052 f1 0.9331127255594193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 18.237942695617676 s\n",
      "Accuracy 0.9338026881228856 precision 0.933896151730136 specificity 0.8812338083099328 recall 0.9338026881228856 f1 0.9338483871235239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 17.810704946517944 s\n",
      "Accuracy 0.9360885069031727 precision 0.9360452428987713 specificity 0.8843015736295643 recall 0.9360885069031727 f1 0.9360666156811328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 18.05617904663086 s\n",
      "Accuracy 0.93407698637652 precision 0.9338379264049949 specificity 0.8798359601618222 recall 0.93407698637652 f1 0.9339488101697284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 17.870079040527344 s\n",
      "Accuracy 0.9362713724055957 precision 0.9362257453474584 specificity 0.8800162423316192 recall 0.9362713724055957 f1 0.9362482942676664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 17.629059076309204 s\n",
      "Accuracy 0.9328883606107707 precision 0.9326451573807443 specificity 0.8753424645178483 recall 0.9328883606107707 f1 0.9327586360443179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 17.83780288696289 s\n",
      "Accuracy 0.9339855536253086 precision 0.9336299665496404 specificity 0.8735325275107854 recall 0.9339855536253086 f1 0.9337892383726292\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 17.961540460586548 s\n",
      "Accuracy 0.9367285361616531 precision 0.9367633615884257 specificity 0.8868767165988048 recall 0.9367285361616531 f1 0.9367457832632549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 18.44761037826538 s\n",
      "Accuracy 0.9385571911858828 precision 0.9384295067572122 specificity 0.8884837546197447 recall 0.9385571911858828 f1 0.9384906893987139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 18.630987882614136 s\n",
      "Accuracy 0.9329797933619822 precision 0.9328243376749515 specificity 0.874422928767132 recall 0.9329797933619822 f1 0.9328990468634435\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 18.367353200912476 s\n",
      "Accuracy 0.9351741793910578 precision 0.93527498733752 specificity 0.8839607495051971 recall 0.9351741793910578 f1 0.935223330996197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 17.86936116218567 s\n",
      "Accuracy 0.9317911675962329 precision 0.9325248737958655 specificity 0.8873353259172911 recall 0.9317911675962329 f1 0.9321086441810665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 17.968693256378174 s\n",
      "Accuracy 0.9336198226204626 precision 0.933300933548115 specificity 0.8753986164227829 recall 0.9336198226204626 f1 0.9334453642662378\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 18.17360019683838 s\n",
      "Accuracy 0.9361799396543842 precision 0.9358937413261558 specificity 0.8814583270399993 recall 0.9361799396543842 f1 0.9360233698678774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 18.002026081085205 s\n",
      "Accuracy 0.934259851878943 precision 0.934393919790011 specificity 0.8865683405166771 recall 0.934259851878943 f1 0.9343246012699407\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 17.773061752319336 s\n",
      "Accuracy 0.9364542379080186 precision 0.936427900803161 specificity 0.8839464157200319 recall 0.9364542379080186 f1 0.9364409754752273\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 18.5349178314209 s\n",
      "Accuracy 0.9303282435768492 precision 0.930385150565774 specificity 0.8767988569559009 recall 0.9303282435768492 f1 0.9303563311427278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 18.407442092895508 s\n",
      "Accuracy 0.9317911675962329 precision 0.9319586965082984 specificity 0.8826783266864179 recall 0.9317911675962329 f1 0.9318716612417879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 17.787733554840088 s\n",
      "Accuracy 0.9327969278595593 precision 0.9328998830145078 specificity 0.8808190435056072 recall 0.9327969278595593 f1 0.93284716529483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 18.522009134292603 s\n",
      "Accuracy 0.9366371034104416 precision 0.93673624019171 specificity 0.8861765595554839 recall 0.9366371034104416 f1 0.9366854131910707\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 18.0140643119812 s\n",
      "Accuracy 0.9277681265429277 precision 0.9280933939339089 specificity 0.8766605794911455 recall 0.9277681265429277 f1 0.9279205047331954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 17.967076301574707 s\n",
      "Accuracy 0.9361799396543842 precision 0.9359916570212047 specificity 0.8799694566962526 recall 0.9361799396543842 f1 0.9360807104870338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 17.889085292816162 s\n",
      "Accuracy 0.9339855536253086 precision 0.9339673848497307 specificity 0.88010998411357 recall 0.9339855536253086 f1 0.9339764278259175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 17.946610927581787 s\n",
      "Accuracy 0.9341684191277315 precision 0.9339096388786675 specificity 0.8758708199845472 recall 0.9341684191277315 f1 0.9340296165588862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 18.121344804763794 s\n",
      "Accuracy 0.9337112553716741 precision 0.9337025330016498 specificity 0.883542640953372 recall 0.9337112553716741 f1 0.9337068840086875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 18.01661729812622 s\n",
      "Accuracy 0.9348084483862119 precision 0.935096192859295 specificity 0.8885074275493868 recall 0.9348084483862119 f1 0.934942537479645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 18.4253408908844 s\n",
      "Accuracy 0.9394715186979976 precision 0.9399116508983876 specificity 0.8974703592415987 recall 0.9394715186979976 f1 0.9396678137052429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 17.74957585334778 s\n",
      "Accuracy 0.9293224833135229 precision 0.9292938124665988 specificity 0.8729405906825622 recall 0.9293224833135229 f1 0.9293080560946922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 18.2204647064209 s\n",
      "Accuracy 0.9329797933619822 precision 0.9329341988111065 specificity 0.8783437451950422 recall 0.9329797933619822 f1 0.9329567381173707\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 18.25006103515625 s\n",
      "Accuracy 0.9384657584346713 precision 0.9383592154307978 specificity 0.887340383079252 recall 0.9384657584346713 f1 0.9384107215083117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 18.015058517456055 s\n",
      "Accuracy 0.9304196763280607 precision 0.9299714784727695 specificity 0.871194235196776 recall 0.9304196763280607 f1 0.9301646676232821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 17.922973155975342 s\n",
      "Accuracy 0.9295967815671573 precision 0.9291970016236174 specificity 0.8682698445999503 recall 0.9295967815671573 f1 0.9293751303168771\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 17.894926071166992 s\n",
      "Accuracy 0.9319740330986559 precision 0.9319199874142445 specificity 0.8785225287586923 recall 0.9319740330986559 f1 0.9319466426920834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 17.975688934326172 s\n",
      "Accuracy 0.9345341501325775 precision 0.9343577968962079 specificity 0.8773420415868239 recall 0.9345341501325775 f1 0.934441787098207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 18.03712773323059 s\n",
      "Accuracy 0.9353570448934808 precision 0.9349632502045269 specificity 0.8786517162824034 recall 0.9353570448934808 f1 0.935133136775351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 17.98953676223755 s\n",
      "Accuracy 0.9367285361616531 precision 0.9370131053324167 specificity 0.8877474527893138 recall 0.9367285361616531 f1 0.9368614470683865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 18.312411785125732 s\n",
      "Accuracy 0.9316997348450214 precision 0.9317454202589094 specificity 0.8804087704014341 recall 0.9316997348450214 f1 0.9317223240492951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 18.067798614501953 s\n",
      "Accuracy 0.9295967815671573 precision 0.9297775065124254 specificity 0.8749209104935243 recall 0.9295967815671573 f1 0.9296838358122222\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 18.097535610198975 s\n",
      "Accuracy 0.9327969278595593 precision 0.9323578514044374 specificity 0.8713626539736563 recall 0.9327969278595593 f1 0.9325480665053818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 19.097132682800293 s\n",
      "Accuracy 0.937094267166499 precision 0.9368060860655986 specificity 0.8813046582325912 recall 0.937094267166499 f1 0.936936574966653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 19.101633548736572 s\n",
      "Accuracy 0.9363628051568071 precision 0.936719632409998 specificity 0.8906319845296936 recall 0.9363628051568071 f1 0.9365263876779232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 18.846311807632446 s\n",
      "Accuracy 0.9349913138886349 precision 0.9352346101537135 specificity 0.8897949955724506 recall 0.9349913138886349 f1 0.9351055819006365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 18.717697620391846 s\n",
      "Accuracy 0.9359970741519612 precision 0.9358951226255182 specificity 0.8835783035818665 recall 0.9359970741519612 f1 0.9359446056492687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 17.679310083389282 s\n",
      "Accuracy 0.9381000274298253 precision 0.9380582214610849 specificity 0.8880647958255004 recall 0.9381000274298253 f1 0.9380788643361347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 17.164230585098267 s\n",
      "Accuracy 0.9300539453232147 precision 0.9301582397440604 specificity 0.8781046123381786 recall 0.9300539453232147 f1 0.9301048702944175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 17.051153421401978 s\n",
      "Accuracy 0.9343512846301545 precision 0.9347912338957068 specificity 0.885884399463485 recall 0.9343512846301545 f1 0.934551309688274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 16.948610305786133 s\n",
      "Accuracy 0.9360885069031727 precision 0.9360280775653635 specificity 0.8838791478388855 recall 0.9360885069031727 f1 0.9360577835827701\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 16.71484136581421 s\n",
      "Accuracy 0.9327969278595593 precision 0.9327501432989241 specificity 0.8760492968796773 recall 0.9327969278595593 f1 0.932773275612525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 17.123573303222656 s\n",
      "Accuracy 0.9305111090792721 precision 0.9301976013164547 specificity 0.8715798341093632 recall 0.9305111090792721 f1 0.9303410510549965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 16.95231318473816 s\n",
      "Accuracy 0.9320654658498674 precision 0.9319638040261943 specificity 0.8749021091814663 recall 0.9320654658498674 f1 0.9320133820137811\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 17.016496181488037 s\n",
      "Accuracy 0.9319740330986559 precision 0.9320665848954978 specificity 0.8809636526965533 recall 0.9319740330986559 f1 0.9320192930691723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 17.386017084121704 s\n",
      "Accuracy 0.9325226296059248 precision 0.9328434940023334 specificity 0.8809506305843262 recall 0.9325226296059248 f1 0.9326725239945967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 18.14548349380493 s\n",
      "Accuracy 0.936911401664076 precision 0.936734783127378 specificity 0.8853805753325964 recall 0.936911401664076 f1 0.9368180877345458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 17.89521336555481 s\n",
      "Accuracy 0.9328883606107707 precision 0.9334110572477606 specificity 0.8866682884295739 recall 0.9328883606107707 f1 0.9331222659770932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 18.37415909767151 s\n",
      "Accuracy 0.9345341501325775 precision 0.9344456148630872 specificity 0.8801021107254652 recall 0.9345341501325775 f1 0.9344888444759085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 17.729056119918823 s\n",
      "Accuracy 0.9355399103959038 precision 0.9357754094806207 specificity 0.8860779721480337 recall 0.9355399103959038 f1 0.9356511939917631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 18.209762573242188 s\n",
      "Accuracy 0.9309682728353296 precision 0.9311296575360075 specificity 0.8802670352935108 recall 0.9309682728353296 f1 0.9310460416157731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 18.15159821510315 s\n",
      "Accuracy 0.9332540916156167 precision 0.9328878759455397 specificity 0.8740299134632823 recall 0.9332540916156167 f1 0.9330508489211743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 18.074848651885986 s\n",
      "Accuracy 0.9317911675962329 precision 0.9317003694215709 specificity 0.8765703173065872 recall 0.9317911675962329 f1 0.9317447423388389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 18.233123302459717 s\n",
      "Accuracy 0.9367285361616531 precision 0.9363923397376115 specificity 0.88221935853986 recall 0.9367285361616531 f1 0.9365403291476669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 17.851081371307373 s\n",
      "Accuracy 0.934442717381366 precision 0.9344000223933681 specificity 0.8844427338148736 recall 0.934442717381366 f1 0.9344211149922965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 18.166258096694946 s\n",
      "Accuracy 0.9359056414007497 precision 0.9357617196887787 specificity 0.8822803566776897 recall 0.9359056414007497 f1 0.9358306756845048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 17.854244470596313 s\n",
      "Accuracy 0.9320654658498674 precision 0.9317840902789054 specificity 0.874961072396817 recall 0.9320654658498674 f1 0.9319135809936295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 18.070477724075317 s\n",
      "Accuracy 0.9351741793910578 precision 0.9352373643596256 specificity 0.8840025700854612 recall 0.9351741793910578 f1 0.9352052655527129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 18.02546000480652 s\n",
      "Accuracy 0.9346255828837889 precision 0.9349270849227602 specificity 0.8901649896741198 recall 0.9346255828837889 f1 0.9347653434117689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 18.126155376434326 s\n",
      "Accuracy 0.9341684191277315 precision 0.9344351125550989 specificity 0.8851679566794933 recall 0.9341684191277315 f1 0.9342937250403558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 17.9156494140625 s\n",
      "Accuracy 0.93407698637652 precision 0.9341998027783581 specificity 0.8813876632075601 recall 0.93407698637652 f1 0.9341366437100777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 17.723567962646484 s\n",
      "Accuracy 0.9309682728353296 precision 0.9308638799925204 specificity 0.8720198685290006 recall 0.9309682728353296 f1 0.9309148219750248\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 18.95077610015869 s\n",
      "Accuracy 0.9346255828837889 precision 0.9344658413762423 specificity 0.8815848339364288 recall 0.9346255828837889 f1 0.934541996675743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 18.322471857070923 s\n",
      "Accuracy 0.9338941208740971 precision 0.9341516600135202 specificity 0.8845848668416945 recall 0.9338941208740971 f1 0.9340154177168826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 17.46055245399475 s\n",
      "Accuracy 0.9341684191277315 precision 0.9348746134592165 specificity 0.8949259036118755 recall 0.9341684191277315 f1 0.9344698096606404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 17.09810996055603 s\n",
      "Accuracy 0.9331626588644052 precision 0.933245877873461 specificity 0.8814535579715372 recall 0.9331626588644052 f1 0.9332034380649874\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 18.033079624176025 s\n",
      "Accuracy 0.9316997348450214 precision 0.9316715164276941 specificity 0.8756164112152642 recall 0.9316997348450214 f1 0.9316855327961707\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 18.47906756401062 s\n",
      "Accuracy 0.9319740330986559 precision 0.9320715449490011 specificity 0.8765418374714518 recall 0.9319740330986559 f1 0.9320217542959464\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 17.715148210525513 s\n",
      "Accuracy 0.9324311968547133 precision 0.9323135943224482 specificity 0.8763075821805439 recall 0.9324311968547133 f1 0.9323706506987226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 17.62506628036499 s\n",
      "Accuracy 0.9365456706592301 precision 0.9366135802456723 specificity 0.8898846692726813 recall 0.9365456706592301 f1 0.9365789723143726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 18.66755485534668 s\n",
      "Accuracy 0.9317911675962329 precision 0.9319431268035675 specificity 0.8804498180356944 recall 0.9317911675962329 f1 0.9318645401300193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 18.130594968795776 s\n",
      "Accuracy 0.9325226296059248 precision 0.9325600188623822 specificity 0.8787033963075132 recall 0.9325226296059248 f1 0.9325411596095349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 17.884000062942505 s\n",
      "Accuracy 0.9326140623571363 precision 0.9330771660555923 specificity 0.8867119849662065 recall 0.9326140623571363 f1 0.9328233015494678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 18.540535926818848 s\n",
      "Accuracy 0.9301453780744262 precision 0.9304454012047501 specificity 0.8790532143051205 recall 0.9301453780744262 f1 0.9302862710431247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 18.28546643257141 s\n",
      "Accuracy 0.9299625125720032 precision 0.9299072220211355 specificity 0.8755294653644895 recall 0.9299625125720032 f1 0.9299345020657144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 17.709083080291748 s\n",
      "Accuracy 0.9323397641035018 precision 0.9320271808846904 specificity 0.8764660547556127 recall 0.9323397641035018 f1 0.9321687008816039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 17.866686820983887 s\n",
      "Accuracy 0.9274023955380818 precision 0.9271314412252695 specificity 0.8632836388351603 recall 0.9274023955380818 f1 0.9272588231048267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 18.018737077713013 s\n",
      "Accuracy 0.934442717381366 precision 0.9345842887302084 specificity 0.8822848188957398 recall 0.934442717381366 f1 0.9345111708778359\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 17.732507705688477 s\n",
      "Accuracy 0.9339855536253086 precision 0.9346336467606792 specificity 0.8901815939689675 recall 0.9339855536253086 f1 0.9342680358763158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 17.880014896392822 s\n",
      "Accuracy 0.9345341501325775 precision 0.9347417572626521 specificity 0.8844197049035278 recall 0.9345341501325775 f1 0.9346329661403481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 18.588682174682617 s\n",
      "Accuracy 0.9355399103959038 precision 0.9353364944561923 specificity 0.8765976405232525 recall 0.9355399103959038 f1 0.9354325991867386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 17.67812442779541 s\n",
      "Accuracy 0.9349913138886349 precision 0.9352060507388964 specificity 0.8858695297384948 recall 0.9349913138886349 f1 0.9350932389829857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 17.67969846725464 s\n",
      "Accuracy 0.9326140623571363 precision 0.9327184223059876 specificity 0.8795749897983897 recall 0.9326140623571363 f1 0.9326649978709295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 17.8855562210083 s\n",
      "Accuracy 0.9305111090792721 precision 0.930493525667097 specificity 0.8808034530212633 recall 0.9305111090792721 f1 0.9305022774092216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 17.856592416763306 s\n",
      "Accuracy 0.9339855536253086 precision 0.9340897496174643 specificity 0.8877659507769037 recall 0.9339855536253086 f1 0.9340362027461812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 17.890069007873535 s\n",
      "Accuracy 0.9332540916156167 precision 0.9331624108668912 specificity 0.8765083049710894 recall 0.9332540916156167 f1 0.9332072104787874\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 18.30687165260315 s\n",
      "Accuracy 0.9352656121422693 precision 0.9348356111057468 specificity 0.8774519110224387 recall 0.9352656121422693 f1 0.9350179608095608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 17.8752703666687 s\n",
      "Accuracy 0.9358142086495382 precision 0.9358317768784203 specificity 0.8850587302266083 recall 0.9358142086495382 f1 0.9358229514358034\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 17.788780450820923 s\n",
      "Accuracy 0.9306939745816951 precision 0.9310643140646486 specificity 0.878680263756897 recall 0.9306939745816951 f1 0.9308658986337294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 17.765228748321533 s\n",
      "Accuracy 0.9297796470695803 precision 0.9295566888415076 specificity 0.8693364672202628 recall 0.9297796470695803 f1 0.9296622222622893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 17.85478377342224 s\n",
      "Accuracy 0.9311511383377525 precision 0.9313361924814515 specificity 0.8788016891763372 recall 0.9311511383377525 f1 0.9312399824857982\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 17.861067056655884 s\n",
      "Accuracy 0.9346255828837889 precision 0.9344027580108578 specificity 0.8806157571512515 recall 0.9346255828837889 f1 0.9345066564062675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 18.213109254837036 s\n",
      "Accuracy 0.9329797933619822 precision 0.9330070876819562 specificity 0.880914449558691 recall 0.9329797933619822 f1 0.9329933484048037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 18.39696741104126 s\n",
      "Accuracy 0.9326140623571363 precision 0.9334279165328621 specificity 0.8864374831878818 recall 0.9326140623571363 f1 0.9329634973449894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 18.156084299087524 s\n",
      "Accuracy 0.9333455243668282 precision 0.9333188786282436 specificity 0.881307561591407 recall 0.9333455243668282 f1 0.9333321093972894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 17.956968307495117 s\n",
      "Accuracy 0.93407698637652 precision 0.9338725253600956 specificity 0.8816652622934497 recall 0.93407698637652 f1 0.9339683718540718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 17.680400848388672 s\n",
      "Accuracy 0.9339855536253086 precision 0.9335514791598468 specificity 0.8762452589885659 recall 0.9339855536253086 f1 0.9337360934062668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 17.652536392211914 s\n",
      "Accuracy 0.9334369571180396 precision 0.9336240208349503 specificity 0.8838786283897656 recall 0.9334369571180396 f1 0.9335264048343982\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 17.693065404891968 s\n",
      "Accuracy 0.9337112553716741 precision 0.933665258840875 specificity 0.8779917768498494 recall 0.9337112553716741 f1 0.9336879969298338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 17.911535501480103 s\n",
      "Accuracy 0.93160830209381 precision 0.9318095606508294 specificity 0.8765333365208416 recall 0.93160830209381 f1 0.9317047930850239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 17.797619342803955 s\n",
      "Accuracy 0.9336198226204626 precision 0.933106499366587 specificity 0.8726325650673133 recall 0.9336198226204626 f1 0.9333177487225679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 17.868051052093506 s\n",
      "Accuracy 0.9330712261131937 precision 0.9331819608163149 specificity 0.8824397421862881 recall 0.9330712261131937 f1 0.9331251233648364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 18.049225330352783 s\n",
      "Accuracy 0.9321568986010789 precision 0.9321380614375898 specificity 0.8760515906987995 recall 0.9321568986010789 f1 0.9321474386379898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 18.2240309715271 s\n",
      "Accuracy 0.9350827466398464 precision 0.9354041170939066 specificity 0.8881071749061297 recall 0.9350827466398464 f1 0.9352315958022936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 19.443533182144165 s\n",
      "Accuracy 0.9341684191277315 precision 0.9340641140791877 specificity 0.8808071179087983 recall 0.9341684191277315 f1 0.9341147826305553\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 17.874898672103882 s\n",
      "Accuracy 0.9334369571180396 precision 0.9336258168111934 specificity 0.8830975455518995 recall 0.9334369571180396 f1 0.9335272889643215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 17.734625577926636 s\n",
      "Accuracy 0.9334369571180396 precision 0.9336735922260055 specificity 0.880633209189471 recall 0.9334369571180396 f1 0.9335493024102227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 17.92246437072754 s\n",
      "Accuracy 0.931242571088964 precision 0.9311679895978728 specificity 0.8746347148132325 recall 0.931242571088964 f1 0.9312046214013022\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 17.96159791946411 s\n",
      "Accuracy 0.9328883606107707 precision 0.9329979254802375 specificity 0.8831878793878388 recall 0.9328883606107707 f1 0.9329416802444438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 17.872561931610107 s\n",
      "Accuracy 0.9338026881228856 precision 0.9338214157957843 specificity 0.8786671242004889 recall 0.9338026881228856 f1 0.9338120103119469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 17.83610773086548 s\n",
      "Accuracy 0.9348998811374234 precision 0.9349921143662328 specificity 0.8829751680690143 recall 0.9348998811374234 f1 0.9349449614873162\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "split_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "smote_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, (split_seed, smote_seed) in enumerate(zip(split_seeds, smote_seeds)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=split_seed)\n",
    "    smote = SMOTE(random_state=smote_seed, n_jobs=THREADS_TO_USE)\n",
    "    x_smote, y_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_smote, y_smote)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(split_seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.931517     0.880704   0.931638  0.931517  0.931576\n1  0.932248     0.870504   0.931780  0.932248  0.931980\n2  0.933528     0.879472   0.933466  0.933528  0.933497\n3  0.929597     0.871070   0.929395  0.929597  0.929491\n4  0.935357     0.884270   0.935661  0.935357  0.935499\n5  0.935357     0.889136   0.935984  0.935357  0.935632\n6  0.932980     0.877738   0.933148  0.932980  0.933061\n7  0.932797     0.874387   0.932528  0.932797  0.932652\n8  0.933620     0.884427   0.933826  0.933620  0.933718\n9  0.935723     0.887753   0.935856  0.935723  0.935787",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.931517</td>\n      <td>0.880704</td>\n      <td>0.931638</td>\n      <td>0.931517</td>\n      <td>0.931576</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.932248</td>\n      <td>0.870504</td>\n      <td>0.931780</td>\n      <td>0.932248</td>\n      <td>0.931980</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.933528</td>\n      <td>0.879472</td>\n      <td>0.933466</td>\n      <td>0.933528</td>\n      <td>0.933497</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.929597</td>\n      <td>0.871070</td>\n      <td>0.929395</td>\n      <td>0.929597</td>\n      <td>0.929491</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.935357</td>\n      <td>0.884270</td>\n      <td>0.935661</td>\n      <td>0.935357</td>\n      <td>0.935499</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.935357</td>\n      <td>0.889136</td>\n      <td>0.935984</td>\n      <td>0.935357</td>\n      <td>0.935632</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.932980</td>\n      <td>0.877738</td>\n      <td>0.933148</td>\n      <td>0.932980</td>\n      <td>0.933061</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.932797</td>\n      <td>0.874387</td>\n      <td>0.932528</td>\n      <td>0.932797</td>\n      <td>0.932652</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.933620</td>\n      <td>0.884427</td>\n      <td>0.933826</td>\n      <td>0.933620</td>\n      <td>0.933718</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.935723</td>\n      <td>0.887753</td>\n      <td>0.935856</td>\n      <td>0.935723</td>\n      <td>0.935787</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.9336454237908018\n",
      "Precision 0.9336944437558495\n",
      "Specificity 0.8813309310048197\n",
      "Recall 0.9336454237908018\n",
      "F1 0.933660787937872\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_10beats_smote_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}