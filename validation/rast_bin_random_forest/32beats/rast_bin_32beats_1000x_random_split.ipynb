{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 32 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id        dw_1        dw_2        dw_3       dw_4      dw_5     mfw_1  \\\n0  e0106  133.429003  134.242162  133.489322  37.853305  5.508392  0.586324   \n1  e0106  133.965830  136.903950  136.743215  38.927755  5.696305  0.593533   \n2  e0106  139.274723  140.184030  140.070259  39.704137  5.761162  0.577124   \n3  e0106  138.676856  143.380168  143.473350  40.663806  5.859970  0.588245   \n4  e0106  140.755171  142.872499  143.424214  40.769824  5.919625  0.585157   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.522381 -0.788889 -0.136987  ... -0.042238  0.026644 -0.034630  0.040781   \n1 -0.515953 -0.790798 -0.224475  ... -0.052676  0.042240 -0.050718  0.057318   \n2 -0.518431 -0.807961 -0.219536  ... -0.051818  0.032123 -0.034994  0.042277   \n3 -0.513443 -0.810437 -0.247007  ... -0.057101  0.036792 -0.033449  0.035388   \n4 -0.517127 -0.798512 -0.176490  ... -0.031786  0.019955 -0.031716  0.039832   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.065560  0.001347 -0.022417 -0.007807 -0.008983    NSR  \n1 -0.078975  0.010010 -0.026053 -0.011060 -0.004790    NSR  \n2 -0.076328  0.011880 -0.026580 -0.008271 -0.005162    NSR  \n3 -0.067010  0.008826 -0.025932 -0.011778 -0.000208    NSR  \n4 -0.068147  0.004500 -0.023807 -0.012157 -0.002940    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>133.429003</td>\n      <td>134.242162</td>\n      <td>133.489322</td>\n      <td>37.853305</td>\n      <td>5.508392</td>\n      <td>0.586324</td>\n      <td>-0.522381</td>\n      <td>-0.788889</td>\n      <td>-0.136987</td>\n      <td>...</td>\n      <td>-0.042238</td>\n      <td>0.026644</td>\n      <td>-0.034630</td>\n      <td>0.040781</td>\n      <td>-0.065560</td>\n      <td>0.001347</td>\n      <td>-0.022417</td>\n      <td>-0.007807</td>\n      <td>-0.008983</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>133.965830</td>\n      <td>136.903950</td>\n      <td>136.743215</td>\n      <td>38.927755</td>\n      <td>5.696305</td>\n      <td>0.593533</td>\n      <td>-0.515953</td>\n      <td>-0.790798</td>\n      <td>-0.224475</td>\n      <td>...</td>\n      <td>-0.052676</td>\n      <td>0.042240</td>\n      <td>-0.050718</td>\n      <td>0.057318</td>\n      <td>-0.078975</td>\n      <td>0.010010</td>\n      <td>-0.026053</td>\n      <td>-0.011060</td>\n      <td>-0.004790</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>139.274723</td>\n      <td>140.184030</td>\n      <td>140.070259</td>\n      <td>39.704137</td>\n      <td>5.761162</td>\n      <td>0.577124</td>\n      <td>-0.518431</td>\n      <td>-0.807961</td>\n      <td>-0.219536</td>\n      <td>...</td>\n      <td>-0.051818</td>\n      <td>0.032123</td>\n      <td>-0.034994</td>\n      <td>0.042277</td>\n      <td>-0.076328</td>\n      <td>0.011880</td>\n      <td>-0.026580</td>\n      <td>-0.008271</td>\n      <td>-0.005162</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>138.676856</td>\n      <td>143.380168</td>\n      <td>143.473350</td>\n      <td>40.663806</td>\n      <td>5.859970</td>\n      <td>0.588245</td>\n      <td>-0.513443</td>\n      <td>-0.810437</td>\n      <td>-0.247007</td>\n      <td>...</td>\n      <td>-0.057101</td>\n      <td>0.036792</td>\n      <td>-0.033449</td>\n      <td>0.035388</td>\n      <td>-0.067010</td>\n      <td>0.008826</td>\n      <td>-0.025932</td>\n      <td>-0.011778</td>\n      <td>-0.000208</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>140.755171</td>\n      <td>142.872499</td>\n      <td>143.424214</td>\n      <td>40.769824</td>\n      <td>5.919625</td>\n      <td>0.585157</td>\n      <td>-0.517127</td>\n      <td>-0.798512</td>\n      <td>-0.176490</td>\n      <td>...</td>\n      <td>-0.031786</td>\n      <td>0.019955</td>\n      <td>-0.031716</td>\n      <td>0.039832</td>\n      <td>-0.068147</td>\n      <td>0.004500</td>\n      <td>-0.023807</td>\n      <td>-0.012157</td>\n      <td>-0.002940</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_32beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    13090\nST      3982\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.237685  0.106778  0.074513  0.049017  0.164754 -0.043134   \ndw_2    0.237685  1.000000  0.838142  0.502265  0.189472  0.396750 -0.511218   \ndw_3    0.106778  0.838142  1.000000  0.702042  0.287089  0.241283 -0.555562   \ndw_4    0.074513  0.502265  0.702042  1.000000  0.873295 -0.014716 -0.278260   \ndw_5    0.049017  0.189472  0.287089  0.873295  1.000000 -0.124955 -0.026226   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.074357  0.037079  0.066460  0.051749  0.016077 -0.150115  0.112145   \ncfr_13 -0.049488  0.134331  0.043879  0.026810  0.019832  0.073383 -0.006052   \ncfr_14 -0.067248  0.012952 -0.017784 -0.031360 -0.039655 -0.001977  0.028472   \ncfr_15 -0.103371 -0.116243 -0.133008 -0.111832 -0.062702  0.047377  0.081087   \ncfr_16 -0.094220 -0.070422 -0.045069 -0.044385 -0.031614  0.064713 -0.029821   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.066522 -0.005085  0.007374  ... -0.101746 -0.045780 -0.057627   \ndw_2   -0.362148  0.007304  0.027974  ... -0.110800  0.180227  0.237271   \ndw_3   -0.499643  0.012774  0.016280  ... -0.199872  0.154880  0.275167   \ndw_4   -0.278962  0.008457  0.006416  ... -0.152384  0.071768  0.115122   \ndw_5   -0.049222  0.001954  0.000388  ... -0.063773  0.011881 -0.006932   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.135231 -0.002228  0.004135  ... -0.135005 -0.212171 -0.056621   \ncfr_13  0.015178  0.006819 -0.001301  ...  0.163738  0.044522 -0.209958   \ncfr_14  0.029755  0.005549 -0.006743  ...  0.121685  0.230485  0.039279   \ncfr_15  0.044183  0.001850 -0.014418  ...  0.293341  0.157001 -0.089191   \ncfr_16 -0.008364  0.011768 -0.004271  ...  0.268445  0.129772  0.199429   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.042941 -0.032342 -0.074357 -0.049488 -0.067248 -0.103371 -0.094220  \ndw_2    0.173162  0.054253  0.037079  0.134331  0.012952 -0.116243 -0.070422  \ndw_3    0.120954 -0.052022  0.066460  0.043879 -0.017784 -0.133008 -0.045069  \ndw_4    0.067878 -0.039769  0.051749  0.026810 -0.031360 -0.111832 -0.044385  \ndw_5    0.044290  0.004779  0.016077  0.019832 -0.039655 -0.062702 -0.031614  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.041745  0.071561  1.000000  0.024910  0.010580 -0.361983 -0.228896  \ncfr_13 -0.266707  0.009957  0.024910  1.000000  0.238508  0.156749 -0.141656  \ncfr_14 -0.173963 -0.282881  0.010580  0.238508  1.000000  0.221302 -0.128261  \ncfr_15 -0.138736 -0.062263 -0.361983  0.156749  0.221302  1.000000  0.344573  \ncfr_16  0.174509  0.012025 -0.228896 -0.141656 -0.128261  0.344573  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.237685</td>\n      <td>0.106778</td>\n      <td>0.074513</td>\n      <td>0.049017</td>\n      <td>0.164754</td>\n      <td>-0.043134</td>\n      <td>0.066522</td>\n      <td>-0.005085</td>\n      <td>0.007374</td>\n      <td>...</td>\n      <td>-0.101746</td>\n      <td>-0.045780</td>\n      <td>-0.057627</td>\n      <td>-0.042941</td>\n      <td>-0.032342</td>\n      <td>-0.074357</td>\n      <td>-0.049488</td>\n      <td>-0.067248</td>\n      <td>-0.103371</td>\n      <td>-0.094220</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.237685</td>\n      <td>1.000000</td>\n      <td>0.838142</td>\n      <td>0.502265</td>\n      <td>0.189472</td>\n      <td>0.396750</td>\n      <td>-0.511218</td>\n      <td>-0.362148</td>\n      <td>0.007304</td>\n      <td>0.027974</td>\n      <td>...</td>\n      <td>-0.110800</td>\n      <td>0.180227</td>\n      <td>0.237271</td>\n      <td>0.173162</td>\n      <td>0.054253</td>\n      <td>0.037079</td>\n      <td>0.134331</td>\n      <td>0.012952</td>\n      <td>-0.116243</td>\n      <td>-0.070422</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.106778</td>\n      <td>0.838142</td>\n      <td>1.000000</td>\n      <td>0.702042</td>\n      <td>0.287089</td>\n      <td>0.241283</td>\n      <td>-0.555562</td>\n      <td>-0.499643</td>\n      <td>0.012774</td>\n      <td>0.016280</td>\n      <td>...</td>\n      <td>-0.199872</td>\n      <td>0.154880</td>\n      <td>0.275167</td>\n      <td>0.120954</td>\n      <td>-0.052022</td>\n      <td>0.066460</td>\n      <td>0.043879</td>\n      <td>-0.017784</td>\n      <td>-0.133008</td>\n      <td>-0.045069</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.074513</td>\n      <td>0.502265</td>\n      <td>0.702042</td>\n      <td>1.000000</td>\n      <td>0.873295</td>\n      <td>-0.014716</td>\n      <td>-0.278260</td>\n      <td>-0.278962</td>\n      <td>0.008457</td>\n      <td>0.006416</td>\n      <td>...</td>\n      <td>-0.152384</td>\n      <td>0.071768</td>\n      <td>0.115122</td>\n      <td>0.067878</td>\n      <td>-0.039769</td>\n      <td>0.051749</td>\n      <td>0.026810</td>\n      <td>-0.031360</td>\n      <td>-0.111832</td>\n      <td>-0.044385</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.049017</td>\n      <td>0.189472</td>\n      <td>0.287089</td>\n      <td>0.873295</td>\n      <td>1.000000</td>\n      <td>-0.124955</td>\n      <td>-0.026226</td>\n      <td>-0.049222</td>\n      <td>0.001954</td>\n      <td>0.000388</td>\n      <td>...</td>\n      <td>-0.063773</td>\n      <td>0.011881</td>\n      <td>-0.006932</td>\n      <td>0.044290</td>\n      <td>0.004779</td>\n      <td>0.016077</td>\n      <td>0.019832</td>\n      <td>-0.039655</td>\n      <td>-0.062702</td>\n      <td>-0.031614</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.074357</td>\n      <td>0.037079</td>\n      <td>0.066460</td>\n      <td>0.051749</td>\n      <td>0.016077</td>\n      <td>-0.150115</td>\n      <td>0.112145</td>\n      <td>0.135231</td>\n      <td>-0.002228</td>\n      <td>0.004135</td>\n      <td>...</td>\n      <td>-0.135005</td>\n      <td>-0.212171</td>\n      <td>-0.056621</td>\n      <td>0.041745</td>\n      <td>0.071561</td>\n      <td>1.000000</td>\n      <td>0.024910</td>\n      <td>0.010580</td>\n      <td>-0.361983</td>\n      <td>-0.228896</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.049488</td>\n      <td>0.134331</td>\n      <td>0.043879</td>\n      <td>0.026810</td>\n      <td>0.019832</td>\n      <td>0.073383</td>\n      <td>-0.006052</td>\n      <td>0.015178</td>\n      <td>0.006819</td>\n      <td>-0.001301</td>\n      <td>...</td>\n      <td>0.163738</td>\n      <td>0.044522</td>\n      <td>-0.209958</td>\n      <td>-0.266707</td>\n      <td>0.009957</td>\n      <td>0.024910</td>\n      <td>1.000000</td>\n      <td>0.238508</td>\n      <td>0.156749</td>\n      <td>-0.141656</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.067248</td>\n      <td>0.012952</td>\n      <td>-0.017784</td>\n      <td>-0.031360</td>\n      <td>-0.039655</td>\n      <td>-0.001977</td>\n      <td>0.028472</td>\n      <td>0.029755</td>\n      <td>0.005549</td>\n      <td>-0.006743</td>\n      <td>...</td>\n      <td>0.121685</td>\n      <td>0.230485</td>\n      <td>0.039279</td>\n      <td>-0.173963</td>\n      <td>-0.282881</td>\n      <td>0.010580</td>\n      <td>0.238508</td>\n      <td>1.000000</td>\n      <td>0.221302</td>\n      <td>-0.128261</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.103371</td>\n      <td>-0.116243</td>\n      <td>-0.133008</td>\n      <td>-0.111832</td>\n      <td>-0.062702</td>\n      <td>0.047377</td>\n      <td>0.081087</td>\n      <td>0.044183</td>\n      <td>0.001850</td>\n      <td>-0.014418</td>\n      <td>...</td>\n      <td>0.293341</td>\n      <td>0.157001</td>\n      <td>-0.089191</td>\n      <td>-0.138736</td>\n      <td>-0.062263</td>\n      <td>-0.361983</td>\n      <td>0.156749</td>\n      <td>0.221302</td>\n      <td>1.000000</td>\n      <td>0.344573</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.094220</td>\n      <td>-0.070422</td>\n      <td>-0.045069</td>\n      <td>-0.044385</td>\n      <td>-0.031614</td>\n      <td>0.064713</td>\n      <td>-0.029821</td>\n      <td>-0.008364</td>\n      <td>0.011768</td>\n      <td>-0.004271</td>\n      <td>...</td>\n      <td>0.268445</td>\n      <td>0.129772</td>\n      <td>0.199429</td>\n      <td>0.174509</td>\n      <td>0.012025</td>\n      <td>-0.228896</td>\n      <td>-0.141656</td>\n      <td>-0.128261</td>\n      <td>0.344573</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_234', 'fft_236', 'fft_198', 'fft_249', 'fft_154', 'fft_200', 'fft_179', 'fft_247', 'fft_235', 'fft_232', 'fft_253', 'fft_148', 'fft_194', 'fft_188', 'fft_216', 'mfw_16', 'fft_184', 'mfw_7', 'fft_205', 'fft_156', 'fft_191', 'mfw_8', 'fft_192', 'fft_222', 'fft_213', 'fft_172', 'fft_157', 'mfw_5', 'fft_171', 'fft_149', 'mfw_6', 'fft_164', 'fft_153', 'fft_223', 'mfw_9', 'fft_225', 'fft_221', 'fft_176', 'fft_240', 'fft_220', 'fft_215', 'mfw_11', 'fft_133', 'fft_207', 'fft_256', 'fft_182', 'fft_161', 'fft_246', 'fft_243', 'fft_166', 'fft_245', 'fft_163', 'fft_142', 'fft_244', 'fft_242', 'fft_132', 'fft_165', 'fft_173', 'fft_130', 'fft_187', 'fft_206', 'mfw_14', 'fft_167', 'fft_181', 'fft_160', 'fft_134', 'fft_151', 'fft_159', 'fft_217', 'fft_210', 'fft_226', 'fft_168', 'fft_201', 'fft_250', 'fft_135', 'fft_224', 'fft_219', 'fft_183', 'fft_239', 'fft_190', 'fft_233', 'fft_255', 'fft_241', 'fft_138', 'fft_248', 'fft_143', 'fft_175', 'fft_197', 'fft_180', 'fft_199', 'fft_211', 'fft_170', 'fft_229', 'cfr_16', 'fft_238', 'fft_196', 'fft_228', 'fft_202', 'fft_195', 'fft_169', 'mfw_12', 'mfw_13', 'fft_231', 'fft_254', 'fft_158', 'fft_212', 'fft_139', 'fft_178', 'fft_208', 'fft_141', 'fft_237', 'fft_251', 'fft_174', 'fft_203', 'fft_137', 'fft_146', 'fft_209', 'fft_193', 'fft_144', 'mfw_10', 'fft_218', 'fft_150', 'fft_227', 'fft_162', 'fft_204', 'fft_189', 'fft_185', 'fft_186', 'fft_177', 'mfw_15', 'fft_155', 'fft_230', 'fft_140', 'fft_152', 'fft_252', 'fft_214', 'fft_145', 'fft_136', 'fft_147', 'fft_131'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_25\n",
      "fft_26\n",
      "fft_29\n",
      "fft_30\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "fft_37\n",
      "fft_38\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_13\n",
      "ar_14\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 75\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         dw_1        dw_2        dw_3       dw_4      dw_5     mfw_1  \\\n0  133.429003  134.242162  133.489322  37.853305  5.508392  0.586324   \n1  133.965830  136.903950  136.743215  38.927755  5.696305  0.593533   \n2  139.274723  140.184030  140.070259  39.704137  5.761162  0.577124   \n3  138.676856  143.380168  143.473350  40.663806  5.859970  0.588245   \n4  140.755171  142.872499  143.424214  40.769824  5.919625  0.585157   \n\n      mfw_2     mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8  \\\n0 -0.522381 -0.788889 -0.136987 -1.009483  ...  0.017932  0.038860 -0.042238   \n1 -0.515953 -0.790798 -0.224475  2.486222  ...  0.014723  0.042961 -0.052676   \n2 -0.518431 -0.807961 -0.219536 -2.150671  ...  0.006243  0.051369 -0.051818   \n3 -0.513443 -0.810437 -0.247007 -4.289119  ...  0.014157  0.055342 -0.057101   \n4 -0.517127 -0.798512 -0.176490 -1.067047  ...  0.034652  0.022510 -0.031786   \n\n      cfr_9    cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0  0.026644 -0.034630  0.040781 -0.065560  0.001347 -0.022417 -0.007807  \n1  0.042240 -0.050718  0.057318 -0.078975  0.010010 -0.026053 -0.011060  \n2  0.032123 -0.034994  0.042277 -0.076328  0.011880 -0.026580 -0.008271  \n3  0.036792 -0.033449  0.035388 -0.067010  0.008826 -0.025932 -0.011778  \n4  0.019955 -0.031716  0.039832 -0.068147  0.004500 -0.023807 -0.012157  \n\n[5 rows x 75 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>133.429003</td>\n      <td>134.242162</td>\n      <td>133.489322</td>\n      <td>37.853305</td>\n      <td>5.508392</td>\n      <td>0.586324</td>\n      <td>-0.522381</td>\n      <td>-0.788889</td>\n      <td>-0.136987</td>\n      <td>-1.009483</td>\n      <td>...</td>\n      <td>0.017932</td>\n      <td>0.038860</td>\n      <td>-0.042238</td>\n      <td>0.026644</td>\n      <td>-0.034630</td>\n      <td>0.040781</td>\n      <td>-0.065560</td>\n      <td>0.001347</td>\n      <td>-0.022417</td>\n      <td>-0.007807</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>133.965830</td>\n      <td>136.903950</td>\n      <td>136.743215</td>\n      <td>38.927755</td>\n      <td>5.696305</td>\n      <td>0.593533</td>\n      <td>-0.515953</td>\n      <td>-0.790798</td>\n      <td>-0.224475</td>\n      <td>2.486222</td>\n      <td>...</td>\n      <td>0.014723</td>\n      <td>0.042961</td>\n      <td>-0.052676</td>\n      <td>0.042240</td>\n      <td>-0.050718</td>\n      <td>0.057318</td>\n      <td>-0.078975</td>\n      <td>0.010010</td>\n      <td>-0.026053</td>\n      <td>-0.011060</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>139.274723</td>\n      <td>140.184030</td>\n      <td>140.070259</td>\n      <td>39.704137</td>\n      <td>5.761162</td>\n      <td>0.577124</td>\n      <td>-0.518431</td>\n      <td>-0.807961</td>\n      <td>-0.219536</td>\n      <td>-2.150671</td>\n      <td>...</td>\n      <td>0.006243</td>\n      <td>0.051369</td>\n      <td>-0.051818</td>\n      <td>0.032123</td>\n      <td>-0.034994</td>\n      <td>0.042277</td>\n      <td>-0.076328</td>\n      <td>0.011880</td>\n      <td>-0.026580</td>\n      <td>-0.008271</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>138.676856</td>\n      <td>143.380168</td>\n      <td>143.473350</td>\n      <td>40.663806</td>\n      <td>5.859970</td>\n      <td>0.588245</td>\n      <td>-0.513443</td>\n      <td>-0.810437</td>\n      <td>-0.247007</td>\n      <td>-4.289119</td>\n      <td>...</td>\n      <td>0.014157</td>\n      <td>0.055342</td>\n      <td>-0.057101</td>\n      <td>0.036792</td>\n      <td>-0.033449</td>\n      <td>0.035388</td>\n      <td>-0.067010</td>\n      <td>0.008826</td>\n      <td>-0.025932</td>\n      <td>-0.011778</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>140.755171</td>\n      <td>142.872499</td>\n      <td>143.424214</td>\n      <td>40.769824</td>\n      <td>5.919625</td>\n      <td>0.585157</td>\n      <td>-0.517127</td>\n      <td>-0.798512</td>\n      <td>-0.176490</td>\n      <td>-1.067047</td>\n      <td>...</td>\n      <td>0.034652</td>\n      <td>0.022510</td>\n      <td>-0.031786</td>\n      <td>0.019955</td>\n      <td>-0.031716</td>\n      <td>0.039832</td>\n      <td>-0.068147</td>\n      <td>0.004500</td>\n      <td>-0.023807</td>\n      <td>-0.012157</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 75 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 2.852999687194824 s\n",
      "Accuracy 0.9197657393850659 precision 0.9190156767309037 specificity 0.787820824091293 recall 0.9197657393850659 f1 0.9166024133272752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 2.8259997367858887 s\n",
      "Accuracy 0.9200585651537335 precision 0.9196462725252301 specificity 0.7725361371822445 recall 0.9200585651537335 f1 0.9163535594503375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 2.8949999809265137 s\n",
      "Accuracy 0.9259150805270864 precision 0.9263665877938273 specificity 0.7774512504093074 recall 0.9259150805270864 f1 0.9222696683491818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 2.8299996852874756 s\n",
      "Accuracy 0.9147877013177159 precision 0.9148174446910607 specificity 0.7528016917922008 recall 0.9147877013177159 f1 0.910192355964427\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 2.830000162124634 s\n",
      "Accuracy 0.922108345534407 precision 0.9215802194958496 specificity 0.7845773285508122 recall 0.922108345534407 f1 0.9188328328758841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 2.8040003776550293 s\n",
      "Accuracy 0.9194729136163983 precision 0.9188142821969719 specificity 0.7834085766385062 recall 0.9194729136163983 f1 0.9161444813943728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 2.876999855041504 s\n",
      "Accuracy 0.9165446559297218 precision 0.9164648369538945 specificity 0.7705262548197142 recall 0.9165446559297218 f1 0.9125775549510603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 2.902998685836792 s\n",
      "Accuracy 0.9121522693997072 precision 0.9116956354485428 specificity 0.7654997805763794 recall 0.9121522693997072 f1 0.9080255793392246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 2.8529980182647705 s\n",
      "Accuracy 0.9197657393850659 precision 0.9184006015833635 specificity 0.7809878829973899 recall 0.9197657393850659 f1 0.9166638228379287\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 2.8929996490478516 s\n",
      "Accuracy 0.9185944363103953 precision 0.9176937074989296 specificity 0.7872500783591725 recall 0.9185944363103953 f1 0.9154458651112072\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 2.8369994163513184 s\n",
      "Accuracy 0.9250366032210835 precision 0.9246762700670748 specificity 0.7885273375640294 recall 0.9250366032210835 f1 0.9218854461458045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 2.8299992084503174 s\n",
      "Accuracy 0.9291361639824305 precision 0.9294793082894565 specificity 0.7960549808196885 recall 0.9291361639824305 f1 0.9260744560161142\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 2.784998893737793 s\n",
      "Accuracy 0.9282576866764275 precision 0.9286904271316357 specificity 0.8062089284130248 recall 0.9282576866764275 f1 0.9253977771518079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 2.8420042991638184 s\n",
      "Accuracy 0.9265007320644216 precision 0.9261563158824416 specificity 0.7916309813243453 recall 0.9265007320644216 f1 0.9234611427689497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 2.9319961071014404 s\n",
      "Accuracy 0.9101024890190337 precision 0.9094718896278754 specificity 0.7621633934435623 recall 0.9101024890190337 f1 0.9058692616502456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 2.841999053955078 s\n",
      "Accuracy 0.9206442166910688 precision 0.9200444440243994 specificity 0.7831512069259581 recall 0.9206442166910688 f1 0.9173168880540153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 2.8850014209747314 s\n",
      "Accuracy 0.9185944363103953 precision 0.9169324485549385 specificity 0.7787639126577098 recall 0.9185944363103953 f1 0.9155488237213855\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 2.8909988403320312 s\n",
      "Accuracy 0.9150805270863837 precision 0.9143223523228513 specificity 0.7694762418550671 recall 0.9150805270863837 f1 0.9112618570495573\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 2.9109978675842285 s\n",
      "Accuracy 0.9095168374816984 precision 0.9090168582861164 specificity 0.7531112093825649 recall 0.9095168374816984 f1 0.9049218303538413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 2.8299999237060547 s\n",
      "Accuracy 0.9224011713030746 precision 0.9228797212829833 specificity 0.7862064296583495 recall 0.9224011713030746 f1 0.9188812457841828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 2.800999879837036 s\n",
      "Accuracy 0.9150805270863837 precision 0.9133380152806043 specificity 0.7687373072970923 recall 0.9150805270863837 f1 0.9116627519853041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 2.913999319076538 s\n",
      "Accuracy 0.913909224011713 precision 0.9147779310589643 specificity 0.7720653384911881 recall 0.913909224011713 f1 0.9096588798321715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 2.8570003509521484 s\n",
      "Accuracy 0.9127379209370424 precision 0.9128186240972156 specificity 0.7591213221266733 recall 0.9127379209370424 f1 0.9082599300208358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 2.9150009155273438 s\n",
      "Accuracy 0.9177159590043924 precision 0.91742237395235 specificity 0.7671032003308959 recall 0.9177159590043924 f1 0.9137466023306364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 2.855999231338501 s\n",
      "Accuracy 0.9168374816983894 precision 0.9162209527567013 specificity 0.7783175735939454 recall 0.9168374816983894 f1 0.913281571375514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 2.8760008811950684 s\n",
      "Accuracy 0.91303074670571 precision 0.9132446891427779 specificity 0.765631612554316 recall 0.91303074670571 f1 0.9087291658365404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 2.8829989433288574 s\n",
      "Accuracy 0.9174231332357248 precision 0.9158209136281751 specificity 0.7754663753038361 recall 0.9174231332357248 f1 0.9142107541174467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 2.8539986610412598 s\n",
      "Accuracy 0.9121522693997072 precision 0.912535800742479 specificity 0.7538116663538986 recall 0.9121522693997072 f1 0.9074000854436595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 2.8079991340637207 s\n",
      "Accuracy 0.9215226939970718 precision 0.9211633066253964 specificity 0.7854595617268727 recall 0.9215226939970718 f1 0.9182008584816151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 2.925999402999878 s\n",
      "Accuracy 0.9197657393850659 precision 0.9190142208379943 specificity 0.7842553717873436 recall 0.9197657393850659 f1 0.9165019979698394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 2.8370022773742676 s\n",
      "Accuracy 0.9215226939970718 precision 0.9214539430929267 specificity 0.7855167030646018 recall 0.9215226939970718 f1 0.9181128179113156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 2.9009997844696045 s\n",
      "Accuracy 0.9256222547584187 precision 0.9256050315114496 specificity 0.7895814949259717 recall 0.9256222547584187 f1 0.9224087265623677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 2.8389997482299805 s\n",
      "Accuracy 0.9206442166910688 precision 0.9203049082743968 specificity 0.7649692917517079 recall 0.9206442166910688 f1 0.9167188092206507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 2.88199782371521 s\n",
      "Accuracy 0.9185944363103953 precision 0.9185375740499339 specificity 0.7933330568205427 recall 0.9185944363103953 f1 0.9153317519713964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 2.863001585006714 s\n",
      "Accuracy 0.9156661786237189 precision 0.9145252870226304 specificity 0.7737684537900406 recall 0.9156661786237189 f1 0.9121415384339474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 2.681999444961548 s\n",
      "Accuracy 0.9226939970717423 precision 0.9219417525751062 specificity 0.7770433387631545 recall 0.9226939970717423 f1 0.9193066254556197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 2.887000799179077 s\n",
      "Accuracy 0.9103953147877013 precision 0.9099078650812469 specificity 0.7571562273302295 recall 0.9103953147877013 f1 0.9059575579387349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 2.787000894546509 s\n",
      "Accuracy 0.9142020497803807 precision 0.9134028857764076 specificity 0.760749694997234 recall 0.9142020497803807 f1 0.910101469645974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 2.929999828338623 s\n",
      "Accuracy 0.9183016105417277 precision 0.9173461932598144 specificity 0.7806574988537768 recall 0.9183016105417277 f1 0.9149758902388836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 2.88100004196167 s\n",
      "Accuracy 0.9159590043923865 precision 0.9166865118336891 specificity 0.7868555077016338 recall 0.9159590043923865 f1 0.9122408695663907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 2.8309988975524902 s\n",
      "Accuracy 0.9127379209370424 precision 0.9120637676467185 specificity 0.7743428370779716 recall 0.9127379209370424 f1 0.9089801577988832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 2.871002674102783 s\n",
      "Accuracy 0.9203513909224011 precision 0.9205484795513511 specificity 0.7776392859569528 recall 0.9203513909224011 f1 0.916616541186628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 2.8379979133605957 s\n",
      "Accuracy 0.9112737920937043 precision 0.9107575843152589 specificity 0.7475899774882789 recall 0.9112737920937043 f1 0.9065582306166046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 2.8549983501434326 s\n",
      "Accuracy 0.9197657393850659 precision 0.9192902609627938 specificity 0.7685433100747417 recall 0.9197657393850659 f1 0.9159584621224446\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 2.8599979877471924 s\n",
      "Accuracy 0.9103953147877013 precision 0.9109093440977749 specificity 0.7500105283292136 recall 0.9103953147877013 f1 0.9054246080067581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 2.810999870300293 s\n",
      "Accuracy 0.9226939970717423 precision 0.9220427068596796 specificity 0.777547829807724 recall 0.9226939970717423 f1 0.9192846121602252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 2.822000026702881 s\n",
      "Accuracy 0.9191800878477306 precision 0.9182885936240985 specificity 0.7649321048683614 recall 0.9191800878477306 f1 0.9153942151184637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 2.8550007343292236 s\n",
      "Accuracy 0.9177159590043924 precision 0.9164651690769746 specificity 0.7698581086149872 recall 0.9177159590043924 f1 0.9141744274820555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 2.7970001697540283 s\n",
      "Accuracy 0.9136163982430454 precision 0.9135185039134696 specificity 0.7693313005453122 recall 0.9136163982430454 f1 0.909537506910945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 2.892000436782837 s\n",
      "Accuracy 0.9159590043923865 precision 0.9145833479297248 specificity 0.7589826667740289 recall 0.9159590043923865 f1 0.9120820548457301\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 2.941998243331909 s\n",
      "Accuracy 0.9197657393850659 precision 0.91899653459878 specificity 0.7799057231729946 recall 0.9197657393850659 f1 0.9163847715940812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 2.8449997901916504 s\n",
      "Accuracy 0.9194729136163983 precision 0.9189996391305353 specificity 0.7836813424688674 recall 0.9194729136163983 f1 0.916088471976928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 2.8400020599365234 s\n",
      "Accuracy 0.9171303074670571 precision 0.916225689197749 specificity 0.7784643925575049 recall 0.9171303074670571 f1 0.9136910242007114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 2.81499981880188 s\n",
      "Accuracy 0.9121522693997072 precision 0.9116356784711331 specificity 0.77439948935937 recall 0.9121522693997072 f1 0.9083279311179718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 2.8269989490509033 s\n",
      "Accuracy 0.9285505124450951 precision 0.9275713100881523 specificity 0.7994229330421143 recall 0.9285505124450951 f1 0.9259900063939321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 2.862999439239502 s\n",
      "Accuracy 0.9165446559297218 precision 0.9165606802150316 specificity 0.7829368531929681 recall 0.9165446559297218 f1 0.9129165692631374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 2.8989999294281006 s\n",
      "Accuracy 0.922108345534407 precision 0.9221522316838159 specificity 0.7796383394488271 recall 0.922108345534407 f1 0.9185205250664682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 2.844999313354492 s\n",
      "Accuracy 0.9106881405563689 precision 0.9099611580693144 specificity 0.764552810396726 recall 0.9106881405563689 f1 0.9065827841259492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 2.8109991550445557 s\n",
      "Accuracy 0.9121522693997072 precision 0.9124950982589635 specificity 0.7708023996871375 recall 0.9121522693997072 f1 0.9079537655285231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 2.8010010719299316 s\n",
      "Accuracy 0.913909224011713 precision 0.9135413021273797 specificity 0.7559588111789028 recall 0.913909224011713 f1 0.9095041700861572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 2.8229994773864746 s\n",
      "Accuracy 0.9156661786237189 precision 0.916322696077539 specificity 0.7626272814306969 recall 0.9156661786237189 f1 0.9112310528986984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 2.8189990520477295 s\n",
      "Accuracy 0.9162518301610542 precision 0.9156612268171421 specificity 0.7842130117455055 recall 0.9162518301610542 f1 0.9128476834197246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 2.813000202178955 s\n",
      "Accuracy 0.9253294289897511 precision 0.9254107607785658 specificity 0.7880228708538288 recall 0.9253294289897511 f1 0.922040124192274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 2.8610005378723145 s\n",
      "Accuracy 0.9200585651537335 precision 0.920708467704447 specificity 0.7862032811081128 recall 0.9200585651537335 f1 0.9164363514399427\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 2.808000087738037 s\n",
      "Accuracy 0.9147877013177159 precision 0.9137000057229129 specificity 0.7821400252951681 recall 0.9147877013177159 f1 0.9114775443494842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 2.8029990196228027 s\n",
      "Accuracy 0.9203513909224011 precision 0.9194557876076835 specificity 0.7905338346333942 recall 0.9203513909224011 f1 0.917333501696351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 2.747001886367798 s\n",
      "Accuracy 0.9265007320644216 precision 0.925362175749989 specificity 0.8112723424259204 recall 0.9265007320644216 f1 0.9242773967878463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 2.867999315261841 s\n",
      "Accuracy 0.9194729136163983 precision 0.9189379828264066 specificity 0.7848937075766229 recall 0.9194729136163983 f1 0.9161435857300196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 2.981998920440674 s\n",
      "Accuracy 0.913909224011713 precision 0.9141447810643173 specificity 0.7661497252420296 recall 0.913909224011713 f1 0.9096428613645682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 2.75600266456604 s\n",
      "Accuracy 0.9171303074670571 precision 0.9177403797076654 specificity 0.7786623683256186 recall 0.9171303074670571 f1 0.913228745840291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 2.812000036239624 s\n",
      "Accuracy 0.9133235724743778 precision 0.9137657445143308 specificity 0.752005014426281 recall 0.9133235724743778 f1 0.9085369136355018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 2.819999933242798 s\n",
      "Accuracy 0.9174231332357248 precision 0.9187789470927986 specificity 0.7690568352511641 recall 0.9174231332357248 f1 0.913066271307389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 2.815997362136841 s\n",
      "Accuracy 0.9218155197657394 precision 0.9217228922877027 specificity 0.7943807992526655 recall 0.9218155197657394 f1 0.9186600850485135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 2.8049986362457275 s\n",
      "Accuracy 0.9174231332357248 precision 0.9166671976692388 specificity 0.7750027266209246 recall 0.9174231332357248 f1 0.9138335053232118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 2.783999443054199 s\n",
      "Accuracy 0.9165446559297218 precision 0.9180425034830864 specificity 0.7698595513149227 recall 0.9165446559297218 f1 0.912153291483588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 2.8790030479431152 s\n",
      "Accuracy 0.9153733528550513 precision 0.914473583908777 specificity 0.7756054923609549 recall 0.9153733528550513 f1 0.9118020818845873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 2.818998098373413 s\n",
      "Accuracy 0.9226939970717423 precision 0.92215441761014 specificity 0.7825437524245428 recall 0.9226939970717423 f1 0.9193822567936845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 2.7970004081726074 s\n",
      "Accuracy 0.9177159590043924 precision 0.9178590846882766 specificity 0.7807983640006849 recall 0.9177159590043924 f1 0.9140171492425962\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 2.8110005855560303 s\n",
      "Accuracy 0.9194729136163983 precision 0.9183984525921691 specificity 0.7831150629231911 recall 0.9194729136163983 f1 0.9162958219639066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 2.8659989833831787 s\n",
      "Accuracy 0.9224011713030746 precision 0.9232886260588457 specificity 0.7837901756797249 recall 0.9224011713030746 f1 0.918714659736057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 2.7810003757476807 s\n",
      "Accuracy 0.9212298682284041 precision 0.9203918117581781 specificity 0.7861344331465113 recall 0.9212298682284041 f1 0.9180868347784326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 2.804999351501465 s\n",
      "Accuracy 0.9144948755490483 precision 0.9134077947430802 specificity 0.7685429866960385 recall 0.9144948755490483 f1 0.9107549747457896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 2.824000597000122 s\n",
      "Accuracy 0.9218155197657394 precision 0.9212554417905111 specificity 0.7858568275646015 recall 0.9218155197657394 f1 0.9185785384216226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 2.8320000171661377 s\n",
      "Accuracy 0.9183016105417277 precision 0.9173341313115864 specificity 0.7660354633071549 recall 0.9183016105417277 f1 0.9145493944374912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 2.8939998149871826 s\n",
      "Accuracy 0.9109809663250366 precision 0.9096595659667652 specificity 0.7754690534543638 recall 0.9109809663250366 f1 0.9074737739942466\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 2.7969985008239746 s\n",
      "Accuracy 0.9185944363103953 precision 0.9181893836102997 specificity 0.7828288992867495 recall 0.9185944363103953 f1 0.915141865550621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 2.782000780105591 s\n",
      "Accuracy 0.91800878477306 precision 0.9177343150814244 specificity 0.7817540137854704 recall 0.91800878477306 f1 0.9144692149606465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 2.8620007038116455 s\n",
      "Accuracy 0.9191800878477306 precision 0.9187954444984315 specificity 0.7740889245163624 recall 0.9191800878477306 f1 0.9154854830007565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 2.725999593734741 s\n",
      "Accuracy 0.9115666178623719 precision 0.9107144859355891 specificity 0.7701836774203209 recall 0.9115666178623719 f1 0.9077118541339457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 2.9329986572265625 s\n",
      "Accuracy 0.9156661786237189 precision 0.9141167766035359 specificity 0.7725883771005855 recall 0.9156661786237189 f1 0.9122890133103154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 2.789999485015869 s\n",
      "Accuracy 0.9226939970717423 precision 0.921628555644465 specificity 0.7944127053264638 recall 0.9226939970717423 f1 0.9199065198398667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 2.835000991821289 s\n",
      "Accuracy 0.9045387994143484 precision 0.9048721230292179 specificity 0.7564646689383127 recall 0.9045387994143484 f1 0.8996594085896737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 2.775998592376709 s\n",
      "Accuracy 0.9250366032210835 precision 0.9249015992889121 specificity 0.7857654491688706 recall 0.9250366032210835 f1 0.9217439178353045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 2.8389995098114014 s\n",
      "Accuracy 0.9106881405563689 precision 0.9104649113971888 specificity 0.7558832362999867 recall 0.9106881405563689 f1 0.9061332607210069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 2.7710001468658447 s\n",
      "Accuracy 0.9171303074670571 precision 0.9173153954496921 specificity 0.7705521112287205 recall 0.9171303074670571 f1 0.9131039902869112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 2.797999143600464 s\n",
      "Accuracy 0.9203513909224011 precision 0.9201927959524124 specificity 0.7760578923939031 recall 0.9203513909224011 f1 0.9166750787004513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 2.789998769760132 s\n",
      "Accuracy 0.9089311859443631 precision 0.9098720340877219 specificity 0.7430405876450084 recall 0.9089311859443631 f1 0.9035625719853156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 2.75700044631958 s\n",
      "Accuracy 0.913909224011713 precision 0.9145906624064241 specificity 0.7645809994612094 recall 0.913909224011713 f1 0.9094741415625132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 2.813000202178955 s\n",
      "Accuracy 0.9200585651537335 precision 0.9198611825333102 specificity 0.7817641475417304 recall 0.9200585651537335 f1 0.9165465267906097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 2.792999267578125 s\n",
      "Accuracy 0.9156661786237189 precision 0.9142578629532271 specificity 0.7809045026385417 recall 0.9156661786237189 f1 0.9124816888037588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 2.831001043319702 s\n",
      "Accuracy 0.9162518301610542 precision 0.9155228682231562 specificity 0.7751680304661235 recall 0.9162518301610542 f1 0.9126267743069157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 2.77799916267395 s\n",
      "Accuracy 0.9165446559297218 precision 0.9167856716010672 specificity 0.7651696297845638 recall 0.9165446559297218 f1 0.9123249685639362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 2.813999891281128 s\n",
      "Accuracy 0.9183016105417277 precision 0.9181204105703134 specificity 0.7700358584409027 recall 0.9183016105417277 f1 0.9144010150915174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 2.8840014934539795 s\n",
      "Accuracy 0.9226939970717423 precision 0.9215729246263709 specificity 0.7978271695497162 recall 0.9226939970717423 f1 0.9200257066512849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 2.7379984855651855 s\n",
      "Accuracy 0.9153733528550513 precision 0.9143477220988995 specificity 0.7740232481803757 recall 0.9153733528550513 f1 0.9118023963272563\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 2.840001344680786 s\n",
      "Accuracy 0.9241581259150805 precision 0.924027308970757 specificity 0.7951517530238071 recall 0.9241581259150805 f1 0.9210865376842265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 2.8369975090026855 s\n",
      "Accuracy 0.9124450951683748 precision 0.9113282095850849 specificity 0.7731516197260714 recall 0.9124450951683748 f1 0.9088099237153472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 2.8799946308135986 s\n",
      "Accuracy 0.9224011713030746 precision 0.9221270479416286 specificity 0.8009134235775838 recall 0.9224011713030746 f1 0.9194882693202643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 2.836998701095581 s\n",
      "Accuracy 0.9089311859443631 precision 0.9080712379384553 specificity 0.7602039884326983 recall 0.9089311859443631 f1 0.9046810218768245\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 2.850999355316162 s\n",
      "Accuracy 0.9156661786237189 precision 0.9145279594740853 specificity 0.7800922838189166 recall 0.9156661786237189 f1 0.9123344523274687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 2.906998634338379 s\n",
      "Accuracy 0.9197657393850659 precision 0.9195035395867449 specificity 0.7776598497263627 recall 0.9197657393850659 f1 0.9161503426508322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 2.8400001525878906 s\n",
      "Accuracy 0.9267935578330894 precision 0.9265341844755968 specificity 0.8013070634860189 recall 0.9267935578330894 f1 0.9239765544034946\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 2.8000011444091797 s\n",
      "Accuracy 0.9194729136163983 precision 0.9184701352262413 specificity 0.7795426266089719 recall 0.9194729136163983 f1 0.9161632293005066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 2.810001850128174 s\n",
      "Accuracy 0.9147877013177159 precision 0.9146576235315709 specificity 0.7773877208360972 recall 0.9147877013177159 f1 0.9109957809891774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 2.7789993286132812 s\n",
      "Accuracy 0.9147877013177159 precision 0.9143262829560689 specificity 0.776143793196632 recall 0.9147877013177159 f1 0.911063093356185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 2.794999361038208 s\n",
      "Accuracy 0.902489019033675 precision 0.9031325402210307 specificity 0.7444260910414063 recall 0.902489019033675 f1 0.8970282759950218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 2.8610000610351562 s\n",
      "Accuracy 0.9106881405563689 precision 0.9112401053532807 specificity 0.7529128512385916 recall 0.9106881405563689 f1 0.9058128616336654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 2.860999584197998 s\n",
      "Accuracy 0.913909224011713 precision 0.9127929431292676 specificity 0.7839937749293482 recall 0.913909224011713 f1 0.9106496201266774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 2.8359978199005127 s\n",
      "Accuracy 0.9194729136163983 precision 0.9198067663109434 specificity 0.7742064297609605 recall 0.9194729136163983 f1 0.9155788453633685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 2.8039989471435547 s\n",
      "Accuracy 0.9194729136163983 precision 0.9182136641004509 specificity 0.7874327898776298 recall 0.9194729136163983 f1 0.9165031343274888\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 2.868001699447632 s\n",
      "Accuracy 0.9133235724743778 precision 0.9127448853678324 specificity 0.7694499758591512 recall 0.9133235724743778 f1 0.9093941497656444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 2.7629969120025635 s\n",
      "Accuracy 0.9127379209370424 precision 0.9118600088283826 specificity 0.7558791765315181 recall 0.9127379209370424 f1 0.9084649767408026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 2.81000018119812 s\n",
      "Accuracy 0.9215226939970718 precision 0.9213563503543787 specificity 0.8017720526155568 recall 0.9215226939970718 f1 0.9185822861479181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 2.8669984340667725 s\n",
      "Accuracy 0.91303074670571 precision 0.9113585731738032 specificity 0.7684609185288663 recall 0.91303074670571 f1 0.9095102725700731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 2.8129971027374268 s\n",
      "Accuracy 0.9206442166910688 precision 0.9205529369572142 specificity 0.7890238006544917 recall 0.9206442166910688 f1 0.9173161776964645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 2.73599910736084 s\n",
      "Accuracy 0.9191800878477306 precision 0.9184521599207047 specificity 0.782980122695264 recall 0.9191800878477306 f1 0.9158571707443084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 2.8170013427734375 s\n",
      "Accuracy 0.9168374816983894 precision 0.917257766535066 specificity 0.7740818629759064 recall 0.9168374816983894 f1 0.9128429498008886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 2.8199968338012695 s\n",
      "Accuracy 0.9162518301610542 precision 0.9155963386148074 specificity 0.7884827114887366 recall 0.9162518301610542 f1 0.9129968954889585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 2.7789981365203857 s\n",
      "Accuracy 0.9238653001464129 precision 0.9243437447232592 specificity 0.7891049531335139 recall 0.9238653001464129 f1 0.9204599435053314\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 2.8089988231658936 s\n",
      "Accuracy 0.9168374816983894 precision 0.9163996409114462 specificity 0.7779611011747788 recall 0.9168374816983894 f1 0.9132106836829005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 2.8159985542297363 s\n",
      "Accuracy 0.9212298682284041 precision 0.9216030669614714 specificity 0.7851352303067658 recall 0.9212298682284041 f1 0.9176785331361127\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 2.8899972438812256 s\n",
      "Accuracy 0.9191800878477306 precision 0.9182786410394546 specificity 0.7827163612155553 recall 0.9191800878477306 f1 0.9159146977407907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 2.9019992351531982 s\n",
      "Accuracy 0.9124450951683748 precision 0.9122033953095401 specificity 0.7669084746522457 recall 0.9124450951683748 f1 0.9083024851714008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 2.797999620437622 s\n",
      "Accuracy 0.9218155197657394 precision 0.9212164654639593 specificity 0.7841473762078214 recall 0.9218155197657394 f1 0.9185451427705577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 2.790998935699463 s\n",
      "Accuracy 0.9156661786237189 precision 0.9150442079966082 specificity 0.7696513358483518 recall 0.9156661786237189 f1 0.9118213462358484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 2.8019981384277344 s\n",
      "Accuracy 0.9086383601756954 precision 0.9087852357314309 specificity 0.7601707093088009 recall 0.9086383601756954 f1 0.904054326401474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 2.855001449584961 s\n",
      "Accuracy 0.9235724743777453 precision 0.9228091436083897 specificity 0.7876634518843942 recall 0.9235724743777453 f1 0.9205007643466976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 2.8029983043670654 s\n",
      "Accuracy 0.9171303074670571 precision 0.9169088724108797 specificity 0.7759695969306485 recall 0.9171303074670571 f1 0.9133833713390928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 2.8000001907348633 s\n",
      "Accuracy 0.9060029282576867 precision 0.9067912572719563 specificity 0.7275190428668907 recall 0.9060029282576867 f1 0.9000158958250644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 2.821000576019287 s\n",
      "Accuracy 0.9109809663250366 precision 0.9116879411022016 specificity 0.760272671375037 recall 0.9109809663250366 f1 0.9063147385046569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 2.804999589920044 s\n",
      "Accuracy 0.9159590043923865 precision 0.9149556509809045 specificity 0.7863904278866463 recall 0.9159590043923865 f1 0.9127688633836959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 2.858997344970703 s\n",
      "Accuracy 0.9171303074670571 precision 0.916715567680894 specificity 0.7876100425113144 recall 0.9171303074670571 f1 0.913785417008142\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 2.7659995555877686 s\n",
      "Accuracy 0.9142020497803807 precision 0.9138107216134216 specificity 0.760561404041512 recall 0.9142020497803807 f1 0.9099581173158882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 2.804999828338623 s\n",
      "Accuracy 0.9168374816983894 precision 0.9168534330762798 specificity 0.7668050039753924 recall 0.9168374816983894 f1 0.9127396248533858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 2.844000816345215 s\n",
      "Accuracy 0.9185944363103953 precision 0.9174178949134788 specificity 0.7758674698352668 recall 0.9185944363103953 f1 0.9152256025071716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 2.819000720977783 s\n",
      "Accuracy 0.9188872620790629 precision 0.9189578551299612 specificity 0.778935250144015 recall 0.9188872620790629 f1 0.9151854039833222\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 2.7800002098083496 s\n",
      "Accuracy 0.9106881405563689 precision 0.9112975038853711 specificity 0.7501002580310892 recall 0.9106881405563689 f1 0.9057047362945702\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 2.8819994926452637 s\n",
      "Accuracy 0.9203513909224011 precision 0.9204179460734941 specificity 0.7718903790388854 recall 0.9203513909224011 f1 0.9164914548797828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 2.8560009002685547 s\n",
      "Accuracy 0.9121522693997072 precision 0.9121844700597465 specificity 0.763414660293902 recall 0.9121522693997072 f1 0.9078076988372256\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 2.8080029487609863 s\n",
      "Accuracy 0.9188872620790629 precision 0.9188502197309646 specificity 0.7743664154384402 recall 0.9188872620790629 f1 0.9150856848580742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 2.7770016193389893 s\n",
      "Accuracy 0.9124450951683748 precision 0.911300204685392 specificity 0.762511222121018 recall 0.9124450951683748 f1 0.9084784289800485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 2.839998245239258 s\n",
      "Accuracy 0.9168374816983894 precision 0.9176253341133527 specificity 0.7692551782005118 recall 0.9168374816983894 f1 0.912604552601738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 2.852999687194824 s\n",
      "Accuracy 0.9103953147877013 precision 0.9113839422918263 specificity 0.7473453743203335 recall 0.9103953147877013 f1 0.9052121406827686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 2.9139978885650635 s\n",
      "Accuracy 0.9232796486090776 precision 0.9226389419860564 specificity 0.7920247264145989 recall 0.9232796486090776 f1 0.9202727355872092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 2.714000940322876 s\n",
      "Accuracy 0.9247437774524158 precision 0.9248681620846746 specificity 0.787065707318391 recall 0.9247437774524158 f1 0.9214022584344639\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 2.808997869491577 s\n",
      "Accuracy 0.9174231332357248 precision 0.9168248421952462 specificity 0.7618502845460743 recall 0.9174231332357248 f1 0.9133873049902919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 2.805999994277954 s\n",
      "Accuracy 0.9150805270863837 precision 0.9145219565355257 specificity 0.7772510478432613 recall 0.9150805270863837 f1 0.9114293862685032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 2.8239998817443848 s\n",
      "Accuracy 0.9142020497803807 precision 0.9141684715188401 specificity 0.7569654941704383 recall 0.9142020497803807 f1 0.9097358152360092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 2.712000608444214 s\n",
      "Accuracy 0.9183016105417277 precision 0.9181232070373412 specificity 0.7745470934968499 recall 0.9183016105417277 f1 0.9145313485095585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 2.872997283935547 s\n",
      "Accuracy 0.9191800878477306 precision 0.9186225072993105 specificity 0.7789229846241315 recall 0.9191800878477306 f1 0.9156812211602364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 2.8779990673065186 s\n",
      "Accuracy 0.91800878477306 precision 0.9169508774880297 specificity 0.785077411730858 recall 0.91800878477306 f1 0.9148473130903586\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 2.8520004749298096 s\n",
      "Accuracy 0.9191800878477306 precision 0.9190740604660802 specificity 0.7772856176248374 recall 0.9191800878477306 f1 0.9154906211035259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 2.8589980602264404 s\n",
      "Accuracy 0.9048316251830161 precision 0.9045402754466784 specificity 0.7489413477696009 recall 0.9048316251830161 f1 0.8998806159919087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 2.8929996490478516 s\n",
      "Accuracy 0.9115666178623719 precision 0.9116637607337088 specificity 0.767448775227225 recall 0.9115666178623719 f1 0.9073156006584733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 2.8940000534057617 s\n",
      "Accuracy 0.9133235724743778 precision 0.9138267330345392 specificity 0.7594578616194397 recall 0.9133235724743778 f1 0.9087568361814629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 2.8340003490448 s\n",
      "Accuracy 0.9168374816983894 precision 0.9166129728744071 specificity 0.7786496303039501 recall 0.9168374816983894 f1 0.9131628728359896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 2.7789998054504395 s\n",
      "Accuracy 0.9206442166910688 precision 0.9209242865947693 specificity 0.7728989016170403 recall 0.9206442166910688 f1 0.9167618404566029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 2.8259975910186768 s\n",
      "Accuracy 0.9259150805270864 precision 0.9248178947013791 specificity 0.7975025724196271 recall 0.9259150805270864 f1 0.923297227520863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 2.8690004348754883 s\n",
      "Accuracy 0.9162518301610542 precision 0.9150099076115709 specificity 0.7748772020970105 recall 0.9162518301610542 f1 0.9128191976414961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 2.835999011993408 s\n",
      "Accuracy 0.9171303074670571 precision 0.9168366482200022 specificity 0.7811256580313909 recall 0.9171303074670571 f1 0.9135572173156322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 2.8099987506866455 s\n",
      "Accuracy 0.9144948755490483 precision 0.9129195202102925 specificity 0.7681532013246087 recall 0.9144948755490483 f1 0.9109563882449428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 2.798999071121216 s\n",
      "Accuracy 0.9174231332357248 precision 0.9186147294454258 specificity 0.7677286097866788 recall 0.9174231332357248 f1 0.9130647161014318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 2.846000909805298 s\n",
      "Accuracy 0.9188872620790629 precision 0.9188973383697262 specificity 0.7808271664209727 recall 0.9188872620790629 f1 0.9152569082943153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 2.8139991760253906 s\n",
      "Accuracy 0.9162518301610542 precision 0.9162611195346688 specificity 0.7683201744865461 recall 0.9162518301610542 f1 0.9121840420609592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 2.891998291015625 s\n",
      "Accuracy 0.9103953147877013 precision 0.9097434302614815 specificity 0.7661407585948489 recall 0.9103953147877013 f1 0.9063078285301602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 2.760997772216797 s\n",
      "Accuracy 0.9144948755490483 precision 0.9136925644591596 specificity 0.7691375128270306 recall 0.9144948755490483 f1 0.9106656054547866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 2.8819992542266846 s\n",
      "Accuracy 0.9068814055636896 precision 0.9072975056327471 specificity 0.7483608813663751 recall 0.9068814055636896 f1 0.9017652552900349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 2.8389997482299805 s\n",
      "Accuracy 0.91800878477306 precision 0.9164621540137146 specificity 0.7819961480176663 recall 0.91800878477306 f1 0.9149849096372863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 2.838996648788452 s\n",
      "Accuracy 0.9147877013177159 precision 0.9144711254182649 specificity 0.7740937142991879 recall 0.9147877013177159 f1 0.910953715242167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 2.7889983654022217 s\n",
      "Accuracy 0.9200585651537335 precision 0.919182897833864 specificity 0.7870185943811857 recall 0.9200585651537335 f1 0.9169269889742246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 2.786998987197876 s\n",
      "Accuracy 0.9244509516837481 precision 0.9241032362535292 specificity 0.782093304436779 recall 0.9244509516837481 f1 0.9211118121141193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 2.791999578475952 s\n",
      "Accuracy 0.922108345534407 precision 0.9232154332857885 specificity 0.7807932212774615 recall 0.922108345534407 f1 0.9182807172167516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 2.8760018348693848 s\n",
      "Accuracy 0.9171303074670571 precision 0.9163323395288108 specificity 0.7860986287581502 recall 0.9171303074670571 f1 0.9138762016213765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 2.813997268676758 s\n",
      "Accuracy 0.9150805270863837 precision 0.9160856454276024 specificity 0.7789311395251132 recall 0.9150805270863837 f1 0.9110369767856186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 2.8199994564056396 s\n",
      "Accuracy 0.9101024890190337 precision 0.9093470276809609 specificity 0.7576781857671585 recall 0.9101024890190337 f1 0.9057641973399903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 2.8129990100860596 s\n",
      "Accuracy 0.9247437774524158 precision 0.9246155046380881 specificity 0.7980163906310113 recall 0.9247437774524158 f1 0.9217585718301882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 2.8059990406036377 s\n",
      "Accuracy 0.9174231332357248 precision 0.9173669335130574 specificity 0.7798561165573471 recall 0.9174231332357248 f1 0.9137474046135537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 2.878999710083008 s\n",
      "Accuracy 0.9188872620790629 precision 0.9188864285354983 specificity 0.7713079771807398 recall 0.9188872620790629 f1 0.9149869869172126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 2.7799978256225586 s\n",
      "Accuracy 0.9156661786237189 precision 0.9159669258370018 specificity 0.772727153368229 recall 0.9156661786237189 f1 0.9116318109834111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 2.7779996395111084 s\n",
      "Accuracy 0.9203513909224011 precision 0.9204410028796318 specificity 0.7995553892228943 recall 0.9203513909224011 f1 0.917253320172658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 2.8049986362457275 s\n",
      "Accuracy 0.9197657393850659 precision 0.9192862989339936 specificity 0.7846463783354198 recall 0.9197657393850659 f1 0.9164177046953536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 2.8459999561309814 s\n",
      "Accuracy 0.9159590043923865 precision 0.915332074917913 specificity 0.7851061704896712 recall 0.9159590043923865 f1 0.912587656069864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 2.785999059677124 s\n",
      "Accuracy 0.9177159590043924 precision 0.9184604454271227 specificity 0.777481991480048 recall 0.9177159590043924 f1 0.9137611865017294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 2.7989981174468994 s\n",
      "Accuracy 0.9256222547584187 precision 0.9255555197360259 specificity 0.7872003561110142 recall 0.9256222547584187 f1 0.922362035203334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 2.879999876022339 s\n",
      "Accuracy 0.9142020497803807 precision 0.9135787352373301 specificity 0.7712476522554209 recall 0.9142020497803807 f1 0.9103670483590705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 2.9460012912750244 s\n",
      "Accuracy 0.91303074670571 precision 0.9144724574470592 specificity 0.7578463897414016 recall 0.91303074670571 f1 0.9081699796493936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 2.747997760772705 s\n",
      "Accuracy 0.9206442166910688 precision 0.9202397819914026 specificity 0.7666969878374984 recall 0.9206442166910688 f1 0.9167885495700119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 2.827998161315918 s\n",
      "Accuracy 0.9238653001464129 precision 0.9236782967756137 specificity 0.7823114054729827 recall 0.9238653001464129 f1 0.9204658521776168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 2.8540000915527344 s\n",
      "Accuracy 0.9118594436310395 precision 0.9116578294751317 specificity 0.7737503067826073 recall 0.9118594436310395 f1 0.9079057509265674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 2.7230000495910645 s\n",
      "Accuracy 0.9197657393850659 precision 0.9185958488312772 specificity 0.7701363551951123 recall 0.9197657393850659 f1 0.9162586236148519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 2.9769997596740723 s\n",
      "Accuracy 0.9241581259150805 precision 0.9233453104042776 specificity 0.7912872288891003 recall 0.9241581259150805 f1 0.921216134658753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 2.750000476837158 s\n",
      "Accuracy 0.9124450951683748 precision 0.9113055544611401 specificity 0.7523606338434201 recall 0.9124450951683748 f1 0.9081458723097836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 2.8310015201568604 s\n",
      "Accuracy 0.9185944363103953 precision 0.9197923037786103 specificity 0.7692050762760406 recall 0.9185944363103953 f1 0.914314184811739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 2.8819985389709473 s\n",
      "Accuracy 0.9089311859443631 precision 0.9081128505783486 specificity 0.7650707017385061 recall 0.9089311859443631 f1 0.9048291898859565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 2.729999542236328 s\n",
      "Accuracy 0.9203513909224011 precision 0.9197052449075613 specificity 0.7837491489514731 recall 0.9203513909224011 f1 0.917049739189956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 2.874000072479248 s\n",
      "Accuracy 0.9159590043923865 precision 0.9156800366691368 specificity 0.7805832939389729 recall 0.9159590043923865 f1 0.9123372563726703\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 2.790997266769409 s\n",
      "Accuracy 0.9150805270863837 precision 0.9154381307860052 specificity 0.7625717664546319 recall 0.9150805270863837 f1 0.9107048225884589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 2.8380000591278076 s\n",
      "Accuracy 0.9168374816983894 precision 0.9154070696666092 specificity 0.7692351441168791 recall 0.9168374816983894 f1 0.9133310685676364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 2.809000015258789 s\n",
      "Accuracy 0.9083455344070278 precision 0.9080763637624579 specificity 0.7603633853619133 recall 0.9083455344070278 f1 0.9038852446345933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 2.811000347137451 s\n",
      "Accuracy 0.9150805270863837 precision 0.9144506650414425 specificity 0.7744749222444003 recall 0.9150805270863837 f1 0.9113695615159744\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 2.8569986820220947 s\n",
      "Accuracy 0.9194729136163983 precision 0.9188603254164344 specificity 0.7889477485635206 recall 0.9194729136163983 f1 0.9162850937398093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 2.82300066947937 s\n",
      "Accuracy 0.9165446559297218 precision 0.9172353621790129 specificity 0.7635167968524569 recall 0.9165446559297218 f1 0.9121553982267069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 2.746997594833374 s\n",
      "Accuracy 0.9209370424597365 precision 0.920785176340611 specificity 0.7790953712557295 recall 0.9209370424597365 f1 0.9173597599093842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 2.706000328063965 s\n",
      "Accuracy 0.9162518301610542 precision 0.9149832967119289 specificity 0.7706988591477839 recall 0.9162518301610542 f1 0.912702196110857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 2.8129985332489014 s\n",
      "Accuracy 0.9183016105417277 precision 0.9183734838080847 specificity 0.7806391728520308 recall 0.9183016105417277 f1 0.9146331794505194\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 2.845000743865967 s\n",
      "Accuracy 0.9133235724743778 precision 0.9140452148708006 specificity 0.7729126664039688 recall 0.9133235724743778 f1 0.9091210961520955\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 2.8979978561401367 s\n",
      "Accuracy 0.9165446559297218 precision 0.9174880238040344 specificity 0.7632701354953394 recall 0.9165446559297218 f1 0.9120846518069936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 2.7889997959136963 s\n",
      "Accuracy 0.9177159590043924 precision 0.917657849777232 specificity 0.7768473838821722 recall 0.9177159590043924 f1 0.913960644474056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 2.815000057220459 s\n",
      "Accuracy 0.9209370424597365 precision 0.92013302877589 specificity 0.7864971117163728 recall 0.9209370424597365 f1 0.917784124852245\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 2.8889997005462646 s\n",
      "Accuracy 0.9156661786237189 precision 0.9152962106654692 specificity 0.7677121128013301 recall 0.9156661786237189 f1 0.9116790453961753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 2.7359981536865234 s\n",
      "Accuracy 0.913909224011713 precision 0.9129960565152612 specificity 0.7662382486889512 recall 0.913909224011713 f1 0.9100139607902186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 2.870000123977661 s\n",
      "Accuracy 0.9142020497803807 precision 0.9135472303371253 specificity 0.7585320665382164 recall 0.9142020497803807 f1 0.909981578136575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 2.839999198913574 s\n",
      "Accuracy 0.9203513909224011 precision 0.920184823163176 specificity 0.7844267530113386 recall 0.9203513909224011 f1 0.9169117097316218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 2.801999807357788 s\n",
      "Accuracy 0.9215226939970718 precision 0.9220924113814348 specificity 0.7749698432441321 recall 0.9215226939970718 f1 0.9176477301571093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 2.755000114440918 s\n",
      "Accuracy 0.9153733528550513 precision 0.9155434151968491 specificity 0.7660220538887857 recall 0.9153733528550513 f1 0.9111641588273925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 2.799999952316284 s\n",
      "Accuracy 0.9115666178623719 precision 0.9102975543962953 specificity 0.7735799134263062 recall 0.9115666178623719 f1 0.9079880555029402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 2.7829995155334473 s\n",
      "Accuracy 0.9147877013177159 precision 0.9153029122816548 specificity 0.7722618051551401 recall 0.9147877013177159 f1 0.9106576738290629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 2.753999948501587 s\n",
      "Accuracy 0.9209370424597365 precision 0.9213236025554481 specificity 0.7792175103731566 recall 0.9209370424597365 f1 0.9172109569856052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 2.8559982776641846 s\n",
      "Accuracy 0.9218155197657394 precision 0.9215903089311431 specificity 0.7799514481119183 recall 0.9218155197657394 f1 0.9183080803370695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 2.73799991607666 s\n",
      "Accuracy 0.9156661786237189 precision 0.9155857071452671 specificity 0.7750638184783398 recall 0.9156661786237189 f1 0.9118113193994433\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 2.8289995193481445 s\n",
      "Accuracy 0.9136163982430454 precision 0.9130966723024937 specificity 0.7531053622405208 recall 0.9136163982430454 f1 0.9091602864277993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 2.838998317718506 s\n",
      "Accuracy 0.913909224011713 precision 0.9147606106632861 specificity 0.7762894728317009 recall 0.913909224011713 f1 0.9097934293048557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 2.8320014476776123 s\n",
      "Accuracy 0.9241581259150805 precision 0.9239960988303231 specificity 0.7893606339263702 recall 0.9241581259150805 f1 0.9209447248100231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 2.76200008392334 s\n",
      "Accuracy 0.9224011713030746 precision 0.9213607083257194 specificity 0.7882527332690236 recall 0.9224011713030746 f1 0.9194264267857163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 2.8179993629455566 s\n",
      "Accuracy 0.9185944363103953 precision 0.9182498018274956 specificity 0.7731918859581368 recall 0.9185944363103953 f1 0.9148447592799933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 2.816000461578369 s\n",
      "Accuracy 0.9194729136163983 precision 0.9189541372114497 specificity 0.7738263282954659 recall 0.9194729136163983 f1 0.9158229108073784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 2.7509987354278564 s\n",
      "Accuracy 0.9174231332357248 precision 0.917934145337332 specificity 0.7710679577916059 recall 0.9174231332357248 f1 0.9133320031349423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 2.867999315261841 s\n",
      "Accuracy 0.9089311859443631 precision 0.9080614500519021 specificity 0.7632637857387723 recall 0.9089311859443631 f1 0.9047873963460613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 2.7929999828338623 s\n",
      "Accuracy 0.9136163982430454 precision 0.9135440585355934 specificity 0.7617520784000964 recall 0.9136163982430454 f1 0.9092933050134012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 2.8609986305236816 s\n",
      "Accuracy 0.913909224011713 precision 0.9140598683167751 specificity 0.771764444863704 recall 0.913909224011713 f1 0.9098406018814261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 2.8459997177124023 s\n",
      "Accuracy 0.9136163982430454 precision 0.913232592671732 specificity 0.7780323447920312 recall 0.9136163982430454 f1 0.9098959592368202\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 2.778998851776123 s\n",
      "Accuracy 0.9191800878477306 precision 0.9190229432197138 specificity 0.7706362280794989 recall 0.9191800878477306 f1 0.9153153975208889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 2.7879996299743652 s\n",
      "Accuracy 0.9089311859443631 precision 0.9088983747005915 specificity 0.7463880980653211 recall 0.9089311859443631 f1 0.9039445246933632\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 2.7649996280670166 s\n",
      "Accuracy 0.9150805270863837 precision 0.9146717671860889 specificity 0.7677499437594121 recall 0.9150805270863837 f1 0.9110903472876813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 2.8219995498657227 s\n",
      "Accuracy 0.91303074670571 precision 0.9137298290741512 specificity 0.7606586924763507 recall 0.91303074670571 f1 0.9084412782757928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 2.7709972858428955 s\n",
      "Accuracy 0.922108345534407 precision 0.9220412568628585 specificity 0.7746143784618589 recall 0.922108345534407 f1 0.9184151465163488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 2.8240015506744385 s\n",
      "Accuracy 0.9171303074670571 precision 0.9160862865278259 specificity 0.7762025579356118 recall 0.9171303074670571 f1 0.9136781675434819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 2.8779985904693604 s\n",
      "Accuracy 0.9171303074670571 precision 0.9169581219605465 specificity 0.7557207168099311 recall 0.9171303074670571 f1 0.9127651150170467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 2.76200008392334 s\n",
      "Accuracy 0.9183016105417277 precision 0.9174943995524968 specificity 0.7867390204334158 recall 0.9183016105417277 f1 0.9150956522735557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 2.7669997215270996 s\n",
      "Accuracy 0.9062957540263543 precision 0.9047509666848281 specificity 0.7560260089003344 recall 0.9062957540263543 f1 0.9021017217989564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 2.8029987812042236 s\n",
      "Accuracy 0.9191800878477306 precision 0.918937573534428 specificity 0.7800877598645934 recall 0.9191800878477306 f1 0.915612089981697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 2.799999475479126 s\n",
      "Accuracy 0.9188872620790629 precision 0.9184914547820752 specificity 0.7844552952146996 recall 0.9188872620790629 f1 0.9154851549172605\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 2.835999011993408 s\n",
      "Accuracy 0.9244509516837481 precision 0.9239557428370769 specificity 0.788016378840428 recall 0.9244509516837481 f1 0.9213158912642024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 2.8399970531463623 s\n",
      "Accuracy 0.9174231332357248 precision 0.9173836237930996 specificity 0.7847082964929103 recall 0.9174231332357248 f1 0.9138834049204111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 2.8089988231658936 s\n",
      "Accuracy 0.9226939970717423 precision 0.9228223198308118 specificity 0.7864110967877803 recall 0.9226939970717423 f1 0.9192811295477102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 2.8779969215393066 s\n",
      "Accuracy 0.9133235724743778 precision 0.9134614704468256 specificity 0.7728407453650192 recall 0.9133235724743778 f1 0.9092766547354788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 2.8259987831115723 s\n",
      "Accuracy 0.9241581259150805 precision 0.9237877565005466 specificity 0.7964933695959858 recall 0.9241581259150805 f1 0.9211964360054674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 2.8430001735687256 s\n",
      "Accuracy 0.9045387994143484 precision 0.9055637842219669 specificity 0.7387738562555609 recall 0.9045387994143484 f1 0.8988401886916894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 2.7599985599517822 s\n",
      "Accuracy 0.9159590043923865 precision 0.9166362939200436 specificity 0.7650737753116257 recall 0.9159590043923865 f1 0.9116020057814166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 2.826000928878784 s\n",
      "Accuracy 0.9092240117130308 precision 0.9081938499104957 specificity 0.7586669095986021 recall 0.9092240117130308 f1 0.9049934479998092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 2.8329989910125732 s\n",
      "Accuracy 0.9142020497803807 precision 0.9133883554111059 specificity 0.763934777910075 recall 0.9142020497803807 f1 0.9102065473802549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 2.742001533508301 s\n",
      "Accuracy 0.9194729136163983 precision 0.9196392038987263 specificity 0.7718468297883753 recall 0.9194729136163983 f1 0.9155575354387748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 2.888000726699829 s\n",
      "Accuracy 0.9147877013177159 precision 0.9154019753671943 specificity 0.7808794963206104 recall 0.9147877013177159 f1 0.9108932061511764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 2.760997772216797 s\n",
      "Accuracy 0.9206442166910688 precision 0.9201374363200666 specificity 0.7832840001116242 recall 0.9206442166910688 f1 0.9172888113833247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 2.8580000400543213 s\n",
      "Accuracy 0.9162518301610542 precision 0.9159759248148419 specificity 0.7698692808130139 recall 0.9162518301610542 f1 0.9123166873250926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 2.774000644683838 s\n",
      "Accuracy 0.9247437774524158 precision 0.9241558039908956 specificity 0.7928661932220711 recall 0.9247437774524158 f1 0.9217746408899054\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 2.8349993228912354 s\n",
      "Accuracy 0.9165446559297218 precision 0.9158433642196037 specificity 0.7661772546290943 recall 0.9165446559297218 f1 0.9126472054597012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 2.9249985218048096 s\n",
      "Accuracy 0.9250366032210835 precision 0.9254718961171006 specificity 0.7985413679703895 recall 0.9250366032210835 f1 0.9219152160675123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 2.82300066947937 s\n",
      "Accuracy 0.9112737920937043 precision 0.9121403510772824 specificity 0.7726099703171467 recall 0.9112737920937043 f1 0.9069725472107254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 2.787999391555786 s\n",
      "Accuracy 0.9136163982430454 precision 0.9127146672558897 specificity 0.7690748346822421 recall 0.9136163982430454 f1 0.9097980011715153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 2.758999824523926 s\n",
      "Accuracy 0.91800878477306 precision 0.9186947664707331 specificity 0.765983286855937 recall 0.91800878477306 f1 0.9137402895632378\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 2.771998882293701 s\n",
      "Accuracy 0.9092240117130308 precision 0.9102199798560822 specificity 0.7519325275980271 recall 0.9092240117130308 f1 0.9041528207326149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 2.8299996852874756 s\n",
      "Accuracy 0.9086383601756954 precision 0.9087769205689772 specificity 0.7720708365940822 recall 0.9086383601756954 f1 0.9044519971563809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 2.838998556137085 s\n",
      "Accuracy 0.9203513909224011 precision 0.9209460039165229 specificity 0.7802495623925348 recall 0.9203513909224011 f1 0.9165841210467857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 2.8120014667510986 s\n",
      "Accuracy 0.91303074670571 precision 0.9125774954929895 specificity 0.7766795311095696 recall 0.91303074670571 f1 0.9092775301721004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 2.864000082015991 s\n",
      "Accuracy 0.9247437774524158 precision 0.9253673235991684 specificity 0.7791931726942118 recall 0.9247437774524158 f1 0.9210648113300733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 2.849997043609619 s\n",
      "Accuracy 0.9188872620790629 precision 0.9185752426987313 specificity 0.7799989062439481 recall 0.9188872620790629 f1 0.9153310319237773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 2.8079993724823 s\n",
      "Accuracy 0.9197657393850659 precision 0.9194199223233595 specificity 0.7740856780147386 recall 0.9197657393850659 f1 0.9160751340852737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 2.799997568130493 s\n",
      "Accuracy 0.9188872620790629 precision 0.9192230759923405 specificity 0.7809925729990727 recall 0.9188872620790629 f1 0.9151703669538153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 2.895998239517212 s\n",
      "Accuracy 0.9183016105417277 precision 0.9187080202700929 specificity 0.7761924065327966 recall 0.9183016105417277 f1 0.9144124303804633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 2.862001895904541 s\n",
      "Accuracy 0.9136163982430454 precision 0.9140050332799026 specificity 0.7752105989254083 recall 0.9136163982430454 f1 0.9095802519124409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 2.767000913619995 s\n",
      "Accuracy 0.9191800878477306 precision 0.9195478010681521 specificity 0.7690732921815903 recall 0.9191800878477306 f1 0.915121045755592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 2.8109991550445557 s\n",
      "Accuracy 0.9185944363103953 precision 0.9178394439206529 specificity 0.7899745649895796 recall 0.9185944363103953 f1 0.9154683970435361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 2.878000020980835 s\n",
      "Accuracy 0.9101024890190337 precision 0.9102238377081763 specificity 0.7740080183221417 recall 0.9101024890190337 f1 0.9060184518441825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 2.9780006408691406 s\n",
      "Accuracy 0.9162518301610542 precision 0.9162701929393873 specificity 0.7774739839021833 recall 0.9162518301610542 f1 0.9124546595839442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 2.8329999446868896 s\n",
      "Accuracy 0.9127379209370424 precision 0.9121901061728923 specificity 0.771955659225294 recall 0.9127379209370424 f1 0.9088615053740442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 2.837999105453491 s\n",
      "Accuracy 0.9194729136163983 precision 0.9191150735325161 specificity 0.7765104880832568 recall 0.9194729136163983 f1 0.9158470930851101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 2.811000347137451 s\n",
      "Accuracy 0.9144948755490483 precision 0.9154261894220171 specificity 0.7727185462745156 recall 0.9144948755490483 f1 0.9102649256313714\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 2.794999837875366 s\n",
      "Accuracy 0.9200585651537335 precision 0.9198680625820885 specificity 0.7777472520945772 recall 0.9200585651537335 f1 0.9164314523709408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 2.7829980850219727 s\n",
      "Accuracy 0.9159590043923865 precision 0.9155269749600365 specificity 0.7536382106166375 recall 0.9159590043923865 f1 0.9115707685874922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 2.866999626159668 s\n",
      "Accuracy 0.9177159590043924 precision 0.9173757764748053 specificity 0.7694948926185396 recall 0.9177159590043924 f1 0.9138317927677504\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 2.8319993019104004 s\n",
      "Accuracy 0.9136163982430454 precision 0.9131788572588878 specificity 0.7562640235037112 recall 0.9136163982430454 f1 0.9092337837197163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 2.7849998474121094 s\n",
      "Accuracy 0.9118594436310395 precision 0.9113679401460896 specificity 0.7741630277317435 recall 0.9118594436310395 f1 0.9080122071276989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 2.8439998626708984 s\n",
      "Accuracy 0.91800878477306 precision 0.9175284173567777 specificity 0.7691847541684882 recall 0.91800878477306 f1 0.9141692581741568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 2.8219988346099854 s\n",
      "Accuracy 0.9168374816983894 precision 0.916074107363826 specificity 0.7760588177611474 recall 0.9168374816983894 f1 0.9132665731172549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 2.957000494003296 s\n",
      "Accuracy 0.91800878477306 precision 0.918061671207665 specificity 0.7739552354041913 recall 0.91800878477306 f1 0.9141446961332201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 2.7449986934661865 s\n",
      "Accuracy 0.9136163982430454 precision 0.9130700390412587 specificity 0.7680993546470131 recall 0.9136163982430454 f1 0.9096416906736216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 2.812997341156006 s\n",
      "Accuracy 0.9183016105417277 precision 0.9176356043660595 specificity 0.7891460802712861 recall 0.9183016105417277 f1 0.9151128857408873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 2.788998603820801 s\n",
      "Accuracy 0.9226939970717423 precision 0.9232436485751466 specificity 0.791092052455104 recall 0.9226939970717423 f1 0.9192944333632859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 2.8299977779388428 s\n",
      "Accuracy 0.9206442166910688 precision 0.9211253599799968 specificity 0.7714644998449685 recall 0.9206442166910688 f1 0.9166678389254758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 2.890000581741333 s\n",
      "Accuracy 0.9136163982430454 precision 0.9123770959926873 specificity 0.7693772404350352 recall 0.9136163982430454 f1 0.9099413108773694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 2.818999767303467 s\n",
      "Accuracy 0.9259150805270864 precision 0.9256149691412078 specificity 0.8074183789711432 recall 0.9259150805270864 f1 0.9232456219759541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 2.8339998722076416 s\n",
      "Accuracy 0.9153733528550513 precision 0.9158658512960647 specificity 0.7595079009122785 recall 0.9153733528550513 f1 0.9108764085469527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 2.856999635696411 s\n",
      "Accuracy 0.9080527086383602 precision 0.9089497312251423 specificity 0.7619382322588033 recall 0.9080527086383602 f1 0.9033081674695469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 2.772000312805176 s\n",
      "Accuracy 0.9144948755490483 precision 0.9139509217555288 specificity 0.7679384935980075 recall 0.9144948755490483 f1 0.9105385682645347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 2.826000213623047 s\n",
      "Accuracy 0.9127379209370424 precision 0.9115826782435662 specificity 0.7727058699019804 recall 0.9127379209370424 f1 0.9091114234019194\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 2.8100011348724365 s\n",
      "Accuracy 0.9153733528550513 precision 0.9142906309202852 specificity 0.7542099976382002 recall 0.9153733528550513 f1 0.9112094141058955\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 2.7959988117218018 s\n",
      "Accuracy 0.9200585651537335 precision 0.9197637936643456 specificity 0.7775834038351862 recall 0.9200585651537335 f1 0.9164591142263092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 2.820998430252075 s\n",
      "Accuracy 0.9118594436310395 precision 0.9126078495194322 specificity 0.7614755362766834 recall 0.9118594436310395 f1 0.9072476618692944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 2.854999542236328 s\n",
      "Accuracy 0.9144948755490483 precision 0.9134558046784184 specificity 0.7799937117709583 recall 0.9144948755490483 f1 0.9110918790116445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 2.7679989337921143 s\n",
      "Accuracy 0.9112737920937043 precision 0.910445909596088 specificity 0.7665900378396048 recall 0.9112737920937043 f1 0.9072864942693064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 2.8480000495910645 s\n",
      "Accuracy 0.9142020497803807 precision 0.9149195163226486 specificity 0.7773041609127486 recall 0.9142020497803807 f1 0.9101583488580587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 2.716998338699341 s\n",
      "Accuracy 0.9165446559297218 precision 0.9150689380195874 specificity 0.7695256522911614 recall 0.9165446559297218 f1 0.9130599347248133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 2.8149988651275635 s\n",
      "Accuracy 0.9218155197657394 precision 0.9213161175295727 specificity 0.7805774861542302 recall 0.9218155197657394 f1 0.918413107843638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 2.766000747680664 s\n",
      "Accuracy 0.9136163982430454 precision 0.9136995301792059 specificity 0.7762901077756647 recall 0.9136163982430454 f1 0.9096991682565421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 2.847999334335327 s\n",
      "Accuracy 0.9142020497803807 precision 0.9133621623557936 specificity 0.7701345032090431 recall 0.9142020497803807 f1 0.9104095401466237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 2.80299973487854 s\n",
      "Accuracy 0.9124450951683748 precision 0.9130012605588707 specificity 0.7619602847278025 recall 0.9124450951683748 f1 0.9079166472654041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 2.8159995079040527 s\n",
      "Accuracy 0.9150805270863837 precision 0.9148997636144469 specificity 0.772628533206605 recall 0.9150805270863837 f1 0.9111672267684228\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 2.822000503540039 s\n",
      "Accuracy 0.9165446559297218 precision 0.9157255956783436 specificity 0.7863746884915517 recall 0.9165446559297218 f1 0.9132939246907643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 2.7619986534118652 s\n",
      "Accuracy 0.9174231332357248 precision 0.9164916901274668 specificity 0.775026003868454 recall 0.9174231332357248 f1 0.9138994044468208\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 2.8509984016418457 s\n",
      "Accuracy 0.9206442166910688 precision 0.9198430796349548 specificity 0.7855095277539266 recall 0.9206442166910688 f1 0.917455539597374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 2.780001163482666 s\n",
      "Accuracy 0.9183016105417277 precision 0.9175431918244765 specificity 0.7783113502862002 recall 0.9183016105417277 f1 0.9148329694721321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 2.7609992027282715 s\n",
      "Accuracy 0.922108345534407 precision 0.921368039455154 specificity 0.7937128402137967 recall 0.922108345534407 f1 0.9191570273942254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 3.0219991207122803 s\n",
      "Accuracy 0.92298682284041 precision 0.9236937692220528 specificity 0.7896936868339647 recall 0.92298682284041 f1 0.9195179322829792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 2.903999090194702 s\n",
      "Accuracy 0.9103953147877013 precision 0.9094257164148636 specificity 0.7616508708189048 recall 0.9103953147877013 f1 0.9062746962710156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 2.809000015258789 s\n",
      "Accuracy 0.9188872620790629 precision 0.9179323629859324 specificity 0.7724169651949695 recall 0.9188872620790629 f1 0.9153357065273859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 2.8289992809295654 s\n",
      "Accuracy 0.9112737920937043 precision 0.9113829355169742 specificity 0.7578606882851538 recall 0.9112737920937043 f1 0.9067020552649668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 2.7970006465911865 s\n",
      "Accuracy 0.9136163982430454 precision 0.9133963219205707 specificity 0.7727854229702418 recall 0.9136163982430454 f1 0.9096819629282629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 2.7909975051879883 s\n",
      "Accuracy 0.9206442166910688 precision 0.9197161716987853 specificity 0.7901982596994398 recall 0.9206442166910688 f1 0.9176363862038056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 2.8609986305236816 s\n",
      "Accuracy 0.9106881405563689 precision 0.9096468414563125 specificity 0.7699114067401328 recall 0.9106881405563689 f1 0.9068746030759423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 2.7729990482330322 s\n",
      "Accuracy 0.91800878477306 precision 0.9169855017492127 specificity 0.7734269301597617 recall 0.91800878477306 f1 0.9144890651572108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 2.83600115776062 s\n",
      "Accuracy 0.9203513909224011 precision 0.9192685779012467 specificity 0.7857681687542148 recall 0.9203513909224011 f1 0.9172753863685991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 2.828000068664551 s\n",
      "Accuracy 0.9118594436310395 precision 0.9110337124789494 specificity 0.7544455417062039 recall 0.9118594436310395 f1 0.9074934372394939\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 2.7759978771209717 s\n",
      "Accuracy 0.9209370424597365 precision 0.9204998842049565 specificity 0.7665833022459326 recall 0.9209370424597365 f1 0.917097974806119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 2.8239996433258057 s\n",
      "Accuracy 0.9162518301610542 precision 0.9151580193312727 specificity 0.7606852748476947 recall 0.9162518301610542 f1 0.9123223665829115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 2.7559995651245117 s\n",
      "Accuracy 0.9200585651537335 precision 0.918897533104995 specificity 0.7782427308702108 recall 0.9200585651537335 f1 0.9167920216637572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 2.811999559402466 s\n",
      "Accuracy 0.9185944363103953 precision 0.917849964821421 specificity 0.7936850791895331 recall 0.9185944363103953 f1 0.9155705660916044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 2.868999481201172 s\n",
      "Accuracy 0.9159590043923865 precision 0.9148402808958009 specificity 0.7724182511284879 recall 0.9159590043923865 f1 0.912391545192784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 2.8139986991882324 s\n",
      "Accuracy 0.9206442166910688 precision 0.9204765505217872 specificity 0.7898744913964172 recall 0.9206442166910688 f1 0.917362680966992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 2.8050005435943604 s\n",
      "Accuracy 0.9235724743777453 precision 0.9230250940293295 specificity 0.7859161469630032 recall 0.9235724743777453 f1 0.9203770713253128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 2.8119986057281494 s\n",
      "Accuracy 0.909809663250366 precision 0.9100005193926352 specificity 0.7585116044981988 recall 0.909809663250366 f1 0.9051916690054161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 2.73699951171875 s\n",
      "Accuracy 0.9185944363103953 precision 0.9184133030623551 specificity 0.7713903679385816 recall 0.9185944363103953 f1 0.9147417162346758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 2.8049991130828857 s\n",
      "Accuracy 0.9156661786237189 precision 0.915035355521592 specificity 0.780332975178432 recall 0.9156661786237189 f1 0.9121469883138922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 2.755000114440918 s\n",
      "Accuracy 0.9106881405563689 precision 0.9104720421547643 specificity 0.7519037822887183 recall 0.9106881405563689 f1 0.9060000917637814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 2.8870010375976562 s\n",
      "Accuracy 0.9165446559297218 precision 0.9169005075270757 specificity 0.7746901460317238 recall 0.9165446559297218 f1 0.9125775779035045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 2.853996753692627 s\n",
      "Accuracy 0.9212298682284041 precision 0.9216031881243406 specificity 0.7697546269382204 recall 0.9212298682284041 f1 0.917252030593211\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 2.773998975753784 s\n",
      "Accuracy 0.9142020497803807 precision 0.9138646926791198 specificity 0.7707911678964952 recall 0.9142020497803807 f1 0.9102582155701743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 2.8329977989196777 s\n",
      "Accuracy 0.9168374816983894 precision 0.916445557762277 specificity 0.7635062375808538 recall 0.9168374816983894 f1 0.9127652798469394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 2.778998374938965 s\n",
      "Accuracy 0.9218155197657394 precision 0.9225213511522669 specificity 0.7829300308050563 recall 0.9218155197657394 f1 0.9181338529661744\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 2.8530006408691406 s\n",
      "Accuracy 0.92298682284041 precision 0.9234045587498186 specificity 0.7915761068011846 recall 0.92298682284041 f1 0.9196409880255635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 2.782998561859131 s\n",
      "Accuracy 0.9127379209370424 precision 0.9121321404796519 specificity 0.7660894493610758 recall 0.9127379209370424 f1 0.9086959833376587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 2.8350000381469727 s\n",
      "Accuracy 0.9197657393850659 precision 0.9194255812252676 specificity 0.7785535069397991 recall 0.9197657393850659 f1 0.9162002014715735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 2.851998805999756 s\n",
      "Accuracy 0.9147877013177159 precision 0.9136441982277661 specificity 0.773848154187091 recall 0.9147877013177159 f1 0.9112439561747488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 2.818998336791992 s\n",
      "Accuracy 0.9188872620790629 precision 0.9184994767261238 specificity 0.7847893948507652 recall 0.9188872620790629 f1 0.9154920523302895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 2.790997266769409 s\n",
      "Accuracy 0.9136163982430454 precision 0.912503176146239 specificity 0.7710095080445708 recall 0.9136163982430454 f1 0.9099410879809783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 2.7990002632141113 s\n",
      "Accuracy 0.9086383601756954 precision 0.9091431735379216 specificity 0.7599105466062273 recall 0.9086383601756954 f1 0.9039453583126764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 2.8160006999969482 s\n",
      "Accuracy 0.9218155197657394 precision 0.9227533897523599 specificity 0.7768611395906071 recall 0.9218155197657394 f1 0.917910773292761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 2.8380000591278076 s\n",
      "Accuracy 0.9092240117130308 precision 0.9089783467056409 specificity 0.7487193178848929 recall 0.9092240117130308 f1 0.9043907882367459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 2.799999237060547 s\n",
      "Accuracy 0.9121522693997072 precision 0.9115719744611502 specificity 0.7755713366486254 recall 0.9121522693997072 f1 0.9083866009791606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 2.8089993000030518 s\n",
      "Accuracy 0.9209370424597365 precision 0.9207448228743963 specificity 0.7773256674632206 recall 0.9209370424597365 f1 0.9173227551094356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 2.7839999198913574 s\n",
      "Accuracy 0.9203513909224011 precision 0.9195510611666814 specificity 0.7808520762067582 recall 0.9203513909224011 f1 0.917023921126642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 2.7589991092681885 s\n",
      "Accuracy 0.9121522693997072 precision 0.9115964242804834 specificity 0.7578980694998444 recall 0.9121522693997072 f1 0.907814623310197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 2.822998523712158 s\n",
      "Accuracy 0.9191800878477306 precision 0.9191233020606798 specificity 0.7793770616174494 recall 0.9191800878477306 f1 0.9155355820814142\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 2.857999563217163 s\n",
      "Accuracy 0.9136163982430454 precision 0.915436104416551 specificity 0.7590766936767124 recall 0.9136163982430454 f1 0.9087285474899482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 2.7859983444213867 s\n",
      "Accuracy 0.9241581259150805 precision 0.9237830324405437 specificity 0.7881365954925441 recall 0.9241581259150805 f1 0.920979207294051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 2.7619998455047607 s\n",
      "Accuracy 0.9103953147877013 precision 0.9113108494490444 specificity 0.7601926463411467 recall 0.9103953147877013 f1 0.9056554899764134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 2.8239994049072266 s\n",
      "Accuracy 0.9188872620790629 precision 0.9189791876040492 specificity 0.7752639310068149 recall 0.9188872620790629 f1 0.9150741232242608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 2.793001174926758 s\n",
      "Accuracy 0.9136163982430454 precision 0.9133877125692139 specificity 0.7763770630662664 recall 0.9136163982430454 f1 0.9097955519074405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 2.7609972953796387 s\n",
      "Accuracy 0.9171303074670571 precision 0.91644798148431 specificity 0.7692972946373059 recall 0.9171303074670571 f1 0.9133369850496835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 2.8120007514953613 s\n",
      "Accuracy 0.9112737920937043 precision 0.9113218579084722 specificity 0.7555751551760098 recall 0.9112737920937043 f1 0.9066455119758547\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 2.7939982414245605 s\n",
      "Accuracy 0.9118594436310395 precision 0.9123262996202279 specificity 0.7555578220209279 recall 0.9118594436310395 f1 0.9071313909243357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 2.854997396469116 s\n",
      "Accuracy 0.91800878477306 precision 0.9179578463391131 specificity 0.7741198949375124 recall 0.91800878477306 f1 0.9141798029612334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 2.8420000076293945 s\n",
      "Accuracy 0.9153733528550513 precision 0.9141195275695845 specificity 0.7775908156433087 recall 0.9153733528550513 f1 0.9120074686340954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 2.828998565673828 s\n",
      "Accuracy 0.9156661786237189 precision 0.9152415232388774 specificity 0.7774325616300533 recall 0.9156661786237189 f1 0.9119901125515775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 2.8309996128082275 s\n",
      "Accuracy 0.9188872620790629 precision 0.9193843022585702 specificity 0.767938677214218 recall 0.9188872620790629 f1 0.9147520764158821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 2.8249990940093994 s\n",
      "Accuracy 0.9174231332357248 precision 0.9172998676575527 specificity 0.7771053291345216 recall 0.9174231332357248 f1 0.9136871769843952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 2.844999074935913 s\n",
      "Accuracy 0.9209370424597365 precision 0.920057567418874 specificity 0.7796975101441411 recall 0.9209370424597365 f1 0.917622102343823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 2.919999361038208 s\n",
      "Accuracy 0.9136163982430454 precision 0.9126169339287497 specificity 0.761874053948445 recall 0.9136163982430454 f1 0.9096071572696975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 2.846999168395996 s\n",
      "Accuracy 0.9086383601756954 precision 0.9086128627532765 specificity 0.736180799159593 recall 0.9086383601756954 f1 0.9032895165116432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 2.7559995651245117 s\n",
      "Accuracy 0.9185944363103953 precision 0.9175294029297668 specificity 0.7804710289744087 recall 0.9185944363103953 f1 0.915314655193998\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 2.8010001182556152 s\n",
      "Accuracy 0.9142020497803807 precision 0.9150282959370767 specificity 0.7768438117336631 recall 0.9142020497803807 f1 0.910116875002445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 2.7259976863861084 s\n",
      "Accuracy 0.922108345534407 precision 0.9216337061460416 specificity 0.7946149629185326 recall 0.922108345534407 f1 0.9190868362974075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 2.8229987621307373 s\n",
      "Accuracy 0.9209370424597365 precision 0.9216063713769421 specificity 0.7816283090121195 recall 0.9209370424597365 f1 0.9172050763162094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 2.8489980697631836 s\n",
      "Accuracy 0.9112737920937043 precision 0.9117931998945283 specificity 0.7496508802381407 recall 0.9112737920937043 f1 0.9063196733234261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 2.807999849319458 s\n",
      "Accuracy 0.9206442166910688 precision 0.9200529394047007 specificity 0.7909260509953557 recall 0.9206442166910688 f1 0.9175301855416974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 2.8219993114471436 s\n",
      "Accuracy 0.9232796486090776 precision 0.9229640954361584 specificity 0.7910880427712721 recall 0.9232796486090776 f1 0.9201381368503229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 2.7549996376037598 s\n",
      "Accuracy 0.9156661786237189 precision 0.9166803140002769 specificity 0.7668189173561867 recall 0.9156661786237189 f1 0.9112692130383959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 2.9040002822875977 s\n",
      "Accuracy 0.9144948755490483 precision 0.9147217071612979 specificity 0.7731324326680777 recall 0.9144948755490483 f1 0.9104621012210088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 2.8370018005371094 s\n",
      "Accuracy 0.9168374816983894 precision 0.9173366417710304 specificity 0.7820721363703718 recall 0.9168374816983894 f1 0.9130573576819797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 2.8089969158172607 s\n",
      "Accuracy 0.9156661786237189 precision 0.9158220278601913 specificity 0.7714542739278654 recall 0.9156661786237189 f1 0.911633947311839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 2.8539986610412598 s\n",
      "Accuracy 0.9238653001464129 precision 0.9229459971238992 specificity 0.8078419239780815 recall 0.9238653001464129 f1 0.9213994331050136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 2.8229997158050537 s\n",
      "Accuracy 0.9171303074670571 precision 0.9164417547777045 specificity 0.7837216475078362 recall 0.9171303074670571 f1 0.9137661699560665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 2.8419992923736572 s\n",
      "Accuracy 0.9197657393850659 precision 0.9202297090669277 specificity 0.7814347280737046 recall 0.9197657393850659 f1 0.9160499842600869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 2.7849998474121094 s\n",
      "Accuracy 0.9156661786237189 precision 0.9153699776589029 specificity 0.7824919075710218 recall 0.9156661786237189 f1 0.9120998799655085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 2.8129994869232178 s\n",
      "Accuracy 0.9183016105417277 precision 0.91852379658065 specificity 0.7779038501131252 recall 0.9183016105417277 f1 0.9145119779060061\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 2.7430009841918945 s\n",
      "Accuracy 0.9200585651537335 precision 0.9198451566595371 specificity 0.7810764025176428 recall 0.9200585651537335 f1 0.9165321475690191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 2.83499813079834 s\n",
      "Accuracy 0.9133235724743778 precision 0.9133406408143898 specificity 0.7765346722619159 recall 0.9133235724743778 f1 0.9094260888603057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 2.780514717102051 s\n",
      "Accuracy 0.927086383601757 precision 0.9268057835640059 specificity 0.7930611300929917 recall 0.927086383601757 f1 0.9240772309608347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 2.8421943187713623 s\n",
      "Accuracy 0.9224011713030746 precision 0.9219701027440984 specificity 0.7820174807625048 recall 0.9224011713030746 f1 0.9190312078564792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 2.863999128341675 s\n",
      "Accuracy 0.9226939970717423 precision 0.921158931011843 specificity 0.7991338153488028 recall 0.9226939970717423 f1 0.9202909063792274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 2.9119980335235596 s\n",
      "Accuracy 0.9171303074670571 precision 0.9182073821192092 specificity 0.7724296617539291 recall 0.9171303074670571 f1 0.9129297626916265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 2.957242488861084 s\n",
      "Accuracy 0.9209370424597365 precision 0.9206773791720477 specificity 0.78721353184377 recall 0.9209370424597365 f1 0.9176174842589834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 2.8579986095428467 s\n",
      "Accuracy 0.9060029282576867 precision 0.9062835752136454 specificity 0.7612610940574746 recall 0.9060029282576867 f1 0.9013456124408774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 2.850999116897583 s\n",
      "Accuracy 0.9209370424597365 precision 0.9205136284274 specificity 0.7759256066600184 recall 0.9209370424597365 f1 0.9173563924904653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 2.8199996948242188 s\n",
      "Accuracy 0.9203513909224011 precision 0.9204670415419847 specificity 0.7691249164450863 recall 0.9203513909224011 f1 0.916399235302447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 2.7609965801239014 s\n",
      "Accuracy 0.9191800878477306 precision 0.9189171516914716 specificity 0.7749838906155875 recall 0.9191800878477306 f1 0.9154726753240858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 2.8209965229034424 s\n",
      "Accuracy 0.9232796486090776 precision 0.9222366936700144 specificity 0.7973647906841294 recall 0.9232796486090776 f1 0.9205755625382507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 2.8929989337921143 s\n",
      "Accuracy 0.9103953147877013 precision 0.9098230951707678 specificity 0.7540825544674897 recall 0.9103953147877013 f1 0.905884033622297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 2.917999029159546 s\n",
      "Accuracy 0.9191800878477306 precision 0.9182727854622434 specificity 0.7790314775388829 recall 0.9191800878477306 f1 0.9158106269821542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 2.8309993743896484 s\n",
      "Accuracy 0.9156661786237189 precision 0.914214391565909 specificity 0.7791837216341511 recall 0.9156661786237189 f1 0.9124490112256649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 2.8569986820220947 s\n",
      "Accuracy 0.9133235724743778 precision 0.9138648116155528 specificity 0.7609604910495427 recall 0.9133235724743778 f1 0.9087940749961434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 2.7979981899261475 s\n",
      "Accuracy 0.9156661786237189 precision 0.9146186633064824 specificity 0.7708768032187323 recall 0.9156661786237189 f1 0.9120149902610206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 2.8189985752105713 s\n",
      "Accuracy 0.9177159590043924 precision 0.917798117914631 specificity 0.7826439447453419 recall 0.9177159590043924 f1 0.9140879377911917\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 2.781001091003418 s\n",
      "Accuracy 0.9089311859443631 precision 0.9099082864937318 specificity 0.7597705552589329 recall 0.9089311859443631 f1 0.9041186216475195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 2.8159983158111572 s\n",
      "Accuracy 0.913909224011713 precision 0.9131193627558188 specificity 0.7811107962674694 recall 0.913909224011713 f1 0.9104309583303898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 2.8550000190734863 s\n",
      "Accuracy 0.9203513909224011 precision 0.9203376016043724 specificity 0.7823472739667993 recall 0.9203513909224011 f1 0.9168082218837547\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 2.8769991397857666 s\n",
      "Accuracy 0.909809663250366 precision 0.9098679499700402 specificity 0.749206612134914 recall 0.909809663250366 f1 0.9049206960564358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 2.836998701095581 s\n",
      "Accuracy 0.9118594436310395 precision 0.9105677680384537 specificity 0.761584226400955 recall 0.9118594436310395 f1 0.9079053639754977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 2.799999713897705 s\n",
      "Accuracy 0.9250366032210835 precision 0.9239238653001465 specificity 0.8107837620788854 recall 0.9250366032210835 f1 0.9227607122574404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 2.7300002574920654 s\n",
      "Accuracy 0.9200585651537335 precision 0.9199569111604401 specificity 0.781573881155706 recall 0.9200585651537335 f1 0.9165122106723032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 2.761000156402588 s\n",
      "Accuracy 0.913909224011713 precision 0.9134443629657876 specificity 0.7797807521192556 recall 0.913909224011713 f1 0.9102759499863786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 2.7699997425079346 s\n",
      "Accuracy 0.9168374816983894 precision 0.9156479336599217 specificity 0.7848447627306007 recall 0.9168374816983894 f1 0.9136992337963594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 2.8129987716674805 s\n",
      "Accuracy 0.9183016105417277 precision 0.9193910659983517 specificity 0.7742564245999936 recall 0.9183016105417277 f1 0.914185362267956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 2.8630001544952393 s\n",
      "Accuracy 0.9159590043923865 precision 0.9153670381302816 specificity 0.7757818111543137 recall 0.9159590043923865 f1 0.9122968611053989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 2.8929991722106934 s\n",
      "Accuracy 0.9106881405563689 precision 0.9100735404427001 specificity 0.7613567497729535 recall 0.9106881405563689 f1 0.9064393939703804\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 2.7920000553131104 s\n",
      "Accuracy 0.9142020497803807 precision 0.9129021259546516 specificity 0.7778901798066908 recall 0.9142020497803807 f1 0.9108379150167863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 2.7989983558654785 s\n",
      "Accuracy 0.9194729136163983 precision 0.9190091319158424 specificity 0.7878805525076825 recall 0.9194729136163983 f1 0.9162038753990044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 2.7719976902008057 s\n",
      "Accuracy 0.9212298682284041 precision 0.921131999951773 specificity 0.795556763945247 recall 0.9212298682284041 f1 0.9180952981061336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 2.7619998455047607 s\n",
      "Accuracy 0.9215226939970718 precision 0.9208773104164366 specificity 0.7847474794199821 recall 0.9215226939970718 f1 0.9182776852666112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 2.873000144958496 s\n",
      "Accuracy 0.9030746705710102 precision 0.9012567420700058 specificity 0.7402572031213948 recall 0.9030746705710102 f1 0.8983229249179844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 2.8810014724731445 s\n",
      "Accuracy 0.9224011713030746 precision 0.9228748243437437 specificity 0.7909999667534098 recall 0.9224011713030746 f1 0.919011546563232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 2.8559980392456055 s\n",
      "Accuracy 0.9171303074670571 precision 0.9166914006097655 specificity 0.7866381463013967 recall 0.9171303074670571 f1 0.9137651568734361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 2.8169989585876465 s\n",
      "Accuracy 0.9118594436310395 precision 0.9116737492411527 specificity 0.7664716084024347 recall 0.9118594436310395 f1 0.9076696524524731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 2.8160006999969482 s\n",
      "Accuracy 0.9045387994143484 precision 0.9034779777947133 specificity 0.7477417124708831 recall 0.9045387994143484 f1 0.8997996596541823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 2.8369991779327393 s\n",
      "Accuracy 0.9206442166910688 precision 0.9205239569693887 specificity 0.7835007924324411 recall 0.9206442166910688 f1 0.9171721076801728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 2.755998134613037 s\n",
      "Accuracy 0.9200585651537335 precision 0.9211613239083319 specificity 0.779697971681603 recall 0.9200585651537335 f1 0.916144546852604\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 2.8190014362335205 s\n",
      "Accuracy 0.9218155197657394 precision 0.9225987396656918 specificity 0.7810431133463078 recall 0.9218155197657394 f1 0.9180631435343435\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 2.8069984912872314 s\n",
      "Accuracy 0.9162518301610542 precision 0.9159910231975096 specificity 0.7786423002766107 recall 0.9162518301610542 f1 0.9125737882132763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 2.8469972610473633 s\n",
      "Accuracy 0.9165446559297218 precision 0.9165615030445534 specificity 0.7700124134952956 recall 0.9165446559297218 f1 0.9125337195811305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 2.895998001098633 s\n",
      "Accuracy 0.9086383601756954 precision 0.907814023229501 specificity 0.7671162388850058 recall 0.9086383601756954 f1 0.9045995874696235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 2.8490002155303955 s\n",
      "Accuracy 0.9200585651537335 precision 0.9210471424159122 specificity 0.7744656062631774 recall 0.9200585651537335 f1 0.9160231118731829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 2.8439981937408447 s\n",
      "Accuracy 0.9109809663250366 precision 0.9094207724070826 specificity 0.7771901085952682 recall 0.9109809663250366 f1 0.9076446176442166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 2.8649957180023193 s\n",
      "Accuracy 0.909809663250366 precision 0.9095847279480381 specificity 0.7561705658225764 recall 0.909809663250366 f1 0.9052379312686183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 2.834001064300537 s\n",
      "Accuracy 0.9194729136163983 precision 0.9192928486369477 specificity 0.7798309073914084 recall 0.9194729136163983 f1 0.9158859604791093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 2.8605117797851562 s\n",
      "Accuracy 0.9147877013177159 precision 0.9147777388890282 specificity 0.782069746577192 recall 0.9147877013177159 f1 0.9111011285104554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 2.827524423599243 s\n",
      "Accuracy 0.9150805270863837 precision 0.9157824292685025 specificity 0.7764944624693887 recall 0.9150805270863837 f1 0.9110382870004533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 2.7840001583099365 s\n",
      "Accuracy 0.9215226939970718 precision 0.9211145824507074 specificity 0.7873544220338864 recall 0.9215226939970718 f1 0.9182685625782051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 2.7939987182617188 s\n",
      "Accuracy 0.9188872620790629 precision 0.918945758728504 specificity 0.7738384763175615 recall 0.9188872620790629 f1 0.9150427291832607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 2.901000499725342 s\n",
      "Accuracy 0.9215226939970718 precision 0.9212976843550368 specificity 0.7786029002806734 recall 0.9215226939970718 f1 0.9179700673905674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 2.7750015258789062 s\n",
      "Accuracy 0.9194729136163983 precision 0.9192018519699636 specificity 0.7843000878638277 recall 0.9194729136163983 f1 0.9160405162837971\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 2.8269972801208496 s\n",
      "Accuracy 0.9191800878477306 precision 0.917454308446503 specificity 0.7890367820105307 recall 0.9191800878477306 f1 0.9165127911592067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 3.05199933052063 s\n",
      "Accuracy 0.9183016105417277 precision 0.9183776419063706 specificity 0.7851600460310624 recall 0.9183016105417277 f1 0.9147616160547316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 2.7960004806518555 s\n",
      "Accuracy 0.9077598828696926 precision 0.907486440677077 specificity 0.7577723250353967 recall 0.9077598828696926 f1 0.9031969081663034\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 2.8009989261627197 s\n",
      "Accuracy 0.9206442166910688 precision 0.9202470149510293 specificity 0.7879933960741231 recall 0.9206442166910688 f1 0.9173832710619186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 2.8340017795562744 s\n",
      "Accuracy 0.9171303074670571 precision 0.9161865709117133 specificity 0.7662895571262922 recall 0.9171303074670571 f1 0.9133413498585315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 2.88199782371521 s\n",
      "Accuracy 0.9080527086383602 precision 0.909165497584333 specificity 0.7551536081158433 recall 0.9080527086383602 f1 0.9030240823577032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 2.862999439239502 s\n",
      "Accuracy 0.9162518301610542 precision 0.915244252629436 specificity 0.784175631609319 recall 0.9162518301610542 f1 0.9130031397784157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 2.8080294132232666 s\n",
      "Accuracy 0.9150805270863837 precision 0.9159659193476454 specificity 0.7635863902382601 recall 0.9150805270863837 f1 0.9105984669128199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 2.773000478744507 s\n",
      "Accuracy 0.9127379209370424 precision 0.9127538661570157 specificity 0.7778880275819724 recall 0.9127379209370424 f1 0.9088688710852229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 2.8739984035491943 s\n",
      "Accuracy 0.9109809663250366 precision 0.9103738465405198 specificity 0.7512265250893873 recall 0.9109809663250366 f1 0.9064056531400047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 2.849998712539673 s\n",
      "Accuracy 0.9188872620790629 precision 0.9183672876313079 specificity 0.7868408262577209 recall 0.9188872620790629 f1 0.91559444903827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 2.840998649597168 s\n",
      "Accuracy 0.9101024890190337 precision 0.9097104814416296 specificity 0.7707322619772143 recall 0.9101024890190337 f1 0.9060699851643063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 2.8359971046447754 s\n",
      "Accuracy 0.9185944363103953 precision 0.9184990080723829 specificity 0.7793653633661757 recall 0.9185944363103953 f1 0.914945902156778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 2.776000499725342 s\n",
      "Accuracy 0.9177159590043924 precision 0.9179957887165151 specificity 0.7726784004602347 recall 0.9177159590043924 f1 0.9137425576531694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 2.8609986305236816 s\n",
      "Accuracy 0.9218155197657394 precision 0.9217335133207676 specificity 0.7906466863598404 recall 0.9218155197657394 f1 0.9185561271243544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 2.803999185562134 s\n",
      "Accuracy 0.9133235724743778 precision 0.9136021895358595 specificity 0.7649949965108314 recall 0.9133235724743778 f1 0.9089922769886148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 2.7729997634887695 s\n",
      "Accuracy 0.9133235724743778 precision 0.9128252923003637 specificity 0.7832159067067948 recall 0.9133235724743778 f1 0.9097941777300419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 2.8399994373321533 s\n",
      "Accuracy 0.9153733528550513 precision 0.915790939673551 specificity 0.7664916423527475 recall 0.9153733528550513 f1 0.9111101152448334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 2.8149983882904053 s\n",
      "Accuracy 0.9194729136163983 precision 0.9196149675953281 specificity 0.7756112678860067 recall 0.9194729136163983 f1 0.9156717636208318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 2.8859992027282715 s\n",
      "Accuracy 0.92298682284041 precision 0.9224276251515857 specificity 0.7868812123502058 recall 0.92298682284041 f1 0.9198064769779472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 2.791001319885254 s\n",
      "Accuracy 0.926207906295754 precision 0.9260276985074273 specificity 0.7981634017211235 recall 0.926207906295754 f1 0.9232747819758418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 2.8980002403259277 s\n",
      "Accuracy 0.9235724743777453 precision 0.9235431780808497 specificity 0.7881867974839247 recall 0.9235724743777453 f1 0.9202741237632545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 2.8839993476867676 s\n",
      "Accuracy 0.9177159590043924 precision 0.9170917663741565 specificity 0.7850931756288252 recall 0.9177159590043924 f1 0.914382354957645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 2.8070006370544434 s\n",
      "Accuracy 0.9183016105417277 precision 0.9177481048404991 specificity 0.7793184327810191 recall 0.9183016105417277 f1 0.9147901722073292\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 2.893998861312866 s\n",
      "Accuracy 0.9183016105417277 precision 0.9191462246667899 specificity 0.7798614876213705 recall 0.9183016105417277 f1 0.9144066302126391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 2.804999589920044 s\n",
      "Accuracy 0.9142020497803807 precision 0.9142442992125199 specificity 0.7552841566128466 recall 0.9142020497803807 f1 0.9096609143029689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 2.8279988765716553 s\n",
      "Accuracy 0.9156661786237189 precision 0.9146765375203378 specificity 0.7797064611359605 recall 0.9156661786237189 f1 0.9122617888375362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 2.819997787475586 s\n",
      "Accuracy 0.9206442166910688 precision 0.9204386821851134 specificity 0.7882418164828203 recall 0.9206442166910688 f1 0.9173292803062542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 2.81099796295166 s\n",
      "Accuracy 0.9095168374816984 precision 0.9092321261850469 specificity 0.7568380307117187 recall 0.9095168374816984 f1 0.904977152806457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 2.8200018405914307 s\n",
      "Accuracy 0.91800878477306 precision 0.9173305615397873 specificity 0.7804574829364406 recall 0.91800878477306 f1 0.9145664479922813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 2.7959983348846436 s\n",
      "Accuracy 0.9174231332357248 precision 0.9176309608516618 specificity 0.7729452566976696 recall 0.9174231332357248 f1 0.9134692825050703\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 2.737999439239502 s\n",
      "Accuracy 0.9232796486090776 precision 0.9221501661663686 specificity 0.793476398610639 recall 0.9232796486090776 f1 0.9205083172427417\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 2.7949984073638916 s\n",
      "Accuracy 0.9183016105417277 precision 0.9178262772094761 specificity 0.7747225502924111 recall 0.9183016105417277 f1 0.9146306032206009\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 2.8979976177215576 s\n",
      "Accuracy 0.9124450951683748 precision 0.9127807026698512 specificity 0.7433472118151715 recall 0.9124450951683748 f1 0.9073771761119839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 2.7989985942840576 s\n",
      "Accuracy 0.9127379209370424 precision 0.9130297199201092 specificity 0.7672235434174854 recall 0.9127379209370424 f1 0.9084563843657787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 2.8420002460479736 s\n",
      "Accuracy 0.9171303074670571 precision 0.9160278178150381 specificity 0.7771086861700607 recall 0.9171303074670571 f1 0.9137291329621994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 2.8329975605010986 s\n",
      "Accuracy 0.9147877013177159 precision 0.9152402542059547 specificity 0.783439638719208 recall 0.9147877013177159 f1 0.9110127063511518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 2.829000234603882 s\n",
      "Accuracy 0.9133235724743778 precision 0.9132511198950126 specificity 0.7604097978911161 recall 0.9133235724743778 f1 0.9089494235059583\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 2.790998697280884 s\n",
      "Accuracy 0.9153733528550513 precision 0.9140112389770165 specificity 0.7733491085882788 recall 0.9153733528550513 f1 0.9119236937602266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 2.774000406265259 s\n",
      "Accuracy 0.9156661786237189 precision 0.9151172463171372 specificity 0.772532318882857 recall 0.9156661786237189 f1 0.9118838303468927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 2.7699992656707764 s\n",
      "Accuracy 0.9191800878477306 precision 0.9186611298244839 specificity 0.7766137135437938 recall 0.9191800878477306 f1 0.9156020036679339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 2.8490006923675537 s\n",
      "Accuracy 0.9215226939970718 precision 0.9207824056885346 specificity 0.7948986612634524 recall 0.9215226939970718 f1 0.9185911399456156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 2.846998691558838 s\n",
      "Accuracy 0.9224011713030746 precision 0.9225013362372484 specificity 0.7883248053118491 recall 0.9224011713030746 f1 0.9190403384630027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 2.8500003814697266 s\n",
      "Accuracy 0.9127379209370424 precision 0.91207644299336 specificity 0.7523261107441171 recall 0.9127379209370424 f1 0.908274793710923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 2.7249999046325684 s\n",
      "Accuracy 0.9162518301610542 precision 0.9159064161576042 specificity 0.7830178267357213 recall 0.9162518301610542 f1 0.9127302519932896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 2.8670003414154053 s\n",
      "Accuracy 0.9077598828696926 precision 0.9079286299481574 specificity 0.7611650579463498 recall 0.9077598828696926 f1 0.9031785575077225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 2.707998275756836 s\n",
      "Accuracy 0.9276720351390922 precision 0.9268184117693272 specificity 0.8024525178267482 recall 0.9276720351390922 f1 0.9251143744000552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 2.81600022315979 s\n",
      "Accuracy 0.9144948755490483 precision 0.9139030683508671 specificity 0.7699042794751967 recall 0.9144948755490483 f1 0.9106154030189896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 2.844998836517334 s\n",
      "Accuracy 0.9212298682284041 precision 0.9224441314835857 specificity 0.7803765825129948 recall 0.9212298682284041 f1 0.917341738729843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 2.831000566482544 s\n",
      "Accuracy 0.9118594436310395 precision 0.9128722616550277 specificity 0.75085279605295 recall 0.9118594436310395 f1 0.9068369463492683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 2.8589999675750732 s\n",
      "Accuracy 0.9185944363103953 precision 0.9189135841737088 specificity 0.773972383873423 recall 0.9185944363103953 f1 0.9146726930146594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 2.7939975261688232 s\n",
      "Accuracy 0.922108345534407 precision 0.92265071285615 specificity 0.7823554720051015 recall 0.922108345534407 f1 0.9184599032551954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 2.8469996452331543 s\n",
      "Accuracy 0.91800878477306 precision 0.918251307104192 specificity 0.777304575676909 recall 0.91800878477306 f1 0.9141884440795106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 2.8349952697753906 s\n",
      "Accuracy 0.91800878477306 precision 0.9170129668717848 specificity 0.7812602329822748 recall 0.91800878477306 f1 0.9147095967449946\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 2.79699969291687 s\n",
      "Accuracy 0.9267935578330894 precision 0.9260917077211893 specificity 0.7994863387980026 recall 0.9267935578330894 f1 0.9240825344803729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 2.7899997234344482 s\n",
      "Accuracy 0.9185944363103953 precision 0.9181973658934321 specificity 0.7751667625819324 recall 0.9185944363103953 f1 0.9149187200897783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 2.8419992923736572 s\n",
      "Accuracy 0.9124450951683748 precision 0.9122988751001397 specificity 0.7622669001972104 recall 0.9124450951683748 f1 0.9081257552865057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 2.896998643875122 s\n",
      "Accuracy 0.9165446559297218 precision 0.9160396108262331 specificity 0.7778713714729033 recall 0.9165446559297218 f1 0.912930175328135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 2.82099986076355 s\n",
      "Accuracy 0.9086383601756954 precision 0.9080858403776234 specificity 0.7663995399736606 recall 0.9086383601756954 f1 0.9044802614620996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 2.775000810623169 s\n",
      "Accuracy 0.9188872620790629 precision 0.9181466605157167 specificity 0.7813170552002169 recall 0.9188872620790629 f1 0.9155140063931458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 2.8269991874694824 s\n",
      "Accuracy 0.9224011713030746 precision 0.9215082975506237 specificity 0.7880986805505213 recall 0.9224011713030746 f1 0.9193620354494688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 2.8020005226135254 s\n",
      "Accuracy 0.9191800878477306 precision 0.9178925126208205 specificity 0.7908899031914789 recall 0.9191800878477306 f1 0.9163189138043597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 2.8289988040924072 s\n",
      "Accuracy 0.91303074670571 precision 0.9122279211410127 specificity 0.7740536262885513 recall 0.91303074670571 f1 0.9093172364378849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 2.7759995460510254 s\n",
      "Accuracy 0.9279648609077599 precision 0.9272278706410202 specificity 0.7987393869135649 recall 0.9279648609077599 f1 0.9252751084664257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 2.8769986629486084 s\n",
      "Accuracy 0.9168374816983894 precision 0.9171294599601612 specificity 0.7735253837020746 recall 0.9168374816983894 f1 0.9128612535991747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 2.8529984951019287 s\n",
      "Accuracy 0.913909224011713 precision 0.9141088840994241 specificity 0.7600885675289274 recall 0.913909224011713 f1 0.9094640412765956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 2.8139986991882324 s\n",
      "Accuracy 0.9191800878477306 precision 0.9191498597939336 specificity 0.7760507483892032 recall 0.9191800878477306 f1 0.9154328955814361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 2.799999475479126 s\n",
      "Accuracy 0.9112737920937043 precision 0.9116999207192604 specificity 0.7606501904821027 recall 0.9112737920937043 f1 0.9067034046323021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 2.8319993019104004 s\n",
      "Accuracy 0.9200585651537335 precision 0.9193925961564965 specificity 0.7817328418094789 recall 0.9200585651537335 f1 0.9166998007094362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 2.709002733230591 s\n",
      "Accuracy 0.9089311859443631 precision 0.9094790312152802 specificity 0.7488698789722551 recall 0.9089311859443631 f1 0.903863938329146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 2.8109970092773438 s\n",
      "Accuracy 0.9089311859443631 precision 0.9089865162867007 specificity 0.7495618798198357 recall 0.9089311859443631 f1 0.9040259632441071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 2.8499984741210938 s\n",
      "Accuracy 0.9191800878477306 precision 0.9199515741553268 specificity 0.7763096396708702 recall 0.9191800878477306 f1 0.915224718398138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 2.815000057220459 s\n",
      "Accuracy 0.9092240117130308 precision 0.9094969292072466 specificity 0.7673488031845952 recall 0.9092240117130308 f1 0.9048580176095946\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 2.843998670578003 s\n",
      "Accuracy 0.9197657393850659 precision 0.9192270794115597 specificity 0.7782396603239108 recall 0.9197657393850659 f1 0.916256380412145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 2.8259987831115723 s\n",
      "Accuracy 0.9171303074670571 precision 0.9172930510406527 specificity 0.7742716106215177 recall 0.9171303074670571 f1 0.91322005988052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 2.826000690460205 s\n",
      "Accuracy 0.9215226939970718 precision 0.9211462584369877 specificity 0.7762970179106632 recall 0.9215226939970718 f1 0.9179538117122363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 2.9009952545166016 s\n",
      "Accuracy 0.9060029282576867 precision 0.9045738964623482 specificity 0.7618660052430833 recall 0.9060029282576867 f1 0.9019582594897549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 2.8699982166290283 s\n",
      "Accuracy 0.9144948755490483 precision 0.9144871025006223 specificity 0.7683042011031018 recall 0.9144948755490483 f1 0.9103815761982668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 2.8359992504119873 s\n",
      "Accuracy 0.9206442166910688 precision 0.9192727530140766 specificity 0.7915910552855474 recall 0.9206442166910688 f1 0.9178780281606617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 2.8179993629455566 s\n",
      "Accuracy 0.9074670571010249 precision 0.9077858229896179 specificity 0.7609010830243832 recall 0.9074670571010249 f1 0.9028260308432958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 2.7709999084472656 s\n",
      "Accuracy 0.9162518301610542 precision 0.915602439458385 specificity 0.7818842809184082 recall 0.9162518301610542 f1 0.9127991841124407\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 2.883000612258911 s\n",
      "Accuracy 0.9200585651537335 precision 0.9192860262987023 specificity 0.7809015571981414 recall 0.9200585651537335 f1 0.9167146965406826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 2.7809996604919434 s\n",
      "Accuracy 0.9171303074670571 precision 0.9155758531161041 specificity 0.773851304349455 recall 0.9171303074670571 f1 0.9138350149894611\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 2.867999792098999 s\n",
      "Accuracy 0.9247437774524158 precision 0.92571155187099 specificity 0.7782606501250668 recall 0.9247437774524158 f1 0.9209571998819521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 2.8319997787475586 s\n",
      "Accuracy 0.9127379209370424 precision 0.913375274038078 specificity 0.7566903715114517 recall 0.9127379209370424 f1 0.9080291057468045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 2.8840346336364746 s\n",
      "Accuracy 0.9121522693997072 precision 0.9125803497926158 specificity 0.7505746745424267 recall 0.9121522693997072 f1 0.9072832178515616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 3.055000066757202 s\n",
      "Accuracy 0.9238653001464129 precision 0.9235630692765754 specificity 0.7901688026623274 recall 0.9238653001464129 f1 0.9207093095198108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 2.9309980869293213 s\n",
      "Accuracy 0.9200585651537335 precision 0.9193861092089073 specificity 0.7776653080551926 recall 0.9200585651537335 f1 0.9165868669615803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 2.8219985961914062 s\n",
      "Accuracy 0.9279648609077599 precision 0.9285943333977031 specificity 0.7986885094489194 recall 0.9279648609077599 f1 0.9248666065870571\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 2.8890016078948975 s\n",
      "Accuracy 0.9127379209370424 precision 0.9121713520668026 specificity 0.7712529797525146 recall 0.9127379209370424 f1 0.90884575537358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 2.8539986610412598 s\n",
      "Accuracy 0.91800878477306 precision 0.9181590888803229 specificity 0.7868527830828068 recall 0.91800878477306 f1 0.9144893554923059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 2.8299992084503174 s\n",
      "Accuracy 0.9144948755490483 precision 0.9157126938400938 specificity 0.7572305072516664 recall 0.9144948755490483 f1 0.9097158131092313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 2.7729973793029785 s\n",
      "Accuracy 0.91303074670571 precision 0.9134106280052898 specificity 0.7628371237239006 recall 0.91303074670571 f1 0.9085950685005416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 2.881000280380249 s\n",
      "Accuracy 0.9153733528550513 precision 0.9151118636174418 specificity 0.7707360997098903 recall 0.9153733528550513 f1 0.9114354883089655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 2.778998613357544 s\n",
      "Accuracy 0.9191800878477306 precision 0.9185177684651217 specificity 0.7820917495147625 recall 0.9191800878477306 f1 0.9158082269807926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 2.8669986724853516 s\n",
      "Accuracy 0.9200585651537335 precision 0.9197494961736825 specificity 0.7930969189340752 recall 0.9200585651537335 f1 0.9168973937144156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 2.774998188018799 s\n",
      "Accuracy 0.9291361639824305 precision 0.9287808955638829 specificity 0.7988307594940409 recall 0.9291361639824305 f1 0.9263425284206525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 2.860999822616577 s\n",
      "Accuracy 0.9074670571010249 precision 0.9068722384034875 specificity 0.7639103727257825 recall 0.9074670571010249 f1 0.9032098732592204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 2.795001745223999 s\n",
      "Accuracy 0.9162518301610542 precision 0.9152859119599503 specificity 0.7858267993156869 recall 0.9162518301610542 f1 0.913035832929681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 2.853998899459839 s\n",
      "Accuracy 0.9188872620790629 precision 0.9186747125733128 specificity 0.7757853006674256 recall 0.9188872620790629 f1 0.9151792115126757\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 2.7669997215270996 s\n",
      "Accuracy 0.9115666178623719 precision 0.9118316569112647 specificity 0.7694505357157574 recall 0.9115666178623719 f1 0.9073315980530012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 2.950000524520874 s\n",
      "Accuracy 0.9109809663250366 precision 0.9120399226655975 specificity 0.7637388622399833 recall 0.9109809663250366 f1 0.9063382976136488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 2.8119986057281494 s\n",
      "Accuracy 0.9209370424597365 precision 0.9198673779815134 specificity 0.7851502183367942 recall 0.9209370424597365 f1 0.917852126366253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 2.793998956680298 s\n",
      "Accuracy 0.9133235724743778 precision 0.9134524287462732 specificity 0.772493673342868 recall 0.9133235724743778 f1 0.909268475767641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 2.923999071121216 s\n",
      "Accuracy 0.9206442166910688 precision 0.9218609970146018 specificity 0.788500061842234 recall 0.9206442166910688 f1 0.9169661225828134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 2.7999982833862305 s\n",
      "Accuracy 0.9165446559297218 precision 0.9166238766943878 specificity 0.7895510414311074 recall 0.9165446559297218 f1 0.9130916515838624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 2.8869993686676025 s\n",
      "Accuracy 0.9218155197657394 precision 0.9208201010082652 specificity 0.8005213654080061 recall 0.9218155197657394 f1 0.9191472971556569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 2.7579991817474365 s\n",
      "Accuracy 0.9238653001464129 precision 0.9237432898423312 specificity 0.7806801096386405 recall 0.9238653001464129 f1 0.9204029516611247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 2.79699969291687 s\n",
      "Accuracy 0.9215226939970718 precision 0.9225556906612357 specificity 0.7853469959179105 recall 0.9215226939970718 f1 0.9178213805727068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 2.8929991722106934 s\n",
      "Accuracy 0.9147877013177159 precision 0.9148955635945214 specificity 0.7698318938544028 recall 0.9147877013177159 f1 0.9106957298757496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 2.8609983921051025 s\n",
      "Accuracy 0.9133235724743778 precision 0.9131213661511581 specificity 0.7681660954797593 recall 0.9133235724743778 f1 0.9092322318133258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 2.8449995517730713 s\n",
      "Accuracy 0.9121522693997072 precision 0.9110606072560681 specificity 0.7566272004520092 recall 0.9121522693997072 f1 0.9079647209536452\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 2.8859989643096924 s\n",
      "Accuracy 0.9171303074670571 precision 0.916982058992012 specificity 0.7747499289140461 recall 0.9171303074670571 f1 0.9133250583971745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 2.825998306274414 s\n",
      "Accuracy 0.9191800878477306 precision 0.9185525069686331 specificity 0.7798184112098171 recall 0.9191800878477306 f1 0.9157309676935277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 2.809000015258789 s\n",
      "Accuracy 0.9080527086383602 precision 0.9072695925733106 specificity 0.7561124911579625 recall 0.9080527086383602 f1 0.903611418200001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 2.862999200820923 s\n",
      "Accuracy 0.9185944363103953 precision 0.9182584272763598 specificity 0.7735526482537098 recall 0.9185944363103953 f1 0.9148524690875135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 2.8449981212615967 s\n",
      "Accuracy 0.9112737920937043 precision 0.9105918626078464 specificity 0.7648650745987717 recall 0.9112737920937043 f1 0.9071787120892437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 2.7659993171691895 s\n",
      "Accuracy 0.9171303074670571 precision 0.9161831123550576 specificity 0.7733120190236565 recall 0.9171303074670571 f1 0.9135536275767182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 2.872999906539917 s\n",
      "Accuracy 0.913909224011713 precision 0.9132060239666646 specificity 0.7670311014855745 recall 0.913909224011713 f1 0.909963008440761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 2.8219995498657227 s\n",
      "Accuracy 0.9142020497803807 precision 0.9136430782212835 specificity 0.7737187473838542 recall 0.9142020497803807 f1 0.9104212835087079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 2.9159996509552 s\n",
      "Accuracy 0.91800878477306 precision 0.9177343150814244 specificity 0.7817540137854704 recall 0.91800878477306 f1 0.9144692149606465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 2.7679996490478516 s\n",
      "Accuracy 0.9174231332357248 precision 0.916876860482044 specificity 0.768098243509518 recall 0.9174231332357248 f1 0.9135561814468293\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 2.9150023460388184 s\n",
      "Accuracy 0.9144948755490483 precision 0.9157382400039205 specificity 0.785306161296114 recall 0.9144948755490483 f1 0.910574555967758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 2.766995906829834 s\n",
      "Accuracy 0.9235724743777453 precision 0.9235139227424267 specificity 0.7868389954340782 recall 0.9235724743777453 f1 0.9202469990184956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 2.82300066947937 s\n",
      "Accuracy 0.9174231332357248 precision 0.9170463028179673 specificity 0.7790064445586734 recall 0.9174231332357248 f1 0.9138218760513309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 2.835998773574829 s\n",
      "Accuracy 0.9191800878477306 precision 0.9183016882344892 specificity 0.769325115558135 recall 0.9191800878477306 f1 0.9155178635322968\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 2.8309993743896484 s\n",
      "Accuracy 0.9247437774524158 precision 0.9244980748833346 specificity 0.7925505481875541 recall 0.9247437774524158 f1 0.9216534454207405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 2.876997947692871 s\n",
      "Accuracy 0.9159590043923865 precision 0.9152775627480273 specificity 0.7722418152876639 recall 0.9159590043923865 f1 0.912221274619524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 2.7789995670318604 s\n",
      "Accuracy 0.9133235724743778 precision 0.9111495107809765 specificity 0.7684986690153192 recall 0.9133235724743778 f1 0.9101151511592189\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 2.8569998741149902 s\n",
      "Accuracy 0.9124450951683748 precision 0.9116782082228642 specificity 0.7732116105352661 recall 0.9124450951683748 f1 0.90867763111351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 2.802999258041382 s\n",
      "Accuracy 0.9165446559297218 precision 0.9165615030445534 specificity 0.7700124134952956 recall 0.9165446559297218 f1 0.9125337195811305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 2.8399999141693115 s\n",
      "Accuracy 0.926207906295754 precision 0.925869404006813 specificity 0.8106568131051974 recall 0.926207906295754 f1 0.9236370634263352\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 2.7850019931793213 s\n",
      "Accuracy 0.9095168374816984 precision 0.9092299256435725 specificity 0.7484988909703513 recall 0.9095168374816984 f1 0.9046987524575267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 2.8709988594055176 s\n",
      "Accuracy 0.9191800878477306 precision 0.9185579735428838 specificity 0.7722812559691692 recall 0.9191800878477306 f1 0.9155122800914766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 2.850999355316162 s\n",
      "Accuracy 0.9177159590043924 precision 0.9175411978026707 specificity 0.7763175581089872 recall 0.9177159590043924 f1 0.9139802954518285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 2.848001718521118 s\n",
      "Accuracy 0.9162518301610542 precision 0.9162962747820899 specificity 0.7741979110155952 recall 0.9162518301610542 f1 0.9123496250240716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 2.8480019569396973 s\n",
      "Accuracy 0.913909224011713 precision 0.9138329411397101 specificity 0.7672644748531403 recall 0.913909224011713 f1 0.909767751377707\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 2.8539974689483643 s\n",
      "Accuracy 0.91800878477306 precision 0.9182360117040695 specificity 0.7857072125304401 recall 0.91800878477306 f1 0.9144350163472044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 2.777998924255371 s\n",
      "Accuracy 0.9177159590043924 precision 0.9180127163892364 specificity 0.7733906602110593 recall 0.9177159590043924 f1 0.9137587594832492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 2.7919979095458984 s\n",
      "Accuracy 0.9188872620790629 precision 0.9181284802818745 specificity 0.7769182210975543 recall 0.9188872620790629 f1 0.9153936131892099\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 2.8219995498657227 s\n",
      "Accuracy 0.9150805270863837 precision 0.9154737399524121 specificity 0.7590367383985738 recall 0.9150805270863837 f1 0.9105862939455633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 2.9759998321533203 s\n",
      "Accuracy 0.9191800878477306 precision 0.9188018582303914 specificity 0.7825216719025936 recall 0.9191800878477306 f1 0.9157243440128233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 2.8949995040893555 s\n",
      "Accuracy 0.9133235724743778 precision 0.9127057606230066 specificity 0.7642002370494317 recall 0.9133235724743778 f1 0.9092424753770088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 2.8299965858459473 s\n",
      "Accuracy 0.9224011713030746 precision 0.9226854528725177 specificity 0.7823204877577006 recall 0.9224011713030746 f1 0.9188274290970977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 3.07900071144104 s\n",
      "Accuracy 0.9144948755490483 precision 0.9140138006662397 specificity 0.7624463281191295 recall 0.9144948755490483 f1 0.9103476195425215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 3.1949996948242188 s\n",
      "Accuracy 0.9174231332357248 precision 0.9169693563334635 specificity 0.7758737317157343 recall 0.9174231332357248 f1 0.9137551584197356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 2.7449989318847656 s\n",
      "Accuracy 0.9200585651537335 precision 0.9199964926998212 specificity 0.7832775477961273 recall 0.9200585651537335 f1 0.9165481639404119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 2.855001211166382 s\n",
      "Accuracy 0.9133235724743778 precision 0.9128098047130422 specificity 0.7520961046758553 recall 0.9133235724743778 f1 0.9088234982586012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 3.0139987468719482 s\n",
      "Accuracy 0.9206442166910688 precision 0.9205149875035044 specificity 0.7873827222204277 recall 0.9206442166910688 f1 0.9172822867577959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 3.1080009937286377 s\n",
      "Accuracy 0.9209370424597365 precision 0.9203493894310145 specificity 0.7770535198992011 recall 0.9209370424597365 f1 0.9174426732126164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 3.0169997215270996 s\n",
      "Accuracy 0.9203513909224011 precision 0.919304691844241 specificity 0.7808127476890181 recall 0.9203513909224011 f1 0.9171187439444809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 2.915372371673584 s\n",
      "Accuracy 0.9168374816983894 precision 0.9164869696492374 specificity 0.7925765285983146 recall 0.9168374816983894 f1 0.9136096554850068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 2.9939332008361816 s\n",
      "Accuracy 0.9136163982430454 precision 0.9133563506403235 specificity 0.758844912938568 recall 0.9136163982430454 f1 0.9092591022502776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 2.9389994144439697 s\n",
      "Accuracy 0.922108345534407 precision 0.9216451846877389 specificity 0.7750559131619424 recall 0.922108345534407 f1 0.9185501051443025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 2.7365691661834717 s\n",
      "Accuracy 0.9183016105417277 precision 0.9177815612893195 specificity 0.7806973812485647 recall 0.9183016105417277 f1 0.9148187189788637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 2.8660013675689697 s\n",
      "Accuracy 0.9136163982430454 precision 0.9136060224712281 specificity 0.768482279500197 recall 0.9136163982430454 f1 0.909485021934936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 2.9305102825164795 s\n",
      "Accuracy 0.9197657393850659 precision 0.9199600298548586 specificity 0.78398179120905 recall 0.9197657393850659 f1 0.9161942867521762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 2.8510146141052246 s\n",
      "Accuracy 0.9174231332357248 precision 0.9166920297200745 specificity 0.7723022251780339 recall 0.9174231332357248 f1 0.9137446207585119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 2.9019339084625244 s\n",
      "Accuracy 0.9147877013177159 precision 0.9143489098317179 specificity 0.7570042118730629 recall 0.9147877013177159 f1 0.9104666099904473\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 2.860344171524048 s\n",
      "Accuracy 0.9226939970717423 precision 0.9229003612926279 specificity 0.7851962557496375 recall 0.9226939970717423 f1 0.9192268444846515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 2.8667750358581543 s\n",
      "Accuracy 0.9203513909224011 precision 0.9193790053106554 specificity 0.7805884342685379 recall 0.9203513909224011 f1 0.9170823976962564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 2.870999574661255 s\n",
      "Accuracy 0.9124450951683748 precision 0.9130579610494874 specificity 0.7592522579749156 recall 0.9124450951683748 f1 0.9078152749754133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 2.74299955368042 s\n",
      "Accuracy 0.9147877013177159 precision 0.9140278246285273 specificity 0.7788683731504903 recall 0.9147877013177159 f1 0.911249693795677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 2.8499975204467773 s\n",
      "Accuracy 0.91800878477306 precision 0.917546303956704 specificity 0.769923766546588 recall 0.91800878477306 f1 0.9141851030557782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 2.9426190853118896 s\n",
      "Accuracy 0.9209370424597365 precision 0.9199616363917344 specificity 0.7859398061225972 recall 0.9209370424597365 f1 0.9178354698212653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 2.8190112113952637 s\n",
      "Accuracy 0.91800878477306 precision 0.9172679737912707 specificity 0.7665414490742455 recall 0.91800878477306 f1 0.914179898270349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 2.8572263717651367 s\n",
      "Accuracy 0.913909224011713 precision 0.9130092653378826 specificity 0.7595103620732794 recall 0.913909224011713 f1 0.90979690839441\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 2.84199857711792 s\n",
      "Accuracy 0.91303074670571 precision 0.9129161950959329 specificity 0.7618236609986866 recall 0.91303074670571 f1 0.9087050351963171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 2.814000129699707 s\n",
      "Accuracy 0.92298682284041 precision 0.9223065760055387 specificity 0.8030623154512759 recall 0.92298682284041 f1 0.9202819222269977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 2.9010000228881836 s\n",
      "Accuracy 0.9218155197657394 precision 0.9216515328291184 specificity 0.7870207181717516 recall 0.9218155197657394 f1 0.9184824299905255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 2.8889999389648438 s\n",
      "Accuracy 0.9144948755490483 precision 0.9141256013581218 specificity 0.7626817488969568 recall 0.9144948755490483 f1 0.9103187910602636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 2.823998212814331 s\n",
      "Accuracy 0.9133235724743778 precision 0.9127820673894979 specificity 0.7745261205656266 recall 0.9133235724743778 f1 0.9095399815207318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 2.8309996128082275 s\n",
      "Accuracy 0.9200585651537335 precision 0.9188650237121677 specificity 0.7891782097473595 recall 0.9200585651537335 f1 0.9171224123177174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 2.834998369216919 s\n",
      "Accuracy 0.9171303074670571 precision 0.9167475238587313 specificity 0.7888945303408785 recall 0.9171303074670571 f1 0.9138121991541385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 2.858999013900757 s\n",
      "Accuracy 0.9200585651537335 precision 0.9190028426474333 specificity 0.7759942272935829 recall 0.9200585651537335 f1 0.9166833787685309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 2.8109982013702393 s\n",
      "Accuracy 0.9133235724743778 precision 0.9123330852121605 specificity 0.7746350613658208 recall 0.9133235724743778 f1 0.9097064709907212\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 2.879000663757324 s\n",
      "Accuracy 0.9159590043923865 precision 0.9168428078570905 specificity 0.7736815591017033 recall 0.9159590043923865 f1 0.911809731255775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 2.824997901916504 s\n",
      "Accuracy 0.9162518301610542 precision 0.9167628333620998 specificity 0.7699277055140324 recall 0.9162518301610542 f1 0.9120930900308781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 2.809999942779541 s\n",
      "Accuracy 0.9194729136163983 precision 0.91914011375332 specificity 0.7775724473581482 recall 0.9194729136163983 f1 0.9158693667085385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 2.9059977531433105 s\n",
      "Accuracy 0.913909224011713 precision 0.9122960038718633 specificity 0.7830794920901818 recall 0.913909224011713 f1 0.9108609287568661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 2.9140007495880127 s\n",
      "Accuracy 0.913909224011713 precision 0.9136220472128452 specificity 0.7829216384382185 recall 0.913909224011713 f1 0.9103139993889977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 2.817521095275879 s\n",
      "Accuracy 0.9215226939970718 precision 0.9211385609652468 specificity 0.799804048505436 recall 0.9215226939970718 f1 0.9185987569681187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 2.8708560466766357 s\n",
      "Accuracy 0.9124450951683748 precision 0.9131139044312274 specificity 0.7663239047176212 recall 0.9124450951683748 f1 0.9080256282232231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 2.8949434757232666 s\n",
      "Accuracy 0.9200585651537335 precision 0.9200510948603989 specificity 0.7856262438334942 recall 0.9200585651537335 f1 0.9165977315352095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 2.8259992599487305 s\n",
      "Accuracy 0.9159590043923865 precision 0.9160946198231131 specificity 0.772044640858904 recall 0.9159590043923865 f1 0.911958306520405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 2.8271093368530273 s\n",
      "Accuracy 0.9112737920937043 precision 0.9110268162395557 specificity 0.7616678386614504 recall 0.9112737920937043 f1 0.9069322722629877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 2.730494260787964 s\n",
      "Accuracy 0.9177159590043924 precision 0.9173935761799633 specificity 0.770229134070798 recall 0.9177159590043924 f1 0.9138477777510597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 2.9622795581817627 s\n",
      "Accuracy 0.9191800878477306 precision 0.9185841302241716 specificity 0.7954283451800473 recall 0.9191800878477306 f1 0.916162819098651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 2.8059966564178467 s\n",
      "Accuracy 0.9168374816983894 precision 0.9159077849749464 specificity 0.7830178118660529 recall 0.9168374816983894 f1 0.9135363103047689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 2.913999557495117 s\n",
      "Accuracy 0.9159590043923865 precision 0.9146680090094539 specificity 0.7836994294822007 recall 0.9159590043923865 f1 0.9128122319519043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 2.9689981937408447 s\n",
      "Accuracy 0.9147877013177159 precision 0.9153203517132402 specificity 0.7729600464300318 recall 0.9147877013177159 f1 0.9106743492299628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 2.867999315261841 s\n",
      "Accuracy 0.9150805270863837 precision 0.9155379615811144 specificity 0.771430521490449 recall 0.9150805270863837 f1 0.9109485148347517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 2.797999620437622 s\n",
      "Accuracy 0.9150805270863837 precision 0.9144983239016784 specificity 0.7649439144478914 recall 0.9150805270863837 f1 0.911061502546964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 2.8100013732910156 s\n",
      "Accuracy 0.9115666178623719 precision 0.9118403113975246 specificity 0.78220456380688 recall 0.9115666178623719 f1 0.9077325288977992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 2.830000162124634 s\n",
      "Accuracy 0.9206442166910688 precision 0.9204141148317826 specificity 0.7830160035055601 recall 0.9206442166910688 f1 0.917192122312881\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 2.8799989223480225 s\n",
      "Accuracy 0.9188872620790629 precision 0.9181977840973082 specificity 0.7937770167913925 recall 0.9188872620790629 f1 0.9158513952295227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 2.8769993782043457 s\n",
      "Accuracy 0.9171303074670571 precision 0.9185385418045395 specificity 0.7695638562896944 recall 0.9171303074670571 f1 0.9127677787865773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 2.80899977684021 s\n",
      "Accuracy 0.9250366032210835 precision 0.9246160930157522 specificity 0.7940179741221782 recall 0.9250366032210835 f1 0.9220471702302767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 2.872999429702759 s\n",
      "Accuracy 0.92298682284041 precision 0.9230638235644612 specificity 0.7757949691297173 recall 0.92298682284041 f1 0.9193102300241984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 2.8539981842041016 s\n",
      "Accuracy 0.9077598828696926 precision 0.9062829779085568 specificity 0.7599750059871896 recall 0.9077598828696926 f1 0.9037157944259561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 2.747999906539917 s\n",
      "Accuracy 0.9203513909224011 precision 0.919806829113192 specificity 0.8021308472702348 recall 0.9203513909224011 f1 0.917523855077631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 2.8670005798339844 s\n",
      "Accuracy 0.9106881405563689 precision 0.9100738697285963 specificity 0.7721352436001399 recall 0.9106881405563689 f1 0.9067897779865388\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 2.9189984798431396 s\n",
      "Accuracy 0.9115666178623719 precision 0.9123190662927947 specificity 0.765018066933074 recall 0.9115666178623719 f1 0.9070590351972853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 2.7819998264312744 s\n",
      "Accuracy 0.9185944363103953 precision 0.918292705291885 specificity 0.7749862651434417 recall 0.9185944363103953 f1 0.9148831050471036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 2.805997610092163 s\n",
      "Accuracy 0.9183016105417277 precision 0.917331203574936 specificity 0.789666241426021 recall 0.9183016105417277 f1 0.9152446268918016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 2.879995822906494 s\n",
      "Accuracy 0.9144948755490483 precision 0.9156503544726017 specificity 0.7660023080530696 recall 0.9144948755490483 f1 0.9100037286180694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 2.9509994983673096 s\n",
      "Accuracy 0.9153733528550513 precision 0.9147215347882653 specificity 0.7783676296382649 recall 0.9153733528550513 f1 0.9117953862948295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 2.8949992656707764 s\n",
      "Accuracy 0.92298682284041 precision 0.9229849912752386 specificity 0.7911019166560306 recall 0.92298682284041 f1 0.9197435156602635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 2.7598187923431396 s\n",
      "Accuracy 0.9124450951683748 precision 0.9138510292934279 specificity 0.7587053820194123 recall 0.9124450951683748 f1 0.9076012329836052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 2.85499906539917 s\n",
      "Accuracy 0.9147877013177159 precision 0.9140968783055404 specificity 0.7672374373323531 recall 0.9147877013177159 f1 0.9108681763539296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 2.871633529663086 s\n",
      "Accuracy 0.9156661786237189 precision 0.9151352713465927 specificity 0.773243240560787 recall 0.9156661786237189 f1 0.911899248907354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 2.7919976711273193 s\n",
      "Accuracy 0.9212298682284041 precision 0.921626261109708 specificity 0.7812178588616511 recall 0.9212298682284041 f1 0.9175645202599022\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 2.7830045223236084 s\n",
      "Accuracy 0.9194729136163983 precision 0.9196712861861139 specificity 0.7827047598984475 recall 0.9194729136163983 f1 0.9158570765193291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 2.810997247695923 s\n",
      "Accuracy 0.922108345534407 precision 0.9223554390011872 specificity 0.7888236653882043 recall 0.922108345534407 f1 0.9187130900649986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 2.8489990234375 s\n",
      "Accuracy 0.9086383601756954 precision 0.9081727430934082 specificity 0.7622284378097465 recall 0.9086383601756954 f1 0.9043118870332915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 2.7769992351531982 s\n",
      "Accuracy 0.9144948755490483 precision 0.912865247829867 specificity 0.7862240801440217 recall 0.9144948755490483 f1 0.911571639153804\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 2.853998899459839 s\n",
      "Accuracy 0.9144948755490483 precision 0.9138762052794639 specificity 0.7762154929561567 recall 0.9144948755490483 f1 0.9108185544496653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 2.86099910736084 s\n",
      "Accuracy 0.9212298682284041 precision 0.9202989292839248 specificity 0.7785768850781898 recall 0.9212298682284041 f1 0.9179110350008681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 2.908999443054199 s\n",
      "Accuracy 0.91303074670571 precision 0.9140232715707204 specificity 0.7619425850472826 recall 0.91303074670571 f1 0.9084077371263388\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 2.7980003356933594 s\n",
      "Accuracy 0.9109809663250366 precision 0.9110313386545967 specificity 0.7753266799347198 recall 0.9109809663250366 f1 0.9069803993448993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 2.8069992065429688 s\n",
      "Accuracy 0.9200585651537335 precision 0.9189288063009337 specificity 0.7889389138876995 recall 0.9200585651537335 f1 0.9170868403849366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 2.862377166748047 s\n",
      "Accuracy 0.9200585651537335 precision 0.9194743248280518 specificity 0.7924585726359948 recall 0.9200585651537335 f1 0.9169719351270614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 2.8463258743286133 s\n",
      "Accuracy 0.9080527086383602 precision 0.9060293194571177 specificity 0.75518830319894 recall 0.9080527086383602 f1 0.9041137448227915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 2.8640005588531494 s\n",
      "Accuracy 0.9150805270863837 precision 0.9144887646209326 specificity 0.7645696456377928 recall 0.9150805270863837 f1 0.9110532069461034\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 2.7919998168945312 s\n",
      "Accuracy 0.9153733528550513 precision 0.9146239134914304 specificity 0.7745517515666684 recall 0.9153733528550513 f1 0.9117144433331646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 2.793997287750244 s\n",
      "Accuracy 0.9212298682284041 precision 0.9208304226699897 specificity 0.7824261677423507 recall 0.9212298682284041 f1 0.9178300893952912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 2.82399845123291 s\n",
      "Accuracy 0.9121522693997072 precision 0.9122286992012855 specificity 0.7607089190536852 recall 0.9121522693997072 f1 0.9077083766810522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 2.8003342151641846 s\n",
      "Accuracy 0.9218155197657394 precision 0.9230895302725257 specificity 0.7869256031659013 recall 0.9218155197657394 f1 0.918110579750249\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 2.8879988193511963 s\n",
      "Accuracy 0.91800878477306 precision 0.9175675148552447 specificity 0.778856163136105 recall 0.91800878477306 f1 0.9144389540374377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 2.775999069213867 s\n",
      "Accuracy 0.9115666178623719 precision 0.9102670023149814 specificity 0.7695345827676874 recall 0.9115666178623719 f1 0.9078689221752099\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 2.7880001068115234 s\n",
      "Accuracy 0.9177159590043924 precision 0.9177737729627949 specificity 0.7681114610144979 recall 0.9177159590043924 f1 0.9136709466080503\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 2.7950005531311035 s\n",
      "Accuracy 0.9200585651537335 precision 0.9202341720211344 specificity 0.7799908084899264 recall 0.9200585651537335 f1 0.9163877771817267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 2.9359984397888184 s\n",
      "Accuracy 0.9168374816983894 precision 0.9160180556099112 specificity 0.7841582100839856 recall 0.9168374816983894 f1 0.9135277179428323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 2.945997714996338 s\n",
      "Accuracy 0.9256222547584187 precision 0.9248961898440429 specificity 0.7973597023931183 recall 0.9256222547584187 f1 0.922839939815634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 2.838000535964966 s\n",
      "Accuracy 0.9127379209370424 precision 0.9133081070774063 specificity 0.7639931765395457 recall 0.9127379209370424 f1 0.908278936424549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 2.902998447418213 s\n",
      "Accuracy 0.9191800878477306 precision 0.918510631602223 specificity 0.7780665865198196 recall 0.9191800878477306 f1 0.9156953937869171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 2.821000099182129 s\n",
      "Accuracy 0.9162518301610542 precision 0.9155359233688382 specificity 0.7644168829245268 recall 0.9162518301610542 f1 0.9122973960800791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 2.8650002479553223 s\n",
      "Accuracy 0.9089311859443631 precision 0.9091229744076769 specificity 0.7672529775735505 recall 0.9089311859443631 f1 0.9045776032908117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 2.782999038696289 s\n",
      "Accuracy 0.9112737920937043 precision 0.9114091103731274 specificity 0.7543197868096105 recall 0.9112737920937043 f1 0.9065792844810983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 2.8549997806549072 s\n",
      "Accuracy 0.9185944363103953 precision 0.9181580009629534 specificity 0.7853645641718064 recall 0.9185944363103953 f1 0.9152247456005832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 2.8619983196258545 s\n",
      "Accuracy 0.9124450951683748 precision 0.9129181385852134 specificity 0.7635357695020288 recall 0.9124450951683748 f1 0.9079889903608188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 2.9180004596710205 s\n",
      "Accuracy 0.9068814055636896 precision 0.9079925928837277 specificity 0.7437249457557281 recall 0.9068814055636896 f1 0.9014201602860492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 2.8229987621307373 s\n",
      "Accuracy 0.9197657393850659 precision 0.9198177832613095 specificity 0.7910661314468049 recall 0.9197657393850659 f1 0.9164324405685362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 2.8250010013580322 s\n",
      "Accuracy 0.9215226939970718 precision 0.9207740739114173 specificity 0.7911174059298557 recall 0.9215226939970718 f1 0.9184905457920065\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 2.8289988040924072 s\n",
      "Accuracy 0.9183016105417277 precision 0.9180384612562285 specificity 0.779454185120281 recall 0.9183016105417277 f1 0.9146994169850633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 2.8399999141693115 s\n",
      "Accuracy 0.9062957540263543 precision 0.9062628401181126 specificity 0.7518413764778987 recall 0.9062957540263543 f1 0.9014118193119992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 2.7360002994537354 s\n",
      "Accuracy 0.9183016105417277 precision 0.9179882433499543 specificity 0.777370763001374 recall 0.9183016105417277 f1 0.9146550393179996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 2.86899995803833 s\n",
      "Accuracy 0.9127379209370424 precision 0.9123324948852184 specificity 0.761988206053156 recall 0.9127379209370424 f1 0.9084994564131673\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 2.8849987983703613 s\n",
      "Accuracy 0.9171303074670571 precision 0.9174028206503214 specificity 0.7832928675208382 recall 0.9171303074670571 f1 0.9134536739975442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 2.854804277420044 s\n",
      "Accuracy 0.9224011713030746 precision 0.921294198565802 specificity 0.7885046214334409 recall 0.9224011713030746 f1 0.9194619828428656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 2.868908405303955 s\n",
      "Accuracy 0.9142020497803807 precision 0.9137273533923662 specificity 0.7614603815092804 recall 0.9142020497803807 f1 0.9100131532266879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 2.790031909942627 s\n",
      "Accuracy 0.9212298682284041 precision 0.9214537066428368 specificity 0.7925511084753146 recall 0.9212298682284041 f1 0.9179215451324336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 2.7880172729492188 s\n",
      "Accuracy 0.9241581259150805 precision 0.9235754417247587 specificity 0.7981791430767824 recall 0.9241581259150805 f1 0.921312580707805\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 2.9247066974639893 s\n",
      "Accuracy 0.9212298682284041 precision 0.9206361028551961 specificity 0.7858017756720295 recall 0.9212298682284041 f1 0.9179886163846429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 2.7299978733062744 s\n",
      "Accuracy 0.9124450951683748 precision 0.912393105612742 specificity 0.7699861126127221 recall 0.9124450951683748 f1 0.9083417627980225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 2.8069984912872314 s\n",
      "Accuracy 0.9136163982430454 precision 0.9127681234533145 specificity 0.7778215109964628 recall 0.9136163982430454 f1 0.9100514638045114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 2.854001045227051 s\n",
      "Accuracy 0.9215226939970718 precision 0.9213736817676837 specificity 0.79055622351218 recall 0.9215226939970718 f1 0.9182742151832961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 2.849999189376831 s\n",
      "Accuracy 0.9244509516837481 precision 0.923325003292953 specificity 0.7913521258772892 recall 0.9244509516837481 f1 0.9216477868885277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 2.9442994594573975 s\n",
      "Accuracy 0.922108345534407 precision 0.9213211375625177 specificity 0.7845681698918763 recall 0.922108345534407 f1 0.9189246229603903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 2.864000082015991 s\n",
      "Accuracy 0.9095168374816984 precision 0.9090492598633426 specificity 0.7542705892033591 recall 0.9095168374816984 f1 0.9049500413719009\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 2.7899999618530273 s\n",
      "Accuracy 0.913909224011713 precision 0.913874581892227 specificity 0.773085043491029 recall 0.913909224011713 f1 0.9099352193474456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 2.7069990634918213 s\n",
      "Accuracy 0.9200585651537335 precision 0.9202774074906653 specificity 0.7721895390285757 recall 0.9200585651537335 f1 0.9161556001054123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 2.822303295135498 s\n",
      "Accuracy 0.9212298682284041 precision 0.9217754235751124 specificity 0.7879314977126228 recall 0.9212298682284041 f1 0.9177104327384168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 2.840998888015747 s\n",
      "Accuracy 0.9212298682284041 precision 0.9201123703222844 specificity 0.7740513392086733 recall 0.9212298682284041 f1 0.917857360979823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 2.828000545501709 s\n",
      "Accuracy 0.9194729136163983 precision 0.919366320366918 specificity 0.7741738040581992 recall 0.9194729136163983 f1 0.9157028875423532\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 2.854999303817749 s\n",
      "Accuracy 0.9136163982430454 precision 0.9134640292980606 specificity 0.7630012259604463 recall 0.9136163982430454 f1 0.909356561991031\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 2.9010009765625 s\n",
      "Accuracy 0.9153733528550513 precision 0.9165692323781636 specificity 0.767222163851561 recall 0.9153733528550513 f1 0.9109364202098241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 2.8109986782073975 s\n",
      "Accuracy 0.9109809663250366 precision 0.9104286805907732 specificity 0.7571822710814338 recall 0.9109809663250366 f1 0.9065831733081391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 2.898001194000244 s\n",
      "Accuracy 0.9142020497803807 precision 0.9139134917417548 specificity 0.7803829151781915 recall 0.9142020497803807 f1 0.9105364607316561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 2.7940008640289307 s\n",
      "Accuracy 0.91303074670571 precision 0.9135155413401332 specificity 0.7715516932120957 recall 0.91303074670571 f1 0.9088401527178952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 2.7585179805755615 s\n",
      "Accuracy 0.913909224011713 precision 0.9133475058673663 specificity 0.7686987798377108 recall 0.913909224011713 f1 0.9099663460397932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 2.8580007553100586 s\n",
      "Accuracy 0.9212298682284041 precision 0.9200558613877583 specificity 0.7816435714821924 recall 0.9212298682284041 f1 0.918097593753233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 2.7920005321502686 s\n",
      "Accuracy 0.9200585651537335 precision 0.92049313511432 specificity 0.7766799682886157 recall 0.9200585651537335 f1 0.9162243667576341\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 2.8059990406036377 s\n",
      "Accuracy 0.9185944363103953 precision 0.9173283475285612 specificity 0.7814758105937373 recall 0.9185944363103953 f1 0.9154311521240404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 2.938000202178955 s\n",
      "Accuracy 0.9150805270863837 precision 0.9145036742007585 specificity 0.7801401733246283 recall 0.9150805270863837 f1 0.9115230984896963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 3.001000165939331 s\n",
      "Accuracy 0.9147877013177159 precision 0.9150868693791702 specificity 0.7636028135843215 recall 0.9147877013177159 f1 0.9104507995970254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 2.872148036956787 s\n",
      "Accuracy 0.9115666178623719 precision 0.9104076903110195 specificity 0.7555376203021039 recall 0.9115666178623719 f1 0.9073511524266693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 2.8093719482421875 s\n",
      "Accuracy 0.9080527086383602 precision 0.9071515037689037 specificity 0.771919357647488 recall 0.9080527086383602 f1 0.9041897498050636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 2.8479950428009033 s\n",
      "Accuracy 0.9200585651537335 precision 0.919456336123274 specificity 0.7686258943393701 recall 0.9200585651537335 f1 0.9163047992225568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 2.7431492805480957 s\n",
      "Accuracy 0.9174231332357248 precision 0.917340718218185 specificity 0.7744862351412743 recall 0.9174231332357248 f1 0.9135982124202005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 2.8309998512268066 s\n",
      "Accuracy 0.9136163982430454 precision 0.9135308080249878 specificity 0.789335500186726 recall 0.9136163982430454 f1 0.9101474328714994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 2.8719985485076904 s\n",
      "Accuracy 0.9191800878477306 precision 0.9189171516914716 specificity 0.7749838906155875 recall 0.9191800878477306 f1 0.9154726753240858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 2.881999969482422 s\n",
      "Accuracy 0.9112737920937043 precision 0.9103399887734293 specificity 0.7726938815568986 recall 0.9112737920937043 f1 0.9075234151487838\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 2.897998094558716 s\n",
      "Accuracy 0.9174231332357248 precision 0.9162023894156628 specificity 0.7854525652729972 recall 0.9174231332357248 f1 0.9143302888303042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 2.8049991130828857 s\n",
      "Accuracy 0.9247437774524158 precision 0.9243806344341293 specificity 0.7782130031312481 recall 0.9247437774524158 f1 0.9213155247400735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 2.805997610092163 s\n",
      "Accuracy 0.9194729136163983 precision 0.9188864157245983 specificity 0.786434480010964 recall 0.9194729136163983 f1 0.916204942503323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 2.840000867843628 s\n",
      "Accuracy 0.9127379209370424 precision 0.9127889108450414 specificity 0.7579807885545318 recall 0.9127379209370424 f1 0.9082322595252568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 2.8159985542297363 s\n",
      "Accuracy 0.9159590043923865 precision 0.9154310588096216 specificity 0.7745592012929902 recall 0.9159590043923865 f1 0.912238383987405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 2.865000009536743 s\n",
      "Accuracy 0.9159590043923865 precision 0.9172142320805042 specificity 0.7675200522208017 recall 0.9159590043923865 f1 0.9115348145291438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 2.8560006618499756 s\n",
      "Accuracy 0.9224011713030746 precision 0.9219555589359397 specificity 0.8007653557925655 recall 0.9224011713030746 f1 0.9195405463243385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 2.8680009841918945 s\n",
      "Accuracy 0.9206442166910688 precision 0.9217756941994004 specificity 0.784576979079944 recall 0.9206442166910688 f1 0.9168761737621302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 2.830545663833618 s\n",
      "Accuracy 0.913909224011713 precision 0.9137300006734825 specificity 0.7589323153067825 recall 0.913909224011713 f1 0.9095389697161567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 2.7960004806518555 s\n",
      "Accuracy 0.9279648609077599 precision 0.928038152387164 specificity 0.7963624878977674 recall 0.9279648609077599 f1 0.9249542307456634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 2.917001485824585 s\n",
      "Accuracy 0.9203513909224011 precision 0.9190597375021199 specificity 0.788754586544718 recall 0.9203513909224011 f1 0.9174558332620828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 2.7739996910095215 s\n",
      "Accuracy 0.9168374816983894 precision 0.915866615602794 specificity 0.784555921743293 recall 0.9168374816983894 f1 0.9135984087813344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 2.8560006618499756 s\n",
      "Accuracy 0.9185944363103953 precision 0.9191308429932907 specificity 0.7783640013754419 recall 0.9185944363103953 f1 0.9147415794482306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 2.8050003051757812 s\n",
      "Accuracy 0.9174231332357248 precision 0.9162323871514173 specificity 0.7745443850239403 recall 0.9174231332357248 f1 0.913989362003502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 2.8723409175872803 s\n",
      "Accuracy 0.9250366032210835 precision 0.9240321237544836 specificity 0.7925284753582758 recall 0.9250366032210835 f1 0.9222259193470165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 2.836000919342041 s\n",
      "Accuracy 0.9147877013177159 precision 0.9146137814374153 specificity 0.7586818454534646 recall 0.9147877013177159 f1 0.9104358481890178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 2.84800124168396 s\n",
      "Accuracy 0.9185944363103953 precision 0.9192635652982759 specificity 0.7738640963280475 recall 0.9185944363103953 f1 0.9145777771611224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 2.8170032501220703 s\n",
      "Accuracy 0.9185944363103953 precision 0.9175404552666984 specificity 0.7841210284387883 recall 0.9185944363103953 f1 0.9154169082602047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 2.8600001335144043 s\n",
      "Accuracy 0.9188872620790629 precision 0.9187997707007768 specificity 0.7676114604183981 recall 0.9188872620790629 f1 0.9149055272937175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 2.895000457763672 s\n",
      "Accuracy 0.9112737920937043 precision 0.9107362026997379 specificity 0.7589109298335314 recall 0.9112737920937043 f1 0.9069363455775873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 2.8979992866516113 s\n",
      "Accuracy 0.9086383601756954 precision 0.9089022601035632 specificity 0.7600812089620109 recall 0.9086383601756954 f1 0.9040178423042395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 2.667999744415283 s\n",
      "Accuracy 0.9174231332357248 precision 0.917410527410325 specificity 0.763751495548218 recall 0.9174231332357248 f1 0.9132606138148573\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 2.9529991149902344 s\n",
      "Accuracy 0.9177159590043924 precision 0.9174898304351902 specificity 0.7741993819769036 recall 0.9177159590043924 f1 0.9139341970459611\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 2.798508882522583 s\n",
      "Accuracy 0.9174231332357248 precision 0.9166130710217839 specificity 0.7799367423462802 recall 0.9174231332357248 f1 0.9139990098770666\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 2.8669986724853516 s\n",
      "Accuracy 0.9215226939970718 precision 0.9214748316308922 specificity 0.8030393076160595 recall 0.9215226939970718 f1 0.9185805148300585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 2.7839982509613037 s\n",
      "Accuracy 0.9183016105417277 precision 0.9177432872705154 specificity 0.7672033839088829 recall 0.9183016105417277 f1 0.9144384163052928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 2.779001235961914 s\n",
      "Accuracy 0.9121522693997072 precision 0.9118014102357528 specificity 0.753266556803873 recall 0.9121522693997072 f1 0.9075985646195097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 2.828998327255249 s\n",
      "Accuracy 0.9147877013177159 precision 0.914859232251528 specificity 0.7683945170968862 recall 0.9147877013177159 f1 0.9106622453897277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 2.843998908996582 s\n",
      "Accuracy 0.9244509516837481 precision 0.9237357407351651 specificity 0.7968674903217631 recall 0.9244509516837481 f1 0.9216257543964745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 2.8741812705993652 s\n",
      "Accuracy 0.9136163982430454 precision 0.915036791517353 specificity 0.7717732309694141 recall 0.9136163982430454 f1 0.9092176067040717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 2.8519985675811768 s\n",
      "Accuracy 0.9133235724743778 precision 0.9130284863846514 specificity 0.7686619871610211 recall 0.9133235724743778 f1 0.9092767029074678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 2.802340030670166 s\n",
      "Accuracy 0.9183016105417277 precision 0.9183243816132884 specificity 0.7785835538317325 recall 0.9183016105417277 f1 0.9145881786046747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 2.75614333152771 s\n",
      "Accuracy 0.9226939970717423 precision 0.9220100006822256 specificity 0.7760852399513971 recall 0.9226939970717423 f1 0.9192560198941822\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 2.8713510036468506 s\n",
      "Accuracy 0.9136163982430454 precision 0.9129516668932093 specificity 0.7745824620460848 recall 0.9136163982430454 f1 0.9098842438497945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 2.8650004863739014 s\n",
      "Accuracy 0.9147877013177159 precision 0.9143481428420716 specificity 0.7653010313027394 recall 0.9147877013177159 f1 0.9107238957092326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 2.8689966201782227 s\n",
      "Accuracy 0.9077598828696926 precision 0.9075225034023504 specificity 0.7666223305017419 recall 0.9077598828696926 f1 0.9034846074302075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 2.805999279022217 s\n",
      "Accuracy 0.9185944363103953 precision 0.9185150564666744 specificity 0.788397260732942 recall 0.9185944363103953 f1 0.9151988396793775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 2.8849997520446777 s\n",
      "Accuracy 0.9153733528550513 precision 0.9156359051936663 specificity 0.7830917419207232 recall 0.9153733528550513 f1 0.9116527489009721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 2.8239965438842773 s\n",
      "Accuracy 0.9203513909224011 precision 0.9201454729444669 specificity 0.7827307676168915 recall 0.9203513909224011 f1 0.9168764712615686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 2.8459994792938232 s\n",
      "Accuracy 0.9183016105417277 precision 0.9174781001101275 specificity 0.7792085502846474 recall 0.9183016105417277 f1 0.9148830708544103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 2.7929999828338623 s\n",
      "Accuracy 0.9133235724743778 precision 0.9126420730531364 specificity 0.7539446989964698 recall 0.9133235724743778 f1 0.9089385857891302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 2.8119993209838867 s\n",
      "Accuracy 0.9244509516837481 precision 0.9243997768946525 specificity 0.7868589257709085 recall 0.9244509516837481 f1 0.9211465187822387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 2.89500093460083 s\n",
      "Accuracy 0.9136163982430454 precision 0.91304143909344 specificity 0.7670091718755392 recall 0.9136163982430454 f1 0.909617248647419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 2.863999366760254 s\n",
      "Accuracy 0.9159590043923865 precision 0.9158861102648886 specificity 0.776694862961045 recall 0.9159590043923865 f1 0.9121581922674094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 2.825000047683716 s\n",
      "Accuracy 0.9153733528550513 precision 0.9149447532250972 specificity 0.7641299803907824 recall 0.9153733528550513 f1 0.9112872968593679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 2.725998640060425 s\n",
      "Accuracy 0.9218155197657394 precision 0.9228456589831306 specificity 0.7752730988994306 recall 0.9218155197657394 f1 0.9178450767135133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 2.786999464035034 s\n",
      "Accuracy 0.91800878477306 precision 0.9170465731513405 specificity 0.7793235491212425 recall 0.91800878477306 f1 0.9146392739407201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 2.8380000591278076 s\n",
      "Accuracy 0.91800878477306 precision 0.9173678616914978 specificity 0.7706477309229127 recall 0.91800878477306 f1 0.9142662980929167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 2.875999689102173 s\n",
      "Accuracy 0.9203513909224011 precision 0.9207804129938159 specificity 0.772835871526096 recall 0.9203513909224011 f1 0.9164185918012453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 2.856997489929199 s\n",
      "Accuracy 0.9124450951683748 precision 0.9116330475092073 specificity 0.757217093826642 recall 0.9124450951683748 f1 0.9081825771717656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 2.8680002689361572 s\n",
      "Accuracy 0.9162518301610542 precision 0.9169128012598481 specificity 0.7606571511529904 recall 0.9162518301610542 f1 0.9117743594661497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 2.844999074935913 s\n",
      "Accuracy 0.9253294289897511 precision 0.925509769961 specificity 0.782736921376432 recall 0.9253294289897511 f1 0.9218758755409587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 2.8229994773864746 s\n",
      "Accuracy 0.9206442166910688 precision 0.9204298465575591 specificity 0.7836973876920525 recall 0.9206442166910688 f1 0.9172061907551587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 2.81600022315979 s\n",
      "Accuracy 0.9253294289897511 precision 0.9247158595207179 specificity 0.7862475266443674 recall 0.9253294289897511 f1 0.9222115205432542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 2.848999261856079 s\n",
      "Accuracy 0.9209370424597365 precision 0.9201234536144023 specificity 0.7993231409482396 recall 0.9209370424597365 f1 0.9181435427345149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 2.8400022983551025 s\n",
      "Accuracy 0.9159590043923865 precision 0.9155818144252695 specificity 0.7686883225656574 recall 0.9159590043923865 f1 0.9120120921919478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 2.80399751663208 s\n",
      "Accuracy 0.9115666178623719 precision 0.9113459768305625 specificity 0.7718027232880218 recall 0.9115666178623719 f1 0.9075498980431752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 2.7539970874786377 s\n",
      "Accuracy 0.9194729136163983 precision 0.9195594607293097 specificity 0.777898057313087 recall 0.9194729136163983 f1 0.9157525075228947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 2.8329999446868896 s\n",
      "Accuracy 0.9144948755490483 precision 0.9145670659752543 specificity 0.7625204540355797 recall 0.9144948755490483 f1 0.9101798367018237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 2.846998453140259 s\n",
      "Accuracy 0.9109809663250366 precision 0.9115190081025533 specificity 0.7538607202590059 recall 0.9109809663250366 f1 0.906150099878964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 2.8509979248046875 s\n",
      "Accuracy 0.9174231332357248 precision 0.9171049615597734 specificity 0.7813932673916798 recall 0.9174231332357248 f1 0.9138727135438548\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 2.859710693359375 s\n",
      "Accuracy 0.9162518301610542 precision 0.9162867891536055 specificity 0.7823505930778177 recall 0.9162518301610542 f1 0.9125941273829785\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 2.8217077255249023 s\n",
      "Accuracy 0.922108345534407 precision 0.9208751488231619 specificity 0.7938526737971345 recall 0.922108345534407 f1 0.9193699782049376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 2.774170160293579 s\n",
      "Accuracy 0.9112737920937043 precision 0.911352515124975 specificity 0.7567223102642547 recall 0.9112737920937043 f1 0.9066738946054677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 2.7999985218048096 s\n",
      "Accuracy 0.9200585651537335 precision 0.9197274070742035 specificity 0.7802314404355707 recall 0.9200585651537335 f1 0.9165452394197671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 2.846005439758301 s\n",
      "Accuracy 0.9133235724743778 precision 0.913379302468751 specificity 0.769685577771127 recall 0.9133235724743778 f1 0.909202300988913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 2.857998847961426 s\n",
      "Accuracy 0.9185944363103953 precision 0.9184444137344804 specificity 0.785460042830589 recall 0.9185944363103953 f1 0.9151366328311069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 2.833017110824585 s\n",
      "Accuracy 0.9142020497803807 precision 0.9141274256322899 specificity 0.784802615820811 recall 0.9142020497803807 f1 0.910604368652039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 2.7709879875183105 s\n",
      "Accuracy 0.9224011713030746 precision 0.9225969434556833 specificity 0.7832036126998854 recall 0.9224011713030746 f1 0.9188755001900237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 2.8134243488311768 s\n",
      "Accuracy 0.9197657393850659 precision 0.9196085522058979 specificity 0.7778255567799058 recall 0.9197657393850659 f1 0.916122787165902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 2.8869996070861816 s\n",
      "Accuracy 0.9203513909224011 precision 0.9196329639953442 specificity 0.776883884427473 recall 0.9203513909224011 f1 0.9168817854908342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 2.770000696182251 s\n",
      "Accuracy 0.9150805270863837 precision 0.9161385799859383 specificity 0.7653135267125781 recall 0.9150805270863837 f1 0.9106091903834871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 2.800999402999878 s\n",
      "Accuracy 0.9212298682284041 precision 0.9213451444760827 specificity 0.7784498637104226 recall 0.9212298682284041 f1 0.9175647779940074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 2.8799996376037598 s\n",
      "Accuracy 0.9203513909224011 precision 0.9194578687021526 specificity 0.7873308552942155 recall 0.9203513909224011 f1 0.917242442614301\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 2.8650012016296387 s\n",
      "Accuracy 0.922108345534407 precision 0.922094386846583 specificity 0.7907371492075009 recall 0.922108345534407 f1 0.9188381675637312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 2.8339991569519043 s\n",
      "Accuracy 0.9224011713030746 precision 0.9231622205126933 specificity 0.7719526106170453 recall 0.9224011713030746 f1 0.9184216850419006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 2.865999937057495 s\n",
      "Accuracy 0.9142020497803807 precision 0.9142077164188624 specificity 0.7585108984763409 recall 0.9142020497803807 f1 0.9097725902136152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 2.8989992141723633 s\n",
      "Accuracy 0.9185944363103953 precision 0.918876939705799 specificity 0.7819149036318148 recall 0.9185944363103953 f1 0.9149109464529712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 2.8470003604888916 s\n",
      "Accuracy 0.9115666178623719 precision 0.910548266324844 specificity 0.7737870351536653 recall 0.9115666178623719 f1 0.9078912592381678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 2.784999132156372 s\n",
      "Accuracy 0.9194729136163983 precision 0.9187612017747808 specificity 0.7615078030037313 recall 0.9194729136163983 f1 0.9155321832946638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 2.7779998779296875 s\n",
      "Accuracy 0.9121522693997072 precision 0.9119367958875155 specificity 0.7625476976076293 recall 0.9121522693997072 f1 0.9078546055620395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 2.9669995307922363 s\n",
      "Accuracy 0.9177159590043924 precision 0.9170671698792153 specificity 0.7875885047722881 recall 0.9177159590043924 f1 0.9144634640753522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 2.758999824523926 s\n",
      "Accuracy 0.9144948755490483 precision 0.9132484784793466 specificity 0.7688922212251452 recall 0.9144948755490483 f1 0.9108311456080161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 2.8219995498657227 s\n",
      "Accuracy 0.91303074670571 precision 0.9129453804140175 specificity 0.7629404713681016 recall 0.91303074670571 f1 0.9087315172840633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 2.833000659942627 s\n",
      "Accuracy 0.9115666178623719 precision 0.9101982335993956 specificity 0.7670068137962976 recall 0.9115666178623719 f1 0.9078156918184132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 2.8699984550476074 s\n",
      "Accuracy 0.9150805270863837 precision 0.9150069344407733 specificity 0.7684017864891421 recall 0.9150805270863837 f1 0.9110061952055001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 2.807997941970825 s\n",
      "Accuracy 0.9191800878477306 precision 0.9187462518497562 specificity 0.7879160964542438 recall 0.9191800878477306 f1 0.9158954513395097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 2.938999652862549 s\n",
      "Accuracy 0.91303074670571 precision 0.9114928679183396 specificity 0.7860102016929271 recall 0.91303074670571 f1 0.910018884571969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 2.823000907897949 s\n",
      "Accuracy 0.9156661786237189 precision 0.9148460069677673 specificity 0.7763929696791281 recall 0.9156661786237189 f1 0.9120963649801893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 2.8212573528289795 s\n",
      "Accuracy 0.9083455344070278 precision 0.9078940510910006 specificity 0.7500313058845408 recall 0.9083455344070278 f1 0.9035935687680176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 2.8209986686706543 s\n",
      "Accuracy 0.9162518301610542 precision 0.9167628333620998 specificity 0.7699277055140324 recall 0.9162518301610542 f1 0.9120930900308781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 2.86799955368042 s\n",
      "Accuracy 0.9162518301610542 precision 0.9156120113538703 specificity 0.7634944217568492 recall 0.9162518301610542 f1 0.9122431054234463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 2.8750007152557373 s\n",
      "Accuracy 0.9121522693997072 precision 0.912005471628928 specificity 0.7566545560026197 recall 0.9121522693997072 f1 0.9076446294457587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 2.777998208999634 s\n",
      "Accuracy 0.9183016105417277 precision 0.9182322787495946 specificity 0.779100360245462 recall 0.9183016105417277 f1 0.914630138287579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 2.838998556137085 s\n",
      "Accuracy 0.9156661786237189 precision 0.9151747739866622 specificity 0.7709363121629123 recall 0.9156661786237189 f1 0.9118163002819399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 2.8848912715911865 s\n",
      "Accuracy 0.9121522693997072 precision 0.9118116160700735 specificity 0.7773078678697629 recall 0.9121522693997072 f1 0.9083615167364085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 2.763000249862671 s\n",
      "Accuracy 0.9136163982430454 precision 0.9131414007076014 specificity 0.7630299297416104 recall 0.9136163982430454 f1 0.9094592555332073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 2.946998119354248 s\n",
      "Accuracy 0.9109809663250366 precision 0.9113287673341928 specificity 0.7653918864188014 recall 0.9109809663250366 f1 0.9065769860663543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 2.8370001316070557 s\n",
      "Accuracy 0.9200585651537335 precision 0.9193024302990855 specificity 0.7815971295137091 recall 0.9200585651537335 f1 0.9167284089730408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 2.8100028038024902 s\n",
      "Accuracy 0.9200585651537335 precision 0.9191206568946846 specificity 0.7809839538453069 recall 0.9200585651537335 f1 0.9167797129635888\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 2.906996250152588 s\n",
      "Accuracy 0.9147877013177159 precision 0.9149315354976043 specificity 0.7712547317430481 recall 0.9147877013177159 f1 0.9107288728104339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 2.871999740600586 s\n",
      "Accuracy 0.9191800878477306 precision 0.9187861420454767 specificity 0.7778370347339262 recall 0.9191800878477306 f1 0.915595882948346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 2.8309998512268066 s\n",
      "Accuracy 0.9185944363103953 precision 0.9178461363673847 specificity 0.7685839184304715 recall 0.9185944363103953 f1 0.9148459663058088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 2.8279995918273926 s\n",
      "Accuracy 0.9183016105417277 precision 0.9181655814899777 specificity 0.7763164700190289 recall 0.9183016105417277 f1 0.9145697394063336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 2.7710752487182617 s\n",
      "Accuracy 0.9133235724743778 precision 0.9128213424114731 specificity 0.768585794941373 recall 0.9133235724743778 f1 0.9093413921464162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 2.923001289367676 s\n",
      "Accuracy 0.9150805270863837 precision 0.915564182534206 specificity 0.7724852693688485 recall 0.9150805270863837 f1 0.9109735640379476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 2.870999574661255 s\n",
      "Accuracy 0.9191800878477306 precision 0.9191376737723834 specificity 0.784315089991657 recall 0.9191800878477306 f1 0.9156714469156331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 2.8569984436035156 s\n",
      "Accuracy 0.9144948755490483 precision 0.9144698302004363 specificity 0.7801710614949375 recall 0.9144948755490483 f1 0.9107487350035486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 2.719999074935913 s\n",
      "Accuracy 0.9215226939970718 precision 0.9203942951905877 specificity 0.781372789745397 recall 0.9215226939970718 f1 0.9183707491869054\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 2.807999610900879 s\n",
      "Accuracy 0.9150805270863837 precision 0.914902177181322 specificity 0.7685458104425744 recall 0.9150805270863837 f1 0.911042235246836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 2.7950003147125244 s\n",
      "Accuracy 0.9177159590043924 precision 0.9177311746950992 specificity 0.7615391903830822 recall 0.9177159590043924 f1 0.9134889697680546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 2.8570005893707275 s\n",
      "Accuracy 0.9276720351390922 precision 0.9277494145470143 specificity 0.7950455067076784 recall 0.9276720351390922 f1 0.9246206545440445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 2.8389992713928223 s\n",
      "Accuracy 0.909809663250366 precision 0.9095257892783043 specificity 0.7498696616441487 recall 0.909809663250366 f1 0.9050463156361724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 2.804854154586792 s\n",
      "Accuracy 0.9168374816983894 precision 0.9156396193801258 specificity 0.7845107316589738 recall 0.9168374816983894 f1 0.9136928502046121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 2.8030142784118652 s\n",
      "Accuracy 0.9188872620790629 precision 0.9180037358480055 specificity 0.7601537196540188 recall 0.9188872620790629 f1 0.9149482421151875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 2.8209376335144043 s\n",
      "Accuracy 0.9200585651537335 precision 0.9206325539901936 specificity 0.772421241958985 recall 0.9200585651537335 f1 0.9160675419994612\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 2.825982093811035 s\n",
      "Accuracy 0.9215226939970718 precision 0.9221302115882117 specificity 0.7711555559032492 recall 0.9215226939970718 f1 0.9175321037876744\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 2.8530006408691406 s\n",
      "Accuracy 0.9235724743777453 precision 0.9231419963888418 specificity 0.7742598343674806 recall 0.9235724743777453 f1 0.9200253751054542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 3.0985121726989746 s\n",
      "Accuracy 0.9095168374816984 precision 0.9083961739598864 specificity 0.7692561395115021 recall 0.9095168374816984 f1 0.9056844528893464\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 2.9950003623962402 s\n",
      "Accuracy 0.9297218155197657 precision 0.9295579407265805 specificity 0.8025313614108305 recall 0.9297218155197657 f1 0.926970514105809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 2.8008453845977783 s\n",
      "Accuracy 0.9206442166910688 precision 0.9209486029259015 specificity 0.7739867143586602 recall 0.9206442166910688 f1 0.9167857894687562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 2.8709685802459717 s\n",
      "Accuracy 0.91303074670571 precision 0.9130638041789858 specificity 0.7717039449523311 recall 0.91303074670571 f1 0.9089713101897827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 3.072000741958618 s\n",
      "Accuracy 0.9147877013177159 precision 0.9144279308558412 specificity 0.7601072336252989 recall 0.9147877013177159 f1 0.9105377435207535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 2.8689990043640137 s\n",
      "Accuracy 0.9168374816983894 precision 0.91715449099413 specificity 0.7648843465242104 recall 0.9168374816983894 f1 0.9125972754848032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 2.9529995918273926 s\n",
      "Accuracy 0.9144948755490483 precision 0.9143046446366417 specificity 0.7696642788894067 recall 0.9144948755490483 f1 0.9104782305568455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 2.7769992351531982 s\n",
      "Accuracy 0.9162518301610542 precision 0.9159748173981855 specificity 0.7739656650588311 recall 0.9162518301610542 f1 0.9124396517083928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 2.8330001831054688 s\n",
      "Accuracy 0.9235724743777453 precision 0.9233736241464993 specificity 0.7892949159974343 recall 0.9235724743777453 f1 0.9203540837781512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 2.832000732421875 s\n",
      "Accuracy 0.9177159590043924 precision 0.9174522489528288 specificity 0.7768395408503915 recall 0.9177159590043924 f1 0.9140229887495722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 2.951000213623047 s\n",
      "Accuracy 0.9174231332357248 precision 0.9161427483645067 specificity 0.7801266063954226 recall 0.9174231332357248 f1 0.9141969777905748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 2.715999126434326 s\n",
      "Accuracy 0.9171303074670571 precision 0.9162839825318111 specificity 0.7738434906983664 recall 0.9171303074670571 f1 0.9135314806722687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 2.9009993076324463 s\n",
      "Accuracy 0.9171303074670571 precision 0.9171266139852363 specificity 0.7719393247720306 recall 0.9171303074670571 f1 0.9131991009888769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 2.9210000038146973 s\n",
      "Accuracy 0.9226939970717423 precision 0.922291710984855 specificity 0.8002475667002713 recall 0.9226939970717423 f1 0.9198108294541063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 2.8390002250671387 s\n",
      "Accuracy 0.9188872620790629 precision 0.9185839803345341 specificity 0.7675748097632742 recall 0.9188872620790629 f1 0.9149701905661538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 2.807000160217285 s\n",
      "Accuracy 0.9197657393850659 precision 0.9195656521461854 specificity 0.7715291262201002 recall 0.9197657393850659 f1 0.9159569248394398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 2.8249998092651367 s\n",
      "Accuracy 0.9124450951683748 precision 0.9120773667854357 specificity 0.770031026754114 recall 0.9124450951683748 f1 0.9084411212639573\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 3.008000612258911 s\n",
      "Accuracy 0.9191800878477306 precision 0.9188692216237145 specificity 0.7930439850258834 recall 0.9191800878477306 f1 0.91599969800816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 2.818000555038452 s\n",
      "Accuracy 0.9127379209370424 precision 0.9133055654204761 specificity 0.7487524764861248 recall 0.9127379209370424 f1 0.9077928282155515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 2.8769989013671875 s\n",
      "Accuracy 0.9124450951683748 precision 0.9117666486948148 specificity 0.7730598574983695 recall 0.9124450951683748 f1 0.9086412753598613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 2.818000316619873 s\n",
      "Accuracy 0.9171303074670571 precision 0.9165426484150063 specificity 0.7806484828170848 recall 0.9171303074670571 f1 0.9136403609576219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 2.9819998741149902 s\n",
      "Accuracy 0.9197657393850659 precision 0.9185938882264518 specificity 0.7920395276679313 recall 0.9197657393850659 f1 0.9168958292189713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 2.8479995727539062 s\n",
      "Accuracy 0.9121522693997072 precision 0.9111070379840904 specificity 0.7716830141861999 recall 0.9121522693997072 f1 0.9084340369691519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 2.7899980545043945 s\n",
      "Accuracy 0.9030746705710102 precision 0.901784365089723 specificity 0.7385837187250707 recall 0.9030746705710102 f1 0.8980391662243622\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 2.8070011138916016 s\n",
      "Accuracy 0.9147877013177159 precision 0.9147924717558622 specificity 0.7785915637864109 recall 0.9147877013177159 f1 0.910991880632062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 2.8189995288848877 s\n",
      "Accuracy 0.9127379209370424 precision 0.9127107508284744 specificity 0.7638349652452603 recall 0.9127379209370424 f1 0.908441071101776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 2.865999221801758 s\n",
      "Accuracy 0.9209370424597365 precision 0.9205017903933618 specificity 0.7951641116340489 recall 0.9209370424597365 f1 0.9178924081596975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 2.777000904083252 s\n",
      "Accuracy 0.9206442166910688 precision 0.9217618168439118 specificity 0.7721328607541948 recall 0.9206442166910688 f1 0.9165298950036188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 2.9370007514953613 s\n",
      "Accuracy 0.9136163982430454 precision 0.9132160845973991 specificity 0.7846037173929898 recall 0.9136163982430454 f1 0.9101029296944263\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 2.837001085281372 s\n",
      "Accuracy 0.9185944363103953 precision 0.9188718045611659 specificity 0.7721814507178831 recall 0.9185944363103953 f1 0.9146323144093055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 2.7730002403259277 s\n",
      "Accuracy 0.9177159590043924 precision 0.917100302380695 specificity 0.7664823245983662 recall 0.9177159590043924 f1 0.9138331492412813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 2.805999279022217 s\n",
      "Accuracy 0.9183016105417277 precision 0.9173659101029588 specificity 0.7745984950237844 recall 0.9183016105417277 f1 0.9147904468113827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 2.8969993591308594 s\n",
      "Accuracy 0.9060029282576867 precision 0.9059352172120271 specificity 0.7651196494283584 recall 0.9060029282576867 f1 0.9015808465677725\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 2.7750003337860107 s\n",
      "Accuracy 0.9171303074670571 precision 0.9179394206726851 specificity 0.7770103266735772 recall 0.9171303074670571 f1 0.913130037223641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 2.9190011024475098 s\n",
      "Accuracy 0.9147877013177159 precision 0.9152062387070962 specificity 0.7730910695146799 recall 0.9147877013177159 f1 0.910708733698798\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 2.7739994525909424 s\n",
      "Accuracy 0.9168374816983894 precision 0.916343606914719 specificity 0.7717853075663877 recall 0.9168374816983894 f1 0.9130460497603503\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 2.921999931335449 s\n",
      "Accuracy 0.9159590043923865 precision 0.9154931388904091 specificity 0.7844186120878823 recall 0.9159590043923865 f1 0.9125118725489384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 2.9199986457824707 s\n",
      "Accuracy 0.9159590043923865 precision 0.9164357855473141 specificity 0.7567067864897231 recall 0.9159590043923865 f1 0.9113997918197582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 2.809000015258789 s\n",
      "Accuracy 0.9215226939970718 precision 0.9211165889794332 specificity 0.7834121143521997 recall 0.9215226939970718 f1 0.9181597857147423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 2.9659998416900635 s\n",
      "Accuracy 0.9124450951683748 precision 0.9118844719179374 specificity 0.7703112376199478 recall 0.9124450951683748 f1 0.9085136941064704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 2.905999183654785 s\n",
      "Accuracy 0.9159590043923865 precision 0.9155225159434333 specificity 0.7819281920406306 recall 0.9159590043923865 f1 0.9124281339265472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 3.0079996585845947 s\n",
      "Accuracy 0.9256222547584187 precision 0.9253834529447863 specificity 0.7926310796397922 recall 0.9256222547584187 f1 0.9225530664919036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 2.998999834060669 s\n",
      "Accuracy 0.91303074670571 precision 0.9137235749051341 specificity 0.7702726288660523 recall 0.91303074670571 f1 0.9087455589091934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 2.8159995079040527 s\n",
      "Accuracy 0.9212298682284041 precision 0.9221114654491394 specificity 0.776518036114034 recall 0.9212298682284041 f1 0.9173119679050817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 2.768000841140747 s\n",
      "Accuracy 0.9191800878477306 precision 0.9188929348882323 specificity 0.7823304011809865 recall 0.9191800878477306 f1 0.9156898231100282\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 2.747997999191284 s\n",
      "Accuracy 0.9191800878477306 precision 0.9186856064763632 specificity 0.7890951010052254 recall 0.9191800878477306 f1 0.915949097546305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 2.884000301361084 s\n",
      "Accuracy 0.909809663250366 precision 0.9094144812855048 specificity 0.7730407213568193 recall 0.909809663250366 f1 0.9058463053845035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 2.7579972743988037 s\n",
      "Accuracy 0.9200585651537335 precision 0.9198268432415369 specificity 0.7759712115212044 recall 0.9200585651537335 f1 0.9163939656471012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 2.797999858856201 s\n",
      "Accuracy 0.9168374816983894 precision 0.9151552031765962 specificity 0.7732561776683463 recall 0.9168374816983894 f1 0.9135821195284242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 2.8630001544952393 s\n",
      "Accuracy 0.9095168374816984 precision 0.9084585919518057 specificity 0.7553263627985967 recall 0.9095168374816984 f1 0.9051927795457921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 2.816997766494751 s\n",
      "Accuracy 0.9235724743777453 precision 0.9230403287275953 specificity 0.7905495516038633 recall 0.9235724743777453 f1 0.9204951644583648\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 2.916998863220215 s\n",
      "Accuracy 0.9168374816983894 precision 0.9165959700638905 specificity 0.7779625377038134 recall 0.9168374816983894 f1 0.9131479199757326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 2.9080007076263428 s\n",
      "Accuracy 0.9168374816983894 precision 0.9158191342490445 specificity 0.7693831093752407 recall 0.9168374816983894 f1 0.9131619229347521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 2.8470005989074707 s\n",
      "Accuracy 0.9218155197657394 precision 0.9222004104588747 specificity 0.7838159260073808 recall 0.9218155197657394 f1 0.9182400234614189\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 2.8629984855651855 s\n",
      "Accuracy 0.9171303074670571 precision 0.917117638187291 specificity 0.7759897991463028 recall 0.9171303074670571 f1 0.9133210751070283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 2.877999782562256 s\n",
      "Accuracy 0.9191800878477306 precision 0.9194431016288517 specificity 0.7696006906249041 recall 0.9191800878477306 f1 0.9151646913694862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 2.8760018348693848 s\n",
      "Accuracy 0.9174231332357248 precision 0.9159443640074262 specificity 0.7974978498022791 recall 0.9174231332357248 f1 0.9148296618858894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 2.9669995307922363 s\n",
      "Accuracy 0.9153733528550513 precision 0.9155434151968491 specificity 0.7660220538887857 recall 0.9153733528550513 f1 0.9111641588273925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 2.841999053955078 s\n",
      "Accuracy 0.9194729136163983 precision 0.9196557651864038 specificity 0.7773744120596232 recall 0.9194729136163983 f1 0.9157104690359624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 2.8469982147216797 s\n",
      "Accuracy 0.9171303074670571 precision 0.9165618366288872 specificity 0.7777134200282618 recall 0.9171303074670571 f1 0.9135473614646563\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 2.9599997997283936 s\n",
      "Accuracy 0.9183016105417277 precision 0.9178718511203646 specificity 0.7844166951513922 recall 0.9183016105417277 f1 0.9148957283434263\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 2.80199933052063 s\n",
      "Accuracy 0.9200585651537335 precision 0.9201782079471078 specificity 0.777550868873924 recall 0.9200585651537335 f1 0.9163348606333019\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 2.8620007038116455 s\n",
      "Accuracy 0.9080527086383602 precision 0.9078532287265698 specificity 0.7536330334056672 recall 0.9080527086383602 f1 0.9033345216380391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 3.0940001010894775 s\n",
      "Accuracy 0.91303074670571 precision 0.9132556510420882 specificity 0.7568094415816837 recall 0.91303074670571 f1 0.9084472567199171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 2.8899989128112793 s\n",
      "Accuracy 0.9224011713030746 precision 0.9226417274608544 specificity 0.7852477374676882 recall 0.9224011713030746 f1 0.9189184769346499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 2.9089999198913574 s\n",
      "Accuracy 0.9174231332357248 precision 0.9171879836963064 specificity 0.7725129728522802 recall 0.9174231332357248 f1 0.9135866240577087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 2.9449987411499023 s\n",
      "Accuracy 0.9185944363103953 precision 0.9188540033983607 specificity 0.7762528312841087 recall 0.9185944363103953 f1 0.914754743370354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 2.8419995307922363 s\n",
      "Accuracy 0.9136163982430454 precision 0.9148167952853413 specificity 0.7571543180690922 recall 0.9136163982430454 f1 0.9088098450389006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 2.8610010147094727 s\n",
      "Accuracy 0.9080527086383602 precision 0.9076103320232581 specificity 0.7569364380264393 recall 0.9080527086383602 f1 0.9035238685646693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 2.828998327255249 s\n",
      "Accuracy 0.9171303074670571 precision 0.9176296595274083 specificity 0.7690288703532107 recall 0.9171303074670571 f1 0.9129734070270147\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 2.8980000019073486 s\n",
      "Accuracy 0.91800878477306 precision 0.9193984347883319 specificity 0.7800731091240267 recall 0.91800878477306 f1 0.9139852254980495\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 3.0160017013549805 s\n",
      "Accuracy 0.9191800878477306 precision 0.9178832352996191 specificity 0.7790618240458533 recall 0.9191800878477306 f1 0.9159741515538731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 2.985999345779419 s\n",
      "Accuracy 0.9124450951683748 precision 0.9124955761041816 specificity 0.7654486245835805 recall 0.9124450951683748 f1 0.9081681302525798\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 3.004999876022339 s\n",
      "Accuracy 0.9194729136163983 precision 0.9194573690422799 specificity 0.7780750832352274 recall 0.9194729136163983 f1 0.9157870173358368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 2.88800048828125 s\n",
      "Accuracy 0.91800878477306 precision 0.9174095704150393 specificity 0.7762417783036395 recall 0.91800878477306 f1 0.9144159223739187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 2.872999429702759 s\n",
      "Accuracy 0.9153733528550513 precision 0.9147196645567701 specificity 0.7710112161624292 recall 0.9153733528550513 f1 0.9115728262821237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 2.872999668121338 s\n",
      "Accuracy 0.9133235724743778 precision 0.9141634807479067 specificity 0.767784027958108 recall 0.9133235724743778 f1 0.9089311278040533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 2.9559998512268066 s\n",
      "Accuracy 0.9153733528550513 precision 0.9157735791500841 specificity 0.7842434641308886 recall 0.9153733528550513 f1 0.9116495428451016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 2.7860045433044434 s\n",
      "Accuracy 0.9194729136163983 precision 0.9183820023445917 specificity 0.7824253699568484 recall 0.9194729136163983 f1 0.9162827474484873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 2.9799962043762207 s\n",
      "Accuracy 0.909809663250366 precision 0.909132668949603 specificity 0.751846342332306 recall 0.909809663250366 f1 0.9052407379877722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 2.862999677658081 s\n",
      "Accuracy 0.9200585651537335 precision 0.9203861647311268 specificity 0.7818703961587089 recall 0.9200585651537335 f1 0.9163988539954195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 2.7999989986419678 s\n",
      "Accuracy 0.91303074670571 precision 0.9129204079389385 specificity 0.7531323438406822 recall 0.91303074670571 f1 0.908427616204716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 2.797999620437622 s\n",
      "Accuracy 0.9203513909224011 precision 0.9200643653313164 specificity 0.7874928531927947 recall 0.9203513909224011 f1 0.9170343083553393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 2.8909988403320312 s\n",
      "Accuracy 0.9206442166910688 precision 0.9206615642095681 specificity 0.7759593871838106 recall 0.9206442166910688 f1 0.9169213704386421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 2.8460004329681396 s\n",
      "Accuracy 0.9124450951683748 precision 0.9120714186787714 specificity 0.7578621785742317 recall 0.9124450951683748 f1 0.9080559438238953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 2.823002338409424 s\n",
      "Accuracy 0.9235724743777453 precision 0.9242071875259995 specificity 0.7667775729259446 recall 0.9235724743777453 f1 0.9195211724351758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 2.8459978103637695 s\n",
      "Accuracy 0.926207906295754 precision 0.925386894988252 specificity 0.7951360200614069 recall 0.926207906295754 f1 0.9234183822773139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 2.837001085281372 s\n",
      "Accuracy 0.9194729136163983 precision 0.9189518051512101 specificity 0.7695854196675151 recall 0.9194729136163983 f1 0.9157018073982544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 2.9019994735717773 s\n",
      "Accuracy 0.9226939970717423 precision 0.922883205877999 specificity 0.7938137896200934 recall 0.9226939970717423 f1 0.9194620453549297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 2.869999408721924 s\n",
      "Accuracy 0.9118594436310395 precision 0.911179571382204 specificity 0.7598421810502939 recall 0.9118594436310395 f1 0.9076177488660863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 2.8399994373321533 s\n",
      "Accuracy 0.91800878477306 precision 0.9183364919000573 specificity 0.7713318665553652 recall 0.91800878477306 f1 0.9139912910883471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 2.9140007495880127 s\n",
      "Accuracy 0.9171303074670571 precision 0.9173772731990955 specificity 0.7777493527500264 recall 0.9171303074670571 f1 0.9132987177382024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 2.8459975719451904 s\n",
      "Accuracy 0.9212298682284041 precision 0.9204283581940604 specificity 0.7944912325764668 recall 0.9212298682284041 f1 0.9183042942136886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 2.772998571395874 s\n",
      "Accuracy 0.9153733528550513 precision 0.9152849886159841 specificity 0.7734231583812609 recall 0.9153733528550513 f1 0.9114638205290626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 2.90200138092041 s\n",
      "Accuracy 0.91800878477306 precision 0.9177507128158352 specificity 0.7824288222787844 recall 0.91800878477306 f1 0.9144835453626928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 2.8909966945648193 s\n",
      "Accuracy 0.9168374816983894 precision 0.916792822362354 specificity 0.7776318436730472 recall 0.9168374816983894 f1 0.9130783990690379\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 3.0689990520477295 s\n",
      "Accuracy 0.9241581259150805 precision 0.9250253388420194 specificity 0.7933544451643876 recall 0.9241581259150805 f1 0.920776364018199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 2.8519997596740723 s\n",
      "Accuracy 0.9177159590043924 precision 0.9177150688063368 specificity 0.7834797379540163 recall 0.9177159590043924 f1 0.9141361689881531\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 2.885998487472534 s\n",
      "Accuracy 0.9171303074670571 precision 0.9172949122555383 specificity 0.75490830331953 recall 0.9171303074670571 f1 0.9126424044091885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 2.800999641418457 s\n",
      "Accuracy 0.9144948755490483 precision 0.9140524615351054 specificity 0.7639497966673827 recall 0.9144948755490483 f1 0.9103816540910704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 2.9170010089874268 s\n",
      "Accuracy 0.9232796486090776 precision 0.9227678725790115 specificity 0.7862846295016092 recall 0.9232796486090776 f1 0.9200745122616919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 2.8640003204345703 s\n",
      "Accuracy 0.9197657393850659 precision 0.9191773340788536 specificity 0.7838364305968509 recall 0.9197657393850659 f1 0.9164319579177405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 2.8909988403320312 s\n",
      "Accuracy 0.9226939970717423 precision 0.9227577344412428 specificity 0.7736820617502769 recall 0.9226939970717423 f1 0.9189549721910336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 2.8540000915527344 s\n",
      "Accuracy 0.9212298682284041 precision 0.9208834793234779 specificity 0.7965051751106487 recall 0.9212298682284041 f1 0.9181985100237315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 2.7820024490356445 s\n",
      "Accuracy 0.9147877013177159 precision 0.9142171339650936 specificity 0.7756144854246828 recall 0.9147877013177159 f1 0.9110836808718467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 2.9880008697509766 s\n",
      "Accuracy 0.9159590043923865 precision 0.9171395301558966 specificity 0.7859906172889249 recall 0.9159590043923865 f1 0.9121065827532147\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 2.7699978351593018 s\n",
      "Accuracy 0.9247437774524158 precision 0.9253895475484769 specificity 0.7860166094898239 recall 0.9247437774524158 f1 0.9212383120247568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 2.7449965476989746 s\n",
      "Accuracy 0.9168374816983894 precision 0.9165177605060861 specificity 0.7827118340165704 recall 0.9168374816983894 f1 0.9133121809461714\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 2.8309993743896484 s\n",
      "Accuracy 0.9153733528550513 precision 0.9151569262740282 specificity 0.7725171448669859 recall 0.9153733528550513 f1 0.9114754321164604\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 2.8519983291625977 s\n",
      "Accuracy 0.9200585651537335 precision 0.9208584023978691 specificity 0.7825472094859395 recall 0.9200585651537335 f1 0.9162968485650088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 2.8179991245269775 s\n",
      "Accuracy 0.9188872620790629 precision 0.9186776970611056 specificity 0.7801587863626374 recall 0.9188872620790629 f1 0.9153035947681435\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 2.871000051498413 s\n",
      "Accuracy 0.9162518301610542 precision 0.9159864585567234 specificity 0.7660379562189743 recall 0.9162518301610542 f1 0.9121981588583638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 2.8660011291503906 s\n",
      "Accuracy 0.9206442166910688 precision 0.9204766792272425 specificity 0.7814461992221319 recall 0.9206442166910688 f1 0.9171292854005515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 2.8049988746643066 s\n",
      "Accuracy 0.9191800878477306 precision 0.9188168962301755 specificity 0.7870620553539314 recall 0.9191800878477306 f1 0.9158481636889289\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 2.7839999198913574 s\n",
      "Accuracy 0.9144948755490483 precision 0.9142397005082789 specificity 0.7671316018926184 recall 0.9144948755490483 f1 0.9104204087499284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 2.796999454498291 s\n",
      "Accuracy 0.9291361639824305 precision 0.9287808955638829 specificity 0.7988307594940409 recall 0.9291361639824305 f1 0.9263425284206525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 2.8219988346099854 s\n",
      "Accuracy 0.9162518301610542 precision 0.9162526287734116 specificity 0.7724328305389624 recall 0.9162518301610542 f1 0.912309691079325\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 2.9929983615875244 s\n",
      "Accuracy 0.9183016105417277 precision 0.9174618389170772 specificity 0.7712915853733769 recall 0.9183016105417277 f1 0.9146571680265696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 2.8570005893707275 s\n",
      "Accuracy 0.9142020497803807 precision 0.915027655231264 specificity 0.766852041107349 recall 0.9142020497803807 f1 0.9098093675803447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 2.991999387741089 s\n",
      "Accuracy 0.909809663250366 precision 0.9109556293991952 specificity 0.7501832579388742 recall 0.909809663250366 f1 0.904661838495735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 2.8459999561309814 s\n",
      "Accuracy 0.9185944363103953 precision 0.9179827450587552 specificity 0.7818575544593357 recall 0.9185944363103953 f1 0.9151836514090513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 2.8389992713928223 s\n",
      "Accuracy 0.91800878477306 precision 0.9176834268334215 specificity 0.7836173001294232 recall 0.91800878477306 f1 0.9145391090942088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 2.90199875831604 s\n",
      "Accuracy 0.9209370424597365 precision 0.9194613340718795 specificity 0.7852579621449354 recall 0.9209370424597365 f1 0.9180466382676742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 2.768000364303589 s\n",
      "Accuracy 0.9147877013177159 precision 0.9150998026564868 specificity 0.7688470747358183 recall 0.9147877013177159 f1 0.910608201074852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 2.837000846862793 s\n",
      "Accuracy 0.9057101024890191 precision 0.905533272382515 specificity 0.7485104911779413 recall 0.9057101024890191 f1 0.9007352459609197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 2.8249988555908203 s\n",
      "Accuracy 0.9127379209370424 precision 0.9123816937981134 specificity 0.7638460544450292 recall 0.9127379209370424 f1 0.9085426269213914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 2.994999647140503 s\n",
      "Accuracy 0.9136163982430454 precision 0.9153964932328679 specificity 0.7635925716488514 recall 0.9136163982430454 f1 0.9088802724925457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 2.9510011672973633 s\n",
      "Accuracy 0.9191800878477306 precision 0.9187211658295316 specificity 0.7830557956553135 recall 0.9191800878477306 f1 0.915765979480714\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 2.794999361038208 s\n",
      "Accuracy 0.9153733528550513 precision 0.914670316328088 specificity 0.7613941898794244 recall 0.9153733528550513 f1 0.9112950674969676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 2.856998920440674 s\n",
      "Accuracy 0.92298682284041 precision 0.9242610438854989 specificity 0.7822636072658918 recall 0.92298682284041 f1 0.9191863212247405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 2.714998722076416 s\n",
      "Accuracy 0.9197657393850659 precision 0.9193336590989778 specificity 0.7746363888511457 recall 0.9197657393850659 f1 0.9161185529711537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 2.7370007038116455 s\n",
      "Accuracy 0.9142020497803807 precision 0.9133883554111059 specificity 0.763934777910075 recall 0.9142020497803807 f1 0.9102065473802549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 3.0359995365142822 s\n",
      "Accuracy 0.9232796486090776 precision 0.9229443129469096 specificity 0.7942425148131523 recall 0.9232796486090776 f1 0.920228010137157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 2.896000623703003 s\n",
      "Accuracy 0.9224011713030746 precision 0.9217353979918516 specificity 0.8014797793852977 recall 0.9224011713030746 f1 0.9196375826389154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 2.857998847961426 s\n",
      "Accuracy 0.9226939970717423 precision 0.9224526776899842 specificity 0.7788465637833138 recall 0.9226939970717423 f1 0.9191856592179343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 2.7959988117218018 s\n",
      "Accuracy 0.9165446559297218 precision 0.9166634774837096 specificity 0.7649370511868742 recall 0.9165446559297218 f1 0.9123523891295923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 2.8559999465942383 s\n",
      "Accuracy 0.9147877013177159 precision 0.9135779169234277 specificity 0.7743866950398438 recall 0.9147877013177159 f1 0.9112885315853523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 2.889998435974121 s\n",
      "Accuracy 0.9212298682284041 precision 0.921491705752452 specificity 0.7849860714208189 recall 0.9212298682284041 f1 0.9177043622063926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 2.7259998321533203 s\n",
      "Accuracy 0.9200585651537335 precision 0.9184755738558549 specificity 0.7883491065679437 recall 0.9200585651537335 f1 0.9172997286186761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 2.7869985103607178 s\n",
      "Accuracy 0.9142020497803807 precision 0.9129076692013413 specificity 0.7722481111225016 recall 0.9142020497803807 f1 0.910657128697531\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 2.934000253677368 s\n",
      "Accuracy 0.9118594436310395 precision 0.9108972507607561 specificity 0.7672020292528556 recall 0.9118594436310395 f1 0.9079573295477663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 2.8129985332489014 s\n",
      "Accuracy 0.9118594436310395 precision 0.9120447937753107 specificity 0.7634614624567378 recall 0.9118594436310395 f1 0.9074637011783162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 2.8169989585876465 s\n",
      "Accuracy 0.9177159590043924 precision 0.9165133731152799 specificity 0.7812512395167263 recall 0.9177159590043924 f1 0.9144960588226424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 2.850998640060425 s\n",
      "Accuracy 0.9142020497803807 precision 0.9139150687798399 specificity 0.7841489451746333 recall 0.9142020497803807 f1 0.9106503312885088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 2.945000410079956 s\n",
      "Accuracy 0.9183016105417277 precision 0.9182661677920888 specificity 0.7761450970793841 recall 0.9183016105417277 f1 0.9145347948739184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 2.760000228881836 s\n",
      "Accuracy 0.9194729136163983 precision 0.9191903149923671 specificity 0.7878089043500007 recall 0.9194729136163983 f1 0.9161429419406745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 2.7859995365142822 s\n",
      "Accuracy 0.9212298682284041 precision 0.9212089911550454 specificity 0.78623411854406 recall 0.9212298682284041 f1 0.9178183058360292\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 3.0100014209747314 s\n",
      "Accuracy 0.922108345534407 precision 0.9212016788323666 specificity 0.7864130922272314 recall 0.922108345534407 f1 0.9190211511782737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 2.879999876022339 s\n",
      "Accuracy 0.9150805270863837 precision 0.913802134006817 specificity 0.7814723559132802 recall 0.9150805270863837 f1 0.9118392631909679\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, seed in enumerate(seeds):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101,n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.919766     0.787821   0.919016  0.919766  0.916602\n1  0.920059     0.772536   0.919646  0.920059  0.916354\n2  0.925915     0.777451   0.926367  0.925915  0.922270\n3  0.914788     0.752802   0.914817  0.914788  0.910192\n4  0.922108     0.784577   0.921580  0.922108  0.918833\n5  0.919473     0.783409   0.918814  0.919473  0.916144\n6  0.916545     0.770526   0.916465  0.916545  0.912578\n7  0.912152     0.765500   0.911696  0.912152  0.908026\n8  0.919766     0.780988   0.918401  0.919766  0.916664\n9  0.918594     0.787250   0.917694  0.918594  0.915446",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.919766</td>\n      <td>0.787821</td>\n      <td>0.919016</td>\n      <td>0.919766</td>\n      <td>0.916602</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.920059</td>\n      <td>0.772536</td>\n      <td>0.919646</td>\n      <td>0.920059</td>\n      <td>0.916354</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.925915</td>\n      <td>0.777451</td>\n      <td>0.926367</td>\n      <td>0.925915</td>\n      <td>0.922270</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.914788</td>\n      <td>0.752802</td>\n      <td>0.914817</td>\n      <td>0.914788</td>\n      <td>0.910192</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.922108</td>\n      <td>0.784577</td>\n      <td>0.921580</td>\n      <td>0.922108</td>\n      <td>0.918833</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.919473</td>\n      <td>0.783409</td>\n      <td>0.918814</td>\n      <td>0.919473</td>\n      <td>0.916144</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.916545</td>\n      <td>0.770526</td>\n      <td>0.916465</td>\n      <td>0.916545</td>\n      <td>0.912578</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.912152</td>\n      <td>0.765500</td>\n      <td>0.911696</td>\n      <td>0.912152</td>\n      <td>0.908026</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.919766</td>\n      <td>0.780988</td>\n      <td>0.918401</td>\n      <td>0.919766</td>\n      <td>0.916664</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.918594</td>\n      <td>0.787250</td>\n      <td>0.917694</td>\n      <td>0.918594</td>\n      <td>0.915446</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.9169850658857979\n",
      "Precision 0.9167239302378036\n",
      "Specificity 0.7750367006162729\n",
      "Recall 0.9169850658857979\n",
      "F1 0.9132225075723633\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_32beats_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}