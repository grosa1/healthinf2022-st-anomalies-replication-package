{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Paper CHF - 32 beats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sU5Wt4HhzLod"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id        dw_1        dw_2        dw_3       dw_4      dw_5     mfw_1  \\\n0  e0106  133.429003  134.242162  133.489322  37.853305  5.508392  0.586324   \n1  e0106  133.965830  136.903950  136.743215  38.927755  5.696305  0.593533   \n2  e0106  139.274723  140.184030  140.070259  39.704137  5.761162  0.577124   \n3  e0106  138.676856  143.380168  143.473350  40.663806  5.859970  0.588245   \n4  e0106  140.755171  142.872499  143.424214  40.769824  5.919625  0.585157   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.522381 -0.788889 -0.136987  ... -0.042238  0.026644 -0.034630  0.040781   \n1 -0.515953 -0.790798 -0.224475  ... -0.052676  0.042240 -0.050718  0.057318   \n2 -0.518431 -0.807961 -0.219536  ... -0.051818  0.032123 -0.034994  0.042277   \n3 -0.513443 -0.810437 -0.247007  ... -0.057101  0.036792 -0.033449  0.035388   \n4 -0.517127 -0.798512 -0.176490  ... -0.031786  0.019955 -0.031716  0.039832   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.065560  0.001347 -0.022417 -0.007807 -0.008983    NSR  \n1 -0.078975  0.010010 -0.026053 -0.011060 -0.004790    NSR  \n2 -0.076328  0.011880 -0.026580 -0.008271 -0.005162    NSR  \n3 -0.067010  0.008826 -0.025932 -0.011778 -0.000208    NSR  \n4 -0.068147  0.004500 -0.023807 -0.012157 -0.002940    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>133.429003</td>\n      <td>134.242162</td>\n      <td>133.489322</td>\n      <td>37.853305</td>\n      <td>5.508392</td>\n      <td>0.586324</td>\n      <td>-0.522381</td>\n      <td>-0.788889</td>\n      <td>-0.136987</td>\n      <td>...</td>\n      <td>-0.042238</td>\n      <td>0.026644</td>\n      <td>-0.034630</td>\n      <td>0.040781</td>\n      <td>-0.065560</td>\n      <td>0.001347</td>\n      <td>-0.022417</td>\n      <td>-0.007807</td>\n      <td>-0.008983</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>133.965830</td>\n      <td>136.903950</td>\n      <td>136.743215</td>\n      <td>38.927755</td>\n      <td>5.696305</td>\n      <td>0.593533</td>\n      <td>-0.515953</td>\n      <td>-0.790798</td>\n      <td>-0.224475</td>\n      <td>...</td>\n      <td>-0.052676</td>\n      <td>0.042240</td>\n      <td>-0.050718</td>\n      <td>0.057318</td>\n      <td>-0.078975</td>\n      <td>0.010010</td>\n      <td>-0.026053</td>\n      <td>-0.011060</td>\n      <td>-0.004790</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>139.274723</td>\n      <td>140.184030</td>\n      <td>140.070259</td>\n      <td>39.704137</td>\n      <td>5.761162</td>\n      <td>0.577124</td>\n      <td>-0.518431</td>\n      <td>-0.807961</td>\n      <td>-0.219536</td>\n      <td>...</td>\n      <td>-0.051818</td>\n      <td>0.032123</td>\n      <td>-0.034994</td>\n      <td>0.042277</td>\n      <td>-0.076328</td>\n      <td>0.011880</td>\n      <td>-0.026580</td>\n      <td>-0.008271</td>\n      <td>-0.005162</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>138.676856</td>\n      <td>143.380168</td>\n      <td>143.473350</td>\n      <td>40.663806</td>\n      <td>5.859970</td>\n      <td>0.588245</td>\n      <td>-0.513443</td>\n      <td>-0.810437</td>\n      <td>-0.247007</td>\n      <td>...</td>\n      <td>-0.057101</td>\n      <td>0.036792</td>\n      <td>-0.033449</td>\n      <td>0.035388</td>\n      <td>-0.067010</td>\n      <td>0.008826</td>\n      <td>-0.025932</td>\n      <td>-0.011778</td>\n      <td>-0.000208</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>140.755171</td>\n      <td>142.872499</td>\n      <td>143.424214</td>\n      <td>40.769824</td>\n      <td>5.919625</td>\n      <td>0.585157</td>\n      <td>-0.517127</td>\n      <td>-0.798512</td>\n      <td>-0.176490</td>\n      <td>...</td>\n      <td>-0.031786</td>\n      <td>0.019955</td>\n      <td>-0.031716</td>\n      <td>0.039832</td>\n      <td>-0.068147</td>\n      <td>0.004500</td>\n      <td>-0.023807</td>\n      <td>-0.012157</td>\n      <td>-0.002940</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_32beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    13090\nST      3982\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.237685  0.106778  0.074513  0.049017  0.164754 -0.043134   \ndw_2    0.237685  1.000000  0.838142  0.502265  0.189472  0.396750 -0.511218   \ndw_3    0.106778  0.838142  1.000000  0.702042  0.287089  0.241283 -0.555562   \ndw_4    0.074513  0.502265  0.702042  1.000000  0.873295 -0.014716 -0.278260   \ndw_5    0.049017  0.189472  0.287089  0.873295  1.000000 -0.124955 -0.026226   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.074357  0.037079  0.066460  0.051749  0.016077 -0.150115  0.112145   \ncfr_13 -0.049488  0.134331  0.043879  0.026810  0.019832  0.073383 -0.006052   \ncfr_14 -0.067248  0.012952 -0.017784 -0.031360 -0.039655 -0.001977  0.028472   \ncfr_15 -0.103371 -0.116243 -0.133008 -0.111832 -0.062702  0.047377  0.081087   \ncfr_16 -0.094220 -0.070422 -0.045069 -0.044385 -0.031614  0.064713 -0.029821   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.066522 -0.005085  0.007374  ... -0.101746 -0.045780 -0.057627   \ndw_2   -0.362148  0.007304  0.027974  ... -0.110800  0.180227  0.237271   \ndw_3   -0.499643  0.012774  0.016280  ... -0.199872  0.154880  0.275167   \ndw_4   -0.278962  0.008457  0.006416  ... -0.152384  0.071768  0.115122   \ndw_5   -0.049222  0.001954  0.000388  ... -0.063773  0.011881 -0.006932   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.135231 -0.002228  0.004135  ... -0.135005 -0.212171 -0.056621   \ncfr_13  0.015178  0.006819 -0.001301  ...  0.163738  0.044522 -0.209958   \ncfr_14  0.029755  0.005549 -0.006743  ...  0.121685  0.230485  0.039279   \ncfr_15  0.044183  0.001850 -0.014418  ...  0.293341  0.157001 -0.089191   \ncfr_16 -0.008364  0.011768 -0.004271  ...  0.268445  0.129772  0.199429   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.042941 -0.032342 -0.074357 -0.049488 -0.067248 -0.103371 -0.094220  \ndw_2    0.173162  0.054253  0.037079  0.134331  0.012952 -0.116243 -0.070422  \ndw_3    0.120954 -0.052022  0.066460  0.043879 -0.017784 -0.133008 -0.045069  \ndw_4    0.067878 -0.039769  0.051749  0.026810 -0.031360 -0.111832 -0.044385  \ndw_5    0.044290  0.004779  0.016077  0.019832 -0.039655 -0.062702 -0.031614  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.041745  0.071561  1.000000  0.024910  0.010580 -0.361983 -0.228896  \ncfr_13 -0.266707  0.009957  0.024910  1.000000  0.238508  0.156749 -0.141656  \ncfr_14 -0.173963 -0.282881  0.010580  0.238508  1.000000  0.221302 -0.128261  \ncfr_15 -0.138736 -0.062263 -0.361983  0.156749  0.221302  1.000000  0.344573  \ncfr_16  0.174509  0.012025 -0.228896 -0.141656 -0.128261  0.344573  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.237685</td>\n      <td>0.106778</td>\n      <td>0.074513</td>\n      <td>0.049017</td>\n      <td>0.164754</td>\n      <td>-0.043134</td>\n      <td>0.066522</td>\n      <td>-0.005085</td>\n      <td>0.007374</td>\n      <td>...</td>\n      <td>-0.101746</td>\n      <td>-0.045780</td>\n      <td>-0.057627</td>\n      <td>-0.042941</td>\n      <td>-0.032342</td>\n      <td>-0.074357</td>\n      <td>-0.049488</td>\n      <td>-0.067248</td>\n      <td>-0.103371</td>\n      <td>-0.094220</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.237685</td>\n      <td>1.000000</td>\n      <td>0.838142</td>\n      <td>0.502265</td>\n      <td>0.189472</td>\n      <td>0.396750</td>\n      <td>-0.511218</td>\n      <td>-0.362148</td>\n      <td>0.007304</td>\n      <td>0.027974</td>\n      <td>...</td>\n      <td>-0.110800</td>\n      <td>0.180227</td>\n      <td>0.237271</td>\n      <td>0.173162</td>\n      <td>0.054253</td>\n      <td>0.037079</td>\n      <td>0.134331</td>\n      <td>0.012952</td>\n      <td>-0.116243</td>\n      <td>-0.070422</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.106778</td>\n      <td>0.838142</td>\n      <td>1.000000</td>\n      <td>0.702042</td>\n      <td>0.287089</td>\n      <td>0.241283</td>\n      <td>-0.555562</td>\n      <td>-0.499643</td>\n      <td>0.012774</td>\n      <td>0.016280</td>\n      <td>...</td>\n      <td>-0.199872</td>\n      <td>0.154880</td>\n      <td>0.275167</td>\n      <td>0.120954</td>\n      <td>-0.052022</td>\n      <td>0.066460</td>\n      <td>0.043879</td>\n      <td>-0.017784</td>\n      <td>-0.133008</td>\n      <td>-0.045069</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.074513</td>\n      <td>0.502265</td>\n      <td>0.702042</td>\n      <td>1.000000</td>\n      <td>0.873295</td>\n      <td>-0.014716</td>\n      <td>-0.278260</td>\n      <td>-0.278962</td>\n      <td>0.008457</td>\n      <td>0.006416</td>\n      <td>...</td>\n      <td>-0.152384</td>\n      <td>0.071768</td>\n      <td>0.115122</td>\n      <td>0.067878</td>\n      <td>-0.039769</td>\n      <td>0.051749</td>\n      <td>0.026810</td>\n      <td>-0.031360</td>\n      <td>-0.111832</td>\n      <td>-0.044385</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.049017</td>\n      <td>0.189472</td>\n      <td>0.287089</td>\n      <td>0.873295</td>\n      <td>1.000000</td>\n      <td>-0.124955</td>\n      <td>-0.026226</td>\n      <td>-0.049222</td>\n      <td>0.001954</td>\n      <td>0.000388</td>\n      <td>...</td>\n      <td>-0.063773</td>\n      <td>0.011881</td>\n      <td>-0.006932</td>\n      <td>0.044290</td>\n      <td>0.004779</td>\n      <td>0.016077</td>\n      <td>0.019832</td>\n      <td>-0.039655</td>\n      <td>-0.062702</td>\n      <td>-0.031614</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.074357</td>\n      <td>0.037079</td>\n      <td>0.066460</td>\n      <td>0.051749</td>\n      <td>0.016077</td>\n      <td>-0.150115</td>\n      <td>0.112145</td>\n      <td>0.135231</td>\n      <td>-0.002228</td>\n      <td>0.004135</td>\n      <td>...</td>\n      <td>-0.135005</td>\n      <td>-0.212171</td>\n      <td>-0.056621</td>\n      <td>0.041745</td>\n      <td>0.071561</td>\n      <td>1.000000</td>\n      <td>0.024910</td>\n      <td>0.010580</td>\n      <td>-0.361983</td>\n      <td>-0.228896</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.049488</td>\n      <td>0.134331</td>\n      <td>0.043879</td>\n      <td>0.026810</td>\n      <td>0.019832</td>\n      <td>0.073383</td>\n      <td>-0.006052</td>\n      <td>0.015178</td>\n      <td>0.006819</td>\n      <td>-0.001301</td>\n      <td>...</td>\n      <td>0.163738</td>\n      <td>0.044522</td>\n      <td>-0.209958</td>\n      <td>-0.266707</td>\n      <td>0.009957</td>\n      <td>0.024910</td>\n      <td>1.000000</td>\n      <td>0.238508</td>\n      <td>0.156749</td>\n      <td>-0.141656</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.067248</td>\n      <td>0.012952</td>\n      <td>-0.017784</td>\n      <td>-0.031360</td>\n      <td>-0.039655</td>\n      <td>-0.001977</td>\n      <td>0.028472</td>\n      <td>0.029755</td>\n      <td>0.005549</td>\n      <td>-0.006743</td>\n      <td>...</td>\n      <td>0.121685</td>\n      <td>0.230485</td>\n      <td>0.039279</td>\n      <td>-0.173963</td>\n      <td>-0.282881</td>\n      <td>0.010580</td>\n      <td>0.238508</td>\n      <td>1.000000</td>\n      <td>0.221302</td>\n      <td>-0.128261</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.103371</td>\n      <td>-0.116243</td>\n      <td>-0.133008</td>\n      <td>-0.111832</td>\n      <td>-0.062702</td>\n      <td>0.047377</td>\n      <td>0.081087</td>\n      <td>0.044183</td>\n      <td>0.001850</td>\n      <td>-0.014418</td>\n      <td>...</td>\n      <td>0.293341</td>\n      <td>0.157001</td>\n      <td>-0.089191</td>\n      <td>-0.138736</td>\n      <td>-0.062263</td>\n      <td>-0.361983</td>\n      <td>0.156749</td>\n      <td>0.221302</td>\n      <td>1.000000</td>\n      <td>0.344573</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.094220</td>\n      <td>-0.070422</td>\n      <td>-0.045069</td>\n      <td>-0.044385</td>\n      <td>-0.031614</td>\n      <td>0.064713</td>\n      <td>-0.029821</td>\n      <td>-0.008364</td>\n      <td>0.011768</td>\n      <td>-0.004271</td>\n      <td>...</td>\n      <td>0.268445</td>\n      <td>0.129772</td>\n      <td>0.199429</td>\n      <td>0.174509</td>\n      <td>0.012025</td>\n      <td>-0.228896</td>\n      <td>-0.141656</td>\n      <td>-0.128261</td>\n      <td>0.344573</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows Ã— 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()\n",
    "patient_ids = data[\"id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mfw_14', 'fft_164', 'fft_170', 'fft_197', 'fft_242', 'fft_253', 'fft_240', 'fft_146', 'fft_241', 'fft_194', 'fft_212', 'fft_187', 'fft_130', 'fft_249', 'fft_200', 'fft_172', 'mfw_12', 'fft_228', 'fft_137', 'fft_155', 'fft_175', 'fft_203', 'fft_227', 'mfw_10', 'fft_159', 'fft_207', 'fft_134', 'fft_173', 'fft_219', 'fft_248', 'fft_185', 'fft_250', 'fft_247', 'fft_153', 'fft_178', 'fft_229', 'fft_148', 'fft_183', 'fft_236', 'fft_154', 'fft_238', 'fft_256', 'fft_246', 'fft_158', 'fft_191', 'fft_149', 'fft_217', 'fft_150', 'fft_132', 'fft_161', 'fft_171', 'fft_169', 'fft_135', 'fft_254', 'fft_165', 'fft_174', 'fft_141', 'fft_166', 'fft_186', 'mfw_6', 'fft_226', 'fft_220', 'fft_143', 'fft_202', 'fft_139', 'fft_230', 'fft_243', 'fft_142', 'fft_160', 'fft_190', 'mfw_5', 'fft_179', 'fft_145', 'fft_151', 'fft_198', 'fft_221', 'fft_136', 'fft_205', 'fft_209', 'fft_140', 'fft_152', 'fft_196', 'fft_163', 'fft_181', 'fft_208', 'fft_233', 'fft_237', 'fft_251', 'fft_167', 'fft_157', 'fft_138', 'fft_177', 'fft_144', 'mfw_15', 'fft_156', 'fft_201', 'fft_225', 'fft_252', 'fft_206', 'fft_211', 'fft_192', 'fft_223', 'fft_195', 'fft_239', 'fft_215', 'fft_168', 'fft_234', 'fft_245', 'cfr_16', 'fft_189', 'fft_204', 'fft_184', 'fft_131', 'fft_193', 'fft_210', 'mfw_7', 'mfw_8', 'fft_176', 'fft_222', 'mfw_13', 'fft_231', 'fft_214', 'mfw_16', 'mfw_11', 'fft_232', 'fft_213', 'fft_244', 'fft_218', 'mfw_9', 'fft_147', 'fft_133', 'fft_255', 'fft_224', 'fft_199', 'fft_182', 'fft_162', 'fft_235', 'fft_188', 'fft_180', 'fft_216'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_25\n",
      "fft_26\n",
      "fft_29\n",
      "fft_30\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "fft_37\n",
      "fft_38\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_13\n",
      "ar_14\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 75\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization best features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAY50lEQVR4nO3debQedZ3n8ffHsAXZpiEz2mwBwXYAl5aI2opLuzSOo8EWBNpR9NDS2tLqeHBE7UZkdAa0laMNnpYWWkRHEFwmanpoBQVXTNgJGA0YhyCtbINEZAl854+qyMNN3aRyc+veS/J+nXNPavlV1fc+z83zeWr7VaoKSZLGesx0FyBJmpkMCElSJwNCktTJgJAkdTIgJEmdDAhJUqfNhlx5koOAjwOzgE9X1Ulj5m8JfBbYH7gdOKyqlieZC1wPLG2b/qiq3ry2be200041d+7cyf0FJGkjd9lll91WVXO65g0WEElmAacBLwFWAIuSLKiq60aaHQXcWVV7JTkcOBk4rJ13Q1U9re/25s6dy+LFiyeneEnaRCT5xXjzhjzEdACwrKpurKr7gXOA+WPazAfOaofPB16UJAPWJEnqaciA2Bm4aWR8RTuts01VrQLuAnZs5+2R5IokFyc5cMA6JUkdBj0HsQFuAXarqtuT7A98Ncm+VfWb0UZJjgaOBthtt92moUxJ2ngNuQdxM7DryPgu7bTONkk2A7YHbq+q+6rqdoCqugy4AXji2A1U1elVNa+q5s2Z03mORZI0QUMGxCJg7yR7JNkCOBxYMKbNAuDIdvgQ4KKqqiRz2pPcJNkT2Bu4ccBaJUljDHaIqapWJTkGuIDmMtczq2pJkhOBxVW1ADgDODvJMuAOmhABeB5wYpIHgIeAN1fVHUPVKklaUzaW7r7nzZtXXuYqSesnyWVVNa9rnndSS5I6GRCSpE4z9TLXKTf3uG9M27aXn/Tyadu2JI3HPQhJUicDQpLUyYCQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJnQwISVInA0KS1MmAkCR1GjQgkhyUZGmSZUmO65i/ZZJz2/mXJpk7Zv5uSVYmOXbIOiVJaxosIJLMAk4DXgbsAxyRZJ8xzY4C7qyqvYBTgJPHzP8Y8C9D1ShJGt+QexAHAMuq6saquh84B5g/ps184Kx2+HzgRUkCkORg4OfAkgFrlCSNY8iA2Bm4aWR8RTuts01VrQLuAnZMsg3wbuADA9YnSVqLmXqS+gTglKpaubZGSY5OsjjJ4ltvvXVqKpOkTcRmA677ZmDXkfFd2mldbVYk2QzYHrgdeCZwSJIPAzsADyW5t6pOHV24qk4HTgeYN29eDfFLSNKmasiAWATsnWQPmiA4HPiLMW0WAEcCPwQOAS6qqgIOXN0gyQnAyrHhIEka1mABUVWrkhwDXADMAs6sqiVJTgQWV9UC4Azg7CTLgDtoQkSSNAMMuQdBVS0EFo6ZdvzI8L3AoetYxwmDFCdJWquZepJakjTNDAhJUicDQpLUyYCQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJncZ9olySu4FaPdr+W+1wVdV2A9cmSZpG4wZEVW07lYVIkmaWXoeYkjw3yRvb4Z2S7DFsWZKk6bbOgEjyfuDdwHvaSVsAnxuyKEnS9OuzB/Eq4JXAbwGq6peAh58kaSPXJyDur6qiPWGd5LHDliRJmgn6BMQXk3wK2CHJm4BvAf80bFmSpOk27lVMq1XV3yd5CfAb4I+A46vqm4NXJkmaVusMiCTvBM41FCRp09LnENO2wL8m+W6SY5L8h6GLkiRNv3UGRFV9oKr2Bd4KPB64OMm3Bq9MkjSt1qcvpl8D/wbcDvz7YcqRJM0UfW6U++sk3wEuBHYE3lRVTxm6MEnS9FrnSWpgV+AdVXXlwLVIkmaQPucg3gNsM9IX0xz7YpKkjd9E+mLaHPtikqSNnn0xSZI6DdoXU5KDkixNsizJcR3zt0xybjv/0iRz2+kHJLmy/bkqyav6blOSNDkG64spySzgNOBlwD7AEUn2GdPsKODOqtoLOAU4uZ1+LTCvqp4GHAR8KkmfE+qSpEkyZF9MBwDLqupGgCTnAPOB60bazAdOaIfPB05Nkqq6Z6TNVjz86FNJ0hTp9a28DYT17YtpZ+CmkfEVwDPHa1NVq5LcRXOvxW1JngmcCewOvK6qVq3n9iVJG2DcgEhyN93f3ANUVW03WFXNBi4F9k3yH4GzkvxLVd07psajgaMBdttttyHLkaRNzrjnIKpq26raruNn257hcDPNTXar7dJO62zTnmPYnqYrj9E6rgdWAvt11Hh6Vc2rqnlz5szpUZIkqa/16YtpfS0C9k6yR5ItgMOBBWPaLACObIcPAS6qqmqX2Qwgye7Ak4DlA9YqSRpjsCuD2nMKxwAXALOAM6tqSZITgcVVtQA4Azg7yTLgDpoQAXgucFySB4CHgL+uqtuGqlWStKZBLx2tqoXAwjHTjh8Zvhc4tGO5s4Gzh6xNkrR2vQ4xJdk9yYvb4dlJvJNakjZyffpiehPNPQqfaiftAnx1wJokSTNAnz2ItwLPoblRjqr6GT4wSJI2en0C4r6qun/1SHt1kXc2S9JGrk9AXJzkvcDstsuN84CvDVuWJGm69QmI44BbgWuAv6K5KulvhyxKkjT9+lzmOpvmHoZ/gt/30jobuGetS0mSHtX67EFcSBMIq82m6fJbkrQR6xMQW1XVytUj7fDWw5UkSZoJ+gTEb5M8ffVIkv2B3w1XkiRpJuhzDuIdwHlJfknT1ffjgMOGLEqSNP36PFFuUZIn0TxNDmBpVT0wbFmSpOnWt7O+ZwBz2/ZPT0JVfXawqiRJ026dAZHkbOAJwJXAg+3kAgwISdqI9dmDmAfsU1V2ryFJm5A+VzFdS3NiWpK0CemzB7ETcF2SHwP3rZ5YVa8crCpJ0rTrExAnDF2EJGnm6XOZ68VTUYgkaWbp80S5ZyVZlGRlkvuTPJjkN1NRnCRp+vQ5SX0qcATwM5qO+v4SOG3IoiRJ069PQFBVy4BZVfVgVf0zcNCwZUmSplufk9T3JNkCuDLJh4Fb6BkskqRHrz4f9K9r2x0D/BbYFfjzIYuSJE2/PgFxcFXdW1W/qaoPVNU7gf88dGGSpOnVJyCO7Jj2hkmuQ5I0w4x7DiLJEcBfAHsmWTAya1vgjqELkyRNr7WdpP4BzQnpnYCPjky/G7h6yKL0SHOP+8a0bXv5SS+ftm1Lml7jBkRV/SLJCuBe76aWpE3PWs9BVNWDwENJtp+ieiRJM0Sf+yBWAtck+SbNZa4AVNXbBqtKkjTt+gTEl9sfSdImpE9vrme1d1I/sZ20tKoeGLYsSdJ06/NM6hcAZwHLgQC7Jjmyqi4ZtDJJ0rTqc4jpo8BLq2opQJInAl8A9l/XgkkOAj4OzAI+XVUnjZm/JfDZdl23A4dV1fIkLwFOArYA7gfeVVUX9f6tNGW8BFfaePUJiM1XhwNAVf00yebrWijJLJpuwV8CrAAWJVlQVdeNNDsKuLOq9kpyOHAycBhwG/CKqvplkv2AC4Cde/9WEoaXtKH6BMTiJJ8GPteOvxZY3GO5A4BlVXUjQJJzgPnAaEDM5+FHmp4PnJokVXXFSJslwOwkW1bVfUgbAcNLjwZ9+mJ6C82H+tvan+vaaeuyM3DTyPgK1twL+H2bqloF3AXsOKbNq4HLu8IhydFJFidZfOutt/YoSZLUV5+rmO5LcipwIfAQzVVM9w9eGZBkX5rDTi8dp7bTgdMB5s2bV1NRkyRtKvo8k/rlwA00J5tPBZYleVmPdd9M8+yI1XZpp3W2SbIZsD3NyWqS7AJ8BXh9Vd3QY3uSpEnU5xDTR4EXVtULqur5wAuBU3ostwjYO8ke7X0UhwMLxrRZwMPdiR8CXFRVlWQH4BvAcVX1/R7bkiRNsj4nqe9un0m92o00PbquVVWtSnIMzRVIs4Azq2pJkhOBxVW1ADgDODvJMpouxA9vFz8G2As4Psnx7bSXVtWve/1WkibME+hare9VTAuBLwIFHEpzyeqfA1TVuN1wVNVCYOGYacePDN/brm/sch8EPtjnF5C06TC8plafgNgK+BXw/Hb8VmA28AqawLCfJknaCPW5iumNU1GIJGlm6dMX0x7A3wBzR9tX1SuHK0uSNN36HGL6Ks3J5K/R3AchSRpjYzw/0icg7q2qTwyydUnSjNUnID6e5P3AvwK/7+6iqi4frCpJ0rTrExBPBl4H/CkPH2KqdlyStJHqExCHAntOVf9LkqSZoU9XG9cCOwxchyRphumzB7ED8JMki3jkOQgvc5WkjVifgHj/4FVIkmacPndSXzwVhUiSZpZxAyLJ3TRXK60xC6iq2m6wqiRJ027cgKiqbaeyEEnSzNLnKiZJ0ibIgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJnQYNiCQHJVmaZFmS4zrmb5nk3Hb+pUnmttN3TPLtJCuTnDpkjZKkboMFRJJZwGnAy4B9gCOS7DOm2VHAnVW1F3AKcHI7/V7g74Bjh6pPkrR2Q+5BHAAsq6obq+p+4Bxg/pg284Gz2uHzgRclSVX9tqq+RxMUkqRpMGRA7AzcNDK+op3W2aaqVgF3ATsOWJMkqadH9UnqJEcnWZxk8a233jrd5UjSRmXIgLgZ2HVkfJd2WmebJJsB2wO3991AVZ1eVfOqat6cOXM2sFxJ0qghA2IRsHeSPZJsARwOLBjTZgFwZDt8CHBRVdWANUmSetpsqBVX1aokxwAXALOAM6tqSZITgcVVtQA4Azg7yTLgDpoQASDJcmA7YIskBwMvrarrhqpXkvRIgwUEQFUtBBaOmXb8yPC9wKHjLDt3yNokSWv3qD5JLUkajgEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6jRoQCQ5KMnSJMuSHNcxf8sk57bzL00yd2Tee9rpS5P82ZB1SpLWNFhAJJkFnAa8DNgHOCLJPmOaHQXcWVV7AacAJ7fL7gMcDuwLHAR8sl2fJGmKDLkHcQCwrKpurKr7gXOA+WPazAfOaofPB16UJO30c6rqvqr6ObCsXZ8kaYoMGRA7AzeNjK9op3W2qapVwF3Ajj2XlSQNaLPpLmBDJDkaOLodXZlk6TSVshNw20QXzsmTWMmarG1irG1irG1iprO23cebMWRA3AzsOjK+Szutq82KJJsB2wO391yWqjodOH0Sa56QJIurat5019HF2ibG2ibG2iZmptY25CGmRcDeSfZIsgXNSecFY9osAI5shw8BLqqqaqcf3l7ltAewN/DjAWuVJI0x2B5EVa1KcgxwATALOLOqliQ5EVhcVQuAM4CzkywD7qAJEdp2XwSuA1YBb62qB4eqVZK0pkHPQVTVQmDhmGnHjwzfCxw6zrIfAj40ZH2TaNoPc62FtU2MtU2MtU3MjKwtzREdSZIeya42JEmdDAhJUicDYi2SvC3J9Um+kORbSa5McliS965jua2S/DjJVUmWJPnADKpt1yTfTnJdW9vbJ7u2Mdub0/azdUWSA3suc0b72l2d5Pwk2wxY35ajr98GrusTSVZOQk0nJDl2gss+L8nlSVYlOWRDa5ksaUzJ581kvKdT+Te4lho+3/ZFd22SM5NsPtU1UFX+jPMD/ITmHoxnAd8amb5yHcsF2KYd3hy4FHjWDKnt8cDT2+FtgZ8C+wz4Gh4OfHqcebPGmb7dyPDHgOMGrO8Rr98GrGcecPa6Xv+e6zoBOHaCy84FngJ8FjhkgNfrJJqrCkdr/VvgQuBy4Bpg/kgtS9talgC7D/U+TvZ7OsV/g+P9P/hP7WdJgC8Ab5mK12/0xz2IcST5R2BP4JvA94FntN9IzgNmt8Of71q2Gqu/SW7e/kza1QAbWNstVXV5O3w3cD2T2I1Jkte337quSvI14MPA/Lam2UlWJvlokquAZ49T42/adQWYzQRfuyRzk/wkyWeS/LT9RvbiJN9P8rMkBwCf4+HX791JPtYu+/YkN7bDeyb5/lq2Mwv4CPDfJlJnu473tTV+D/gj4DFJLmvnPTVJJdmtHb8hydZd66mq5VV1NfDQRGtZh3OB14yMv4amP7VXVdXTgRcCH23fO2juYfpkVe1bVb/Y0I1P1Xs6WX+D7Tq+muSydo/96HZan/8HC9vPkqK5D2yXidYwYVOdSI+mH2A5zS3wLwC+PjJ9nd8Sae79uBJYCZw8k2obaTsX+L+MfFvawJr2pdkj2akd/wPgDcCpI20KeE2Pdf0z8Cvg28DWE6xnLs19NE+mOZx6GXAmzTey+cBXR18/4HHAonb4fJqbPXemuZnzf65lO28H/uv6vv4jy+9P8817a2A7ms4pj6X51r0dcExby2tpukX4YY91foYB9iDadV8P/CHwVJovKJsDpwJXt3/zv2tfy7nAzyd521Pynk7W3+Dq/wftv7OBa2n6m+v1/6BdbnOavbMDh3g/1/bjHsRAqurBqnoaTeofkGS/aS7pEdpjql8C3lHtt6VJ8KfAeVV1G0BV3dHR5sF2u2tVVW+k+RC6HtiQcwM/r6prquohmg/cC6v5X3cNzYfN6Db/DdgmybY0Xb38L+B5wIHAd7tWnuQPae7l+YcNqPFA4CtVdU/7XqzuceAHwHPaGv7HumqZQufR9HxwGM0exWuBOcD+7d/8r4Ct2ra/HWD7g76nI8tO1t/g29o9hR+1NexNz/8HrU8Cl1TVlL/vBsTAqur/0XwDOWiaS/m99mTXl4DPV9WXp3jz91bPu+LbducAr96A7d03MvzQyPhDdN8o+gPgjTTHzr9L80HybJpvyl3+GNgLWJZkObB1mp4BJsMl7fZ3B/43zTf25zL9AXEuzbmlQ2jCYnvg11X1QJIXspbO3ybJ0O/p723o32CSFwAvBp5dVU8FrqAJz17/D5K8nyZ83zmR7W8oA2JiHljbFQVprtzZoR2eDbyE5qTyTKgtNF2cXF9VH5vkbV8EHJpkx3Zbf7C+K2ivdtlr9TDwSqbutYPmA+RYmg/nK2iOqd9XVXd1Na6qb1TV46pqblXNBe6p5gFY6+MS4OD2HM22wCtGavkvwM/ab8t30Jy4/N76/lKTqaqW0FzgcHNV3QJ8HpiX5Brg9Uzt+9XHer2nk/w3uD3NQ9HuSfIkmhPovST5S+DPgCPa93/KPaq7+55GpwNXJ7m8ql7bMf/xwFntycvHAF+sqq/PkNqeA7wOuCbJle2091bTLcoGqaYPrQ8BFyd5kOY/43fWczWhee22a4evAt6yobWth+/SHAa4pKoeTHITA3/gVdXlSc6l+V1/TXOcnKpa3n5AXdI2/R6wS1XdOd66kjwD+Arw74BXJPlAVe07QM1PHhm+jXFOtAIz4dDq+r6nk/k3+H+ANye5nmYP5kfrsew/Ar8Aftie8/9yVZ04wTomxK42JEmdPMQkSerkIaYN0B5rv7Bj1ouq6vaprmfUTK5ttSRfAfYYM/ndVXXBdNSzLjOp3iTvY82ekM+rphdk9TQT3tOZUMN4PMQkSerkISZJUicDQpLUyYCQxkjyYNuPz+qfuRNYx8FJ9hmgPGnKeJJaWtPv2i4jNsTBwNdpnqveS5LNqmrVBm5XmjTuQUg9JNk/ycVtr5wXJHl8O/1NSRal6b32S0m2TvInNHfffqTdA3lCku8kmdcus1PbLQdJ3pBkQZKLgAuTPDZN3/8/TvMMjfltu33baVem6S137+l5JbQpMSCkNa3uMv3KJF9puy75B5reUfen6T109eWkX66qZ7T97FwPHFVVP6DpcO9dVfW0qrphHdt7ervu5wPvAy6qqgNouoT4SJLHAm8GPt7u2cwDVkzuryytyUNM0poecYip7Yl3P+CbbZcHs4Bb2tn7JfkgsAOwDTCRa9e/OdLz7UuBV+bhJ8ptBewG/BB4X5JdaELpZxPYjrReDAhp3QIsqaqu/oY+AxxcVVcleQPNswi6rOLhPfatxswb7RI7wKuraumYNtcnuRR4ObAwyV9V1UX9fwVp/XmISVq3pcCcJM+Gprv0JKs7wNsWuKU9DDXaOeLd7bzVltM8GAiabrLHcwHwN20nfST54/bfPYEbq+oTNF1/P2WDfiOpBwNCWoequp/mQ/3k9sEvVwJ/0s7+O5pnjn+fR/YQeg7wrvZE8xOAvwfekuQKmicBjue/0zxB7OokS9pxaB7teW3bA+9+NM95lgZlVxuSpE7uQUiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6vT/AUdH+immA7jkAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "         dw_1        dw_2        dw_3       dw_4      dw_5     mfw_1  \\\n0  133.429003  134.242162  133.489322  37.853305  5.508392  0.586324   \n1  133.965830  136.903950  136.743215  38.927755  5.696305  0.593533   \n2  139.274723  140.184030  140.070259  39.704137  5.761162  0.577124   \n3  138.676856  143.380168  143.473350  40.663806  5.859970  0.588245   \n4  140.755171  142.872499  143.424214  40.769824  5.919625  0.585157   \n\n      mfw_2     mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8  \\\n0 -0.522381 -0.788889 -0.136987 -1.009483  ...  0.017932  0.038860 -0.042238   \n1 -0.515953 -0.790798 -0.224475  2.486222  ...  0.014723  0.042961 -0.052676   \n2 -0.518431 -0.807961 -0.219536 -2.150671  ...  0.006243  0.051369 -0.051818   \n3 -0.513443 -0.810437 -0.247007 -4.289119  ...  0.014157  0.055342 -0.057101   \n4 -0.517127 -0.798512 -0.176490 -1.067047  ...  0.034652  0.022510 -0.031786   \n\n      cfr_9    cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0  0.026644 -0.034630  0.040781 -0.065560  0.001347 -0.022417 -0.007807  \n1  0.042240 -0.050718  0.057318 -0.078975  0.010010 -0.026053 -0.011060  \n2  0.032123 -0.034994  0.042277 -0.076328  0.011880 -0.026580 -0.008271  \n3  0.036792 -0.033449  0.035388 -0.067010  0.008826 -0.025932 -0.011778  \n4  0.019955 -0.031716  0.039832 -0.068147  0.004500 -0.023807 -0.012157  \n\n[5 rows x 75 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>133.429003</td>\n      <td>134.242162</td>\n      <td>133.489322</td>\n      <td>37.853305</td>\n      <td>5.508392</td>\n      <td>0.586324</td>\n      <td>-0.522381</td>\n      <td>-0.788889</td>\n      <td>-0.136987</td>\n      <td>-1.009483</td>\n      <td>...</td>\n      <td>0.017932</td>\n      <td>0.038860</td>\n      <td>-0.042238</td>\n      <td>0.026644</td>\n      <td>-0.034630</td>\n      <td>0.040781</td>\n      <td>-0.065560</td>\n      <td>0.001347</td>\n      <td>-0.022417</td>\n      <td>-0.007807</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>133.965830</td>\n      <td>136.903950</td>\n      <td>136.743215</td>\n      <td>38.927755</td>\n      <td>5.696305</td>\n      <td>0.593533</td>\n      <td>-0.515953</td>\n      <td>-0.790798</td>\n      <td>-0.224475</td>\n      <td>2.486222</td>\n      <td>...</td>\n      <td>0.014723</td>\n      <td>0.042961</td>\n      <td>-0.052676</td>\n      <td>0.042240</td>\n      <td>-0.050718</td>\n      <td>0.057318</td>\n      <td>-0.078975</td>\n      <td>0.010010</td>\n      <td>-0.026053</td>\n      <td>-0.011060</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>139.274723</td>\n      <td>140.184030</td>\n      <td>140.070259</td>\n      <td>39.704137</td>\n      <td>5.761162</td>\n      <td>0.577124</td>\n      <td>-0.518431</td>\n      <td>-0.807961</td>\n      <td>-0.219536</td>\n      <td>-2.150671</td>\n      <td>...</td>\n      <td>0.006243</td>\n      <td>0.051369</td>\n      <td>-0.051818</td>\n      <td>0.032123</td>\n      <td>-0.034994</td>\n      <td>0.042277</td>\n      <td>-0.076328</td>\n      <td>0.011880</td>\n      <td>-0.026580</td>\n      <td>-0.008271</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>138.676856</td>\n      <td>143.380168</td>\n      <td>143.473350</td>\n      <td>40.663806</td>\n      <td>5.859970</td>\n      <td>0.588245</td>\n      <td>-0.513443</td>\n      <td>-0.810437</td>\n      <td>-0.247007</td>\n      <td>-4.289119</td>\n      <td>...</td>\n      <td>0.014157</td>\n      <td>0.055342</td>\n      <td>-0.057101</td>\n      <td>0.036792</td>\n      <td>-0.033449</td>\n      <td>0.035388</td>\n      <td>-0.067010</td>\n      <td>0.008826</td>\n      <td>-0.025932</td>\n      <td>-0.011778</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>140.755171</td>\n      <td>142.872499</td>\n      <td>143.424214</td>\n      <td>40.769824</td>\n      <td>5.919625</td>\n      <td>0.585157</td>\n      <td>-0.517127</td>\n      <td>-0.798512</td>\n      <td>-0.176490</td>\n      <td>-1.067047</td>\n      <td>...</td>\n      <td>0.034652</td>\n      <td>0.022510</td>\n      <td>-0.031786</td>\n      <td>0.019955</td>\n      <td>-0.031716</td>\n      <td>0.039832</td>\n      <td>-0.068147</td>\n      <td>0.004500</td>\n      <td>-0.023807</td>\n      <td>-0.012157</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 75 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest - L1SO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['e0106', 'e0110', 'e0115', 'e0129', 'e0133', 'e0151', 'e0202',\n       'e0203', 'e0204', 'e0205', 'e0206', 'e0207', 'e0208', 'e0210',\n       'e0211', 'e0212', 'e0213', 'e0302', 'e0303', 'e0304', 'e0305',\n       'e0306', 'e0403', 'e0404', 'e0405', 'e0406', 'e0408', 'e0409',\n       'e0410', 'e0411', 'e0413', 'e0415', 'e0417', 'e0418', 'e0515',\n       'e0601', 'e0602', 'e0603', 'e0605', 'e0606', 'e0607', 'e0609',\n       'e0610', 'e0611', 'e0612', 'e0613', 'e0614', 'e0615', 'e0704',\n       'e0801', 'e0808', 'e0817', 'e0818', 'e1301', 'e1302', 'e1304'],\n      dtype=object)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvds = X_fsel.copy()\n",
    "cvds[\"patient_id\"] = patient_ids\n",
    "cvds[\"label\"] = y\n",
    "\n",
    "patients = np.unique(cvds[\"patient_id\"].values)\n",
    "patients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def eval_metrics(tp, tn, fp, fn):\n",
    "    acc = (tp + tn) /(tp + tn + fp + fn)\n",
    "    sens = tp / (tp+fn)\n",
    "    spec = tn / (tn+fp)\n",
    "    precision = tp / (tp+fp)\n",
    "    recall = tp / (tp+fn)\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "    return acc, sens, spec, precision, recall, f1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 56 - 1.3299973011016846 s\n",
      "Accuracy 0.8133333333333334 precision 0.8481777777777778 specificity 0.18666666666666668 recall 0.8133333333333334 f1 0.7296078431372549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 56 - 1.3256807327270508 s\n",
      "Accuracy 0.8054298642533937 precision 0.8432874019778466 specificity 0.19457013574660634 recall 0.8054298642533937 f1 0.7186291520656847\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 56 - 1.310516119003296 s\n",
      "Accuracy 0.9211267605633803 precision 0.9273477484626066 specificity 0.07887323943661972 recall 0.9211267605633803 f1 0.8833092396018338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 56 - 1.3140010833740234 s\n",
      "Accuracy 0.8651685393258427 precision 0.8833480621133695 specificity 0.1348314606741573 recall 0.8651685393258427 f1 0.8026262352781914\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "5 of 56 - 1.4439983367919922 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "6 of 56 - 1.4320199489593506 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 56 - 1.4220013618469238 s\n",
      "Accuracy 0.7124600638977636 precision 0.7951392787514419 specificity 0.28753993610223644 recall 0.7124600638977636 f1 0.5928305755567213\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 56 - 1.4300501346588135 s\n",
      "Accuracy 0.7398119122257053 precision 0.8075097532453493 specificity 0.2601880877742947 recall 0.7398119122257053 f1 0.6291733740009603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 56 - 1.404998779296875 s\n",
      "Accuracy 0.9806629834254144 precision 0.9724907918968693 specificity 0.013734775678227092 recall 0.9806629834254144 f1 0.9765597910261449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 56 - 1.4250006675720215 s\n",
      "Accuracy 0.6525198938992043 precision 0.7732623180350245 specificity 0.34748010610079577 recall 0.6525198938992043 f1 0.5153126609926301\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 56 - 1.4009993076324463 s\n",
      "Accuracy 0.7732558139534884 precision 0.8248186317716455 specificity 0.2394024138946129 recall 0.7732558139534884 f1 0.6772624694002448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 56 - 1.3279986381530762 s\n",
      "Accuracy 0.7522123893805309 precision 0.8136110893570364 specificity 0.24778761061946902 recall 0.7522123893805309 f1 0.6458389201752033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 56 - 1.3370213508605957 s\n",
      "Accuracy 0.9090909090909091 precision 0.9173553719008264 specificity 0.09090909090909091 recall 0.9090909090909091 f1 0.8658008658008657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 56 - 1.3600022792816162 s\n",
      "Accuracy 0.8109090909090909 precision 0.8466644628099174 specificity 0.1890909090909091 recall 0.8109090909090909 f1 0.7262358525009127\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 56 - 1.3339996337890625 s\n",
      "Accuracy 0.8181818181818182 precision 0.8512396694214877 specificity 0.18181818181818182 recall 0.8181818181818182 f1 0.7363636363636364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 56 - 1.5729994773864746 s\n",
      "Accuracy 0.9473684210526315 precision 0.9501385041551246 specificity 0.05263157894736842 recall 0.9473684210526315 f1 0.9217638691322904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 56 - 1.3899996280670166 s\n",
      "Accuracy 0.7130681818181818 precision 0.7953980501033058 specificity 0.2869318181818182 recall 0.7130681818181818 f1 0.5936322176993819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 56 - 1.4579999446868896 s\n",
      "Accuracy 0.9692780337941628 precision 0.9702218730017154 specificity 0.030721966205837174 recall 0.9692780337941628 f1 0.9541566916132868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 56 - 1.442002296447754 s\n",
      "Accuracy 0.8602150537634409 precision 0.8797548849577986 specificity 0.13978494623655913 recall 0.8602150537634409 f1 0.795574616197402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 56 - 1.416999101638794 s\n",
      "Accuracy 0.9885496183206107 precision 0.9886807295612143 specificity 0.011450381679389313 recall 0.9885496183206107 f1 0.9828573940308568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 56 - 1.4019997119903564 s\n",
      "Accuracy 0.8114478114478114 precision 0.8469997392556314 specificity 0.18855218855218855 recall 0.8114478114478114 f1 0.726984842226478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 56 - 1.3989992141723633 s\n",
      "Accuracy 0.6706827309236948 precision 0.7791325946355704 specificity 0.3293172690763052 recall 0.6706827309236948 f1 0.5384808464627742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 56 - 1.3620011806488037 s\n",
      "Accuracy 0.3333333333333333 precision 0.7777777777777777 specificity 0.6666666666666666 recall 0.3333333333333333 f1 0.16666666666666666\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 56 - 1.380000352859497 s\n",
      "Accuracy 0.8447488584474886 precision 0.8688517754008466 specificity 0.1552511415525114 recall 0.8447488584474886 f1 0.7736561327365613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 56 - 1.3605105876922607 s\n",
      "Accuracy 0.68 precision 0.7824000000000001 specificity 0.32 recall 0.68 f1 0.5504761904761905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 56 - 1.370999813079834 s\n",
      "Accuracy 0.734982332155477 precision 0.805216696425227 specificity 0.26501766784452296 recall 0.734982332155477 f1 0.6227141551459846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 56 - 1.4439990520477295 s\n",
      "Accuracy 0.4840989399293286 precision 0.7648022063259502 specificity 0.11731888414474545 recall 0.4840989399293286 f1 0.5896602337591738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 56 - 1.4030001163482666 s\n",
      "Accuracy 0.04962779156327544 precision 0.9528351261321725 specificity 0.9503722084367245 recall 0.04962779156327544 f1 0.004692935372413753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 56 - 1.3640010356903076 s\n",
      "Accuracy 0.14345991561181434 precision 0.8771208317755346 specificity 0.8565400843881856 recall 0.14345991561181434 f1 0.03599732199853644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 56 - 1.4680001735687256 s\n",
      "Accuracy 0.9265175718849841 precision 0.9319172391266625 specificity 0.07348242811501597 recall 0.9265175718849841 f1 0.8911777640021405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 56 - 1.42099928855896 s\n",
      "Accuracy 0.8828125 precision 0.8489071196660481 specificity 0.23476796255862847 recall 0.8828125 f1 0.8601192954696868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 56 - 1.424999713897705 s\n",
      "Accuracy 0.5 precision 0.7548476454293629 specificity 0.5366492146596858 recall 0.5 f1 0.35317862641282716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 56 - 1.3969995975494385 s\n",
      "Accuracy 0.8477508650519031 precision 0.8709306641443469 specificity 0.1522491349480969 recall 0.8477508650519031 f1 0.7778987338491247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 56 - 1.4160006046295166 s\n",
      "Accuracy 0.9046321525885559 precision 0.8890839330212627 specificity 0.14162669473196993 recall 0.9046321525885559 f1 0.8965537693508995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 56 - 1.4450008869171143 s\n",
      "Accuracy 0.9444444444444444 precision 0.9475308641975309 specificity 0.05555555555555555 recall 0.9444444444444444 f1 0.9174603174603174\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "36 of 56 - 1.395998477935791 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 56 - 1.3969998359680176 s\n",
      "Accuracy 0.8917378917378918 precision 0.9034585758232482 specificity 0.10826210826210826 recall 0.8917378917378918 f1 0.840704699138434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 56 - 1.3320024013519287 s\n",
      "Accuracy 0.048 precision 0.9543039999999999 specificity 0.952 recall 0.048 f1 0.0043969465648854966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 56 - 1.4039971828460693 s\n",
      "Accuracy 0.7622950819672131 precision 0.8187987100241871 specificity 0.23770491803278687 recall 0.7622950819672131 f1 0.6594738848646589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 56 - 1.4350407123565674 s\n",
      "Accuracy 0.8098360655737705 precision 0.8459983875302337 specificity 0.1901639344262295 recall 0.8098360655737705 f1 0.7247445949156569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 56 - 1.4910008907318115 s\n",
      "Accuracy 0.35802469135802467 precision 0.7701569882639842 specificity 0.6419753086419753 recall 0.35802469135802467 f1 0.1887766554433221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 56 - 1.4470007419586182 s\n",
      "Accuracy 0.9457627118644067 precision 0.9487043952887101 specificity 0.05423728813559322 recall 0.9457627118644067 f1 0.9193999881887438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 56 - 1.3279986381530762 s\n",
      "Accuracy 0.8571428571428571 precision 0.8775510204081632 specificity 0.14285714285714285 recall 0.8571428571428571 f1 0.7912087912087911\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "44 of 56 - 1.3360002040863037 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 56 - 1.3220031261444092 s\n",
      "Accuracy 0.6108597285067874 precision 0.3776223776223776 specificity 0.38178733031674206 recall 0.6108597285067874 f1 0.46672428694900603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 56 - 1.328037977218628 s\n",
      "Accuracy 0.753968253968254 precision 0.8144998740236835 specificity 0.24603174603174602 recall 0.753968253968254 f1 0.6482080011491776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 56 - 1.2979991436004639 s\n",
      "Accuracy 0.4649859943977591 precision 0.5519063214022811 specificity 0.5757808490006633 recall 0.4649859943977591 f1 0.41085933763004584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 56 - 1.2820017337799072 s\n",
      "Accuracy 0.9868421052631579 precision 0.9870152354570637 specificity 0.013157894736842105 recall 0.9868421052631579 f1 0.9803067270826071\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "49 of 56 - 1.2679991722106934 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "50 of 56 - 1.3589978218078613 s\n",
      "Accuracy 0.9966887417218543 precision 1.0 specificity 0.0 recall 0.9966887417218543 f1 0.9983416252072967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 56 - 1.187283992767334 s\n",
      "Accuracy 0.1271186440677966 precision 0.8933696070878275 specificity 0.8793122240994059 recall 0.1271186440677966 f1 0.03767363336447567\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "52 of 56 - 1.2770018577575684 s\n",
      "Accuracy 0.9512195121951219 precision 1.0 specificity 0.0 recall 0.9512195121951219 f1 0.975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 56 - 1.2660019397735596 s\n",
      "Accuracy 0.7244582043343654 precision 0.8008545277432172 specificity 0.29751981764365665 recall 0.7244582043343654 f1 0.6147858296571297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 56 - 1.2749998569488525 s\n",
      "Accuracy 0.8613138686131386 precision 0.8805477116521924 specificity 0.1386861313868613 recall 0.8613138686131386 f1 0.797137541147846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 56 - 1.300997018814087 s\n",
      "Accuracy 0.9053030303030303 precision 0.9142705463728191 specificity 0.0946969696969697 recall 0.9053030303030303 f1 0.8603078498704742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 56 - 1.300001859664917 s\n",
      "Accuracy 0.7751004016064257 precision 0.8256802309640167 specificity 0.2248995983935743 recall 0.7751004016064257 f1 0.6768976357920369\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "tot = len(patients)\n",
    "for i, patient in enumerate(patients):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    df1 = cvds.loc[cvds[\"patient_id\"] != patient]\n",
    "    df2 = cvds.loc[cvds[\"patient_id\"] == patient]\n",
    "\n",
    "    y_train = df1[\"label\"].values\n",
    "    x_train = df1.loc[:, ~df1.columns.isin(['patient_id', 'label'])]\n",
    "    y_test = df2[\"label\"].values\n",
    "    x_test = df2.loc[:, ~df2.columns.isin(['patient_id', 'label'])]\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, max_depth=6, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, zero_division=1, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(patients), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.813333     0.186667   0.848178  0.813333  0.729608\n1  0.805430     0.194570   0.843287  0.805430  0.718629\n2  0.921127     0.078873   0.927348  0.921127  0.883309\n3  0.865169     0.134831   0.883348  0.865169  0.802626\n4  1.000000     0.000000   1.000000  1.000000  1.000000\n5  1.000000     0.000000   1.000000  1.000000  1.000000\n6  0.712460     0.287540   0.795139  0.712460  0.592831\n7  0.739812     0.260188   0.807510  0.739812  0.629173\n8  0.980663     0.013735   0.972491  0.980663  0.976560\n9  0.652520     0.347480   0.773262  0.652520  0.515313",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.813333</td>\n      <td>0.186667</td>\n      <td>0.848178</td>\n      <td>0.813333</td>\n      <td>0.729608</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.805430</td>\n      <td>0.194570</td>\n      <td>0.843287</td>\n      <td>0.805430</td>\n      <td>0.718629</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.921127</td>\n      <td>0.078873</td>\n      <td>0.927348</td>\n      <td>0.921127</td>\n      <td>0.883309</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.865169</td>\n      <td>0.134831</td>\n      <td>0.883348</td>\n      <td>0.865169</td>\n      <td>0.802626</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.712460</td>\n      <td>0.287540</td>\n      <td>0.795139</td>\n      <td>0.712460</td>\n      <td>0.592831</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.739812</td>\n      <td>0.260188</td>\n      <td>0.807510</td>\n      <td>0.739812</td>\n      <td>0.629173</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.980663</td>\n      <td>0.013735</td>\n      <td>0.972491</td>\n      <td>0.980663</td>\n      <td>0.976560</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.652520</td>\n      <td>0.347480</td>\n      <td>0.773262</td>\n      <td>0.652520</td>\n      <td>0.515313</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.7611042805927298\n",
      "Precision 0.8669917700406836\n",
      "Specificity 0.23565810122599892\n",
      "Recall 0.7611042805927298\n",
      "F1 0.6972893082881761\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_32beats_l1so.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}