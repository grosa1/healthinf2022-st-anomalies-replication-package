{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 32 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id        dw_1        dw_2        dw_3       dw_4      dw_5     mfw_1  \\\n0  e0106  133.429003  134.242162  133.489322  37.853305  5.508392  0.586324   \n1  e0106  133.965830  136.903950  136.743215  38.927755  5.696305  0.593533   \n2  e0106  139.274723  140.184030  140.070259  39.704137  5.761162  0.577124   \n3  e0106  138.676856  143.380168  143.473350  40.663806  5.859970  0.588245   \n4  e0106  140.755171  142.872499  143.424214  40.769824  5.919625  0.585157   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.522381 -0.788889 -0.136987  ... -0.042238  0.026644 -0.034630  0.040781   \n1 -0.515953 -0.790798 -0.224475  ... -0.052676  0.042240 -0.050718  0.057318   \n2 -0.518431 -0.807961 -0.219536  ... -0.051818  0.032123 -0.034994  0.042277   \n3 -0.513443 -0.810437 -0.247007  ... -0.057101  0.036792 -0.033449  0.035388   \n4 -0.517127 -0.798512 -0.176490  ... -0.031786  0.019955 -0.031716  0.039832   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.065560  0.001347 -0.022417 -0.007807 -0.008983    NSR  \n1 -0.078975  0.010010 -0.026053 -0.011060 -0.004790    NSR  \n2 -0.076328  0.011880 -0.026580 -0.008271 -0.005162    NSR  \n3 -0.067010  0.008826 -0.025932 -0.011778 -0.000208    NSR  \n4 -0.068147  0.004500 -0.023807 -0.012157 -0.002940    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>133.429003</td>\n      <td>134.242162</td>\n      <td>133.489322</td>\n      <td>37.853305</td>\n      <td>5.508392</td>\n      <td>0.586324</td>\n      <td>-0.522381</td>\n      <td>-0.788889</td>\n      <td>-0.136987</td>\n      <td>...</td>\n      <td>-0.042238</td>\n      <td>0.026644</td>\n      <td>-0.034630</td>\n      <td>0.040781</td>\n      <td>-0.065560</td>\n      <td>0.001347</td>\n      <td>-0.022417</td>\n      <td>-0.007807</td>\n      <td>-0.008983</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>133.965830</td>\n      <td>136.903950</td>\n      <td>136.743215</td>\n      <td>38.927755</td>\n      <td>5.696305</td>\n      <td>0.593533</td>\n      <td>-0.515953</td>\n      <td>-0.790798</td>\n      <td>-0.224475</td>\n      <td>...</td>\n      <td>-0.052676</td>\n      <td>0.042240</td>\n      <td>-0.050718</td>\n      <td>0.057318</td>\n      <td>-0.078975</td>\n      <td>0.010010</td>\n      <td>-0.026053</td>\n      <td>-0.011060</td>\n      <td>-0.004790</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>139.274723</td>\n      <td>140.184030</td>\n      <td>140.070259</td>\n      <td>39.704137</td>\n      <td>5.761162</td>\n      <td>0.577124</td>\n      <td>-0.518431</td>\n      <td>-0.807961</td>\n      <td>-0.219536</td>\n      <td>...</td>\n      <td>-0.051818</td>\n      <td>0.032123</td>\n      <td>-0.034994</td>\n      <td>0.042277</td>\n      <td>-0.076328</td>\n      <td>0.011880</td>\n      <td>-0.026580</td>\n      <td>-0.008271</td>\n      <td>-0.005162</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>138.676856</td>\n      <td>143.380168</td>\n      <td>143.473350</td>\n      <td>40.663806</td>\n      <td>5.859970</td>\n      <td>0.588245</td>\n      <td>-0.513443</td>\n      <td>-0.810437</td>\n      <td>-0.247007</td>\n      <td>...</td>\n      <td>-0.057101</td>\n      <td>0.036792</td>\n      <td>-0.033449</td>\n      <td>0.035388</td>\n      <td>-0.067010</td>\n      <td>0.008826</td>\n      <td>-0.025932</td>\n      <td>-0.011778</td>\n      <td>-0.000208</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>140.755171</td>\n      <td>142.872499</td>\n      <td>143.424214</td>\n      <td>40.769824</td>\n      <td>5.919625</td>\n      <td>0.585157</td>\n      <td>-0.517127</td>\n      <td>-0.798512</td>\n      <td>-0.176490</td>\n      <td>...</td>\n      <td>-0.031786</td>\n      <td>0.019955</td>\n      <td>-0.031716</td>\n      <td>0.039832</td>\n      <td>-0.068147</td>\n      <td>0.004500</td>\n      <td>-0.023807</td>\n      <td>-0.012157</td>\n      <td>-0.002940</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_32beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    13090\nST      3982\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.237685  0.106778  0.074513  0.049017  0.164754 -0.043134   \ndw_2    0.237685  1.000000  0.838142  0.502265  0.189472  0.396750 -0.511218   \ndw_3    0.106778  0.838142  1.000000  0.702042  0.287089  0.241283 -0.555562   \ndw_4    0.074513  0.502265  0.702042  1.000000  0.873295 -0.014716 -0.278260   \ndw_5    0.049017  0.189472  0.287089  0.873295  1.000000 -0.124955 -0.026226   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.074357  0.037079  0.066460  0.051749  0.016077 -0.150115  0.112145   \ncfr_13 -0.049488  0.134331  0.043879  0.026810  0.019832  0.073383 -0.006052   \ncfr_14 -0.067248  0.012952 -0.017784 -0.031360 -0.039655 -0.001977  0.028472   \ncfr_15 -0.103371 -0.116243 -0.133008 -0.111832 -0.062702  0.047377  0.081087   \ncfr_16 -0.094220 -0.070422 -0.045069 -0.044385 -0.031614  0.064713 -0.029821   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.066522 -0.005085  0.007374  ... -0.101746 -0.045780 -0.057627   \ndw_2   -0.362148  0.007304  0.027974  ... -0.110800  0.180227  0.237271   \ndw_3   -0.499643  0.012774  0.016280  ... -0.199872  0.154880  0.275167   \ndw_4   -0.278962  0.008457  0.006416  ... -0.152384  0.071768  0.115122   \ndw_5   -0.049222  0.001954  0.000388  ... -0.063773  0.011881 -0.006932   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.135231 -0.002228  0.004135  ... -0.135005 -0.212171 -0.056621   \ncfr_13  0.015178  0.006819 -0.001301  ...  0.163738  0.044522 -0.209958   \ncfr_14  0.029755  0.005549 -0.006743  ...  0.121685  0.230485  0.039279   \ncfr_15  0.044183  0.001850 -0.014418  ...  0.293341  0.157001 -0.089191   \ncfr_16 -0.008364  0.011768 -0.004271  ...  0.268445  0.129772  0.199429   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.042941 -0.032342 -0.074357 -0.049488 -0.067248 -0.103371 -0.094220  \ndw_2    0.173162  0.054253  0.037079  0.134331  0.012952 -0.116243 -0.070422  \ndw_3    0.120954 -0.052022  0.066460  0.043879 -0.017784 -0.133008 -0.045069  \ndw_4    0.067878 -0.039769  0.051749  0.026810 -0.031360 -0.111832 -0.044385  \ndw_5    0.044290  0.004779  0.016077  0.019832 -0.039655 -0.062702 -0.031614  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.041745  0.071561  1.000000  0.024910  0.010580 -0.361983 -0.228896  \ncfr_13 -0.266707  0.009957  0.024910  1.000000  0.238508  0.156749 -0.141656  \ncfr_14 -0.173963 -0.282881  0.010580  0.238508  1.000000  0.221302 -0.128261  \ncfr_15 -0.138736 -0.062263 -0.361983  0.156749  0.221302  1.000000  0.344573  \ncfr_16  0.174509  0.012025 -0.228896 -0.141656 -0.128261  0.344573  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.237685</td>\n      <td>0.106778</td>\n      <td>0.074513</td>\n      <td>0.049017</td>\n      <td>0.164754</td>\n      <td>-0.043134</td>\n      <td>0.066522</td>\n      <td>-0.005085</td>\n      <td>0.007374</td>\n      <td>...</td>\n      <td>-0.101746</td>\n      <td>-0.045780</td>\n      <td>-0.057627</td>\n      <td>-0.042941</td>\n      <td>-0.032342</td>\n      <td>-0.074357</td>\n      <td>-0.049488</td>\n      <td>-0.067248</td>\n      <td>-0.103371</td>\n      <td>-0.094220</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.237685</td>\n      <td>1.000000</td>\n      <td>0.838142</td>\n      <td>0.502265</td>\n      <td>0.189472</td>\n      <td>0.396750</td>\n      <td>-0.511218</td>\n      <td>-0.362148</td>\n      <td>0.007304</td>\n      <td>0.027974</td>\n      <td>...</td>\n      <td>-0.110800</td>\n      <td>0.180227</td>\n      <td>0.237271</td>\n      <td>0.173162</td>\n      <td>0.054253</td>\n      <td>0.037079</td>\n      <td>0.134331</td>\n      <td>0.012952</td>\n      <td>-0.116243</td>\n      <td>-0.070422</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.106778</td>\n      <td>0.838142</td>\n      <td>1.000000</td>\n      <td>0.702042</td>\n      <td>0.287089</td>\n      <td>0.241283</td>\n      <td>-0.555562</td>\n      <td>-0.499643</td>\n      <td>0.012774</td>\n      <td>0.016280</td>\n      <td>...</td>\n      <td>-0.199872</td>\n      <td>0.154880</td>\n      <td>0.275167</td>\n      <td>0.120954</td>\n      <td>-0.052022</td>\n      <td>0.066460</td>\n      <td>0.043879</td>\n      <td>-0.017784</td>\n      <td>-0.133008</td>\n      <td>-0.045069</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.074513</td>\n      <td>0.502265</td>\n      <td>0.702042</td>\n      <td>1.000000</td>\n      <td>0.873295</td>\n      <td>-0.014716</td>\n      <td>-0.278260</td>\n      <td>-0.278962</td>\n      <td>0.008457</td>\n      <td>0.006416</td>\n      <td>...</td>\n      <td>-0.152384</td>\n      <td>0.071768</td>\n      <td>0.115122</td>\n      <td>0.067878</td>\n      <td>-0.039769</td>\n      <td>0.051749</td>\n      <td>0.026810</td>\n      <td>-0.031360</td>\n      <td>-0.111832</td>\n      <td>-0.044385</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.049017</td>\n      <td>0.189472</td>\n      <td>0.287089</td>\n      <td>0.873295</td>\n      <td>1.000000</td>\n      <td>-0.124955</td>\n      <td>-0.026226</td>\n      <td>-0.049222</td>\n      <td>0.001954</td>\n      <td>0.000388</td>\n      <td>...</td>\n      <td>-0.063773</td>\n      <td>0.011881</td>\n      <td>-0.006932</td>\n      <td>0.044290</td>\n      <td>0.004779</td>\n      <td>0.016077</td>\n      <td>0.019832</td>\n      <td>-0.039655</td>\n      <td>-0.062702</td>\n      <td>-0.031614</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.074357</td>\n      <td>0.037079</td>\n      <td>0.066460</td>\n      <td>0.051749</td>\n      <td>0.016077</td>\n      <td>-0.150115</td>\n      <td>0.112145</td>\n      <td>0.135231</td>\n      <td>-0.002228</td>\n      <td>0.004135</td>\n      <td>...</td>\n      <td>-0.135005</td>\n      <td>-0.212171</td>\n      <td>-0.056621</td>\n      <td>0.041745</td>\n      <td>0.071561</td>\n      <td>1.000000</td>\n      <td>0.024910</td>\n      <td>0.010580</td>\n      <td>-0.361983</td>\n      <td>-0.228896</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.049488</td>\n      <td>0.134331</td>\n      <td>0.043879</td>\n      <td>0.026810</td>\n      <td>0.019832</td>\n      <td>0.073383</td>\n      <td>-0.006052</td>\n      <td>0.015178</td>\n      <td>0.006819</td>\n      <td>-0.001301</td>\n      <td>...</td>\n      <td>0.163738</td>\n      <td>0.044522</td>\n      <td>-0.209958</td>\n      <td>-0.266707</td>\n      <td>0.009957</td>\n      <td>0.024910</td>\n      <td>1.000000</td>\n      <td>0.238508</td>\n      <td>0.156749</td>\n      <td>-0.141656</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.067248</td>\n      <td>0.012952</td>\n      <td>-0.017784</td>\n      <td>-0.031360</td>\n      <td>-0.039655</td>\n      <td>-0.001977</td>\n      <td>0.028472</td>\n      <td>0.029755</td>\n      <td>0.005549</td>\n      <td>-0.006743</td>\n      <td>...</td>\n      <td>0.121685</td>\n      <td>0.230485</td>\n      <td>0.039279</td>\n      <td>-0.173963</td>\n      <td>-0.282881</td>\n      <td>0.010580</td>\n      <td>0.238508</td>\n      <td>1.000000</td>\n      <td>0.221302</td>\n      <td>-0.128261</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.103371</td>\n      <td>-0.116243</td>\n      <td>-0.133008</td>\n      <td>-0.111832</td>\n      <td>-0.062702</td>\n      <td>0.047377</td>\n      <td>0.081087</td>\n      <td>0.044183</td>\n      <td>0.001850</td>\n      <td>-0.014418</td>\n      <td>...</td>\n      <td>0.293341</td>\n      <td>0.157001</td>\n      <td>-0.089191</td>\n      <td>-0.138736</td>\n      <td>-0.062263</td>\n      <td>-0.361983</td>\n      <td>0.156749</td>\n      <td>0.221302</td>\n      <td>1.000000</td>\n      <td>0.344573</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.094220</td>\n      <td>-0.070422</td>\n      <td>-0.045069</td>\n      <td>-0.044385</td>\n      <td>-0.031614</td>\n      <td>0.064713</td>\n      <td>-0.029821</td>\n      <td>-0.008364</td>\n      <td>0.011768</td>\n      <td>-0.004271</td>\n      <td>...</td>\n      <td>0.268445</td>\n      <td>0.129772</td>\n      <td>0.199429</td>\n      <td>0.174509</td>\n      <td>0.012025</td>\n      <td>-0.228896</td>\n      <td>-0.141656</td>\n      <td>-0.128261</td>\n      <td>0.344573</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows Ã— 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_226', 'fft_256', 'fft_143', 'fft_159', 'fft_240', 'fft_137', 'fft_247', 'mfw_16', 'fft_132', 'fft_212', 'fft_181', 'fft_161', 'fft_234', 'fft_190', 'fft_231', 'fft_149', 'fft_233', 'fft_146', 'fft_179', 'fft_171', 'mfw_12', 'fft_227', 'mfw_7', 'fft_155', 'fft_157', 'fft_180', 'fft_183', 'fft_172', 'fft_253', 'fft_139', 'fft_220', 'fft_136', 'fft_186', 'fft_168', 'fft_176', 'fft_178', 'fft_169', 'fft_236', 'fft_202', 'fft_173', 'fft_167', 'fft_153', 'fft_145', 'fft_150', 'fft_170', 'fft_207', 'fft_222', 'fft_191', 'fft_188', 'fft_134', 'fft_177', 'fft_200', 'fft_194', 'fft_225', 'fft_203', 'mfw_15', 'mfw_5', 'fft_252', 'fft_249', 'fft_242', 'fft_148', 'fft_211', 'fft_187', 'fft_205', 'fft_214', 'fft_156', 'fft_228', 'fft_162', 'fft_160', 'fft_250', 'mfw_13', 'fft_199', 'fft_217', 'fft_164', 'fft_147', 'fft_255', 'fft_154', 'cfr_16', 'fft_248', 'fft_166', 'fft_213', 'fft_130', 'fft_219', 'fft_158', 'fft_238', 'fft_175', 'fft_210', 'mfw_9', 'fft_197', 'fft_204', 'fft_229', 'fft_251', 'mfw_8', 'fft_196', 'fft_243', 'fft_216', 'fft_141', 'fft_193', 'fft_140', 'fft_208', 'fft_185', 'fft_206', 'fft_254', 'mfw_10', 'fft_184', 'fft_230', 'fft_165', 'fft_131', 'fft_135', 'fft_163', 'fft_174', 'fft_189', 'fft_223', 'fft_201', 'fft_133', 'fft_224', 'fft_151', 'fft_221', 'fft_209', 'fft_246', 'fft_182', 'fft_241', 'fft_198', 'fft_244', 'mfw_6', 'fft_232', 'fft_215', 'fft_195', 'fft_218', 'fft_237', 'fft_138', 'fft_152', 'fft_144', 'fft_142', 'fft_239', 'fft_235', 'mfw_14', 'fft_245', 'fft_192', 'mfw_11'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_25\n",
      "fft_26\n",
      "fft_29\n",
      "fft_30\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "fft_37\n",
      "fft_38\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_13\n",
      "ar_14\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 75\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         dw_1        dw_2        dw_3       dw_4      dw_5     mfw_1  \\\n0  133.429003  134.242162  133.489322  37.853305  5.508392  0.586324   \n1  133.965830  136.903950  136.743215  38.927755  5.696305  0.593533   \n2  139.274723  140.184030  140.070259  39.704137  5.761162  0.577124   \n3  138.676856  143.380168  143.473350  40.663806  5.859970  0.588245   \n4  140.755171  142.872499  143.424214  40.769824  5.919625  0.585157   \n\n      mfw_2     mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8  \\\n0 -0.522381 -0.788889 -0.136987 -1.009483  ...  0.017932  0.038860 -0.042238   \n1 -0.515953 -0.790798 -0.224475  2.486222  ...  0.014723  0.042961 -0.052676   \n2 -0.518431 -0.807961 -0.219536 -2.150671  ...  0.006243  0.051369 -0.051818   \n3 -0.513443 -0.810437 -0.247007 -4.289119  ...  0.014157  0.055342 -0.057101   \n4 -0.517127 -0.798512 -0.176490 -1.067047  ...  0.034652  0.022510 -0.031786   \n\n      cfr_9    cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0  0.026644 -0.034630  0.040781 -0.065560  0.001347 -0.022417 -0.007807  \n1  0.042240 -0.050718  0.057318 -0.078975  0.010010 -0.026053 -0.011060  \n2  0.032123 -0.034994  0.042277 -0.076328  0.011880 -0.026580 -0.008271  \n3  0.036792 -0.033449  0.035388 -0.067010  0.008826 -0.025932 -0.011778  \n4  0.019955 -0.031716  0.039832 -0.068147  0.004500 -0.023807 -0.012157  \n\n[5 rows x 75 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>133.429003</td>\n      <td>134.242162</td>\n      <td>133.489322</td>\n      <td>37.853305</td>\n      <td>5.508392</td>\n      <td>0.586324</td>\n      <td>-0.522381</td>\n      <td>-0.788889</td>\n      <td>-0.136987</td>\n      <td>-1.009483</td>\n      <td>...</td>\n      <td>0.017932</td>\n      <td>0.038860</td>\n      <td>-0.042238</td>\n      <td>0.026644</td>\n      <td>-0.034630</td>\n      <td>0.040781</td>\n      <td>-0.065560</td>\n      <td>0.001347</td>\n      <td>-0.022417</td>\n      <td>-0.007807</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>133.965830</td>\n      <td>136.903950</td>\n      <td>136.743215</td>\n      <td>38.927755</td>\n      <td>5.696305</td>\n      <td>0.593533</td>\n      <td>-0.515953</td>\n      <td>-0.790798</td>\n      <td>-0.224475</td>\n      <td>2.486222</td>\n      <td>...</td>\n      <td>0.014723</td>\n      <td>0.042961</td>\n      <td>-0.052676</td>\n      <td>0.042240</td>\n      <td>-0.050718</td>\n      <td>0.057318</td>\n      <td>-0.078975</td>\n      <td>0.010010</td>\n      <td>-0.026053</td>\n      <td>-0.011060</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>139.274723</td>\n      <td>140.184030</td>\n      <td>140.070259</td>\n      <td>39.704137</td>\n      <td>5.761162</td>\n      <td>0.577124</td>\n      <td>-0.518431</td>\n      <td>-0.807961</td>\n      <td>-0.219536</td>\n      <td>-2.150671</td>\n      <td>...</td>\n      <td>0.006243</td>\n      <td>0.051369</td>\n      <td>-0.051818</td>\n      <td>0.032123</td>\n      <td>-0.034994</td>\n      <td>0.042277</td>\n      <td>-0.076328</td>\n      <td>0.011880</td>\n      <td>-0.026580</td>\n      <td>-0.008271</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>138.676856</td>\n      <td>143.380168</td>\n      <td>143.473350</td>\n      <td>40.663806</td>\n      <td>5.859970</td>\n      <td>0.588245</td>\n      <td>-0.513443</td>\n      <td>-0.810437</td>\n      <td>-0.247007</td>\n      <td>-4.289119</td>\n      <td>...</td>\n      <td>0.014157</td>\n      <td>0.055342</td>\n      <td>-0.057101</td>\n      <td>0.036792</td>\n      <td>-0.033449</td>\n      <td>0.035388</td>\n      <td>-0.067010</td>\n      <td>0.008826</td>\n      <td>-0.025932</td>\n      <td>-0.011778</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>140.755171</td>\n      <td>142.872499</td>\n      <td>143.424214</td>\n      <td>40.769824</td>\n      <td>5.919625</td>\n      <td>0.585157</td>\n      <td>-0.517127</td>\n      <td>-0.798512</td>\n      <td>-0.176490</td>\n      <td>-1.067047</td>\n      <td>...</td>\n      <td>0.034652</td>\n      <td>0.022510</td>\n      <td>-0.031786</td>\n      <td>0.019955</td>\n      <td>-0.031716</td>\n      <td>0.039832</td>\n      <td>-0.068147</td>\n      <td>0.004500</td>\n      <td>-0.023807</td>\n      <td>-0.012157</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 75 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 4.212051868438721 s\n",
      "Accuracy 0.9256222547584187 precision 0.9255560986170169 specificity 0.8628407220371807 recall 0.9256222547584187 f1 0.9255887565463421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 4.180998802185059 s\n",
      "Accuracy 0.9238653001464129 precision 0.9240752763410198 specificity 0.863967513924863 recall 0.9238653001464129 f1 0.9239665539462553\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 4.315043210983276 s\n",
      "Accuracy 0.9206442166910688 precision 0.9208195835800198 specificity 0.8608938135515702 recall 0.9206442166910688 f1 0.920729350542878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 4.314999580383301 s\n",
      "Accuracy 0.927086383601757 precision 0.9276820943679455 specificity 0.8759090291584455 recall 0.927086383601757 f1 0.9273544421932957\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 4.344000339508057 s\n",
      "Accuracy 0.9326500732064422 precision 0.9324785774775338 specificity 0.8756608284136473 recall 0.9326500732064422 f1 0.9325605025373509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 4.174999237060547 s\n",
      "Accuracy 0.9244509516837481 precision 0.9237173963278279 specificity 0.8580068671568112 recall 0.9244509516837481 f1 0.9240028336450977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 4.266067743301392 s\n",
      "Accuracy 0.9288433382137629 precision 0.9288753122050908 specificity 0.8706287016980824 recall 0.9288433382137629 f1 0.9288592199188225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 4.086066961288452 s\n",
      "Accuracy 0.9338213762811127 precision 0.9337640102744827 specificity 0.8798700157597277 recall 0.9338213762811127 f1 0.9337922694070868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 4.252999782562256 s\n",
      "Accuracy 0.9238653001464129 precision 0.9251577685027198 specificity 0.8732260487878136 recall 0.9238653001464129 f1 0.9244063883500566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 4.120030164718628 s\n",
      "Accuracy 0.9320644216691069 precision 0.9323178806550474 specificity 0.8799608984587701 recall 0.9320644216691069 f1 0.9321844128764784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 4.090000867843628 s\n",
      "Accuracy 0.9256222547584187 precision 0.9259863777815817 specificity 0.8648993502469038 recall 0.9256222547584187 f1 0.9257937812127308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 4.090050935745239 s\n",
      "Accuracy 0.9247437774524158 precision 0.9242324056464012 specificity 0.8567279675936248 recall 0.9247437774524158 f1 0.9244576682754814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 4.189556360244751 s\n",
      "Accuracy 0.9370424597364568 precision 0.936511217292374 specificity 0.8719173124328915 recall 0.9370424597364568 f1 0.9367279922868184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 4.150999069213867 s\n",
      "Accuracy 0.9273792093704246 precision 0.9277074385706268 specificity 0.8756978730601485 recall 0.9273792093704246 f1 0.9275330483427187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 4.185510873794556 s\n",
      "Accuracy 0.9256222547584187 precision 0.9255525583975964 specificity 0.8576793405025598 recall 0.9256222547584187 f1 0.9255869787526713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 4.132001876831055 s\n",
      "Accuracy 0.930307467057101 precision 0.9300214649926658 specificity 0.8705644044472893 recall 0.930307467057101 f1 0.930153902451097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 4.200512170791626 s\n",
      "Accuracy 0.9200585651537335 precision 0.9190762569838751 specificity 0.8398701857238259 recall 0.9200585651537335 f1 0.919451997482366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 4.412998199462891 s\n",
      "Accuracy 0.9297218155197657 precision 0.9295435730470228 specificity 0.8709047147985405 recall 0.9297218155197657 f1 0.929628902480839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 4.259000301361084 s\n",
      "Accuracy 0.9185944363103953 precision 0.9177920998577567 specificity 0.8368121363819608 recall 0.9185944363103953 f1 0.9181320510369566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 4.196044445037842 s\n",
      "Accuracy 0.9218155197657394 precision 0.9225639389340824 specificity 0.8627027241581996 recall 0.9218155197657394 f1 0.9221523679736581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 4.0515546798706055 s\n",
      "Accuracy 0.9232796486090776 precision 0.9234733254035253 specificity 0.8709965359110093 recall 0.9232796486090776 f1 0.9233728647441405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 4.144999027252197 s\n",
      "Accuracy 0.9238653001464129 precision 0.923155652073704 specificity 0.8562660908793428 recall 0.9238653001464129 f1 0.9234401554016272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 4.36704158782959 s\n",
      "Accuracy 0.9288433382137629 precision 0.9291416349946199 specificity 0.8748859671531587 recall 0.9288433382137629 f1 0.9289840328308852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 4.2669994831085205 s\n",
      "Accuracy 0.9226939970717423 precision 0.9227586636968672 specificity 0.8669938881770465 recall 0.9226939970717423 f1 0.9227259252559398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 4.023000001907349 s\n",
      "Accuracy 0.9235724743777453 precision 0.923189915597054 specificity 0.8621238639208612 recall 0.9235724743777453 f1 0.9233638514913535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 4.136998653411865 s\n",
      "Accuracy 0.91800878477306 precision 0.9187439583437237 specificity 0.85532869644107 recall 0.91800878477306 f1 0.9183431102709826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 4.220999479293823 s\n",
      "Accuracy 0.9224011713030746 precision 0.9229588378738429 specificity 0.8653135626731177 recall 0.9224011713030746 f1 0.9226568919720557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 4.155999422073364 s\n",
      "Accuracy 0.9238653001464129 precision 0.9231635007374211 specificity 0.8572412544640907 recall 0.9238653001464129 f1 0.9234443140984322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 4.035999059677124 s\n",
      "Accuracy 0.9250366032210835 precision 0.9255709316253068 specificity 0.8777738649572392 recall 0.9250366032210835 f1 0.9252780661106222\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 4.068512678146362 s\n",
      "Accuracy 0.9232796486090776 precision 0.9226631467852153 specificity 0.8576925177043078 recall 0.9232796486090776 f1 0.9229213940480203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 4.379998207092285 s\n",
      "Accuracy 0.9244509516837481 precision 0.9241230205586214 specificity 0.855264325366352 recall 0.9244509516837481 f1 0.9242763772566915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 4.194027662277222 s\n",
      "Accuracy 0.9194729136163983 precision 0.9205257399583656 specificity 0.8593608006874576 recall 0.9194729136163983 f1 0.9199348823704782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 4.281999588012695 s\n",
      "Accuracy 0.9332357247437775 precision 0.9326107320952988 specificity 0.8733480990247459 recall 0.9332357247437775 f1 0.9328404903942736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 4.094826936721802 s\n",
      "Accuracy 0.9308931185944364 precision 0.9306572706669204 specificity 0.8701651040104552 recall 0.9308931185944364 f1 0.9307683745035421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 4.276661396026611 s\n",
      "Accuracy 0.9317715959004392 precision 0.9324050739052828 specificity 0.8853944443268665 recall 0.9317715959004392 f1 0.9320508382847033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 4.154450178146362 s\n",
      "Accuracy 0.9212298682284041 precision 0.9206461002205079 specificity 0.8585538782594595 recall 0.9212298682284041 f1 0.9208932525409715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 4.115017890930176 s\n",
      "Accuracy 0.9200585651537335 precision 0.9191601565039115 specificity 0.8483614685706189 recall 0.9200585651537335 f1 0.9194969687871758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 4.007512331008911 s\n",
      "Accuracy 0.9282576866764275 precision 0.9275012988760637 specificity 0.8583946471576915 recall 0.9282576866764275 f1 0.9277896368805094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 4.045513153076172 s\n",
      "Accuracy 0.9326500732064422 precision 0.9329739995263276 specificity 0.8802907784000652 recall 0.9326500732064422 f1 0.9328014383730503\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 4.052096366882324 s\n",
      "Accuracy 0.9267935578330894 precision 0.9275084999419526 specificity 0.8765366369858589 recall 0.9267935578330894 f1 0.927109875884985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 4.098025560379028 s\n",
      "Accuracy 0.9320644216691069 precision 0.9316398021264551 specificity 0.8788470196286418 recall 0.9320644216691069 f1 0.9318187235739074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 4.07088041305542 s\n",
      "Accuracy 0.934407027818448 precision 0.9337060266120547 specificity 0.8678810975582849 recall 0.934407027818448 f1 0.9339586007908873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 4.024171829223633 s\n",
      "Accuracy 0.9335285505124451 precision 0.9330699691325277 specificity 0.8767284299599667 recall 0.9335285505124451 f1 0.9332612697620338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 4.054041385650635 s\n",
      "Accuracy 0.930307467057101 precision 0.930852369341198 specificity 0.8798402807535398 recall 0.930307467057101 f1 0.9305531704267072\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 4.061000108718872 s\n",
      "Accuracy 0.926207906295754 precision 0.9255745241101715 specificity 0.8619443621642491 recall 0.926207906295754 f1 0.925831260790105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 4.036045074462891 s\n",
      "Accuracy 0.9194729136163983 precision 0.9194351975080445 specificity 0.8471275792642151 recall 0.9194729136163983 f1 0.9194539503652346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 3.9790499210357666 s\n",
      "Accuracy 0.9250366032210835 precision 0.9244142014001477 specificity 0.8574650031186039 recall 0.9250366032210835 f1 0.9246746412281256\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 4.161053419113159 s\n",
      "Accuracy 0.9256222547584187 precision 0.925114602106951 specificity 0.8619344116909811 recall 0.9256222547584187 f1 0.9253347160345784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 4.049000263214111 s\n",
      "Accuracy 0.9288433382137629 precision 0.9282210309650653 specificity 0.8666474772770526 recall 0.9288433382137629 f1 0.9284668646318598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 4.13700008392334 s\n",
      "Accuracy 0.926207906295754 precision 0.9262733936153333 specificity 0.8679065749768965 recall 0.926207906295754 f1 0.9262402339569501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 4.196631908416748 s\n",
      "Accuracy 0.9188872620790629 precision 0.9178290851785291 specificity 0.8468549963387363 recall 0.9188872620790629 f1 0.9181691166473903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 3.988957405090332 s\n",
      "Accuracy 0.9276720351390922 precision 0.9270987266001359 specificity 0.8681185335155541 recall 0.9276720351390922 f1 0.927330851682212\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 4.139020204544067 s\n",
      "Accuracy 0.9265007320644216 precision 0.9262125769309865 specificity 0.859524692635397 recall 0.9265007320644216 f1 0.9263480298449761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 4.030508756637573 s\n",
      "Accuracy 0.9276720351390922 precision 0.9268964579564842 specificity 0.8515148171995492 recall 0.9276720351390922 f1 0.927204746168659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 4.062018156051636 s\n",
      "Accuracy 0.9288433382137629 precision 0.9288752493240878 specificity 0.8708071640621825 recall 0.9288433382137629 f1 0.9288591885504507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 4.039559602737427 s\n",
      "Accuracy 0.92298682284041 precision 0.9227535727702544 specificity 0.855967165211157 recall 0.92298682284041 f1 0.9228650636025627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 4.119999647140503 s\n",
      "Accuracy 0.9297218155197657 precision 0.9310032074651833 specificity 0.8862344925617797 recall 0.9297218155197657 f1 0.9302431559927183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 4.041026830673218 s\n",
      "Accuracy 0.9215226939970718 precision 0.9212687637047675 specificity 0.8589633598453835 recall 0.9215226939970718 f1 0.9213891741617358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 4.109997987747192 s\n",
      "Accuracy 0.931185944363104 precision 0.9310934982658048 specificity 0.8713262746007279 recall 0.931185944363104 f1 0.9311387593199603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 3.9458978176116943 s\n",
      "Accuracy 0.9297218155197657 precision 0.9289791339947928 specificity 0.862153259507244 recall 0.9297218155197657 f1 0.9292544902897241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 4.146017789840698 s\n",
      "Accuracy 0.9247437774524158 precision 0.9240872779056477 specificity 0.8608760481826537 recall 0.9247437774524158 f1 0.9243510462538634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 4.247326374053955 s\n",
      "Accuracy 0.9256222547584187 precision 0.925759066111954 specificity 0.865351585799945 recall 0.9256222547584187 f1 0.9256889864713339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 4.616613149642944 s\n",
      "Accuracy 0.9361639824304538 precision 0.936470526353878 specificity 0.8872389271204633 recall 0.9361639824304538 f1 0.9363066012243991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 4.05525279045105 s\n",
      "Accuracy 0.927086383601757 precision 0.9276225238053506 specificity 0.8722965583134064 recall 0.927086383601757 f1 0.9273309745323703\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 4.0160253047943115 s\n",
      "Accuracy 0.9250366032210835 precision 0.9244842207274201 specificity 0.8615730505069491 recall 0.9250366032210835 f1 0.9247190001815084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 4.126550674438477 s\n",
      "Accuracy 0.9200585651537335 precision 0.9195249201338256 specificity 0.859028625436812 recall 0.9200585651537335 f1 0.9197554648589126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 4.151511907577515 s\n",
      "Accuracy 0.9285505124450951 precision 0.9281642482179195 specificity 0.8689365097351787 recall 0.9285505124450951 f1 0.9283369396487066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 4.09403395652771 s\n",
      "Accuracy 0.9267935578330894 precision 0.92633703816788 specificity 0.8711687959680803 recall 0.9267935578330894 f1 0.9265323942462694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 4.020042657852173 s\n",
      "Accuracy 0.9250366032210835 precision 0.9247296825994759 specificity 0.8618666269607761 recall 0.9250366032210835 f1 0.9248727226878235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 4.085000276565552 s\n",
      "Accuracy 0.9308931185944364 precision 0.9300367292796689 specificity 0.8613821986070446 recall 0.9308931185944364 f1 0.9303098879441627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 4.058000087738037 s\n",
      "Accuracy 0.92298682284041 precision 0.922490072779757 specificity 0.8586924207032404 recall 0.92298682284041 f1 0.9227086600538916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 4.05660343170166 s\n",
      "Accuracy 0.9247437774524158 precision 0.9243692591745345 specificity 0.8645156118069733 recall 0.9247437774524158 f1 0.9245391563018908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 4.064051866531372 s\n",
      "Accuracy 0.9226939970717423 precision 0.9221552660167172 specificity 0.8457138303488806 recall 0.9226939970717423 f1 0.9223971359253207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 4.101999998092651 s\n",
      "Accuracy 0.927086383601757 precision 0.9260520831306904 specificity 0.849952840556868 recall 0.927086383601757 f1 0.9263697733082268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 4.124048948287964 s\n",
      "Accuracy 0.9267935578330894 precision 0.9261911385437637 specificity 0.8609693829990466 recall 0.9267935578330894 f1 0.9264414707499133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 4.069998502731323 s\n",
      "Accuracy 0.9203513909224011 precision 0.9196777612594431 specificity 0.854534464839355 recall 0.9203513909224011 f1 0.919955868261135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 4.111508369445801 s\n",
      "Accuracy 0.9256222547584187 precision 0.9258874689806417 specificity 0.8719006937389627 recall 0.9256222547584187 f1 0.9257483034647501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 4.050518751144409 s\n",
      "Accuracy 0.934407027818448 precision 0.933511052368681 specificity 0.8626883680238872 recall 0.934407027818448 f1 0.9337467191637084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 4.090024948120117 s\n",
      "Accuracy 0.935285505124451 precision 0.9353160801865145 specificity 0.8781697431657662 recall 0.935285505124451 f1 0.9353006840000251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 4.057996511459351 s\n",
      "Accuracy 0.934407027818448 precision 0.9347800949818613 specificity 0.8867679318429775 recall 0.934407027818448 f1 0.9345784253843894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 4.1350486278533936 s\n",
      "Accuracy 0.9232796486090776 precision 0.9230332523561603 specificity 0.8625979165643964 recall 0.9232796486090776 f1 0.9231498849504686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 4.027509450912476 s\n",
      "Accuracy 0.9238653001464129 precision 0.9232942413954753 specificity 0.8582017125954466 recall 0.9238653001464129 f1 0.923538265727347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 3.9900312423706055 s\n",
      "Accuracy 0.9273792093704246 precision 0.9275626330243469 specificity 0.8781760103937011 recall 0.9273792093704246 f1 0.9274672720709545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 4.127513408660889 s\n",
      "Accuracy 0.930307467057101 precision 0.9301870221291602 specificity 0.8719565474094451 recall 0.930307467057101 f1 0.9302455540799534\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 4.17902135848999 s\n",
      "Accuracy 0.9358711566617862 precision 0.935487724503334 specificity 0.8771704346582861 recall 0.9358711566617862 f1 0.9356551815652101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 4.043059825897217 s\n",
      "Accuracy 0.9276720351390922 precision 0.9274138214286722 specificity 0.8700266448311197 recall 0.9276720351390922 f1 0.9275345439429296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 4.112201452255249 s\n",
      "Accuracy 0.9244509516837481 precision 0.9241526915124778 specificity 0.8641690911735828 recall 0.9244509516837481 f1 0.9242915368237705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 4.321079254150391 s\n",
      "Accuracy 0.9159590043923865 precision 0.9157174806453993 specificity 0.8490198482122566 recall 0.9159590043923865 f1 0.9158332755565199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 4.230531692504883 s\n",
      "Accuracy 0.9285505124450951 precision 0.928260906660383 specificity 0.8686788710853567 recall 0.9285505124450951 f1 0.9283952345857209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 4.163000106811523 s\n",
      "Accuracy 0.9212298682284041 precision 0.9209900486147871 specificity 0.8523393443828053 recall 0.9212298682284041 f1 0.921104836654284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 4.085091829299927 s\n",
      "Accuracy 0.9218155197657394 precision 0.9215726649506507 specificity 0.8513252428644774 recall 0.9218155197657394 f1 0.9216889289791657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 4.113103628158569 s\n",
      "Accuracy 0.9338213762811127 precision 0.9341582005170936 specificity 0.8775491275395996 recall 0.9338213762811127 f1 0.9339789416029451\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 3.982999801635742 s\n",
      "Accuracy 0.9253294289897511 precision 0.925361053527684 specificity 0.8696115809205839 recall 0.9253294289897511 f1 0.9253451387856951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 4.110072135925293 s\n",
      "Accuracy 0.9341142020497804 precision 0.9338960045691214 specificity 0.88627880168447 recall 0.9341142020497804 f1 0.9339967931704247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 3.983926296234131 s\n",
      "Accuracy 0.9253294289897511 precision 0.9253608687375469 specificity 0.8701262077097319 recall 0.9253294289897511 f1 0.9253450465872919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 4.096765041351318 s\n",
      "Accuracy 0.9282576866764275 precision 0.9285520744573549 specificity 0.8756763477403985 recall 0.9282576866764275 f1 0.9283964983193687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 4.088046073913574 s\n",
      "Accuracy 0.9259150805270864 precision 0.9265537386148541 specificity 0.8685272553345694 recall 0.9259150805270864 f1 0.9262040881796387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 4.109452247619629 s\n",
      "Accuracy 0.9291361639824305 precision 0.9290191550135647 specificity 0.873838272372233 recall 0.9291361639824305 f1 0.9290759990943139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 4.063592195510864 s\n",
      "Accuracy 0.9238653001464129 precision 0.9242801855044845 specificity 0.8705021112782739 recall 0.9238653001464129 f1 0.9240580809073161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 4.061050891876221 s\n",
      "Accuracy 0.9235724743777453 precision 0.9225417618462441 specificity 0.8498928068608964 recall 0.9235724743777453 f1 0.9228631653322469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 4.028071880340576 s\n",
      "Accuracy 0.9253294289897511 precision 0.9264344357119088 specificity 0.8686555470371085 recall 0.9253294289897511 f1 0.9258051484701216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 4.048062324523926 s\n",
      "Accuracy 0.9267935578330894 precision 0.9267935578330894 specificity 0.868978010602991 recall 0.9267935578330894 f1 0.9267935578330894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 4.076040744781494 s\n",
      "Accuracy 0.9332357247437775 precision 0.9339926480024342 specificity 0.886512564601286 recall 0.9332357247437775 f1 0.9335632305709017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 3.960071563720703 s\n",
      "Accuracy 0.9285505124450951 precision 0.9280250863635288 specificity 0.8671340290021582 recall 0.9285505124450951 f1 0.9282460075582641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 4.0543248653411865 s\n",
      "Accuracy 0.927086383601757 precision 0.9267600270429038 specificity 0.8649069242376312 recall 0.927086383601757 f1 0.9269105248280091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 4.018020153045654 s\n",
      "Accuracy 0.9247437774524158 precision 0.9245820256057746 specificity 0.8616247819506245 recall 0.9247437774524158 f1 0.9246602904568261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 4.136560440063477 s\n",
      "Accuracy 0.9247437774524158 precision 0.9245175098656454 specificity 0.8597706955861237 recall 0.9247437774524158 f1 0.9246255006795877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 4.0268073081970215 s\n",
      "Accuracy 0.9259150805270864 precision 0.9263085206086302 specificity 0.8677731023415514 recall 0.9259150805270864 f1 0.9260991413412791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 4.097999572753906 s\n",
      "Accuracy 0.9308931185944364 precision 0.9311410766563691 specificity 0.8810637997808232 recall 0.9308931185944364 f1 0.9310104649877875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 4.077998399734497 s\n",
      "Accuracy 0.9203513909224011 precision 0.9202851094485296 specificity 0.8598133971936918 recall 0.9203513909224011 f1 0.9203178437852602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 4.054047346115112 s\n",
      "Accuracy 0.9267935578330894 precision 0.9277720158257343 specificity 0.8770803242888483 recall 0.9267935578330894 f1 0.9272129569671335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 4.07101845741272 s\n",
      "Accuracy 0.9294289897510981 precision 0.9290209836144138 specificity 0.8695240939397552 recall 0.9294289897510981 f1 0.9292014142004262\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 4.065027236938477 s\n",
      "Accuracy 0.9329428989751098 precision 0.9329131190198683 specificity 0.8772142781337032 recall 0.9329428989751098 f1 0.9329279026369275\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 4.123510360717773 s\n",
      "Accuracy 0.9297218155197657 precision 0.9295450127757695 specificity 0.8716109858029887 recall 0.9297218155197657 f1 0.929629632719807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 4.169042110443115 s\n",
      "Accuracy 0.9370424597364568 precision 0.9367907596847331 specificity 0.8764347592986405 recall 0.9370424597364568 f1 0.936907687972326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 4.2165281772613525 s\n",
      "Accuracy 0.9185944363103953 precision 0.9180656017089849 specificity 0.8460716974707927 recall 0.9185944363103953 f1 0.918303441633575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 4.0670270919799805 s\n",
      "Accuracy 0.9215226939970718 precision 0.9204854842889715 specificity 0.8458887915667574 recall 0.9215226939970718 f1 0.9208364442640455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 4.265001058578491 s\n",
      "Accuracy 0.9279648609077599 precision 0.9277937457615177 specificity 0.8734754510197708 recall 0.9279648609077599 f1 0.9278756071201165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 4.229029893875122 s\n",
      "Accuracy 0.9265007320644216 precision 0.9257135741435112 specificity 0.8581854406585608 recall 0.9265007320644216 f1 0.9260060486295205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 4.163909196853638 s\n",
      "Accuracy 0.9235724743777453 precision 0.9238743746592013 specificity 0.8704102384195108 recall 0.9235724743777453 f1 0.9237152160933162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 4.231999397277832 s\n",
      "Accuracy 0.9241581259150805 precision 0.9245942302378434 specificity 0.874241312484358 recall 0.9241581259150805 f1 0.924359153566759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 4.133999586105347 s\n",
      "Accuracy 0.9279648609077599 precision 0.9277739696476743 specificity 0.8638071070747697 recall 0.9279648609077599 f1 0.9278655818591544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 4.1670637130737305 s\n",
      "Accuracy 0.922108345534407 precision 0.9219839062531985 specificity 0.8647401863921389 recall 0.922108345534407 f1 0.9220445074805194\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 4.190019369125366 s\n",
      "Accuracy 0.9282576866764275 precision 0.9281661084272589 specificity 0.8706466095026982 recall 0.9282576866764275 f1 0.9282109584506657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 4.0129992961883545 s\n",
      "Accuracy 0.9288433382137629 precision 0.9282002552406611 specificity 0.8586950606907118 recall 0.9288433382137629 f1 0.9284647850269463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 4.059001207351685 s\n",
      "Accuracy 0.9276720351390922 precision 0.9274657998402118 specificity 0.8696482214707709 recall 0.9276720351390922 f1 0.927563829485925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 4.12501859664917 s\n",
      "Accuracy 0.9308931185944364 precision 0.931281419929898 specificity 0.8810570484300716 recall 0.9308931185944364 f1 0.9310722811390297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 4.179001092910767 s\n",
      "Accuracy 0.9326500732064422 precision 0.932481682573577 specificity 0.8771878589116925 recall 0.9326500732064422 f1 0.932562078920356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 4.078018426895142 s\n",
      "Accuracy 0.9256222547584187 precision 0.9255599301439742 specificity 0.868336591514071 recall 0.9256222547584187 f1 0.9255906806229196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 4.124059438705444 s\n",
      "Accuracy 0.9291361639824305 precision 0.9290744231076421 specificity 0.8710742897735817 recall 0.9291361639824305 f1 0.9291048731718875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 4.093029260635376 s\n",
      "Accuracy 0.9250366032210835 precision 0.9253910290546724 specificity 0.8671616710918616 recall 0.9250366032210835 f1 0.9252034212407267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 4.008998870849609 s\n",
      "Accuracy 0.9247437774524158 precision 0.9248452399280245 specificity 0.8649729193528886 recall 0.9247437774524158 f1 0.924793573762231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 4.0259997844696045 s\n",
      "Accuracy 0.9300146412884334 precision 0.9299833643714664 specificity 0.8713370789105365 recall 0.9300146412884334 f1 0.9299988968969873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 3.9472436904907227 s\n",
      "Accuracy 0.9235724743777453 precision 0.9236795929255162 specificity 0.8589895760481993 recall 0.9235724743777453 f1 0.923625088419119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 3.9559977054595947 s\n",
      "Accuracy 0.9267935578330894 precision 0.9272741463381331 specificity 0.8748973335145 recall 0.9267935578330894 f1 0.9270136771536146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 4.203027248382568 s\n",
      "Accuracy 0.9238653001464129 precision 0.9236091703825243 specificity 0.8592957022975175 recall 0.9238653001464129 f1 0.9237305614611987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 4.06050968170166 s\n",
      "Accuracy 0.9241581259150805 precision 0.9249457699641864 specificity 0.8710175782335233 recall 0.9241581259150805 f1 0.9245066514534237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 4.04200005531311 s\n",
      "Accuracy 0.9320644216691069 precision 0.9325903108465267 specificity 0.8841434504285774 recall 0.9320644216691069 f1 0.93230064765845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 4.019510269165039 s\n",
      "Accuracy 0.9282576866764275 precision 0.9280974079861238 specificity 0.8642294265486313 recall 0.9282576866764275 f1 0.9281748800279898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 4.0455121994018555 s\n",
      "Accuracy 0.927086383601757 precision 0.9268248546848701 specificity 0.8686537766408703 recall 0.927086383601757 f1 0.9269472336512045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 4.021043062210083 s\n",
      "Accuracy 0.922108345534407 precision 0.9229580598669361 specificity 0.867547368518603 recall 0.922108345534407 f1 0.9224837056005161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 4.044998645782471 s\n",
      "Accuracy 0.9294289897510981 precision 0.9290395321563895 specificity 0.8733123119769887 recall 0.9294289897510981 f1 0.9292110319192202\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 3.9569997787475586 s\n",
      "Accuracy 0.9346998535871157 precision 0.9342492209127251 specificity 0.8716310355734925 recall 0.9346998535871157 f1 0.9344430822270832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 4.053000450134277 s\n",
      "Accuracy 0.926207906295754 precision 0.9264787709778811 specificity 0.8703654669366582 recall 0.926207906295754 f1 0.9263367080596598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 3.9919984340667725 s\n",
      "Accuracy 0.926207906295754 precision 0.9260117439884293 specificity 0.8603541771938601 recall 0.926207906295754 f1 0.9261060035321259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 4.065027713775635 s\n",
      "Accuracy 0.9194729136163983 precision 0.9198633905110489 specificity 0.8642701794487287 recall 0.9194729136163983 f1 0.9196560147876074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 4.094508409500122 s\n",
      "Accuracy 0.9224011713030746 precision 0.9230870509427085 specificity 0.8715685566917173 recall 0.9224011713030746 f1 0.9227077335517331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 4.019027948379517 s\n",
      "Accuracy 0.9235724743777453 precision 0.9228120148148563 specificity 0.8566610741814912 recall 0.9235724743777453 f1 0.9231052544975812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 4.015000104904175 s\n",
      "Accuracy 0.9332357247437775 precision 0.9340729614703576 specificity 0.8871197039809822 recall 0.9332357247437775 f1 0.933593711000873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 4.083998918533325 s\n",
      "Accuracy 0.9241581259150805 precision 0.924908215926282 specificity 0.8755060546723055 recall 0.9241581259150805 f1 0.924488637703497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 4.1139750480651855 s\n",
      "Accuracy 0.9226939970717423 precision 0.9222695804056573 specificity 0.8581022232802956 recall 0.9226939970717423 f1 0.9224615510692676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 4.0740296840667725 s\n",
      "Accuracy 0.9218155197657394 precision 0.921258588541039 specificity 0.8560100359464651 recall 0.9218155197657394 f1 0.9214999036136463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 4.031999588012695 s\n",
      "Accuracy 0.9259150805270864 precision 0.9267334337851836 specificity 0.8685693908037185 recall 0.9259150805270864 f1 0.926277816338396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 4.186002016067505 s\n",
      "Accuracy 0.9235724743777453 precision 0.9239466031346975 specificity 0.8709134327207617 recall 0.9235724743777453 f1 0.9237472787900388\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 4.0970189571380615 s\n",
      "Accuracy 0.9235724743777453 precision 0.9234691417404179 specificity 0.8568376191164421 recall 0.9235724743777453 f1 0.9235198603363715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 4.009000062942505 s\n",
      "Accuracy 0.9224011713030746 precision 0.9230780885982693 specificity 0.8601549966280496 recall 0.9224011713030746 f1 0.9227093557088821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 4.071223258972168 s\n",
      "Accuracy 0.9282576866764275 precision 0.9282876093052722 specificity 0.8760504565214483 recall 0.9282576866764275 f1 0.928272545445358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 4.048999786376953 s\n",
      "Accuracy 0.9244509516837481 precision 0.9245170648945465 specificity 0.8660165874577419 recall 0.9244509516837481 f1 0.9244835957067037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 4.08396315574646 s\n",
      "Accuracy 0.931185944363104 precision 0.9306270414935074 specificity 0.8713498123451431 recall 0.931185944363104 f1 0.9308509913243901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 4.244999647140503 s\n",
      "Accuracy 0.9224011713030746 precision 0.9227491859783215 specificity 0.8557329881559849 recall 0.9224011713030746 f1 0.9225666225957819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 4.16700005531311 s\n",
      "Accuracy 0.9185944363103953 precision 0.9182369590004741 specificity 0.8437309509677329 recall 0.9185944363103953 f1 0.9184052027581014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 4.207001209259033 s\n",
      "Accuracy 0.931185944363104 precision 0.9309886970932983 specificity 0.8751643570638276 recall 0.931185944363104 f1 0.9310821825103562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 4.190032005310059 s\n",
      "Accuracy 0.9282576866764275 precision 0.9277223398390338 specificity 0.8619952044151978 recall 0.9282576866764275 f1 0.9279516397739734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 4.106998682022095 s\n",
      "Accuracy 0.9265007320644216 precision 0.9265940863048578 specificity 0.873504808689703 recall 0.9265007320644216 f1 0.9265464896258627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 4.186999559402466 s\n",
      "Accuracy 0.9212298682284041 precision 0.9211293086632446 specificity 0.8582947225144099 recall 0.9212298682284041 f1 0.9211786634918944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 4.385024070739746 s\n",
      "Accuracy 0.9273792093704246 precision 0.9271496140683505 specificity 0.8707959402628053 recall 0.9273792093704246 f1 0.9272578174431911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 4.4210522174835205 s\n",
      "Accuracy 0.927086383601757 precision 0.927266928346114 specificity 0.8617913778475914 recall 0.927086383601757 f1 0.9271739694342456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 4.5165112018585205 s\n",
      "Accuracy 0.9279648609077599 precision 0.9278986014721425 specificity 0.8639058999752097 recall 0.9279648609077599 f1 0.9279313039008548\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 4.450944423675537 s\n",
      "Accuracy 0.9267935578330894 precision 0.9262632909323884 specificity 0.865709929503258 recall 0.9267935578330894 f1 0.9264870299402346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 4.030054092407227 s\n",
      "Accuracy 0.9323572474377745 precision 0.9319575191055134 specificity 0.872415920857457 recall 0.9323572474377745 f1 0.9321334546835466\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 4.063030004501343 s\n",
      "Accuracy 0.9294289897510981 precision 0.9292153803368076 specificity 0.8673810691944159 recall 0.9294289897510981 f1 0.9293169726159201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 4.148278474807739 s\n",
      "Accuracy 0.9241581259150805 precision 0.9238796819041701 specificity 0.8616776953069349 recall 0.9241581259150805 f1 0.9240105132108809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 4.13853645324707 s\n",
      "Accuracy 0.927086383601757 precision 0.9273231040807983 specificity 0.8701042874887955 recall 0.927086383601757 f1 0.9271996270518057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 4.0469970703125 s\n",
      "Accuracy 0.9446559297218156 precision 0.9448994882317868 specificity 0.9014429623911611 recall 0.9446559297218156 f1 0.9447688764597751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 4.1400463581085205 s\n",
      "Accuracy 0.9306002928257686 precision 0.9305142125766985 specificity 0.8771604433705503 recall 0.9306002928257686 f1 0.9305563179087775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 4.17702841758728 s\n",
      "Accuracy 0.9209370424597365 precision 0.921075617920473 specificity 0.8613551447799769 recall 0.9209370424597365 f1 0.9210046983552985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 4.112048149108887 s\n",
      "Accuracy 0.9346998535871157 precision 0.9350900049523768 specificity 0.8906574927109224 recall 0.9346998535871157 f1 0.9348774042352366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 4.01402473449707 s\n",
      "Accuracy 0.9191800878477306 precision 0.9199113005856054 specificity 0.8567207630586698 recall 0.9191800878477306 f1 0.9195122620065418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 4.2020263671875 s\n",
      "Accuracy 0.9320644216691069 precision 0.9321273248233528 specificity 0.8748799234847565 recall 0.9320644216691069 f1 0.932095445986677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 4.1590540409088135 s\n",
      "Accuracy 0.9212298682284041 precision 0.9210761595063813 specificity 0.8644127577540277 recall 0.9212298682284041 f1 0.9211505017074013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 4.112862825393677 s\n",
      "Accuracy 0.9253294289897511 precision 0.9247251529583079 specificity 0.8570305596329328 recall 0.9253294289897511 f1 0.9249808242307055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 4.047999858856201 s\n",
      "Accuracy 0.9156661786237189 precision 0.91590420409368 specificity 0.8460727191196603 recall 0.9156661786237189 f1 0.915781488430806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 4.026999235153198 s\n",
      "Accuracy 0.9323572474377745 precision 0.9325694498200373 specificity 0.882918448047816 recall 0.9323572474377745 f1 0.9324582450844394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 4.142027139663696 s\n",
      "Accuracy 0.9273792093704246 precision 0.9284835748595853 specificity 0.8748719935338904 recall 0.9273792093704246 f1 0.927849071704332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 4.153001308441162 s\n",
      "Accuracy 0.9346998535871157 precision 0.934553629988993 specificity 0.8756839535530431 recall 0.9346998535871157 f1 0.9346240314628559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 4.12007737159729 s\n",
      "Accuracy 0.9206442166910688 precision 0.9193725933343017 specificity 0.8359681694089617 recall 0.9206442166910688 f1 0.9197519282422794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 3.9526631832122803 s\n",
      "Accuracy 0.9212298682284041 precision 0.9212625712507629 specificity 0.8642223372238013 recall 0.9212298682284041 f1 0.921246118744886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 4.127998352050781 s\n",
      "Accuracy 0.927086383601757 precision 0.9270547435566733 specificity 0.8687110730562799 recall 0.927086383601757 f1 0.9270704593636767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 4.120342016220093 s\n",
      "Accuracy 0.9306002928257686 precision 0.9300214203135595 specificity 0.8626343071373818 recall 0.9306002928257686 f1 0.9302631915177019\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 4.164052486419678 s\n",
      "Accuracy 0.9232796486090776 precision 0.9236466754389346 specificity 0.8626245547144805 recall 0.9232796486090776 f1 0.9234527574640261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 4.032999753952026 s\n",
      "Accuracy 0.9276720351390922 precision 0.927702377220016 specificity 0.8745437644755513 recall 0.9276720351390922 f1 0.9276871035553541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 4.085000038146973 s\n",
      "Accuracy 0.9235724743777453 precision 0.9229004789245898 specificity 0.8584903999435244 recall 0.9235724743777453 f1 0.9231720629152781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 4.113059997558594 s\n",
      "Accuracy 0.9285505124450951 precision 0.9288277321456437 specificity 0.8696539517305121 recall 0.9285505124450951 f1 0.9286823312005348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 4.193047523498535 s\n",
      "Accuracy 0.9238653001464129 precision 0.9233068841739686 specificity 0.8524301550392446 recall 0.9238653001464129 f1 0.9235517607283751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 4.1549999713897705 s\n",
      "Accuracy 0.92298682284041 precision 0.9231513929944192 specificity 0.8682300488498111 recall 0.92298682284041 f1 0.9230665750083424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 3.813835859298706 s\n",
      "Accuracy 0.926207906295754 precision 0.9259680973189645 specificity 0.8664652531080516 recall 0.926207906295754 f1 0.926081366702469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 3.800999164581299 s\n",
      "Accuracy 0.9235724743777453 precision 0.9234071128788395 specificity 0.8589210186147825 recall 0.9235724743777453 f1 0.9234871837394619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 3.7552459239959717 s\n",
      "Accuracy 0.9294289897510981 precision 0.9285233081541167 specificity 0.859497243873675 recall 0.9294289897510981 f1 0.9287970724961978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 3.749999523162842 s\n",
      "Accuracy 0.9285505124450951 precision 0.9291086402228881 specificity 0.8764635205586664 recall 0.9285505124450951 f1 0.9288029077433595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 3.7947306632995605 s\n",
      "Accuracy 0.9232796486090776 precision 0.9240109443693892 specificity 0.8718865690270845 recall 0.9232796486090776 f1 0.9236046954698928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 3.756998300552368 s\n",
      "Accuracy 0.9297218155197657 precision 0.9304362033286846 specificity 0.8787703201765638 recall 0.9297218155197657 f1 0.9300370834547983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 3.7560195922851562 s\n",
      "Accuracy 0.9244509516837481 precision 0.9245903987779039 specificity 0.86282301342073 recall 0.9244509516837481 f1 0.9245190031696991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 3.7430429458618164 s\n",
      "Accuracy 0.9320644216691069 precision 0.9319487507261139 specificity 0.8763356807010301 recall 0.9320644216691069 f1 0.9320048977215079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 3.923192262649536 s\n",
      "Accuracy 0.9235724743777453 precision 0.9248313839443205 specificity 0.8791045275394811 recall 0.9235724743777453 f1 0.9240927929593818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 3.7918567657470703 s\n",
      "Accuracy 0.9235724743777453 precision 0.9234164852452863 specificity 0.8643681597415237 recall 0.9235724743777453 f1 0.9234919192259928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 3.84346866607666 s\n",
      "Accuracy 0.926207906295754 precision 0.9260153036562657 specificity 0.8621156828535733 recall 0.926207906295754 f1 0.9261078072051467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 3.7921903133392334 s\n",
      "Accuracy 0.9224011713030746 precision 0.9229415081276263 specificity 0.8683338022551172 recall 0.9224011713030746 f1 0.9226484755026745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 3.7214889526367188 s\n",
      "Accuracy 0.9215226939970718 precision 0.9209471012048601 specificity 0.8485688945197488 recall 0.9215226939970718 f1 0.921200787452287\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 3.7509689331054688 s\n",
      "Accuracy 0.9282576866764275 precision 0.9284140693990723 specificity 0.8759375484539355 recall 0.9282576866764275 f1 0.9283333035813292\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 3.8547403812408447 s\n",
      "Accuracy 0.930307467057101 precision 0.9308166359917538 specificity 0.8855324220526876 recall 0.930307467057101 f1 0.9305359400920674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 3.7760000228881836 s\n",
      "Accuracy 0.9206442166910688 precision 0.9202736461311675 specificity 0.8498870576920031 recall 0.9206442166910688 f1 0.9204462776987948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 3.7290055751800537 s\n",
      "Accuracy 0.9297218155197657 precision 0.9301405784581835 specificity 0.8735342905431444 recall 0.9297218155197657 f1 0.9299159160219145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 3.989999294281006 s\n",
      "Accuracy 0.9259150805270864 precision 0.926509361794867 specificity 0.8752879967395631 recall 0.9259150805270864 f1 0.926182666781798\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 3.979999542236328 s\n",
      "Accuracy 0.9238653001464129 precision 0.9242920100292876 specificity 0.8678976754707098 recall 0.9238653001464129 f1 0.9240638521633177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 3.755070686340332 s\n",
      "Accuracy 0.9250366032210835 precision 0.9260205297299224 specificity 0.8751859052353983 recall 0.9250366032210835 f1 0.9254593473288746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 3.755531072616577 s\n",
      "Accuracy 0.9250366032210835 precision 0.9251664228882035 specificity 0.8698486088021787 recall 0.9250366032210835 f1 0.9250998748554312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 3.775045394897461 s\n",
      "Accuracy 0.9323572474377745 precision 0.9329792295645833 specificity 0.8873416053346921 recall 0.9323572474377745 f1 0.932630845667636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 3.7559995651245117 s\n",
      "Accuracy 0.9197657393850659 precision 0.9197019296060932 specificity 0.8629577039332886 recall 0.9197657393850659 f1 0.9197334342914458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 3.8945112228393555 s\n",
      "Accuracy 0.9285505124450951 precision 0.9282171842366845 specificity 0.87030334657787 recall 0.9285505124450951 f1 0.9283688832068382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 4.009000301361084 s\n",
      "Accuracy 0.9291361639824305 precision 0.9295985568802866 specificity 0.8798916204171888 recall 0.9291361639824305 f1 0.9293471552147617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 4.005871057510376 s\n",
      "Accuracy 0.9247437774524158 precision 0.9245095142012203 specificity 0.8563636084292595 recall 0.9247437774524158 f1 0.9246214420250227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 4.060041904449463 s\n",
      "Accuracy 0.9294289897510981 precision 0.9294619804782502 specificity 0.8680478877923721 recall 0.9294289897510981 f1 0.9294453782102431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 3.920518636703491 s\n",
      "Accuracy 0.9273792093704246 precision 0.9270844620801307 specificity 0.8665966219288431 recall 0.9273792093704246 f1 0.9272213859723722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 3.8496992588043213 s\n",
      "Accuracy 0.9282576866764275 precision 0.9287188093210258 specificity 0.8719662303365432 recall 0.9282576866764275 f1 0.9284704333521911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 4.2060253620147705 s\n",
      "Accuracy 0.9267935578330894 precision 0.9271254915265013 specificity 0.8743296900667704 recall 0.9267935578330894 f1 0.9269492479395911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 4.375021934509277 s\n",
      "Accuracy 0.9282576866764275 precision 0.927901042301207 specificity 0.8569618157959863 recall 0.9282576866764275 f1 0.9280661821919363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 4.155998945236206 s\n",
      "Accuracy 0.92298682284041 precision 0.9235607091874716 specificity 0.8628518903947393 recall 0.92298682284041 f1 0.9232503348140011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 4.14904522895813 s\n",
      "Accuracy 0.9250366032210835 precision 0.9246195303667736 specificity 0.8607105514688905 recall 0.9250366032210835 f1 0.9248076223074729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 4.348231792449951 s\n",
      "Accuracy 0.9212298682284041 precision 0.9214140419077201 specificity 0.8563532060710303 recall 0.9212298682284041 f1 0.9213193537354104\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 4.162619113922119 s\n",
      "Accuracy 0.927086383601757 precision 0.9271181897666145 specificity 0.8701124691707095 recall 0.927086383601757 f1 0.9271021828327247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 4.1080002784729 s\n",
      "Accuracy 0.9267935578330894 precision 0.9264159427657331 specificity 0.8582896690506756 recall 0.9267935578330894 f1 0.9265893489637077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 4.0790252685546875 s\n",
      "Accuracy 0.9256222547584187 precision 0.9251414125030049 specificity 0.8581583359588808 recall 0.9256222547584187 f1 0.9253547990901164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 4.11080527305603 s\n",
      "Accuracy 0.927086383601757 precision 0.9281055038262086 specificity 0.8779078988704376 recall 0.927086383601757 f1 0.9275205996729472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 4.1130335330963135 s\n",
      "Accuracy 0.9185944363103953 precision 0.9194756851331267 specificity 0.8613140183165209 recall 0.9185944363103953 f1 0.9189859571468867\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 4.136678218841553 s\n",
      "Accuracy 0.9224011713030746 precision 0.9224335806624562 specificity 0.8657229472530604 recall 0.9224011713030746 f1 0.922417274561749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 4.184406757354736 s\n",
      "Accuracy 0.9267935578330894 precision 0.9268565359134782 specificity 0.8717515003408876 recall 0.9267935578330894 f1 0.9268246347381082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 4.088057994842529 s\n",
      "Accuracy 0.926207906295754 precision 0.9264168702382947 specificity 0.865845136745652 recall 0.926207906295754 f1 0.9263086024385919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 4.1690027713775635 s\n",
      "Accuracy 0.926207906295754 precision 0.926207906295754 specificity 0.8693453812723807 recall 0.926207906295754 f1 0.926207906295754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 4.0889973640441895 s\n",
      "Accuracy 0.9297218155197657 precision 0.9297858395772951 specificity 0.8719716891959726 recall 0.9297218155197657 f1 0.9297534047719275\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 4.366999626159668 s\n",
      "Accuracy 0.9244509516837481 precision 0.9247992680784337 specificity 0.8684291673810173 recall 0.9244509516837481 f1 0.9246148158361073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 4.1249988079071045 s\n",
      "Accuracy 0.9244509516837481 precision 0.9245193011350372 specificity 0.8628728718023166 recall 0.9244509516837481 f1 0.9244847091597462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 4.121101140975952 s\n",
      "Accuracy 0.9267935578330894 precision 0.9271254915265013 specificity 0.8743296900667704 recall 0.9267935578330894 f1 0.9269492479395911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 4.129736661911011 s\n",
      "Accuracy 0.9250366032210835 precision 0.9251059124757232 specificity 0.8618417955771143 recall 0.9250366032210835 f1 0.925070836950816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 4.168061971664429 s\n",
      "Accuracy 0.930307467057101 precision 0.9299845259652455 specificity 0.8737082291692254 recall 0.930307467057101 f1 0.9301309985144279\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 4.120017766952515 s\n",
      "Accuracy 0.9238653001464129 precision 0.9253146349155296 specificity 0.8833507344416787 recall 0.9238653001464129 f1 0.9244465973639828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 4.084025621414185 s\n",
      "Accuracy 0.9203513909224011 precision 0.9201021927362667 specificity 0.8600932969280384 recall 0.9203513909224011 f1 0.9202203225923488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 4.071507930755615 s\n",
      "Accuracy 0.9212298682284041 precision 0.9210626554851666 specificity 0.8566514993096614 recall 0.9212298682284041 f1 0.9211436820086815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 4.142999887466431 s\n",
      "Accuracy 0.9241581259150805 precision 0.9236776517299715 specificity 0.8524331702236203 recall 0.9241581259150805 f1 0.9238939385135114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 4.047508955001831 s\n",
      "Accuracy 0.9256222547584187 precision 0.9246120005832731 specificity 0.8488490901294417 recall 0.9256222547584187 f1 0.9249456193012543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 4.075045347213745 s\n",
      "Accuracy 0.9241581259150805 precision 0.9237099936477368 specificity 0.8591054767886735 recall 0.9241581259150805 f1 0.9239106468064403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 4.174056529998779 s\n",
      "Accuracy 0.930307467057101 precision 0.9297817155153415 specificity 0.8733238846465492 recall 0.930307467057101 f1 0.929994544175027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 4.117510795593262 s\n",
      "Accuracy 0.9279648609077599 precision 0.9272274269376863 specificity 0.8623128999138495 recall 0.9279648609077599 f1 0.9275016356109135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 4.140547275543213 s\n",
      "Accuracy 0.9279648609077599 precision 0.9280283139562553 specificity 0.871770434533748 recall 0.9279648609077599 f1 0.9279961710335026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 4.136908769607544 s\n",
      "Accuracy 0.9256222547584187 precision 0.9256869777846823 specificity 0.8686379646348485 recall 0.9256222547584187 f1 0.9256542035055122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 4.0721354484558105 s\n",
      "Accuracy 0.9288433382137629 precision 0.9284693691738698 specificity 0.8664427524150207 recall 0.9288433382137629 f1 0.9286385016666286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 4.140049457550049 s\n",
      "Accuracy 0.9218155197657394 precision 0.9222019244262669 specificity 0.866800863732282 recall 0.9218155197657394 f1 0.9219964596507875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 4.039306163787842 s\n",
      "Accuracy 0.9306002928257686 precision 0.9299792027947726 specificity 0.8673474143480304 recall 0.9306002928257686 f1 0.9302236061078931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 4.112490653991699 s\n",
      "Accuracy 0.9267935578330894 precision 0.9270660097878761 specificity 0.870194335085686 recall 0.9267935578330894 f1 0.9269231142611798\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 3.9887537956237793 s\n",
      "Accuracy 0.9215226939970718 precision 0.9214558297755114 specificity 0.8596285204401257 recall 0.9215226939970718 f1 0.9214888513800481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 4.09804630279541 s\n",
      "Accuracy 0.9317715959004392 precision 0.9323697464090269 specificity 0.8788726609689356 recall 0.9317715959004392 f1 0.9320398816712354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 4.133124113082886 s\n",
      "Accuracy 0.9326500732064422 precision 0.9324210899886602 specificity 0.8735522469117435 recall 0.9326500732064422 f1 0.932528741099708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 4.166000843048096 s\n",
      "Accuracy 0.9259150805270864 precision 0.9259500469013396 specificity 0.8604611708357841 recall 0.9259150805270864 f1 0.9259324572488977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 4.10802149772644 s\n",
      "Accuracy 0.9282576866764275 precision 0.9277482814730076 specificity 0.8663175846779848 recall 0.9282576866764275 f1 0.9279652157685515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 4.158000469207764 s\n",
      "Accuracy 0.9282576866764275 precision 0.9276219761177382 specificity 0.8647189569628413 recall 0.9282576866764275 f1 0.9278743670548832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 4.227006196975708 s\n",
      "Accuracy 0.9267935578330894 precision 0.9276524512003917 specificity 0.8798785296481693 recall 0.9267935578330894 f1 0.9271642900655956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 4.240151643753052 s\n",
      "Accuracy 0.9314787701317716 precision 0.9312539849870033 specificity 0.8745744300612259 recall 0.9314787701317716 f1 0.9313596389216288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 4.404000520706177 s\n",
      "Accuracy 0.9282576866764275 precision 0.9276177078776731 specificity 0.8641633734931973 recall 0.9282576866764275 f1 0.9278720987793694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 4.355998992919922 s\n",
      "Accuracy 0.9259150805270864 precision 0.9256978925930502 specificity 0.8641772691855597 recall 0.9259150805270864 f1 0.9258013726452653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 4.575022459030151 s\n",
      "Accuracy 0.9306002928257686 precision 0.9306309362713477 specificity 0.8753825794795891 recall 0.9306002928257686 f1 0.930615509521416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 3.9410464763641357 s\n",
      "Accuracy 0.9256222547584187 precision 0.926432941035898 specificity 0.8746382187700894 recall 0.9256222547584187 f1 0.9259778665117725\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 3.826542377471924 s\n",
      "Accuracy 0.9314787701317716 precision 0.9314787701317716 specificity 0.8788400782087586 recall 0.9314787701317716 f1 0.9314787701317716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 3.7663614749908447 s\n",
      "Accuracy 0.9308931185944364 precision 0.9306606353472441 specificity 0.8714266140687564 recall 0.9308931185944364 f1 0.9307700903049494\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 3.7440085411071777 s\n",
      "Accuracy 0.9332357247437775 precision 0.9341358441004871 specificity 0.8895209355954214 recall 0.9332357247437775 f1 0.9336152106036077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 3.7870209217071533 s\n",
      "Accuracy 0.926207906295754 precision 0.9261457110672886 specificity 0.8688419311526749 recall 0.926207906295754 f1 0.9261763955553034\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 3.8056387901306152 s\n",
      "Accuracy 0.9291361639824305 precision 0.9297881876502666 specificity 0.8752288785481961 recall 0.9291361639824305 f1 0.9294279968253735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 3.7829062938690186 s\n",
      "Accuracy 0.9288433382137629 precision 0.9299559129068197 specificity 0.8871324737066081 recall 0.9288433382137629 f1 0.9293019943049532\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 3.7580654621124268 s\n",
      "Accuracy 0.9279648609077599 precision 0.9280303326874738 specificity 0.8689303399804357 recall 0.9279648609077599 f1 0.9279971758711006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 3.771599292755127 s\n",
      "Accuracy 0.9285505124450951 precision 0.9292531111046579 specificity 0.8793916213704565 recall 0.9285505124450951 f1 0.9288604570433555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 3.7669992446899414 s\n",
      "Accuracy 0.9320644216691069 precision 0.9320644216691069 specificity 0.8757144818544774 recall 0.9320644216691069 f1 0.9320644216691069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 3.7441139221191406 s\n",
      "Accuracy 0.9297218155197657 precision 0.9303503088768333 specificity 0.879014135436299 recall 0.9297218155197657 f1 0.9300022106577907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 3.735706090927124 s\n",
      "Accuracy 0.9314787701317716 precision 0.9316719361084721 specificity 0.8763140763267306 recall 0.9314787701317716 f1 0.9315715353349576\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 3.777714490890503 s\n",
      "Accuracy 0.927086383601757 precision 0.9267739077467337 specificity 0.8686950364653518 recall 0.927086383601757 f1 0.9269176419112065\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 3.703120708465576 s\n",
      "Accuracy 0.9276720351390922 precision 0.9275717704453829 specificity 0.8619032448688371 recall 0.9276720351390922 f1 0.9276209377968662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 3.8459980487823486 s\n",
      "Accuracy 0.9232796486090776 precision 0.9223887762280167 specificity 0.8481370952860374 recall 0.9232796486090776 f1 0.9227257002732429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 3.7890079021453857 s\n",
      "Accuracy 0.922108345534407 precision 0.9220425118374402 specificity 0.861417158914772 recall 0.922108345534407 f1 0.9220750187414077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 3.760030746459961 s\n",
      "Accuracy 0.9136163982430454 precision 0.9135809549162405 specificity 0.8504281672823615 recall 0.9136163982430454 f1 0.9135985770446727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 3.7027699947357178 s\n",
      "Accuracy 0.9279648609077599 precision 0.9289089612002632 specificity 0.8719344012556534 recall 0.9279648609077599 f1 0.9283756606118526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 3.7500052452087402 s\n",
      "Accuracy 0.926207906295754 precision 0.9272106992397903 specificity 0.8743158865185832 recall 0.926207906295754 f1 0.9266390995877613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 3.8210396766662598 s\n",
      "Accuracy 0.9288433382137629 precision 0.9285202252535302 specificity 0.8665789556359043 recall 0.9288433382137629 f1 0.9286689845101956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 3.7241370677948 s\n",
      "Accuracy 0.9244509516837481 precision 0.9246522889151801 specificity 0.8682772876252602 recall 0.9244509516837481 f1 0.9245479251340537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 3.8349993228912354 s\n",
      "Accuracy 0.9308931185944364 precision 0.9306676688078055 specificity 0.8740472148761708 recall 0.9308931185944364 f1 0.9307736768980406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 3.7820656299591064 s\n",
      "Accuracy 0.9300146412884334 precision 0.9294222075225638 specificity 0.8603505623289036 recall 0.9300146412884334 f1 0.9296706094559081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 3.730050563812256 s\n",
      "Accuracy 0.9273792093704246 precision 0.9273159138184991 specificity 0.8678996370426192 recall 0.9273792093704246 f1 0.9273471427546615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 3.785479784011841 s\n",
      "Accuracy 0.9209370424597365 precision 0.9225768888787054 specificity 0.8693157630649893 recall 0.9209370424597365 f1 0.9216095956639191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 3.71290922164917 s\n",
      "Accuracy 0.9317715959004392 precision 0.9326099687432088 specificity 0.8812011173167269 recall 0.9317715959004392 f1 0.9321345707668106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 3.7809524536132812 s\n",
      "Accuracy 0.9285505124450951 precision 0.9290180732506632 specificity 0.8785292950258645 recall 0.9285505124450951 f1 0.9287640852414837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 3.809079885482788 s\n",
      "Accuracy 0.931185944363104 precision 0.9305999765563047 specificity 0.8757839732630738 recall 0.931185944363104 f1 0.9308180632077895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 3.7420706748962402 s\n",
      "Accuracy 0.9226939970717423 precision 0.9221621659237771 specificity 0.8566029388645655 recall 0.9226939970717423 f1 0.9223945493835217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 3.81595778465271 s\n",
      "Accuracy 0.9265007320644216 precision 0.926602625376747 specificity 0.8655811639989889 recall 0.9265007320644216 f1 0.92655073141403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 3.7509994506835938 s\n",
      "Accuracy 0.9241581259150805 precision 0.9252327579636107 specificity 0.8788954746102701 recall 0.9241581259150805 f1 0.9246109838058784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 3.7824199199676514 s\n",
      "Accuracy 0.9235724743777453 precision 0.9236066639967784 specificity 0.8613954886593549 recall 0.9235724743777453 f1 0.9235894651979341\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 3.734452724456787 s\n",
      "Accuracy 0.9200585651537335 precision 0.919949286866878 specificity 0.8492528014877474 recall 0.9200585651537335 f1 0.9200029823199025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 3.824000120162964 s\n",
      "Accuracy 0.9203513909224011 precision 0.9200420590623335 specificity 0.8589067840701587 recall 0.9203513909224011 f1 0.9201865898135403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 3.7567474842071533 s\n",
      "Accuracy 0.9203513909224011 precision 0.9205648243450263 specificity 0.8602437333605817 recall 0.9203513909224011 f1 0.9204544341145331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 3.7204625606536865 s\n",
      "Accuracy 0.9279648609077599 precision 0.9284446990755476 specificity 0.8758426457987862 recall 0.9279648609077599 f1 0.9281844640391225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 3.7621843814849854 s\n",
      "Accuracy 0.9288433382137629 precision 0.9285740440794464 specificity 0.8669063888501983 recall 0.9288433382137629 f1 0.9287001199098133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 3.8359992504119873 s\n",
      "Accuracy 0.9317715959004392 precision 0.931153555701791 specificity 0.8630960595468063 recall 0.9317715959004392 f1 0.9314049898558839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 3.7880420684814453 s\n",
      "Accuracy 0.930307467057101 precision 0.9298758401090109 specificity 0.8695792583170809 recall 0.930307467057101 f1 0.9300646538386841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 3.797999620437622 s\n",
      "Accuracy 0.9335285505124451 precision 0.9340086114363934 specificity 0.8865026805938908 recall 0.9335285505124451 f1 0.9337450261705659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 3.810636281967163 s\n",
      "Accuracy 0.9232796486090776 precision 0.9236211946635102 specificity 0.8694713150266157 recall 0.9232796486090776 f1 0.9234402692249335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 3.763509750366211 s\n",
      "Accuracy 0.9232796486090776 precision 0.9230935120456075 specificity 0.8637995621989467 recall 0.9232796486090776 f1 0.9231828973228575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 3.903047561645508 s\n",
      "Accuracy 0.9244509516837481 precision 0.9240860840574266 specificity 0.8605302129640965 recall 0.9244509516837481 f1 0.9242535384158336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 3.9890599250793457 s\n",
      "Accuracy 0.926207906295754 precision 0.9254844218650404 specificity 0.8597086253834895 recall 0.926207906295754 f1 0.9257641457455752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 3.753922700881958 s\n",
      "Accuracy 0.9308931185944364 precision 0.9303758064044257 specificity 0.8692641123185285 recall 0.9308931185944364 f1 0.9305921526304322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 3.7731845378875732 s\n",
      "Accuracy 0.9276720351390922 precision 0.9274628462287874 specificity 0.8684083633281655 recall 0.9276720351390922 f1 0.9275623288324937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 3.8324196338653564 s\n",
      "Accuracy 0.9238653001464129 precision 0.923999142320222 specificity 0.8663753769735407 recall 0.9238653001464129 f1 0.9239305785080281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 3.849006175994873 s\n",
      "Accuracy 0.9256222547584187 precision 0.9259516029578342 specificity 0.8742426257682646 recall 0.9256222547584187 f1 0.9257767543174305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 3.8130319118499756 s\n",
      "Accuracy 0.92298682284041 precision 0.9233931096110346 specificity 0.8627284395012299 recall 0.92298682284041 f1 0.9231774024406338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 3.7985215187072754 s\n",
      "Accuracy 0.9197657393850659 precision 0.9193769009426747 specificity 0.852402938180913 recall 0.9197657393850659 f1 0.9195564961057123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 3.7972912788391113 s\n",
      "Accuracy 0.9244509516837481 precision 0.9254084525524193 specificity 0.8772014692641636 recall 0.9244509516837481 f1 0.9248613836635277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 3.7385735511779785 s\n",
      "Accuracy 0.9238653001464129 precision 0.9240848402500683 specificity 0.8595356396225786 recall 0.9238653001464129 f1 0.9239712776026756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 3.804056406021118 s\n",
      "Accuracy 0.9250366032210835 precision 0.9259302870148561 specificity 0.8749599278757066 recall 0.9250366032210835 f1 0.9254245305326384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 3.7773280143737793 s\n",
      "Accuracy 0.9297218155197657 precision 0.9303266527749741 specificity 0.8823517497539405 recall 0.9297218155197657 f1 0.9299908480238007\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 3.735999584197998 s\n",
      "Accuracy 0.9317715959004392 precision 0.9316128098889623 specificity 0.8667850019732319 recall 0.9317715959004392 f1 0.9316894736523513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 3.786212921142578 s\n",
      "Accuracy 0.9306002928257686 precision 0.9305130032766508 specificity 0.8760056842276329 recall 0.9306002928257686 f1 0.930555708882724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 3.70200252532959 s\n",
      "Accuracy 0.9253294289897511 precision 0.9258782064302034 specificity 0.8688756549416036 recall 0.9253294289897511 f1 0.9255804096930055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 3.7775204181671143 s\n",
      "Accuracy 0.9218155197657394 precision 0.9223115404150678 specificity 0.8605132632164576 recall 0.9218155197657394 f1 0.922045994855368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 3.7094874382019043 s\n",
      "Accuracy 0.9238653001464129 precision 0.925166902289696 specificity 0.8725404185917813 recall 0.9238653001464129 f1 0.9244106844211497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 3.461430311203003 s\n",
      "Accuracy 0.9226939970717423 precision 0.9226939970717423 specificity 0.8612647558146066 recall 0.9226939970717423 f1 0.9226939970717423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 3.4669439792633057 s\n",
      "Accuracy 0.9209370424597365 precision 0.9205847729032764 specificity 0.8463347926242025 recall 0.9209370424597365 f1 0.9207502994622453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 3.429978609085083 s\n",
      "Accuracy 0.9300146412884334 precision 0.9302272263527869 specificity 0.8812771338846682 recall 0.9300146412884334 f1 0.9301159068287418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 3.5629987716674805 s\n",
      "Accuracy 0.9300146412884334 precision 0.9298313536485184 specificity 0.8803596999599936 recall 0.9300146412884334 f1 0.9299180194523874\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 3.443129777908325 s\n",
      "Accuracy 0.927086383601757 precision 0.9265726558604893 specificity 0.8571562345436288 recall 0.927086383601757 f1 0.9267985315371902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 3.536196231842041 s\n",
      "Accuracy 0.9226939970717423 precision 0.922629692836444 specificity 0.8639118053107728 recall 0.9226939970717423 f1 0.9226614366151056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 3.4339990615844727 s\n",
      "Accuracy 0.9291361639824305 precision 0.9289578157406985 specificity 0.8705628098878125 recall 0.9291361639824305 f1 0.929043212992472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 3.4439990520477295 s\n",
      "Accuracy 0.9300146412884334 precision 0.9298652469248079 specificity 0.8715167792361223 recall 0.9300146412884334 f1 0.9299373077136895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 3.4620003700256348 s\n",
      "Accuracy 0.9267935578330894 precision 0.9279780172452217 specificity 0.8760790382375206 recall 0.9267935578330894 f1 0.9272920532010286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 3.4543445110321045 s\n",
      "Accuracy 0.9285505124450951 precision 0.9281560363001562 specificity 0.8671397376679436 recall 0.9285505124450951 f1 0.9283326947050448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 3.5070295333862305 s\n",
      "Accuracy 0.9288433382137629 precision 0.9285573870139963 specificity 0.8766786593993967 recall 0.9288433382137629 f1 0.9286880554375537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 3.4759981632232666 s\n",
      "Accuracy 0.9250366032210835 precision 0.924968161540003 specificity 0.8592160951129821 recall 0.9250366032210835 f1 0.9250019589936985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 3.4380078315734863 s\n",
      "Accuracy 0.9273792093704246 precision 0.9290675815294239 specificity 0.8789234520306052 recall 0.9273792093704246 f1 0.9280558059324155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 3.492326498031616 s\n",
      "Accuracy 0.9265007320644216 precision 0.9270229869373311 specificity 0.8743082362009775 recall 0.9265007320644216 f1 0.9267386852459508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 3.427999258041382 s\n",
      "Accuracy 0.9206442166910688 precision 0.9210411762408601 specificity 0.8634812584128199 recall 0.9206442166910688 f1 0.9208304096315191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 3.4953625202178955 s\n",
      "Accuracy 0.9232796486090776 precision 0.9230377190832387 specificity 0.8642284060494376 recall 0.9232796486090776 f1 0.923152156059594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 3.3972816467285156 s\n",
      "Accuracy 0.9133235724743778 precision 0.9134722223289611 specificity 0.849843015538836 recall 0.9133235724743778 f1 0.9133963008217758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 3.5259993076324463 s\n",
      "Accuracy 0.9238653001464129 precision 0.9240744682441824 specificity 0.8643390942816178 recall 0.9238653001464129 f1 0.9239661548250228\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 3.5000007152557373 s\n",
      "Accuracy 0.9288433382137629 precision 0.9293582131765241 specificity 0.8772160283188767 recall 0.9288433382137629 f1 0.9290773671404919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 3.478011131286621 s\n",
      "Accuracy 0.9294289897510981 precision 0.9301691814527221 specificity 0.8806337357823112 recall 0.9294289897510981 f1 0.9297532934373556\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 3.6485066413879395 s\n",
      "Accuracy 0.9320644216691069 precision 0.9317936208214237 specificity 0.8759424975982091 recall 0.9320644216691069 f1 0.9319185140052159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 3.4650158882141113 s\n",
      "Accuracy 0.9250366032210835 precision 0.925835291966963 specificity 0.8755585210618995 recall 0.9250366032210835 f1 0.9253866534792159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 3.4505555629730225 s\n",
      "Accuracy 0.9235724743777453 precision 0.9232353116485648 specificity 0.8603525175824265 recall 0.9235724743777453 f1 0.9233913799830713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 3.4685423374176025 s\n",
      "Accuracy 0.922108345534407 precision 0.9221764791999532 specificity 0.8618352139221636 recall 0.922108345534407 f1 0.9221420017751287\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 3.495518207550049 s\n",
      "Accuracy 0.9224011713030746 precision 0.9212406382511974 specificity 0.8411027246091171 recall 0.9224011713030746 f1 0.9216046237022952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 3.5020241737365723 s\n",
      "Accuracy 0.9238653001464129 precision 0.9239344427818224 specificity 0.861419929716929 recall 0.9238653001464129 f1 0.9238994541727081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 3.3470003604888916 s\n",
      "Accuracy 0.9329428989751098 precision 0.9320849842206618 specificity 0.8664069180881141 recall 0.9329428989751098 f1 0.9322979832689853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 3.446859836578369 s\n",
      "Accuracy 0.930307467057101 precision 0.929728224940633 specificity 0.8655166365722435 recall 0.930307467057101 f1 0.9299662720762993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 3.4555108547210693 s\n",
      "Accuracy 0.9338213762811127 precision 0.9337643519456732 specificity 0.8803614886066012 recall 0.9338213762811127 f1 0.933792441124459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 3.444230079650879 s\n",
      "Accuracy 0.9209370424597365 precision 0.9201755303978357 specificity 0.8488885252339865 recall 0.9209370424597365 f1 0.9204858753449344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 3.461862564086914 s\n",
      "Accuracy 0.9197657393850659 precision 0.9209962652382991 specificity 0.8666725173393243 recall 0.9197657393850659 f1 0.9202898792630564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 3.425048828125 s\n",
      "Accuracy 0.9279648609077599 precision 0.9279041691436402 specificity 0.871944447932636 recall 0.9279648609077599 f1 0.9279341004230341\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 3.4703590869903564 s\n",
      "Accuracy 0.9279648609077599 precision 0.9289336868295197 specificity 0.8789107897889673 recall 0.9279648609077599 f1 0.9283791823647932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 3.4690253734588623 s\n",
      "Accuracy 0.9267935578330894 precision 0.9269244083995645 specificity 0.8701920383417521 recall 0.9267935578330894 f1 0.9268573218085139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 3.4885761737823486 s\n",
      "Accuracy 0.9288433382137629 precision 0.929143340174932 specificity 0.8743747315251156 recall 0.9288433382137629 f1 0.9289848683626871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 3.4954051971435547 s\n",
      "Accuracy 0.92298682284041 precision 0.923149822699257 specificity 0.8690814077159483 recall 0.92298682284041 f1 0.9230657977120519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 3.4959983825683594 s\n",
      "Accuracy 0.9185944363103953 precision 0.9197273087133563 specificity 0.8654239049536975 recall 0.9185944363103953 f1 0.919082059913224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 3.481416940689087 s\n",
      "Accuracy 0.9285505124450951 precision 0.9284859749772628 specificity 0.8667187800768238 recall 0.9285505124450951 f1 0.9285178185912484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 3.485999584197998 s\n",
      "Accuracy 0.9218155197657394 precision 0.921421611599787 specificity 0.858701592242953 recall 0.9218155197657394 f1 0.9216012615805035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 3.4469993114471436 s\n",
      "Accuracy 0.9247437774524158 precision 0.9256038057882302 specificity 0.8734863358381108 recall 0.9247437774524158 f1 0.9251195741088483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 3.4589173793792725 s\n",
      "Accuracy 0.9244509516837481 precision 0.9247795210246689 specificity 0.8736705476377433 recall 0.9244509516837481 f1 0.9246051421031047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 3.4828789234161377 s\n",
      "Accuracy 0.927086383601757 precision 0.9266484888287382 specificity 0.8624109311506994 recall 0.927086383601757 f1 0.9268437190659379\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 3.447803497314453 s\n",
      "Accuracy 0.9306002928257686 precision 0.9298580622772494 specificity 0.864049108823257 recall 0.9306002928257686 f1 0.9301267103075831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 3.4205214977264404 s\n",
      "Accuracy 0.9206442166910688 precision 0.9206791531126219 specificity 0.8576360656076494 recall 0.9206442166910688 f1 0.9206615820929608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 3.424685001373291 s\n",
      "Accuracy 0.9224011713030746 precision 0.923301831700769 specificity 0.8672848647817484 recall 0.9224011713030746 f1 0.9227971660409108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 3.4444398880004883 s\n",
      "Accuracy 0.9273792093704246 precision 0.9267020245055245 specificity 0.8563766668285918 recall 0.9273792093704246 f1 0.9269788645890559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 3.415602922439575 s\n",
      "Accuracy 0.927086383601757 precision 0.9272476850491486 specificity 0.8725319551906845 recall 0.927086383601757 f1 0.927164452531561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 3.54355788230896 s\n",
      "Accuracy 0.9338213762811127 precision 0.9337149424326894 specificity 0.8839275414678051 recall 0.9338213762811127 f1 0.9337664967070993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 3.4760000705718994 s\n",
      "Accuracy 0.9300146412884334 precision 0.9295723622536497 specificity 0.8714600383422022 recall 0.9300146412884334 f1 0.9297633472128561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 3.4807474613189697 s\n",
      "Accuracy 0.9358711566617862 precision 0.9362853696699042 specificity 0.8866631868141798 recall 0.9358711566617862 f1 0.9360601980274367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 3.422170400619507 s\n",
      "Accuracy 0.9244509516837481 precision 0.924264807566934 specificity 0.8643999293472372 recall 0.9244509516837481 f1 0.9243541686952209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 3.457000255584717 s\n",
      "Accuracy 0.926207906295754 precision 0.92614267049992 specificity 0.8644801371035339 recall 0.926207906295754 f1 0.9261748685944959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 3.4618451595306396 s\n",
      "Accuracy 0.9279648609077599 precision 0.9280836652885059 specificity 0.8791377162318531 recall 0.9279648609077599 f1 0.9280226422144288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 3.5329995155334473 s\n",
      "Accuracy 0.9341142020497804 precision 0.9339736284474129 specificity 0.8787470640615811 recall 0.9341142020497804 f1 0.9340412545614848\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 3.461134910583496 s\n",
      "Accuracy 0.9265007320644216 precision 0.9259944702036803 specificity 0.8661527534224959 recall 0.9265007320644216 f1 0.9262103655572018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 3.3835525512695312 s\n",
      "Accuracy 0.9317715959004392 precision 0.9323970959070791 specificity 0.8864433935876432 recall 0.9317715959004392 f1 0.9320470212316663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 3.4665536880493164 s\n",
      "Accuracy 0.9253294289897511 precision 0.925171231649973 specificity 0.8639986868673352 recall 0.9253294289897511 f1 0.9252477282981925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 3.4434568881988525 s\n",
      "Accuracy 0.9308931185944364 precision 0.9305588460007836 specificity 0.871099433257458 recall 0.9308931185944364 f1 0.9307107498616013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 3.448016881942749 s\n",
      "Accuracy 0.9329428989751098 precision 0.9329148912060373 specificity 0.8822627042357782 recall 0.9329428989751098 f1 0.9329287909622817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 3.4441182613372803 s\n",
      "Accuracy 0.9288433382137629 precision 0.929277652764094 specificity 0.8778106840932668 recall 0.9288433382137629 f1 0.929042991361293\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 3.5400516986846924 s\n",
      "Accuracy 0.9238653001464129 precision 0.9237354651702107 specificity 0.8618101992631734 recall 0.9238653001464129 f1 0.923798723679776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 3.447998285293579 s\n",
      "Accuracy 0.9215226939970718 precision 0.9214559623082101 specificity 0.8598175882427606 recall 0.9215226939970718 f1 0.9214889179110267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 3.519005537033081 s\n",
      "Accuracy 0.9206442166910688 precision 0.9208159084961329 specificity 0.8629086031939309 recall 0.9206442166910688 f1 0.9207275305758496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 3.4950082302093506 s\n",
      "Accuracy 0.9291361639824305 precision 0.9288443463286327 specificity 0.8682806643363302 recall 0.9291361639824305 f1 0.9289797099297152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 3.4689996242523193 s\n",
      "Accuracy 0.9215226939970718 precision 0.9220140633077184 specificity 0.8692639971068336 recall 0.9215226939970718 f1 0.92174869049264\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 3.512000560760498 s\n",
      "Accuracy 0.9215226939970718 precision 0.9208569909073973 specificity 0.8499821113215031 recall 0.9215226939970718 f1 0.9211392497604511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 3.46600079536438 s\n",
      "Accuracy 0.9235724743777453 precision 0.9234071128788395 specificity 0.8589210186147825 recall 0.9235724743777453 f1 0.9234871837394619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 3.369291067123413 s\n",
      "Accuracy 0.9294289897510981 precision 0.9289015467232681 specificity 0.8637283339378712 recall 0.9294289897510981 f1 0.929126745141823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 3.535301446914673 s\n",
      "Accuracy 0.9317715959004392 precision 0.9315320750623411 specificity 0.8781571904511212 recall 0.9317715959004392 f1 0.9316434157722892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 3.429847002029419 s\n",
      "Accuracy 0.9320644216691069 precision 0.9323257511603625 specificity 0.8772839107518015 recall 0.9320644216691069 f1 0.9321882729433856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 3.457156181335449 s\n",
      "Accuracy 0.9259150805270864 precision 0.9257473348109585 specificity 0.8586650156623329 recall 0.9259150805270864 f1 0.9258285426195733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 3.4823851585388184 s\n",
      "Accuracy 0.9300146412884334 precision 0.9293190912748234 specificity 0.862036482314091 recall 0.9300146412884334 f1 0.9295887001520168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 3.4210102558135986 s\n",
      "Accuracy 0.9267935578330894 precision 0.9281331409477761 specificity 0.8797438863588034 recall 0.9267935578330894 f1 0.9273441726524737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 3.5095410346984863 s\n",
      "Accuracy 0.9358711566617862 precision 0.9357393742646212 specificity 0.8847823823538769 recall 0.9358711566617862 f1 0.9358026285008735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 3.3982045650482178 s\n",
      "Accuracy 0.9165446559297218 precision 0.9168865640386249 specificity 0.8539602166577285 recall 0.9165446559297218 f1 0.9167074070439066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 3.5459978580474854 s\n",
      "Accuracy 0.9147877013177159 precision 0.9149016315217845 specificity 0.8475593225553611 recall 0.9147877013177159 f1 0.9148437526902906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 3.4318783283233643 s\n",
      "Accuracy 0.9267935578330894 precision 0.9270037659298915 specificity 0.8656173918626922 recall 0.9267935578330894 f1 0.9268948529832736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 3.493598461151123 s\n",
      "Accuracy 0.9250366032210835 precision 0.9247426560995566 specificity 0.8657275071528129 recall 0.9250366032210835 f1 0.9248793527402229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 3.4570140838623047 s\n",
      "Accuracy 0.9226939970717423 precision 0.9220498771431437 specificity 0.8592754897521137 recall 0.9226939970717423 f1 0.922313103587737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 3.3799386024475098 s\n",
      "Accuracy 0.9282576866764275 precision 0.9281056225548272 specificity 0.8690676538624343 recall 0.9282576866764275 f1 0.9281790349795158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 3.4539902210235596 s\n",
      "Accuracy 0.9224011713030746 precision 0.9217199918028112 specificity 0.8513273181806728 recall 0.9224011713030746 f1 0.9220051765652387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 3.4590370655059814 s\n",
      "Accuracy 0.9323572474377745 precision 0.9322112950522634 specificity 0.8747078070337654 recall 0.9323572474377745 f1 0.9322816108849342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 3.47194766998291 s\n",
      "Accuracy 0.9285505124450951 precision 0.9282480565156517 specificity 0.8647999205788521 recall 0.9285505124450951 f1 0.9283886564500692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 3.4465107917785645 s\n",
      "Accuracy 0.9273792093704246 precision 0.9268816574628554 specificity 0.8710316892076755 recall 0.9273792093704246 f1 0.9270896567953839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 3.4779953956604004 s\n",
      "Accuracy 0.9285505124450951 precision 0.928435990514711 specificity 0.8753052584196336 recall 0.9285505124450951 f1 0.9284916091849064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 3.4404945373535156 s\n",
      "Accuracy 0.9244509516837481 precision 0.9248606043390952 specificity 0.8720411187532728 recall 0.9244509516837481 f1 0.9246411264840387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 3.4100663661956787 s\n",
      "Accuracy 0.9250366032210835 precision 0.9242749910155117 specificity 0.854887720331426 recall 0.9250366032210835 f1 0.9245731889029588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 3.4268481731414795 s\n",
      "Accuracy 0.9332357247437775 precision 0.9333676607909226 specificity 0.8731682562232785 recall 0.9332357247437775 f1 0.9332999483222223\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 3.5189578533172607 s\n",
      "Accuracy 0.9285505124450951 precision 0.9281706895660904 specificity 0.8703385827051381 recall 0.9285505124450951 f1 0.9283402691920877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 3.4559993743896484 s\n",
      "Accuracy 0.9247437774524158 precision 0.9250545778994558 specificity 0.8685180210016626 recall 0.9247437774524158 f1 0.9248908283179764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 3.610997438430786 s\n",
      "Accuracy 0.926207906295754 precision 0.926207906295754 specificity 0.8702139941639279 recall 0.926207906295754 f1 0.926207906295754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 3.444596529006958 s\n",
      "Accuracy 0.927086383601757 precision 0.9271863029223751 specificity 0.8677704550864256 recall 0.927086383601757 f1 0.9271353986567455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 3.4359982013702393 s\n",
      "Accuracy 0.9267935578330894 precision 0.9265581848270634 specificity 0.8683857720394922 recall 0.9267935578330894 f1 0.9266692502130138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 3.4640376567840576 s\n",
      "Accuracy 0.9253294289897511 precision 0.9244767051535753 specificity 0.8507780735417246 recall 0.9253294289897511 f1 0.9248003541442895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 3.436000347137451 s\n",
      "Accuracy 0.9306002928257686 precision 0.9301007046846554 specificity 0.8688123149919875 recall 0.9306002928257686 f1 0.9303123135322948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 3.5345075130462646 s\n",
      "Accuracy 0.9250366032210835 precision 0.9253131034489953 specificity 0.8677156571767466 recall 0.9250366032210835 f1 0.9251682257639771\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 3.4069154262542725 s\n",
      "Accuracy 0.9206442166910688 precision 0.9212186293938013 specificity 0.8611732845752438 recall 0.9206442166910688 f1 0.9209083214670004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 3.391000509262085 s\n",
      "Accuracy 0.9346998535871157 precision 0.934338544709168 specificity 0.8718014245908997 recall 0.9346998535871157 f1 0.934500742454583\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 3.4090065956115723 s\n",
      "Accuracy 0.9349926793557833 precision 0.9357079754820249 specificity 0.8925156168412764 recall 0.9349926793557833 f1 0.9352998401447674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 3.499155044555664 s\n",
      "Accuracy 0.9218155197657394 precision 0.922216757194019 specificity 0.8632067828261836 recall 0.9218155197657394 f1 0.9220037197117062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 3.461874008178711 s\n",
      "Accuracy 0.9232796486090776 precision 0.9229280519149671 specificity 0.8633042110073378 recall 0.9232796486090776 f1 0.9230891579156002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 3.34601092338562 s\n",
      "Accuracy 0.9253294289897511 precision 0.9253592575866357 specificity 0.8745692655512661 recall 0.9253294289897511 f1 0.9253442427226105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 3.458542823791504 s\n",
      "Accuracy 0.9226939970717423 precision 0.9226939970717423 specificity 0.867889653791372 recall 0.9226939970717423 f1 0.9226939970717423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 3.4180009365081787 s\n",
      "Accuracy 0.9297218155197657 precision 0.9299093418495131 specificity 0.8778101327917929 recall 0.9297218155197657 f1 0.9298118462067679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 3.422598123550415 s\n",
      "Accuracy 0.9241581259150805 precision 0.9236277242442702 specificity 0.8529984935565295 recall 0.9241581259150805 f1 0.9238622643261039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 3.5070526599884033 s\n",
      "Accuracy 0.9308931185944364 precision 0.9320381598857513 specificity 0.8899428466802328 recall 0.9308931185944364 f1 0.9313606639903407\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 3.455357313156128 s\n",
      "Accuracy 0.9241581259150805 precision 0.9234488445220059 specificity 0.8586784427969048 recall 0.9241581259150805 f1 0.9237281524860977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 3.522012233734131 s\n",
      "Accuracy 0.9267935578330894 precision 0.9271502815826846 specificity 0.8676590708020372 recall 0.9267935578330894 f1 0.9269613797329734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 3.4304347038269043 s\n",
      "Accuracy 0.927086383601757 precision 0.9265348169552645 specificity 0.8656235285777937 recall 0.927086383601757 f1 0.9267648719386438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 3.478052854537964 s\n",
      "Accuracy 0.9244509516837481 precision 0.9238186457766333 specificity 0.8558266360155836 recall 0.9244509516837481 f1 0.924083995814653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 3.407233715057373 s\n",
      "Accuracy 0.9265007320644216 precision 0.9276164406815625 specificity 0.8774076329441922 recall 0.9265007320644216 f1 0.9269717873703294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 3.5059125423431396 s\n",
      "Accuracy 0.9241581259150805 precision 0.9245534011776335 specificity 0.8661848189583119 recall 0.9241581259150805 f1 0.9243432266547189\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 3.4717557430267334 s\n",
      "Accuracy 0.9241581259150805 precision 0.9237811676887959 specificity 0.8636842730591605 recall 0.9241581259150805 f1 0.9239523164293957\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 3.35560941696167 s\n",
      "Accuracy 0.9279648609077599 precision 0.9284685925766343 specificity 0.8713445483905508 recall 0.9279648609077599 f1 0.9281960523570402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 3.434002637863159 s\n",
      "Accuracy 0.9247437774524158 precision 0.9252872408030033 specificity 0.8694050685430796 recall 0.9247437774524158 f1 0.9249922680754735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 3.4632925987243652 s\n",
      "Accuracy 0.9279648609077599 precision 0.9281510806475618 specificity 0.8772982920442882 recall 0.9279648609077599 f1 0.9280542897447741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 3.5390913486480713 s\n",
      "Accuracy 0.9224011713030746 precision 0.9231872990433976 specificity 0.8699029523539162 recall 0.9224011713030746 f1 0.9227494445592205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 3.513036012649536 s\n",
      "Accuracy 0.9232796486090776 precision 0.9230342524717797 specificity 0.8629637689902722 recall 0.9232796486090776 f1 0.9231503934630343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 3.509049654006958 s\n",
      "Accuracy 0.9209370424597365 precision 0.9209370424597365 specificity 0.8620432253497448 recall 0.9209370424597365 f1 0.9209370424597365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 3.5350005626678467 s\n",
      "Accuracy 0.9238653001464129 precision 0.9229923123437759 specificity 0.8461492154527381 recall 0.9238653001464129 f1 0.9233322380492218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 3.693027973175049 s\n",
      "Accuracy 0.9306002928257686 precision 0.9305152345920372 specificity 0.8781324052303656 recall 0.9306002928257686 f1 0.9305568326106448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 3.5260000228881836 s\n",
      "Accuracy 0.9156661786237189 precision 0.915884003950333 specificity 0.8553584096495661 recall 0.9156661786237189 f1 0.9157714932389841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 3.5679996013641357 s\n",
      "Accuracy 0.9235724743777453 precision 0.9229749255608283 specificity 0.8499490309985989 recall 0.9235724743777453 f1 0.9232352529300281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 3.5860517024993896 s\n",
      "Accuracy 0.9267935578330894 precision 0.9267935578330894 specificity 0.8668107503793198 recall 0.9267935578330894 f1 0.9267935578330894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 3.5359997749328613 s\n",
      "Accuracy 0.926207906295754 precision 0.9259030301958987 specificity 0.863018389367365 recall 0.926207906295754 f1 0.9260449871995384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 3.584435224533081 s\n",
      "Accuracy 0.9276720351390922 precision 0.9278403322047628 specificity 0.8690194026071196 recall 0.9276720351390922 f1 0.9277535533947057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 3.567514657974243 s\n",
      "Accuracy 0.9317715959004392 precision 0.9315215135754934 specificity 0.874664452684595 recall 0.9317715959004392 f1 0.9316380145128411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 3.461998701095581 s\n",
      "Accuracy 0.9232796486090776 precision 0.9220439154202373 specificity 0.8431785543563778 recall 0.9232796486090776 f1 0.9223049439671445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 3.628419876098633 s\n",
      "Accuracy 0.934407027818448 precision 0.9345941084506304 specificity 0.8808901007781578 recall 0.934407027818448 f1 0.9344967132239602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 3.508117437362671 s\n",
      "Accuracy 0.9212298682284041 precision 0.921619686082354 specificity 0.8655918335210055 recall 0.9212298682284041 f1 0.9214125216337952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 3.5910370349884033 s\n",
      "Accuracy 0.9273792093704246 precision 0.9264348744829333 specificity 0.8549197882836594 recall 0.9273792093704246 f1 0.9267366094870959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 3.597052574157715 s\n",
      "Accuracy 0.9209370424597365 precision 0.9217732003900063 specificity 0.8682312175785044 recall 0.9209370424597365 f1 0.9213062360913604\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 3.4550013542175293 s\n",
      "Accuracy 0.9256222547584187 precision 0.9252364139715886 specificity 0.8556964568036516 recall 0.9256222547584187 f1 0.9254139504927472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 3.6718227863311768 s\n",
      "Accuracy 0.931185944363104 precision 0.9312181837255101 specificity 0.8711611892879336 recall 0.931185944363104 f1 0.9312019566570108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 3.523216962814331 s\n",
      "Accuracy 0.9259150805270864 precision 0.9259498392773765 specificity 0.8610589186703342 recall 0.9259150805270864 f1 0.9259323536609583\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 3.564512252807617 s\n",
      "Accuracy 0.9259150805270864 precision 0.9262260356640235 specificity 0.8692180667539783 recall 0.9259150805270864 f1 0.9260621443370076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 3.562378168106079 s\n",
      "Accuracy 0.9171303074670571 precision 0.9189300072809513 specificity 0.8667856963682423 recall 0.9171303074670571 f1 0.9178621912223349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 3.477998733520508 s\n",
      "Accuracy 0.9209370424597365 precision 0.9204120606372147 specificity 0.8477487243812487 recall 0.9209370424597365 f1 0.9206476214584708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 3.483999252319336 s\n",
      "Accuracy 0.9276720351390922 precision 0.9281194716840305 specificity 0.8743647016763676 recall 0.9276720351390922 f1 0.9278781988932012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 3.35500431060791 s\n",
      "Accuracy 0.9267935578330894 precision 0.9259049316074266 specificity 0.8553859139003925 recall 0.9267935578330894 f1 0.9262117039180332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 3.548002243041992 s\n",
      "Accuracy 0.927086383601757 precision 0.9266736281818657 specificity 0.8675631313360599 recall 0.927086383601757 f1 0.9268567324138189\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 3.5476739406585693 s\n",
      "Accuracy 0.9185944363103953 precision 0.918220071447359 specificity 0.8554464074639376 recall 0.9185944363103953 f1 0.9183927082375106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 3.4797513484954834 s\n",
      "Accuracy 0.9226939970717423 precision 0.923054613025379 specificity 0.863987747946315 recall 0.9226939970717423 f1 0.9228640018226903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 3.5370194911956787 s\n",
      "Accuracy 0.9332357247437775 precision 0.9337340855936443 specificity 0.8893534060242451 recall 0.9332357247437775 f1 0.9334584919576123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 3.5396907329559326 s\n",
      "Accuracy 0.9215226939970718 precision 0.922340127342166 specificity 0.8707969221402627 recall 0.9215226939970718 f1 0.9218827366211866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 3.786513090133667 s\n",
      "Accuracy 0.9224011713030746 precision 0.9222368654446221 specificity 0.8589434375926015 recall 0.9224011713030746 f1 0.9223164338916039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 3.8690528869628906 s\n",
      "Accuracy 0.9267935578330894 precision 0.9269269720068096 specificity 0.8684105513542194 recall 0.9267935578330894 f1 0.9268585924729502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 3.7863337993621826 s\n",
      "Accuracy 0.9226939970717423 precision 0.9226284058649598 specificity 0.8620827872413864 recall 0.9226939970717423 f1 0.9226607904999602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 3.776906967163086 s\n",
      "Accuracy 0.9367496339677892 precision 0.9365884521994964 specificity 0.8827440369182868 recall 0.9367496339677892 f1 0.9366651823453448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 3.6919989585876465 s\n",
      "Accuracy 0.927086383601757 precision 0.926723254946357 specificity 0.8682151704837178 recall 0.927086383601757 f1 0.9268873525722107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 3.7440876960754395 s\n",
      "Accuracy 0.9203513909224011 precision 0.92015507709058 specificity 0.8573714525567977 recall 0.9203513909224011 f1 0.9202495565012316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 3.7034449577331543 s\n",
      "Accuracy 0.926207906295754 precision 0.9256191445678873 specificity 0.8562330062152025 recall 0.926207906295754 f1 0.9258709180186993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 3.7320451736450195 s\n",
      "Accuracy 0.9188872620790629 precision 0.919347523154343 specificity 0.8658136000373531 recall 0.9188872620790629 f1 0.9191005847025961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 3.7860262393951416 s\n",
      "Accuracy 0.9279648609077599 precision 0.9276622414506943 specificity 0.8644911257397987 recall 0.9279648609077599 f1 0.9278029659904311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 3.739002227783203 s\n",
      "Accuracy 0.9282576866764275 precision 0.9283556524783201 specificity 0.8702752099485851 recall 0.9282576866764275 f1 0.9283057239324723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 3.7829973697662354 s\n",
      "Accuracy 0.9267935578330894 precision 0.9267297440554515 specificity 0.8668414194656318 recall 0.9267935578330894 f1 0.9267612326155862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 3.7219998836517334 s\n",
      "Accuracy 0.9244509516837481 precision 0.9248575587028941 specificity 0.8727057259944019 recall 0.9244509516837481 f1 0.9246396403694317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 3.7209980487823486 s\n",
      "Accuracy 0.9306002928257686 precision 0.9304467018173092 specificity 0.869331280976773 recall 0.9306002928257686 f1 0.9305208241870949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 3.728806495666504 s\n",
      "Accuracy 0.935285505124451 precision 0.9346587362828505 specificity 0.8718985633661502 recall 0.935285505124451 f1 0.9348931996750537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 3.7324211597442627 s\n",
      "Accuracy 0.927086383601757 precision 0.92821701352531 specificity 0.8843110536103185 recall 0.927086383601757 f1 0.9275545257951188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 3.7633438110351562 s\n",
      "Accuracy 0.9282576866764275 precision 0.9280063937658979 specificity 0.8725801491914699 recall 0.9282576866764275 f1 0.9281236954108533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 3.7650420665740967 s\n",
      "Accuracy 0.927086383601757 precision 0.9268205322774332 specificity 0.8672302316040673 recall 0.927086383601757 f1 0.9269450277889865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 3.7953884601593018 s\n",
      "Accuracy 0.931185944363104 precision 0.9305402760015579 specificity 0.8642570936115797 recall 0.931185944363104 f1 0.9307958431958415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 3.7281219959259033 s\n",
      "Accuracy 0.9282576866764275 precision 0.9276248061135127 specificity 0.8650868315520427 recall 0.9282576866764275 f1 0.9278758709648984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 3.8660261631011963 s\n",
      "Accuracy 0.9285505124450951 precision 0.928368786352507 specificity 0.8686162389534615 recall 0.9285505124450951 f1 0.928455864208246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 3.7680914402008057 s\n",
      "Accuracy 0.9317715959004392 precision 0.9321865922165816 specificity 0.8836920752276678 recall 0.9317715959004392 f1 0.9319615322766451\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 3.7827298641204834 s\n",
      "Accuracy 0.9282576866764275 precision 0.9278420137680821 specificity 0.8674639986090238 recall 0.9282576866764275 f1 0.9280263339381927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 3.8210465908050537 s\n",
      "Accuracy 0.9241581259150805 precision 0.9235759691492925 specificity 0.8527268189816032 recall 0.9241581259150805 f1 0.9238287676210242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 3.744022846221924 s\n",
      "Accuracy 0.931185944363104 precision 0.9310980164703224 specificity 0.875704591009745 recall 0.931185944363104 f1 0.931141035026787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 3.8990046977996826 s\n",
      "Accuracy 0.9244509516837481 precision 0.9247105869978861 specificity 0.8730092824169006 recall 0.9244509516837481 f1 0.9245743040192335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 3.8209993839263916 s\n",
      "Accuracy 0.9253294289897511 precision 0.9261806688783975 specificity 0.8748827470198932 recall 0.9253294289897511 f1 0.9257008354720038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 3.791999101638794 s\n",
      "Accuracy 0.9206442166910688 precision 0.921189495961687 specificity 0.8662623894389325 recall 0.9206442166910688 f1 0.920894158345411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 3.8590011596679688 s\n",
      "Accuracy 0.9273792093704246 precision 0.9285877657191388 specificity 0.8746048387661497 recall 0.9273792093704246 f1 0.927888682805195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 3.8089993000030518 s\n",
      "Accuracy 0.9247437774524158 precision 0.9244548782111007 specificity 0.8584829967236173 recall 0.9247437774524158 f1 0.9245908012888413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 3.856513261795044 s\n",
      "Accuracy 0.9188872620790629 precision 0.9185994873444795 specificity 0.8560419528501519 recall 0.9188872620790629 f1 0.9187351747845663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 3.850775718688965 s\n",
      "Accuracy 0.9323572474377745 precision 0.9326412324679559 specificity 0.8814221377340157 recall 0.9323572474377745 f1 0.9324907306033903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 3.971055269241333 s\n",
      "Accuracy 0.926207906295754 precision 0.9267844587518624 specificity 0.8718305487737253 recall 0.926207906295754 f1 0.9264696084245773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 3.810537815093994 s\n",
      "Accuracy 0.92298682284041 precision 0.9237524176684712 specificity 0.8727919638990236 recall 0.92298682284041 f1 0.9233250816294999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 3.900061845779419 s\n",
      "Accuracy 0.9206442166910688 precision 0.9205472315629648 specificity 0.8613761637895343 recall 0.9206442166910688 f1 0.9205948131087958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 3.8950419425964355 s\n",
      "Accuracy 0.927086383601757 precision 0.9269917749318901 specificity 0.8671125712116705 recall 0.927086383601757 f1 0.9270381373716247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 3.749030828475952 s\n",
      "Accuracy 0.9285505124450951 precision 0.9283225522921869 specificity 0.871978214984429 recall 0.9285505124450951 f1 0.9284299008921197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 3.858999252319336 s\n",
      "Accuracy 0.927086383601757 precision 0.9265606323827918 specificity 0.8694758917632363 recall 0.927086383601757 f1 0.9267784305580602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 3.7709996700286865 s\n",
      "Accuracy 0.9203513909224011 precision 0.9205689728387821 specificity 0.858341797745471 recall 0.9203513909224011 f1 0.9204564847684416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 3.8205184936523438 s\n",
      "Accuracy 0.926207906295754 precision 0.9258149309362158 specificity 0.8664561136687984 recall 0.926207906295754 f1 0.9259911954768181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 3.941999673843384 s\n",
      "Accuracy 0.9308931185944364 precision 0.9316544822461756 specificity 0.884214635903466 recall 0.9308931185944364 f1 0.9312235295148751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 3.9125125408172607 s\n",
      "Accuracy 0.9314787701317716 precision 0.9309062168470573 specificity 0.8668695826898964 recall 0.9314787701317716 f1 0.931140645271449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 3.9820010662078857 s\n",
      "Accuracy 0.9297218155197657 precision 0.9295376819248371 specificity 0.8679980151646843 recall 0.9297218155197657 f1 0.9296259144313486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 3.9680583477020264 s\n",
      "Accuracy 0.9291361639824305 precision 0.9294763751178199 specificity 0.8736339418449097 recall 0.9291361639824305 f1 0.929295742079331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 4.371040105819702 s\n",
      "Accuracy 0.9285505124450951 precision 0.9284862328072315 specificity 0.8670936318926149 recall 0.9285505124450951 f1 0.9285179481014271\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 4.23625373840332 s\n",
      "Accuracy 0.9294289897510981 precision 0.9299604330047068 specificity 0.8747313072031689 recall 0.9294289897510981 f1 0.929670938589345\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 4.0600011348724365 s\n",
      "Accuracy 0.9265007320644216 precision 0.927919294135619 specificity 0.8776998052446955 recall 0.9265007320644216 f1 0.9270829028173371\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 4.138047456741333 s\n",
      "Accuracy 0.9273792093704246 precision 0.9273792093704246 specificity 0.8729493483704863 recall 0.9273792093704246 f1 0.9273792093704247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 3.9849627017974854 s\n",
      "Accuracy 0.9194729136163983 precision 0.9195904277048117 specificity 0.8468136179630921 recall 0.9194729136163983 f1 0.9195307203941171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 4.034998893737793 s\n",
      "Accuracy 0.9209370424597365 precision 0.9206917846177975 specificity 0.8618206978735505 recall 0.9209370424597365 f1 0.9208079528063218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 3.9525089263916016 s\n",
      "Accuracy 0.9241581259150805 precision 0.9241944175043397 specificity 0.8556916709904604 recall 0.9241581259150805 f1 0.9241761651331217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 4.121509313583374 s\n",
      "Accuracy 0.9273792093704246 precision 0.9279423489834288 specificity 0.8748288884076372 recall 0.9273792093704246 f1 0.9276342280472812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 4.03302001953125 s\n",
      "Accuracy 0.9215226939970718 precision 0.9210278363490134 specificity 0.8538039284060124 recall 0.9215226939970718 f1 0.9212487346897162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 4.080000162124634 s\n",
      "Accuracy 0.91800878477306 precision 0.918075735911078 specificity 0.8610509190177718 recall 0.91800878477306 f1 0.9180418618960253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 4.092428207397461 s\n",
      "Accuracy 0.9194729136163983 precision 0.9195094244199329 specificity 0.8525141442340372 recall 0.9194729136163983 f1 0.9194910654546927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 3.871591091156006 s\n",
      "Accuracy 0.9238653001464129 precision 0.9241562886274781 specificity 0.8620297886531303 recall 0.9238653001464129 f1 0.924004098988277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 3.9919981956481934 s\n",
      "Accuracy 0.9267935578330894 precision 0.9270649709200405 specificity 0.8705476992028842 recall 0.9267935578330894 f1 0.9269226037204875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 4.025541305541992 s\n",
      "Accuracy 0.930307467057101 precision 0.9299181456816545 specificity 0.8690007001894449 recall 0.930307467057101 f1 0.9300920518076603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 4.007104158401489 s\n",
      "Accuracy 0.9244509516837481 precision 0.9244509516837481 specificity 0.862548694391458 recall 0.9244509516837481 f1 0.9244509516837481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 4.122225522994995 s\n",
      "Accuracy 0.9259150805270864 precision 0.9253343401655132 specificity 0.8608017429940875 recall 0.9259150805270864 f1 0.9255786299490457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 3.9480273723602295 s\n",
      "Accuracy 0.9288433382137629 precision 0.928872902947669 specificity 0.8773857480153235 recall 0.9288433382137629 f1 0.9288580180483543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 3.9980404376983643 s\n",
      "Accuracy 0.9291361639824305 precision 0.9295319856520161 specificity 0.878224710500299 recall 0.9291361639824305 f1 0.9293191597918986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 4.055532693862915 s\n",
      "Accuracy 0.9279648609077599 precision 0.9281639972478254 specificity 0.8714364149379887 recall 0.9279648609077599 f1 0.9280606625799183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 4.0015575885772705 s\n",
      "Accuracy 0.9215226939970718 precision 0.921593794541779 specificity 0.8573259980027574 recall 0.9215226939970718 f1 0.9215578293301558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 4.05058217048645 s\n",
      "Accuracy 0.9288433382137629 precision 0.9283306564760974 specificity 0.857959696631156 recall 0.9288433382137629 f1 0.9285556161684789\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 4.034000635147095 s\n",
      "Accuracy 0.9232796486090776 precision 0.9231061627232136 specificity 0.8698312099091206 recall 0.9232796486090776 f1 0.9231893020484107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 4.0441436767578125 s\n",
      "Accuracy 0.9300146412884334 precision 0.9299845804866277 specificity 0.8748179003960084 recall 0.9300146412884334 f1 0.9299995063951242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 4.007903337478638 s\n",
      "Accuracy 0.9250366032210835 precision 0.9245210449492975 specificity 0.8603372217394722 recall 0.9250366032210835 f1 0.9247450845044566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 3.985997438430786 s\n",
      "Accuracy 0.9241581259150805 precision 0.9237004487333551 specificity 0.8571486561817341 recall 0.9241581259150805 f1 0.9239057158155738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 3.977017879486084 s\n",
      "Accuracy 0.9273792093704246 precision 0.9275834097248513 specificity 0.8687511026810398 recall 0.9273792093704246 f1 0.927477524628502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 4.160065412521362 s\n",
      "Accuracy 0.9259150805270864 precision 0.9255368937543261 specificity 0.8641911629320522 recall 0.9259150805270864 f1 0.9257084345945398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 4.013018846511841 s\n",
      "Accuracy 0.926207906295754 precision 0.9263449999889583 specificity 0.8654950583542422 recall 0.926207906295754 f1 0.9262747713953384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 3.9800710678100586 s\n",
      "Accuracy 0.9338213762811127 precision 0.9337132244877311 specificity 0.882694576579717 recall 0.9338213762811127 f1 0.9337656288326285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 4.0655882358551025 s\n",
      "Accuracy 0.926207906295754 precision 0.9267823255210877 specificity 0.8721778130364071 recall 0.926207906295754 f1 0.9264685768496991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 3.9691827297210693 s\n",
      "Accuracy 0.9241581259150805 precision 0.9238081936135161 specificity 0.8571202194961781 recall 0.9241581259150805 f1 0.9239704448639094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 4.03000020980835 s\n",
      "Accuracy 0.9308931185944364 precision 0.930488237812741 specificity 0.865771104279464 recall 0.9308931185944364 f1 0.9306695550645934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 4.018319606781006 s\n",
      "Accuracy 0.9197657393850659 precision 0.9199012479053911 specificity 0.8627520687109199 recall 0.9197657393850659 f1 0.9198318848493763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 4.011511564254761 s\n",
      "Accuracy 0.9226939970717423 precision 0.9233421484505411 specificity 0.8711605384823228 recall 0.9226939970717423 f1 0.9229853211811117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 4.136029481887817 s\n",
      "Accuracy 0.9235724743777453 precision 0.9234765114458131 specificity 0.863944409108428 recall 0.9235724743777453 f1 0.9235235682816794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 4.0079991817474365 s\n",
      "Accuracy 0.9335285505124451 precision 0.9333852305646142 specificity 0.8768388350276963 recall 0.9335285505124451 f1 0.9334542236834635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 4.069411039352417 s\n",
      "Accuracy 0.9212298682284041 precision 0.9205888260430463 specificity 0.8564360792197926 recall 0.9212298682284041 f1 0.920855373370133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 3.9920008182525635 s\n",
      "Accuracy 0.9250366032210835 precision 0.9262084915989429 specificity 0.8756567684997912 recall 0.9250366032210835 f1 0.9255301877569351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 4.038999319076538 s\n",
      "Accuracy 0.9244509516837481 precision 0.9233544059537097 specificity 0.8472037484418411 recall 0.9244509516837481 f1 0.9236775937708079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 4.039998769760132 s\n",
      "Accuracy 0.9247437774524158 precision 0.9250458700789991 specificity 0.8711141406063979 recall 0.9247437774524158 f1 0.9248865545144874\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 4.062042713165283 s\n",
      "Accuracy 0.9224011713030746 precision 0.92271802255926 specificity 0.8652087713355485 recall 0.9224011713030746 f1 0.9225513145087046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 4.150000333786011 s\n",
      "Accuracy 0.9191800878477306 precision 0.9187577607982486 specificity 0.8569545824456578 recall 0.9191800878477306 f1 0.9189491608010663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 4.070713758468628 s\n",
      "Accuracy 0.9300146412884334 precision 0.929561301747549 specificity 0.8602863806548975 recall 0.9300146412884334 f1 0.9297634445634365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 4.126954793930054 s\n",
      "Accuracy 0.9218155197657394 precision 0.921446289557411 specificity 0.8507696940628405 recall 0.9218155197657394 f1 0.9216181667139963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 3.98720645904541 s\n",
      "Accuracy 0.922108345534407 precision 0.9226082874614684 specificity 0.8680768438742185 recall 0.922108345534407 f1 0.9223384466733827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 4.155999183654785 s\n",
      "Accuracy 0.9259150805270864 precision 0.9270145544670857 specificity 0.8782795480759215 recall 0.9259150805270864 f1 0.9263787890245311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 4.094513893127441 s\n",
      "Accuracy 0.9241581259150805 precision 0.924330255422264 specificity 0.8647966661283191 recall 0.9241581259150805 f1 0.9242416007158223\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 4.130552768707275 s\n",
      "Accuracy 0.9308931185944364 precision 0.9304545517781958 specificity 0.8684479908519361 recall 0.9308931185944364 f1 0.930646575132869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 3.966047525405884 s\n",
      "Accuracy 0.9244509516837481 precision 0.9249363412042786 specificity 0.872391707265691 recall 0.9244509516837481 f1 0.9246736948075593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 3.9769999980926514 s\n",
      "Accuracy 0.9291361639824305 precision 0.930259571574937 specificity 0.882887491862302 recall 0.9291361639824305 f1 0.9296046005536859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 4.136001825332642 s\n",
      "Accuracy 0.9291361639824305 precision 0.9289519282375133 specificity 0.8676657474563114 recall 0.9291361639824305 f1 0.9290402273193064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 4.573998212814331 s\n",
      "Accuracy 0.9259150805270864 precision 0.9255891402575807 specificity 0.8644892066223747 recall 0.9259150805270864 f1 0.9257395369184561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 4.191041707992554 s\n",
      "Accuracy 0.9241581259150805 precision 0.9233153271843322 specificity 0.8550449032411098 recall 0.9241581259150805 f1 0.9236232307631885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 4.041999101638794 s\n",
      "Accuracy 0.9215226939970718 precision 0.922120749463091 specificity 0.8650694169461616 recall 0.9215226939970718 f1 0.9217955757433818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 3.9340016841888428 s\n",
      "Accuracy 0.9279648609077599 precision 0.9280917006948023 specificity 0.8736632490213384 recall 0.9279648609077599 f1 0.9280266242806728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 4.0195088386535645 s\n",
      "Accuracy 0.9241581259150805 precision 0.9241907493193858 specificity 0.8661439472028066 recall 0.9241581259150805 f1 0.9241743348590773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 4.036011695861816 s\n",
      "Accuracy 0.9259150805270864 precision 0.9258831186761962 specificity 0.86715136306756 recall 0.9259150805270864 f1 0.9258989958452937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 4.084998846054077 s\n",
      "Accuracy 0.9300146412884334 precision 0.9291710401602953 specificity 0.8614273661370213 recall 0.9300146412884334 f1 0.9294468723449311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 4.057002067565918 s\n",
      "Accuracy 0.9294289897510981 precision 0.930726464553708 specificity 0.8813189064795446 recall 0.9294289897510981 f1 0.9299633952058177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 4.0539984703063965 s\n",
      "Accuracy 0.9244509516837481 precision 0.9255006586474226 specificity 0.8772730791996063 recall 0.9244509516837481 f1 0.9248964379313704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 4.103998899459839 s\n",
      "Accuracy 0.926207906295754 precision 0.9263463444724483 specificity 0.8645505051823547 recall 0.926207906295754 f1 0.9262754378627159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 3.9615511894226074 s\n",
      "Accuracy 0.9232796486090776 precision 0.9232796486090776 specificity 0.8666576845226599 recall 0.9232796486090776 f1 0.9232796486090776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 4.094018459320068 s\n",
      "Accuracy 0.9244509516837481 precision 0.9240729488241887 specificity 0.8572079112313157 recall 0.9244509516837481 f1 0.9242467972258952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 4.007000207901001 s\n",
      "Accuracy 0.9285505124450951 precision 0.9283573413569254 specificity 0.8629482008726097 recall 0.9285505124450951 f1 0.9284500611787587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 4.0139994621276855 s\n",
      "Accuracy 0.9256222547584187 precision 0.9251232154514759 specificity 0.8634204889939446 recall 0.9256222547584187 f1 0.9253392015870635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 4.009000062942505 s\n",
      "Accuracy 0.926207906295754 precision 0.9268508267083224 specificity 0.8744298901027535 recall 0.926207906295754 f1 0.9264960023403666\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 3.962559223175049 s\n",
      "Accuracy 0.9259150805270864 precision 0.9263606068499673 specificity 0.8735596349040068 recall 0.9259150805270864 f1 0.9261205111145207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 3.9839982986450195 s\n",
      "Accuracy 0.9259150805270864 precision 0.9257077967433766 specificity 0.8683243194937618 recall 0.9259150805270864 f1 0.9258064017991126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 3.9700000286102295 s\n",
      "Accuracy 0.9291361639824305 precision 0.9301497222285371 specificity 0.8841438574476826 recall 0.9291361639824305 f1 0.9295623149869673\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 4.049001693725586 s\n",
      "Accuracy 0.9256222547584187 precision 0.9253789376856559 specificity 0.8648855526932503 recall 0.9256222547584187 f1 0.9254939558819408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 4.026022672653198 s\n",
      "Accuracy 0.9267935578330894 precision 0.9265478748260468 specificity 0.864572342658676 recall 0.9267935578330894 f1 0.9266640014049989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 4.071999549865723 s\n",
      "Accuracy 0.9235724743777453 precision 0.9245401998397657 specificity 0.8710491241997069 recall 0.9235724743777453 f1 0.9239922422683364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 3.971998929977417 s\n",
      "Accuracy 0.9226939970717423 precision 0.9226280142369209 specificity 0.8615239719151541 recall 0.9226939970717423 f1 0.9226605938854622\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 3.9840011596679688 s\n",
      "Accuracy 0.9267935578330894 precision 0.9270613713995199 specificity 0.8717685430839015 recall 0.9267935578330894 f1 0.9269208347670026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 3.9870455265045166 s\n",
      "Accuracy 0.9300146412884334 precision 0.9301682202795244 specificity 0.8785473251539403 recall 0.9300146412884334 f1 0.930088842176836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 4.049999713897705 s\n",
      "Accuracy 0.9238653001464129 precision 0.9241485766149639 specificity 0.8646745753712545 recall 0.9238653001464129 f1 0.9240003052128694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 4.345025062561035 s\n",
      "Accuracy 0.9250366032210835 precision 0.92491359299351 specificity 0.867345824463144 recall 0.9250366032210835 f1 0.9249734556688181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 4.008019685745239 s\n",
      "Accuracy 0.9212298682284041 precision 0.9214140419077201 specificity 0.8563532060710303 recall 0.9212298682284041 f1 0.9213193537354104\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 4.0239996910095215 s\n",
      "Accuracy 0.9256222547584187 precision 0.9259898804205768 specificity 0.8639411371491325 recall 0.9256222547584187 f1 0.9257954962168317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 4.041999340057373 s\n",
      "Accuracy 0.9183016105417277 precision 0.9190460355640482 specificity 0.8607517904140751 recall 0.9183016105417277 f1 0.9186373012088072\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 4.002000331878662 s\n",
      "Accuracy 0.9291361639824305 precision 0.9302153700056703 specificity 0.8863561878340132 recall 0.9291361639824305 f1 0.929583870261187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 4.059050559997559 s\n",
      "Accuracy 0.927086383601757 precision 0.9268648334111015 specificity 0.862890748690366 recall 0.927086383601757 f1 0.9269704183685138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 3.9965085983276367 s\n",
      "Accuracy 0.9200585651537335 precision 0.9199610424289405 specificity 0.8605451554499871 recall 0.9200585651537335 f1 0.9200088944118806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 4.022048711776733 s\n",
      "Accuracy 0.9317715959004392 precision 0.9322332224477583 specificity 0.8883722048883328 recall 0.9317715959004392 f1 0.9319794507566023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 4.083998680114746 s\n",
      "Accuracy 0.9329428989751098 precision 0.9321862738594244 specificity 0.865831001598504 recall 0.9329428989751098 f1 0.9324470398445234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 4.0139992237091064 s\n",
      "Accuracy 0.9300146412884334 precision 0.9299831771475578 specificity 0.8707975551970807 recall 0.9300146412884334 f1 0.9299988030630554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 3.9880456924438477 s\n",
      "Accuracy 0.930307467057101 precision 0.9301812988250793 specificity 0.8677507461721399 recall 0.930307467057101 f1 0.9302426647758839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 3.9800593852996826 s\n",
      "Accuracy 0.9273792093704246 precision 0.9269512741997341 specificity 0.8592703507468774 recall 0.9273792093704246 f1 0.9271442782034709\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 4.048144817352295 s\n",
      "Accuracy 0.9308931185944364 precision 0.9302234895441728 specificity 0.8583393096843029 recall 0.9308931185944364 f1 0.9304950547844617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 4.031000375747681 s\n",
      "Accuracy 0.9279648609077599 precision 0.9269086055894272 specificity 0.8471408305153946 recall 0.9279648609077599 f1 0.9272430800198159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 4.045999765396118 s\n",
      "Accuracy 0.9273792093704246 precision 0.9270550132204511 specificity 0.8720336431492242 recall 0.9273792093704246 f1 0.9272023935675737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 4.010000705718994 s\n",
      "Accuracy 0.9256222547584187 precision 0.9258795499278661 specificity 0.8745462710947024 recall 0.9256222547584187 f1 0.9257444099919254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 3.991999626159668 s\n",
      "Accuracy 0.9279648609077599 precision 0.9280291882020771 specificity 0.8705438961456767 recall 0.9279648609077599 f1 0.9279966061960598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 4.024999380111694 s\n",
      "Accuracy 0.9259150805270864 precision 0.9255816336418551 specificity 0.8624352373769593 recall 0.9259150805270864 f1 0.9257356902796232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 4.237000942230225 s\n",
      "Accuracy 0.9215226939970718 precision 0.9220742397611008 specificity 0.8725403427201914 recall 0.9215226939970718 f1 0.9217730168683972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 4.269001483917236 s\n",
      "Accuracy 0.9253294289897511 precision 0.9258601395306966 specificity 0.872030011376137 recall 0.9253294289897511 f1 0.9255716506086115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 4.309564113616943 s\n",
      "Accuracy 0.9288433382137629 precision 0.9281185599559607 specificity 0.8581175007099736 recall 0.9288433382137629 f1 0.9284024688325965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 4.114999771118164 s\n",
      "Accuracy 0.922108345534407 precision 0.9216785642287593 specificity 0.8566836262198168 recall 0.922108345534407 f1 0.9218732151131458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 4.093999624252319 s\n",
      "Accuracy 0.9326500732064422 precision 0.9320121210101892 specificity 0.8716402565116922 recall 0.9326500732064422 f1 0.9322482265934933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 4.20602822303772 s\n",
      "Accuracy 0.9291361639824305 precision 0.9293194925090694 specificity 0.879334052585927 recall 0.9291361639824305 f1 0.9292241386920136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 4.1970415115356445 s\n",
      "Accuracy 0.9194729136163983 precision 0.9198876556854247 specificity 0.8583875433140488 recall 0.9194729136163983 f1 0.9196679030158144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 4.032023191452026 s\n",
      "Accuracy 0.9326500732064422 precision 0.932430744761452 specificity 0.8771622104803949 recall 0.9326500732064422 f1 0.9325336681633446\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 3.977999687194824 s\n",
      "Accuracy 0.9306002928257686 precision 0.9308851562814687 specificity 0.880023286919137 recall 0.9306002928257686 f1 0.9307343079592811\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 4.024000883102417 s\n",
      "Accuracy 0.9317715959004392 precision 0.9328632479266415 specificity 0.8837202765832304 recall 0.9317715959004392 f1 0.9322283506134956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 4.283999443054199 s\n",
      "Accuracy 0.9364568081991215 precision 0.9367997251661582 specificity 0.8869906990494715 recall 0.9364568081991215 f1 0.9366153054733776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 3.7689995765686035 s\n",
      "Accuracy 0.9306002928257686 precision 0.9309471205156453 specificity 0.8821385896807984 recall 0.9306002928257686 f1 0.9307612179450164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 3.8009285926818848 s\n",
      "Accuracy 0.9197657393850659 precision 0.9196364187658432 specificity 0.8599930393892604 recall 0.9197657393850659 f1 0.9196994642148375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 3.700043201446533 s\n",
      "Accuracy 0.9282576866764275 precision 0.9280398882394922 specificity 0.8650425614625302 recall 0.9282576866764275 f1 0.9281435843384974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 3.7370378971099854 s\n",
      "Accuracy 0.9300146412884334 precision 0.9308349001234854 specificity 0.8818084502310529 recall 0.9300146412884334 f1 0.9303696741224855\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 3.685045003890991 s\n",
      "Accuracy 0.9203513909224011 precision 0.9207322283594893 specificity 0.8570090952296809 recall 0.9203513909224011 f1 0.9205314633605309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 3.917999744415283 s\n",
      "Accuracy 0.9314787701317716 precision 0.9313657546696184 specificity 0.8779529944395252 recall 0.9314787701317716 f1 0.9314205941655762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 3.8165111541748047 s\n",
      "Accuracy 0.9244509516837481 precision 0.925041962344566 specificity 0.8682490196814316 recall 0.9244509516837481 f1 0.924719945740423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 3.7700002193450928 s\n",
      "Accuracy 0.9197657393850659 precision 0.9202938961678102 specificity 0.8611938758292196 recall 0.9197657393850659 f1 0.9200098565443114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 3.828998565673828 s\n",
      "Accuracy 0.926207906295754 precision 0.925607528172433 specificity 0.85436882879711 recall 0.926207906295754 f1 0.9258648353951928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 3.690000295639038 s\n",
      "Accuracy 0.9247437774524158 precision 0.9251648991203828 specificity 0.8601707962901975 recall 0.9247437774524158 f1 0.9249414659091325\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 3.802051544189453 s\n",
      "Accuracy 0.9276720351390922 precision 0.9272952024392469 specificity 0.8652718462180866 recall 0.9276720351390922 f1 0.9274658713849833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 3.7329983711242676 s\n",
      "Accuracy 0.9282576866764275 precision 0.9278411342796036 specificity 0.8672835559532365 recall 0.9282576866764275 f1 0.928025878281991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 3.7290000915527344 s\n",
      "Accuracy 0.930307467057101 precision 0.931526017541885 specificity 0.884108613840667 recall 0.930307467057101 f1 0.9308096764728014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 3.7239983081817627 s\n",
      "Accuracy 0.9291361639824305 precision 0.9297669291647188 specificity 0.8782679912264423 recall 0.9291361639824305 f1 0.9294177812773174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 3.751460313796997 s\n",
      "Accuracy 0.9285505124450951 precision 0.9283665600892532 specificity 0.8675212259838322 recall 0.9285505124450951 f1 0.9284547354201705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 3.8229994773864746 s\n",
      "Accuracy 0.9200585651537335 precision 0.9196971930868372 specificity 0.8521428295560145 recall 0.9200585651537335 f1 0.9198653754256959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 3.71699857711792 s\n",
      "Accuracy 0.92298682284041 precision 0.9222479403775995 specificity 0.8588933321628247 recall 0.92298682284041 f1 0.9225314507289305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 3.7330238819122314 s\n",
      "Accuracy 0.9329428989751098 precision 0.9329120931106981 specificity 0.8742498939665851 recall 0.9329428989751098 f1 0.9329273883864928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 3.7030439376831055 s\n",
      "Accuracy 0.9288433382137629 precision 0.9293727727694003 specificity 0.8746800954726393 recall 0.9288433382137629 f1 0.9290844095999404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 3.768026351928711 s\n",
      "Accuracy 0.9200585651537335 precision 0.9196904120193883 specificity 0.8502898374984666 recall 0.9200585651537335 f1 0.9198619101163488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 3.718007802963257 s\n",
      "Accuracy 0.9273792093704246 precision 0.9285723917125882 specificity 0.8834868812967333 recall 0.9273792093704246 f1 0.9278714940817658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 3.7049999237060547 s\n",
      "Accuracy 0.9338213762811127 precision 0.9338213762811127 specificity 0.879596918342905 recall 0.9338213762811127 f1 0.9338213762811127\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 3.703007221221924 s\n",
      "Accuracy 0.9288433382137629 precision 0.9288753752293342 specificity 0.8704497256480418 recall 0.9288433382137629 f1 0.9288592513586461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 3.6250078678131104 s\n",
      "Accuracy 0.926207906295754 precision 0.9253932648199997 specificity 0.8532348914903147 recall 0.926207906295754 f1 0.9257044255815646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 3.756133556365967 s\n",
      "Accuracy 0.9282576866764275 precision 0.9279739785942537 specificity 0.8617989615731632 recall 0.9282576866764275 f1 0.928107144146042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 3.753999948501587 s\n",
      "Accuracy 0.9232796486090776 precision 0.9232099995977806 specificity 0.85654936497456 recall 0.9232796486090776 f1 0.9232444032015781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 3.731506586074829 s\n",
      "Accuracy 0.9267935578330894 precision 0.9268600784287163 specificity 0.8667845084765766 recall 0.9267935578330894 f1 0.9268263982429886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 3.775965452194214 s\n",
      "Accuracy 0.9297218155197657 precision 0.9291392815219531 specificity 0.8648455840978251 recall 0.9297218155197657 f1 0.9293791103510685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 3.6555185317993164 s\n",
      "Accuracy 0.9224011713030746 precision 0.9224999968367422 specificity 0.8660297950939935 recall 0.9224011713030746 f1 0.9224496708614881\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 3.7360002994537354 s\n",
      "Accuracy 0.9279648609077599 precision 0.9280278204762235 specificity 0.8724604058144511 recall 0.9279648609077599 f1 0.9279959253995055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 3.6950106620788574 s\n",
      "Accuracy 0.9265007320644216 precision 0.925870081914203 specificity 0.8647922877253074 recall 0.9265007320644216 f1 0.9261209106266244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 3.822000026702881 s\n",
      "Accuracy 0.9212298682284041 precision 0.9207768319705939 specificity 0.8568511901871093 recall 0.9212298682284041 f1 0.9209803059357743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 3.6640098094940186 s\n",
      "Accuracy 0.9238653001464129 precision 0.9239291249950109 specificity 0.8688509554976476 recall 0.9238653001464129 f1 0.923896806240754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 3.6750218868255615 s\n",
      "Accuracy 0.9165446559297218 precision 0.9188258722550727 specificity 0.8667192198415915 recall 0.9165446559297218 f1 0.9174448301323163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 3.6600096225738525 s\n",
      "Accuracy 0.9256222547584187 precision 0.9248649644680929 specificity 0.8507671929783449 recall 0.9256222547584187 f1 0.9251709288494637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 3.667531967163086 s\n",
      "Accuracy 0.9250366032210835 precision 0.9257018246279957 specificity 0.8704068843476414 recall 0.9250366032210835 f1 0.9253356913683102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 3.68999981880188 s\n",
      "Accuracy 0.9212298682284041 precision 0.9214931487929883 specificity 0.856062723227332 recall 0.9212298682284041 f1 0.9213563972704307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 3.7149782180786133 s\n",
      "Accuracy 0.9306002928257686 precision 0.9318155488643513 specificity 0.8881326029626597 recall 0.9306002928257686 f1 0.9310955647946857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 3.6615114212036133 s\n",
      "Accuracy 0.922108345534407 precision 0.9209329005039119 specificity 0.8408266449053636 recall 0.922108345534407 f1 0.9212950669581265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 3.7483789920806885 s\n",
      "Accuracy 0.9329428989751098 precision 0.9323288156369481 specificity 0.8689333047171548 recall 0.9329428989751098 f1 0.9325687312324484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 3.9800496101379395 s\n",
      "Accuracy 0.9273792093704246 precision 0.9269628564734335 specificity 0.8618396405655198 recall 0.9273792093704246 f1 0.9271502609603259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 3.8080005645751953 s\n",
      "Accuracy 0.927086383601757 precision 0.9271169694665122 specificity 0.873524547363044 recall 0.927086383601757 f1 0.9271015740294863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 3.7105116844177246 s\n",
      "Accuracy 0.9265007320644216 precision 0.9264695221703696 specificity 0.869610841118213 recall 0.9265007320644216 f1 0.9264850237827879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 3.8179404735565186 s\n",
      "Accuracy 0.9206442166910688 precision 0.9210449335327462 specificity 0.8625700283215391 recall 0.9206442166910688 f1 0.9208322495682976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 3.716000556945801 s\n",
      "Accuracy 0.9209370424597365 precision 0.922098393113202 specificity 0.8731722062361038 recall 0.9209370424597365 f1 0.9214278104677414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 3.65899920463562 s\n",
      "Accuracy 0.9288433382137629 precision 0.9280710468389796 specificity 0.860357299562587 recall 0.9288433382137629 f1 0.928354881832135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 3.7560553550720215 s\n",
      "Accuracy 0.930307467057101 precision 0.9307099234554855 specificity 0.8775498931599754 recall 0.930307467057101 f1 0.9304935734102656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 3.7222890853881836 s\n",
      "Accuracy 0.9300146412884334 precision 0.9298679355146166 specificity 0.8730895385604518 recall 0.9300146412884334 f1 0.9299386681866846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 3.856046676635742 s\n",
      "Accuracy 0.9244509516837481 precision 0.9243845379717229 specificity 0.8618496479077645 recall 0.9244509516837481 f1 0.9244173274266638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 3.831195116043091 s\n",
      "Accuracy 0.9320644216691069 precision 0.931409958062251 specificity 0.8655978266426936 recall 0.9320644216691069 f1 0.9316642924223869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 3.8300018310546875 s\n",
      "Accuracy 0.9247437774524158 precision 0.9253541773055377 specificity 0.8720227499852913 recall 0.9247437774524158 f1 0.92501936136406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 3.8910274505615234 s\n",
      "Accuracy 0.9194729136163983 precision 0.91872916587495 specificity 0.8529993984346563 recall 0.9194729136163983 f1 0.9190269908620705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 3.894073486328125 s\n",
      "Accuracy 0.9273792093704246 precision 0.9273182586686775 specificity 0.8712550647520959 recall 0.9273792093704246 f1 0.9273483204532947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 3.7788569927215576 s\n",
      "Accuracy 0.9232796486090776 precision 0.9224440657922278 specificity 0.8570241777000466 recall 0.9232796486090776 f1 0.9227430876329253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 3.7062370777130127 s\n",
      "Accuracy 0.9265007320644216 precision 0.9262888279476376 specificity 0.8666884289519875 recall 0.9265007320644216 f1 0.9263896872463747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 3.7230634689331055 s\n",
      "Accuracy 0.9235724743777453 precision 0.923674682422158 specificity 0.8635965546908991 recall 0.9235724743777453 f1 0.9236226482142085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 3.900425910949707 s\n",
      "Accuracy 0.9294289897510981 precision 0.9310718844022178 specificity 0.8864934814688901 recall 0.9294289897510981 f1 0.9300760588234921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 3.7671384811401367 s\n",
      "Accuracy 0.9297218155197657 precision 0.9298423559085108 specificity 0.8790466242729986 recall 0.9297218155197657 f1 0.9297804384707749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 3.9770307540893555 s\n",
      "Accuracy 0.9183016105417277 precision 0.9191512601866135 specificity 0.8591970697242061 recall 0.9183016105417277 f1 0.9186815210607715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 4.058045864105225 s\n",
      "Accuracy 0.9133235724743778 precision 0.9141331379105904 specificity 0.854711457629618 recall 0.9133235724743778 f1 0.9136886442609121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 3.810980796813965 s\n",
      "Accuracy 0.9285505124450951 precision 0.9275811112586547 specificity 0.8563008325289492 recall 0.9285505124450951 f1 0.9278591597912403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 3.8620009422302246 s\n",
      "Accuracy 0.9314787701317716 precision 0.9315375489976654 specificity 0.8803317781367098 recall 0.9314787701317716 f1 0.9315077440784458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 3.7805206775665283 s\n",
      "Accuracy 0.9218155197657394 precision 0.9212938337304196 specificity 0.8536931871782842 recall 0.9218155197657394 f1 0.9215246653037906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 3.806999921798706 s\n",
      "Accuracy 0.9285505124450951 precision 0.9287294034085676 specificity 0.8809386995393865 recall 0.9285505124450951 f1 0.9286363118749091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 3.7995147705078125 s\n",
      "Accuracy 0.9194729136163983 precision 0.9197942210568274 specificity 0.8620005285507315 recall 0.9194729136163983 f1 0.9196253910476186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 3.93999981880188 s\n",
      "Accuracy 0.9265007320644216 precision 0.9264110604512664 specificity 0.8715150844475522 recall 0.9265007320644216 f1 0.9264549745029808\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 3.8439979553222656 s\n",
      "Accuracy 0.9276720351390922 precision 0.9282527711557466 specificity 0.8785790256799269 recall 0.9276720351390922 f1 0.9279327627795964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 3.8362529277801514 s\n",
      "Accuracy 0.9226939970717423 precision 0.9230518881536984 specificity 0.8647221968922976 recall 0.9226939970717423 f1 0.9228626660482858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 3.956174612045288 s\n",
      "Accuracy 0.9247437774524158 precision 0.924535998004003 specificity 0.8675174170373127 recall 0.9247437774524158 f1 0.9246348852186953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 3.657001256942749 s\n",
      "Accuracy 0.9294289897510981 precision 0.9292127414782392 specificity 0.86625282843072 recall 0.9294289897510981 f1 0.9293156310182787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 3.7659997940063477 s\n",
      "Accuracy 0.926207906295754 precision 0.9254970879705874 specificity 0.8568298566105558 recall 0.926207906295754 f1 0.9257809564267294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 3.7790002822875977 s\n",
      "Accuracy 0.9288433382137629 precision 0.9292008936290274 specificity 0.8783982790728321 recall 0.9288433382137629 f1 0.9290096386227011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 3.8580546379089355 s\n",
      "Accuracy 0.9253294289897511 precision 0.9265567491443788 specificity 0.8754876672994006 recall 0.9253294289897511 f1 0.9258440360150089\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 3.8880021572113037 s\n",
      "Accuracy 0.9253294289897511 precision 0.9257617972540058 specificity 0.8757910310172113 recall 0.9253294289897511 f1 0.9255285177346126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 3.8870060443878174 s\n",
      "Accuracy 0.9358711566617862 precision 0.9359594722710392 specificity 0.8837033623095694 recall 0.9358711566617862 f1 0.9359143516811015\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 3.928001880645752 s\n",
      "Accuracy 0.9241581259150805 precision 0.9238216897870247 specificity 0.8608202891341811 recall 0.9241581259150805 f1 0.923977354794491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 3.9339983463287354 s\n",
      "Accuracy 0.9317715959004392 precision 0.9310304767506168 specificity 0.8644133332732603 recall 0.9317715959004392 f1 0.9312976524704767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 3.83927059173584 s\n",
      "Accuracy 0.9253294289897511 precision 0.9254341356958449 specificity 0.8622629408332425 recall 0.9253294289897511 f1 0.9253808335129324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 3.918999671936035 s\n",
      "Accuracy 0.9294289897510981 precision 0.9296633855653974 specificity 0.8724563073967405 recall 0.9294289897510981 f1 0.9295410068862764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 3.903510808944702 s\n",
      "Accuracy 0.9273792093704246 precision 0.927585394316774 specificity 0.8678335826562212 recall 0.9273792093704246 f1 0.9274785039265273\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 3.908508062362671 s\n",
      "Accuracy 0.9297218155197657 precision 0.9296613196794015 specificity 0.8731771973927218 recall 0.9297218155197657 f1 0.9296911484331214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 3.9600274562835693 s\n",
      "Accuracy 0.9256222547584187 precision 0.9264675275990846 specificity 0.8706682866153636 recall 0.9256222547584187 f1 0.9259944042598592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 4.014509916305542 s\n",
      "Accuracy 0.9282576866764275 precision 0.9272734377621289 specificity 0.856947118685124 recall 0.9282576866764275 f1 0.9275313537071935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 3.9440035820007324 s\n",
      "Accuracy 0.9329428989751098 precision 0.9322336355869235 specificity 0.8681913283716755 recall 0.9329428989751098 f1 0.932485302364711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 4.098999977111816 s\n",
      "Accuracy 0.9238653001464129 precision 0.9238653001464129 specificity 0.871379225717485 recall 0.9238653001464129 f1 0.9238653001464129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 3.869508743286133 s\n",
      "Accuracy 0.9244509516837481 precision 0.9236723048556648 specificity 0.8567933105683342 recall 0.9244509516837481 f1 0.9239679869657008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 3.9009974002838135 s\n",
      "Accuracy 0.9209370424597365 precision 0.921707218815734 specificity 0.8652374748043641 recall 0.9209370424597365 f1 0.9212813679270294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 3.804997682571411 s\n",
      "Accuracy 0.9203513909224011 precision 0.9200210778214981 specificity 0.8526969866355344 recall 0.9203513909224011 f1 0.9201758885155397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 3.8279178142547607 s\n",
      "Accuracy 0.9300146412884334 precision 0.9299854577660702 specificity 0.8773020687691101 recall 0.9300146412884334 f1 0.9299999460718557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 3.888007879257202 s\n",
      "Accuracy 0.9265007320644216 precision 0.9263472889820805 specificity 0.8673666199738449 recall 0.9265007320644216 f1 0.9264214143372453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 3.904998540878296 s\n",
      "Accuracy 0.922108345534407 precision 0.9231064977973497 specificity 0.8715592755005475 recall 0.922108345534407 f1 0.9225390466450335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 3.859508514404297 s\n",
      "Accuracy 0.9267935578330894 precision 0.9265974295331935 specificity 0.860649175364799 recall 0.9267935578330894 f1 0.9266916564328366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 3.878000020980835 s\n",
      "Accuracy 0.922108345534407 precision 0.9219798703852418 specificity 0.8618628673018365 recall 0.922108345534407 f1 0.9220424731428231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 3.9129996299743652 s\n",
      "Accuracy 0.9300146412884334 precision 0.9298609543668389 specificity 0.8689888864435137 recall 0.9300146412884334 f1 0.9299351355777474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 3.9459989070892334 s\n",
      "Accuracy 0.9232796486090776 precision 0.9241389713118194 specificity 0.877111829734554 recall 0.9232796486090776 f1 0.9236517845371227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 3.792997360229492 s\n",
      "Accuracy 0.9226939970717423 precision 0.9224384236782157 specificity 0.8589365270539043 recall 0.9226939970717423 f1 0.9225595926295299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 3.8389997482299805 s\n",
      "Accuracy 0.930307467057101 precision 0.9316161946442162 specificity 0.8848832838400217 recall 0.930307467057101 f1 0.9308410645612827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 3.8319995403289795 s\n",
      "Accuracy 0.922108345534407 precision 0.9219790980339764 specificity 0.8613089505373859 recall 0.922108345534407 f1 0.92204208382508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 3.8799967765808105 s\n",
      "Accuracy 0.9276720351390922 precision 0.9277049180211088 specificity 0.8673922568503655 recall 0.9276720351390922 f1 0.9276883711150555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 3.9240002632141113 s\n",
      "Accuracy 0.9215226939970718 precision 0.921728325933742 specificity 0.864515677794476 recall 0.9215226939970718 f1 0.9216218553877386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 3.825000047683716 s\n",
      "Accuracy 0.9218155197657394 precision 0.9221514768382837 specificity 0.8590690466913236 recall 0.9218155197657394 f1 0.9219750794431744\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 3.9110000133514404 s\n",
      "Accuracy 0.9285505124450951 precision 0.9287550922719533 specificity 0.8692782992599798 recall 0.9285505124450951 f1 0.9286489843469641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 3.8380014896392822 s\n",
      "Accuracy 0.9212298682284041 precision 0.9203964968364956 specificity 0.8518122244353501 recall 0.9212298682284041 f1 0.9207141061569696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 3.857999324798584 s\n",
      "Accuracy 0.9194729136163983 precision 0.919120492245646 specificity 0.8542977329149846 recall 0.9194729136163983 f1 0.9192843434078471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 3.825047254562378 s\n",
      "Accuracy 0.9194729136163983 precision 0.9192353318383159 specificity 0.8524295510309184 recall 0.9194729136163983 f1 0.9193490740471434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 3.8769986629486084 s\n",
      "Accuracy 0.9212298682284041 precision 0.921334938079445 specificity 0.8595661373407543 recall 0.9212298682284041 f1 0.9212814781084471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 3.8815557956695557 s\n",
      "Accuracy 0.926207906295754 precision 0.9256749482701191 specificity 0.8650623973559903 recall 0.926207906295754 f1 0.9259001358029558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 3.857999563217163 s\n",
      "Accuracy 0.9194729136163983 precision 0.9197247689952139 specificity 0.8594838277105369 recall 0.9194729136163983 f1 0.9195938602324373\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 3.9015207290649414 s\n",
      "Accuracy 0.9241581259150805 precision 0.9237835147336932 specificity 0.8642249929853361 recall 0.9241581259150805 f1 0.923953523379394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 3.955000400543213 s\n",
      "Accuracy 0.926207906295754 precision 0.9266866103029633 specificity 0.8748438056538812 recall 0.926207906295754 f1 0.9264271849375671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 4.1419970989227295 s\n",
      "Accuracy 0.9224011713030746 precision 0.9229209683944292 specificity 0.8718666077528807 recall 0.9224011713030746 f1 0.9226384997602833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 4.198997259140015 s\n",
      "Accuracy 0.9244509516837481 precision 0.9247242310457114 specificity 0.8684386276661562 recall 0.9244509516837481 f1 0.9245810148210563\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 4.103059530258179 s\n",
      "Accuracy 0.9232796486090776 precision 0.9235532603641182 specificity 0.8675835613406718 recall 0.9232796486090776 f1 0.9234099229949165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 3.9839999675750732 s\n",
      "Accuracy 0.9297218155197657 precision 0.9294494074043876 specificity 0.8743614885635383 recall 0.9297218155197657 f1 0.929575258142243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 4.016998291015625 s\n",
      "Accuracy 0.9332357247437775 precision 0.9329621889144603 specificity 0.8756478492928815 recall 0.9332357247437775 f1 0.9330883217519634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 4.116586923599243 s\n",
      "Accuracy 0.9297218155197657 precision 0.9293410508462231 specificity 0.8706384901586177 recall 0.9297218155197657 f1 0.9295109161976243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 4.1650004386901855 s\n",
      "Accuracy 0.9291361639824305 precision 0.9282772185618697 specificity 0.8559405874134449 recall 0.9291361639824305 f1 0.9285816296311526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 4.127001047134399 s\n",
      "Accuracy 0.9226939970717423 precision 0.92262601634619 specificity 0.8586575088633055 recall 0.9226939970717423 f1 0.9226595908551908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 4.295999526977539 s\n",
      "Accuracy 0.9215226939970718 precision 0.9205972148028956 specificity 0.8440967101087982 recall 0.9215226939970718 f1 0.920951549737166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 4.459057807922363 s\n",
      "Accuracy 0.926207906295754 precision 0.9254366989172624 specificity 0.8580936510426131 recall 0.926207906295754 f1 0.9257277462213997\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 4.233999013900757 s\n",
      "Accuracy 0.9247437774524158 precision 0.9244554719097979 specificity 0.8586811819818435 recall 0.9247437774524158 f1 0.9245911039906878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 4.207053899765015 s\n",
      "Accuracy 0.9238653001464129 precision 0.9242221664698043 specificity 0.8657512976563295 recall 0.9238653001464129 f1 0.9240333912774291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 4.1695075035095215 s\n",
      "Accuracy 0.9291361639824305 precision 0.9296851271393908 specificity 0.8783573773175024 recall 0.9291361639824305 f1 0.9293840332889862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 4.301002502441406 s\n",
      "Accuracy 0.9235724743777453 precision 0.9238248465052397 specificity 0.8617989821227434 recall 0.9235724743777453 f1 0.9236935473391086\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 4.340506076812744 s\n",
      "Accuracy 0.9332357247437775 precision 0.9323008353489768 specificity 0.8540064108671998 recall 0.9332357247437775 f1 0.9326056482758034\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 4.249000310897827 s\n",
      "Accuracy 0.9265007320644216 precision 0.9260824730417406 specificity 0.8661916467244382 recall 0.9265007320644216 f1 0.9262683258220096\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 4.219032049179077 s\n",
      "Accuracy 0.9253294289897511 precision 0.9252307261934982 specificity 0.8622392187658163 recall 0.9253294289897511 f1 0.9252791334193157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 4.253054857254028 s\n",
      "Accuracy 0.9300146412884334 precision 0.9306494513029402 specificity 0.8839141086223254 recall 0.9300146412884334 f1 0.9302949485252975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 4.187539577484131 s\n",
      "Accuracy 0.9226939970717423 precision 0.9226251980470589 specificity 0.857476143277533 recall 0.9226939970717423 f1 0.9226591800324185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 4.2679994106292725 s\n",
      "Accuracy 0.927086383601757 precision 0.9282651648578675 specificity 0.8806712975778984 recall 0.927086383601757 f1 0.9275771253359818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 4.212000608444214 s\n",
      "Accuracy 0.9276720351390922 precision 0.9280474985992572 specificity 0.8733047392715649 recall 0.9276720351390922 f1 0.9278471710723859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 4.070510149002075 s\n",
      "Accuracy 0.9118594436310395 precision 0.9120680348250592 specificity 0.8371714237241966 recall 0.9118594436310395 f1 0.911961177513406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 4.11401891708374 s\n",
      "Accuracy 0.9291361639824305 precision 0.928292924612809 specificity 0.8623538016390625 recall 0.9291361639824305 f1 0.9285623469866728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 4.342046499252319 s\n",
      "Accuracy 0.9224011713030746 precision 0.9217742671237089 specificity 0.8588072975924144 recall 0.9224011713030746 f1 0.9220336877663403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 4.323999404907227 s\n",
      "Accuracy 0.9288433382137629 precision 0.9287493831955994 specificity 0.8686588724766707 recall 0.9288433382137629 f1 0.9287954094937007\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 4.13700008392334 s\n",
      "Accuracy 0.9215226939970718 precision 0.9210432509520621 specificity 0.8567516610008135 recall 0.9215226939970718 f1 0.9212567014514276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 4.1120007038116455 s\n",
      "Accuracy 0.9320644216691069 precision 0.9321263439404028 specificity 0.8762693248564327 recall 0.9320644216691069 f1 0.9320949579461965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 4.195999383926392 s\n",
      "Accuracy 0.930307467057101 precision 0.9309167111130539 specificity 0.8821610912568263 recall 0.930307467057101 f1 0.9305784883639651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 4.12451171875 s\n",
      "Accuracy 0.9300146412884334 precision 0.9301085985525108 specificity 0.8750353624148323 recall 0.9300146412884334 f1 0.9300606766081768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 4.052000045776367 s\n",
      "Accuracy 0.9226939970717423 precision 0.9226939970717423 specificity 0.8640337081717339 recall 0.9226939970717423 f1 0.9226939970717423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 4.14351224899292 s\n",
      "Accuracy 0.9253294289897511 precision 0.926565175829955 specificity 0.8822070443194423 recall 0.9253294289897511 f1 0.9258377862246835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 4.066039800643921 s\n",
      "Accuracy 0.9256222547584187 precision 0.9247801625643657 specificity 0.8569698503073598 recall 0.9256222547584187 f1 0.9250801932863908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 4.116509199142456 s\n",
      "Accuracy 0.9306002928257686 precision 0.9314103672429199 specificity 0.8833537146352087 recall 0.9306002928257686 f1 0.9309502768256592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 4.169999837875366 s\n",
      "Accuracy 0.9226939970717423 precision 0.9228236938419776 specificity 0.8685037232280098 recall 0.9226939970717423 f1 0.9227572312238894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 4.139038324356079 s\n",
      "Accuracy 0.9253294289897511 precision 0.9255537686972489 specificity 0.873788390128068 recall 0.9253294289897511 f1 0.9254366306215995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 4.12899923324585 s\n",
      "Accuracy 0.9332357247437775 precision 0.9331799875086718 specificity 0.881884728536082 recall 0.9332357247437775 f1 0.9332074382230654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 4.088508605957031 s\n",
      "Accuracy 0.9285505124450951 precision 0.927845706158092 specificity 0.8582331309452746 recall 0.9285505124450951 f1 0.9281254923450882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 4.072000741958618 s\n",
      "Accuracy 0.9206442166910688 precision 0.9202994768801132 specificity 0.8569263862144842 recall 0.9206442166910688 f1 0.9204594812593564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 4.162508726119995 s\n",
      "Accuracy 0.9285505124450951 precision 0.9284866173213862 specificity 0.8676518675565021 recall 0.9285505124450951 f1 0.9285181412460902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 4.09000039100647 s\n",
      "Accuracy 0.9282576866764275 precision 0.9292596588443224 specificity 0.8803858203541762 recall 0.9282576866764275 f1 0.9286832444689581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 4.139998912811279 s\n",
      "Accuracy 0.9253294289897511 precision 0.9247316843096144 specificity 0.8580217674233933 recall 0.9253294289897511 f1 0.9249842494083051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 4.156999111175537 s\n",
      "Accuracy 0.9253294289897511 precision 0.9262249378611322 specificity 0.870046083108176 recall 0.9253294289897511 f1 0.9257219683912224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 4.119000196456909 s\n",
      "Accuracy 0.9206442166910688 precision 0.9212473840014962 specificity 0.856059960971631 recall 0.9206442166910688 f1 0.9209223009551326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 4.113000154495239 s\n",
      "Accuracy 0.9332357247437775 precision 0.9330074639704556 specificity 0.8740916944089594 recall 0.9332357247437775 f1 0.9331147307540529\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 3.9750354290008545 s\n",
      "Accuracy 0.926207906295754 precision 0.925659749664482 specificity 0.8626796948436216 recall 0.926207906295754 f1 0.9258921787831311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 4.12000036239624 s\n",
      "Accuracy 0.9297218155197657 precision 0.929602023249477 specificity 0.8721315823923819 recall 0.9297218155197657 f1 0.9296602390222496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 4.091017246246338 s\n",
      "Accuracy 0.9203513909224011 precision 0.9220532193139258 specificity 0.8718955677399062 recall 0.9203513909224011 f1 0.9210410554688111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 4.1800549030303955 s\n",
      "Accuracy 0.9241581259150805 precision 0.9234520137964903 specificity 0.8590578535661428 recall 0.9241581259150805 f1 0.9237298362695789\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 4.069509744644165 s\n",
      "Accuracy 0.9174231332357248 precision 0.9184061442265582 specificity 0.8598832568231494 recall 0.9174231332357248 f1 0.9178563923955309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 4.041999340057373 s\n",
      "Accuracy 0.922108345534407 precision 0.9217743488925613 specificity 0.8523917274476394 recall 0.922108345534407 f1 0.9219308431693308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 4.105998992919922 s\n",
      "Accuracy 0.9232796486090776 precision 0.9222345478901481 specificity 0.8476967382842643 recall 0.9232796486090776 f1 0.9225710378971721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 4.017000675201416 s\n",
      "Accuracy 0.9297218155197657 precision 0.9305081940824559 specificity 0.8804976927046031 recall 0.9297218155197657 f1 0.9300645206884628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 4.131000280380249 s\n",
      "Accuracy 0.9212298682284041 precision 0.9210539995691135 specificity 0.8515764165552626 recall 0.9212298682284041 f1 0.9211393106173497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 4.141998529434204 s\n",
      "Accuracy 0.9247437774524158 precision 0.9237014165149612 specificity 0.8470522912659348 recall 0.9247437774524158 f1 0.9240427300268951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 4.116002798080444 s\n",
      "Accuracy 0.9244509516837481 precision 0.925048596573476 specificity 0.8671614043952346 recall 0.9244509516837481 f1 0.924723157627552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 4.107038736343384 s\n",
      "Accuracy 0.9300146412884334 precision 0.9298606424515631 specificity 0.8688044186973533 recall 0.9300146412884334 f1 0.9299349777403125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 4.01800012588501 s\n",
      "Accuracy 0.9259150805270864 precision 0.9267274279430131 specificity 0.8693059465957391 recall 0.9259150805270864 f1 0.9262749397293688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 4.098022699356079 s\n",
      "Accuracy 0.930307467057101 precision 0.9302488962316177 specificity 0.8762468799962864 recall 0.930307467057101 f1 0.9302777653509267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 4.07803750038147 s\n",
      "Accuracy 0.9285505124450951 precision 0.9279177011423921 specificity 0.8673472908155896 recall 0.9285505124450951 f1 0.9281638712881264\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 4.125002384185791 s\n",
      "Accuracy 0.9297218155197657 precision 0.9291883267019931 specificity 0.8662719597372623 recall 0.9297218155197657 f1 0.9294127159725877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 4.360729694366455 s\n",
      "Accuracy 0.9235724743777453 precision 0.9232823692507586 specificity 0.8575414496728877 recall 0.9235724743777453 f1 0.923418951228835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 4.199999809265137 s\n",
      "Accuracy 0.9188872620790629 precision 0.918303978374402 specificity 0.8412833319389619 recall 0.9188872620790629 f1 0.9185651221529927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 4.211998701095581 s\n",
      "Accuracy 0.9212298682284041 precision 0.9210639955254345 specificity 0.8574305415966315 recall 0.9212298682284041 f1 0.921144358754051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 4.070000171661377 s\n",
      "Accuracy 0.9297218155197657 precision 0.9297218155197657 specificity 0.8758993288015542 recall 0.9297218155197657 f1 0.9297218155197657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 4.066040277481079 s\n",
      "Accuracy 0.9317715959004392 precision 0.9325531779992455 specificity 0.8872979705693865 recall 0.9317715959004392 f1 0.9321076371814188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 4.164000988006592 s\n",
      "Accuracy 0.9212298682284041 precision 0.9206123867405399 specificity 0.8535625292753719 recall 0.9212298682284041 f1 0.9208756422167873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 4.223000526428223 s\n",
      "Accuracy 0.9291361639824305 precision 0.9292524259188661 specificity 0.881580071822985 recall 0.9291361639824305 f1 0.9291926734365916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 4.13300085067749 s\n",
      "Accuracy 0.9279648609077599 precision 0.9276726843702569 specificity 0.8676377465070999 recall 0.9279648609077599 f1 0.9278083102790465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 4.181999206542969 s\n",
      "Accuracy 0.927086383601757 precision 0.9263264623019181 specificity 0.8576994215431915 recall 0.927086383601757 f1 0.92661723216584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 4.310999631881714 s\n",
      "Accuracy 0.9194729136163983 precision 0.920402790103273 specificity 0.8618827407491121 recall 0.9194729136163983 f1 0.9198838515518885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 4.131999969482422 s\n",
      "Accuracy 0.9256222547584187 precision 0.9256843865626209 specificity 0.8722296230934591 recall 0.9256222547584187 f1 0.9256529134225333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 4.219999313354492 s\n",
      "Accuracy 0.922108345534407 precision 0.9219716365196318 specificity 0.8559068229046903 recall 0.922108345534407 f1 0.9220383226921152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 4.1520469188690186 s\n",
      "Accuracy 0.9288433382137629 precision 0.9287521616879231 specificity 0.8713426741181659 recall 0.9288433382137629 f1 0.9287968084513603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 4.180046081542969 s\n",
      "Accuracy 0.9218155197657394 precision 0.9217822396098507 specificity 0.8611404597387496 recall 0.9218155197657394 f1 0.9217987772723597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 4.101088523864746 s\n",
      "Accuracy 0.9250366032210835 precision 0.9250366032210835 specificity 0.8695402095990679 recall 0.9250366032210835 f1 0.9250366032210835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 4.063000679016113 s\n",
      "Accuracy 0.926207906295754 precision 0.9259690730523129 specificity 0.866824574225963 recall 0.926207906295754 f1 0.926081863333951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 4.0909998416900635 s\n",
      "Accuracy 0.9235724743777453 precision 0.9251594379266415 specificity 0.8781502367799527 recall 0.9235724743777453 f1 0.9242120149515951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 4.15700101852417 s\n",
      "Accuracy 0.9300146412884334 precision 0.9294808566168993 specificity 0.8628550127766667 recall 0.9300146412884334 f1 0.9297088999413715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 4.062047004699707 s\n",
      "Accuracy 0.9288433382137629 precision 0.9282182444335708 specificity 0.8662852376079073 recall 0.9288433382137629 f1 0.9284653827389027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 4.117001056671143 s\n",
      "Accuracy 0.9185944363103953 precision 0.9188053944723915 specificity 0.8602854665995731 recall 0.9185944363103953 f1 0.9186962936877737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 3.8489997386932373 s\n",
      "Accuracy 0.9247437774524158 precision 0.9261691905523276 specificity 0.8757352929504889 recall 0.9247437774524158 f1 0.9253305008207606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 4.031000852584839 s\n",
      "Accuracy 0.9294289897510981 precision 0.9293352635987072 specificity 0.8691825872139711 recall 0.9294289897510981 f1 0.9293811722991897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 3.8750007152557373 s\n",
      "Accuracy 0.92298682284041 precision 0.9234009115404689 specificity 0.8608046862467179 recall 0.92298682284041 f1 0.9231812192921268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 3.8929991722106934 s\n",
      "Accuracy 0.9224011713030746 precision 0.9218462761958511 specificity 0.8478208128383923 recall 0.9224011713030746 f1 0.9220929868972673\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 3.841998338699341 s\n",
      "Accuracy 0.9294289897510981 precision 0.9291087782108092 specificity 0.8676371732128918 recall 0.9294289897510981 f1 0.9292560710574369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 3.9030001163482666 s\n",
      "Accuracy 0.9218155197657394 precision 0.9226039324027834 specificity 0.8691961806395838 recall 0.9218155197657394 f1 0.9221650447770935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 3.928999662399292 s\n",
      "Accuracy 0.9235724743777453 precision 0.9231118127165111 specificity 0.8562957863747136 recall 0.9235724743777453 f1 0.9233186171184764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 3.8580000400543213 s\n",
      "Accuracy 0.930307467057101 precision 0.929844328414805 specificity 0.8633839521801581 recall 0.930307467057101 f1 0.9300482579322327\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 3.9449996948242188 s\n",
      "Accuracy 0.9265007320644216 precision 0.9259511149670773 specificity 0.8656948448495352 recall 0.9265007320644216 f1 0.9261804291343345\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 3.9825079441070557 s\n",
      "Accuracy 0.9203513909224011 precision 0.9208843933751639 specificity 0.8746021196374275 recall 0.9203513909224011 f1 0.9205928775431219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 3.827998638153076 s\n",
      "Accuracy 0.9279648609077599 precision 0.9277069434493765 specificity 0.8605135911590828 recall 0.9279648609077599 f1 0.9278290174900777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 3.8185107707977295 s\n",
      "Accuracy 0.9224011713030746 precision 0.9221587429750547 specificity 0.8517810790432293 recall 0.9224011713030746 f1 0.9222747763873409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 3.55500864982605 s\n",
      "Accuracy 0.9224011713030746 precision 0.923718193775914 specificity 0.8740014808970459 recall 0.9224011713030746 f1 0.9229495349907341\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 3.4670050144195557 s\n",
      "Accuracy 0.922108345534407 precision 0.9225583080069797 specificity 0.86156039418659 recall 0.922108345534407 f1 0.9223184140612823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 3.6209793090820312 s\n",
      "Accuracy 0.9273792093704246 precision 0.9270940163200702 specificity 0.8694462993470903 recall 0.9273792093704246 f1 0.9272262738922818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 3.521998405456543 s\n",
      "Accuracy 0.9244509516837481 precision 0.9239788670827349 specificity 0.8593887826956469 recall 0.9244509516837481 f1 0.924188252092151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 3.5815181732177734 s\n",
      "Accuracy 0.9212298682284041 precision 0.9207806168367427 specificity 0.8576141706156347 recall 0.9212298682284041 f1 0.9209822574619589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 3.5805203914642334 s\n",
      "Accuracy 0.926207906295754 precision 0.9280633043305441 specificity 0.8813649240438914 recall 0.926207906295754 f1 0.9269361752256796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 3.5700433254241943 s\n",
      "Accuracy 0.9285505124450951 precision 0.9285505124450951 specificity 0.8676321252880475 recall 0.9285505124450951 f1 0.9285505124450951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 3.6429998874664307 s\n",
      "Accuracy 0.9232796486090776 precision 0.9228768854348922 specificity 0.8630292978974878 recall 0.9232796486090776 f1 0.9230582785697616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 3.483027458190918 s\n",
      "Accuracy 0.9241581259150805 precision 0.92372391995389 specificity 0.8619405915412062 recall 0.9241581259150805 f1 0.9239178410310989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 3.6670005321502686 s\n",
      "Accuracy 0.9341142020497804 precision 0.9334887726257699 specificity 0.8717918462545506 recall 0.9341142020497804 f1 0.933723383668885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 3.6719982624053955 s\n",
      "Accuracy 0.9279648609077599 precision 0.9285908600897513 specificity 0.8780958558183152 recall 0.9279648609077599 f1 0.9282444413334703\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 3.7290303707122803 s\n",
      "Accuracy 0.9288433382137629 precision 0.928676103489779 specificity 0.8603508353829995 recall 0.9288433382137629 f1 0.9287570013125914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 3.7855136394500732 s\n",
      "Accuracy 0.926207906295754 precision 0.9263333162404171 specificity 0.8735768407726682 recall 0.926207906295754 f1 0.9262689796478613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 3.785029649734497 s\n",
      "Accuracy 0.9314787701317716 precision 0.9328144025118986 specificity 0.890792654945963 recall 0.9314787701317716 f1 0.9320127530489553\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 3.7429986000061035 s\n",
      "Accuracy 0.9291361639824305 precision 0.92987990038514 specificity 0.8848322754713721 recall 0.9291361639824305 f1 0.9294587379175686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 3.6430296897888184 s\n",
      "Accuracy 0.9247437774524158 precision 0.923543318788406 specificity 0.8398291459529564 recall 0.9247437774524158 f1 0.9239024812565834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 3.7806508541107178 s\n",
      "Accuracy 0.9241581259150805 precision 0.9252613610344997 specificity 0.8765469627817419 recall 0.9241581259150805 f1 0.9246245048881281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 3.7860004901885986 s\n",
      "Accuracy 0.9241581259150805 precision 0.9241228312943007 specificity 0.8566140005242596 recall 0.9241581259150805 f1 0.9241403725290227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 3.803025722503662 s\n",
      "Accuracy 0.930307467057101 precision 0.9300424844958497 specificity 0.876842551014455 recall 0.930307467057101 f1 0.930164671410247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 3.843693733215332 s\n",
      "Accuracy 0.9256222547584187 precision 0.9257408727183741 specificity 0.8777882898322245 recall 0.9256222547584187 f1 0.9256799667365156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 3.6690680980682373 s\n",
      "Accuracy 0.9232796486090776 precision 0.9228023255268952 specificity 0.857898522524308 recall 0.9232796486090776 f1 0.9230144475543686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 3.80552077293396 s\n",
      "Accuracy 0.9224011713030746 precision 0.9222304457220388 specificity 0.8551860422423931 recall 0.9224011713030746 f1 0.9223131910398198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 3.7675201892852783 s\n",
      "Accuracy 0.9235724743777453 precision 0.9236672404241428 specificity 0.8704424205035225 recall 0.9235724743777453 f1 0.9236189499876375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 3.8630008697509766 s\n",
      "Accuracy 0.9247437774524158 precision 0.9247800790574636 specificity 0.8559745997386777 recall 0.9247437774524158 f1 0.9247618212357974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 3.7250001430511475 s\n",
      "Accuracy 0.9276720351390922 precision 0.9272175227228626 specificity 0.8682790478053505 recall 0.9276720351390922 f1 0.9274148653662535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 3.785008192062378 s\n",
      "Accuracy 0.9288433382137629 precision 0.928407259085602 specificity 0.8634794439905917 recall 0.9288433382137629 f1 0.9286013094895634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 3.8199987411499023 s\n",
      "Accuracy 0.9285505124450951 precision 0.9289333076427316 specificity 0.8806604467165196 recall 0.9285505124450951 f1 0.9287272222256615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 3.7290005683898926 s\n",
      "Accuracy 0.9259150805270864 precision 0.9261385973958903 specificity 0.8744773785581632 recall 0.9259150805270864 f1 0.9260218587622885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 3.7615771293640137 s\n",
      "Accuracy 0.9300146412884334 precision 0.9307657266072848 specificity 0.8797711554686982 recall 0.9300146412884334 f1 0.9303439673406254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 3.7240586280822754 s\n",
      "Accuracy 0.9247437774524158 precision 0.9258594670981478 specificity 0.8759883440269512 recall 0.9247437774524158 f1 0.9252157454851914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 3.7783288955688477 s\n",
      "Accuracy 0.9253294289897511 precision 0.9246141046857227 specificity 0.8534379329760449 recall 0.9253294289897511 f1 0.9249052876461336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 3.740008592605591 s\n",
      "Accuracy 0.9250366032210835 precision 0.9250366032210835 specificity 0.8617056247645107 recall 0.9250366032210835 f1 0.9250366032210835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 3.7001166343688965 s\n",
      "Accuracy 0.927086383601757 precision 0.9274668005322854 specificity 0.8717170317210426 recall 0.927086383601757 f1 0.9272639864199275\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 3.643000364303589 s\n",
      "Accuracy 0.92298682284041 precision 0.9233008314840472 specificity 0.8664338229285073 recall 0.92298682284041 f1 0.9231355400560797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 3.6739985942840576 s\n",
      "Accuracy 0.930307467057101 precision 0.9310316951408862 specificity 0.887888876756048 recall 0.930307467057101 f1 0.930620389939175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 3.6280009746551514 s\n",
      "Accuracy 0.9276720351390922 precision 0.9272630163592892 specificity 0.8576232726044318 recall 0.9276720351390922 f1 0.9274492828955354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 3.7139992713928223 s\n",
      "Accuracy 0.9244509516837481 precision 0.9237965974586252 specificity 0.8451007487387258 recall 0.9244509516837481 f1 0.9240802094362651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 3.692007303237915 s\n",
      "Accuracy 0.9273792093704246 precision 0.926653970253415 specificity 0.8598295425162077 recall 0.9273792093704246 f1 0.9269338060383909\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 3.705998182296753 s\n",
      "Accuracy 0.9323572474377745 precision 0.9326401586212792 specificity 0.8817420952071267 recall 0.9323572474377745 f1 0.9324902052328294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 3.6120240688323975 s\n",
      "Accuracy 0.9288433382137629 precision 0.9284862093808425 specificity 0.8703955804934533 recall 0.9288433382137629 f1 0.9286471870786467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 3.605818033218384 s\n",
      "Accuracy 0.9235724743777453 precision 0.9234097591437851 specificity 0.8604684826026512 recall 0.9235724743777453 f1 0.923488520799627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 3.5829994678497314 s\n",
      "Accuracy 0.9256222547584187 precision 0.9250407701279295 specificity 0.85719421404567 recall 0.9256222547584187 f1 0.9252892557060555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 3.599214553833008 s\n",
      "Accuracy 0.930307467057101 precision 0.9306222267584154 specificity 0.8811953215063264 recall 0.930307467057101 f1 0.9304545241759952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 3.690006971359253 s\n",
      "Accuracy 0.9250366032210835 precision 0.9242352262462666 specificity 0.8544356715829701 recall 0.9250366032210835 f1 0.9245410670134745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 3.4490010738372803 s\n",
      "Accuracy 0.9291361639824305 precision 0.9294693534864913 specificity 0.8755234590006333 recall 0.9291361639824305 f1 0.9292923095061821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 3.68599796295166 s\n",
      "Accuracy 0.9288433382137629 precision 0.9290030335917725 specificity 0.8744823493100206 recall 0.9288433382137629 f1 0.928920582831859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 3.561999797821045 s\n",
      "Accuracy 0.9259150805270864 precision 0.9266813256491289 specificity 0.8748927715362714 recall 0.9259150805270864 f1 0.9262528588447358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 3.570997714996338 s\n",
      "Accuracy 0.9256222547584187 precision 0.9263497638350219 specificity 0.8740860032283203 recall 0.9256222547584187 f1 0.9259449020041488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 3.585005044937134 s\n",
      "Accuracy 0.9317715959004392 precision 0.9313738909724003 specificity 0.8726037910736446 recall 0.9317715959004392 f1 0.9315489602544424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 3.5060019493103027 s\n",
      "Accuracy 0.9232796486090776 precision 0.9229154500783435 specificity 0.8601686970196515 recall 0.9232796486090776 f1 0.9230826947797748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 3.6399998664855957 s\n",
      "Accuracy 0.9294289897510981 precision 0.9289260638882711 specificity 0.8678293839707727 recall 0.9294289897510981 f1 0.929139590649313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 3.5420002937316895 s\n",
      "Accuracy 0.9279648609077599 precision 0.9285077122603931 specificity 0.8785096722388989 recall 0.9279648609077599 f1 0.9282099794114361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 3.6040070056915283 s\n",
      "Accuracy 0.9300146412884334 precision 0.9302354685030191 specificity 0.8781120595550991 recall 0.9300146412884334 f1 0.9301199618683156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 3.5736238956451416 s\n",
      "Accuracy 0.92298682284041 precision 0.9236381667904727 specificity 0.8645300275866638 recall 0.92298682284041 f1 0.9232825238466104\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 3.828998565673828 s\n",
      "Accuracy 0.9294289897510981 precision 0.9287678204848698 specificity 0.8562571002792048 recall 0.9294289897510981 f1 0.9290405982736484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 3.897000789642334 s\n",
      "Accuracy 0.9206442166910688 precision 0.9200243408195482 specificity 0.8451988920062999 recall 0.9206442166910688 f1 0.920296158378574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 3.9155080318450928 s\n",
      "Accuracy 0.92298682284041 precision 0.9223366743160106 specificity 0.8492572580597074 recall 0.92298682284041 f1 0.9226149643379165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 3.9710350036621094 s\n",
      "Accuracy 0.9218155197657394 precision 0.9221997549034063 specificity 0.8673224600076019 recall 0.9218155197657394 f1 0.9219953977421211\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 3.751014232635498 s\n",
      "Accuracy 0.9267935578330894 precision 0.9271516468229263 specificity 0.8672870932952865 recall 0.9267935578330894 f1 0.9269620478523157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 3.7449989318847656 s\n",
      "Accuracy 0.9285505124450951 precision 0.9278781531050991 specificity 0.8623687636741376 recall 0.9285505124450951 f1 0.9281427910524592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 3.764522075653076 s\n",
      "Accuracy 0.9314787701317716 precision 0.9316590449776543 specificity 0.8821814571699634 recall 0.9314787701317716 f1 0.9315651815858766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 3.7235360145568848 s\n",
      "Accuracy 0.9185944363103953 precision 0.9176679938784839 specificity 0.8432656947623155 recall 0.9185944363103953 f1 0.9180249514573169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 3.984988212585449 s\n",
      "Accuracy 0.9291361639824305 precision 0.9286661864560192 specificity 0.8616091928113134 recall 0.9291361639824305 f1 0.9288736453699743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 3.977118968963623 s\n",
      "Accuracy 0.9256222547584187 precision 0.9247648913936787 specificity 0.8482857474313058 recall 0.9256222547584187 f1 0.9250962756716617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 3.9359991550445557 s\n",
      "Accuracy 0.9212298682284041 precision 0.9208123702175485 specificity 0.8529644222401501 recall 0.9212298682284041 f1 0.9210035623615599\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 3.9689993858337402 s\n",
      "Accuracy 0.9215226939970718 precision 0.9210810920510367 specificity 0.8538627986971218 recall 0.9215226939970718 f1 0.9212815573852858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 4.285508871078491 s\n",
      "Accuracy 0.9212298682284041 precision 0.9202570398800874 specificity 0.8446867080103941 recall 0.9212298682284041 f1 0.9206145338533552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 4.125999450683594 s\n",
      "Accuracy 0.9297218155197657 precision 0.9305357945579227 specificity 0.8773458821483772 recall 0.9297218155197657 f1 0.9300776664403719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 3.9960765838623047 s\n",
      "Accuracy 0.9256222547584187 precision 0.926348441433278 specificity 0.8742533465181377 recall 0.9256222547584187 f1 0.9259442672488382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 4.170509099960327 s\n",
      "Accuracy 0.9235724743777453 precision 0.9239572848849196 specificity 0.8683450502925454 recall 0.9235724743777453 f1 0.9237525032110523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 4.029000759124756 s\n",
      "Accuracy 0.9232796486090776 precision 0.9232084455624104 specificity 0.8542817047444502 recall 0.9232796486090776 f1 0.923243622970787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 4.137000322341919 s\n",
      "Accuracy 0.9267935578330894 precision 0.9263778608178662 specificity 0.8617461339590314 recall 0.9267935578330894 f1 0.9265650350270815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 3.974000930786133 s\n",
      "Accuracy 0.92298682284041 precision 0.9230864508522104 specificity 0.8656419773929407 recall 0.92298682284041 f1 0.9230357179278375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 3.9439995288848877 s\n",
      "Accuracy 0.9291361639824305 precision 0.9297322690243106 specificity 0.8831408903791969 recall 0.9291361639824305 f1 0.9294011246434757\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 4.043999671936035 s\n",
      "Accuracy 0.9297218155197657 precision 0.9294908727252458 specificity 0.8714468494597616 recall 0.9297218155197657 f1 0.9295996296632091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 4.03850793838501 s\n",
      "Accuracy 0.9250366032210835 precision 0.9246952525111368 specificity 0.8666738035807868 recall 0.9250366032210835 f1 0.9248512027955713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 3.919999599456787 s\n",
      "Accuracy 0.9250366032210835 precision 0.9253306322524529 specificity 0.8616949159501603 recall 0.9250366032210835 f1 0.9251768453708695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 4.007999897003174 s\n",
      "Accuracy 0.9320644216691069 precision 0.9317891035721926 specificity 0.8745828522242309 recall 0.9320644216691069 f1 0.9319161974169929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 3.9050004482269287 s\n",
      "Accuracy 0.9241581259150805 precision 0.9242605607221553 specificity 0.8637254445419944 recall 0.9241581259150805 f1 0.9242084089172362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 3.964509963989258 s\n",
      "Accuracy 0.9285505124450951 precision 0.9286082993837195 specificity 0.879939904667382 recall 0.9285505124450951 f1 0.928579000682317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 3.909043312072754 s\n",
      "Accuracy 0.9285505124450951 precision 0.9282679834961964 specificity 0.8707949183012703 recall 0.9285505124450951 f1 0.9283988571486032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 3.9609992504119873 s\n",
      "Accuracy 0.9226939970717423 precision 0.9224373796645557 specificity 0.8585511374053412 recall 0.9226939970717423 f1 0.9225590618905075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 3.876999616622925 s\n",
      "Accuracy 0.930307467057101 precision 0.9310026430682166 specificity 0.881631133924911 recall 0.930307467057101 f1 0.9306133866392174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 3.9990389347076416 s\n",
      "Accuracy 0.9224011713030746 precision 0.9223663271522504 specificity 0.8569911315237634 recall 0.9224011713030746 f1 0.9223836448511303\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 3.933511257171631 s\n",
      "Accuracy 0.931185944363104 precision 0.9321288445581802 specificity 0.887996445574003 recall 0.931185944363104 f1 0.9315822523829488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 3.927999496459961 s\n",
      "Accuracy 0.9297218155197657 precision 0.9301235727334999 specificity 0.8773130481122425 recall 0.9297218155197657 f1 0.9299076415976191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 3.9730498790740967 s\n",
      "Accuracy 0.9338213762811127 precision 0.9340046745095789 specificity 0.8822673099229761 recall 0.9338213762811127 f1 0.9339092155393579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 3.927506685256958 s\n",
      "Accuracy 0.926207906295754 precision 0.925566070533023 specificity 0.8608114224053302 recall 0.926207906295754 f1 0.9258267910562005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 3.9910008907318115 s\n",
      "Accuracy 0.9265007320644216 precision 0.9261795965909653 specificity 0.8660685655819091 recall 0.9265007320644216 f1 0.9263276008875632\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 4.020000219345093 s\n",
      "Accuracy 0.9265007320644216 precision 0.9261618177238308 specificity 0.8611878694317112 recall 0.9265007320644216 f1 0.9263184876079447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 3.9175078868865967 s\n",
      "Accuracy 0.9267935578330894 precision 0.9269957912744525 specificity 0.8693024432199529 recall 0.9267935578330894 f1 0.9268909172560145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 3.961036443710327 s\n",
      "Accuracy 0.9241581259150805 precision 0.9243315929431528 specificity 0.8640550609215053 recall 0.9241581259150805 f1 0.9242422626149162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 3.9709999561309814 s\n",
      "Accuracy 0.9273792093704246 precision 0.9281075166602158 specificity 0.8752759072076765 recall 0.9273792093704246 f1 0.9277017811841354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 3.9350414276123047 s\n",
      "Accuracy 0.9171303074670571 precision 0.9170941715756237 specificity 0.8504365464385554 recall 0.9171303074670571 f1 0.9171121373199339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 3.9509994983673096 s\n",
      "Accuracy 0.9306002928257686 precision 0.9305675611585136 specificity 0.8674229108788571 recall 0.9306002928257686 f1 0.9305838188646897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 3.8949995040893555 s\n",
      "Accuracy 0.9232796486090776 precision 0.9231561559092192 specificity 0.8660526618032244 recall 0.9232796486090776 f1 0.9232162760010492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 4.009999752044678 s\n",
      "Accuracy 0.9370424597364568 precision 0.9375024977617753 specificity 0.8924219871469563 recall 0.9370424597364568 f1 0.9372487073983387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 3.6759989261627197 s\n",
      "Accuracy 0.9203513909224011 precision 0.9208029700885361 specificity 0.8600511180989353 recall 0.9203513909224011 f1 0.9205624099422615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 3.7631239891052246 s\n",
      "Accuracy 0.9191800878477306 precision 0.9189121991547009 specificity 0.8526813658509759 recall 0.9191800878477306 f1 0.9190395741126902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 3.635000467300415 s\n",
      "Accuracy 0.927086383601757 precision 0.9273319267492555 specificity 0.8666300491227451 recall 0.927086383601757 f1 0.927203971636429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 3.7328109741210938 s\n",
      "Accuracy 0.9338213762811127 precision 0.9335269083371502 specificity 0.869477194411215 recall 0.9338213762811127 f1 0.9336631791685863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 3.7135980129241943 s\n",
      "Accuracy 0.9308931185944364 precision 0.9311556497924083 specificity 0.8761415777503434 recall 0.9308931185944364 f1 0.9310176158865636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 3.884002923965454 s\n",
      "Accuracy 0.927086383601757 precision 0.9271886784661735 specificity 0.8655363056182858 recall 0.927086383601757 f1 0.9271365786067456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 3.9789962768554688 s\n",
      "Accuracy 0.9276720351390922 precision 0.9272999048127771 specificity 0.8663755431824955 recall 0.9276720351390922 f1 0.927468294855409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 3.7980000972747803 s\n",
      "Accuracy 0.9209370424597365 precision 0.920330599176925 specificity 0.8582183169031712 recall 0.9209370424597365 f1 0.9205848135524382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 3.846999406814575 s\n",
      "Accuracy 0.913909224011713 precision 0.9145630442716193 specificity 0.8506921722655252 recall 0.913909224011713 f1 0.9142103544915782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 3.815999984741211 s\n",
      "Accuracy 0.9265007320644216 precision 0.927100677601507 specificity 0.8748522583946198 recall 0.9265007320644216 f1 0.926770943737017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 3.8099992275238037 s\n",
      "Accuracy 0.9226939970717423 precision 0.9251042105773304 specificity 0.8857013126889818 recall 0.9226939970717423 f1 0.9235879862292746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 3.8039989471435547 s\n",
      "Accuracy 0.9203513909224011 precision 0.921227196123278 specificity 0.8632350636546918 recall 0.9203513909224011 f1 0.9207397901135913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 3.8299973011016846 s\n",
      "Accuracy 0.9335285505124451 precision 0.932887262001707 specificity 0.8696640921960286 recall 0.9335285505124451 f1 0.9331295591831844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 3.8295087814331055 s\n",
      "Accuracy 0.9174231332357248 precision 0.9178962718990519 specificity 0.8533098509043503 recall 0.9174231332357248 f1 0.9176449578013148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 3.765000343322754 s\n",
      "Accuracy 0.9244509516837481 precision 0.9243851960190467 specificity 0.8627969256717932 recall 0.9244509516837481 f1 0.9244176578447995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 3.870999813079834 s\n",
      "Accuracy 0.9250366032210835 precision 0.9245087683206802 specificity 0.8582067046183047 recall 0.9250366032210835 f1 0.9247386940165748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 3.971999406814575 s\n",
      "Accuracy 0.9308931185944364 precision 0.9299577366804962 specificity 0.856048345647166 recall 0.9308931185944364 f1 0.9302505413521155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 3.991000175476074 s\n",
      "Accuracy 0.9232796486090776 precision 0.923776440049622 specificity 0.8694663517456411 recall 0.9232796486090776 f1 0.923508077133337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 3.9389994144439697 s\n",
      "Accuracy 0.9320644216691069 precision 0.9326904412621239 specificity 0.8810612762887412 recall 0.9320644216691069 f1 0.9323430870362339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 4.018039703369141 s\n",
      "Accuracy 0.9282576866764275 precision 0.9294130917266634 specificity 0.8834241066490348 recall 0.9282576866764275 f1 0.9287367573582629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 4.074000597000122 s\n",
      "Accuracy 0.926207906295754 precision 0.9254532052862237 specificity 0.8631251767355144 recall 0.926207906295754 f1 0.9257250273157219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 4.059999465942383 s\n",
      "Accuracy 0.9329428989751098 precision 0.933438484392444 specificity 0.8834192711157228 recall 0.9329428989751098 f1 0.9331669562035996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 3.9859988689422607 s\n",
      "Accuracy 0.9273792093704246 precision 0.9281061883185647 specificity 0.8754447293393722 recall 0.9273792093704246 f1 0.9277011445288977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 3.98099946975708 s\n",
      "Accuracy 0.9285505124450951 precision 0.9285505124450951 specificity 0.8680033602730151 recall 0.9285505124450951 f1 0.9285505124450951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 4.0075085163116455 s\n",
      "Accuracy 0.9291361639824305 precision 0.92861128760463 specificity 0.8674353320062435 recall 0.9291361639824305 f1 0.9288317704077612\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 4.230998992919922 s\n",
      "Accuracy 0.9247437774524158 precision 0.9244659309973282 specificity 0.8621541302787378 recall 0.9247437774524158 f1 0.9245964366085844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 4.090999126434326 s\n",
      "Accuracy 0.9273792093704246 precision 0.9276965358329613 specificity 0.8785714165802013 recall 0.9273792093704246 f1 0.9275277138186486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 3.9420533180236816 s\n",
      "Accuracy 0.9253294289897511 precision 0.9255757977803375 specificity 0.8652367414200027 recall 0.9253294289897511 f1 0.9254474845245457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 4.247000217437744 s\n",
      "Accuracy 0.9267935578330894 precision 0.9277131932020559 specificity 0.8825577878504363 recall 0.9267935578330894 f1 0.9271850762822349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 4.077999591827393 s\n",
      "Accuracy 0.9288433382137629 precision 0.9290659619457617 specificity 0.8766800905480466 recall 0.9288433382137629 f1 0.9289495824914233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 4.014000177383423 s\n",
      "Accuracy 0.9218155197657394 precision 0.9218482357516229 specificity 0.8645292447381235 recall 0.9218155197657394 f1 0.9218317763934241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 3.8999993801116943 s\n",
      "Accuracy 0.9306002928257686 precision 0.930831885894184 specificity 0.8742763095592585 recall 0.9306002928257686 f1 0.9307108884963397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 3.9900004863739014 s\n",
      "Accuracy 0.9308931185944364 precision 0.9303468735444576 specificity 0.870556667579726 recall 0.9308931185944364 f1 0.9305691453623819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 4.006999731063843 s\n",
      "Accuracy 0.9267935578330894 precision 0.926443999779159 specificity 0.8654313925100462 recall 0.9267935578330894 f1 0.926603767001952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 3.9679999351501465 s\n",
      "Accuracy 0.927086383601757 precision 0.9266275926686044 specificity 0.8580695797548529 recall 0.927086383601757 f1 0.926832901447472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 3.99399995803833 s\n",
      "Accuracy 0.9265007320644216 precision 0.9261589883770095 specificity 0.8604046970601171 recall 0.9265007320644216 f1 0.9263170372801508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 3.977999687194824 s\n",
      "Accuracy 0.9209370424597365 precision 0.9208692697689825 specificity 0.8580127591940876 recall 0.9209370424597365 f1 0.9209027453115683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 3.999511480331421 s\n",
      "Accuracy 0.9250366032210835 precision 0.9248519684938956 specificity 0.8654313480101626 recall 0.9250366032210835 f1 0.9249405704882812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 3.990999221801758 s\n",
      "Accuracy 0.9188872620790629 precision 0.9184929405267903 specificity 0.8572315543795593 recall 0.9188872620790629 f1 0.918673103184344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 3.9989988803863525 s\n",
      "Accuracy 0.9226939970717423 precision 0.9235170619277856 specificity 0.8710342095740277 recall 0.9226939970717423 f1 0.9230564078059049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 3.9590001106262207 s\n",
      "Accuracy 0.930307467057101 precision 0.9307106805525737 specificity 0.8773824079003261 recall 0.930307467057101 f1 0.9304939416668033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 3.9590003490448 s\n",
      "Accuracy 0.934407027818448 precision 0.9349529707063882 specificity 0.8825661090629421 recall 0.934407027818448 f1 0.934652451580574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 3.990000009536743 s\n",
      "Accuracy 0.9265007320644216 precision 0.9265992984684971 specificity 0.8686947378318773 recall 0.9265007320644216 f1 0.9265490787809724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 3.9640004634857178 s\n",
      "Accuracy 0.9241581259150805 precision 0.9234514163016164 specificity 0.8542117504482507 recall 0.9241581259150805 f1 0.9237391008971175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 3.9255073070526123 s\n",
      "Accuracy 0.9308931185944364 precision 0.9309568382849197 specificity 0.8730633818943223 recall 0.9308931185944364 f1 0.9309245528400841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 4.006999254226685 s\n",
      "Accuracy 0.922108345534407 precision 0.9224156154078519 specificity 0.8553197169498309 recall 0.922108345534407 f1 0.9222552331323886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 3.975999593734741 s\n",
      "Accuracy 0.9291361639824305 precision 0.9294835761382778 specificity 0.8716826792781444 recall 0.9291361639824305 f1 0.9292992623210417\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 3.9879984855651855 s\n",
      "Accuracy 0.9279648609077599 precision 0.9278999165396102 specificity 0.8658230178801188 recall 0.9279648609077599 f1 0.927931964433095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 3.983001470565796 s\n",
      "Accuracy 0.9259150805270864 precision 0.9251325780115977 specificity 0.854800875580127 recall 0.9259150805270864 f1 0.9254346083295198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 4.047000408172607 s\n",
      "Accuracy 0.9250366032210835 precision 0.9244721617250028 specificity 0.8596803489882848 recall 0.9250366032210835 f1 0.9247126935359424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 3.966048002243042 s\n",
      "Accuracy 0.9294289897510981 precision 0.9300684045024701 specificity 0.882874382372364 recall 0.9294289897510981 f1 0.9297116426552164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 3.946028232574463 s\n",
      "Accuracy 0.9250366032210835 precision 0.9245918286547773 specificity 0.8648655252153187 recall 0.9250366032210835 f1 0.9247879453282082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 3.9875104427337646 s\n",
      "Accuracy 0.922108345534407 precision 0.9228292190737822 specificity 0.86026978522295 recall 0.922108345534407 f1 0.9224349125040452\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 3.9440009593963623 s\n",
      "Accuracy 0.9291361639824305 precision 0.931059285218493 specificity 0.8967954612571534 recall 0.9291361639824305 f1 0.9298480765667013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 4.007999658584595 s\n",
      "Accuracy 0.9265007320644216 precision 0.9264066707543109 specificity 0.8673305298858652 recall 0.9265007320644216 f1 0.9264527650711639\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 3.929999351501465 s\n",
      "Accuracy 0.9323572474377745 precision 0.9331415376150557 specificity 0.8874678032158724 recall 0.9323572474377745 f1 0.9326943611491443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 4.12999963760376 s\n",
      "Accuracy 0.9349926793557833 precision 0.9351746269692979 specificity 0.8836032839391269 recall 0.9349926793557833 f1 0.9350798207473132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 4.115001201629639 s\n",
      "Accuracy 0.9238653001464129 precision 0.923535319514231 specificity 0.8543855385950786 recall 0.9238653001464129 f1 0.9236897218860934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 4.011998891830444 s\n",
      "Accuracy 0.927086383601757 precision 0.9269250325414874 specificity 0.8630241901472809 recall 0.927086383601757 f1 0.9270030568234395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 4.104039907455444 s\n",
      "Accuracy 0.9253294289897511 precision 0.9256171402965553 specificity 0.8757306643721715 recall 0.9253294289897511 f1 0.925465118745329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 4.073031187057495 s\n",
      "Accuracy 0.9224011713030746 precision 0.9219019716660578 specificity 0.8478640555587521 recall 0.9224011713030746 f1 0.9221276125076621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 4.0345094203948975 s\n",
      "Accuracy 0.9256222547584187 precision 0.9243916551186389 specificity 0.8436070803770942 recall 0.9256222547584187 f1 0.9244818067106716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 3.794229030609131 s\n",
      "Accuracy 0.9267935578330894 precision 0.926923650435562 specificity 0.8707166135202461 recall 0.9267935578330894 f1 0.9268569461186049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 3.836862802505493 s\n",
      "Accuracy 0.9314787701317716 precision 0.9330126699587393 specificity 0.8969014914496128 recall 0.9314787701317716 f1 0.9320672788886856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 3.8150291442871094 s\n",
      "Accuracy 0.9300146412884334 precision 0.9303641558635646 specificity 0.8811044174208112 recall 0.9300146412884334 f1 0.9301769244255653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 3.80600905418396 s\n",
      "Accuracy 0.9232796486090776 precision 0.9235710695576802 specificity 0.8615206629164878 recall 0.9232796486090776 f1 0.9234186855621819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 3.8550002574920654 s\n",
      "Accuracy 0.9250366032210835 precision 0.9241471728956333 specificity 0.8521026907342644 recall 0.9250366032210835 f1 0.9244694219542964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 3.7569611072540283 s\n",
      "Accuracy 0.9253294289897511 precision 0.9251130844258959 specificity 0.8642438650151384 recall 0.9253294289897511 f1 0.9252161694424531\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 3.981633186340332 s\n",
      "Accuracy 0.9212298682284041 precision 0.9211301070187355 specificity 0.8590582544848228 recall 0.9212298682284041 f1 0.9211790650556815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 3.872781753540039 s\n",
      "Accuracy 0.9308931185944364 precision 0.931091663878959 specificity 0.8734772064054653 recall 0.9308931185944364 f1 0.9309885513413262\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 3.8780274391174316 s\n",
      "Accuracy 0.9218155197657394 precision 0.922123343375284 specificity 0.8675166170240245 recall 0.9218155197657394 f1 0.9219612569973299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 3.7667829990386963 s\n",
      "Accuracy 0.9308931185944364 precision 0.9311506826802113 specificity 0.8778298704648394 recall 0.9308931185944364 f1 0.9310151786157281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 3.802999258041382 s\n",
      "Accuracy 0.9238653001464129 precision 0.9238653001464129 specificity 0.8626198007026449 recall 0.9238653001464129 f1 0.9238653001464129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 3.8385164737701416 s\n",
      "Accuracy 0.9326500732064422 precision 0.9321143374093247 specificity 0.8668635713592743 recall 0.9326500732064422 f1 0.9323388164760312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 3.877134084701538 s\n",
      "Accuracy 0.9265007320644216 precision 0.9258458235067399 specificity 0.8659534762839183 recall 0.9265007320644216 f1 0.926098477647768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 3.805346727371216 s\n",
      "Accuracy 0.9265007320644216 precision 0.9270941060974196 specificity 0.8758429850437371 recall 0.9265007320644216 f1 0.926767772852198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 3.826749801635742 s\n",
      "Accuracy 0.9212298682284041 precision 0.9206878811912652 specificity 0.8497574735437479 recall 0.9212298682284041 f1 0.9209286167552537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 3.7718567848205566 s\n",
      "Accuracy 0.9238653001464129 precision 0.9233960758091706 specificity 0.8596964937960039 recall 0.9238653001464129 f1 0.9236041866999521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 3.8889782428741455 s\n",
      "Accuracy 0.9273792093704246 precision 0.9267475433595098 specificity 0.8568649454181815 recall 0.9273792093704246 f1 0.9270114967524647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 3.7456371784210205 s\n",
      "Accuracy 0.9285505124450951 precision 0.9290189401240281 specificity 0.8783687036160903 recall 0.9285505124450951 f1 0.928764505536984\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "split_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "smote_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, (split_seed, smote_seed) in enumerate(zip(split_seeds, smote_seeds)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=split_seed)\n",
    "    smote = SMOTE(random_state=smote_seed, n_jobs=THREADS_TO_USE)\n",
    "    x_smote, y_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_smote, y_smote)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(split_seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.925622     0.862841   0.925556  0.925622  0.925589\n1  0.923865     0.863968   0.924075  0.923865  0.923967\n2  0.920644     0.860894   0.920820  0.920644  0.920729\n3  0.927086     0.875909   0.927682  0.927086  0.927354\n4  0.932650     0.875661   0.932479  0.932650  0.932561\n5  0.924451     0.858007   0.923717  0.924451  0.924003\n6  0.928843     0.870629   0.928875  0.928843  0.928859\n7  0.933821     0.879870   0.933764  0.933821  0.933792\n8  0.923865     0.873226   0.925158  0.923865  0.924406\n9  0.932064     0.879961   0.932318  0.932064  0.932184",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.925622</td>\n      <td>0.862841</td>\n      <td>0.925556</td>\n      <td>0.925622</td>\n      <td>0.925589</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.923865</td>\n      <td>0.863968</td>\n      <td>0.924075</td>\n      <td>0.923865</td>\n      <td>0.923967</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.920644</td>\n      <td>0.860894</td>\n      <td>0.920820</td>\n      <td>0.920644</td>\n      <td>0.920729</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.927086</td>\n      <td>0.875909</td>\n      <td>0.927682</td>\n      <td>0.927086</td>\n      <td>0.927354</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.932650</td>\n      <td>0.875661</td>\n      <td>0.932479</td>\n      <td>0.932650</td>\n      <td>0.932561</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.924451</td>\n      <td>0.858007</td>\n      <td>0.923717</td>\n      <td>0.924451</td>\n      <td>0.924003</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.928843</td>\n      <td>0.870629</td>\n      <td>0.928875</td>\n      <td>0.928843</td>\n      <td>0.928859</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.933821</td>\n      <td>0.879870</td>\n      <td>0.933764</td>\n      <td>0.933821</td>\n      <td>0.933792</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.923865</td>\n      <td>0.873226</td>\n      <td>0.925158</td>\n      <td>0.923865</td>\n      <td>0.924406</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.932064</td>\n      <td>0.879961</td>\n      <td>0.932318</td>\n      <td>0.932064</td>\n      <td>0.932184</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.9262717423133238\n",
      "Precision 0.9262897980456046\n",
      "Specificity 0.8670761481935747\n",
      "Recall 0.9262717423133238\n",
      "F1 0.9262485454814935\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_32beats_smote_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}