{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Paper CHF - 8 beats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sU5Wt4HhzLod"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1  \\\n0  e0106  30.571581  30.571114  30.597163   8.654545  1.254944  0.902949   \n1  e0106  35.327463  37.090233  36.619925  10.318908  1.501561  0.936195   \n2  e0106  33.754220  34.253945  34.112950   9.653801  1.420377  0.922050   \n3  e0106  33.428166  32.277378  32.154651   9.225828  1.332695  0.898518   \n4  e0106  34.438584  33.565638  33.382364   9.589036  1.426830  0.886530   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.773465 -1.399254 -0.734867  ... -0.052333  0.042084 -0.051954  0.052820   \n1 -0.694743 -1.301387 -0.880195  ... -0.025711  0.004880 -0.014158  0.033816   \n2 -0.707779 -1.271389 -0.778260  ... -0.041095  0.024671 -0.028207  0.045623   \n3 -0.728415 -1.302251 -0.708089  ... -0.053417  0.034100 -0.041100  0.034451   \n4 -0.727896 -1.310174 -0.910833  ... -0.077430  0.064301 -0.063539  0.066193   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.078516  0.018113 -0.033035 -0.008121 -0.004387    NSR  \n1 -0.052615 -0.010039 -0.020460 -0.003424 -0.010776    NSR  \n2 -0.069928 -0.007982 -0.010177 -0.011244 -0.007525    NSR  \n3 -0.060591 -0.005673 -0.010582 -0.020471  0.001472    NSR  \n4 -0.087852  0.018333 -0.028678 -0.022301  0.009486    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>30.571581</td>\n      <td>30.571114</td>\n      <td>30.597163</td>\n      <td>8.654545</td>\n      <td>1.254944</td>\n      <td>0.902949</td>\n      <td>-0.773465</td>\n      <td>-1.399254</td>\n      <td>-0.734867</td>\n      <td>...</td>\n      <td>-0.052333</td>\n      <td>0.042084</td>\n      <td>-0.051954</td>\n      <td>0.052820</td>\n      <td>-0.078516</td>\n      <td>0.018113</td>\n      <td>-0.033035</td>\n      <td>-0.008121</td>\n      <td>-0.004387</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>35.327463</td>\n      <td>37.090233</td>\n      <td>36.619925</td>\n      <td>10.318908</td>\n      <td>1.501561</td>\n      <td>0.936195</td>\n      <td>-0.694743</td>\n      <td>-1.301387</td>\n      <td>-0.880195</td>\n      <td>...</td>\n      <td>-0.025711</td>\n      <td>0.004880</td>\n      <td>-0.014158</td>\n      <td>0.033816</td>\n      <td>-0.052615</td>\n      <td>-0.010039</td>\n      <td>-0.020460</td>\n      <td>-0.003424</td>\n      <td>-0.010776</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>33.754220</td>\n      <td>34.253945</td>\n      <td>34.112950</td>\n      <td>9.653801</td>\n      <td>1.420377</td>\n      <td>0.922050</td>\n      <td>-0.707779</td>\n      <td>-1.271389</td>\n      <td>-0.778260</td>\n      <td>...</td>\n      <td>-0.041095</td>\n      <td>0.024671</td>\n      <td>-0.028207</td>\n      <td>0.045623</td>\n      <td>-0.069928</td>\n      <td>-0.007982</td>\n      <td>-0.010177</td>\n      <td>-0.011244</td>\n      <td>-0.007525</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>33.428166</td>\n      <td>32.277378</td>\n      <td>32.154651</td>\n      <td>9.225828</td>\n      <td>1.332695</td>\n      <td>0.898518</td>\n      <td>-0.728415</td>\n      <td>-1.302251</td>\n      <td>-0.708089</td>\n      <td>...</td>\n      <td>-0.053417</td>\n      <td>0.034100</td>\n      <td>-0.041100</td>\n      <td>0.034451</td>\n      <td>-0.060591</td>\n      <td>-0.005673</td>\n      <td>-0.010582</td>\n      <td>-0.020471</td>\n      <td>0.001472</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>34.438584</td>\n      <td>33.565638</td>\n      <td>33.382364</td>\n      <td>9.589036</td>\n      <td>1.426830</td>\n      <td>0.886530</td>\n      <td>-0.727896</td>\n      <td>-1.310174</td>\n      <td>-0.910833</td>\n      <td>...</td>\n      <td>-0.077430</td>\n      <td>0.064301</td>\n      <td>-0.063539</td>\n      <td>0.066193</td>\n      <td>-0.087852</td>\n      <td>0.018333</td>\n      <td>-0.028678</td>\n      <td>-0.022301</td>\n      <td>0.009486</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_8beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    52426\nST     15929\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.232673  0.111713  0.079107  0.076764  0.077147 -0.018860   \ndw_2    0.232673  1.000000  0.839282  0.452814  0.160598  0.424152 -0.484394   \ndw_3    0.111713  0.839282  1.000000  0.631576  0.240584  0.301445 -0.535593   \ndw_4    0.079107  0.452814  0.631576  1.000000  0.895025  0.016860 -0.237619   \ndw_5    0.076764  0.160598  0.240584  0.895025  1.000000 -0.105960 -0.011988   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.039241  0.029218  0.051187  0.042171  0.016035 -0.094790  0.068312   \ncfr_13 -0.027948  0.115506  0.045371  0.026140  0.013783  0.077604 -0.004769   \ncfr_14 -0.044903 -0.000752 -0.026800 -0.032931 -0.034165  0.032269  0.017775   \ncfr_15 -0.065581 -0.115788 -0.130477 -0.089245 -0.041855  0.009040  0.083235   \ncfr_16 -0.044688 -0.079295 -0.049044 -0.033579 -0.018000  0.054551 -0.035391   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.030559  0.040220 -0.014666  ... -0.053028 -0.055461 -0.025675   \ndw_2   -0.404156  0.100065  0.435652  ... -0.136686  0.140104  0.232989   \ndw_3   -0.534332 -0.030329  0.564342  ... -0.206789  0.121560  0.266346   \ndw_4   -0.260776 -0.029358  0.299563  ... -0.147248  0.048851  0.116574   \ndw_5   -0.035024 -0.012480  0.061799  ... -0.066765  0.004155  0.014207   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.129263  0.122377 -0.090957  ... -0.127261 -0.207625 -0.097674   \ncfr_13  0.006963  0.049874  0.008203  ...  0.128357  0.032112 -0.217503   \ncfr_14  0.034991  0.012523 -0.020623  ...  0.096622  0.214725  0.044225   \ncfr_15  0.080419 -0.058850 -0.098386  ...  0.258472  0.163393 -0.078272   \ncfr_16 -0.001319  0.067956  0.036802  ...  0.240666  0.138617  0.171483   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.018685 -0.009704 -0.039241 -0.027948 -0.044903 -0.065581 -0.044688  \ndw_2    0.166906  0.045325  0.029218  0.115506 -0.000752 -0.115788 -0.079295  \ndw_3    0.117884 -0.049549  0.051187  0.045371 -0.026800 -0.130477 -0.049044  \ndw_4    0.042862 -0.044403  0.042171  0.026140 -0.032931 -0.089245 -0.033579  \ndw_5    0.013282 -0.012686  0.016035  0.013783 -0.034165 -0.041855 -0.018000  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.019114  0.057081  1.000000  0.003281 -0.017734 -0.318789 -0.208539  \ncfr_13 -0.271096 -0.046139  0.003281  1.000000  0.186633  0.097077 -0.171867  \ncfr_14 -0.177405 -0.291133 -0.017734  0.186633  1.000000  0.157260 -0.146906  \ncfr_15 -0.146256 -0.095566 -0.318789  0.097077  0.157260  1.000000  0.229510  \ncfr_16  0.114201 -0.004097 -0.208539 -0.171867 -0.146906  0.229510  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.232673</td>\n      <td>0.111713</td>\n      <td>0.079107</td>\n      <td>0.076764</td>\n      <td>0.077147</td>\n      <td>-0.018860</td>\n      <td>0.030559</td>\n      <td>0.040220</td>\n      <td>-0.014666</td>\n      <td>...</td>\n      <td>-0.053028</td>\n      <td>-0.055461</td>\n      <td>-0.025675</td>\n      <td>-0.018685</td>\n      <td>-0.009704</td>\n      <td>-0.039241</td>\n      <td>-0.027948</td>\n      <td>-0.044903</td>\n      <td>-0.065581</td>\n      <td>-0.044688</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.232673</td>\n      <td>1.000000</td>\n      <td>0.839282</td>\n      <td>0.452814</td>\n      <td>0.160598</td>\n      <td>0.424152</td>\n      <td>-0.484394</td>\n      <td>-0.404156</td>\n      <td>0.100065</td>\n      <td>0.435652</td>\n      <td>...</td>\n      <td>-0.136686</td>\n      <td>0.140104</td>\n      <td>0.232989</td>\n      <td>0.166906</td>\n      <td>0.045325</td>\n      <td>0.029218</td>\n      <td>0.115506</td>\n      <td>-0.000752</td>\n      <td>-0.115788</td>\n      <td>-0.079295</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.111713</td>\n      <td>0.839282</td>\n      <td>1.000000</td>\n      <td>0.631576</td>\n      <td>0.240584</td>\n      <td>0.301445</td>\n      <td>-0.535593</td>\n      <td>-0.534332</td>\n      <td>-0.030329</td>\n      <td>0.564342</td>\n      <td>...</td>\n      <td>-0.206789</td>\n      <td>0.121560</td>\n      <td>0.266346</td>\n      <td>0.117884</td>\n      <td>-0.049549</td>\n      <td>0.051187</td>\n      <td>0.045371</td>\n      <td>-0.026800</td>\n      <td>-0.130477</td>\n      <td>-0.049044</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.079107</td>\n      <td>0.452814</td>\n      <td>0.631576</td>\n      <td>1.000000</td>\n      <td>0.895025</td>\n      <td>0.016860</td>\n      <td>-0.237619</td>\n      <td>-0.260776</td>\n      <td>-0.029358</td>\n      <td>0.299563</td>\n      <td>...</td>\n      <td>-0.147248</td>\n      <td>0.048851</td>\n      <td>0.116574</td>\n      <td>0.042862</td>\n      <td>-0.044403</td>\n      <td>0.042171</td>\n      <td>0.026140</td>\n      <td>-0.032931</td>\n      <td>-0.089245</td>\n      <td>-0.033579</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.076764</td>\n      <td>0.160598</td>\n      <td>0.240584</td>\n      <td>0.895025</td>\n      <td>1.000000</td>\n      <td>-0.105960</td>\n      <td>-0.011988</td>\n      <td>-0.035024</td>\n      <td>-0.012480</td>\n      <td>0.061799</td>\n      <td>...</td>\n      <td>-0.066765</td>\n      <td>0.004155</td>\n      <td>0.014207</td>\n      <td>0.013282</td>\n      <td>-0.012686</td>\n      <td>0.016035</td>\n      <td>0.013783</td>\n      <td>-0.034165</td>\n      <td>-0.041855</td>\n      <td>-0.018000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.039241</td>\n      <td>0.029218</td>\n      <td>0.051187</td>\n      <td>0.042171</td>\n      <td>0.016035</td>\n      <td>-0.094790</td>\n      <td>0.068312</td>\n      <td>0.129263</td>\n      <td>0.122377</td>\n      <td>-0.090957</td>\n      <td>...</td>\n      <td>-0.127261</td>\n      <td>-0.207625</td>\n      <td>-0.097674</td>\n      <td>0.019114</td>\n      <td>0.057081</td>\n      <td>1.000000</td>\n      <td>0.003281</td>\n      <td>-0.017734</td>\n      <td>-0.318789</td>\n      <td>-0.208539</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.027948</td>\n      <td>0.115506</td>\n      <td>0.045371</td>\n      <td>0.026140</td>\n      <td>0.013783</td>\n      <td>0.077604</td>\n      <td>-0.004769</td>\n      <td>0.006963</td>\n      <td>0.049874</td>\n      <td>0.008203</td>\n      <td>...</td>\n      <td>0.128357</td>\n      <td>0.032112</td>\n      <td>-0.217503</td>\n      <td>-0.271096</td>\n      <td>-0.046139</td>\n      <td>0.003281</td>\n      <td>1.000000</td>\n      <td>0.186633</td>\n      <td>0.097077</td>\n      <td>-0.171867</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.044903</td>\n      <td>-0.000752</td>\n      <td>-0.026800</td>\n      <td>-0.032931</td>\n      <td>-0.034165</td>\n      <td>0.032269</td>\n      <td>0.017775</td>\n      <td>0.034991</td>\n      <td>0.012523</td>\n      <td>-0.020623</td>\n      <td>...</td>\n      <td>0.096622</td>\n      <td>0.214725</td>\n      <td>0.044225</td>\n      <td>-0.177405</td>\n      <td>-0.291133</td>\n      <td>-0.017734</td>\n      <td>0.186633</td>\n      <td>1.000000</td>\n      <td>0.157260</td>\n      <td>-0.146906</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.065581</td>\n      <td>-0.115788</td>\n      <td>-0.130477</td>\n      <td>-0.089245</td>\n      <td>-0.041855</td>\n      <td>0.009040</td>\n      <td>0.083235</td>\n      <td>0.080419</td>\n      <td>-0.058850</td>\n      <td>-0.098386</td>\n      <td>...</td>\n      <td>0.258472</td>\n      <td>0.163393</td>\n      <td>-0.078272</td>\n      <td>-0.146256</td>\n      <td>-0.095566</td>\n      <td>-0.318789</td>\n      <td>0.097077</td>\n      <td>0.157260</td>\n      <td>1.000000</td>\n      <td>0.229510</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.044688</td>\n      <td>-0.079295</td>\n      <td>-0.049044</td>\n      <td>-0.033579</td>\n      <td>-0.018000</td>\n      <td>0.054551</td>\n      <td>-0.035391</td>\n      <td>-0.001319</td>\n      <td>0.067956</td>\n      <td>0.036802</td>\n      <td>...</td>\n      <td>0.240666</td>\n      <td>0.138617</td>\n      <td>0.171483</td>\n      <td>0.114201</td>\n      <td>-0.004097</td>\n      <td>-0.208539</td>\n      <td>-0.171867</td>\n      <td>-0.146906</td>\n      <td>0.229510</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows Ã— 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()\n",
    "patient_ids = data[\"id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_176', 'fft_247', 'cfr_16', 'fft_183', 'fft_242', 'fft_133', 'fft_150', 'fft_161', 'fft_146', 'fft_218', 'fft_143', 'fft_165', 'fft_197', 'fft_217', 'fft_186', 'fft_207', 'fft_172', 'fft_152', 'fft_213', 'fft_160', 'fft_209', 'fft_131', 'fft_148', 'fft_155', 'fft_149', 'fft_168', 'fft_206', 'fft_170', 'fft_248', 'fft_188', 'fft_166', 'fft_231', 'fft_142', 'fft_204', 'fft_167', 'fft_136', 'fft_163', 'fft_235', 'fft_252', 'fft_244', 'fft_195', 'fft_249', 'fft_210', 'fft_147', 'fft_228', 'fft_200', 'fft_256', 'fft_191', 'fft_202', 'fft_208', 'fft_179', 'fft_219', 'fft_237', 'fft_182', 'fft_157', 'fft_138', 'fft_214', 'fft_232', 'fft_243', 'fft_193', 'fft_185', 'fft_215', 'mfw_11', 'fft_154', 'fft_201', 'fft_190', 'fft_140', 'fft_230', 'fft_199', 'fft_223', 'fft_250', 'fft_253', 'fft_130', 'fft_141', 'fft_171', 'fft_224', 'fft_227', 'fft_203', 'fft_225', 'fft_132', 'fft_184', 'fft_229', 'fft_175', 'fft_134', 'fft_164', 'fft_181', 'fft_180', 'fft_156', 'fft_212', 'fft_222', 'fft_240', 'fft_198', 'fft_178', 'fft_251', 'fft_255', 'fft_153', 'fft_194', 'fft_169', 'fft_159', 'fft_238', 'fft_220', 'fft_145', 'fft_246', 'fft_174', 'fft_139', 'fft_187', 'fft_137', 'fft_196', 'fft_241', 'fft_173', 'fft_236', 'fft_233', 'fft_234', 'fft_135', 'fft_162', 'fft_151', 'fft_192', 'fft_245', 'fft_205', 'fft_226', 'fft_216', 'fft_189', 'fft_144', 'fft_177', 'fft_221', 'fft_211', 'fft_254', 'fft_239', 'fft_158'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "mfw_5\n",
      "mfw_6\n",
      "mfw_7\n",
      "mfw_8\n",
      "mfw_9\n",
      "mfw_10\n",
      "mfw_12\n",
      "mfw_13\n",
      "mfw_14\n",
      "mfw_15\n",
      "mfw_16\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_24\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 77\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization best features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1     mfw_2  \\\n0  30.571581  30.571114  30.597163   8.654545  1.254944  0.902949 -0.773465   \n1  35.327463  37.090233  36.619925  10.318908  1.501561  0.936195 -0.694743   \n2  33.754220  34.253945  34.112950   9.653801  1.420377  0.922050 -0.707779   \n3  33.428166  32.277378  32.154651   9.225828  1.332695  0.898518 -0.728415   \n4  34.438584  33.565638  33.382364   9.589036  1.426830  0.886530 -0.727896   \n\n      mfw_3     mfw_4      mfw_5  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -1.399254 -0.734867  12.762118  ...  0.012196  0.047766 -0.052333  0.042084   \n1 -1.301387 -0.880195  10.573212  ...  0.022624  0.032716 -0.025711  0.004880   \n2 -1.271389 -0.778260  10.515795  ...  0.010279  0.036796 -0.041095  0.024671   \n3 -1.302251 -0.708089  11.496901  ...  0.005352  0.048697 -0.053417  0.034100   \n4 -1.310174 -0.910833  10.732432  ... -0.003147  0.052752 -0.077430  0.064301   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.051954  0.052820 -0.078516  0.018113 -0.033035 -0.008121  \n1 -0.014158  0.033816 -0.052615 -0.010039 -0.020460 -0.003424  \n2 -0.028207  0.045623 -0.069928 -0.007982 -0.010177 -0.011244  \n3 -0.041100  0.034451 -0.060591 -0.005673 -0.010582 -0.020471  \n4 -0.063539  0.066193 -0.087852  0.018333 -0.028678 -0.022301  \n\n[5 rows x 77 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30.571581</td>\n      <td>30.571114</td>\n      <td>30.597163</td>\n      <td>8.654545</td>\n      <td>1.254944</td>\n      <td>0.902949</td>\n      <td>-0.773465</td>\n      <td>-1.399254</td>\n      <td>-0.734867</td>\n      <td>12.762118</td>\n      <td>...</td>\n      <td>0.012196</td>\n      <td>0.047766</td>\n      <td>-0.052333</td>\n      <td>0.042084</td>\n      <td>-0.051954</td>\n      <td>0.052820</td>\n      <td>-0.078516</td>\n      <td>0.018113</td>\n      <td>-0.033035</td>\n      <td>-0.008121</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35.327463</td>\n      <td>37.090233</td>\n      <td>36.619925</td>\n      <td>10.318908</td>\n      <td>1.501561</td>\n      <td>0.936195</td>\n      <td>-0.694743</td>\n      <td>-1.301387</td>\n      <td>-0.880195</td>\n      <td>10.573212</td>\n      <td>...</td>\n      <td>0.022624</td>\n      <td>0.032716</td>\n      <td>-0.025711</td>\n      <td>0.004880</td>\n      <td>-0.014158</td>\n      <td>0.033816</td>\n      <td>-0.052615</td>\n      <td>-0.010039</td>\n      <td>-0.020460</td>\n      <td>-0.003424</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33.754220</td>\n      <td>34.253945</td>\n      <td>34.112950</td>\n      <td>9.653801</td>\n      <td>1.420377</td>\n      <td>0.922050</td>\n      <td>-0.707779</td>\n      <td>-1.271389</td>\n      <td>-0.778260</td>\n      <td>10.515795</td>\n      <td>...</td>\n      <td>0.010279</td>\n      <td>0.036796</td>\n      <td>-0.041095</td>\n      <td>0.024671</td>\n      <td>-0.028207</td>\n      <td>0.045623</td>\n      <td>-0.069928</td>\n      <td>-0.007982</td>\n      <td>-0.010177</td>\n      <td>-0.011244</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33.428166</td>\n      <td>32.277378</td>\n      <td>32.154651</td>\n      <td>9.225828</td>\n      <td>1.332695</td>\n      <td>0.898518</td>\n      <td>-0.728415</td>\n      <td>-1.302251</td>\n      <td>-0.708089</td>\n      <td>11.496901</td>\n      <td>...</td>\n      <td>0.005352</td>\n      <td>0.048697</td>\n      <td>-0.053417</td>\n      <td>0.034100</td>\n      <td>-0.041100</td>\n      <td>0.034451</td>\n      <td>-0.060591</td>\n      <td>-0.005673</td>\n      <td>-0.010582</td>\n      <td>-0.020471</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34.438584</td>\n      <td>33.565638</td>\n      <td>33.382364</td>\n      <td>9.589036</td>\n      <td>1.426830</td>\n      <td>0.886530</td>\n      <td>-0.727896</td>\n      <td>-1.310174</td>\n      <td>-0.910833</td>\n      <td>10.732432</td>\n      <td>...</td>\n      <td>-0.003147</td>\n      <td>0.052752</td>\n      <td>-0.077430</td>\n      <td>0.064301</td>\n      <td>-0.063539</td>\n      <td>0.066193</td>\n      <td>-0.087852</td>\n      <td>0.018333</td>\n      <td>-0.028678</td>\n      <td>-0.022301</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 77 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest - L1SO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['e0106', 'e0110', 'e0115', 'e0129', 'e0133', 'e0151', 'e0202',\n       'e0203', 'e0204', 'e0205', 'e0206', 'e0207', 'e0208', 'e0210',\n       'e0211', 'e0212', 'e0213', 'e0302', 'e0303', 'e0304', 'e0305',\n       'e0306', 'e0403', 'e0404', 'e0405', 'e0406', 'e0408', 'e0409',\n       'e0410', 'e0411', 'e0413', 'e0415', 'e0417', 'e0418', 'e0515',\n       'e0601', 'e0602', 'e0603', 'e0605', 'e0606', 'e0607', 'e0609',\n       'e0610', 'e0611', 'e0612', 'e0613', 'e0614', 'e0615', 'e0704',\n       'e0801', 'e0808', 'e0817', 'e0818', 'e1301', 'e1302', 'e1304'],\n      dtype=object)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvds = X_fsel.copy()\n",
    "cvds[\"patient_id\"] = patient_ids\n",
    "cvds[\"label\"] = y\n",
    "\n",
    "patients = np.unique(cvds[\"patient_id\"].values)\n",
    "patients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 56 - 18.667592763900757 s\n",
      "Accuracy 0.8215077605321508 precision 0.8533672400823988 specificity 0.17849223946784923 recall 0.8215077605321508 f1 0.7410070000661275\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 56 - 18.042016983032227 s\n",
      "Accuracy 0.8024830699774267 precision 0.8414960076229687 specificity 0.19751693002257337 recall 0.8024830699774267 f1 0.7145466033236699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 56 - 16.907806873321533 s\n",
      "Accuracy 0.9204225352112676 precision 0.8930118163007337 specificity 0.12838055981573326 recall 0.9204225352112676 f1 0.8891461001737868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 56 - 16.570454359054565 s\n",
      "Accuracy 0.8643356643356643 precision 0.8827404763069099 specificity 0.13566433566433567 recall 0.8643356643356643 f1 0.8014395207193407\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "5 of 56 - 16.711426258087158 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "6 of 56 - 16.729687929153442 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 56 - 17.179555416107178 s\n",
      "Accuracy 0.7240829346092504 precision 0.8010106579172274 specificity 0.31212876455509503 recall 0.7240829346092504 f1 0.6181138804538778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 56 - 17.057823419570923 s\n",
      "Accuracy 0.7723004694835681 precision 0.7891322201270264 specificity 0.36878819808310453 recall 0.7723004694835681 f1 0.7071655704988076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 56 - 16.601059436798096 s\n",
      "Accuracy 0.7922705314009661 precision 0.9849471478146464 specificity 0.8414431233653201 recall 0.7922705314009661 f1 0.8723373767869066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 56 - 16.899847984313965 s\n",
      "Accuracy 0.6507620941020543 precision 0.7727292090180367 specificity 0.3492379058979457 recall 0.6507620941020543 f1 0.5130858100427277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 56 - 17.592291831970215 s\n",
      "Accuracy 0.7936046511627907 precision 0.7688090668644969 specificity 0.4298857365391745 recall 0.7936046511627907 f1 0.7615047497859357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 56 - 18.427571773529053 s\n",
      "Accuracy 0.7571743929359823 precision 0.816138668381991 specificity 0.24282560706401765 recall 0.7571743929359823 f1 0.652539740645834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 56 - 18.293598175048828 s\n",
      "Accuracy 0.9038984587488668 precision 0.91313396497971 specificity 0.09610154125113328 recall 0.9038984587488668 f1 0.858273107973924\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 56 - 17.524497032165527 s\n",
      "Accuracy 0.81 precision 0.8461000000000001 specificity 0.19 recall 0.81 f1 0.7249723756906078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 56 - 17.579715728759766 s\n",
      "Accuracy 0.7126254622292657 precision 0.6664663240353307 specificity 0.181746004348719 recall 0.7126254622292657 f1 0.6883534995906531\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 56 - 17.56265878677368 s\n",
      "Accuracy 0.9474068663257852 precision 0.9501729040354591 specificity 0.052593133674214754 recall 0.9474068663257852 f1 0.9218204843394924\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 56 - 17.432058334350586 s\n",
      "Accuracy 0.7578125 precision 0.7603508758863136 specificity 0.43806734694883837 recall 0.7578125 f1 0.7062496602394425\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 56 - 16.889764070510864 s\n",
      "Accuracy 0.969313387034906 precision 0.9702550552501754 specificity 0.03068661296509398 recall 0.969313387034906 f1 0.9542091659669683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 56 - 17.26808190345764 s\n",
      "Accuracy 0.8588025022341377 precision 0.8787392356094783 specificity 0.14119749776586238 recall 0.8588025022341377 f1 0.7935665429298138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 56 - 17.339539766311646 s\n",
      "Accuracy 0.9880725190839694 precision 0.9791029166651471 specificity 0.010481000684593698 recall 0.9880725190839694 f1 0.9835672688169678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 56 - 18.0396089553833 s\n",
      "Accuracy 0.8159663865546218 precision 0.8499203556738618 specificity 0.19754712695889168 recall 0.8159663865546218 f1 0.7357544892667044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 56 - 17.697988271713257 s\n",
      "Accuracy 0.6733466933867736 precision 0.7800490761081281 specificity 0.32665330661322645 recall 0.6733466933867736 f1 0.5419029676118705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 56 - 18.412354230880737 s\n",
      "Accuracy 0.3607540702656384 precision 0.5745750705377922 specificity 0.6479737462583217 recall 0.3607540702656384 f1 0.25491671151941686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 56 - 17.92035746574402 s\n",
      "Accuracy 0.8424657534246576 precision 0.7150826154497952 specificity 0.15348566357939106 recall 0.8424657534246576 f1 0.7735652085349085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 56 - 17.576694011688232 s\n",
      "Accuracy 0.7166309778729479 precision 0.7721344037298131 specificity 0.4100909266666717 recall 0.7166309778729479 f1 0.6349936805629149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 56 - 17.51863145828247 s\n",
      "Accuracy 0.6831421006178288 precision 0.5324112939303653 specificity 0.2503737304641677 recall 0.6831421006178288 f1 0.5967078381179228\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 56 - 17.724998712539673 s\n",
      "Accuracy 0.6422907488986784 precision 0.8389809229548065 specificity 0.4454196075224458 recall 0.6422907488986784 f1 0.7145901292943375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 56 - 17.651062726974487 s\n",
      "Accuracy 0.45719602977667495 precision 0.9535669738231409 specificity 0.9600218023882701 recall 0.45719602977667495 f1 0.5789648489800407\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 56 - 18.343917846679688 s\n",
      "Accuracy 0.14541622760800843 precision 0.8765000244539 specificity 0.8558152994855877 recall 0.14541622760800843 f1 0.03856140674229846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 56 - 17.292966604232788 s\n",
      "Accuracy 0.8986432561851556 precision 0.8537110933758979 specificity 0.07288392241708769 recall 0.8986432561851556 f1 0.8756011214111772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 56 - 17.64770197868347 s\n",
      "Accuracy 0.8810916179337231 precision 0.8928460812096294 specificity 0.5815302892591824 recall 0.8810916179337231 f1 0.8863003940300919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 56 - 18.532007694244385 s\n",
      "Accuracy 0.5879158180583842 precision 0.7719524506573607 specificity 0.6194380952516338 recall 0.5879158180583842 f1 0.5157750862002376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 56 - 17.679579496383667 s\n",
      "Accuracy 0.8547968885047537 precision 0.8535578509649382 specificity 0.20530918782408294 recall 0.8547968885047537 f1 0.7977360523321694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 56 - 17.33107566833496 s\n",
      "Accuracy 0.5034059945504087 precision 0.9343677167475449 specificity 0.9065633448531033 recall 0.5034059945504087 f1 0.6124672570120009\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 56 - 17.651084661483765 s\n",
      "Accuracy 0.9320175438596491 precision 0.9055476845097821 specificity 0.09096072668885392 recall 0.9320175438596491 f1 0.9178079519825523\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "36 of 56 - 17.574613571166992 s\n",
      "Accuracy 0.9723214285714286 precision 1.0 specificity 0.0 recall 0.9723214285714286 f1 0.9859665006790402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 56 - 17.585055828094482 s\n",
      "Accuracy 0.799288256227758 precision 0.8601223255197576 specificity 0.5079373367121207 recall 0.799288256227758 f1 0.8241042898196816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 56 - 17.22339940071106 s\n",
      "Accuracy 0.057 precision 0.8190021732831062 specificity 0.9130386238306804 recall 0.057 f1 0.027747402921781822\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 56 - 17.98970627784729 s\n",
      "Accuracy 0.8887372013651877 precision 0.8871159476991674 specificity 0.7886490894740179 recall 0.8887372013651877 f1 0.8877734125587354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 56 - 17.631696462631226 s\n",
      "Accuracy 0.9098360655737705 precision 0.9145794046530998 specificity 0.6285916902452896 recall 0.9098360655737705 f1 0.8994806991733221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 56 - 18.000584602355957 s\n",
      "Accuracy 0.38645111624326406 precision 0.772400966562221 specificity 0.6521496075203065 recall 0.38645111624326406 f1 0.24323937263529463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 56 - 17.59094476699829 s\n",
      "Accuracy 0.9220338983050848 precision 0.933112838197584 specificity 0.5194145943702698 recall 0.9220338983050848 f1 0.9270042372881356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 56 - 17.433931589126587 s\n",
      "Accuracy 0.8571428571428571 precision 0.8775510204081632 specificity 0.14285714285714285 recall 0.8571428571428571 f1 0.7912087912087911\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "44 of 56 - 18.16391158103943 s\n",
      "Accuracy 0.9932795698924731 precision 1.0 specificity 0.0 recall 0.9932795698924731 f1 0.9966284558327715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 56 - 17.688599824905396 s\n",
      "Accuracy 0.62119503945885 precision 0.6529284465798137 specificity 0.4045992068110865 recall 0.62119503945885 f1 0.49334762112062397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 56 - 17.50318694114685 s\n",
      "Accuracy 0.755203171456888 precision 0.8151286587216539 specificity 0.244796828543112 recall 0.755203171456888 f1 0.6498755693395242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 56 - 17.60011386871338 s\n",
      "Accuracy 0.5592151366503153 precision 0.5891927948677833 specificity 0.5885466603761875 recall 0.5592151366503153 f1 0.5597065261943224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 56 - 17.718880653381348 s\n",
      "Accuracy 0.9780701754385965 precision 0.9761232349165597 specificity 0.09526315789473684 recall 0.9780701754385965 f1 0.977085534945223\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "49 of 56 - 17.20310115814209 s\n",
      "Accuracy 0.8689991863303499 precision 1.0 specificity 0.0 recall 0.8689991863303499 f1 0.9299085764040054\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "50 of 56 - 17.261022090911865 s\n",
      "Accuracy 0.9942148760330578 precision 1.0 specificity 0.0 recall 0.9942148760330578 f1 0.9970990468296725\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 56 - 17.690333604812622 s\n",
      "Accuracy 0.15574348132487667 precision 0.8320698288238283 specificity 0.8635027095331828 recall 0.15574348132487667 f1 0.09798493247073883\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "52 of 56 - 18.494710683822632 s\n",
      "Accuracy 0.8160569105691057 precision 1.0 specificity 0.0 recall 0.8160569105691057 f1 0.8987129266927812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 56 - 19.711530208587646 s\n",
      "Accuracy 0.7959814528593508 precision 0.8161564967193925 specificity 0.4966998835407155 recall 0.7959814528593508 f1 0.7575763451534472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 56 - 18.597644567489624 s\n",
      "Accuracy 0.907103825136612 precision 0.9076955689872592 specificity 0.4409552465933458 recall 0.907103825136612 f1 0.8887089878489094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 56 - 18.56326961517334 s\n",
      "Accuracy 0.9063386944181646 precision 0.9151111345814585 specificity 0.09366130558183539 recall 0.9063386944181646 f1 0.8618089024839719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 56 - 18.475626230239868 s\n",
      "Accuracy 0.7793380140421263 precision 0.8281766829664042 specificity 0.2341149007560799 recall 0.7793380140421263 f1 0.6856651321842836\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "tot = len(patients)\n",
    "for i, patient in enumerate(patients):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    df1 = cvds.loc[cvds[\"patient_id\"] != patient]\n",
    "    df2 = cvds.loc[cvds[\"patient_id\"] == patient]\n",
    "\n",
    "    y_train = df1[\"label\"].values\n",
    "    x_train = df1.loc[:, ~df1.columns.isin(['patient_id', 'label'])]\n",
    "    y_test = df2[\"label\"].values\n",
    "    x_test = df2.loc[:, ~df2.columns.isin(['patient_id', 'label'])]\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, zero_division=1, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(patients), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.821508     0.178492   0.853367  0.821508  0.741007\n1  0.802483     0.197517   0.841496  0.802483  0.714547\n2  0.920423     0.128381   0.893012  0.920423  0.889146\n3  0.864336     0.135664   0.882740  0.864336  0.801440\n4  1.000000     0.000000   1.000000  1.000000  1.000000\n5  1.000000     0.000000   1.000000  1.000000  1.000000\n6  0.724083     0.312129   0.801011  0.724083  0.618114\n7  0.772300     0.368788   0.789132  0.772300  0.707166\n8  0.792271     0.841443   0.984947  0.792271  0.872337\n9  0.650762     0.349238   0.772729  0.650762  0.513086",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.821508</td>\n      <td>0.178492</td>\n      <td>0.853367</td>\n      <td>0.821508</td>\n      <td>0.741007</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.802483</td>\n      <td>0.197517</td>\n      <td>0.841496</td>\n      <td>0.802483</td>\n      <td>0.714547</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.920423</td>\n      <td>0.128381</td>\n      <td>0.893012</td>\n      <td>0.920423</td>\n      <td>0.889146</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.864336</td>\n      <td>0.135664</td>\n      <td>0.882740</td>\n      <td>0.864336</td>\n      <td>0.801440</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.724083</td>\n      <td>0.312129</td>\n      <td>0.801011</td>\n      <td>0.724083</td>\n      <td>0.618114</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.772300</td>\n      <td>0.368788</td>\n      <td>0.789132</td>\n      <td>0.772300</td>\n      <td>0.707166</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.792271</td>\n      <td>0.841443</td>\n      <td>0.984947</td>\n      <td>0.792271</td>\n      <td>0.872337</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.650762</td>\n      <td>0.349238</td>\n      <td>0.772729</td>\n      <td>0.650762</td>\n      <td>0.513086</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.7636697547133229\n",
      "Precision 0.8548102665091439\n",
      "Specificity 0.33328716605329706\n",
      "Recall 0.7636697547133229\n",
      "F1 0.7278245868826533\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_8beats_l1so.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}