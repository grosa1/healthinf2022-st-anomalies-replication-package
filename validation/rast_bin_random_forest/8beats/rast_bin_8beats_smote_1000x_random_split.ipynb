{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 8 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1  \\\n0  e0106  30.571581  30.571114  30.597163   8.654545  1.254944  0.902949   \n1  e0106  35.327463  37.090233  36.619925  10.318908  1.501561  0.936195   \n2  e0106  33.754220  34.253945  34.112950   9.653801  1.420377  0.922050   \n3  e0106  33.428166  32.277378  32.154651   9.225828  1.332695  0.898518   \n4  e0106  34.438584  33.565638  33.382364   9.589036  1.426830  0.886530   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.773465 -1.399254 -0.734867  ... -0.052333  0.042084 -0.051954  0.052820   \n1 -0.694743 -1.301387 -0.880195  ... -0.025711  0.004880 -0.014158  0.033816   \n2 -0.707779 -1.271389 -0.778260  ... -0.041095  0.024671 -0.028207  0.045623   \n3 -0.728415 -1.302251 -0.708089  ... -0.053417  0.034100 -0.041100  0.034451   \n4 -0.727896 -1.310174 -0.910833  ... -0.077430  0.064301 -0.063539  0.066193   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.078516  0.018113 -0.033035 -0.008121 -0.004387    NSR  \n1 -0.052615 -0.010039 -0.020460 -0.003424 -0.010776    NSR  \n2 -0.069928 -0.007982 -0.010177 -0.011244 -0.007525    NSR  \n3 -0.060591 -0.005673 -0.010582 -0.020471  0.001472    NSR  \n4 -0.087852  0.018333 -0.028678 -0.022301  0.009486    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>30.571581</td>\n      <td>30.571114</td>\n      <td>30.597163</td>\n      <td>8.654545</td>\n      <td>1.254944</td>\n      <td>0.902949</td>\n      <td>-0.773465</td>\n      <td>-1.399254</td>\n      <td>-0.734867</td>\n      <td>...</td>\n      <td>-0.052333</td>\n      <td>0.042084</td>\n      <td>-0.051954</td>\n      <td>0.052820</td>\n      <td>-0.078516</td>\n      <td>0.018113</td>\n      <td>-0.033035</td>\n      <td>-0.008121</td>\n      <td>-0.004387</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>35.327463</td>\n      <td>37.090233</td>\n      <td>36.619925</td>\n      <td>10.318908</td>\n      <td>1.501561</td>\n      <td>0.936195</td>\n      <td>-0.694743</td>\n      <td>-1.301387</td>\n      <td>-0.880195</td>\n      <td>...</td>\n      <td>-0.025711</td>\n      <td>0.004880</td>\n      <td>-0.014158</td>\n      <td>0.033816</td>\n      <td>-0.052615</td>\n      <td>-0.010039</td>\n      <td>-0.020460</td>\n      <td>-0.003424</td>\n      <td>-0.010776</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>33.754220</td>\n      <td>34.253945</td>\n      <td>34.112950</td>\n      <td>9.653801</td>\n      <td>1.420377</td>\n      <td>0.922050</td>\n      <td>-0.707779</td>\n      <td>-1.271389</td>\n      <td>-0.778260</td>\n      <td>...</td>\n      <td>-0.041095</td>\n      <td>0.024671</td>\n      <td>-0.028207</td>\n      <td>0.045623</td>\n      <td>-0.069928</td>\n      <td>-0.007982</td>\n      <td>-0.010177</td>\n      <td>-0.011244</td>\n      <td>-0.007525</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>33.428166</td>\n      <td>32.277378</td>\n      <td>32.154651</td>\n      <td>9.225828</td>\n      <td>1.332695</td>\n      <td>0.898518</td>\n      <td>-0.728415</td>\n      <td>-1.302251</td>\n      <td>-0.708089</td>\n      <td>...</td>\n      <td>-0.053417</td>\n      <td>0.034100</td>\n      <td>-0.041100</td>\n      <td>0.034451</td>\n      <td>-0.060591</td>\n      <td>-0.005673</td>\n      <td>-0.010582</td>\n      <td>-0.020471</td>\n      <td>0.001472</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>34.438584</td>\n      <td>33.565638</td>\n      <td>33.382364</td>\n      <td>9.589036</td>\n      <td>1.426830</td>\n      <td>0.886530</td>\n      <td>-0.727896</td>\n      <td>-1.310174</td>\n      <td>-0.910833</td>\n      <td>...</td>\n      <td>-0.077430</td>\n      <td>0.064301</td>\n      <td>-0.063539</td>\n      <td>0.066193</td>\n      <td>-0.087852</td>\n      <td>0.018333</td>\n      <td>-0.028678</td>\n      <td>-0.022301</td>\n      <td>0.009486</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_8beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    52426\nST     15929\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.232673  0.111713  0.079107  0.076764  0.077147 -0.018860   \ndw_2    0.232673  1.000000  0.839282  0.452814  0.160598  0.424152 -0.484394   \ndw_3    0.111713  0.839282  1.000000  0.631576  0.240584  0.301445 -0.535593   \ndw_4    0.079107  0.452814  0.631576  1.000000  0.895025  0.016860 -0.237619   \ndw_5    0.076764  0.160598  0.240584  0.895025  1.000000 -0.105960 -0.011988   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.039241  0.029218  0.051187  0.042171  0.016035 -0.094790  0.068312   \ncfr_13 -0.027948  0.115506  0.045371  0.026140  0.013783  0.077604 -0.004769   \ncfr_14 -0.044903 -0.000752 -0.026800 -0.032931 -0.034165  0.032269  0.017775   \ncfr_15 -0.065581 -0.115788 -0.130477 -0.089245 -0.041855  0.009040  0.083235   \ncfr_16 -0.044688 -0.079295 -0.049044 -0.033579 -0.018000  0.054551 -0.035391   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.030559  0.040220 -0.014666  ... -0.053028 -0.055461 -0.025675   \ndw_2   -0.404156  0.100065  0.435652  ... -0.136686  0.140104  0.232989   \ndw_3   -0.534332 -0.030329  0.564342  ... -0.206789  0.121560  0.266346   \ndw_4   -0.260776 -0.029358  0.299563  ... -0.147248  0.048851  0.116574   \ndw_5   -0.035024 -0.012480  0.061799  ... -0.066765  0.004155  0.014207   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.129263  0.122377 -0.090957  ... -0.127261 -0.207625 -0.097674   \ncfr_13  0.006963  0.049874  0.008203  ...  0.128357  0.032112 -0.217503   \ncfr_14  0.034991  0.012523 -0.020623  ...  0.096622  0.214725  0.044225   \ncfr_15  0.080419 -0.058850 -0.098386  ...  0.258472  0.163393 -0.078272   \ncfr_16 -0.001319  0.067956  0.036802  ...  0.240666  0.138617  0.171483   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.018685 -0.009704 -0.039241 -0.027948 -0.044903 -0.065581 -0.044688  \ndw_2    0.166906  0.045325  0.029218  0.115506 -0.000752 -0.115788 -0.079295  \ndw_3    0.117884 -0.049549  0.051187  0.045371 -0.026800 -0.130477 -0.049044  \ndw_4    0.042862 -0.044403  0.042171  0.026140 -0.032931 -0.089245 -0.033579  \ndw_5    0.013282 -0.012686  0.016035  0.013783 -0.034165 -0.041855 -0.018000  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.019114  0.057081  1.000000  0.003281 -0.017734 -0.318789 -0.208539  \ncfr_13 -0.271096 -0.046139  0.003281  1.000000  0.186633  0.097077 -0.171867  \ncfr_14 -0.177405 -0.291133 -0.017734  0.186633  1.000000  0.157260 -0.146906  \ncfr_15 -0.146256 -0.095566 -0.318789  0.097077  0.157260  1.000000  0.229510  \ncfr_16  0.114201 -0.004097 -0.208539 -0.171867 -0.146906  0.229510  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.232673</td>\n      <td>0.111713</td>\n      <td>0.079107</td>\n      <td>0.076764</td>\n      <td>0.077147</td>\n      <td>-0.018860</td>\n      <td>0.030559</td>\n      <td>0.040220</td>\n      <td>-0.014666</td>\n      <td>...</td>\n      <td>-0.053028</td>\n      <td>-0.055461</td>\n      <td>-0.025675</td>\n      <td>-0.018685</td>\n      <td>-0.009704</td>\n      <td>-0.039241</td>\n      <td>-0.027948</td>\n      <td>-0.044903</td>\n      <td>-0.065581</td>\n      <td>-0.044688</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.232673</td>\n      <td>1.000000</td>\n      <td>0.839282</td>\n      <td>0.452814</td>\n      <td>0.160598</td>\n      <td>0.424152</td>\n      <td>-0.484394</td>\n      <td>-0.404156</td>\n      <td>0.100065</td>\n      <td>0.435652</td>\n      <td>...</td>\n      <td>-0.136686</td>\n      <td>0.140104</td>\n      <td>0.232989</td>\n      <td>0.166906</td>\n      <td>0.045325</td>\n      <td>0.029218</td>\n      <td>0.115506</td>\n      <td>-0.000752</td>\n      <td>-0.115788</td>\n      <td>-0.079295</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.111713</td>\n      <td>0.839282</td>\n      <td>1.000000</td>\n      <td>0.631576</td>\n      <td>0.240584</td>\n      <td>0.301445</td>\n      <td>-0.535593</td>\n      <td>-0.534332</td>\n      <td>-0.030329</td>\n      <td>0.564342</td>\n      <td>...</td>\n      <td>-0.206789</td>\n      <td>0.121560</td>\n      <td>0.266346</td>\n      <td>0.117884</td>\n      <td>-0.049549</td>\n      <td>0.051187</td>\n      <td>0.045371</td>\n      <td>-0.026800</td>\n      <td>-0.130477</td>\n      <td>-0.049044</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.079107</td>\n      <td>0.452814</td>\n      <td>0.631576</td>\n      <td>1.000000</td>\n      <td>0.895025</td>\n      <td>0.016860</td>\n      <td>-0.237619</td>\n      <td>-0.260776</td>\n      <td>-0.029358</td>\n      <td>0.299563</td>\n      <td>...</td>\n      <td>-0.147248</td>\n      <td>0.048851</td>\n      <td>0.116574</td>\n      <td>0.042862</td>\n      <td>-0.044403</td>\n      <td>0.042171</td>\n      <td>0.026140</td>\n      <td>-0.032931</td>\n      <td>-0.089245</td>\n      <td>-0.033579</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.076764</td>\n      <td>0.160598</td>\n      <td>0.240584</td>\n      <td>0.895025</td>\n      <td>1.000000</td>\n      <td>-0.105960</td>\n      <td>-0.011988</td>\n      <td>-0.035024</td>\n      <td>-0.012480</td>\n      <td>0.061799</td>\n      <td>...</td>\n      <td>-0.066765</td>\n      <td>0.004155</td>\n      <td>0.014207</td>\n      <td>0.013282</td>\n      <td>-0.012686</td>\n      <td>0.016035</td>\n      <td>0.013783</td>\n      <td>-0.034165</td>\n      <td>-0.041855</td>\n      <td>-0.018000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.039241</td>\n      <td>0.029218</td>\n      <td>0.051187</td>\n      <td>0.042171</td>\n      <td>0.016035</td>\n      <td>-0.094790</td>\n      <td>0.068312</td>\n      <td>0.129263</td>\n      <td>0.122377</td>\n      <td>-0.090957</td>\n      <td>...</td>\n      <td>-0.127261</td>\n      <td>-0.207625</td>\n      <td>-0.097674</td>\n      <td>0.019114</td>\n      <td>0.057081</td>\n      <td>1.000000</td>\n      <td>0.003281</td>\n      <td>-0.017734</td>\n      <td>-0.318789</td>\n      <td>-0.208539</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.027948</td>\n      <td>0.115506</td>\n      <td>0.045371</td>\n      <td>0.026140</td>\n      <td>0.013783</td>\n      <td>0.077604</td>\n      <td>-0.004769</td>\n      <td>0.006963</td>\n      <td>0.049874</td>\n      <td>0.008203</td>\n      <td>...</td>\n      <td>0.128357</td>\n      <td>0.032112</td>\n      <td>-0.217503</td>\n      <td>-0.271096</td>\n      <td>-0.046139</td>\n      <td>0.003281</td>\n      <td>1.000000</td>\n      <td>0.186633</td>\n      <td>0.097077</td>\n      <td>-0.171867</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.044903</td>\n      <td>-0.000752</td>\n      <td>-0.026800</td>\n      <td>-0.032931</td>\n      <td>-0.034165</td>\n      <td>0.032269</td>\n      <td>0.017775</td>\n      <td>0.034991</td>\n      <td>0.012523</td>\n      <td>-0.020623</td>\n      <td>...</td>\n      <td>0.096622</td>\n      <td>0.214725</td>\n      <td>0.044225</td>\n      <td>-0.177405</td>\n      <td>-0.291133</td>\n      <td>-0.017734</td>\n      <td>0.186633</td>\n      <td>1.000000</td>\n      <td>0.157260</td>\n      <td>-0.146906</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.065581</td>\n      <td>-0.115788</td>\n      <td>-0.130477</td>\n      <td>-0.089245</td>\n      <td>-0.041855</td>\n      <td>0.009040</td>\n      <td>0.083235</td>\n      <td>0.080419</td>\n      <td>-0.058850</td>\n      <td>-0.098386</td>\n      <td>...</td>\n      <td>0.258472</td>\n      <td>0.163393</td>\n      <td>-0.078272</td>\n      <td>-0.146256</td>\n      <td>-0.095566</td>\n      <td>-0.318789</td>\n      <td>0.097077</td>\n      <td>0.157260</td>\n      <td>1.000000</td>\n      <td>0.229510</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.044688</td>\n      <td>-0.079295</td>\n      <td>-0.049044</td>\n      <td>-0.033579</td>\n      <td>-0.018000</td>\n      <td>0.054551</td>\n      <td>-0.035391</td>\n      <td>-0.001319</td>\n      <td>0.067956</td>\n      <td>0.036802</td>\n      <td>...</td>\n      <td>0.240666</td>\n      <td>0.138617</td>\n      <td>0.171483</td>\n      <td>0.114201</td>\n      <td>-0.004097</td>\n      <td>-0.208539</td>\n      <td>-0.171867</td>\n      <td>-0.146906</td>\n      <td>0.229510</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_199', 'fft_242', 'fft_241', 'fft_143', 'fft_152', 'fft_248', 'fft_179', 'fft_216', 'fft_145', 'fft_144', 'fft_229', 'fft_239', 'fft_193', 'fft_176', 'fft_243', 'fft_205', 'fft_240', 'fft_167', 'fft_147', 'fft_223', 'fft_181', 'fft_175', 'fft_190', 'fft_197', 'fft_235', 'fft_217', 'fft_170', 'fft_203', 'fft_158', 'fft_213', 'fft_210', 'fft_159', 'fft_211', 'fft_224', 'fft_157', 'fft_136', 'fft_178', 'fft_232', 'fft_212', 'fft_163', 'fft_153', 'fft_173', 'fft_209', 'fft_162', 'fft_231', 'fft_214', 'fft_215', 'fft_151', 'fft_198', 'fft_194', 'fft_238', 'fft_249', 'fft_202', 'fft_132', 'fft_204', 'fft_165', 'fft_246', 'fft_133', 'fft_169', 'fft_177', 'fft_196', 'fft_233', 'fft_208', 'fft_186', 'fft_237', 'fft_222', 'fft_146', 'fft_171', 'fft_206', 'fft_220', 'fft_174', 'fft_180', 'fft_131', 'fft_201', 'fft_187', 'fft_137', 'fft_182', 'fft_195', 'fft_227', 'fft_189', 'fft_226', 'fft_139', 'fft_140', 'fft_219', 'fft_192', 'fft_148', 'fft_200', 'fft_164', 'fft_218', 'fft_256', 'cfr_16', 'fft_155', 'fft_247', 'fft_135', 'fft_156', 'fft_236', 'fft_251', 'fft_188', 'fft_172', 'fft_130', 'fft_245', 'fft_149', 'fft_161', 'fft_254', 'mfw_11', 'fft_230', 'fft_134', 'fft_250', 'fft_225', 'fft_166', 'fft_142', 'fft_168', 'fft_234', 'fft_221', 'fft_184', 'fft_255', 'fft_252', 'fft_244', 'fft_185', 'fft_154', 'fft_228', 'fft_138', 'fft_253', 'fft_141', 'fft_207', 'fft_160', 'fft_150', 'fft_183', 'fft_191'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "mfw_5\n",
      "mfw_6\n",
      "mfw_7\n",
      "mfw_8\n",
      "mfw_9\n",
      "mfw_10\n",
      "mfw_12\n",
      "mfw_13\n",
      "mfw_14\n",
      "mfw_15\n",
      "mfw_16\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_24\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 77\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1     mfw_2  \\\n0  30.571581  30.571114  30.597163   8.654545  1.254944  0.902949 -0.773465   \n1  35.327463  37.090233  36.619925  10.318908  1.501561  0.936195 -0.694743   \n2  33.754220  34.253945  34.112950   9.653801  1.420377  0.922050 -0.707779   \n3  33.428166  32.277378  32.154651   9.225828  1.332695  0.898518 -0.728415   \n4  34.438584  33.565638  33.382364   9.589036  1.426830  0.886530 -0.727896   \n\n      mfw_3     mfw_4      mfw_5  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -1.399254 -0.734867  12.762118  ...  0.012196  0.047766 -0.052333  0.042084   \n1 -1.301387 -0.880195  10.573212  ...  0.022624  0.032716 -0.025711  0.004880   \n2 -1.271389 -0.778260  10.515795  ...  0.010279  0.036796 -0.041095  0.024671   \n3 -1.302251 -0.708089  11.496901  ...  0.005352  0.048697 -0.053417  0.034100   \n4 -1.310174 -0.910833  10.732432  ... -0.003147  0.052752 -0.077430  0.064301   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.051954  0.052820 -0.078516  0.018113 -0.033035 -0.008121  \n1 -0.014158  0.033816 -0.052615 -0.010039 -0.020460 -0.003424  \n2 -0.028207  0.045623 -0.069928 -0.007982 -0.010177 -0.011244  \n3 -0.041100  0.034451 -0.060591 -0.005673 -0.010582 -0.020471  \n4 -0.063539  0.066193 -0.087852  0.018333 -0.028678 -0.022301  \n\n[5 rows x 77 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30.571581</td>\n      <td>30.571114</td>\n      <td>30.597163</td>\n      <td>8.654545</td>\n      <td>1.254944</td>\n      <td>0.902949</td>\n      <td>-0.773465</td>\n      <td>-1.399254</td>\n      <td>-0.734867</td>\n      <td>12.762118</td>\n      <td>...</td>\n      <td>0.012196</td>\n      <td>0.047766</td>\n      <td>-0.052333</td>\n      <td>0.042084</td>\n      <td>-0.051954</td>\n      <td>0.052820</td>\n      <td>-0.078516</td>\n      <td>0.018113</td>\n      <td>-0.033035</td>\n      <td>-0.008121</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35.327463</td>\n      <td>37.090233</td>\n      <td>36.619925</td>\n      <td>10.318908</td>\n      <td>1.501561</td>\n      <td>0.936195</td>\n      <td>-0.694743</td>\n      <td>-1.301387</td>\n      <td>-0.880195</td>\n      <td>10.573212</td>\n      <td>...</td>\n      <td>0.022624</td>\n      <td>0.032716</td>\n      <td>-0.025711</td>\n      <td>0.004880</td>\n      <td>-0.014158</td>\n      <td>0.033816</td>\n      <td>-0.052615</td>\n      <td>-0.010039</td>\n      <td>-0.020460</td>\n      <td>-0.003424</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33.754220</td>\n      <td>34.253945</td>\n      <td>34.112950</td>\n      <td>9.653801</td>\n      <td>1.420377</td>\n      <td>0.922050</td>\n      <td>-0.707779</td>\n      <td>-1.271389</td>\n      <td>-0.778260</td>\n      <td>10.515795</td>\n      <td>...</td>\n      <td>0.010279</td>\n      <td>0.036796</td>\n      <td>-0.041095</td>\n      <td>0.024671</td>\n      <td>-0.028207</td>\n      <td>0.045623</td>\n      <td>-0.069928</td>\n      <td>-0.007982</td>\n      <td>-0.010177</td>\n      <td>-0.011244</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33.428166</td>\n      <td>32.277378</td>\n      <td>32.154651</td>\n      <td>9.225828</td>\n      <td>1.332695</td>\n      <td>0.898518</td>\n      <td>-0.728415</td>\n      <td>-1.302251</td>\n      <td>-0.708089</td>\n      <td>11.496901</td>\n      <td>...</td>\n      <td>0.005352</td>\n      <td>0.048697</td>\n      <td>-0.053417</td>\n      <td>0.034100</td>\n      <td>-0.041100</td>\n      <td>0.034451</td>\n      <td>-0.060591</td>\n      <td>-0.005673</td>\n      <td>-0.010582</td>\n      <td>-0.020471</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34.438584</td>\n      <td>33.565638</td>\n      <td>33.382364</td>\n      <td>9.589036</td>\n      <td>1.426830</td>\n      <td>0.886530</td>\n      <td>-0.727896</td>\n      <td>-1.310174</td>\n      <td>-0.910833</td>\n      <td>10.732432</td>\n      <td>...</td>\n      <td>-0.003147</td>\n      <td>0.052752</td>\n      <td>-0.077430</td>\n      <td>0.064301</td>\n      <td>-0.063539</td>\n      <td>0.066193</td>\n      <td>-0.087852</td>\n      <td>0.018333</td>\n      <td>-0.028678</td>\n      <td>-0.022301</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 77 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 25.13999891281128 s\n",
      "Accuracy 0.931021871114037 precision 0.9318856365504441 specificity 0.8879979759386244 recall 0.931021871114037 f1 0.9313883906574394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 25.414000034332275 s\n",
      "Accuracy 0.9305098383439397 precision 0.932219875402598 specificity 0.8938476265395888 recall 0.9305098383439397 f1 0.9311632969339931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 24.96199893951416 s\n",
      "Accuracy 0.9265598712603321 precision 0.9273733141049257 specificity 0.8774283839121562 recall 0.9265598712603321 f1 0.9269147558630166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 24.824002981185913 s\n",
      "Accuracy 0.9263404286445761 precision 0.9276800689278679 specificity 0.8835290024030793 recall 0.9263404286445761 f1 0.9268846924659829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 25.02999210357666 s\n",
      "Accuracy 0.9253895106429668 precision 0.927202112086528 specificity 0.8854512617383408 recall 0.9253895106429668 f1 0.9260924234440107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 23.341999769210815 s\n",
      "Accuracy 0.926998756491844 precision 0.9283243157404468 specificity 0.8841927803864096 recall 0.926998756491844 f1 0.9275373585485523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 23.668002128601074 s\n",
      "Accuracy 0.9264867237217468 precision 0.9281209286196253 specificity 0.8849091250599468 recall 0.9264867237217468 f1 0.9271314691708761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 23.37599802017212 s\n",
      "Accuracy 0.9287542974178918 precision 0.9299354137932058 specificity 0.8871575361442605 recall 0.9287542974178918 f1 0.9292376391438026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 23.927999258041382 s\n",
      "Accuracy 0.9283154121863799 precision 0.9293178144644548 specificity 0.8803020389188785 recall 0.9283154121863799 f1 0.9287412405971858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 23.955999612808228 s\n",
      "Accuracy 0.9240728549484309 precision 0.9260863119414676 specificity 0.8830011871615446 recall 0.9240728549484309 f1 0.9248479294536612\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 23.47100067138672 s\n",
      "Accuracy 0.9275107892619413 precision 0.928984701873595 specificity 0.8858050292880604 recall 0.9275107892619413 f1 0.928099159571043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 24.139999389648438 s\n",
      "Accuracy 0.9261941335674054 precision 0.9275873518273747 specificity 0.8815979014102582 recall 0.9261941335674054 f1 0.9267606746746089\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 24.23999810218811 s\n",
      "Accuracy 0.926998756491844 precision 0.9293736845729662 specificity 0.8900650252873532 recall 0.926998756491844 f1 0.9278740555996344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 23.63099980354309 s\n",
      "Accuracy 0.9294126252651598 precision 0.930819281790743 specificity 0.8868382118252732 recall 0.9294126252651598 f1 0.9299770628673698\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 23.315999507904053 s\n",
      "Accuracy 0.9300709531124277 precision 0.931376527721377 specificity 0.8913177994361332 recall 0.9300709531124277 f1 0.9305923510658114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 23.688998699188232 s\n",
      "Accuracy 0.9231219369468218 precision 0.9248741353263557 specificity 0.8814666584334957 recall 0.9231219369468218 f1 0.9238114290860527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 23.80000066757202 s\n",
      "Accuracy 0.9278033794162827 precision 0.9293897927303097 specificity 0.8872203214184908 recall 0.9278033794162827 f1 0.9284279816847213\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 23.594999313354492 s\n",
      "Accuracy 0.9256089532587228 precision 0.92673786329834 specificity 0.880396385982928 recall 0.9256089532587228 f1 0.9260808859560647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 23.881999492645264 s\n",
      "Accuracy 0.9256821007973082 precision 0.9270264340008922 specificity 0.8818286199957441 recall 0.9256821007973082 f1 0.9262304171195683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 23.982999563217163 s\n",
      "Accuracy 0.9305829858825251 precision 0.9322615214957481 specificity 0.8920961636175154 recall 0.9305829858825251 f1 0.931230482991317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 23.385000228881836 s\n",
      "Accuracy 0.9270719040304294 precision 0.9283066603822393 specificity 0.886176943895838 recall 0.9270719040304294 f1 0.927574865138362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 23.673999309539795 s\n",
      "Accuracy 0.9267061663375027 precision 0.9286697230370456 specificity 0.8864229324858965 recall 0.9267061663375027 f1 0.9274586687207081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 23.688998699188232 s\n",
      "Accuracy 0.9290468875722332 precision 0.9311659617916213 specificity 0.895852068539231 recall 0.9290468875722332 f1 0.929824218871621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 23.681998014450073 s\n",
      "Accuracy 0.9293394777265745 precision 0.9304460233327239 specificity 0.8861389243323615 recall 0.9293394777265745 f1 0.9297975865423436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 23.70899772644043 s\n",
      "Accuracy 0.9253895106429668 precision 0.9266664300658054 specificity 0.8792651615916139 recall 0.9253895106429668 f1 0.9259172645205047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 23.881999731063843 s\n",
      "Accuracy 0.9223173140223832 precision 0.9237119309338756 specificity 0.8773398329481613 recall 0.9223173140223832 f1 0.9228887589955782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 24.018999099731445 s\n",
      "Accuracy 0.9271450515690147 precision 0.9285326459520353 specificity 0.8852196527770206 recall 0.9271450515690147 f1 0.9277039642270793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 23.567997932434082 s\n",
      "Accuracy 0.9286080023407213 precision 0.9303480505735934 specificity 0.8878620513452731 recall 0.9286080023407213 f1 0.9292842270483119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 23.80400013923645 s\n",
      "Accuracy 0.9258283958744788 precision 0.9271245090917255 specificity 0.8834741031320078 recall 0.9258283958744788 f1 0.926356829527585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 23.3700008392334 s\n",
      "Accuracy 0.9270719040304294 precision 0.9287517727450482 specificity 0.8859404949288494 recall 0.9270719040304294 f1 0.9277305708857567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 23.018768310546875 s\n",
      "Accuracy 0.9275839368005266 precision 0.9291125315363332 specificity 0.8879910787091706 recall 0.9275839368005266 f1 0.9281868165872194\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 23.521862030029297 s\n",
      "Accuracy 0.926998756491844 precision 0.9282991143062639 specificity 0.8858306006031066 recall 0.926998756491844 f1 0.9275256154532344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 23.34985876083374 s\n",
      "Accuracy 0.9277302318776973 precision 0.9286010238414372 specificity 0.8815419288042583 recall 0.9277302318776973 f1 0.9281043919872379\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 22.990843057632446 s\n",
      "Accuracy 0.9235608221783337 precision 0.9250231687150142 specificity 0.8798821896556949 recall 0.9235608221783337 f1 0.9241530094274016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 23.372857332229614 s\n",
      "Accuracy 0.927437641723356 precision 0.9294707829144007 specificity 0.8905434004398268 recall 0.927437641723356 f1 0.9282020724311377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 23.34885549545288 s\n",
      "Accuracy 0.9264867237217468 precision 0.9274193685866757 specificity 0.8799787562274293 recall 0.9264867237217468 f1 0.9268856624774684\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 23.760871171951294 s\n",
      "Accuracy 0.9277302318776973 precision 0.9292000517370813 specificity 0.8884849495140899 recall 0.9277302318776973 f1 0.9283119899474286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 23.041844844818115 s\n",
      "Accuracy 0.9299978055738425 precision 0.9318838100420146 specificity 0.8949371220575233 recall 0.9299978055738425 f1 0.9307051068453228\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 23.50786280632019 s\n",
      "Accuracy 0.9297783629580865 precision 0.9309412322240528 specificity 0.8876223931181814 recall 0.9297783629580865 f1 0.930255079588017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 23.18785047531128 s\n",
      "Accuracy 0.9329968546558408 precision 0.9344298389502639 specificity 0.8967642266637925 recall 0.9329968546558408 f1 0.9335536686757802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 23.0058434009552 s\n",
      "Accuracy 0.9286080023407213 precision 0.9304836505839637 specificity 0.8908912293396288 recall 0.9286080023407213 f1 0.9293215985534684\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 23.032844305038452 s\n",
      "Accuracy 0.926998756491844 precision 0.9280296784317908 specificity 0.882795614229059 recall 0.926998756491844 f1 0.9274319916091909\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 23.354857921600342 s\n",
      "Accuracy 0.9294857728037451 precision 0.9306408438919738 specificity 0.8896129300309868 recall 0.9294857728037451 f1 0.9299564858354129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 23.29485273361206 s\n",
      "Accuracy 0.9288274449564772 precision 0.9300954900788072 specificity 0.8887140593250085 recall 0.9288274449564772 f1 0.9293393125900383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 23.74087119102478 s\n",
      "Accuracy 0.9283885597249653 precision 0.9302618409443264 specificity 0.8901364259557699 recall 0.9283885597249653 f1 0.9291031685481562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 23.564865112304688 s\n",
      "Accuracy 0.9265598712603321 precision 0.9275315190595053 specificity 0.881639977180965 recall 0.9265598712603321 f1 0.9269719639691352\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 24.11788535118103 s\n",
      "Accuracy 0.927437641723356 precision 0.9295267483199487 specificity 0.8930880848963003 recall 0.927437641723356 f1 0.9282119001497312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 22.969841957092285 s\n",
      "Accuracy 0.9279496744934533 precision 0.9296716945867515 specificity 0.8874457075494949 recall 0.9279496744934533 f1 0.9286200842685683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 23.632866621017456 s\n",
      "Accuracy 0.9286080023407213 precision 0.9298711863226148 specificity 0.8880420098761064 recall 0.9286080023407213 f1 0.9291191288076467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 23.48986053466797 s\n",
      "Accuracy 0.9246580352571137 precision 0.9253033471995977 specificity 0.8757750663382787 recall 0.9246580352571137 f1 0.9249461513417242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 22.951842784881592 s\n",
      "Accuracy 0.9273644941847707 precision 0.9291283028785703 specificity 0.8889649707428251 recall 0.9273644941847707 f1 0.9280444987392775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 23.203851222991943 s\n",
      "Accuracy 0.9275839368005266 precision 0.9287095718712262 specificity 0.8813357114757705 recall 0.9275839368005266 f1 0.9280544344721976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 23.42085886001587 s\n",
      "Accuracy 0.9283885597249653 precision 0.929822469920439 specificity 0.8858526483979271 recall 0.9283885597249653 f1 0.9289635770761203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 23.41385793685913 s\n",
      "Accuracy 0.9280959695706239 precision 0.9296890100823849 specificity 0.8885741142208738 recall 0.9280959695706239 f1 0.928720137618062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 23.300857543945312 s\n",
      "Accuracy 0.9289737400336479 precision 0.9303953962995185 specificity 0.8886564696029905 recall 0.9289737400336479 f1 0.9295396379434142\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 23.42485737800598 s\n",
      "Accuracy 0.9239997074098456 precision 0.925521383860542 specificity 0.8798815169279965 recall 0.9239997074098456 f1 0.9246132558989559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 23.216851234436035 s\n",
      "Accuracy 0.9298515104966718 precision 0.9313003964436588 specificity 0.8893652939895939 recall 0.9298515104966718 f1 0.9304262185956603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 23.759871244430542 s\n",
      "Accuracy 0.9261941335674054 precision 0.9284865204829725 specificity 0.8905266619241801 recall 0.9261941335674054 f1 0.9270399140186182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 23.348857879638672 s\n",
      "Accuracy 0.9275839368005266 precision 0.9288908967541171 specificity 0.8875011928776163 recall 0.9275839368005266 f1 0.9281106778724615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 23.391855716705322 s\n",
      "Accuracy 0.924292297564187 precision 0.9260894385493305 specificity 0.8844930686961595 recall 0.924292297564187 f1 0.924991069479201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 23.127848863601685 s\n",
      "Accuracy 0.926998756491844 precision 0.9277369698025252 specificity 0.8789571384272112 recall 0.926998756491844 f1 0.9273228701488643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 23.315855741500854 s\n",
      "Accuracy 0.9253895106429668 precision 0.9271902760182994 specificity 0.8832434561185217 recall 0.9253895106429668 f1 0.9260938743118364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 23.672868728637695 s\n",
      "Accuracy 0.9272913466461854 precision 0.9283916085512461 specificity 0.8812040933329083 recall 0.9272913466461854 f1 0.9277524584125616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 23.23785161972046 s\n",
      "Accuracy 0.9254626581815522 precision 0.9273460109173497 specificity 0.8894318640704547 recall 0.9254626581815522 f1 0.926178321881982\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 23.497863292694092 s\n",
      "Accuracy 0.9293394777265745 precision 0.930916633036223 specificity 0.8926272628172695 recall 0.9293394777265745 f1 0.9299502399290841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 23.342855215072632 s\n",
      "Accuracy 0.9272913466461854 precision 0.9292487419504876 specificity 0.8898562731217423 recall 0.9272913466461854 f1 0.9280328835771324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 23.724870681762695 s\n",
      "Accuracy 0.9261941335674054 precision 0.9282123339986545 specificity 0.890550993460337 recall 0.9261941335674054 f1 0.9269516295497513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 23.31485390663147 s\n",
      "Accuracy 0.9284617072635506 precision 0.9298482661421763 specificity 0.8848273984466978 recall 0.9284617072635506 f1 0.9290219364763069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 23.518861532211304 s\n",
      "Accuracy 0.924292297564187 precision 0.9260879767906436 specificity 0.8831856914559589 recall 0.924292297564187 f1 0.9249938317000544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 23.362855911254883 s\n",
      "Accuracy 0.9248043303342842 precision 0.9264882781306797 specificity 0.8843627761886422 recall 0.9248043303342842 f1 0.9254655804578704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 23.409858465194702 s\n",
      "Accuracy 0.927437641723356 precision 0.9283973803166552 specificity 0.8853350625798639 recall 0.927437641723356 f1 0.9278415382356181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 23.18385148048401 s\n",
      "Accuracy 0.9286811498793066 precision 0.929747021939387 specificity 0.8860238219280843 recall 0.9286811498793066 f1 0.9291241562198578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 23.802873373031616 s\n",
      "Accuracy 0.9252432155657963 precision 0.9269181405755903 specificity 0.8838015806188907 recall 0.9252432155657963 f1 0.9259031365355594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 23.828842639923096 s\n",
      "Accuracy 0.9284617072635506 precision 0.9295137019651737 specificity 0.8822282928041446 recall 0.9284617072635506 f1 0.9289041320380728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 23.607620000839233 s\n",
      "Accuracy 0.9285348548021359 precision 0.9300830039410413 specificity 0.8899451095892907 recall 0.9285348548021359 f1 0.9291411219978765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 23.47361707687378 s\n",
      "Accuracy 0.9272181991076001 precision 0.9288503287215223 specificity 0.8856879266888797 recall 0.9272181991076001 f1 0.9278612484587859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 23.349615812301636 s\n",
      "Accuracy 0.927657084339112 precision 0.9296802047958788 specificity 0.8905564106515816 recall 0.927657084339112 f1 0.9284185607472624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 23.38761305809021 s\n",
      "Accuracy 0.9243654451027723 precision 0.9260845918228213 specificity 0.8821415437271203 recall 0.9243654451027723 f1 0.9250433860646888\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 23.32961344718933 s\n",
      "Accuracy 0.9248043303342842 precision 0.9269795709090601 specificity 0.8883017996447965 recall 0.9248043303342842 f1 0.9256175786284423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 23.03560495376587 s\n",
      "Accuracy 0.9287542974178918 precision 0.930326051111543 specificity 0.8881543497032514 recall 0.9287542974178918 f1 0.9293727854513808\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 23.424615144729614 s\n",
      "Accuracy 0.9292663301879892 precision 0.930346445774971 specificity 0.8834941332315827 recall 0.9292663301879892 f1 0.9297180617065487\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 23.500617504119873 s\n",
      "Accuracy 0.9263404286445761 precision 0.9279728540035846 specificity 0.8863143030312651 recall 0.9263404286445761 f1 0.9269812740741726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 23.431614875793457 s\n",
      "Accuracy 0.9317533464998903 precision 0.9332849092834742 specificity 0.8938025228089481 recall 0.9317533464998903 f1 0.932348725038912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 23.707618713378906 s\n",
      "Accuracy 0.9299978055738425 precision 0.931723898486658 specificity 0.8891640728355404 recall 0.9299978055738425 f1 0.9306676993365429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 23.31561303138733 s\n",
      "Accuracy 0.9264135761831614 precision 0.9278329481196098 specificity 0.885755710575502 recall 0.9264135761831614 f1 0.9269820362887221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 23.3526132106781 s\n",
      "Accuracy 0.9259746909516495 precision 0.9281846775595372 specificity 0.8927601362375547 recall 0.9259746909516495 f1 0.9267857124817029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 23.622618675231934 s\n",
      "Accuracy 0.9244385926413576 precision 0.9260616910327909 specificity 0.8821794361179631 recall 0.9244385926413576 f1 0.925083389804289\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 23.29261088371277 s\n",
      "Accuracy 0.9269256089532587 precision 0.9276403047706364 specificity 0.877906057120981 recall 0.9269256089532587 f1 0.9272410039648254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 23.436617136001587 s\n",
      "Accuracy 0.9292663301879892 precision 0.93023893320567 specificity 0.8847332883510153 recall 0.9292663301879892 f1 0.9296765509428491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 23.10260581970215 s\n",
      "Accuracy 0.9261941335674054 precision 0.9273163253300932 specificity 0.8775380217905048 recall 0.9261941335674054 f1 0.92666734640923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 23.113607168197632 s\n",
      "Accuracy 0.927437641723356 precision 0.9288147123042947 specificity 0.8876706359532276 recall 0.927437641723356 f1 0.9279885563728922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 23.63262104988098 s\n",
      "Accuracy 0.9258283958744788 precision 0.927338936489384 specificity 0.8813574476948919 recall 0.9258283958744788 f1 0.926436709267066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 23.171608209609985 s\n",
      "Accuracy 0.9282422646477946 precision 0.9296955937995365 specificity 0.8891479996497762 recall 0.9282422646477946 f1 0.9288174636707291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 23.33261275291443 s\n",
      "Accuracy 0.9261209860288201 precision 0.9275958589788666 specificity 0.8837409068723213 recall 0.9261209860288201 f1 0.9267124951127853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 23.257609367370605 s\n",
      "Accuracy 0.9223173140223832 precision 0.9239508618425603 specificity 0.8818997382675315 recall 0.9223173140223832 f1 0.9229641282353181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 23.589619398117065 s\n",
      "Accuracy 0.9259746909516495 precision 0.9281092713492954 specificity 0.8921885701235 recall 0.9259746909516495 f1 0.926763776109344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 23.507616758346558 s\n",
      "Accuracy 0.9246580352571137 precision 0.9264986724824609 specificity 0.8847881032002054 recall 0.9246580352571137 f1 0.9253711697686448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 23.21260905265808 s\n",
      "Accuracy 0.924292297564187 precision 0.9253966030960418 specificity 0.8793775974108047 recall 0.924292297564187 f1 0.924755709066671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 23.528619050979614 s\n",
      "Accuracy 0.9263404286445761 precision 0.9274312198041671 specificity 0.882126441035919 recall 0.9263404286445761 f1 0.9267964084662944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 23.956629753112793 s\n",
      "Accuracy 0.9235608221783337 precision 0.9251845011211102 specificity 0.8798528106489503 recall 0.9235608221783337 f1 0.9242098616029986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 23.620621919631958 s\n",
      "Accuracy 0.9220978714066271 precision 0.9237302042979644 specificity 0.8810492017152808 recall 0.9220978714066271 f1 0.9227459204244876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 23.210609912872314 s\n",
      "Accuracy 0.9279496744934533 precision 0.9294736191305399 specificity 0.8848262748574669 recall 0.9279496744934533 f1 0.9285577630033175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 23.40961527824402 s\n",
      "Accuracy 0.9257552483358935 precision 0.9273520588007158 specificity 0.8847966416397411 recall 0.9257552483358935 f1 0.9263866405799952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 23.58862066268921 s\n",
      "Accuracy 0.9253895106429668 precision 0.927264709948038 specificity 0.8878315151476638 recall 0.9253895106429668 f1 0.9261069652885647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 23.496619701385498 s\n",
      "Accuracy 0.9294857728037451 precision 0.9307913750932102 specificity 0.8876543185390383 recall 0.9294857728037451 f1 0.9300132240997693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 23.613619327545166 s\n",
      "Accuracy 0.9268524614146734 precision 0.9286054828401605 specificity 0.8869699292208154 recall 0.9268524614146734 f1 0.9275332515006551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 23.34661316871643 s\n",
      "Accuracy 0.9288274449564772 precision 0.9306443736275188 specificity 0.8891706046979733 recall 0.9288274449564772 f1 0.9295264720343952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 23.546618223190308 s\n",
      "Accuracy 0.9297052154195011 precision 0.9307889127191034 specificity 0.8854680502700317 recall 0.9297052154195011 f1 0.930156013791081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 23.37961435317993 s\n",
      "Accuracy 0.9310950186526223 precision 0.9320304140408603 specificity 0.886513470550518 recall 0.9310950186526223 f1 0.9314900854566951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 23.374614000320435 s\n",
      "Accuracy 0.9261209860288201 precision 0.9274815627792785 specificity 0.8859865321009455 recall 0.9261209860288201 f1 0.9266681294289938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 23.273611068725586 s\n",
      "Accuracy 0.9250969204886256 precision 0.9264688397850799 specificity 0.8828204097059323 recall 0.9250969204886256 f1 0.9256529505130372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 23.430614948272705 s\n",
      "Accuracy 0.9284617072635506 precision 0.9298598186965756 specificity 0.8857250752135852 recall 0.9284617072635506 f1 0.9290244332105358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 23.099606037139893 s\n",
      "Accuracy 0.9232682320239924 precision 0.9246624710737404 specificity 0.8773281126905538 recall 0.9232682320239924 f1 0.9238402222776386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 23.26161217689514 s\n",
      "Accuracy 0.9296320678809158 precision 0.9309663770862985 specificity 0.8891458757282609 recall 0.9296320678809158 f1 0.9301671235859688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 22.9106023311615 s\n",
      "Accuracy 0.9275107892619413 precision 0.928394545173591 specificity 0.8811813210077225 recall 0.9275107892619413 f1 0.9278901941108351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 23.84762716293335 s\n",
      "Accuracy 0.9242191500256016 precision 0.9256296186969158 specificity 0.8779325297477336 recall 0.9242191500256016 f1 0.9247966415499558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 23.51661777496338 s\n",
      "Accuracy 0.9288274449564772 precision 0.9298127741292104 specificity 0.883261672130889 recall 0.9288274449564772 f1 0.9292438764451536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 23.073540925979614 s\n",
      "Accuracy 0.9286811498793066 precision 0.9308721422146795 specificity 0.8933427361957234 recall 0.9286811498793066 f1 0.9294894057663831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 23.541442155838013 s\n",
      "Accuracy 0.9281691171092092 precision 0.929952085561148 specificity 0.8894818972081181 recall 0.9281691171092092 f1 0.9288551994218508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 23.820446729660034 s\n",
      "Accuracy 0.9263404286445761 precision 0.9283069631653843 specificity 0.8852657237858695 recall 0.9263404286445761 f1 0.927096601877818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 23.168434381484985 s\n",
      "Accuracy 0.9263404286445761 precision 0.9279303954921116 specificity 0.8826979479911152 recall 0.9263404286445761 f1 0.9269743871182446\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 23.288434982299805 s\n",
      "Accuracy 0.9251700680272109 precision 0.9266870159841974 specificity 0.8811920545449573 recall 0.9251700680272109 f1 0.9257804259969786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 23.067434310913086 s\n",
      "Accuracy 0.9314607563455489 precision 0.9328494514647753 specificity 0.89132382729205 recall 0.9314607563455489 f1 0.9320121884417403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 23.518442392349243 s\n",
      "Accuracy 0.9306561334211104 precision 0.9315631705762119 specificity 0.8887064878227946 recall 0.9306561334211104 f1 0.9310380351855546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 22.79742693901062 s\n",
      "Accuracy 0.9252432155657963 precision 0.927140438586551 specificity 0.886700849191904 recall 0.9252432155657963 f1 0.9259709244597067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 23.210436582565308 s\n",
      "Accuracy 0.9258283958744788 precision 0.9275715967671874 specificity 0.8851134492314553 recall 0.9258283958744788 f1 0.9265092006821408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 22.990431547164917 s\n",
      "Accuracy 0.9294857728037451 precision 0.9309009642736545 specificity 0.890245394632979 recall 0.9294857728037451 f1 0.930046755412195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 23.33443832397461 s\n",
      "Accuracy 0.9280959695706239 precision 0.9295873120176087 specificity 0.8883351499220266 recall 0.9280959695706239 f1 0.9286858134855406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 23.462440252304077 s\n",
      "Accuracy 0.9306561334211104 precision 0.9316935841052902 specificity 0.8871582889507502 recall 0.9306561334211104 f1 0.931088239816401\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 23.785446882247925 s\n",
      "Accuracy 0.9272181991076001 precision 0.9287406137051993 specificity 0.8857896848406814 recall 0.9272181991076001 f1 0.9278231999303385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 23.378440618515015 s\n",
      "Accuracy 0.9285348548021359 precision 0.9303676187416554 specificity 0.8933534113460037 recall 0.9285348548021359 f1 0.9292272413908516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 23.021430730819702 s\n",
      "Accuracy 0.9286080023407213 precision 0.9293318918587953 specificity 0.881863640653086 recall 0.9286080023407213 f1 0.9289248157590946\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 23.282434463500977 s\n",
      "Accuracy 0.9269256089532587 precision 0.9286740591658443 specificity 0.889284388168998 recall 0.9269256089532587 f1 0.9275990863363178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 23.486441135406494 s\n",
      "Accuracy 0.9291931826494039 precision 0.9307458449353067 specificity 0.8895923960982243 recall 0.9291931826494039 f1 0.9298024513927008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 23.423438787460327 s\n",
      "Accuracy 0.9293394777265745 precision 0.9308082158540483 specificity 0.8885088823366818 recall 0.9293394777265745 f1 0.9299223076043963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 23.431437492370605 s\n",
      "Accuracy 0.9237802647940897 precision 0.9252848404554527 specificity 0.8799140427235435 recall 0.9237802647940897 f1 0.9243875303095094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 23.277438640594482 s\n",
      "Accuracy 0.9251700680272109 precision 0.9262325281764199 specificity 0.8796609447661521 recall 0.9251700680272109 f1 0.9256179415365948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 23.12743353843689 s\n",
      "Accuracy 0.9275839368005266 precision 0.9286765008059691 specificity 0.8857391383804457 recall 0.9275839368005266 f1 0.9280364889890902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 23.524441719055176 s\n",
      "Accuracy 0.9293394777265745 precision 0.9314544204612154 specificity 0.8939870368004875 recall 0.9293394777265745 f1 0.9301224351707685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 23.24543595314026 s\n",
      "Accuracy 0.9282422646477946 precision 0.9294755154144989 specificity 0.8872839215846366 recall 0.9282422646477946 f1 0.9287437351689868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 23.48043942451477 s\n",
      "Accuracy 0.9271450515690147 precision 0.9289142062781055 specificity 0.8878271748683676 recall 0.9271450515690147 f1 0.927829479552889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 23.538440704345703 s\n",
      "Accuracy 0.9308755760368663 precision 0.9322278989284333 specificity 0.8899125542843184 recall 0.9308755760368663 f1 0.9314165201820254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 23.418440103530884 s\n",
      "Accuracy 0.9245848877185283 precision 0.9270252926027489 specificity 0.8881499850535136 recall 0.9245848877185283 f1 0.925483317255507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 23.584442853927612 s\n",
      "Accuracy 0.9282422646477946 precision 0.930555129692813 specificity 0.891854860601084 recall 0.9282422646477946 f1 0.9290937450278227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 23.47544240951538 s\n",
      "Accuracy 0.9268524614146734 precision 0.9281001476822266 specificity 0.8825672214617833 recall 0.9268524614146734 f1 0.9273655656783389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 23.76644730567932 s\n",
      "Accuracy 0.9277302318776973 precision 0.9288266853291004 specificity 0.8855653808473525 recall 0.9277302318776973 f1 0.9281845290606414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 23.430440187454224 s\n",
      "Accuracy 0.9237071172555044 precision 0.9252371213226361 specificity 0.8822267265751229 recall 0.9237071172555044 f1 0.9243187307667644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 23.775445222854614 s\n",
      "Accuracy 0.9261941335674054 precision 0.9276021706965442 specificity 0.8854751560562549 recall 0.9261941335674054 f1 0.9267589658379624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 22.989431142807007 s\n",
      "Accuracy 0.927657084339112 precision 0.9296615244139902 specificity 0.8900920761166238 recall 0.927657084339112 f1 0.9284138727380572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 23.12443494796753 s\n",
      "Accuracy 0.9230487894082364 precision 0.9247969229322613 specificity 0.8808917842953068 recall 0.9230487894082364 f1 0.9237381479649518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 24.238454818725586 s\n",
      "Accuracy 0.9286080023407213 precision 0.9299881560855044 specificity 0.8885211429817896 recall 0.9286080023407213 f1 0.929159398215183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 23.21343469619751 s\n",
      "Accuracy 0.923853412332675 precision 0.9250994164274198 specificity 0.8756406926057901 recall 0.923853412332675 f1 0.9243740545990431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 23.820449352264404 s\n",
      "Accuracy 0.9265598712603321 precision 0.9285567102237979 specificity 0.8874366285023636 recall 0.9265598712603321 f1 0.9273203483871425\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 23.343435287475586 s\n",
      "Accuracy 0.9226830517153097 precision 0.9247451510221979 specificity 0.8815176455021373 recall 0.9226830517153097 f1 0.9234766242260399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 23.15043306350708 s\n",
      "Accuracy 0.9251700680272109 precision 0.9265074264151034 specificity 0.8775245573313876 recall 0.9251700680272109 f1 0.9257222969409337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 23.37243890762329 s\n",
      "Accuracy 0.9308755760368663 precision 0.9314450577815931 specificity 0.8839443034919141 recall 0.9308755760368663 f1 0.9311295984175062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 23.249438285827637 s\n",
      "Accuracy 0.924292297564187 precision 0.9265046221855936 specificity 0.8857280870396799 recall 0.924292297564187 f1 0.9251251415476843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 23.20943546295166 s\n",
      "Accuracy 0.9284617072635506 precision 0.9292056681127701 specificity 0.8842075932359604 recall 0.9284617072635506 f1 0.9287846551602218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 24.043453454971313 s\n",
      "Accuracy 0.9256089532587228 precision 0.9271881128026241 specificity 0.8826525045461139 recall 0.9256089532587228 f1 0.9262385985230775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 23.482439517974854 s\n",
      "Accuracy 0.9247311827956989 precision 0.9266561842757854 specificity 0.8815291348544502 recall 0.9247311827956989 f1 0.9254811898238764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 23.36043930053711 s\n",
      "Accuracy 0.9289005924950625 precision 0.9297397040641382 specificity 0.8811918972226231 recall 0.9289005924950625 f1 0.9292631608120588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 22.97843098640442 s\n",
      "Accuracy 0.9277302318776973 precision 0.9286655111428009 specificity 0.8817711424240876 recall 0.9277302318776973 f1 0.9281288613304857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 23.52444338798523 s\n",
      "Accuracy 0.9354107234291567 precision 0.9369117868018926 specificity 0.9028228515013139 recall 0.9354107234291567 f1 0.9359785511632163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 23.84444761276245 s\n",
      "Accuracy 0.9255358057201375 precision 0.9267246253982389 specificity 0.8785258371619302 recall 0.9255358057201375 f1 0.9260323074132665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 23.359439373016357 s\n",
      "Accuracy 0.9253163631043816 precision 0.9263631659958378 specificity 0.8791269967647963 recall 0.9253163631043816 f1 0.9257590440226785\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 23.444440603256226 s\n",
      "Accuracy 0.9294857728037451 precision 0.9312307561851337 specificity 0.8912034889901944 recall 0.9294857728037451 f1 0.9301563894515474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 23.636443853378296 s\n",
      "Accuracy 0.9243654451027723 precision 0.9253428799551509 specificity 0.8793734086360815 recall 0.9243654451027723 f1 0.9247812189949813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 23.439441919326782 s\n",
      "Accuracy 0.9285348548021359 precision 0.9296020292160253 specificity 0.8858001578656761 recall 0.9285348548021359 f1 0.9289785524447121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 23.338438987731934 s\n",
      "Accuracy 0.9279496744934533 precision 0.9296248156494449 specificity 0.8869966873154032 recall 0.9279496744934533 f1 0.9286052276401927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 23.26343536376953 s\n",
      "Accuracy 0.9251700680272109 precision 0.9267961398042687 specificity 0.8841486340732153 recall 0.9251700680272109 f1 0.9258123544926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 23.205435752868652 s\n",
      "Accuracy 0.9252432155657963 precision 0.927330597697114 specificity 0.8861344093644558 recall 0.9252432155657963 f1 0.9260354136064054\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 23.200436115264893 s\n",
      "Accuracy 0.9286811498793066 precision 0.9302152476271653 specificity 0.88489295366862 recall 0.9286811498793066 f1 0.9292932363423835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 23.465441465377808 s\n",
      "Accuracy 0.9258283958744788 precision 0.9267651962682555 specificity 0.8821594295363732 recall 0.9258283958744788 f1 0.9262264313573217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 23.273435831069946 s\n",
      "Accuracy 0.9304366908053544 precision 0.931739278714842 specificity 0.8894887744947123 recall 0.9304366908053544 f1 0.9309606171950912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 23.56344723701477 s\n",
      "Accuracy 0.9239997074098456 precision 0.9253598937554075 specificity 0.8801811208857172 recall 0.9239997074098456 f1 0.9245552471870201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 23.273433923721313 s\n",
      "Accuracy 0.9271450515690147 precision 0.9284808066827401 specificity 0.8868698180600914 recall 0.9271450515690147 f1 0.9276827117773431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 23.455440759658813 s\n",
      "Accuracy 0.9299978055738425 precision 0.931009888042711 specificity 0.885857296431645 recall 0.9299978055738425 f1 0.9304217943897902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 23.379438400268555 s\n",
      "Accuracy 0.9286811498793066 precision 0.93044376591996 specificity 0.8902663294833028 recall 0.9286811498793066 f1 0.9293590560621706\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 23.248436212539673 s\n",
      "Accuracy 0.9250237729500402 precision 0.9269349582139276 specificity 0.8851992599425726 recall 0.9250237729500402 f1 0.9257599425237519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 23.27943754196167 s\n",
      "Accuracy 0.9298515104966718 precision 0.9323898150581367 specificity 0.9001120128042387 recall 0.9298515104966718 f1 0.9307437945774255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 23.463440895080566 s\n",
      "Accuracy 0.9284617072635506 precision 0.9302061221292411 specificity 0.8928666175236972 recall 0.9284617072635506 f1 0.9291263636351081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 23.077434062957764 s\n",
      "Accuracy 0.9266330187989175 precision 0.927746014746433 specificity 0.8842840173539295 recall 0.9266330187989175 f1 0.927094481156554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 23.227436304092407 s\n",
      "Accuracy 0.9260478384902348 precision 0.9277230452988401 specificity 0.8866508317714672 recall 0.9260478384902348 f1 0.9267021390540751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 23.5364408493042 s\n",
      "Accuracy 0.9250237729500402 precision 0.9264533131230933 specificity 0.88315184336134 recall 0.9250237729500402 f1 0.9255995305299008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 23.250441074371338 s\n",
      "Accuracy 0.9277302318776973 precision 0.9288122492004174 specificity 0.883030726264086 recall 0.9277302318776973 f1 0.9281825229875915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 23.29743719100952 s\n",
      "Accuracy 0.9275839368005266 precision 0.9285511561505762 specificity 0.8828536150051022 recall 0.9275839368005266 f1 0.9279934807942425\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 23.310437440872192 s\n",
      "Accuracy 0.927437641723356 precision 0.9291327720072964 specificity 0.8876235780896508 recall 0.927437641723356 f1 0.9280979606359737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 23.044432878494263 s\n",
      "Accuracy 0.9261209860288201 precision 0.9279694763039523 specificity 0.8871342841061477 recall 0.9261209860288201 f1 0.926832474672317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 23.409444093704224 s\n",
      "Accuracy 0.9240728549484309 precision 0.9258866719589062 specificity 0.8827895660815824 recall 0.9240728549484309 f1 0.9247812649247606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 23.075430154800415 s\n",
      "Accuracy 0.9278033794162827 precision 0.9291391321104107 specificity 0.8850489642241157 recall 0.9278033794162827 f1 0.928344741366353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 23.477436542510986 s\n",
      "Accuracy 0.9287542974178918 precision 0.9296332870065589 specificity 0.8815267469250536 recall 0.9287542974178918 f1 0.929131955517703\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 23.24143648147583 s\n",
      "Accuracy 0.9271450515690147 precision 0.9282137400235693 specificity 0.8817226070986003 recall 0.9271450515690147 f1 0.9275937170943273\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 23.24943709373474 s\n",
      "Accuracy 0.9249506254114549 precision 0.9266352017591343 specificity 0.8815501079278649 recall 0.9249506254114549 f1 0.9256185480462047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 23.843448162078857 s\n",
      "Accuracy 0.927437641723356 precision 0.929276489343757 specificity 0.8901357482921549 recall 0.927437641723356 f1 0.9281395614661897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 23.068431615829468 s\n",
      "Accuracy 0.926998756491844 precision 0.9290032413013469 specificity 0.8888157076016094 recall 0.926998756491844 f1 0.9277583687864996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 23.130433559417725 s\n",
      "Accuracy 0.9272181991076001 precision 0.9289291707984212 specificity 0.890031521643796 recall 0.9272181991076001 f1 0.9278776028009332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 23.334437131881714 s\n",
      "Accuracy 0.9286080023407213 precision 0.9300666596307816 specificity 0.8899053082224452 recall 0.9286080023407213 f1 0.9291838207645182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 23.394437551498413 s\n",
      "Accuracy 0.9251700680272109 precision 0.9270260834859605 specificity 0.8838491459424744 recall 0.9251700680272109 f1 0.9258914167898278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 23.318438291549683 s\n",
      "Accuracy 0.9296320678809158 precision 0.9303568011486739 specificity 0.8849478701243889 recall 0.9296320678809158 f1 0.9299472593883114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 23.2904372215271 s\n",
      "Accuracy 0.9280228220320387 precision 0.929591886650742 specificity 0.8890688998421249 recall 0.9280228220320387 f1 0.928637630627231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 23.04443335533142 s\n",
      "Accuracy 0.9273644941847707 precision 0.9288992532736702 specificity 0.8836722966392563 recall 0.9273644941847707 f1 0.9279781254072863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 23.29643726348877 s\n",
      "Accuracy 0.9281691171092092 precision 0.9293954321175634 specificity 0.8834419169847988 recall 0.9281691171092092 f1 0.9286739585501357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 23.569442987442017 s\n",
      "Accuracy 0.9264135761831614 precision 0.927530026300004 specificity 0.8791773829884731 recall 0.9264135761831614 f1 0.9268827854115759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 23.652443647384644 s\n",
      "Accuracy 0.9256089532587228 precision 0.9266913837593235 specificity 0.8803098366818897 recall 0.9256089532587228 f1 0.9260637221489136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 23.0694317817688 s\n",
      "Accuracy 0.9256821007973082 precision 0.9273450540126836 specificity 0.8833736424511294 recall 0.9256821007973082 f1 0.9263393037292438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 23.260254859924316 s\n",
      "Accuracy 0.9249506254114549 precision 0.9266380462773254 specificity 0.8813970398047319 recall 0.9249506254114549 f1 0.9256198622150733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 23.16018581390381 s\n",
      "Accuracy 0.9263404286445761 precision 0.9278419908452784 specificity 0.8876342630882158 recall 0.9263404286445761 f1 0.9269335050925778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 23.51119065284729 s\n",
      "Accuracy 0.9259015434130642 precision 0.9274096618530858 specificity 0.885418757742251 recall 0.9259015434130642 f1 0.9265011116648804\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 23.29619026184082 s\n",
      "Accuracy 0.9308755760368663 precision 0.9318486354650983 specificity 0.8879541513906194 recall 0.9308755760368663 f1 0.93128301891927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 23.400201320648193 s\n",
      "Accuracy 0.9243654451027723 precision 0.9257222473362262 specificity 0.8815355815192324 recall 0.9243654451027723 f1 0.9249177541244382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 23.18718695640564 s\n",
      "Accuracy 0.9263404286445761 precision 0.9275328734854952 specificity 0.88515093889607 recall 0.9263404286445761 f1 0.9268293028052873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 23.15218448638916 s\n",
      "Accuracy 0.9250237729500402 precision 0.9268855822135064 specificity 0.8834337669393458 recall 0.9250237729500402 f1 0.9257479529324651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 23.254186868667603 s\n",
      "Accuracy 0.9257552483358935 precision 0.9272320182633668 specificity 0.8840773990907469 recall 0.9257552483358935 f1 0.9263464550734497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 23.713191747665405 s\n",
      "Accuracy 0.9286080023407213 precision 0.9294406158343059 specificity 0.8838702524965769 recall 0.9286080023407213 f1 0.9289656645295614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 23.281188011169434 s\n",
      "Accuracy 0.9289005924950625 precision 0.9303081987357752 specificity 0.8886632388188493 recall 0.9289005924950625 f1 0.9294615308353088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 23.52819037437439 s\n",
      "Accuracy 0.9288274449564772 precision 0.9298796398230391 specificity 0.8872164207260038 recall 0.9288274449564772 f1 0.9292639500663109\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 23.089186906814575 s\n",
      "Accuracy 0.9259746909516495 precision 0.9275651221716268 specificity 0.8846079173612659 recall 0.9259746909516495 f1 0.9266045079378804\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 23.322190284729004 s\n",
      "Accuracy 0.9237071172555044 precision 0.9258817108731326 specificity 0.8841860970373128 recall 0.9237071172555044 f1 0.9245315478327429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 23.474186897277832 s\n",
      "Accuracy 0.9248043303342842 precision 0.9269948610748091 specificity 0.8888929186163417 recall 0.9248043303342842 f1 0.9256205183375872\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 23.479188919067383 s\n",
      "Accuracy 0.926998756491844 precision 0.9287735340269903 specificity 0.8887649744236219 recall 0.926998756491844 f1 0.9276824769772068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 23.48418879508972 s\n",
      "Accuracy 0.9263404286445761 precision 0.9286247054959912 specificity 0.8886156506847568 recall 0.9263404286445761 f1 0.9271905328287025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 23.514190673828125 s\n",
      "Accuracy 0.9270719040304294 precision 0.9283692652485523 specificity 0.8868808363083095 recall 0.9270719040304294 f1 0.9275959362546067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 23.73819136619568 s\n",
      "Accuracy 0.9288274449564772 precision 0.930241315160559 specificity 0.8858745832916898 recall 0.9288274449564772 f1 0.9293957221154324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 23.239184856414795 s\n",
      "Accuracy 0.9281691171092092 precision 0.9290864831834396 specificity 0.8816868858624065 recall 0.9281691171092092 f1 0.9285611557874442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 23.41418981552124 s\n",
      "Accuracy 0.9280959695706239 precision 0.9295289087154424 specificity 0.8856520303632053 recall 0.9280959695706239 f1 0.9286707878836266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 23.232187032699585 s\n",
      "Accuracy 0.9245848877185283 precision 0.926470632677982 specificity 0.8846229938525042 recall 0.9245848877185283 f1 0.9253135084728824\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 23.363189458847046 s\n",
      "Accuracy 0.9261209860288201 precision 0.9272706133795 specificity 0.8782271403118737 recall 0.9261209860288201 f1 0.9266035941087144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 23.33418846130371 s\n",
      "Accuracy 0.9271450515690147 precision 0.9286126657528089 specificity 0.883503861226744 recall 0.9271450515690147 f1 0.927735284678043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 23.527190685272217 s\n",
      "Accuracy 0.9268524614146734 precision 0.9281104494597563 specificity 0.8835740178683139 recall 0.9268524614146734 f1 0.9273677487507878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 23.259187936782837 s\n",
      "Accuracy 0.9272181991076001 precision 0.9289679556591952 specificity 0.8894972997301284 recall 0.9272181991076001 f1 0.9278919409903382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 23.490188121795654 s\n",
      "Accuracy 0.9237802647940897 precision 0.9251639171510199 specificity 0.874036280151369 recall 0.9237802647940897 f1 0.9243538020798913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 23.105186223983765 s\n",
      "Accuracy 0.9275839368005266 precision 0.9293415560730476 specificity 0.8887967621599341 recall 0.9275839368005266 f1 0.9282625756082944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 23.617192268371582 s\n",
      "Accuracy 0.9272913466461854 precision 0.9288615600171701 specificity 0.8869037372196896 recall 0.9272913466461854 f1 0.9279105682070794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 23.869192361831665 s\n",
      "Accuracy 0.9264135761831614 precision 0.9274494419083795 specificity 0.8819088178658679 recall 0.9264135761831614 f1 0.9268494294388091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 25.114202976226807 s\n",
      "Accuracy 0.9243654451027723 precision 0.9269027701601549 specificity 0.8896347851035321 recall 0.9243654451027723 f1 0.9252883218041744\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 25.337205410003662 s\n",
      "Accuracy 0.9265598712603321 precision 0.9278747287734685 specificity 0.8845105918945365 recall 0.9265598712603321 f1 0.9270938039802712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 24.124194860458374 s\n",
      "Accuracy 0.9297783629580865 precision 0.9316043065688923 specificity 0.8929695905879023 recall 0.9297783629580865 f1 0.9304714318523233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 23.25418996810913 s\n",
      "Accuracy 0.927876526954868 precision 0.9287978244359084 specificity 0.8810816063272522 recall 0.927876526954868 f1 0.9282705494769319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 23.801189422607422 s\n",
      "Accuracy 0.9250237729500402 precision 0.9262346211195752 specificity 0.879228393959573 recall 0.9250237729500402 f1 0.9255271826902753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 23.891193151474 s\n",
      "Accuracy 0.9264867237217468 precision 0.9287402122571861 specificity 0.8911054038897583 recall 0.9264867237217468 f1 0.9273185997945984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 23.292189836502075 s\n",
      "Accuracy 0.924292297564187 precision 0.9264730451849096 specificity 0.8857572185190647 recall 0.924292297564187 f1 0.9251147488695362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 23.628191232681274 s\n",
      "Accuracy 0.9254626581815522 precision 0.9269279557898484 specificity 0.878027939702727 recall 0.9254626581815522 f1 0.9260605052162271\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 23.69419264793396 s\n",
      "Accuracy 0.9279496744934533 precision 0.9289634008429005 specificity 0.8820869085859175 recall 0.9279496744934533 f1 0.9283777132927874\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 23.5191912651062 s\n",
      "Accuracy 0.9239265598712604 precision 0.9263736226224706 specificity 0.8866663945452266 recall 0.9239265598712604 f1 0.9248312759748937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 26.816218376159668 s\n",
      "Accuracy 0.9259015434130642 precision 0.9280268055033337 specificity 0.8870976287913261 recall 0.9259015434130642 f1 0.9267042365671183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 24.063193321228027 s\n",
      "Accuracy 0.9280959695706239 precision 0.9295247665892084 specificity 0.8889509521680979 recall 0.9280959695706239 f1 0.9286629583691408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 24.71320104598999 s\n",
      "Accuracy 0.9318264940384756 precision 0.932961925447802 specificity 0.8913436151873817 recall 0.9318264940384756 f1 0.9322890793753255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 23.446195363998413 s\n",
      "Accuracy 0.9299978055738425 precision 0.9311906396707899 specificity 0.8899037640700027 recall 0.9299978055738425 f1 0.9304818888418726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 24.629196166992188 s\n",
      "Accuracy 0.9256089532587228 precision 0.9274796364634282 specificity 0.886286238127245 recall 0.9256089532587228 f1 0.9263294431192146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 24.51919722557068 s\n",
      "Accuracy 0.9280959695706239 precision 0.9294537662453571 specificity 0.888656913483793 recall 0.9280959695706239 f1 0.9286388609171478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 24.07919454574585 s\n",
      "Accuracy 0.9283154121863799 precision 0.9292313903504559 specificity 0.8840218772555261 recall 0.9283154121863799 f1 0.9287046581952785\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 22.924185037612915 s\n",
      "Accuracy 0.9287542974178918 precision 0.9307074629239339 specificity 0.8951155557230411 recall 0.9287542974178918 f1 0.9294806355447567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 23.28018617630005 s\n",
      "Accuracy 0.9259746909516495 precision 0.9287404771340467 specificity 0.8946613445677297 recall 0.9259746909516495 f1 0.9269506491787392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 23.601189136505127 s\n",
      "Accuracy 0.9283154121863799 precision 0.9303090112799195 specificity 0.8930362205614522 recall 0.9283154121863799 f1 0.9290606694514729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 23.256186962127686 s\n",
      "Accuracy 0.9264135761831614 precision 0.9285778079208657 specificity 0.8891213181380124 recall 0.9264135761831614 f1 0.9272233708886392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 23.35318875312805 s\n",
      "Accuracy 0.9243654451027723 precision 0.9263008245135124 specificity 0.8854547173553761 recall 0.9243654451027723 f1 0.9251080754620299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 23.956193208694458 s\n",
      "Accuracy 0.9302172481895984 precision 0.930814310982855 specificity 0.8863868887640993 recall 0.9302172481895984 f1 0.9304809902453877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 23.51819086074829 s\n",
      "Accuracy 0.9296320678809158 precision 0.9309188238442709 specificity 0.8856999968669622 recall 0.9296320678809158 f1 0.9301561176215315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 23.5251886844635 s\n",
      "Accuracy 0.9289737400336479 precision 0.9300358915859962 specificity 0.8847088026972912 recall 0.9289737400336479 f1 0.929417194636873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 23.324188947677612 s\n",
      "Accuracy 0.9253163631043816 precision 0.9269613892392115 specificity 0.8817680455618897 recall 0.9253163631043816 f1 0.9259704635349421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 23.567191123962402 s\n",
      "Accuracy 0.9264135761831614 precision 0.9281144854976716 specificity 0.884962959266554 recall 0.9264135761831614 f1 0.9270809733261867\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 23.58118987083435 s\n",
      "Accuracy 0.9247311827956989 precision 0.9262602305312637 specificity 0.884671725914789 recall 0.9247311827956989 f1 0.9253384020914962\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 23.4961895942688 s\n",
      "Accuracy 0.9272181991076001 precision 0.9294110280855519 specificity 0.8906128223620268 recall 0.9272181991076001 f1 0.9280336869377753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 23.45818829536438 s\n",
      "Accuracy 0.9268524614146734 precision 0.9276263896784713 specificity 0.8796359673576646 recall 0.9268524614146734 f1 0.9271901961495266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 23.523191928863525 s\n",
      "Accuracy 0.9299978055738425 precision 0.9312584027726375 specificity 0.8886102045176114 recall 0.9299978055738425 f1 0.9305080721976475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 23.31818652153015 s\n",
      "Accuracy 0.9275107892619413 precision 0.929525544183173 specificity 0.8895113393569481 recall 0.9275107892619413 f1 0.9282724659962771\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 23.702192544937134 s\n",
      "Accuracy 0.9297783629580865 precision 0.9306138422259413 specificity 0.8844968039170171 recall 0.9297783629580865 f1 0.9301369548987538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 23.463189601898193 s\n",
      "Accuracy 0.9256089532587228 precision 0.9276719377434358 specificity 0.8855971388062209 recall 0.9256089532587228 f1 0.9263952346339933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 23.44418978691101 s\n",
      "Accuracy 0.9263404286445761 precision 0.9275255329392813 specificity 0.8785240793720382 recall 0.9263404286445761 f1 0.9268359452853686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 23.430190563201904 s\n",
      "Accuracy 0.9272913466461854 precision 0.9285993434770096 specificity 0.8839428650189352 recall 0.9272913466461854 f1 0.9278242936162365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 23.23018765449524 s\n",
      "Accuracy 0.9291931826494039 precision 0.9302224573301676 specificity 0.8866114774681745 recall 0.9291931826494039 f1 0.9296222355910125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 23.142185926437378 s\n",
      "Accuracy 0.9235608221783337 precision 0.9244784651326734 specificity 0.8769669547645783 recall 0.9235608221783337 f1 0.923955806895577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 23.688192129135132 s\n",
      "Accuracy 0.9304366908053544 precision 0.9317335610986139 specificity 0.891417155300386 recall 0.9304366908053544 f1 0.9309551763381975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 23.4361891746521 s\n",
      "Accuracy 0.9286080023407213 precision 0.9302117971509413 specificity 0.887749999265313 recall 0.9286080023407213 f1 0.9292381928965884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 23.162187814712524 s\n",
      "Accuracy 0.9262672811059908 precision 0.9288609525124603 specificity 0.8940648913420223 recall 0.9262672811059908 f1 0.927193814571086\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 23.75119161605835 s\n",
      "Accuracy 0.9280228220320387 precision 0.9295526297606328 specificity 0.8868482378619176 recall 0.9280228220320387 f1 0.9286289483172345\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 23.604191064834595 s\n",
      "Accuracy 0.9285348548021359 precision 0.9306983372038743 specificity 0.8918768624182842 recall 0.9285348548021359 f1 0.9293389839805948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 23.478190183639526 s\n",
      "Accuracy 0.9258283958744788 precision 0.9277092896699339 specificity 0.8853459491068192 recall 0.9258283958744788 f1 0.9265550709256\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 23.44418978691101 s\n",
      "Accuracy 0.9270719040304294 precision 0.9283909425881601 specificity 0.8854920977159417 recall 0.9270719040304294 f1 0.927606032091175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 23.95719337463379 s\n",
      "Accuracy 0.9275839368005266 precision 0.9288970066813489 specificity 0.8871142634017217 recall 0.9275839368005266 f1 0.9281135201115919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 23.40318989753723 s\n",
      "Accuracy 0.9275839368005266 precision 0.9294099892006298 specificity 0.8895608622680348 recall 0.9275839368005266 f1 0.9282833904842102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 23.089186906814575 s\n",
      "Accuracy 0.9270719040304294 precision 0.9287093660018784 specificity 0.883773568863126 recall 0.9270719040304294 f1 0.92772076375884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 23.809191703796387 s\n",
      "Accuracy 0.9231950844854071 precision 0.924687357513498 specificity 0.8831720180747419 recall 0.9231950844854071 f1 0.9237910980911996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 23.78219223022461 s\n",
      "Accuracy 0.9264135761831614 precision 0.9277840765394891 specificity 0.8807321997574423 recall 0.9264135761831614 f1 0.9269735615247339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 23.37619137763977 s\n",
      "Accuracy 0.9254626581815522 precision 0.9278109755630922 specificity 0.8865029874158916 recall 0.9254626581815522 f1 0.92633904420119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 23.664190530776978 s\n",
      "Accuracy 0.9259015434130642 precision 0.9278924796437473 specificity 0.8864100551879885 recall 0.9259015434130642 f1 0.9266620766824193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 25.2362060546875 s\n",
      "Accuracy 0.9259746909516495 precision 0.9280528023511911 specificity 0.8897101767782712 recall 0.9259746909516495 f1 0.9267539315178015\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 23.463189125061035 s\n",
      "Accuracy 0.9273644941847707 precision 0.9302468317636835 specificity 0.8972947587379553 recall 0.9273644941847707 f1 0.9283672668157026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 24.140194416046143 s\n",
      "Accuracy 0.9291200351108185 precision 0.9305209041440364 specificity 0.8914744244040261 recall 0.9291200351108185 f1 0.9296732369408962\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 25.209203004837036 s\n",
      "Accuracy 0.9288274449564772 precision 0.9310210537146854 specificity 0.895685161704625 recall 0.9288274449564772 f1 0.9296285061912183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 24.323195695877075 s\n",
      "Accuracy 0.9280228220320387 precision 0.9290014189066225 specificity 0.8821967192459301 recall 0.9280228220320387 f1 0.928437543287936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 24.688969612121582 s\n",
      "Accuracy 0.9284617072635506 precision 0.930073408558866 specificity 0.8886381001714572 recall 0.9284617072635506 f1 0.929092469187951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 24.309719562530518 s\n",
      "Accuracy 0.9264867237217468 precision 0.9282344597377297 specificity 0.8861971507454226 recall 0.9264867237217468 f1 0.9271671971875766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 23.724866151809692 s\n",
      "Accuracy 0.927876526954868 precision 0.9293952128142962 specificity 0.8873403304340102 recall 0.927876526954868 f1 0.9284776583530865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 23.990104913711548 s\n",
      "Accuracy 0.9247311827956989 precision 0.926255602924697 specificity 0.8834526062701724 recall 0.9247311827956989 f1 0.9253393276271337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 24.05943489074707 s\n",
      "Accuracy 0.9292663301879892 precision 0.93041842448337 specificity 0.88533643060471 recall 0.9292663301879892 f1 0.9297421121452151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 24.3017578125 s\n",
      "Accuracy 0.9299246580352571 precision 0.931817202031324 specificity 0.8975645372997872 recall 0.9299246580352571 f1 0.930625725511515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 23.346665143966675 s\n",
      "Accuracy 0.9278033794162827 precision 0.9290670301016779 specificity 0.8865059207172202 recall 0.9278033794162827 f1 0.9283166466170094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 23.657716989517212 s\n",
      "Accuracy 0.9212201009436033 precision 0.9231052199757234 specificity 0.8787851971110502 recall 0.9212201009436033 f1 0.921959322764524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 24.056485891342163 s\n",
      "Accuracy 0.9247311827956989 precision 0.9254612457294848 specificity 0.8769682726074303 recall 0.9247311827956989 f1 0.9250528434667326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 23.442986965179443 s\n",
      "Accuracy 0.9257552483358935 precision 0.9266265577066909 specificity 0.8765667044216785 recall 0.9257552483358935 f1 0.9261333021876034\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 23.55208396911621 s\n",
      "Accuracy 0.9250237729500402 precision 0.9273552333929551 specificity 0.8867038598309133 recall 0.9250237729500402 f1 0.9258932688655751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 24.257084131240845 s\n",
      "Accuracy 0.923853412332675 precision 0.9254452576222455 specificity 0.8818832403112121 recall 0.923853412332675 f1 0.9244874193133257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 24.529086112976074 s\n",
      "Accuracy 0.9271450515690147 precision 0.9283496740471537 specificity 0.8805383648836058 recall 0.9271450515690147 f1 0.927645504576048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 24.205085277557373 s\n",
      "Accuracy 0.9275839368005266 precision 0.9289179470927263 specificity 0.8873627607201189 recall 0.9275839368005266 f1 0.9281204537308589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 24.669087171554565 s\n",
      "Accuracy 0.924292297564187 precision 0.926044095486435 specificity 0.8866671133952239 recall 0.924292297564187 f1 0.9249702104890041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 24.919600009918213 s\n",
      "Accuracy 0.9289737400336479 precision 0.9300243823803718 specificity 0.885635746882597 recall 0.9289737400336479 f1 0.9294117873389744\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 24.54822278022766 s\n",
      "Accuracy 0.9297052154195011 precision 0.930806862100559 specificity 0.8911101455447797 recall 0.9297052154195011 f1 0.9301546484105935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 24.650088787078857 s\n",
      "Accuracy 0.9291200351108185 precision 0.9303507222779325 specificity 0.8865475729313179 recall 0.9291200351108185 f1 0.92962235425596\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 23.834622621536255 s\n",
      "Accuracy 0.9264867237217468 precision 0.9277351162401868 specificity 0.8830720500809912 recall 0.9264867237217468 f1 0.9269990876965356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 23.382081747055054 s\n",
      "Accuracy 0.9233413795625777 precision 0.9257423495166363 specificity 0.8865802507230286 recall 0.9233413795625777 f1 0.92423049517997\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 23.731082916259766 s\n",
      "Accuracy 0.9261209860288201 precision 0.9279411287760738 specificity 0.8871277530362031 recall 0.9261209860288201 f1 0.926823019009155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 23.957680702209473 s\n",
      "Accuracy 0.9299246580352571 precision 0.9322852833621195 specificity 0.8980925807434275 recall 0.9299246580352571 f1 0.9307711292372901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 24.32827615737915 s\n",
      "Accuracy 0.9320459366542316 precision 0.9334185675957055 specificity 0.8928102457192366 recall 0.9320459366542316 f1 0.9325894449855449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 23.8105947971344 s\n",
      "Accuracy 0.9296320678809158 precision 0.9319420556259627 specificity 0.8962523516805849 recall 0.9296320678809158 f1 0.9304692917799796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 23.796082973480225 s\n",
      "Accuracy 0.9226830517153097 precision 0.9249133668351809 specificity 0.882177261799722 recall 0.9226830517153097 f1 0.923530432408677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 23.18308138847351 s\n",
      "Accuracy 0.9326311169629142 precision 0.9337236662555852 specificity 0.8926010086829668 recall 0.9326311169629142 f1 0.9330769814427514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 23.567081928253174 s\n",
      "Accuracy 0.9285348548021359 precision 0.9306288176044097 specificity 0.8957158682488944 recall 0.9285348548021359 f1 0.929303689679733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 24.1220862865448 s\n",
      "Accuracy 0.9290468875722332 precision 0.9302639734051953 specificity 0.8882509617431521 recall 0.9290468875722332 f1 0.929541599154773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 23.47810959815979 s\n",
      "Accuracy 0.927657084339112 precision 0.9295349287750704 specificity 0.8917770114592559 recall 0.927657084339112 f1 0.928367474063879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 23.35547137260437 s\n",
      "Accuracy 0.9275107892619413 precision 0.929019287443888 specificity 0.8853282944753461 recall 0.9275107892619413 f1 0.9281121419831352\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 23.641135692596436 s\n",
      "Accuracy 0.9286080023407213 precision 0.9308363686842032 specificity 0.8947551886568247 recall 0.9286080023407213 f1 0.929422984163158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 24.011164665222168 s\n",
      "Accuracy 0.9286811498793066 precision 0.9301782692819096 specificity 0.8885391991519135 recall 0.9286811498793066 f1 0.9292731179683136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 24.490084171295166 s\n",
      "Accuracy 0.9255358057201375 precision 0.9269825103463809 specificity 0.8817596846614456 recall 0.9255358057201375 f1 0.9261205981253866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 23.861083507537842 s\n",
      "Accuracy 0.9293394777265745 precision 0.9308985796176531 specificity 0.8908076533063514 recall 0.9293394777265745 f1 0.929948387192804\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 24.500086069107056 s\n",
      "Accuracy 0.9315339038841343 precision 0.9327184347552199 specificity 0.8926053532020275 recall 0.9315339038841343 f1 0.9320117429261444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 23.605083227157593 s\n",
      "Accuracy 0.927437641723356 precision 0.9287553952418792 specificity 0.8834183436392383 recall 0.927437641723356 f1 0.9279750301057993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 23.867082595825195 s\n",
      "Accuracy 0.9264135761831614 precision 0.9277695004083142 specificity 0.8833602187182088 recall 0.9264135761831614 f1 0.9269639817046738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 23.713082790374756 s\n",
      "Accuracy 0.9280959695706239 precision 0.9297515109994525 specificity 0.8867110361302969 recall 0.9280959695706239 f1 0.928745636218438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 23.55459237098694 s\n",
      "Accuracy 0.9247311827956989 precision 0.9262255594528368 specificity 0.8821387858688988 recall 0.9247311827956989 f1 0.9253314255055018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 23.60158658027649 s\n",
      "Accuracy 0.9246580352571137 precision 0.9264163399856427 specificity 0.8818382566109747 recall 0.9246580352571137 f1 0.9253504127882609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 23.877083778381348 s\n",
      "Accuracy 0.9278033794162827 precision 0.929429570344853 specificity 0.8879830156610363 recall 0.9278033794162827 f1 0.9284398649665085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 23.8850839138031 s\n",
      "Accuracy 0.9260478384902348 precision 0.9271064629175227 specificity 0.8825883594624943 recall 0.9260478384902348 f1 0.9264911580273769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 24.01608395576477 s\n",
      "Accuracy 0.9299978055738425 precision 0.9316825930424733 specificity 0.8912321525564955 recall 0.9299978055738425 f1 0.9306488379413534\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 23.592082738876343 s\n",
      "Accuracy 0.9273644941847707 precision 0.9296405484701746 specificity 0.892313179592667 recall 0.9273644941847707 f1 0.9282009528758731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 24.072593927383423 s\n",
      "Accuracy 0.9319727891156463 precision 0.9337712631780302 specificity 0.8963399509946666 recall 0.9319727891156463 f1 0.9326504928091852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 23.70408272743225 s\n",
      "Accuracy 0.9283885597249653 precision 0.9295141229905534 specificity 0.884796700128743 recall 0.9283885597249653 f1 0.928854919447602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 23.584612369537354 s\n",
      "Accuracy 0.9231950844854071 precision 0.9250378523431295 specificity 0.879112545739712 recall 0.9231950844854071 f1 0.9239212344731281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 23.603081703186035 s\n",
      "Accuracy 0.9247311827956989 precision 0.9258081381077886 specificity 0.8781044290968643 recall 0.9247311827956989 f1 0.9251861199689905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 23.736083507537842 s\n",
      "Accuracy 0.9291200351108185 precision 0.9304635606890724 specificity 0.8873231107339214 recall 0.9291200351108185 f1 0.9296611844950068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 23.93708372116089 s\n",
      "Accuracy 0.9251700680272109 precision 0.9267408338962229 specificity 0.8842251366496842 recall 0.9251700680272109 f1 0.9257931123511357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 23.75359296798706 s\n",
      "Accuracy 0.9255358057201375 precision 0.92688353755954 specificity 0.8831265953769777 recall 0.9255358057201375 f1 0.9260830389378064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 23.375793933868408 s\n",
      "Accuracy 0.9284617072635506 precision 0.9294991175438817 specificity 0.8871765200637748 recall 0.9284617072635506 f1 0.9288926383176374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 23.81176233291626 s\n",
      "Accuracy 0.9296320678809158 precision 0.9308527990185266 specificity 0.8901298285608277 recall 0.9296320678809158 f1 0.9301254117947193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 23.798083066940308 s\n",
      "Accuracy 0.9250969204886256 precision 0.9261388107035797 specificity 0.8803396172723823 recall 0.9250969204886256 f1 0.9255362501770323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 23.76308274269104 s\n",
      "Accuracy 0.9260478384902348 precision 0.9278686989465389 specificity 0.886352567865646 recall 0.9260478384902348 f1 0.9267520348906712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 23.581594705581665 s\n",
      "Accuracy 0.9277302318776973 precision 0.9286946501523484 specificity 0.881179417714436 recall 0.9277302318776973 f1 0.9281405368402187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 23.75400137901306 s\n",
      "Accuracy 0.9282422646477946 precision 0.9296998043289146 specificity 0.8874152458357355 recall 0.9282422646477946 f1 0.9288224161492395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 23.631175756454468 s\n",
      "Accuracy 0.9248043303342842 precision 0.9262127096623216 specificity 0.8818861364785824 recall 0.9248043303342842 f1 0.9253747354774048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 23.689082384109497 s\n",
      "Accuracy 0.9271450515690147 precision 0.9288782865062069 specificity 0.8854163703793216 recall 0.9271450515690147 f1 0.9278231850440535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 23.881083965301514 s\n",
      "Accuracy 0.9257552483358935 precision 0.9268094064498363 specificity 0.8788574953956754 recall 0.9257552483358935 f1 0.9262011948414741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 23.483082056045532 s\n",
      "Accuracy 0.9271450515690147 precision 0.9278889965942232 specificity 0.8783864386122029 recall 0.9271450515690147 f1 0.9274718670512797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 23.68759322166443 s\n",
      "Accuracy 0.9284617072635506 precision 0.9299306190637288 specificity 0.8891953566991686 recall 0.9284617072635506 f1 0.9290423901126424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 23.53650689125061 s\n",
      "Accuracy 0.9293394777265745 precision 0.9312253985214433 specificity 0.8949029006531953 recall 0.9293394777265745 f1 0.9300457987366662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 24.456713438034058 s\n",
      "Accuracy 0.9304366908053544 precision 0.9321898728906571 specificity 0.8949914093540231 recall 0.9304366908053544 f1 0.9311011831342937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 24.10311198234558 s\n",
      "Accuracy 0.9275839368005266 precision 0.9291697787142232 specificity 0.8918921906668567 recall 0.9275839368005266 f1 0.9281972218560443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 23.616085052490234 s\n",
      "Accuracy 0.9271450515690147 precision 0.9291335906501837 specificity 0.8896394412746542 recall 0.9271450515690147 f1 0.9278972143968893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 23.490581035614014 s\n",
      "Accuracy 0.9275107892619413 precision 0.9282630277788131 specificity 0.8813862921396385 recall 0.9275107892619413 f1 0.9278388559237883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 23.849802494049072 s\n",
      "Accuracy 0.9264135761831614 precision 0.9274728187229359 specificity 0.8818971603177359 recall 0.9264135761831614 f1 0.9268581633821537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 23.862085819244385 s\n",
      "Accuracy 0.9308755760368663 precision 0.9319673476805193 specificity 0.8894414265779512 recall 0.9308755760368663 f1 0.9313246365496268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 23.586081743240356 s\n",
      "Accuracy 0.9273644941847707 precision 0.9284522884464349 specificity 0.8850318947635806 recall 0.9273644941847707 f1 0.9278161308103487\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 23.758081674575806 s\n",
      "Accuracy 0.9230487894082364 precision 0.9247666643049585 specificity 0.8795445579536519 recall 0.9230487894082364 f1 0.9237307518109602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 24.32608413696289 s\n",
      "Accuracy 0.927876526954868 precision 0.9290241289951103 specificity 0.8887588856074835 recall 0.927876526954868 f1 0.9283447563083344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 23.95456314086914 s\n",
      "Accuracy 0.9304366908053544 precision 0.9320355071773203 specificity 0.8932282475155424 recall 0.9304366908053544 f1 0.9310545726455054\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 23.514082193374634 s\n",
      "Accuracy 0.9291931826494039 precision 0.9302648393683978 specificity 0.8886689520201899 recall 0.9291931826494039 f1 0.9296350293527128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 23.807008266448975 s\n",
      "Accuracy 0.9273644941847707 precision 0.9294527866838931 specificity 0.890054596676484 recall 0.9273644941847707 f1 0.9281482550344016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 23.86111068725586 s\n",
      "Accuracy 0.9321190841928169 precision 0.9335667079377448 specificity 0.8951523865998884 recall 0.9321190841928169 f1 0.9326834693782284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 24.67216992378235 s\n",
      "Accuracy 0.9328505595786701 precision 0.9339865316495789 specificity 0.8938464751992891 recall 0.9328505595786701 f1 0.9333101484750441\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 24.63808536529541 s\n",
      "Accuracy 0.9239265598712604 precision 0.9250425747080274 specificity 0.875208211146544 recall 0.9239265598712604 f1 0.9243992051111062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 23.894594430923462 s\n",
      "Accuracy 0.9281691171092092 precision 0.9297723191322436 specificity 0.8888154320910937 recall 0.9281691171092092 f1 0.9287962754131887\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 24.3718101978302 s\n",
      "Accuracy 0.9229756418696511 precision 0.9245856028548731 specificity 0.8800962256888671 recall 0.9229756418696511 f1 0.9236188438735699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 24.69167733192444 s\n",
      "Accuracy 0.9273644941847707 precision 0.9286472757981402 specificity 0.8848536119109719 recall 0.9273644941847707 f1 0.9278869892674748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 23.866085052490234 s\n",
      "Accuracy 0.9247311827956989 precision 0.9256869107608146 specificity 0.8785513076629508 recall 0.9247311827956989 f1 0.9251396992207926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 23.46508264541626 s\n",
      "Accuracy 0.9297052154195011 precision 0.9309761774084201 specificity 0.8908602244439247 recall 0.9297052154195011 f1 0.9302150414414885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 23.47808051109314 s\n",
      "Accuracy 0.9241460024870163 precision 0.9256398299185636 specificity 0.8784593150113758 recall 0.9241460024870163 f1 0.9247523977978848\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 23.83108353614807 s\n",
      "Accuracy 0.9291200351108185 precision 0.9303097641144611 specificity 0.885996542187775 recall 0.9291200351108185 f1 0.9296084446434755\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 23.963083744049072 s\n",
      "Accuracy 0.9294126252651598 precision 0.9310142197676968 specificity 0.8921301598971132 recall 0.9294126252651598 f1 0.9300328806038726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 23.204060792922974 s\n",
      "Accuracy 0.9280959695706239 precision 0.9294316925466526 specificity 0.8884786993891588 recall 0.9280959695706239 f1 0.9286314746403244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 23.358548402786255 s\n",
      "Accuracy 0.9269256089532587 precision 0.9284572246772753 specificity 0.8850040275048632 recall 0.9269256089532587 f1 0.9275351321645176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 23.480141401290894 s\n",
      "Accuracy 0.9285348548021359 precision 0.9290757080087858 specificity 0.8806997761057419 recall 0.9285348548021359 f1 0.9287782818340363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 24.17503595352173 s\n",
      "Accuracy 0.9269256089532587 precision 0.9287678418896673 specificity 0.8875201152717167 recall 0.9269256089532587 f1 0.9276350270151559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 24.258035898208618 s\n",
      "Accuracy 0.924511740179943 precision 0.9265757224267863 specificity 0.8838415272650872 recall 0.924511740179943 f1 0.9253018723900776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 24.275817155838013 s\n",
      "Accuracy 0.9321922317314022 precision 0.9330803686804033 specificity 0.8886872576044299 recall 0.9321922317314022 f1 0.9325676898494514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 23.261034965515137 s\n",
      "Accuracy 0.926779313876088 precision 0.929417547323945 specificity 0.8947746444878569 recall 0.926779313876088 f1 0.9277178193788511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 23.522037506103516 s\n",
      "Accuracy 0.927657084339112 precision 0.9284773606448776 specificity 0.8810631555907745 recall 0.927657084339112 f1 0.9280120784535061\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 23.62303376197815 s\n",
      "Accuracy 0.9249506254114549 precision 0.9268191219310378 specificity 0.8850992426303663 recall 0.9249506254114549 f1 0.9256726771529195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 23.367029428482056 s\n",
      "Accuracy 0.9275839368005266 precision 0.9294635745687242 specificity 0.8910025508513626 recall 0.9275839368005266 f1 0.9282970573944304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 23.668340921401978 s\n",
      "Accuracy 0.9251700680272109 precision 0.9269029475515966 specificity 0.8870655022638472 recall 0.9251700680272109 f1 0.9258417593038282\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 23.70254874229431 s\n",
      "Accuracy 0.9292663301879892 precision 0.9308261596416751 specificity 0.8914011009246019 recall 0.9292663301879892 f1 0.9298740523007727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 23.403034925460815 s\n",
      "Accuracy 0.9267061663375027 precision 0.9280358975761014 specificity 0.8836674114107061 recall 0.9267061663375027 f1 0.9272469271198893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 24.14103603363037 s\n",
      "Accuracy 0.9302903957281837 precision 0.9308118569745645 specificity 0.8787085690072041 recall 0.9302903957281837 f1 0.9305267775547647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 24.028038024902344 s\n",
      "Accuracy 0.9220978714066271 precision 0.9238206326187415 specificity 0.8776788022140034 recall 0.9220978714066271 f1 0.9227846567267797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 23.54654335975647 s\n",
      "Accuracy 0.9308755760368663 precision 0.9319240028044465 specificity 0.8892194402867507 recall 0.9308755760368663 f1 0.9313091814460445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 23.603437185287476 s\n",
      "Accuracy 0.9250237729500402 precision 0.9260933984480078 specificity 0.8808665872341208 recall 0.9250237729500402 f1 0.9254727919882992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 23.44454526901245 s\n",
      "Accuracy 0.9262672811059908 precision 0.9277537076802166 specificity 0.8831845612924016 recall 0.9262672811059908 f1 0.9268640258353908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 23.946036100387573 s\n",
      "Accuracy 0.9300709531124277 precision 0.931636437389956 specificity 0.8897046970264582 recall 0.9300709531124277 f1 0.9306852169451526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 23.56203532218933 s\n",
      "Accuracy 0.9254626581815522 precision 0.9267591461830275 specificity 0.8788382937707987 recall 0.9254626581815522 f1 0.925998215041992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 23.516034841537476 s\n",
      "Accuracy 0.9284617072635506 precision 0.9292465616571247 specificity 0.8820207284704514 recall 0.9284617072635506 f1 0.9288023467438616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 24.076141357421875 s\n",
      "Accuracy 0.9262672811059908 precision 0.9274384456532226 specificity 0.8804785604183386 recall 0.9262672811059908 f1 0.9267550562416532\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 23.735034942626953 s\n",
      "Accuracy 0.924292297564187 precision 0.9252258320132483 specificity 0.87600812832939 recall 0.924292297564187 f1 0.9246945751118238\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 24.15303945541382 s\n",
      "Accuracy 0.9275839368005266 precision 0.9282067084911547 specificity 0.88097799690925 recall 0.9275839368005266 f1 0.927860592957993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 23.873034715652466 s\n",
      "Accuracy 0.9340940677346208 precision 0.9354470412124645 specificity 0.8958377936145555 recall 0.9340940677346208 f1 0.9346266662395163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 23.5770366191864 s\n",
      "Accuracy 0.9273644941847707 precision 0.9286208902687723 specificity 0.8832616951617149 recall 0.9273644941847707 f1 0.9278800135277105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 23.430036544799805 s\n",
      "Accuracy 0.9320459366542316 precision 0.9332962161664229 specificity 0.8910852925816488 recall 0.9320459366542316 f1 0.9325498669835565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 23.26954460144043 s\n",
      "Accuracy 0.9270719040304294 precision 0.9286944741919554 specificity 0.8902467713655448 recall 0.9270719040304294 f1 0.9277009432767259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 23.31703519821167 s\n",
      "Accuracy 0.9286080023407213 precision 0.9300507765696524 specificity 0.8893444816072225 recall 0.9286080023407213 f1 0.929179508197724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 23.943578243255615 s\n",
      "Accuracy 0.9272913466461854 precision 0.9295776909359834 specificity 0.890097804240249 recall 0.9272913466461854 f1 0.928138741789456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 23.60210084915161 s\n",
      "Accuracy 0.9306561334211104 precision 0.9314990514922414 specificity 0.8886698283383633 recall 0.9306561334211104 f1 0.9310139572104966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 23.973033666610718 s\n",
      "Accuracy 0.9294126252651598 precision 0.9304970277790747 specificity 0.8869996839399074 recall 0.9294126252651598 f1 0.9298615265964599\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 23.620035409927368 s\n",
      "Accuracy 0.9291931826494039 precision 0.9313785751942214 specificity 0.8946559916295699 recall 0.9291931826494039 f1 0.9299960466832016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 23.852036476135254 s\n",
      "Accuracy 0.9289737400336479 precision 0.9302338517797893 specificity 0.8893553053228008 recall 0.9289737400336479 f1 0.9294818129246118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 23.852035522460938 s\n",
      "Accuracy 0.9259015434130642 precision 0.9279402582802935 specificity 0.8894240648338912 recall 0.9259015434130642 f1 0.9266687679994495\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 23.43903613090515 s\n",
      "Accuracy 0.9255358057201375 precision 0.9269237149690831 specificity 0.882190352822931 recall 0.9255358057201375 f1 0.9260989622348348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 23.532033920288086 s\n",
      "Accuracy 0.9253895106429668 precision 0.9272343583736826 specificity 0.8852736258330104 recall 0.9253895106429668 f1 0.9261037259617823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 23.966546535491943 s\n",
      "Accuracy 0.9275839368005266 precision 0.9294451285403346 specificity 0.8892594785967246 recall 0.9275839368005266 f1 0.9282958640932514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 23.69360589981079 s\n",
      "Accuracy 0.9300709531124277 precision 0.9318307319701062 specificity 0.8923919255345684 recall 0.9300709531124277 f1 0.93074413794292\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 24.310075283050537 s\n",
      "Accuracy 0.9271450515690147 precision 0.9279734473289192 specificity 0.8809518860640986 recall 0.9271450515690147 f1 0.9275031400311877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 23.67003583908081 s\n",
      "Accuracy 0.9280959695706239 precision 0.929212100047392 specificity 0.8852676806392162 recall 0.9280959695706239 f1 0.9285580765867688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 24.671069622039795 s\n",
      "Accuracy 0.9277302318776973 precision 0.9291221226369366 specificity 0.8854673395117784 recall 0.9277302318776973 f1 0.9282906708487405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 24.24103593826294 s\n",
      "Accuracy 0.926998756491844 precision 0.9282133740265919 specificity 0.8815101129936412 recall 0.926998756491844 f1 0.9275014522866752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 24.08855152130127 s\n",
      "Accuracy 0.9289737400336479 precision 0.9300040548967976 specificity 0.8872619537708358 recall 0.9289737400336479 f1 0.9294022364088346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 23.875035285949707 s\n",
      "Accuracy 0.9254626581815522 precision 0.9270859427146276 specificity 0.8845627393449497 recall 0.9254626581815522 f1 0.9261033740465762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 23.864603519439697 s\n",
      "Accuracy 0.9261941335674054 precision 0.9284187655875951 specificity 0.8895549566424265 recall 0.9261941335674054 f1 0.9270215950490472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 23.63907527923584 s\n",
      "Accuracy 0.9277302318776973 precision 0.9297451936468833 specificity 0.8915822921284481 recall 0.9277302318776973 f1 0.9284860026215812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 23.571035623550415 s\n",
      "Accuracy 0.9338746251188648 precision 0.9349442327434024 specificity 0.8927845483673083 recall 0.9338746251188648 f1 0.9343127030961709\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 23.670035123825073 s\n",
      "Accuracy 0.9298515104966718 precision 0.9311707164573239 specificity 0.8895017663999962 recall 0.9298515104966718 f1 0.9303808039924986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 23.591038465499878 s\n",
      "Accuracy 0.9239265598712604 precision 0.9263557938857523 specificity 0.8884465968463586 recall 0.9239265598712604 f1 0.9248189483008366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 23.2170352935791 s\n",
      "Accuracy 0.9241460024870163 precision 0.9257220989563836 specificity 0.8815189529719925 recall 0.9241460024870163 f1 0.9247755583107538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 23.937084436416626 s\n",
      "Accuracy 0.9265598712603321 precision 0.9280342251438385 specificity 0.8856929377936799 recall 0.9265598712603321 f1 0.927147772777167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 23.219035625457764 s\n",
      "Accuracy 0.9255358057201375 precision 0.9264458757542702 specificity 0.8781551485732264 recall 0.9255358057201375 f1 0.9259274622567428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 23.705034732818604 s\n",
      "Accuracy 0.9289737400336479 precision 0.9305103360072932 specificity 0.8895418999701931 recall 0.9289737400336479 f1 0.9295774106410795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 23.648035764694214 s\n",
      "Accuracy 0.9289005924950625 precision 0.9296911997243147 specificity 0.8862140054237126 recall 0.9289005924950625 f1 0.9292401066288845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 23.653545141220093 s\n",
      "Accuracy 0.9270719040304294 precision 0.9285961605121245 specificity 0.8870393935039207 recall 0.9270719040304294 f1 0.9276748088779552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 23.738651037216187 s\n",
      "Accuracy 0.9305098383439397 precision 0.9312939241227933 specificity 0.8859674681032178 recall 0.9305098383439397 f1 0.9308475809859899\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 23.268049240112305 s\n",
      "Accuracy 0.9283885597249653 precision 0.9298283127787038 specificity 0.8870631564057585 recall 0.9283885597249653 f1 0.9289633347890349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 23.459569454193115 s\n",
      "Accuracy 0.9318264940384756 precision 0.9329947081648824 specificity 0.8889854154902819 recall 0.9318264940384756 f1 0.9323043361402281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 23.42803645133972 s\n",
      "Accuracy 0.9240728549484309 precision 0.9256863285033 specificity 0.8831078513557986 recall 0.9240728549484309 f1 0.9247119487152266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 23.364032983779907 s\n",
      "Accuracy 0.9256821007973082 precision 0.9262806860223147 specificity 0.8743895292073891 recall 0.9256821007973082 f1 0.9259518457542694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 24.535549640655518 s\n",
      "Accuracy 0.9288274449564772 precision 0.9304417182689045 specificity 0.8881193742945653 recall 0.9288274449564772 f1 0.9294606178328911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 23.925036668777466 s\n",
      "Accuracy 0.9309487235754517 precision 0.9323432425116015 specificity 0.8927637601433948 recall 0.9309487235754517 f1 0.9314988758274251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 24.166162252426147 s\n",
      "Accuracy 0.9305829858825251 precision 0.9320711271935364 specificity 0.8963320048815177 recall 0.9305829858825251 f1 0.9311565141379299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 24.020036458969116 s\n",
      "Accuracy 0.9258283958744788 precision 0.9272015624659755 specificity 0.8817421531328621 recall 0.9258283958744788 f1 0.9263872758248783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 24.211036205291748 s\n",
      "Accuracy 0.9250969204886256 precision 0.926280524062835 specificity 0.8785620973988386 recall 0.9250969204886256 f1 0.9255912230957355\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 24.044037580490112 s\n",
      "Accuracy 0.9279496744934533 precision 0.9296201073158025 specificity 0.8886520284393753 recall 0.9279496744934533 f1 0.9285997656429577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 24.11903405189514 s\n",
      "Accuracy 0.930144100651013 precision 0.9310781740262293 specificity 0.8868633081164108 recall 0.930144100651013 f1 0.9305379136902191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 23.333035469055176 s\n",
      "Accuracy 0.927876526954868 precision 0.9301833939765425 specificity 0.8922838860993948 recall 0.927876526954868 f1 0.9287238784371412\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 24.03103542327881 s\n",
      "Accuracy 0.9273644941847707 precision 0.9288804605046941 specificity 0.8847648561790724 recall 0.9273644941847707 f1 0.9279694338131256\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 24.25403642654419 s\n",
      "Accuracy 0.9242191500256016 precision 0.925679774592031 specificity 0.8781000589586387 recall 0.9242191500256016 f1 0.9248143698022094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 23.757566213607788 s\n",
      "Accuracy 0.9280228220320387 precision 0.9288512189217302 specificity 0.8816315285983214 recall 0.9280228220320387 f1 0.928380608167226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 23.63203740119934 s\n",
      "Accuracy 0.9280959695706239 precision 0.9295113999301501 specificity 0.8851318860718317 recall 0.9280959695706239 f1 0.9286655864393591\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 24.208589792251587 s\n",
      "Accuracy 0.9262672811059908 precision 0.9273027217697192 specificity 0.8798638312008287 recall 0.9262672811059908 f1 0.9267052645097396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 24.21498155593872 s\n",
      "Accuracy 0.9281691171092092 precision 0.9289851339107607 specificity 0.8830297231909524 recall 0.9281691171092092 f1 0.9285209634666061\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 24.023547649383545 s\n",
      "Accuracy 0.9267061663375027 precision 0.9277684707741786 specificity 0.8799362200603351 recall 0.9267061663375027 f1 0.9271543506800141\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 23.981632709503174 s\n",
      "Accuracy 0.9277302318776973 precision 0.9290437958350163 specificity 0.8839502202275153 recall 0.9277302318776973 f1 0.9282654533715016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 23.672545433044434 s\n",
      "Accuracy 0.9269256089532587 precision 0.9288412507833238 specificity 0.8894186031115507 recall 0.9269256089532587 f1 0.927654155359932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 23.675058603286743 s\n",
      "Accuracy 0.9281691171092092 precision 0.92980814932686 specificity 0.8911138767462646 recall 0.9281691171092092 f1 0.9288029151146395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 23.195035457611084 s\n",
      "Accuracy 0.9279496744934533 precision 0.9295943032446681 specificity 0.8885730653279411 recall 0.9279496744934533 f1 0.9285912176511714\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 24.63654923439026 s\n",
      "Accuracy 0.9232682320239924 precision 0.9242310865710451 specificity 0.8746018453860552 recall 0.9232682320239924 f1 0.9236828034157327\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 24.489542961120605 s\n",
      "Accuracy 0.9294126252651598 precision 0.9311635261701889 specificity 0.8928327198929755 recall 0.9294126252651598 f1 0.9300808390494313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 23.923548221588135 s\n",
      "Accuracy 0.9262672811059908 precision 0.9274810759891974 specificity 0.8809571466165589 recall 0.9262672811059908 f1 0.9267700497658077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 24.267036199569702 s\n",
      "Accuracy 0.9246580352571137 precision 0.9262513611599222 specificity 0.8847164188998733 recall 0.9246580352571137 f1 0.9252872607482723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 24.60355019569397 s\n",
      "Accuracy 0.9286080023407213 precision 0.9306254974504432 specificity 0.8898317144050722 recall 0.9286080023407213 f1 0.9293712283350186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 23.994776248931885 s\n",
      "Accuracy 0.9263404286445761 precision 0.9280429491276161 specificity 0.8840864695867334 recall 0.9263404286445761 f1 0.927010294215013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 24.021027326583862 s\n",
      "Accuracy 0.9255358057201375 precision 0.9265717848559822 specificity 0.8811864856249102 recall 0.9255358057201375 f1 0.9259721340401481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 24.418829441070557 s\n",
      "Accuracy 0.9246580352571137 precision 0.9262898385234298 specificity 0.8811451899019477 recall 0.9246580352571137 f1 0.9253082397041704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 23.639139652252197 s\n",
      "Accuracy 0.9273644941847707 precision 0.928124776795137 specificity 0.8778875712113966 recall 0.9273644941847707 f1 0.9276981982750617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 24.55601453781128 s\n",
      "Accuracy 0.9258283958744788 precision 0.9268467921796557 specificity 0.8809625395141988 recall 0.9258283958744788 f1 0.9262585310061753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 24.161014318466187 s\n",
      "Accuracy 0.9265598712603321 precision 0.9285786305627377 specificity 0.889043479833171 recall 0.9265598712603321 f1 0.9273228140263652\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 24.402527809143066 s\n",
      "Accuracy 0.9288274449564772 precision 0.9306186495424864 specificity 0.8929837342873215 recall 0.9288274449564772 f1 0.9295077079434043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 24.032147645950317 s\n",
      "Accuracy 0.9277302318776973 precision 0.9299650603570953 specificity 0.8913042251182527 recall 0.9277302318776973 f1 0.9285577699334517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 23.682013988494873 s\n",
      "Accuracy 0.9298515104966718 precision 0.9317651060449107 specificity 0.8936127076497594 recall 0.9298515104966718 f1 0.9305715020122803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 23.646958827972412 s\n",
      "Accuracy 0.9291931826494039 precision 0.9313756335183063 specificity 0.893599767536948 recall 0.9291931826494039 f1 0.9299987627561377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 23.520015001296997 s\n",
      "Accuracy 0.926779313876088 precision 0.9282634058141348 specificity 0.8845565423206952 recall 0.926779313876088 f1 0.9273730383252256\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 23.83401346206665 s\n",
      "Accuracy 0.9247311827956989 precision 0.9266025265000798 specificity 0.8798239645677792 recall 0.9247311827956989 f1 0.9254670404254318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 23.65052366256714 s\n",
      "Accuracy 0.927437641723356 precision 0.9284966307839281 specificity 0.8846249253790057 recall 0.927437641723356 f1 0.9278792548853677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 23.89397668838501 s\n",
      "Accuracy 0.9268524614146734 precision 0.928021699644941 specificity 0.8811109099666145 recall 0.9268524614146734 f1 0.9273389871217803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 23.935595512390137 s\n",
      "Accuracy 0.9286080023407213 precision 0.930024935029923 specificity 0.886289253296595 recall 0.9286080023407213 f1 0.9291764314033134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 23.613014221191406 s\n",
      "Accuracy 0.9275107892619413 precision 0.9284178318298272 specificity 0.8851931677341687 recall 0.9275107892619413 f1 0.9278950922719938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 23.83701467514038 s\n",
      "Accuracy 0.9284617072635506 precision 0.9295831416964061 specificity 0.8860626044633243 recall 0.9284617072635506 f1 0.9289248611292407\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 23.864015340805054 s\n",
      "Accuracy 0.9284617072635506 precision 0.9300593466661589 specificity 0.8921165389458584 recall 0.9284617072635506 f1 0.929079512401993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 23.821014642715454 s\n",
      "Accuracy 0.927437641723356 precision 0.9291215271227442 specificity 0.8881906613355893 recall 0.927437641723356 f1 0.9280927997455606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 23.763011932373047 s\n",
      "Accuracy 0.9302172481895984 precision 0.9315639102483737 specificity 0.8904524443179473 recall 0.9302172481895984 f1 0.9307546964248249\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 23.962036848068237 s\n",
      "Accuracy 0.9261209860288201 precision 0.9277310460792236 specificity 0.8821392164361863 recall 0.9261209860288201 f1 0.9267628818029088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 23.328668117523193 s\n",
      "Accuracy 0.924511740179943 precision 0.9259733325252149 specificity 0.8799481693508632 recall 0.924511740179943 f1 0.9251042840535519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 23.946014165878296 s\n",
      "Accuracy 0.9265598712603321 precision 0.9274662722212397 specificity 0.8814543310561881 recall 0.9265598712603321 f1 0.9269473586868383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 23.38801383972168 s\n",
      "Accuracy 0.9272181991076001 precision 0.9280519423593308 specificity 0.879301849602035 recall 0.9272181991076001 f1 0.9275797560239799\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 23.713013887405396 s\n",
      "Accuracy 0.926998756491844 precision 0.9286422672062281 specificity 0.8884461319871262 recall 0.926998756491844 f1 0.9276391402904439\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 23.464014291763306 s\n",
      "Accuracy 0.9287542974178918 precision 0.9305454687911255 specificity 0.8922789539437219 recall 0.9287542974178918 f1 0.9294364041341286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 23.70201301574707 s\n",
      "Accuracy 0.9269256089532587 precision 0.9284445325102104 specificity 0.8872029917167729 recall 0.9269256089532587 f1 0.9275261842457602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 23.712015390396118 s\n",
      "Accuracy 0.9261941335674054 precision 0.9280297373790815 specificity 0.8857873736425482 recall 0.9261941335674054 f1 0.9269049122571894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 23.09853219985962 s\n",
      "Accuracy 0.924292297564187 precision 0.925586999003586 specificity 0.883063709290012 recall 0.924292297564187 f1 0.9248197508068735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 24.132606029510498 s\n",
      "Accuracy 0.9261209860288201 precision 0.9275231442867019 specificity 0.883419854975077 recall 0.9261209860288201 f1 0.9266874771037579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 24.047083377838135 s\n",
      "Accuracy 0.9260478384902348 precision 0.9274616176821455 specificity 0.8834346495837998 recall 0.9260478384902348 f1 0.9266183547013347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 24.86954116821289 s\n",
      "Accuracy 0.9285348548021359 precision 0.9301121908388265 specificity 0.8911932935041703 recall 0.9285348548021359 f1 0.9291481443595561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 24.612569570541382 s\n",
      "Accuracy 0.9261209860288201 precision 0.9276443643606881 specificity 0.8839939001074077 recall 0.9261209860288201 f1 0.9267289549552027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 23.5140540599823 s\n",
      "Accuracy 0.9283154121863799 precision 0.9293243705854433 specificity 0.8817881901327913 recall 0.9283154121863799 f1 0.9287421352916451\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 23.325015783309937 s\n",
      "Accuracy 0.9280959695706239 precision 0.9297077702660703 specificity 0.8890035188025968 recall 0.9280959695706239 f1 0.9287255391483671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 23.844013690948486 s\n",
      "Accuracy 0.9303635432667691 precision 0.9309564192368681 specificity 0.8844135621452418 recall 0.9303635432667691 f1 0.9306267369058467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 23.825035333633423 s\n",
      "Accuracy 0.9279496744934533 precision 0.9291768921975895 specificity 0.887438093564954 recall 0.9279496744934533 f1 0.9284485299330937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 23.863014221191406 s\n",
      "Accuracy 0.9260478384902348 precision 0.9281400437294355 specificity 0.888599132570574 recall 0.9260478384902348 f1 0.9268353081140193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 23.720014810562134 s\n",
      "Accuracy 0.9251700680272109 precision 0.9265269977213045 specificity 0.8813975759390686 recall 0.9251700680272109 f1 0.9257232506016493\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 23.8250150680542 s\n",
      "Accuracy 0.9260478384902348 precision 0.9276869723748971 specificity 0.8871036069159589 recall 0.9260478384902348 f1 0.9266888156781387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 23.83737015724182 s\n",
      "Accuracy 0.9302903957281837 precision 0.9323536784657712 specificity 0.8951934038965056 recall 0.9302903957281837 f1 0.9310544848617087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 23.615013599395752 s\n",
      "Accuracy 0.9275839368005266 precision 0.9277134700818569 specificity 0.8714996558073108 recall 0.9275839368005266 f1 0.9276470413904842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 23.703014373779297 s\n",
      "Accuracy 0.9270719040304294 precision 0.9282076792170915 specificity 0.882922107511451 recall 0.9270719040304294 f1 0.927543819637109\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 23.65252423286438 s\n",
      "Accuracy 0.9260478384902348 precision 0.9275529112634397 specificity 0.8826711018611373 recall 0.9260478384902348 f1 0.9266519261171187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 23.82401442527771 s\n",
      "Accuracy 0.9260478384902348 precision 0.927846276712354 specificity 0.8874156818081459 recall 0.9260478384902348 f1 0.926741759809595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 24.022014141082764 s\n",
      "Accuracy 0.9250969204886256 precision 0.9262047095292084 specificity 0.8825148519463718 recall 0.9250969204886256 f1 0.9255579750764991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 24.78968071937561 s\n",
      "Accuracy 0.9295589203423305 precision 0.9309880278814208 specificity 0.8871853617338264 recall 0.9295589203423305 f1 0.930130695436522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 24.593528270721436 s\n",
      "Accuracy 0.9251700680272109 precision 0.9263053724100101 specificity 0.8795364512554364 recall 0.9251700680272109 f1 0.9256452505982395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 23.991012573242188 s\n",
      "Accuracy 0.9259015434130642 precision 0.9279823019833565 specificity 0.8889234217388133 recall 0.9259015434130642 f1 0.9266840259893024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 24.55909252166748 s\n",
      "Accuracy 0.9262672811059908 precision 0.9279039034705919 specificity 0.8823273753851155 recall 0.9262672811059908 f1 0.9269181524262936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 24.125635147094727 s\n",
      "Accuracy 0.9259015434130642 precision 0.9272319191225237 specificity 0.8786302134029259 recall 0.9259015434130642 f1 0.9264499929846521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 24.452016353607178 s\n",
      "Accuracy 0.9248774778728696 precision 0.9272364175527346 specificity 0.8879110267119505 recall 0.9248774778728696 f1 0.925751333594398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 25.200525760650635 s\n",
      "Accuracy 0.9282422646477946 precision 0.9291863588313338 specificity 0.8863816711690825 recall 0.9282422646477946 f1 0.9286395047696078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 25.289530992507935 s\n",
      "Accuracy 0.9262672811059908 precision 0.9276697520847553 specificity 0.8802170338788342 recall 0.9262672811059908 f1 0.9268394861216013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 24.906514644622803 s\n",
      "Accuracy 0.9262672811059908 precision 0.9282288701994463 specificity 0.8860904145025382 recall 0.9262672811059908 f1 0.9270194667977365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 24.272013902664185 s\n",
      "Accuracy 0.9280228220320387 precision 0.9297357303196385 specificity 0.8900275869187079 recall 0.9280228220320387 f1 0.9286839107499356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 25.217986822128296 s\n",
      "Accuracy 0.9282422646477946 precision 0.9296168439357775 specificity 0.8845762959521812 recall 0.9282422646477946 f1 0.9287985277346098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 24.889044523239136 s\n",
      "Accuracy 0.927876526954868 precision 0.9287489326734165 specificity 0.8814960893554511 recall 0.927876526954868 f1 0.9282513981667572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 24.352532863616943 s\n",
      "Accuracy 0.9265598712603321 precision 0.9286617237142607 specificity 0.8905370374781559 recall 0.9265598712603321 f1 0.9273451304995486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 23.8750479221344 s\n",
      "Accuracy 0.9266330187989175 precision 0.927994380988796 specificity 0.8856099080199387 recall 0.9266330187989175 f1 0.9271815622013952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 24.830525398254395 s\n",
      "Accuracy 0.9262672811059908 precision 0.9279100776732775 specificity 0.8835046378195069 recall 0.9262672811059908 f1 0.9269178137903841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 24.563599109649658 s\n",
      "Accuracy 0.9264867237217468 precision 0.9277734210637624 specificity 0.8803937501594845 recall 0.9264867237217468 f1 0.9270170053562982\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 24.12452793121338 s\n",
      "Accuracy 0.9270719040304294 precision 0.9281733812376002 specificity 0.8818806921050774 recall 0.9270719040304294 f1 0.927532522045822\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 24.190524101257324 s\n",
      "Accuracy 0.9286811498793066 precision 0.9299383547135707 specificity 0.8892881328631657 recall 0.9286811498793066 f1 0.929188081815358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 24.599609851837158 s\n",
      "Accuracy 0.9256089532587228 precision 0.9273601040404533 specificity 0.886586607696583 recall 0.9256089532587228 f1 0.9262885657740041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 24.966036081314087 s\n",
      "Accuracy 0.9265598712603321 precision 0.9282224723746557 specificity 0.8870680355776012 recall 0.9265598712603321 f1 0.9272094894547304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 24.1060152053833 s\n",
      "Accuracy 0.9268524614146734 precision 0.9278796806782407 specificity 0.88298352546494 recall 0.9268524614146734 f1 0.927284021410898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 24.44301438331604 s\n",
      "Accuracy 0.9258283958744788 precision 0.9274646661427748 specificity 0.8849275961652728 recall 0.9258283958744788 f1 0.9264731403862468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 24.351014614105225 s\n",
      "Accuracy 0.9259015434130642 precision 0.9267795489926655 specificity 0.8782863167654106 recall 0.9259015434130642 f1 0.9262807912323502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 24.747525453567505 s\n",
      "Accuracy 0.9266330187989175 precision 0.9277080911279537 specificity 0.8836066830798174 recall 0.9266330187989175 f1 0.9270814439478579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 25.006678581237793 s\n",
      "Accuracy 0.9260478384902348 precision 0.928412305408866 specificity 0.8900571836111436 recall 0.9260478384902348 f1 0.9269179961173861\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 23.88001251220703 s\n",
      "Accuracy 0.9297052154195011 precision 0.9309819161623846 specificity 0.8872832064863859 recall 0.9297052154195011 f1 0.9302231822618022\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 24.02701425552368 s\n",
      "Accuracy 0.9282422646477946 precision 0.9289475616571297 specificity 0.8773884188873321 recall 0.9282422646477946 f1 0.9285544526348861\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 24.276836395263672 s\n",
      "Accuracy 0.9242191500256016 precision 0.9259699870093666 specificity 0.8803531736737069 recall 0.9242191500256016 f1 0.9249118735679196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 24.19109797477722 s\n",
      "Accuracy 0.9262672811059908 precision 0.9281161234079214 specificity 0.8872562701908248 recall 0.9262672811059908 f1 0.9269787542878155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 24.548015356063843 s\n",
      "Accuracy 0.9291200351108185 precision 0.930628451875682 specificity 0.8882995606090086 recall 0.9291200351108185 f1 0.9297167966669683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 24.94452929496765 s\n",
      "Accuracy 0.9254626581815522 precision 0.9273858732728448 specificity 0.8863898837480162 recall 0.9254626581815522 f1 0.9262001737292518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 25.0055570602417 s\n",
      "Accuracy 0.9246580352571137 precision 0.9264024436093032 specificity 0.8853553234962688 recall 0.9246580352571137 f1 0.9253372757004222\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 24.344014644622803 s\n",
      "Accuracy 0.9286080023407213 precision 0.9299811392765317 specificity 0.8858058148157256 recall 0.9286080023407213 f1 0.9291618847082389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 23.98401403427124 s\n",
      "Accuracy 0.9279496744934533 precision 0.9292885899771071 specificity 0.8865887925742968 recall 0.9279496744934533 f1 0.9284895991384154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 25.061014652252197 s\n",
      "Accuracy 0.9275107892619413 precision 0.9288479181287893 specificity 0.8847056381434744 recall 0.9275107892619413 f1 0.9280530128801332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 24.60201644897461 s\n",
      "Accuracy 0.9283154121863799 precision 0.9298386551530922 specificity 0.8889489990231453 recall 0.9283154121863799 f1 0.9289151331005551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 24.539177417755127 s\n",
      "Accuracy 0.927876526954868 precision 0.9297314587987272 specificity 0.8898248171199064 recall 0.927876526954868 f1 0.9285852300393235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 24.195534467697144 s\n",
      "Accuracy 0.9270719040304294 precision 0.9282433654788784 specificity 0.8838388283319717 recall 0.9270719040304294 f1 0.9275555972765328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 24.53642702102661 s\n",
      "Accuracy 0.9253163631043816 precision 0.9268029162578788 specificity 0.884635370654239 recall 0.9253163631043816 f1 0.9259094759008037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 23.405073881149292 s\n",
      "Accuracy 0.9308755760368663 precision 0.9325166168139294 specificity 0.8942247522294036 recall 0.9308755760368663 f1 0.9315056345064519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 24.85101628303528 s\n",
      "Accuracy 0.9271450515690147 precision 0.9287187876377838 specificity 0.8835695193412653 recall 0.9271450515690147 f1 0.927772294844621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 24.756524324417114 s\n",
      "Accuracy 0.9272913466461854 precision 0.9286999055744797 specificity 0.8886667153765482 recall 0.9272913466461854 f1 0.9278511302470989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 24.50755500793457 s\n",
      "Accuracy 0.9245848877185283 precision 0.9263135509288072 specificity 0.8825731066050289 recall 0.9245848877185283 f1 0.92526533845471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 23.739014625549316 s\n",
      "Accuracy 0.9239265598712604 precision 0.9256005113806299 specificity 0.8796906839681423 recall 0.9239265598712604 f1 0.924593798392232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 24.12001657485962 s\n",
      "Accuracy 0.9292663301879892 precision 0.9302457968289514 specificity 0.8841313973572128 recall 0.9292663301879892 f1 0.9296797872177123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 24.252012491226196 s\n",
      "Accuracy 0.9249506254114549 precision 0.9261253246960786 specificity 0.8809404684434008 recall 0.9249506254114549 f1 0.9254383405489295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 23.56352472305298 s\n",
      "Accuracy 0.9259015434130642 precision 0.9276841404810983 specificity 0.8853219123680635 recall 0.9259015434130642 f1 0.9265952723279\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 23.68856692314148 s\n",
      "Accuracy 0.9273644941847707 precision 0.9291304891797637 specificity 0.888860476825834 recall 0.9273644941847707 f1 0.9280454992026961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 23.5610454082489 s\n",
      "Accuracy 0.9264135761831614 precision 0.9288911297831434 specificity 0.8915591727588459 recall 0.9264135761831614 f1 0.9273145960830553\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 24.309012174606323 s\n",
      "Accuracy 0.9263404286445761 precision 0.9288115695537975 specificity 0.8888503503702194 recall 0.9263404286445761 f1 0.9272495311389107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 23.666014432907104 s\n",
      "Accuracy 0.9279496744934533 precision 0.9297579310285763 specificity 0.8900763777785703 recall 0.9279496744934533 f1 0.9286423225431749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 23.480014085769653 s\n",
      "Accuracy 0.9248774778728696 precision 0.9264051766219628 specificity 0.8818699802764576 recall 0.9248774778728696 f1 0.925490062666676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 24.503013849258423 s\n",
      "Accuracy 0.9259746909516495 precision 0.927457412900272 specificity 0.8815552240984286 recall 0.9259746909516495 f1 0.9265729330921122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 23.40710186958313 s\n",
      "Accuracy 0.9279496744934533 precision 0.9294881075354569 specificity 0.8885076895601688 recall 0.9279496744934533 f1 0.9285551833106594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 23.77152419090271 s\n",
      "Accuracy 0.9269256089532587 precision 0.9289749842732499 specificity 0.8912025005756228 recall 0.9269256089532587 f1 0.9276923811820498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 24.13401484489441 s\n",
      "Accuracy 0.926779313876088 precision 0.9279876633799984 specificity 0.8844093491156062 recall 0.926779313876088 f1 0.9272753608530138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 23.653013706207275 s\n",
      "Accuracy 0.9273644941847707 precision 0.9286866926466965 specificity 0.885542763936244 recall 0.9273644941847707 f1 0.9278998778217512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 23.692014932632446 s\n",
      "Accuracy 0.9256089532587228 precision 0.927073336888395 specificity 0.8815453720653134 recall 0.9256089532587228 f1 0.9262004485573446\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 23.868014097213745 s\n",
      "Accuracy 0.9247311827956989 precision 0.926776269667048 specificity 0.8855195686588773 recall 0.9247311827956989 f1 0.9255105099534244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 24.118035078048706 s\n",
      "Accuracy 0.9284617072635506 precision 0.9293020649755277 specificity 0.8829729355344453 recall 0.9284617072635506 f1 0.92882310100733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 23.769015073776245 s\n",
      "Accuracy 0.9268524614146734 precision 0.9285485943031946 specificity 0.8870301731589946 recall 0.9268524614146734 f1 0.9275138750102827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 23.429604291915894 s\n",
      "Accuracy 0.9286080023407213 precision 0.9300314578390083 specificity 0.8874581375803949 recall 0.9286080023407213 f1 0.9291765232597918\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 23.762013912200928 s\n",
      "Accuracy 0.9286811498793066 precision 0.9296922378078244 specificity 0.8848636380425371 recall 0.9286811498793066 f1 0.9291053395373599\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 23.75701403617859 s\n",
      "Accuracy 0.9270719040304294 precision 0.928091285284115 specificity 0.8808902428992293 recall 0.9270719040304294 f1 0.9275030349988871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 23.783595085144043 s\n",
      "Accuracy 0.9254626581815522 precision 0.9269609466886102 specificity 0.8825538986566095 recall 0.9254626581815522 f1 0.9260641012531514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 23.878015756607056 s\n",
      "Accuracy 0.9270719040304294 precision 0.9286704786395841 specificity 0.8858951911210778 recall 0.9270719040304294 f1 0.9277028345893286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 23.716012716293335 s\n",
      "Accuracy 0.9278033794162827 precision 0.9295886129073779 specificity 0.888352089349529 recall 0.9278033794162827 f1 0.9284926678532576\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 23.750056266784668 s\n",
      "Accuracy 0.9228293467924804 precision 0.9237927937745523 specificity 0.8763417965421552 recall 0.9228293467924804 f1 0.9232422853929148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 23.998014211654663 s\n",
      "Accuracy 0.9261209860288201 precision 0.9277152511135177 specificity 0.8859901307404529 recall 0.9261209860288201 f1 0.9267492643020859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 23.767536163330078 s\n",
      "Accuracy 0.9229756418696511 precision 0.9242670259709772 specificity 0.8753038616007449 recall 0.9229756418696511 f1 0.9235130333158992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 23.838074445724487 s\n",
      "Accuracy 0.9289005924950625 precision 0.9302968003437212 specificity 0.8862307543846536 recall 0.9289005924950625 f1 0.9294620706857807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 24.069014310836792 s\n",
      "Accuracy 0.9275107892619413 precision 0.9293961367384789 specificity 0.8887459058891611 recall 0.9275107892619413 f1 0.92823202945082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 23.605014324188232 s\n",
      "Accuracy 0.9250237729500402 precision 0.9270798696569492 specificity 0.8853282934676707 recall 0.9250237729500402 f1 0.9258077239017033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 23.796014547348022 s\n",
      "Accuracy 0.927657084339112 precision 0.9289276201068608 specificity 0.8859221626207162 recall 0.927657084339112 f1 0.9281736635770251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 23.71552538871765 s\n",
      "Accuracy 0.9282422646477946 precision 0.9295414877964177 specificity 0.8845075077132928 recall 0.9282422646477946 f1 0.9287717915737732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 23.851548671722412 s\n",
      "Accuracy 0.9250969204886256 precision 0.9272709245248957 specificity 0.8898168199300445 recall 0.9250969204886256 f1 0.9259051761186122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 23.639012098312378 s\n",
      "Accuracy 0.9285348548021359 precision 0.9297251800618309 specificity 0.8854568541921339 recall 0.9285348548021359 f1 0.9290239235790828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 23.40501594543457 s\n",
      "Accuracy 0.9235608221783337 precision 0.9247971149992186 specificity 0.8779586252853703 recall 0.9235608221783337 f1 0.9240745266550016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 24.750542879104614 s\n",
      "Accuracy 0.923853412332675 precision 0.9259517583847864 specificity 0.882373686245763 recall 0.923853412332675 f1 0.9246582490206362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 24.02601671218872 s\n",
      "Accuracy 0.9277302318776973 precision 0.9289575110654685 specificity 0.884744341328866 recall 0.9277302318776973 f1 0.9282332148592043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 23.97403383255005 s\n",
      "Accuracy 0.9250969204886256 precision 0.9275593870870267 specificity 0.8884642270844244 recall 0.9250969204886256 f1 0.926002237714392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 24.339014053344727 s\n",
      "Accuracy 0.9302903957281837 precision 0.9317037094091977 specificity 0.8903296070350362 recall 0.9302903957281837 f1 0.9308512811611414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 24.248621702194214 s\n",
      "Accuracy 0.9305829858825251 precision 0.9319406910184566 specificity 0.8908726176898701 recall 0.9305829858825251 f1 0.9311237937140924\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 23.72801399230957 s\n",
      "Accuracy 0.9286811498793066 precision 0.9304066177868537 specificity 0.8879563481697222 recall 0.9286811498793066 f1 0.9293523036106008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 23.650015592575073 s\n",
      "Accuracy 0.9263404286445761 precision 0.9277214614987161 specificity 0.8856989014893474 recall 0.9263404286445761 f1 0.9268954875623352\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 24.4990131855011 s\n",
      "Accuracy 0.9216589861751152 precision 0.9233877167654093 specificity 0.8769647271803793 recall 0.9216589861751152 f1 0.9223489635555859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 23.962015867233276 s\n",
      "Accuracy 0.9265598712603321 precision 0.9285180174727955 specificity 0.8903622334814085 recall 0.9265598712603321 f1 0.9272990094124521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 25.812015295028687 s\n",
      "Accuracy 0.9340209201960354 precision 0.9358621346310768 specificity 0.9002271866396665 recall 0.9340209201960354 f1 0.9347041079189166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 23.946465253829956 s\n",
      "Accuracy 0.9270719040304294 precision 0.9293672023372711 specificity 0.8913084374182629 recall 0.9270719040304294 f1 0.9279175186938047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 24.12505006790161 s\n",
      "Accuracy 0.9253163631043816 precision 0.9272827249483472 specificity 0.8856284323468547 recall 0.9253163631043816 f1 0.9260701352619658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 24.861525058746338 s\n",
      "Accuracy 0.923853412332675 precision 0.9252498155080849 specificity 0.8793738248708376 recall 0.923853412332675 f1 0.9244231948620968\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 23.316014528274536 s\n",
      "Accuracy 0.9305098383439397 precision 0.9317852379856411 specificity 0.8888951611808202 recall 0.9305098383439397 f1 0.9310252337039978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 23.722522735595703 s\n",
      "Accuracy 0.9283885597249653 precision 0.929938060796315 specificity 0.8868246259623841 recall 0.9283885597249653 f1 0.9290018672454066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 25.543739557266235 s\n",
      "Accuracy 0.9282422646477946 precision 0.9294436171193836 specificity 0.887811406177452 recall 0.9282422646477946 f1 0.9287314944755769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 24.83653688430786 s\n",
      "Accuracy 0.9240728549484309 precision 0.9260712868287094 specificity 0.8874951487614808 recall 0.9240728549484309 f1 0.9248298733863047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 24.742403268814087 s\n",
      "Accuracy 0.9283885597249653 precision 0.9306333531770091 specificity 0.8933559229518264 recall 0.9283885597249653 f1 0.9292133456208381\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 23.857014894485474 s\n",
      "Accuracy 0.9297783629580865 precision 0.9309724142527649 specificity 0.8871152800257984 recall 0.9297783629580865 f1 0.9302670661633606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 24.039016485214233 s\n",
      "Accuracy 0.9302903957281837 precision 0.9317544259262116 specificity 0.8918553114833561 recall 0.9302903957281837 f1 0.9308656114699766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 24.625097036361694 s\n",
      "Accuracy 0.9295589203423305 precision 0.9304881410173554 specificity 0.884822159192287 recall 0.9295589203423305 f1 0.9299528391065113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 24.40802240371704 s\n",
      "Accuracy 0.9261941335674054 precision 0.9272776200629979 specificity 0.8807017236548631 recall 0.9261941335674054 f1 0.9266491006439567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 23.91501545906067 s\n",
      "Accuracy 0.9271450515690147 precision 0.927935969781854 specificity 0.8779425640905804 recall 0.9271450515690147 f1 0.9274908112092534\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 23.303013563156128 s\n",
      "Accuracy 0.9268524614146734 precision 0.9282869590493267 specificity 0.8852398327089841 recall 0.9268524614146734 f1 0.9274275815487334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 24.072014093399048 s\n",
      "Accuracy 0.9317533464998903 precision 0.9326379985498 specificity 0.8886576589027745 recall 0.9317533464998903 f1 0.9321273567683009\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 23.575014352798462 s\n",
      "Accuracy 0.9304366908053544 precision 0.9320963508485149 specificity 0.8928925245539996 recall 0.9304366908053544 f1 0.9310757462926674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 23.951523780822754 s\n",
      "Accuracy 0.9253895106429668 precision 0.9269990938931743 specificity 0.8845050353395222 recall 0.9253895106429668 f1 0.9260255649047257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 23.49867606163025 s\n",
      "Accuracy 0.9256821007973082 precision 0.9274162861856053 specificity 0.8854295491519062 recall 0.9256821007973082 f1 0.9263589185348885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 24.001002311706543 s\n",
      "Accuracy 0.9291931826494039 precision 0.9305164233990642 specificity 0.8894475197047832 recall 0.9291931826494039 f1 0.9297234570857175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 23.672003030776978 s\n",
      "Accuracy 0.9283154121863799 precision 0.9306994477283919 specificity 0.8987606570875909 recall 0.9283154121863799 f1 0.9291623211045369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 23.885002613067627 s\n",
      "Accuracy 0.9291931826494039 precision 0.9300816922814331 specificity 0.8831226362954617 recall 0.9291931826494039 f1 0.9295731732657878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 23.614002227783203 s\n",
      "Accuracy 0.9335088874259381 precision 0.9348214361148118 specificity 0.8947242954016279 recall 0.9335088874259381 f1 0.934029224175091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 23.372002601623535 s\n",
      "Accuracy 0.9244385926413576 precision 0.925684083916561 specificity 0.8798108446914543 recall 0.9244385926413576 f1 0.9249535138852085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 23.531516551971436 s\n",
      "Accuracy 0.9223173140223832 precision 0.9240527412058361 specificity 0.8779515168414809 recall 0.9223173140223832 f1 0.9230081270029212\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 24.813127994537354 s\n",
      "Accuracy 0.9273644941847707 precision 0.9291414130405702 specificity 0.8869680471499287 recall 0.9273644941847707 f1 0.9280539396559732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 24.15057611465454 s\n",
      "Accuracy 0.9284617072635506 precision 0.930354892344989 specificity 0.8949336336650637 recall 0.9284617072635506 f1 0.929168798271619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 23.783520221710205 s\n",
      "Accuracy 0.927437641723356 precision 0.9286141511476234 specificity 0.8863622022433313 recall 0.927437641723356 f1 0.9279196635323987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 23.823002338409424 s\n",
      "Accuracy 0.926779313876088 precision 0.9284182020455986 specificity 0.8849246445558604 recall 0.926779313876088 f1 0.9274259231804465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 24.200002670288086 s\n",
      "Accuracy 0.9284617072635506 precision 0.9304492687073339 specificity 0.8922128976908006 recall 0.9284617072635506 f1 0.9292078132110189\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 23.67251205444336 s\n",
      "Accuracy 0.9275839368005266 precision 0.9289212394676395 specificity 0.8855711955192507 recall 0.9275839368005266 f1 0.928124792163159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 24.44100332260132 s\n",
      "Accuracy 0.9239265598712604 precision 0.926356761554718 specificity 0.8884125621356446 recall 0.9239265598712604 f1 0.9248193850509969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 24.091002464294434 s\n",
      "Accuracy 0.927437641723356 precision 0.929348159289586 specificity 0.892007380154713 recall 0.927437641723356 f1 0.9281576704657215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 23.822004318237305 s\n",
      "Accuracy 0.9298515104966718 precision 0.9317015826955322 specificity 0.8938700731075517 recall 0.9298515104966718 f1 0.9305500377479231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 23.526002883911133 s\n",
      "Accuracy 0.9282422646477946 precision 0.929527716480636 specificity 0.8870729202802917 recall 0.9282422646477946 f1 0.9287626552006278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 24.586602687835693 s\n",
      "Accuracy 0.9307292809596958 precision 0.9316227218461994 specificity 0.889011529290371 recall 0.9307292809596958 f1 0.9311057956368938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 23.32700228691101 s\n",
      "Accuracy 0.9259746909516495 precision 0.9280492436487403 specificity 0.8886346990521915 recall 0.9259746909516495 f1 0.9267561787713933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 23.882002592086792 s\n",
      "Accuracy 0.9292663301879892 precision 0.9307628877018528 specificity 0.8891013172073254 recall 0.9292663301879892 f1 0.929857488758882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 22.5950186252594 s\n",
      "Accuracy 0.9303635432667691 precision 0.9317893728019689 specificity 0.8918983573034501 recall 0.9303635432667691 f1 0.9309256580175308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 21.871001482009888 s\n",
      "Accuracy 0.924511740179943 precision 0.9259180984766939 specificity 0.876715166253472 recall 0.924511740179943 f1 0.9250898872929276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 22.151042938232422 s\n",
      "Accuracy 0.9279496744934533 precision 0.929111482917274 specificity 0.8886479291813404 recall 0.9279496744934533 f1 0.928423218695321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 21.846001148223877 s\n",
      "Accuracy 0.9297052154195011 precision 0.9314374304257164 specificity 0.891353756301716 recall 0.9297052154195011 f1 0.9303714603745104\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 21.478002071380615 s\n",
      "Accuracy 0.9272181991076001 precision 0.9296639239191619 specificity 0.8906605396895061 recall 0.9272181991076001 f1 0.9281142606150098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 21.939002752304077 s\n",
      "Accuracy 0.9245848877185283 precision 0.9262920217904757 specificity 0.8836799901088699 recall 0.9245848877185283 f1 0.9252554069966373\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 21.597001552581787 s\n",
      "Accuracy 0.9286080023407213 precision 0.9296866936551036 specificity 0.8820970007820147 recall 0.9286080023407213 f1 0.9290605982149062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 22.237001657485962 s\n",
      "Accuracy 0.9254626581815522 precision 0.9268705755948701 specificity 0.881677747989622 recall 0.9254626581815522 f1 0.9260337726578837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 21.420002698898315 s\n",
      "Accuracy 0.9275107892619413 precision 0.929168024730964 specificity 0.8889123557258803 recall 0.9275107892619413 f1 0.9281552942130623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 21.89459252357483 s\n",
      "Accuracy 0.9292663301879892 precision 0.9308622346231243 specificity 0.8880474369147712 recall 0.9292663301879892 f1 0.9298938091233014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 22.05236554145813 s\n",
      "Accuracy 0.9264135761831614 precision 0.9279859132051517 specificity 0.8874262042458051 recall 0.9264135761831614 f1 0.9270314546499449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 21.88486957550049 s\n",
      "Accuracy 0.924511740179943 precision 0.9261507744096137 specificity 0.8821213600069049 recall 0.924511740179943 f1 0.9251622521562876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 21.890729427337646 s\n",
      "Accuracy 0.9279496744934533 precision 0.9297576563981849 specificity 0.8913836407578419 recall 0.9279496744934533 f1 0.928638664317718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 22.473002195358276 s\n",
      "Accuracy 0.9291931826494039 precision 0.9306425417427072 specificity 0.8879839549596166 recall 0.9291931826494039 f1 0.9297702010433688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 21.933510303497314 s\n",
      "Accuracy 0.9283885597249653 precision 0.9299400249886909 specificity 0.8867147293174857 recall 0.9283885597249653 f1 0.9290027725430552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 22.204862117767334 s\n",
      "Accuracy 0.9294857728037451 precision 0.9308880332026561 specificity 0.8879629128189858 recall 0.9294857728037451 f1 0.9300466613377666\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 21.709511756896973 s\n",
      "Accuracy 0.9282422646477946 precision 0.9301566422816491 specificity 0.8920064141528419 recall 0.9282422646477946 f1 0.9289648213146781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 21.75400424003601 s\n",
      "Accuracy 0.9284617072635506 precision 0.9294931498644603 specificity 0.8839458101473833 recall 0.9284617072635506 f1 0.9288944561275527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 21.797001361846924 s\n",
      "Accuracy 0.9304366908053544 precision 0.9318892543343976 specificity 0.8926264816094265 recall 0.9304366908053544 f1 0.9310064951620296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 22.054001569747925 s\n",
      "Accuracy 0.9248043303342842 precision 0.9262137295264412 specificity 0.88019079148815 recall 0.9248043303342842 f1 0.9253780615492915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 21.99100089073181 s\n",
      "Accuracy 0.9291200351108185 precision 0.9309200447487317 specificity 0.8915763627564324 recall 0.9291200351108185 f1 0.9298074743081717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 22.011512756347656 s\n",
      "Accuracy 0.9245848877185283 precision 0.9256809215755688 specificity 0.878372212522904 recall 0.9245848877185283 f1 0.925046595175563\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 22.468491315841675 s\n",
      "Accuracy 0.9297052154195011 precision 0.9310051841732114 specificity 0.8873961673264508 recall 0.9297052154195011 f1 0.9302312607370653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 21.74999976158142 s\n",
      "Accuracy 0.931899641577061 precision 0.9331128421818424 specificity 0.8901547251691876 recall 0.931899641577061 f1 0.9323918455203201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 21.232597589492798 s\n",
      "Accuracy 0.9286080023407213 precision 0.9297192594140837 specificity 0.8833179998354296 recall 0.9286080023407213 f1 0.9290711625284175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 21.88200283050537 s\n",
      "Accuracy 0.9291200351108185 precision 0.931183970629839 specificity 0.8927878107085334 recall 0.9291200351108185 f1 0.9298901291164035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 21.350003957748413 s\n",
      "Accuracy 0.9272181991076001 precision 0.9284273730347903 specificity 0.8863997415674647 recall 0.9272181991076001 f1 0.9277117486791526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 22.236001014709473 s\n",
      "Accuracy 0.9256089532587228 precision 0.9274545726473675 specificity 0.8847588824983346 recall 0.9256089532587228 f1 0.9263250158574936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 21.570001363754272 s\n",
      "Accuracy 0.9207812157120913 precision 0.9221327760543047 specificity 0.8728516209093362 recall 0.9207812157120913 f1 0.9213430231965416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 22.473004817962646 s\n",
      "Accuracy 0.9297783629580865 precision 0.9305780686834262 specificity 0.8813987884554347 recall 0.9297783629580865 f1 0.9301256354491586\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 21.814000606536865 s\n",
      "Accuracy 0.9283885597249653 precision 0.9299967772404069 specificity 0.8880376355036252 recall 0.9283885597249653 f1 0.9290194066493762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 21.674001216888428 s\n",
      "Accuracy 0.927437641723356 precision 0.928624111077307 specificity 0.8839327765500825 recall 0.927437641723356 f1 0.9279268773763364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 21.380003929138184 s\n",
      "Accuracy 0.9254626581815522 precision 0.92674997641895 specificity 0.8812319083344368 recall 0.9254626581815522 f1 0.9259912655930522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 21.854001760482788 s\n",
      "Accuracy 0.9279496744934533 precision 0.9295705482807052 specificity 0.889790271027382 recall 0.9279496744934533 f1 0.9285803096536961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 21.68200135231018 s\n",
      "Accuracy 0.9268524614146734 precision 0.9280293429770007 specificity 0.8823650013807399 recall 0.9268524614146734 f1 0.927340084392624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 21.42200207710266 s\n",
      "Accuracy 0.9297052154195011 precision 0.9303429099531834 specificity 0.8818839654944249 recall 0.9297052154195011 f1 0.9299878001367632\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 21.63100242614746 s\n",
      "Accuracy 0.9265598712603321 precision 0.9287767849362203 specificity 0.8908061758325926 recall 0.9265598712603321 f1 0.9273812393335472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 21.328001737594604 s\n",
      "Accuracy 0.9244385926413576 precision 0.9260107989245636 specificity 0.8804617521691724 recall 0.9244385926413576 f1 0.9250691698262529\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 22.06500220298767 s\n",
      "Accuracy 0.9252432155657963 precision 0.9265961275678279 specificity 0.8774074185957723 recall 0.9252432155657963 f1 0.9258013236843112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 21.45700192451477 s\n",
      "Accuracy 0.9275107892619413 precision 0.9288646332937665 specificity 0.8868450257073882 recall 0.9275107892619413 f1 0.9280551626698713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 21.287004470825195 s\n",
      "Accuracy 0.9261941335674054 precision 0.9276479607371646 specificity 0.8842790227253147 recall 0.9261941335674054 f1 0.926777297257511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 21.77100110054016 s\n",
      "Accuracy 0.9270719040304294 precision 0.9288281698633029 specificity 0.8863182805828383 recall 0.9270719040304294 f1 0.9277556327937145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 21.4290030002594 s\n",
      "Accuracy 0.9295589203423305 precision 0.9307785174087443 specificity 0.8893387927951683 recall 0.9295589203423305 f1 0.9300531216145584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 21.333003044128418 s\n",
      "Accuracy 0.9280959695706239 precision 0.9292998860245449 specificity 0.8858394834092395 recall 0.9280959695706239 f1 0.9285890979599253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 22.32900094985962 s\n",
      "Accuracy 0.9259015434130642 precision 0.9267768188929922 specificity 0.8785616533227798 recall 0.9259015434130642 f1 0.9262794916417445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 23.32600426673889 s\n",
      "Accuracy 0.9257552483358935 precision 0.9269102586890127 specificity 0.8821799056366861 recall 0.9257552483358935 f1 0.9262344913175479\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 24.11799907684326 s\n",
      "Accuracy 0.9286080023407213 precision 0.9298373063170571 specificity 0.8870417930888349 recall 0.9286080023407213 f1 0.9291087090279311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 22.96000099182129 s\n",
      "Accuracy 0.9289737400336479 precision 0.9305433615807371 specificity 0.8933352390315964 recall 0.9289737400336479 f1 0.9295798016322889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 23.292002201080322 s\n",
      "Accuracy 0.9291931826494039 precision 0.9301669301396551 specificity 0.88149325733393 recall 0.9291931826494039 f1 0.9296072308183324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 24.14200186729431 s\n",
      "Accuracy 0.9248774778728696 precision 0.9271183284709089 specificity 0.8876195467867515 recall 0.9248774778728696 f1 0.9257143509357224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 23.38000178337097 s\n",
      "Accuracy 0.9281691171092092 precision 0.9292692079069986 specificity 0.8856543559905419 recall 0.9281691171092092 f1 0.928624874961655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 23.565001964569092 s\n",
      "Accuracy 0.930144100651013 precision 0.9312316519849134 specificity 0.8873690222154584 recall 0.930144100651013 f1 0.9305940530855537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 23.381000995635986 s\n",
      "Accuracy 0.9272181991076001 precision 0.9282659251195448 specificity 0.8825429347938712 recall 0.9272181991076001 f1 0.927658104343193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 23.377001523971558 s\n",
      "Accuracy 0.931899641577061 precision 0.9330473149514642 specificity 0.8913756037945016 recall 0.931899641577061 f1 0.9323665994163193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 23.48900270462036 s\n",
      "Accuracy 0.9265598712603321 precision 0.928017450966709 specificity 0.8851513686906503 recall 0.9265598712603321 f1 0.9271429870991841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 23.187001705169678 s\n",
      "Accuracy 0.9297783629580865 precision 0.9313226388005108 specificity 0.8905831570408538 recall 0.9297783629580865 f1 0.930383189884133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 23.390002727508545 s\n",
      "Accuracy 0.9264135761831614 precision 0.9282266304020341 specificity 0.8890485005887407 recall 0.9264135761831614 f1 0.9271085031804882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 23.717002391815186 s\n",
      "Accuracy 0.9257552483358935 precision 0.9273646842928172 specificity 0.882612010631001 recall 0.9257552483358935 f1 0.9263956354162907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 24.052002429962158 s\n",
      "Accuracy 0.9258283958744788 precision 0.9279494968686456 specificity 0.8878217664407149 recall 0.9258283958744788 f1 0.9266273641908078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 24.346002101898193 s\n",
      "Accuracy 0.9257552483358935 precision 0.9276094313974843 specificity 0.887185971550712 recall 0.9257552483358935 f1 0.9264680087365507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 23.819002151489258 s\n",
      "Accuracy 0.9273644941847707 precision 0.9288344573019874 specificity 0.8874122017020737 recall 0.9273644941847707 f1 0.9279481562220803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 23.237996339797974 s\n",
      "Accuracy 0.9253895106429668 precision 0.92652330579571 specificity 0.8788866029496243 recall 0.9253895106429668 f1 0.925865064758488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 23.377002954483032 s\n",
      "Accuracy 0.931241313729793 precision 0.9327012350171349 specificity 0.8922279382424528 recall 0.931241313729793 f1 0.9318152579789881\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 23.233001947402954 s\n",
      "Accuracy 0.9267061663375027 precision 0.9284935388234817 specificity 0.8851350681677825 recall 0.9267061663375027 f1 0.9274028784475654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 24.622002124786377 s\n",
      "Accuracy 0.9289005924950625 precision 0.9305601125737755 specificity 0.8934270093790757 recall 0.9289005924950625 f1 0.9295362785328568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 24.16000199317932 s\n",
      "Accuracy 0.9259015434130642 precision 0.9277065616282866 specificity 0.884217680998557 recall 0.9259015434130642 f1 0.9266055665548764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 24.496002435684204 s\n",
      "Accuracy 0.9248043303342842 precision 0.9264812807136287 specificity 0.8847224961616356 recall 0.9248043303342842 f1 0.9254623521308883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 24.204002857208252 s\n",
      "Accuracy 0.9281691171092092 precision 0.9292888957769703 specificity 0.8859410093289952 recall 0.9281691171092092 f1 0.9286316663368811\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 24.38300347328186 s\n",
      "Accuracy 0.9284617072635506 precision 0.9302508933069997 specificity 0.8920895086329907 recall 0.9284617072635506 f1 0.9291432696510105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 23.97300124168396 s\n",
      "Accuracy 0.9242191500256016 precision 0.9260505732171169 specificity 0.8834555210810909 recall 0.9242191500256016 f1 0.9249320401394133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 23.649002075195312 s\n",
      "Accuracy 0.9283885597249653 precision 0.929835250994298 specificity 0.8881772946220652 recall 0.9283885597249653 f1 0.9289635673735654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 24.6050021648407 s\n",
      "Accuracy 0.9244385926413576 precision 0.9263988641854574 specificity 0.883740380362987 recall 0.9244385926413576 f1 0.9251943498154089\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 23.464003086090088 s\n",
      "Accuracy 0.9284617072635506 precision 0.9301647831889427 specificity 0.890917373334562 recall 0.9284617072635506 f1 0.92911780001614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 23.785001754760742 s\n",
      "Accuracy 0.927657084339112 precision 0.9287870113669251 specificity 0.8820067649971044 recall 0.927657084339112 f1 0.9281283509087642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 23.52300238609314 s\n",
      "Accuracy 0.9287542974178918 precision 0.9302266332553957 specificity 0.884645544800045 recall 0.9287542974178918 f1 0.9293453021752762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 23.700000762939453 s\n",
      "Accuracy 0.9286811498793066 precision 0.9306242745793634 specificity 0.8924472542166885 recall 0.9286811498793066 f1 0.9294124411034733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 23.8780038356781 s\n",
      "Accuracy 0.9264135761831614 precision 0.9277078943672461 specificity 0.8806851107872435 recall 0.9264135761831614 f1 0.9269461450186999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 24.630001544952393 s\n",
      "Accuracy 0.9286080023407213 precision 0.9300800357438699 specificity 0.8905972725989602 recall 0.9286080023407213 f1 0.9291869379790854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 24.05400061607361 s\n",
      "Accuracy 0.9286811498793066 precision 0.9299123306933494 specificity 0.8844123133384787 recall 0.9286811498793066 f1 0.9291866211702468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 24.33600401878357 s\n",
      "Accuracy 0.9248043303342842 precision 0.9266186072256375 specificity 0.8834447119021474 recall 0.9248043303342842 f1 0.9255121354086779\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 23.86600136756897 s\n",
      "Accuracy 0.9300709531124277 precision 0.9310368428993552 specificity 0.8888402099975646 recall 0.9300709531124277 f1 0.9304743073895823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 23.742001056671143 s\n",
      "Accuracy 0.9248774778728696 precision 0.9269402630518552 specificity 0.8898477129371299 recall 0.9248774778728696 f1 0.925649363796819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 23.73200249671936 s\n",
      "Accuracy 0.9240728549484309 precision 0.925787671516327 specificity 0.8821000743640924 recall 0.9240728549484309 f1 0.9247490947547002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 23.877001523971558 s\n",
      "Accuracy 0.9283885597249653 precision 0.929789932286964 specificity 0.8862564612391111 recall 0.9283885597249653 f1 0.928951415709778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 23.9680016040802 s\n",
      "Accuracy 0.923853412332675 precision 0.9257534516567393 specificity 0.883271153952551 recall 0.923853412332675 f1 0.9245894607633482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 24.382999658584595 s\n",
      "Accuracy 0.9288274449564772 precision 0.9309011263955185 specificity 0.894493622697199 recall 0.9288274449564772 f1 0.9295945905705781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 24.185001850128174 s\n",
      "Accuracy 0.9245848877185283 precision 0.926057664851153 specificity 0.8847746766447971 recall 0.9245848877185283 f1 0.9251722143334649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 24.63300347328186 s\n",
      "Accuracy 0.9308755760368663 precision 0.9320537648437818 specificity 0.8865596515812929 recall 0.9308755760368663 f1 0.9313599851108683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 24.247002363204956 s\n",
      "Accuracy 0.9291931826494039 precision 0.9310029161448643 specificity 0.8943830925562142 recall 0.9291931826494039 f1 0.929876062250954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 24.411001443862915 s\n",
      "Accuracy 0.9286080023407213 precision 0.9299625401605212 specificity 0.8853588343939727 recall 0.9286080023407213 f1 0.9291560752294954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 23.52200222015381 s\n",
      "Accuracy 0.9247311827956989 precision 0.9255939774693339 specificity 0.8766621178557132 recall 0.9247311827956989 f1 0.9251055296362336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 24.3280029296875 s\n",
      "Accuracy 0.9270719040304294 precision 0.9285017621775856 specificity 0.8833377861834801 recall 0.9270719040304294 f1 0.9276490656778206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 24.27200436592102 s\n",
      "Accuracy 0.9245848877185283 precision 0.9261810482796263 specificity 0.8822985129156253 recall 0.9245848877185283 f1 0.925220228749149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 23.855000257492065 s\n",
      "Accuracy 0.9259015434130642 precision 0.9277736223214426 specificity 0.8851481206965981 recall 0.9259015434130642 f1 0.92662586458453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 24.131001472473145 s\n",
      "Accuracy 0.9279496744934533 precision 0.9291148628462486 specificity 0.8850358670104493 recall 0.9279496744934533 f1 0.928429893616619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 25.60800266265869 s\n",
      "Accuracy 0.9275839368005266 precision 0.9292287817960997 specificity 0.8875183917874849 recall 0.9275839368005266 f1 0.9282275991314214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 24.440003395080566 s\n",
      "Accuracy 0.9268524614146734 precision 0.928399787561204 specificity 0.8877453206443328 recall 0.9268524614146734 f1 0.927461543445502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 24.388002157211304 s\n",
      "Accuracy 0.9273644941847707 precision 0.9283067605440132 specificity 0.8818751653745954 recall 0.9273644941847707 f1 0.9277655360229705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 22.436002016067505 s\n",
      "Accuracy 0.9303635432667691 precision 0.9316740430641515 specificity 0.8897151896493675 recall 0.9303635432667691 f1 0.930889798650775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 21.913001775741577 s\n",
      "Accuracy 0.9283885597249653 precision 0.9299773848014778 specificity 0.8890660308215311 recall 0.9283885597249653 f1 0.9290104927988355\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 22.08500099182129 s\n",
      "Accuracy 0.9261209860288201 precision 0.9272808431249223 specificity 0.881215721298106 recall 0.9261209860288201 f1 0.9266035329131074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 22.492003202438354 s\n",
      "Accuracy 0.9253895106429668 precision 0.9273693085356183 specificity 0.8883127576789414 recall 0.9253895106429668 f1 0.9261400606327324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 22.6952862739563 s\n",
      "Accuracy 0.9256821007973082 precision 0.9283496292732164 specificity 0.8932242646909163 recall 0.9256821007973082 f1 0.926633622755873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 22.169410943984985 s\n",
      "Accuracy 0.9286811498793066 precision 0.9306181211793105 specificity 0.8901765122646751 recall 0.9286811498793066 f1 0.9294170480865672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 23.036002159118652 s\n",
      "Accuracy 0.9267061663375027 precision 0.9277670715440248 specificity 0.8800538076751709 recall 0.9267061663375027 f1 0.9271536905455358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 22.339003562927246 s\n",
      "Accuracy 0.9248774778728696 precision 0.9262742441068105 specificity 0.8818713085609683 recall 0.9248774778728696 f1 0.9254438409581589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 22.25300359725952 s\n",
      "Accuracy 0.9289737400336479 precision 0.9305161426673235 specificity 0.8892254870588265 recall 0.9289737400336479 f1 0.9295800820231855\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 22.242000341415405 s\n",
      "Accuracy 0.9261941335674054 precision 0.9278527627537989 specificity 0.8862339290161091 recall 0.9261941335674054 f1 0.9268439418168465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 21.964001655578613 s\n",
      "Accuracy 0.9296320678809158 precision 0.9304546588032223 specificity 0.8856831969564891 recall 0.9296320678809158 f1 0.9299845996695061\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 22.3930025100708 s\n",
      "Accuracy 0.9280959695706239 precision 0.9296217492174863 specificity 0.8878811100467707 recall 0.9280959695706239 f1 0.9286986215170763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 22.32000231742859 s\n",
      "Accuracy 0.927876526954868 precision 0.9295255876148112 specificity 0.886121234832203 recall 0.927876526954868 f1 0.9285250713260168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 22.13600182533264 s\n",
      "Accuracy 0.9246580352571137 precision 0.926003064545845 specificity 0.8809040824949405 recall 0.9246580352571137 f1 0.9252074069073388\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 22.55800223350525 s\n",
      "Accuracy 0.9237071172555044 precision 0.9249710456594872 specificity 0.8796418840863359 recall 0.9237071172555044 f1 0.924228540616249\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 22.64300227165222 s\n",
      "Accuracy 0.9259746909516495 precision 0.9280113259044201 specificity 0.8889680391982712 recall 0.9259746909516495 f1 0.9267427771724394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 22.312002658843994 s\n",
      "Accuracy 0.9254626581815522 precision 0.9268487779711827 specificity 0.8814206901691456 recall 0.9254626581815522 f1 0.9260264481006442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 22.295002460479736 s\n",
      "Accuracy 0.9268524614146734 precision 0.9282183020975111 specificity 0.8831017829123725 recall 0.9268524614146734 f1 0.9274071539763681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 22.691002368927002 s\n",
      "Accuracy 0.9295589203423305 precision 0.9310922868785612 specificity 0.8916735311904744 recall 0.9295589203423305 f1 0.9301573787600789\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 21.929001569747925 s\n",
      "Accuracy 0.9256821007973082 precision 0.9279012316098102 specificity 0.8874456351261895 recall 0.9256821007973082 f1 0.9265139104106751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 22.44300365447998 s\n",
      "Accuracy 0.9290468875722332 precision 0.9301166151395132 specificity 0.8850996806964411 recall 0.9290468875722332 f1 0.9294926856724782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 22.12200140953064 s\n",
      "Accuracy 0.9270719040304294 precision 0.9290888354051803 specificity 0.8889903191006396 recall 0.9270719040304294 f1 0.9278351886169277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 22.098002195358276 s\n",
      "Accuracy 0.924292297564187 precision 0.9259333664908009 specificity 0.8839968761600214 recall 0.924292297564187 f1 0.9249391414075896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 22.193001747131348 s\n",
      "Accuracy 0.9267061663375027 precision 0.9278324797060211 specificity 0.8805592825190749 recall 0.9267061663375027 f1 0.9271774759500635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 21.945000410079956 s\n",
      "Accuracy 0.927876526954868 precision 0.9295758052880522 specificity 0.8905514037316147 recall 0.927876526954868 f1 0.928531540764097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 21.85100030899048 s\n",
      "Accuracy 0.924292297564187 precision 0.9256692182921272 specificity 0.8758475423065258 recall 0.924292297564187 f1 0.9248609598215327\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 22.16700267791748 s\n",
      "Accuracy 0.9294857728037451 precision 0.9307424661757293 specificity 0.8859188054840158 recall 0.9294857728037451 f1 0.9299986238803906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 22.489001512527466 s\n",
      "Accuracy 0.926998756491844 precision 0.9286120684616663 specificity 0.8886117963873548 recall 0.926998756491844 f1 0.9276285173419999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 22.32900381088257 s\n",
      "Accuracy 0.9264135761831614 precision 0.9283287488440478 specificity 0.887001498429518 recall 0.9264135761831614 f1 0.9271480244371368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 22.200003623962402 s\n",
      "Accuracy 0.9275107892619413 precision 0.9291441206888259 specificity 0.8858912445033582 recall 0.9275107892619413 f1 0.9281540923010421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 21.849000692367554 s\n",
      "Accuracy 0.9251700680272109 precision 0.9262975372045094 specificity 0.8762730382850815 recall 0.9251700680272109 f1 0.9256463156113364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 22.609002590179443 s\n",
      "Accuracy 0.9289737400336479 precision 0.9304853675101291 specificity 0.8894625898317227 recall 0.9289737400336479 f1 0.9295690350896043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 21.884001970291138 s\n",
      "Accuracy 0.9285348548021359 precision 0.9303023249384141 specificity 0.8898957116303925 recall 0.9285348548021359 f1 0.9292151525876323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 22.821999549865723 s\n",
      "Accuracy 0.9266330187989175 precision 0.9280724838473374 specificity 0.8839635995885848 recall 0.9266330187989175 f1 0.9272120920767355\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 22.274003505706787 s\n",
      "Accuracy 0.9269256089532587 precision 0.9288581703403418 specificity 0.8899456021406081 recall 0.9269256089532587 f1 0.9276581870350799\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 22.195001125335693 s\n",
      "Accuracy 0.9300709531124277 precision 0.9313795840384675 specificity 0.8895757838313239 recall 0.9300709531124277 f1 0.9305965743780878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 21.81009817123413 s\n",
      "Accuracy 0.9313876088069637 precision 0.93299007605175 specificity 0.8918426888358262 recall 0.9313876088069637 f1 0.9320109925874747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 22.422003030776978 s\n",
      "Accuracy 0.9253895106429668 precision 0.9266543308707338 specificity 0.8801223029763272 recall 0.9253895106429668 f1 0.9259115942815924\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 22.238000631332397 s\n",
      "Accuracy 0.9296320678809158 precision 0.9311556300182017 specificity 0.8929495498524646 recall 0.9296320678809158 f1 0.9302243686551521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 22.11699914932251 s\n",
      "Accuracy 0.9269256089532587 precision 0.9281955748905554 specificity 0.8836650507183231 recall 0.9269256089532587 f1 0.9274451133540241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 22.423000812530518 s\n",
      "Accuracy 0.9281691171092092 precision 0.9299065134138929 specificity 0.8861566309009683 recall 0.9281691171092092 f1 0.9288480026743952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 22.00000238418579 s\n",
      "Accuracy 0.931021871114037 precision 0.932367970256905 specificity 0.8904285339243462 recall 0.931021871114037 f1 0.9315598158961759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 21.8860023021698 s\n",
      "Accuracy 0.9249506254114549 precision 0.9271210518814681 specificity 0.8861978374407438 recall 0.9249506254114549 f1 0.9257693811504797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 22.090000867843628 s\n",
      "Accuracy 0.9268524614146734 precision 0.9282193976142636 specificity 0.8846606115451121 recall 0.9268524614146734 f1 0.9274048474254069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 22.146002292633057 s\n",
      "Accuracy 0.9275107892619413 precision 0.9287700015784824 specificity 0.884898284082918 recall 0.9275107892619413 f1 0.9280248716415259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 23.155001401901245 s\n",
      "Accuracy 0.9240728549484309 precision 0.9261813498155375 specificity 0.8866224456598814 recall 0.9240728549484309 f1 0.9248686034339081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 23.51200222969055 s\n",
      "Accuracy 0.9281691171092092 precision 0.9300079540126975 specificity 0.8908363082796903 recall 0.9281691171092092 f1 0.9288701162545545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 23.24099850654602 s\n",
      "Accuracy 0.9223173140223832 precision 0.923916313783854 specificity 0.8778281930215215 recall 0.9223173140223832 f1 0.922960666409148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 23.622001886367798 s\n",
      "Accuracy 0.9275107892619413 precision 0.929325887051289 specificity 0.8880060351597385 recall 0.9275107892619413 f1 0.9282106039264834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 23.40200138092041 s\n",
      "Accuracy 0.9326311169629142 precision 0.933659116002271 specificity 0.890491521163985 recall 0.9326311169629142 f1 0.9330565175704667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 23.610002756118774 s\n",
      "Accuracy 0.9286080023407213 precision 0.9299452699435323 specificity 0.886467302473068 recall 0.9286080023407213 f1 0.9291480546883569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 23.457001447677612 s\n",
      "Accuracy 0.9281691171092092 precision 0.929118593123695 specificity 0.8848889985356598 recall 0.9281691171092092 f1 0.9285700150293018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 23.178000450134277 s\n",
      "Accuracy 0.9252432155657963 precision 0.9269623232692175 specificity 0.8829451219023482 recall 0.9252432155657963 f1 0.9259202293535922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 23.564001083374023 s\n",
      "Accuracy 0.9264867237217468 precision 0.9276807892132626 specificity 0.8834570760121648 recall 0.9264867237217468 f1 0.9269788330128835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 24.091002225875854 s\n",
      "Accuracy 0.9277302318776973 precision 0.9287947664936435 specificity 0.8805789418642782 recall 0.9277302318776973 f1 0.9281789437575003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 23.96900248527527 s\n",
      "Accuracy 0.927437641723356 precision 0.9286516546544514 specificity 0.8837032335790643 recall 0.927437641723356 f1 0.9279372099405093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 23.20800018310547 s\n",
      "Accuracy 0.9253895106429668 precision 0.9269479954881411 specificity 0.8843630383016445 recall 0.9253895106429668 f1 0.9260082309030683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 23.690003156661987 s\n",
      "Accuracy 0.9233413795625777 precision 0.9245136371780192 specificity 0.8761025309999283 recall 0.9233413795625777 f1 0.9238337643282453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 22.98100233078003 s\n",
      "Accuracy 0.9272913466461854 precision 0.9288497668518993 specificity 0.8875439170473775 recall 0.9272913466461854 f1 0.927905130015329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 23.438000917434692 s\n",
      "Accuracy 0.9241460024870163 precision 0.9261390794974623 specificity 0.8859215318895187 recall 0.9241460024870163 f1 0.9249060975345081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 23.013002634048462 s\n",
      "Accuracy 0.9260478384902348 precision 0.927636865990031 specificity 0.8883050117319978 recall 0.9260478384902348 f1 0.9266689666117499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 23.27099847793579 s\n",
      "Accuracy 0.9286811498793066 precision 0.9303044835125603 specificity 0.8903427737798508 recall 0.9286811498793066 f1 0.929312145742936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 23.684000253677368 s\n",
      "Accuracy 0.9259015434130642 precision 0.9275627068840432 specificity 0.8844013029598335 recall 0.9259015434130642 f1 0.9265560786038979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 23.243000030517578 s\n",
      "Accuracy 0.9259015434130642 precision 0.9273829174207123 specificity 0.8823733674821198 recall 0.9259015434130642 f1 0.9264977416749592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 23.640000581741333 s\n",
      "Accuracy 0.9283154121863799 precision 0.9293553828388398 specificity 0.883115510648741 recall 0.9283154121863799 f1 0.9287522513127235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 23.13499879837036 s\n",
      "Accuracy 0.9254626581815522 precision 0.9268485479570313 specificity 0.8830609132792534 recall 0.9254626581815522 f1 0.9260235098018377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 24.02799892425537 s\n",
      "Accuracy 0.9264867237217468 precision 0.9280461784267949 specificity 0.8860324243009482 recall 0.9264867237217468 f1 0.9271033177119345\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 23.350998878479004 s\n",
      "Accuracy 0.9259746909516495 precision 0.9278182629416628 specificity 0.8872243468957314 recall 0.9259746909516495 f1 0.9266841042404506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 23.845999002456665 s\n",
      "Accuracy 0.9248774778728696 precision 0.9264893110827047 specificity 0.8831885084212079 recall 0.9248774778728696 f1 0.9255166479173829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 23.421000480651855 s\n",
      "Accuracy 0.9281691171092092 precision 0.9296364332291683 specificity 0.8890214774573092 recall 0.9281691171092092 f1 0.9287493268610305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 23.917998552322388 s\n",
      "Accuracy 0.9294126252651598 precision 0.9305464915331608 specificity 0.8868180210544759 recall 0.9294126252651598 f1 0.9298797905453365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 23.074000358581543 s\n",
      "Accuracy 0.931021871114037 precision 0.932482880018588 specificity 0.891228366190187 recall 0.931021871114037 f1 0.9315980474008357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 23.893999338150024 s\n",
      "Accuracy 0.9268524614146734 precision 0.9281443557199668 specificity 0.8846334179672669 recall 0.9268524614146734 f1 0.9273782123698128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 23.398000240325928 s\n",
      "Accuracy 0.9296320678809158 precision 0.9313455463230994 specificity 0.8941407203475608 recall 0.9296320678809158 f1 0.930284703609649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 23.75999903678894 s\n",
      "Accuracy 0.9315339038841343 precision 0.9330534244414127 specificity 0.8962748051981272 recall 0.9315339038841343 f1 0.9321192256691682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 23.214999437332153 s\n",
      "Accuracy 0.9309487235754517 precision 0.9324372501469251 specificity 0.894643763961023 recall 0.9309487235754517 f1 0.9315268004133856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 23.82300114631653 s\n",
      "Accuracy 0.9289005924950625 precision 0.9303682171563159 specificity 0.8881777661107262 recall 0.9289005924950625 f1 0.9294833102421413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 23.39899754524231 s\n",
      "Accuracy 0.9270719040304294 precision 0.9293815523664383 specificity 0.8919364120792161 recall 0.9270719040304294 f1 0.9279198174375528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 23.30199956893921 s\n",
      "Accuracy 0.9291200351108185 precision 0.930612341933213 specificity 0.8906603933083036 recall 0.9291200351108185 f1 0.9297062948815994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 22.90400004386902 s\n",
      "Accuracy 0.9286811498793066 precision 0.9303473726164906 specificity 0.890916064599777 recall 0.9286811498793066 f1 0.929325184307167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 23.922999143600464 s\n",
      "Accuracy 0.9279496744934533 precision 0.9302204394500581 specificity 0.8919438262070944 recall 0.9279496744934533 f1 0.9287868822508414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 23.256002187728882 s\n",
      "Accuracy 0.9293394777265745 precision 0.9308595863476641 specificity 0.8914784653089248 recall 0.9293394777265745 f1 0.9299336388919299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 23.439996480941772 s\n",
      "Accuracy 0.9305098383439397 precision 0.9319277082659818 specificity 0.8910124160468491 recall 0.9305098383439397 f1 0.9310711433111617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 23.845000982284546 s\n",
      "Accuracy 0.9259015434130642 precision 0.9273008339338258 specificity 0.8872375079379712 recall 0.9259015434130642 f1 0.9264596211413555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 23.187999486923218 s\n",
      "Accuracy 0.9275107892619413 precision 0.929177882408648 specificity 0.8855616136455483 recall 0.9275107892619413 f1 0.9281663878183761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 23.39799952507019 s\n",
      "Accuracy 0.9284617072635506 precision 0.9296093505781166 specificity 0.8875975880396764 recall 0.9284617072635506 f1 0.9289321395541829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 23.233001470565796 s\n",
      "Accuracy 0.9321922317314022 precision 0.9332666629892873 specificity 0.890101976275471 recall 0.9321922317314022 f1 0.9326348243471936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 23.094998836517334 s\n",
      "Accuracy 0.9269256089532587 precision 0.9287407633553909 specificity 0.8913458072393757 recall 0.9269256089532587 f1 0.9276155594430664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 23.513000011444092 s\n",
      "Accuracy 0.9298515104966718 precision 0.9313524967428792 specificity 0.8949949298998047 recall 0.9298515104966718 f1 0.9304316485695632\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 23.478999614715576 s\n",
      "Accuracy 0.9304366908053544 precision 0.9315810146314346 specificity 0.8886620211908312 recall 0.9304366908053544 f1 0.9309055938341472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 23.090999364852905 s\n",
      "Accuracy 0.9280228220320387 precision 0.9300894878056994 specificity 0.8909730653878987 recall 0.9280228220320387 f1 0.9287977429789347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 23.27499794960022 s\n",
      "Accuracy 0.926779313876088 precision 0.9280562218894295 specificity 0.8830659276361359 recall 0.926779313876088 f1 0.9273021612495346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 23.8279972076416 s\n",
      "Accuracy 0.9281691171092092 precision 0.9298824863734536 specificity 0.8887809318769145 recall 0.9281691171092092 f1 0.9288336333592075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 24.72500205039978 s\n",
      "Accuracy 0.9278033794162827 precision 0.9296557024639353 specificity 0.8917887144493761 recall 0.9278033794162827 f1 0.9285055957867018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 23.950950145721436 s\n",
      "Accuracy 0.9277302318776973 precision 0.9292175885906658 specificity 0.8859837013254931 recall 0.9277302318776973 f1 0.9283231235655109\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 23.04799771308899 s\n",
      "Accuracy 0.9248774778728696 precision 0.9259052379261097 specificity 0.8784029691286274 recall 0.9248774778728696 f1 0.9253135948211167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 23.394999027252197 s\n",
      "Accuracy 0.9285348548021359 precision 0.9301848610289561 specificity 0.8874081013902053 recall 0.9285348548021359 f1 0.929181509680091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 23.16999912261963 s\n",
      "Accuracy 0.9273644941847707 precision 0.9282733086235381 specificity 0.8829033157088506 recall 0.9273644941847707 f1 0.9277517777837967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 23.407999753952026 s\n",
      "Accuracy 0.9297783629580865 precision 0.9308705826151513 specificity 0.8857865822858073 recall 0.9297783629580865 f1 0.9302319187359995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 23.56203293800354 s\n",
      "Accuracy 0.927657084339112 precision 0.9289623206950398 specificity 0.8818683167304069 recall 0.927657084339112 f1 0.9281925400412843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 24.72099781036377 s\n",
      "Accuracy 0.9277302318776973 precision 0.9288966835327802 specificity 0.8856274289520077 recall 0.9277302318776973 f1 0.9282099142222414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 23.832029819488525 s\n",
      "Accuracy 0.9275107892619413 precision 0.9293263668401609 specificity 0.889319049176699 recall 0.9275107892619413 f1 0.9282073149470923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 23.515997648239136 s\n",
      "Accuracy 0.9298515104966718 precision 0.9315885279689771 specificity 0.8925970033568079 recall 0.9298515104966718 f1 0.9305163317125095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 23.563998699188232 s\n",
      "Accuracy 0.9242191500256016 precision 0.9256893318291691 specificity 0.8823421088013483 recall 0.9242191500256016 f1 0.9248100504158301\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 23.41700029373169 s\n",
      "Accuracy 0.9305829858825251 precision 0.9316242648111485 specificity 0.8858337854368356 recall 0.9305829858825251 f1 0.9310180873571654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 23.94299840927124 s\n",
      "Accuracy 0.9273644941847707 precision 0.9285797218772854 specificity 0.8808567598647704 recall 0.9273644941847707 f1 0.9278685153812152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 23.59899926185608 s\n",
      "Accuracy 0.9277302318776973 precision 0.9293051056342398 specificity 0.8870494065685799 recall 0.9277302318776973 f1 0.9283511739099252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 23.12300133705139 s\n",
      "Accuracy 0.9267061663375027 precision 0.9278949844305938 specificity 0.8831466291369208 recall 0.9267061663375027 f1 0.9271969540056741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 23.370999574661255 s\n",
      "Accuracy 0.9293394777265745 precision 0.9305128289428787 specificity 0.8847154192242211 recall 0.9293394777265745 f1 0.9298239019493538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 23.38499927520752 s\n",
      "Accuracy 0.9250969204886256 precision 0.9270702573810093 specificity 0.8883061822472844 recall 0.9250969204886256 f1 0.925844906690386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 23.758033514022827 s\n",
      "Accuracy 0.9218052812522859 precision 0.9231934759303877 specificity 0.8747583929260708 recall 0.9218052812522859 f1 0.9223782203066203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 23.812999963760376 s\n",
      "Accuracy 0.9268524614146734 precision 0.9278162513306952 specificity 0.8825689299924317 recall 0.9268524614146734 f1 0.9272607077691465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 23.219998359680176 s\n",
      "Accuracy 0.9264135761831614 precision 0.9285226380284817 specificity 0.8863605226390568 recall 0.9264135761831614 f1 0.9272139490927741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 23.995999336242676 s\n",
      "Accuracy 0.9257552483358935 precision 0.9274389171431061 specificity 0.8859514804773476 recall 0.9257552483358935 f1 0.9264137476004033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 23.330000400543213 s\n",
      "Accuracy 0.9299978055738425 precision 0.9313710363356652 specificity 0.8924085536179563 recall 0.9299978055738425 f1 0.9305404539302716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 23.486998796463013 s\n",
      "Accuracy 0.9246580352571137 precision 0.9257426290818201 specificity 0.8783947038519546 recall 0.9246580352571137 f1 0.9251154645679454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 23.539999961853027 s\n",
      "Accuracy 0.9298515104966718 precision 0.9313226204456023 specificity 0.8895877063078145 recall 0.9298515104966718 f1 0.9304334451683417\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 23.833999156951904 s\n",
      "Accuracy 0.9313144612683784 precision 0.9325725323791892 specificity 0.8899270726761165 recall 0.9313144612683784 f1 0.931822564948912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 24.72030782699585 s\n",
      "Accuracy 0.9288274449564772 precision 0.9301446260694516 specificity 0.8854988851661512 recall 0.9288274449564772 f1 0.9293621582684799\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 23.903148412704468 s\n",
      "Accuracy 0.9280228220320387 precision 0.9288019623794068 specificity 0.882306687492642 recall 0.9280228220320387 f1 0.9283608787627813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 23.844855070114136 s\n",
      "Accuracy 0.9272913466461854 precision 0.9294096642688333 specificity 0.8918031338231835 recall 0.9272913466461854 f1 0.9280790282510908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 23.433998584747314 s\n",
      "Accuracy 0.9250237729500402 precision 0.9266160762137648 specificity 0.8798207248466089 recall 0.9250237729500402 f1 0.9256631448470755\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 23.6072039604187 s\n",
      "Accuracy 0.9254626581815522 precision 0.92717728590729 specificity 0.8868832932657918 recall 0.9254626581815522 f1 0.9261290316692158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 24.05000114440918 s\n",
      "Accuracy 0.9280228220320387 precision 0.9292938589795172 specificity 0.8853751567899496 recall 0.9280228220320387 f1 0.9285407240749056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 23.517998218536377 s\n",
      "Accuracy 0.9298515104966718 precision 0.9315915599519208 specificity 0.8897370076660043 recall 0.9298515104966718 f1 0.9305245648592306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 23.556450366973877 s\n",
      "Accuracy 0.9295589203423305 precision 0.9310956067187316 specificity 0.8886055552882403 recall 0.9295589203423305 f1 0.9301651785450543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 24.17599844932556 s\n",
      "Accuracy 0.9250969204886256 precision 0.9262652264956412 specificity 0.8815349593351651 recall 0.9250969204886256 f1 0.9255815460727134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 23.46803569793701 s\n",
      "Accuracy 0.9259746909516495 precision 0.9267912354409702 specificity 0.8790144521559248 recall 0.9259746909516495 f1 0.9263293975960502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 23.602999448776245 s\n",
      "Accuracy 0.926998756491844 precision 0.9279487992849416 specificity 0.8819012858579367 recall 0.926998756491844 f1 0.9274025770138835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 23.794998168945312 s\n",
      "Accuracy 0.9281691171092092 precision 0.9300084422237516 specificity 0.8895059680174822 recall 0.9281691171092092 f1 0.9288738969799232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 23.14246940612793 s\n",
      "Accuracy 0.9256089532587228 precision 0.9266455500237324 specificity 0.8802248252405513 recall 0.9256089532587228 f1 0.9260466708665896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 23.6603000164032 s\n",
      "Accuracy 0.9207812157120913 precision 0.9225888149214868 specificity 0.8779632545637778 recall 0.9207812157120913 f1 0.9214953559670588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 23.692301034927368 s\n",
      "Accuracy 0.9286080023407213 precision 0.9299696511209867 specificity 0.8896334244626126 recall 0.9286080023407213 f1 0.9291508273304742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 24.391032695770264 s\n",
      "Accuracy 0.9256821007973082 precision 0.9272619907999002 specificity 0.8849195550077458 recall 0.9256821007973082 f1 0.9263073217295807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 23.99215054512024 s\n",
      "Accuracy 0.9251700680272109 precision 0.9268531583019982 specificity 0.8854436823460127 recall 0.9251700680272109 f1 0.9258289023869934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 23.346545457839966 s\n",
      "Accuracy 0.9271450515690147 precision 0.9289599985806962 specificity 0.8883387111896033 recall 0.9271450515690147 f1 0.9278434884806125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 23.730350255966187 s\n",
      "Accuracy 0.9280228220320387 precision 0.9299419826999235 specificity 0.8909590336478822 recall 0.9280228220320387 f1 0.9287496873183624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 23.612510919570923 s\n",
      "Accuracy 0.9241460024870163 precision 0.9260335596983799 specificity 0.8827673994709694 recall 0.9241460024870163 f1 0.9248795205763389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 24.207019329071045 s\n",
      "Accuracy 0.9289005924950625 precision 0.9304797966058135 specificity 0.8921152880708655 recall 0.9289005924950625 f1 0.9295127477924965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 23.268998861312866 s\n",
      "Accuracy 0.924511740179943 precision 0.9258992999619702 specificity 0.8796757181246747 recall 0.924511740179943 f1 0.9250783127507318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 23.522000312805176 s\n",
      "Accuracy 0.9286080023407213 precision 0.9299896924826117 specificity 0.8868722964368674 recall 0.9286080023407213 f1 0.9291629948804077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 23.273805618286133 s\n",
      "Accuracy 0.9257552483358935 precision 0.9265254550377875 specificity 0.8780155237448187 recall 0.9257552483358935 f1 0.926092414247571\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 23.29119873046875 s\n",
      "Accuracy 0.9252432155657963 precision 0.9274257306779541 specificity 0.8847211122867007 recall 0.9252432155657963 f1 0.9260709490090646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 23.526997566223145 s\n",
      "Accuracy 0.926998756491844 precision 0.9285199533072742 specificity 0.8864079780599973 recall 0.926998756491844 f1 0.9276018584856629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 23.74000072479248 s\n",
      "Accuracy 0.9275839368005266 precision 0.9287840102042109 specificity 0.8865115069627688 recall 0.9275839368005266 f1 0.9280743024718526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 23.628148317337036 s\n",
      "Accuracy 0.9277302318776973 precision 0.9296934778536705 specificity 0.8900299704149601 recall 0.9277302318776973 f1 0.9284738291261677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 23.69899868965149 s\n",
      "Accuracy 0.9258283958744788 precision 0.9279744968234402 specificity 0.8880438495933513 recall 0.9258283958744788 f1 0.9266348015814843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 24.138078212738037 s\n",
      "Accuracy 0.9298515104966718 precision 0.9312134851429121 specificity 0.8884035285954072 recall 0.9298515104966718 f1 0.9303977766079164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 24.3381450176239 s\n",
      "Accuracy 0.9304366908053544 precision 0.9322784663303075 specificity 0.8935388824392984 recall 0.9304366908053544 f1 0.9311342796576152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 24.158968687057495 s\n",
      "Accuracy 0.9272181991076001 precision 0.9284609870830302 specificity 0.8840832487045518 recall 0.9272181991076001 f1 0.9277274582004063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 23.83500051498413 s\n",
      "Accuracy 0.9308755760368663 precision 0.9325434297140875 specificity 0.8955478792205112 recall 0.9308755760368663 f1 0.931511106245084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 24.12200093269348 s\n",
      "Accuracy 0.9272181991076001 precision 0.9287553376912223 specificity 0.8834026432715192 recall 0.9272181991076001 f1 0.9278330662439577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 23.86899995803833 s\n",
      "Accuracy 0.9269256089532587 precision 0.9283496978411906 specificity 0.8851528085333435 recall 0.9269256089532587 f1 0.9274973036302722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 24.437997579574585 s\n",
      "Accuracy 0.9286080023407213 precision 0.9302414975163886 specificity 0.889054101461881 recall 0.9286080023407213 f1 0.9292453711278782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 23.817996978759766 s\n",
      "Accuracy 0.9249506254114549 precision 0.9263993937957336 specificity 0.8842467632214176 recall 0.9249506254114549 f1 0.9255309775146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 23.907997131347656 s\n",
      "Accuracy 0.927876526954868 precision 0.9290930057993483 specificity 0.8802573618709232 recall 0.927876526954868 f1 0.9283820727019602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 24.030001401901245 s\n",
      "Accuracy 0.9289737400336479 precision 0.9307507817724511 specificity 0.891192169934393 recall 0.9289737400336479 f1 0.9296544012991929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 24.20899796485901 s\n",
      "Accuracy 0.9256821007973082 precision 0.9264599569845264 specificity 0.8783060943664277 recall 0.9256821007973082 f1 0.9260220597848462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 23.382000207901 s\n",
      "Accuracy 0.9261941335674054 precision 0.927380466900918 specificity 0.8820128276956573 recall 0.9261941335674054 f1 0.9266853306408454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 23.951000213623047 s\n",
      "Accuracy 0.9289737400336479 precision 0.9303255687456962 specificity 0.8897954928358361 recall 0.9289737400336479 f1 0.9295131622606139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 24.055999755859375 s\n",
      "Accuracy 0.9261941335674054 precision 0.9280919407676832 specificity 0.8869212353320813 recall 0.9261941335674054 f1 0.9269227311022641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 23.867998600006104 s\n",
      "Accuracy 0.9294126252651598 precision 0.9312839835673392 specificity 0.893761387571895 recall 0.9294126252651598 f1 0.9301177569380653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 23.664002895355225 s\n",
      "Accuracy 0.9275839368005266 precision 0.9286795506557688 specificity 0.8836990464019553 recall 0.9275839368005266 f1 0.9280403259209836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 23.717996835708618 s\n",
      "Accuracy 0.9285348548021359 precision 0.9298133330453642 specificity 0.8861504397425854 recall 0.9285348548021359 f1 0.9290545083909888\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 23.463999032974243 s\n",
      "Accuracy 0.9288274449564772 precision 0.9298135464001025 specificity 0.8811312005122819 recall 0.9288274449564772 f1 0.9292464203044802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 23.60599994659424 s\n",
      "Accuracy 0.9249506254114549 precision 0.9268885014209669 specificity 0.8858984135173199 recall 0.9249506254114549 f1 0.9256936696645095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 23.192513704299927 s\n",
      "Accuracy 0.9264867237217468 precision 0.9283447813908735 specificity 0.8863617531501572 recall 0.9264867237217468 f1 0.9272039145165375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 22.797709226608276 s\n",
      "Accuracy 0.9247311827956989 precision 0.926170536838915 specificity 0.8823016415671473 recall 0.9247311827956989 f1 0.9253117390065171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 23.638997793197632 s\n",
      "Accuracy 0.9281691171092092 precision 0.9300066029151086 specificity 0.8882494332212019 recall 0.9281691171092092 f1 0.9288765907665879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 23.527999877929688 s\n",
      "Accuracy 0.9281691171092092 precision 0.9303314473005686 specificity 0.8933302036133431 recall 0.9281691171092092 f1 0.9289673225091367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 23.53099822998047 s\n",
      "Accuracy 0.9282422646477946 precision 0.9296440642455399 specificity 0.8861009686452104 recall 0.9282422646477946 f1 0.9288054400737304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 24.31699800491333 s\n",
      "Accuracy 0.9292663301879892 precision 0.9313586437652179 specificity 0.895374496738111 recall 0.9292663301879892 f1 0.9300372435930907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 24.20400071144104 s\n",
      "Accuracy 0.9245848877185283 precision 0.9258491008972325 specificity 0.8803615640816761 recall 0.9245848877185283 f1 0.9251058921650139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 25.364999771118164 s\n",
      "Accuracy 0.9265598712603321 precision 0.9287029981630454 specificity 0.8888856037295257 recall 0.9265598712603321 f1 0.9273638278984258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 23.71699857711792 s\n",
      "Accuracy 0.927876526954868 precision 0.9290763850235186 specificity 0.8850834338893686 recall 0.927876526954868 f1 0.928369192304697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 24.68599772453308 s\n",
      "Accuracy 0.9283885597249653 precision 0.9298091900277564 specificity 0.8850687201515754 recall 0.9283885597249653 f1 0.9289603411623929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 25.330000400543213 s\n",
      "Accuracy 0.9260478384902348 precision 0.9274877778832904 specificity 0.8818148051511707 recall 0.9260478384902348 f1 0.9266305217080681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 24.478999376296997 s\n",
      "Accuracy 0.927657084339112 precision 0.9291194062357993 specificity 0.8895619852083302 recall 0.927657084339112 f1 0.9282339219176386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 23.99400019645691 s\n",
      "Accuracy 0.9250969204886256 precision 0.9262997283516109 specificity 0.8858309772288616 recall 0.9250969204886256 f1 0.9255875107804861\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 24.592000007629395 s\n",
      "Accuracy 0.9262672811059908 precision 0.9280085531409 specificity 0.8856166503141365 recall 0.9262672811059908 f1 0.9269467186737865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 25.19599938392639 s\n",
      "Accuracy 0.9224636090995538 precision 0.9248470754029378 specificity 0.8827819594886663 recall 0.9224636090995538 f1 0.9233587721239007\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 24.333303213119507 s\n",
      "Accuracy 0.9287542974178918 precision 0.9301199836998465 specificity 0.8864045995705709 recall 0.9287542974178918 f1 0.9293046050757626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 23.52399778366089 s\n",
      "Accuracy 0.9220978714066271 precision 0.9236860367556617 specificity 0.8758803467108603 recall 0.9220978714066271 f1 0.9227409623426617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 23.39511775970459 s\n",
      "Accuracy 0.9247311827956989 precision 0.9266693664292757 specificity 0.8836808715718727 recall 0.9247311827956989 f1 0.9254800790160379\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 24.529719829559326 s\n",
      "Accuracy 0.9259746909516495 precision 0.9274871817553765 specificity 0.885975531290583 recall 0.9259746909516495 f1 0.9265746871973057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 24.54753303527832 s\n",
      "Accuracy 0.9264867237217468 precision 0.927886979836387 specificity 0.8813983721882237 recall 0.9264867237217468 f1 0.927056315382552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 24.2868812084198 s\n",
      "Accuracy 0.9300709531124277 precision 0.9319724663485071 specificity 0.8924527208028963 recall 0.9300709531124277 f1 0.9307906774432732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 23.247687816619873 s\n",
      "Accuracy 0.9264867237217468 precision 0.9277769087573158 specificity 0.8783267504735973 recall 0.9264867237217468 f1 0.9270212702418011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 24.57200288772583 s\n",
      "Accuracy 0.9283154121863799 precision 0.9297495596416323 specificity 0.8910139616607979 recall 0.9283154121863799 f1 0.9288801769605006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 24.315452337265015 s\n",
      "Accuracy 0.9265598712603321 precision 0.9284227727532918 specificity 0.8841195755473116 recall 0.9265598712603321 f1 0.9272844618789725\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 23.6829993724823 s\n",
      "Accuracy 0.9298515104966718 precision 0.9313351006256724 specificity 0.8888726983055316 recall 0.9298515104966718 f1 0.9304391942180309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 23.81395435333252 s\n",
      "Accuracy 0.9253895106429668 precision 0.926656497748576 specificity 0.8817103681040688 recall 0.9253895106429668 f1 0.9259099776808934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 23.445261240005493 s\n",
      "Accuracy 0.9320459366542316 precision 0.9331464717849579 specificity 0.8915147594168303 recall 0.9320459366542316 f1 0.9324958947289111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 21.848000049591064 s\n",
      "Accuracy 0.9291931826494039 precision 0.9310095545206447 specificity 0.8915460681307291 recall 0.9291931826494039 f1 0.9298862113791794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 23.015480756759644 s\n",
      "Accuracy 0.9305098383439397 precision 0.9316773485836073 specificity 0.8896182612962842 recall 0.9305098383439397 f1 0.9309856810476244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 22.357169151306152 s\n",
      "Accuracy 0.9303635432667691 precision 0.9317051910369883 specificity 0.887727819591612 recall 0.9303635432667691 f1 0.9309042253665099\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 22.30215358734131 s\n",
      "Accuracy 0.9280959695706239 precision 0.9293988535146708 specificity 0.8874193760455403 recall 0.9280959695706239 f1 0.9286218242853352\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 22.44797706604004 s\n",
      "Accuracy 0.931241313729793 precision 0.9327185543338867 specificity 0.8912500962055632 recall 0.931241313729793 f1 0.9318232134978117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 22.208791494369507 s\n",
      "Accuracy 0.9254626581815522 precision 0.9277256447533203 specificity 0.8873448698854844 recall 0.9254626581815522 f1 0.9263086342944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 23.17692995071411 s\n",
      "Accuracy 0.9305098383439397 precision 0.9318087725951149 specificity 0.8936061359058121 recall 0.9305098383439397 f1 0.9310249814891056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 22.27605891227722 s\n",
      "Accuracy 0.9254626581815522 precision 0.926480910135107 specificity 0.8776553303048896 recall 0.9254626581815522 f1 0.9258962137391746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 22.992098331451416 s\n",
      "Accuracy 0.9253895106429668 precision 0.9263505319443448 specificity 0.8796257199698401 recall 0.9253895106429668 f1 0.9257992121794105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 21.97000551223755 s\n",
      "Accuracy 0.9263404286445761 precision 0.9278057456063342 specificity 0.8852659601520022 recall 0.9263404286445761 f1 0.9269258277101922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 22.785300970077515 s\n",
      "Accuracy 0.9277302318776973 precision 0.9292094060864646 specificity 0.883320465291129 recall 0.9277302318776973 f1 0.9283253137756765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 22.912998914718628 s\n",
      "Accuracy 0.9241460024870163 precision 0.9254925720269305 specificity 0.8811905616860244 recall 0.9241460024870163 f1 0.9246950721842074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 22.92499852180481 s\n",
      "Accuracy 0.9256089532587228 precision 0.9269100042882983 specificity 0.8821247023060392 recall 0.9256089532587228 f1 0.9261411995747291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 22.346998929977417 s\n",
      "Accuracy 0.9271450515690147 precision 0.9282975456516739 specificity 0.8844129779220306 recall 0.9271450515690147 f1 0.9276210622559368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 22.818915367126465 s\n",
      "Accuracy 0.9282422646477946 precision 0.9295309940456112 specificity 0.8884505537692828 recall 0.9282422646477946 f1 0.9287614294916696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 22.493144989013672 s\n",
      "Accuracy 0.9286811498793066 precision 0.9306363113651882 specificity 0.8880387357000312 recall 0.9286811498793066 f1 0.9294289752595007\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 22.653999090194702 s\n",
      "Accuracy 0.9268524614146734 precision 0.9275123290651158 specificity 0.8781909502829798 recall 0.9268524614146734 f1 0.9271455750402602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 22.882999897003174 s\n",
      "Accuracy 0.9231219369468218 precision 0.9247047429351012 specificity 0.8817300234061112 recall 0.9231219369468218 f1 0.9237524005041506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 22.4060001373291 s\n",
      "Accuracy 0.92048862555775 precision 0.9217495175359999 specificity 0.8736237961499854 recall 0.92048862555775 f1 0.9210157022229056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 22.402000188827515 s\n",
      "Accuracy 0.9287542974178918 precision 0.9296702912530476 specificity 0.8822801554742943 recall 0.9287542974178918 f1 0.9291454420309485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 22.81199836730957 s\n",
      "Accuracy 0.9297783629580865 precision 0.9315281325942322 specificity 0.8912521786334909 recall 0.9297783629580865 f1 0.9304508067317332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 22.441002130508423 s\n",
      "Accuracy 0.9248774778728696 precision 0.9262016755609762 specificity 0.8799410818667639 recall 0.9248774778728696 f1 0.9254210522272797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 22.026998043060303 s\n",
      "Accuracy 0.9258283958744788 precision 0.9275154094728306 specificity 0.8865443708514326 recall 0.9258283958744788 f1 0.9264867010586483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 22.5629985332489 s\n",
      "Accuracy 0.9244385926413576 precision 0.9249865377336283 specificity 0.8701154086731525 recall 0.9244385926413576 f1 0.9246887036113646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 22.624000310897827 s\n",
      "Accuracy 0.9272181991076001 precision 0.9281638422571168 specificity 0.883476885377807 recall 0.9272181991076001 f1 0.9276187764275526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 23.437999725341797 s\n",
      "Accuracy 0.9278033794162827 precision 0.9295775769505032 specificity 0.8902129791153169 recall 0.9278033794162827 f1 0.9284841535985704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 23.73499894142151 s\n",
      "Accuracy 0.9294126252651598 precision 0.9306456457325065 specificity 0.8866373727258072 recall 0.9294126252651598 f1 0.9299158279781254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 22.082997798919678 s\n",
      "Accuracy 0.930802428498281 precision 0.9315835074084683 specificity 0.8886812992172389 recall 0.930802428498281 f1 0.9311367618964872\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 22.193973064422607 s\n",
      "Accuracy 0.9286811498793066 precision 0.9305161989913152 specificity 0.8921396113011926 recall 0.9286811498793066 f1 0.9293779851994121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 22.45299792289734 s\n",
      "Accuracy 0.9294126252651598 precision 0.930774017540142 specificity 0.8896060467098948 recall 0.9294126252651598 f1 0.9299561166704595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 22.767517805099487 s\n",
      "Accuracy 0.927876526954868 precision 0.9293101858005707 specificity 0.8846181320638667 recall 0.927876526954868 f1 0.9284533268696511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 21.674428462982178 s\n",
      "Accuracy 0.9264135761831614 precision 0.9287025860757694 specificity 0.8891097325145308 recall 0.9264135761831614 f1 0.9272636480737162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 21.951998710632324 s\n",
      "Accuracy 0.9262672811059908 precision 0.927966250669536 specificity 0.881971101913875 recall 0.9262672811059908 f1 0.9269404955459313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 22.31200098991394 s\n",
      "Accuracy 0.9259746909516495 precision 0.9278866944436324 specificity 0.8840201176180164 recall 0.9259746909516495 f1 0.9267154257367048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 22.572998762130737 s\n",
      "Accuracy 0.9244385926413576 precision 0.9257188769893571 specificity 0.8808443615224785 recall 0.9244385926413576 f1 0.92496458102237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 21.64100193977356 s\n",
      "Accuracy 0.9294857728037451 precision 0.930579754232783 specificity 0.8854048962843349 recall 0.9294857728037451 f1 0.9299403238350199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 22.064998149871826 s\n",
      "Accuracy 0.9280959695706239 precision 0.9296656854639672 specificity 0.8925158710757758 recall 0.9280959695706239 f1 0.9287029638670082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 22.349998950958252 s\n",
      "Accuracy 0.927657084339112 precision 0.9285930935574995 specificity 0.8846846405537295 recall 0.927657084339112 f1 0.928052915796546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 22.053155660629272 s\n",
      "Accuracy 0.9267061663375027 precision 0.9281724827480378 specificity 0.8831947764075561 recall 0.9267061663375027 f1 0.9272961724288509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 22.29299807548523 s\n",
      "Accuracy 0.9284617072635506 precision 0.9296604314322673 specificity 0.8839045444937614 recall 0.9284617072635506 f1 0.9289560273070596\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 22.436546325683594 s\n",
      "Accuracy 0.9291931826494039 precision 0.93085078925659 specificity 0.8911460842029104 recall 0.9291931826494039 f1 0.9298343734730226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 22.31560230255127 s\n",
      "Accuracy 0.927437641723356 precision 0.9291130173885365 specificity 0.8872236413929452 recall 0.927437641723356 f1 0.928092206790135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 22.359906911849976 s\n",
      "Accuracy 0.9247311827956989 precision 0.926272393798638 specificity 0.8824975973971155 recall 0.9247311827956989 f1 0.9253471181253661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 22.330297708511353 s\n",
      "Accuracy 0.9267061663375027 precision 0.9284310537469449 specificity 0.8868430464810665 recall 0.9267061663375027 f1 0.9273775959076803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 22.179657220840454 s\n",
      "Accuracy 0.9283154121863799 precision 0.9299634973996732 specificity 0.8908001638717805 recall 0.9283154121863799 f1 0.9289532029899488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 22.309075832366943 s\n",
      "Accuracy 0.9248774778728696 precision 0.9265627050741977 specificity 0.8850668203786031 recall 0.9248774778728696 f1 0.9255375951339796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 21.82017970085144 s\n",
      "Accuracy 0.9296320678809158 precision 0.9315987628049348 specificity 0.8942355077561601 recall 0.9296320678809158 f1 0.9303670481374635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 22.221819400787354 s\n",
      "Accuracy 0.9275107892619413 precision 0.9288897967268519 specificity 0.8836541998400106 recall 0.9275107892619413 f1 0.9280696906779634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 22.377187967300415 s\n",
      "Accuracy 0.9302903957281837 precision 0.931529848938662 specificity 0.8869466291417945 recall 0.9302903957281837 f1 0.9307959699031333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 22.240015268325806 s\n",
      "Accuracy 0.926998756491844 precision 0.9286000533749135 specificity 0.8878410669687256 recall 0.926998756491844 f1 0.9276262186906842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 22.63714909553528 s\n",
      "Accuracy 0.9272181991076001 precision 0.92843279604876 specificity 0.8825939865882617 recall 0.9272181991076001 f1 0.9277194672970499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 22.059998512268066 s\n",
      "Accuracy 0.9259746909516495 precision 0.928340381499739 specificity 0.8905123410985484 recall 0.9259746909516495 f1 0.9268434172873828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 22.372997283935547 s\n",
      "Accuracy 0.9261209860288201 precision 0.9280584615133922 specificity 0.8883239911339156 recall 0.9261209860288201 f1 0.9268586956440772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 22.29598331451416 s\n",
      "Accuracy 0.9269256089532587 precision 0.9285138989909342 specificity 0.8863191066055089 recall 0.9269256089532587 f1 0.9275519404145061\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 22.533946990966797 s\n",
      "Accuracy 0.930144100651013 precision 0.9319576981712345 specificity 0.8919322308743052 recall 0.930144100651013 f1 0.9308364133921222\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 22.247886180877686 s\n",
      "Accuracy 0.9283885597249653 precision 0.9292594816726677 specificity 0.8831282826210762 recall 0.9283885597249653 f1 0.9287615366436481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 22.31228017807007 s\n",
      "Accuracy 0.927437641723356 precision 0.929168299129958 specificity 0.8872361453861655 recall 0.927437641723356 f1 0.9281109052711523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 22.665108919143677 s\n",
      "Accuracy 0.9256821007973082 precision 0.9277373391589677 specificity 0.8926625169869193 recall 0.9256821007973082 f1 0.926443584625161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 22.220051050186157 s\n",
      "Accuracy 0.9247311827956989 precision 0.9261143102589914 specificity 0.8809808508811738 recall 0.9247311827956989 f1 0.9252941212992011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 22.243592739105225 s\n",
      "Accuracy 0.9243654451027723 precision 0.9261427073274112 specificity 0.8834649330361249 recall 0.9243654451027723 f1 0.9250601257270664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 21.792019605636597 s\n",
      "Accuracy 0.9321190841928169 precision 0.933814720698764 specificity 0.8960745211999318 recall 0.9321190841928169 f1 0.9327640232700907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 22.99304986000061 s\n",
      "Accuracy 0.9255358057201375 precision 0.9271733438619303 specificity 0.8860192744869131 recall 0.9255358057201375 f1 0.9261781870282123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 22.9350004196167 s\n",
      "Accuracy 0.9297052154195011 precision 0.9313272454294043 specificity 0.891363082074542 recall 0.9297052154195011 f1 0.9303345135116486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 22.35006332397461 s\n",
      "Accuracy 0.9273644941847707 precision 0.9287416500073937 specificity 0.8868354275112702 recall 0.9273644941847707 f1 0.9279169488073395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 22.409014463424683 s\n",
      "Accuracy 0.9299978055738425 precision 0.931142138251012 specificity 0.8847104698700194 recall 0.9299978055738425 f1 0.9304719789199312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 22.04736876487732 s\n",
      "Accuracy 0.9255358057201375 precision 0.9275273500115466 specificity 0.8866803172790608 recall 0.9255358057201375 f1 0.9262952469633007\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 22.591426134109497 s\n",
      "Accuracy 0.9223904615609685 precision 0.9237164981351897 specificity 0.8759707335487558 recall 0.9223904615609685 f1 0.9229392401830693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 22.145161151885986 s\n",
      "Accuracy 0.9283885597249653 precision 0.9301446734303396 specificity 0.8889478857430612 recall 0.9283885597249653 f1 0.9290672837738249\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 22.430501699447632 s\n",
      "Accuracy 0.9255358057201375 precision 0.9271190383577768 specificity 0.8831177116328032 recall 0.9255358057201375 f1 0.9261658459997097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 22.36200499534607 s\n",
      "Accuracy 0.9283885597249653 precision 0.9296182567414993 specificity 0.8876492315001279 recall 0.9283885597249653 f1 0.9288882734861067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 23.037734985351562 s\n",
      "Accuracy 0.9273644941847707 precision 0.9288724504744745 specificity 0.8867398456880369 recall 0.9273644941847707 f1 0.9279626791833705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 22.069814205169678 s\n",
      "Accuracy 0.9277302318776973 precision 0.929076149165789 specificity 0.8834918074824549 recall 0.9277302318776973 f1 0.928277767498479\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 22.34227681159973 s\n",
      "Accuracy 0.9270719040304294 precision 0.9282351832132623 specificity 0.8861476880358569 recall 0.9270719040304294 f1 0.9275492331543291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 22.290998935699463 s\n",
      "Accuracy 0.9294857728037451 precision 0.9304910298691877 specificity 0.8850459873733008 recall 0.9294857728037451 f1 0.9299079411423868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 21.930000066757202 s\n",
      "Accuracy 0.926998756491844 precision 0.928160101618537 specificity 0.8836378919652614 recall 0.926998756491844 f1 0.9274790047956801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 22.033998250961304 s\n",
      "Accuracy 0.9295589203423305 precision 0.9315255256258601 specificity 0.8959556870946329 recall 0.9295589203423305 f1 0.9302882759955281\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "split_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "smote_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, (split_seed, smote_seed) in enumerate(zip(split_seeds, smote_seeds)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=split_seed)\n",
    "    smote = SMOTE(random_state=smote_seed, n_jobs=THREADS_TO_USE)\n",
    "    x_smote, y_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_smote, y_smote)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(split_seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.931022     0.887998   0.931886  0.931022  0.931388\n1  0.930510     0.893848   0.932220  0.930510  0.931163\n2  0.926560     0.877428   0.927373  0.926560  0.926915\n3  0.926340     0.883529   0.927680  0.926340  0.926885\n4  0.925390     0.885451   0.927202  0.925390  0.926092\n5  0.926999     0.884193   0.928324  0.926999  0.927537\n6  0.926487     0.884909   0.928121  0.926487  0.927131\n7  0.928754     0.887158   0.929935  0.928754  0.929238\n8  0.928315     0.880302   0.929318  0.928315  0.928741\n9  0.924073     0.883001   0.926086  0.924073  0.924848",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.931022</td>\n      <td>0.887998</td>\n      <td>0.931886</td>\n      <td>0.931022</td>\n      <td>0.931388</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.930510</td>\n      <td>0.893848</td>\n      <td>0.932220</td>\n      <td>0.930510</td>\n      <td>0.931163</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.926560</td>\n      <td>0.877428</td>\n      <td>0.927373</td>\n      <td>0.926560</td>\n      <td>0.926915</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.926340</td>\n      <td>0.883529</td>\n      <td>0.927680</td>\n      <td>0.926340</td>\n      <td>0.926885</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.925390</td>\n      <td>0.885451</td>\n      <td>0.927202</td>\n      <td>0.925390</td>\n      <td>0.926092</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.926999</td>\n      <td>0.884193</td>\n      <td>0.928324</td>\n      <td>0.926999</td>\n      <td>0.927537</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.926487</td>\n      <td>0.884909</td>\n      <td>0.928121</td>\n      <td>0.926487</td>\n      <td>0.927131</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.928754</td>\n      <td>0.887158</td>\n      <td>0.929935</td>\n      <td>0.928754</td>\n      <td>0.929238</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.928315</td>\n      <td>0.880302</td>\n      <td>0.929318</td>\n      <td>0.928315</td>\n      <td>0.928741</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.924073</td>\n      <td>0.883001</td>\n      <td>0.926086</td>\n      <td>0.924073</td>\n      <td>0.924848</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.9272688903518397\n",
      "Precision 0.9287637909239836\n",
      "Specificity 0.8860215807553363\n",
      "Recall 0.9272688903518397\n",
      "F1 0.9278590988239862\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_8beats_smote_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}