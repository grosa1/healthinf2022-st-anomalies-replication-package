{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 8 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1  \\\n0  e0106  30.571581  30.571114  30.597163   8.654545  1.254944  0.902949   \n1  e0106  35.327463  37.090233  36.619925  10.318908  1.501561  0.936195   \n2  e0106  33.754220  34.253945  34.112950   9.653801  1.420377  0.922050   \n3  e0106  33.428166  32.277378  32.154651   9.225828  1.332695  0.898518   \n4  e0106  34.438584  33.565638  33.382364   9.589036  1.426830  0.886530   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.773465 -1.399254 -0.734867  ... -0.052333  0.042084 -0.051954  0.052820   \n1 -0.694743 -1.301387 -0.880195  ... -0.025711  0.004880 -0.014158  0.033816   \n2 -0.707779 -1.271389 -0.778260  ... -0.041095  0.024671 -0.028207  0.045623   \n3 -0.728415 -1.302251 -0.708089  ... -0.053417  0.034100 -0.041100  0.034451   \n4 -0.727896 -1.310174 -0.910833  ... -0.077430  0.064301 -0.063539  0.066193   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.078516  0.018113 -0.033035 -0.008121 -0.004387    NSR  \n1 -0.052615 -0.010039 -0.020460 -0.003424 -0.010776    NSR  \n2 -0.069928 -0.007982 -0.010177 -0.011244 -0.007525    NSR  \n3 -0.060591 -0.005673 -0.010582 -0.020471  0.001472    NSR  \n4 -0.087852  0.018333 -0.028678 -0.022301  0.009486    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>30.571581</td>\n      <td>30.571114</td>\n      <td>30.597163</td>\n      <td>8.654545</td>\n      <td>1.254944</td>\n      <td>0.902949</td>\n      <td>-0.773465</td>\n      <td>-1.399254</td>\n      <td>-0.734867</td>\n      <td>...</td>\n      <td>-0.052333</td>\n      <td>0.042084</td>\n      <td>-0.051954</td>\n      <td>0.052820</td>\n      <td>-0.078516</td>\n      <td>0.018113</td>\n      <td>-0.033035</td>\n      <td>-0.008121</td>\n      <td>-0.004387</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>35.327463</td>\n      <td>37.090233</td>\n      <td>36.619925</td>\n      <td>10.318908</td>\n      <td>1.501561</td>\n      <td>0.936195</td>\n      <td>-0.694743</td>\n      <td>-1.301387</td>\n      <td>-0.880195</td>\n      <td>...</td>\n      <td>-0.025711</td>\n      <td>0.004880</td>\n      <td>-0.014158</td>\n      <td>0.033816</td>\n      <td>-0.052615</td>\n      <td>-0.010039</td>\n      <td>-0.020460</td>\n      <td>-0.003424</td>\n      <td>-0.010776</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>33.754220</td>\n      <td>34.253945</td>\n      <td>34.112950</td>\n      <td>9.653801</td>\n      <td>1.420377</td>\n      <td>0.922050</td>\n      <td>-0.707779</td>\n      <td>-1.271389</td>\n      <td>-0.778260</td>\n      <td>...</td>\n      <td>-0.041095</td>\n      <td>0.024671</td>\n      <td>-0.028207</td>\n      <td>0.045623</td>\n      <td>-0.069928</td>\n      <td>-0.007982</td>\n      <td>-0.010177</td>\n      <td>-0.011244</td>\n      <td>-0.007525</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>33.428166</td>\n      <td>32.277378</td>\n      <td>32.154651</td>\n      <td>9.225828</td>\n      <td>1.332695</td>\n      <td>0.898518</td>\n      <td>-0.728415</td>\n      <td>-1.302251</td>\n      <td>-0.708089</td>\n      <td>...</td>\n      <td>-0.053417</td>\n      <td>0.034100</td>\n      <td>-0.041100</td>\n      <td>0.034451</td>\n      <td>-0.060591</td>\n      <td>-0.005673</td>\n      <td>-0.010582</td>\n      <td>-0.020471</td>\n      <td>0.001472</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>34.438584</td>\n      <td>33.565638</td>\n      <td>33.382364</td>\n      <td>9.589036</td>\n      <td>1.426830</td>\n      <td>0.886530</td>\n      <td>-0.727896</td>\n      <td>-1.310174</td>\n      <td>-0.910833</td>\n      <td>...</td>\n      <td>-0.077430</td>\n      <td>0.064301</td>\n      <td>-0.063539</td>\n      <td>0.066193</td>\n      <td>-0.087852</td>\n      <td>0.018333</td>\n      <td>-0.028678</td>\n      <td>-0.022301</td>\n      <td>0.009486</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_8beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    52426\nST     15929\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.232673  0.111713  0.079107  0.076764  0.077147 -0.018860   \ndw_2    0.232673  1.000000  0.839282  0.452814  0.160598  0.424152 -0.484394   \ndw_3    0.111713  0.839282  1.000000  0.631576  0.240584  0.301445 -0.535593   \ndw_4    0.079107  0.452814  0.631576  1.000000  0.895025  0.016860 -0.237619   \ndw_5    0.076764  0.160598  0.240584  0.895025  1.000000 -0.105960 -0.011988   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.039241  0.029218  0.051187  0.042171  0.016035 -0.094790  0.068312   \ncfr_13 -0.027948  0.115506  0.045371  0.026140  0.013783  0.077604 -0.004769   \ncfr_14 -0.044903 -0.000752 -0.026800 -0.032931 -0.034165  0.032269  0.017775   \ncfr_15 -0.065581 -0.115788 -0.130477 -0.089245 -0.041855  0.009040  0.083235   \ncfr_16 -0.044688 -0.079295 -0.049044 -0.033579 -0.018000  0.054551 -0.035391   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.030559  0.040220 -0.014666  ... -0.053028 -0.055461 -0.025675   \ndw_2   -0.404156  0.100065  0.435652  ... -0.136686  0.140104  0.232989   \ndw_3   -0.534332 -0.030329  0.564342  ... -0.206789  0.121560  0.266346   \ndw_4   -0.260776 -0.029358  0.299563  ... -0.147248  0.048851  0.116574   \ndw_5   -0.035024 -0.012480  0.061799  ... -0.066765  0.004155  0.014207   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.129263  0.122377 -0.090957  ... -0.127261 -0.207625 -0.097674   \ncfr_13  0.006963  0.049874  0.008203  ...  0.128357  0.032112 -0.217503   \ncfr_14  0.034991  0.012523 -0.020623  ...  0.096622  0.214725  0.044225   \ncfr_15  0.080419 -0.058850 -0.098386  ...  0.258472  0.163393 -0.078272   \ncfr_16 -0.001319  0.067956  0.036802  ...  0.240666  0.138617  0.171483   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.018685 -0.009704 -0.039241 -0.027948 -0.044903 -0.065581 -0.044688  \ndw_2    0.166906  0.045325  0.029218  0.115506 -0.000752 -0.115788 -0.079295  \ndw_3    0.117884 -0.049549  0.051187  0.045371 -0.026800 -0.130477 -0.049044  \ndw_4    0.042862 -0.044403  0.042171  0.026140 -0.032931 -0.089245 -0.033579  \ndw_5    0.013282 -0.012686  0.016035  0.013783 -0.034165 -0.041855 -0.018000  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.019114  0.057081  1.000000  0.003281 -0.017734 -0.318789 -0.208539  \ncfr_13 -0.271096 -0.046139  0.003281  1.000000  0.186633  0.097077 -0.171867  \ncfr_14 -0.177405 -0.291133 -0.017734  0.186633  1.000000  0.157260 -0.146906  \ncfr_15 -0.146256 -0.095566 -0.318789  0.097077  0.157260  1.000000  0.229510  \ncfr_16  0.114201 -0.004097 -0.208539 -0.171867 -0.146906  0.229510  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.232673</td>\n      <td>0.111713</td>\n      <td>0.079107</td>\n      <td>0.076764</td>\n      <td>0.077147</td>\n      <td>-0.018860</td>\n      <td>0.030559</td>\n      <td>0.040220</td>\n      <td>-0.014666</td>\n      <td>...</td>\n      <td>-0.053028</td>\n      <td>-0.055461</td>\n      <td>-0.025675</td>\n      <td>-0.018685</td>\n      <td>-0.009704</td>\n      <td>-0.039241</td>\n      <td>-0.027948</td>\n      <td>-0.044903</td>\n      <td>-0.065581</td>\n      <td>-0.044688</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.232673</td>\n      <td>1.000000</td>\n      <td>0.839282</td>\n      <td>0.452814</td>\n      <td>0.160598</td>\n      <td>0.424152</td>\n      <td>-0.484394</td>\n      <td>-0.404156</td>\n      <td>0.100065</td>\n      <td>0.435652</td>\n      <td>...</td>\n      <td>-0.136686</td>\n      <td>0.140104</td>\n      <td>0.232989</td>\n      <td>0.166906</td>\n      <td>0.045325</td>\n      <td>0.029218</td>\n      <td>0.115506</td>\n      <td>-0.000752</td>\n      <td>-0.115788</td>\n      <td>-0.079295</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.111713</td>\n      <td>0.839282</td>\n      <td>1.000000</td>\n      <td>0.631576</td>\n      <td>0.240584</td>\n      <td>0.301445</td>\n      <td>-0.535593</td>\n      <td>-0.534332</td>\n      <td>-0.030329</td>\n      <td>0.564342</td>\n      <td>...</td>\n      <td>-0.206789</td>\n      <td>0.121560</td>\n      <td>0.266346</td>\n      <td>0.117884</td>\n      <td>-0.049549</td>\n      <td>0.051187</td>\n      <td>0.045371</td>\n      <td>-0.026800</td>\n      <td>-0.130477</td>\n      <td>-0.049044</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.079107</td>\n      <td>0.452814</td>\n      <td>0.631576</td>\n      <td>1.000000</td>\n      <td>0.895025</td>\n      <td>0.016860</td>\n      <td>-0.237619</td>\n      <td>-0.260776</td>\n      <td>-0.029358</td>\n      <td>0.299563</td>\n      <td>...</td>\n      <td>-0.147248</td>\n      <td>0.048851</td>\n      <td>0.116574</td>\n      <td>0.042862</td>\n      <td>-0.044403</td>\n      <td>0.042171</td>\n      <td>0.026140</td>\n      <td>-0.032931</td>\n      <td>-0.089245</td>\n      <td>-0.033579</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.076764</td>\n      <td>0.160598</td>\n      <td>0.240584</td>\n      <td>0.895025</td>\n      <td>1.000000</td>\n      <td>-0.105960</td>\n      <td>-0.011988</td>\n      <td>-0.035024</td>\n      <td>-0.012480</td>\n      <td>0.061799</td>\n      <td>...</td>\n      <td>-0.066765</td>\n      <td>0.004155</td>\n      <td>0.014207</td>\n      <td>0.013282</td>\n      <td>-0.012686</td>\n      <td>0.016035</td>\n      <td>0.013783</td>\n      <td>-0.034165</td>\n      <td>-0.041855</td>\n      <td>-0.018000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.039241</td>\n      <td>0.029218</td>\n      <td>0.051187</td>\n      <td>0.042171</td>\n      <td>0.016035</td>\n      <td>-0.094790</td>\n      <td>0.068312</td>\n      <td>0.129263</td>\n      <td>0.122377</td>\n      <td>-0.090957</td>\n      <td>...</td>\n      <td>-0.127261</td>\n      <td>-0.207625</td>\n      <td>-0.097674</td>\n      <td>0.019114</td>\n      <td>0.057081</td>\n      <td>1.000000</td>\n      <td>0.003281</td>\n      <td>-0.017734</td>\n      <td>-0.318789</td>\n      <td>-0.208539</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.027948</td>\n      <td>0.115506</td>\n      <td>0.045371</td>\n      <td>0.026140</td>\n      <td>0.013783</td>\n      <td>0.077604</td>\n      <td>-0.004769</td>\n      <td>0.006963</td>\n      <td>0.049874</td>\n      <td>0.008203</td>\n      <td>...</td>\n      <td>0.128357</td>\n      <td>0.032112</td>\n      <td>-0.217503</td>\n      <td>-0.271096</td>\n      <td>-0.046139</td>\n      <td>0.003281</td>\n      <td>1.000000</td>\n      <td>0.186633</td>\n      <td>0.097077</td>\n      <td>-0.171867</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.044903</td>\n      <td>-0.000752</td>\n      <td>-0.026800</td>\n      <td>-0.032931</td>\n      <td>-0.034165</td>\n      <td>0.032269</td>\n      <td>0.017775</td>\n      <td>0.034991</td>\n      <td>0.012523</td>\n      <td>-0.020623</td>\n      <td>...</td>\n      <td>0.096622</td>\n      <td>0.214725</td>\n      <td>0.044225</td>\n      <td>-0.177405</td>\n      <td>-0.291133</td>\n      <td>-0.017734</td>\n      <td>0.186633</td>\n      <td>1.000000</td>\n      <td>0.157260</td>\n      <td>-0.146906</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.065581</td>\n      <td>-0.115788</td>\n      <td>-0.130477</td>\n      <td>-0.089245</td>\n      <td>-0.041855</td>\n      <td>0.009040</td>\n      <td>0.083235</td>\n      <td>0.080419</td>\n      <td>-0.058850</td>\n      <td>-0.098386</td>\n      <td>...</td>\n      <td>0.258472</td>\n      <td>0.163393</td>\n      <td>-0.078272</td>\n      <td>-0.146256</td>\n      <td>-0.095566</td>\n      <td>-0.318789</td>\n      <td>0.097077</td>\n      <td>0.157260</td>\n      <td>1.000000</td>\n      <td>0.229510</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.044688</td>\n      <td>-0.079295</td>\n      <td>-0.049044</td>\n      <td>-0.033579</td>\n      <td>-0.018000</td>\n      <td>0.054551</td>\n      <td>-0.035391</td>\n      <td>-0.001319</td>\n      <td>0.067956</td>\n      <td>0.036802</td>\n      <td>...</td>\n      <td>0.240666</td>\n      <td>0.138617</td>\n      <td>0.171483</td>\n      <td>0.114201</td>\n      <td>-0.004097</td>\n      <td>-0.208539</td>\n      <td>-0.171867</td>\n      <td>-0.146906</td>\n      <td>0.229510</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows Ã— 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_130', 'fft_198', 'cfr_16', 'fft_251', 'fft_192', 'fft_147', 'fft_196', 'fft_243', 'fft_186', 'fft_172', 'fft_226', 'fft_149', 'fft_197', 'fft_212', 'mfw_11', 'fft_220', 'fft_161', 'fft_247', 'fft_230', 'fft_174', 'fft_253', 'fft_164', 'fft_170', 'fft_213', 'fft_215', 'fft_141', 'fft_254', 'fft_225', 'fft_203', 'fft_157', 'fft_201', 'fft_219', 'fft_190', 'fft_206', 'fft_224', 'fft_248', 'fft_181', 'fft_188', 'fft_202', 'fft_189', 'fft_256', 'fft_144', 'fft_231', 'fft_223', 'fft_136', 'fft_210', 'fft_182', 'fft_155', 'fft_169', 'fft_175', 'fft_236', 'fft_221', 'fft_167', 'fft_249', 'fft_162', 'fft_232', 'fft_204', 'fft_205', 'fft_139', 'fft_131', 'fft_207', 'fft_239', 'fft_252', 'fft_233', 'fft_244', 'fft_235', 'fft_176', 'fft_165', 'fft_234', 'fft_216', 'fft_222', 'fft_199', 'fft_178', 'fft_154', 'fft_134', 'fft_238', 'fft_168', 'fft_143', 'fft_193', 'fft_237', 'fft_214', 'fft_242', 'fft_166', 'fft_145', 'fft_227', 'fft_184', 'fft_138', 'fft_185', 'fft_132', 'fft_191', 'fft_240', 'fft_245', 'fft_163', 'fft_183', 'fft_158', 'fft_173', 'fft_148', 'fft_152', 'fft_156', 'fft_159', 'fft_246', 'fft_153', 'fft_218', 'fft_146', 'fft_200', 'fft_151', 'fft_241', 'fft_135', 'fft_150', 'fft_250', 'fft_177', 'fft_228', 'fft_195', 'fft_137', 'fft_140', 'fft_171', 'fft_208', 'fft_142', 'fft_217', 'fft_194', 'fft_255', 'fft_209', 'fft_133', 'fft_229', 'fft_179', 'fft_211', 'fft_160', 'fft_187', 'fft_180'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "mfw_5\n",
      "mfw_6\n",
      "mfw_7\n",
      "mfw_8\n",
      "mfw_9\n",
      "mfw_10\n",
      "mfw_12\n",
      "mfw_13\n",
      "mfw_14\n",
      "mfw_15\n",
      "mfw_16\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_24\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 77\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1     mfw_2  \\\n0  30.571581  30.571114  30.597163   8.654545  1.254944  0.902949 -0.773465   \n1  35.327463  37.090233  36.619925  10.318908  1.501561  0.936195 -0.694743   \n2  33.754220  34.253945  34.112950   9.653801  1.420377  0.922050 -0.707779   \n3  33.428166  32.277378  32.154651   9.225828  1.332695  0.898518 -0.728415   \n4  34.438584  33.565638  33.382364   9.589036  1.426830  0.886530 -0.727896   \n\n      mfw_3     mfw_4      mfw_5  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -1.399254 -0.734867  12.762118  ...  0.012196  0.047766 -0.052333  0.042084   \n1 -1.301387 -0.880195  10.573212  ...  0.022624  0.032716 -0.025711  0.004880   \n2 -1.271389 -0.778260  10.515795  ...  0.010279  0.036796 -0.041095  0.024671   \n3 -1.302251 -0.708089  11.496901  ...  0.005352  0.048697 -0.053417  0.034100   \n4 -1.310174 -0.910833  10.732432  ... -0.003147  0.052752 -0.077430  0.064301   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.051954  0.052820 -0.078516  0.018113 -0.033035 -0.008121  \n1 -0.014158  0.033816 -0.052615 -0.010039 -0.020460 -0.003424  \n2 -0.028207  0.045623 -0.069928 -0.007982 -0.010177 -0.011244  \n3 -0.041100  0.034451 -0.060591 -0.005673 -0.010582 -0.020471  \n4 -0.063539  0.066193 -0.087852  0.018333 -0.028678 -0.022301  \n\n[5 rows x 77 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30.571581</td>\n      <td>30.571114</td>\n      <td>30.597163</td>\n      <td>8.654545</td>\n      <td>1.254944</td>\n      <td>0.902949</td>\n      <td>-0.773465</td>\n      <td>-1.399254</td>\n      <td>-0.734867</td>\n      <td>12.762118</td>\n      <td>...</td>\n      <td>0.012196</td>\n      <td>0.047766</td>\n      <td>-0.052333</td>\n      <td>0.042084</td>\n      <td>-0.051954</td>\n      <td>0.052820</td>\n      <td>-0.078516</td>\n      <td>0.018113</td>\n      <td>-0.033035</td>\n      <td>-0.008121</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35.327463</td>\n      <td>37.090233</td>\n      <td>36.619925</td>\n      <td>10.318908</td>\n      <td>1.501561</td>\n      <td>0.936195</td>\n      <td>-0.694743</td>\n      <td>-1.301387</td>\n      <td>-0.880195</td>\n      <td>10.573212</td>\n      <td>...</td>\n      <td>0.022624</td>\n      <td>0.032716</td>\n      <td>-0.025711</td>\n      <td>0.004880</td>\n      <td>-0.014158</td>\n      <td>0.033816</td>\n      <td>-0.052615</td>\n      <td>-0.010039</td>\n      <td>-0.020460</td>\n      <td>-0.003424</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33.754220</td>\n      <td>34.253945</td>\n      <td>34.112950</td>\n      <td>9.653801</td>\n      <td>1.420377</td>\n      <td>0.922050</td>\n      <td>-0.707779</td>\n      <td>-1.271389</td>\n      <td>-0.778260</td>\n      <td>10.515795</td>\n      <td>...</td>\n      <td>0.010279</td>\n      <td>0.036796</td>\n      <td>-0.041095</td>\n      <td>0.024671</td>\n      <td>-0.028207</td>\n      <td>0.045623</td>\n      <td>-0.069928</td>\n      <td>-0.007982</td>\n      <td>-0.010177</td>\n      <td>-0.011244</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33.428166</td>\n      <td>32.277378</td>\n      <td>32.154651</td>\n      <td>9.225828</td>\n      <td>1.332695</td>\n      <td>0.898518</td>\n      <td>-0.728415</td>\n      <td>-1.302251</td>\n      <td>-0.708089</td>\n      <td>11.496901</td>\n      <td>...</td>\n      <td>0.005352</td>\n      <td>0.048697</td>\n      <td>-0.053417</td>\n      <td>0.034100</td>\n      <td>-0.041100</td>\n      <td>0.034451</td>\n      <td>-0.060591</td>\n      <td>-0.005673</td>\n      <td>-0.010582</td>\n      <td>-0.020471</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34.438584</td>\n      <td>33.565638</td>\n      <td>33.382364</td>\n      <td>9.589036</td>\n      <td>1.426830</td>\n      <td>0.886530</td>\n      <td>-0.727896</td>\n      <td>-1.310174</td>\n      <td>-0.910833</td>\n      <td>10.732432</td>\n      <td>...</td>\n      <td>-0.003147</td>\n      <td>0.052752</td>\n      <td>-0.077430</td>\n      <td>0.064301</td>\n      <td>-0.063539</td>\n      <td>0.066193</td>\n      <td>-0.087852</td>\n      <td>0.018333</td>\n      <td>-0.028678</td>\n      <td>-0.022301</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 77 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 15.877999305725098 s\n",
      "Accuracy 0.9271450515690147 precision 0.926877664143614 specificity 0.8033881098380605 recall 0.9271450515690147 f1 0.9243896616004199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 15.544999122619629 s\n",
      "Accuracy 0.9303635432667691 precision 0.9300234607525437 specificity 0.819016386081463 recall 0.9303635432667691 f1 0.9280663992890682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 16.323999404907227 s\n",
      "Accuracy 0.9263404286445761 precision 0.9259592053676553 specificity 0.8052780984974423 recall 0.9263404286445761 f1 0.9236521864329281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 16.147000789642334 s\n",
      "Accuracy 0.9270719040304294 precision 0.926478743693992 specificity 0.8038295553905483 recall 0.9270719040304294 f1 0.9244356816267241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 15.966000080108643 s\n",
      "Accuracy 0.9270719040304294 precision 0.9266383413294788 specificity 0.8049615239102834 recall 0.9270719040304294 f1 0.9244080593717537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 15.498999834060669 s\n",
      "Accuracy 0.9273644941847707 precision 0.9268111792893707 specificity 0.8113701294921025 recall 0.9273644941847707 f1 0.9249060149642833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 15.568001508712769 s\n",
      "Accuracy 0.9314607563455489 precision 0.9315875580028411 specificity 0.8112848361860726 recall 0.9314607563455489 f1 0.9288675146288358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 16.21699810028076 s\n",
      "Accuracy 0.9268524614146734 precision 0.9264973911305575 specificity 0.8029027816760453 recall 0.9268524614146734 f1 0.9241069905314983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 15.006000280380249 s\n",
      "Accuracy 0.9242191500256016 precision 0.9237949178070334 specificity 0.7941244743654722 recall 0.9242191500256016 f1 0.9212147488707373\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 14.875997066497803 s\n",
      "Accuracy 0.9295589203423305 precision 0.9290995953663312 specificity 0.8142122617466087 recall 0.9295589203423305 f1 0.9271757500617601\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 15.270998239517212 s\n",
      "Accuracy 0.9282422646477946 precision 0.9282277462215904 specificity 0.8093333688791784 recall 0.9282422646477946 f1 0.9255777567368201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 14.766000509262085 s\n",
      "Accuracy 0.9227561992538951 precision 0.922534316500164 specificity 0.7938027113137982 recall 0.9227561992538951 f1 0.9196453455595593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 14.777002573013306 s\n",
      "Accuracy 0.9305829858825251 precision 0.9297980623911003 specificity 0.8105294016116923 recall 0.9305829858825251 f1 0.9282553686584217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 14.68799877166748 s\n",
      "Accuracy 0.9308755760368663 precision 0.9305347069414146 specificity 0.8144798651779483 recall 0.9308755760368663 f1 0.9284833404389936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 15.011999607086182 s\n",
      "Accuracy 0.9253895106429668 precision 0.9250353462091908 specificity 0.7984934924816816 recall 0.9253895106429668 f1 0.922501214765182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 14.948999404907227 s\n",
      "Accuracy 0.9265598712603321 precision 0.9257674039090676 specificity 0.8053160860660832 recall 0.9265598712603321 f1 0.9240262521836615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 15.035997867584229 s\n",
      "Accuracy 0.930802428498281 precision 0.9310205006777783 specificity 0.8138193719043649 recall 0.930802428498281 f1 0.9282293574442382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 15.330999851226807 s\n",
      "Accuracy 0.9270719040304294 precision 0.9265901423180618 specificity 0.8073421278412117 recall 0.9270719040304294 f1 0.9244833883957165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 15.223000764846802 s\n",
      "Accuracy 0.9256821007973082 precision 0.925779208290972 specificity 0.8020844440722869 recall 0.9256821007973082 f1 0.9227551926519211\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 14.931004047393799 s\n",
      "Accuracy 0.9264867237217468 precision 0.9261566215215528 specificity 0.8004671842447885 recall 0.9264867237217468 f1 0.9236645714934512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 14.944998264312744 s\n",
      "Accuracy 0.9263404286445761 precision 0.925862814368486 specificity 0.8016628301430655 recall 0.9263404286445761 f1 0.9235940391311663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 14.706000328063965 s\n",
      "Accuracy 0.9261209860288201 precision 0.9255150539639353 specificity 0.80654816091838 recall 0.9261209860288201 f1 0.9235383979000187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 14.99500036239624 s\n",
      "Accuracy 0.9289737400336479 precision 0.928539300932442 specificity 0.8053238356579584 recall 0.9289737400336479 f1 0.9263587974614081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 14.7989981174469 s\n",
      "Accuracy 0.9272181991076001 precision 0.927001244104808 specificity 0.8071802150237708 recall 0.9272181991076001 f1 0.9245418089143039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 14.8340003490448 s\n",
      "Accuracy 0.9287542974178918 precision 0.9281389475668361 specificity 0.8094813456765552 recall 0.9287542974178918 f1 0.9262988814840989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 14.76200008392334 s\n",
      "Accuracy 0.9285348548021359 precision 0.9279742590164437 specificity 0.8076969206796365 recall 0.9285348548021359 f1 0.9260119146333856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 14.803999662399292 s\n",
      "Accuracy 0.9253163631043816 precision 0.9248913342133877 specificity 0.8045209337023101 recall 0.9253163631043816 f1 0.9226033983620672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 14.611999750137329 s\n",
      "Accuracy 0.9286811498793066 precision 0.9283334222555003 specificity 0.8093463674837927 recall 0.9286811498793066 f1 0.9261279041336349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 15.006000757217407 s\n",
      "Accuracy 0.9278033794162827 precision 0.9276446256046621 specificity 0.8044101417018673 recall 0.9278033794162827 f1 0.9250533938283376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 14.615999460220337 s\n",
      "Accuracy 0.9285348548021359 precision 0.9281190341364941 specificity 0.8092199388748454 recall 0.9285348548021359 f1 0.9259983117447914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 14.969000339508057 s\n",
      "Accuracy 0.9272181991076001 precision 0.927474792191092 specificity 0.798971649260816 recall 0.9272181991076001 f1 0.9242039429711815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 14.81399917602539 s\n",
      "Accuracy 0.9294857728037451 precision 0.9293284341681424 specificity 0.8081813496407078 recall 0.9294857728037451 f1 0.9268611434859326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 14.736999750137329 s\n",
      "Accuracy 0.9289737400336479 precision 0.9285908024826403 specificity 0.8108243438585653 recall 0.9289737400336479 f1 0.9264731830224056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 14.916002750396729 s\n",
      "Accuracy 0.9257552483358935 precision 0.925356116665536 specificity 0.8121047938530859 recall 0.9257552483358935 f1 0.923232745348335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 14.92599630355835 s\n",
      "Accuracy 0.9264867237217468 precision 0.9258361620356249 specificity 0.8075901718964756 recall 0.9264867237217468 f1 0.9239538918189153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 15.207000255584717 s\n",
      "Accuracy 0.9283885597249653 precision 0.9282721860851203 specificity 0.8113727816007973 recall 0.9283885597249653 f1 0.9258057681568542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 14.712999820709229 s\n",
      "Accuracy 0.9305098383439397 precision 0.9301433227805497 specificity 0.8183031956717367 recall 0.9305098383439397 f1 0.9282075594619043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 14.79499864578247 s\n",
      "Accuracy 0.9286080023407213 precision 0.9283245384451713 specificity 0.8102256214774433 recall 0.9286080023407213 f1 0.9260536131321949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 14.762999773025513 s\n",
      "Accuracy 0.9281691171092092 precision 0.9282856607868655 specificity 0.807682084970063 recall 0.9281691171092092 f1 0.9254263540197921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 14.987000465393066 s\n",
      "Accuracy 0.9262672811059908 precision 0.9261145043916471 specificity 0.8038162156975847 recall 0.9262672811059908 f1 0.9234687643975098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 15.091997623443604 s\n",
      "Accuracy 0.9279496744934533 precision 0.9277175218825505 specificity 0.8097751227263761 recall 0.9279496744934533 f1 0.9253555011468058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 14.718000173568726 s\n",
      "Accuracy 0.927876526954868 precision 0.9277841497297994 specificity 0.8036982460311415 recall 0.927876526954868 f1 0.9250908699970898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 14.806998252868652 s\n",
      "Accuracy 0.9272913466461854 precision 0.926640425852509 specificity 0.8046241156197803 recall 0.9272913466461854 f1 0.924700609436841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 14.591997861862183 s\n",
      "Accuracy 0.9272913466461854 precision 0.9271380088449577 specificity 0.8043866412803657 recall 0.9272913466461854 f1 0.9245283658580244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 14.98099970817566 s\n",
      "Accuracy 0.9298515104966718 precision 0.9295414189879313 specificity 0.8124785000611295 recall 0.9298515104966718 f1 0.9273831057312608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 14.743999242782593 s\n",
      "Accuracy 0.9278033794162827 precision 0.9274321034000951 specificity 0.8033163304044777 recall 0.9278033794162827 f1 0.9250936685237604\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 14.6010000705719 s\n",
      "Accuracy 0.9275107892619413 precision 0.9268892506571235 specificity 0.8077888239240673 recall 0.9275107892619413 f1 0.9249919127697851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 15.123080730438232 s\n",
      "Accuracy 0.9308755760368663 precision 0.9311594913271791 specificity 0.8116036682763949 recall 0.9308755760368663 f1 0.9282356901365371\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 14.560532569885254 s\n",
      "Accuracy 0.9302903957281837 precision 0.9301063934408398 specificity 0.8158611345487928 recall 0.9302903957281837 f1 0.9278692628413202\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 14.720538139343262 s\n",
      "Accuracy 0.9270719040304294 precision 0.9272888467674069 specificity 0.802302858674662 recall 0.9270719040304294 f1 0.9241473208495189\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 14.7185378074646 s\n",
      "Accuracy 0.9272913466461854 precision 0.9271006846381918 specificity 0.7971535071091127 recall 0.9272913466461854 f1 0.9243612360643124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 14.971549987792969 s\n",
      "Accuracy 0.9252432155657963 precision 0.9244048560422843 specificity 0.801630312752121 recall 0.9252432155657963 f1 0.9226068663561277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 14.859545469284058 s\n",
      "Accuracy 0.9291200351108185 precision 0.9289456091161089 specificity 0.8119180556011834 recall 0.9291200351108185 f1 0.9265817341447176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 14.83054518699646 s\n",
      "Accuracy 0.9263404286445761 precision 0.9260223393913417 specificity 0.807308216472882 recall 0.9263404286445761 f1 0.9236821367441048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 14.952547550201416 s\n",
      "Accuracy 0.9261941335674054 precision 0.9257945629276013 specificity 0.8056853797472917 recall 0.9261941335674054 f1 0.9235192667454676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 14.655535221099854 s\n",
      "Accuracy 0.9297783629580865 precision 0.9299026318762511 specificity 0.8070649005874468 recall 0.9297783629580865 f1 0.9270524122551351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 14.830545663833618 s\n",
      "Accuracy 0.9302903957281837 precision 0.9301983063943192 specificity 0.8088497034325509 recall 0.9302903957281837 f1 0.927678701986354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 14.811542272567749 s\n",
      "Accuracy 0.9264135761831614 precision 0.9263297909886042 specificity 0.8035843621281683 recall 0.9264135761831614 f1 0.923591625220285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 14.913545370101929 s\n",
      "Accuracy 0.927657084339112 precision 0.927190910991027 specificity 0.8068175326351064 recall 0.927657084339112 f1 0.9250618869295766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 14.690538883209229 s\n",
      "Accuracy 0.9305829858825251 precision 0.9303520554765963 specificity 0.8148092990988408 recall 0.9305829858825251 f1 0.9281575479913906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 15.012550830841064 s\n",
      "Accuracy 0.9271450515690147 precision 0.9268366588902283 specificity 0.803442775614839 recall 0.9271450515690147 f1 0.924404046176052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 14.52253270149231 s\n",
      "Accuracy 0.9253895106429668 precision 0.9250690759639686 specificity 0.7949808123281416 recall 0.9253895106429668 f1 0.9224005691751677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 14.801544189453125 s\n",
      "Accuracy 0.9223904615609685 precision 0.9219691526903337 specificity 0.7932482993006096 recall 0.9223904615609685 f1 0.9193205271974921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 14.826544046401978 s\n",
      "Accuracy 0.9282422646477946 precision 0.9281508005480812 specificity 0.8033102763060093 recall 0.9282422646477946 f1 0.925454848921972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 14.730539798736572 s\n",
      "Accuracy 0.9291931826494039 precision 0.9285731263439954 specificity 0.8064940639362861 recall 0.9291931826494039 f1 0.9266764156959318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 14.91554880142212 s\n",
      "Accuracy 0.9243654451027723 precision 0.923769193305144 specificity 0.8009209976509482 recall 0.9243654451027723 f1 0.9216005163230122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 14.933546543121338 s\n",
      "Accuracy 0.9281691171092092 precision 0.9275073798941218 specificity 0.8134973270858809 recall 0.9281691171092092 f1 0.9258176133877372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 14.825544357299805 s\n",
      "Accuracy 0.927657084339112 precision 0.9273563078326355 specificity 0.8040840602065549 recall 0.927657084339112 f1 0.9249402289376149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 14.972548723220825 s\n",
      "Accuracy 0.9281691171092092 precision 0.9276613308169807 specificity 0.806933120320819 recall 0.9281691171092092 f1 0.925601504357178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 14.780539512634277 s\n",
      "Accuracy 0.9240728549484309 precision 0.9240645652643499 specificity 0.7991419552442958 recall 0.9240728549484309 f1 0.9210667933669977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 14.682538986206055 s\n",
      "Accuracy 0.927657084339112 precision 0.9275678556770708 specificity 0.7983084863436177 recall 0.927657084339112 f1 0.9247336412074131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 14.718538284301758 s\n",
      "Accuracy 0.9285348548021359 precision 0.9283839341995671 specificity 0.8124125278376261 recall 0.9285348548021359 f1 0.9259900932340819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 14.838541984558105 s\n",
      "Accuracy 0.9256821007973082 precision 0.9254843837863416 specificity 0.7989652611195518 recall 0.9256821007973082 f1 0.9227628395638692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 14.605533599853516 s\n",
      "Accuracy 0.9268524614146734 precision 0.9268932799248031 specificity 0.8018461077983449 recall 0.9268524614146734 f1 0.9239605217007572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 15.16555380821228 s\n",
      "Accuracy 0.9304366908053544 precision 0.9305589999899285 specificity 0.8139185430595143 recall 0.9304366908053544 f1 0.9278845999558815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 14.793541193008423 s\n",
      "Accuracy 0.9291931826494039 precision 0.9288988276980926 specificity 0.8152344219391665 recall 0.9291931826494039 f1 0.9267722830704455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 15.036550521850586 s\n",
      "Accuracy 0.9305829858825251 precision 0.9301373619996112 specificity 0.8173595215002233 recall 0.9305829858825251 f1 0.9282871654231348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 14.750545024871826 s\n",
      "Accuracy 0.9280228220320387 precision 0.9274947352444715 specificity 0.807192461686239 recall 0.9280228220320387 f1 0.9254657056363852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 14.820541858673096 s\n",
      "Accuracy 0.927437641723356 precision 0.9272491533470387 specificity 0.8064988218837936 recall 0.927437641723356 f1 0.9247401584159681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 14.823544025421143 s\n",
      "Accuracy 0.9314607563455489 precision 0.9309912226165045 specificity 0.8170393893902552 recall 0.9314607563455489 f1 0.9291818639971988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 14.934547424316406 s\n",
      "Accuracy 0.9286080023407213 precision 0.9282430854385662 specificity 0.811090770060773 recall 0.9286080023407213 f1 0.9261008045947539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 14.760541439056396 s\n",
      "Accuracy 0.9272913466461854 precision 0.9273477900368867 specificity 0.8025371781020066 recall 0.9272913466461854 f1 0.9244215853125719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 14.883545160293579 s\n",
      "Accuracy 0.9227561992538951 precision 0.9220875681979637 specificity 0.7974731485983778 recall 0.9227561992538951 f1 0.9198934938290989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 15.00455093383789 s\n",
      "Accuracy 0.9296320678809158 precision 0.9291691898812283 specificity 0.8124865449949502 recall 0.9296320678809158 f1 0.9272107669032592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 14.566532611846924 s\n",
      "Accuracy 0.9285348548021359 precision 0.928381107334182 specificity 0.7982380479972626 recall 0.9285348548021359 f1 0.9256496840740303\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 14.904546737670898 s\n",
      "Accuracy 0.9275107892619413 precision 0.9271552289097575 specificity 0.8047884343817316 recall 0.9275107892619413 f1 0.9248258275272749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 14.67853832244873 s\n",
      "Accuracy 0.9268524614146734 precision 0.9263831022750946 specificity 0.8042162215225425 recall 0.9268524614146734 f1 0.924177795333002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 15.017549753189087 s\n",
      "Accuracy 0.9261209860288201 precision 0.9258809713576652 specificity 0.8061201990961049 recall 0.9261209860288201 f1 0.9234039567635081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 14.709538221359253 s\n",
      "Accuracy 0.9259015434130642 precision 0.9256129247208834 specificity 0.7977576600422348 recall 0.9259015434130642 f1 0.9229849383303168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 14.598536491394043 s\n",
      "Accuracy 0.9277302318776973 precision 0.9272790468008832 specificity 0.8040336535343426 recall 0.9277302318776973 f1 0.9250631906440722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 15.102553129196167 s\n",
      "Accuracy 0.9269256089532587 precision 0.9263422865039516 specificity 0.7981040854641908 recall 0.9269256089532587 f1 0.9241395886984414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 14.82054352760315 s\n",
      "Accuracy 0.9259746909516495 precision 0.9253279830939258 specificity 0.8049262703721155 recall 0.9259746909516495 f1 0.9233633142711001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 14.971549034118652 s\n",
      "Accuracy 0.9298515104966718 precision 0.9292411549828937 specificity 0.8157885195344508 recall 0.9298515104966718 f1 0.9275655247117012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 14.571533918380737 s\n",
      "Accuracy 0.9299978055738425 precision 0.929601754977795 specificity 0.8117125396611599 recall 0.9299978055738425 f1 0.927542584276438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 14.84754490852356 s\n",
      "Accuracy 0.9278033794162827 precision 0.9274440910638805 specificity 0.807857700106684 recall 0.9278033794162827 f1 0.9252005961778056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 14.712539196014404 s\n",
      "Accuracy 0.9290468875722332 precision 0.9286846966828753 specificity 0.8072664782040296 recall 0.9290468875722332 f1 0.9264559935539783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 15.046552419662476 s\n",
      "Accuracy 0.9318264940384756 precision 0.9317162524800612 specificity 0.813222313657935 recall 0.9318264940384756 f1 0.9293522367691713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 14.760541439056396 s\n",
      "Accuracy 0.9244385926413576 precision 0.9240314648649102 specificity 0.7987785182721989 recall 0.9244385926413576 f1 0.921554411820151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 14.863547563552856 s\n",
      "Accuracy 0.9272913466461854 precision 0.9269092229315327 specificity 0.8064603669336513 recall 0.9272913466461854 f1 0.924651709176568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 14.902544736862183 s\n",
      "Accuracy 0.9250969204886256 precision 0.9249274113327888 specificity 0.7996742520564377 recall 0.9250969204886256 f1 0.9221743315475283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 14.647536993026733 s\n",
      "Accuracy 0.9257552483358935 precision 0.9252722859210909 specificity 0.8045798438234035 recall 0.9257552483358935 f1 0.9230721802667723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 14.990549087524414 s\n",
      "Accuracy 0.9278033794162827 precision 0.9274225060987817 specificity 0.8068055304646469 recall 0.9278033794162827 f1 0.9251820790790865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 14.757540702819824 s\n",
      "Accuracy 0.9294857728037451 precision 0.9290515166358538 specificity 0.812367381528974 recall 0.9294857728037451 f1 0.9270490123423343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 14.57053279876709 s\n",
      "Accuracy 0.9302172481895984 precision 0.9297146685550359 specificity 0.8192280881598331 recall 0.9302172481895984 f1 0.9279785440859749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 14.780543088912964 s\n",
      "Accuracy 0.930802428498281 precision 0.9302464223007464 specificity 0.8179822801996667 recall 0.930802428498281 f1 0.9285644293321457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 14.721539735794067 s\n",
      "Accuracy 0.931021871114037 precision 0.93038305364172 specificity 0.8171707082647635 recall 0.931021871114037 f1 0.9288002727621859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 14.59153699874878 s\n",
      "Accuracy 0.9245848877185283 precision 0.9241496821161354 specificity 0.8019041038462129 recall 0.9245848877185283 f1 0.9217938384532738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 14.813541889190674 s\n",
      "Accuracy 0.9221710189452125 precision 0.9217181632229626 specificity 0.7993341331887807 recall 0.9221710189452125 f1 0.9192701320435401\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 14.738542318344116 s\n",
      "Accuracy 0.9289737400336479 precision 0.9286439995965544 specificity 0.8075579399006844 recall 0.9289737400336479 f1 0.92637771945699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 14.757540941238403 s\n",
      "Accuracy 0.9256821007973082 precision 0.9252313323571476 specificity 0.8010976789859583 recall 0.9256821007973082 f1 0.922898360528111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 14.786540508270264 s\n",
      "Accuracy 0.9283885597249653 precision 0.9279891019084053 specificity 0.8055015128470557 recall 0.9283885597249653 f1 0.925753789014129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 14.630537033081055 s\n",
      "Accuracy 0.9268524614146734 precision 0.926656174356736 specificity 0.8095188591412928 recall 0.9268524614146734 f1 0.9242200425507621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 15.07355284690857 s\n",
      "Accuracy 0.9273644941847707 precision 0.9273781048000507 specificity 0.8041904099805018 recall 0.9273644941847707 f1 0.9245490845086777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 14.964550733566284 s\n",
      "Accuracy 0.9335088874259381 precision 0.9335769988782986 specificity 0.8235120070606143 recall 0.9335088874259381 f1 0.9312434530149212\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 14.875544309616089 s\n",
      "Accuracy 0.9270719040304294 precision 0.9267398843466143 specificity 0.8009553262936346 recall 0.9270719040304294 f1 0.9242753578841211\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 14.811544418334961 s\n",
      "Accuracy 0.9275107892619413 precision 0.9270412169553943 specificity 0.811567851017957 recall 0.9275107892619413 f1 0.9250301404488136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 14.683537244796753 s\n",
      "Accuracy 0.9258283958744788 precision 0.9251932695357176 specificity 0.8048981090201206 recall 0.9258283958744788 f1 0.9232091200839627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 14.853391647338867 s\n",
      "Accuracy 0.9245848877185283 precision 0.9246133011024151 specificity 0.8000694901616561 recall 0.9245848877185283 f1 0.9216030123298016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 14.520380020141602 s\n",
      "Accuracy 0.9283885597249653 precision 0.9278899920032997 specificity 0.8054704432319264 recall 0.9283885597249653 f1 0.9257867135581686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 15.129396915435791 s\n",
      "Accuracy 0.9282422646477946 precision 0.927903042436577 specificity 0.811720549427217 recall 0.9282422646477946 f1 0.9257348359857606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 14.73238730430603 s\n",
      "Accuracy 0.9250237729500402 precision 0.9253477798288272 specificity 0.7942040911348341 recall 0.9250237729500402 f1 0.9218197629289757\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 14.790387868881226 s\n",
      "Accuracy 0.927437641723356 precision 0.9269016771467805 specificity 0.8043936969103285 recall 0.927437641723356 f1 0.924802625739596\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 14.509380102157593 s\n",
      "Accuracy 0.9267061663375027 precision 0.926188694664493 specificity 0.8068693597222228 recall 0.9267061663375027 f1 0.9241112426936693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 15.016393423080444 s\n",
      "Accuracy 0.9268524614146734 precision 0.9263825642756348 specificity 0.8069958050409795 recall 0.9268524614146734 f1 0.9242469861795811\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 14.81738805770874 s\n",
      "Accuracy 0.9239265598712604 precision 0.9235564600894325 specificity 0.795328273747628 recall 0.9239265598712604 f1 0.9209292208758777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 14.711385250091553 s\n",
      "Accuracy 0.9291200351108185 precision 0.9285242835244788 specificity 0.8136519766879677 recall 0.9291200351108185 f1 0.9267645159819816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 14.553382635116577 s\n",
      "Accuracy 0.9264867237217468 precision 0.925965050334426 specificity 0.8057709817983205 recall 0.9264867237217468 f1 0.9238615693717116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 14.717388391494751 s\n",
      "Accuracy 0.9283154121863799 precision 0.9284851577880082 specificity 0.8110853884595824 recall 0.9283154121863799 f1 0.9256428048419212\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 14.971394538879395 s\n",
      "Accuracy 0.9272913466461854 precision 0.9268403413608436 specificity 0.8088123422977246 recall 0.9272913466461854 f1 0.9247327019062827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 14.67038106918335 s\n",
      "Accuracy 0.9275839368005266 precision 0.926891945569454 specificity 0.8098077811275871 recall 0.9275839368005266 f1 0.9251429162194503\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 14.900392770767212 s\n",
      "Accuracy 0.926998756491844 precision 0.926510152011762 specificity 0.800070317483639 recall 0.926998756491844 f1 0.9242305733057495\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 14.746385335922241 s\n",
      "Accuracy 0.9270719040304294 precision 0.9267982316984552 specificity 0.8006802107875538 recall 0.9270719040304294 f1 0.9242499388372258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 14.91939091682434 s\n",
      "Accuracy 0.9248043303342842 precision 0.9243341673973041 specificity 0.8021457653266525 recall 0.9248043303342842 f1 0.9220357920047452\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 14.560381650924683 s\n",
      "Accuracy 0.9311681661912077 precision 0.9311005018385783 specificity 0.811105449514581 recall 0.9311681661912077 f1 0.9286196952414575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 14.552383184432983 s\n",
      "Accuracy 0.9281691171092092 precision 0.9275440404127713 specificity 0.8102038231137519 recall 0.9281691171092092 f1 0.9257234992771305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 14.875391721725464 s\n",
      "Accuracy 0.9294126252651598 precision 0.9290019814952325 specificity 0.8044314964463094 recall 0.9294126252651598 f1 0.9267778389322989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 15.072394609451294 s\n",
      "Accuracy 0.9261209860288201 precision 0.9255345594622871 specificity 0.7974920796700169 recall 0.9261209860288201 f1 0.9233022726230133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 14.793389081954956 s\n",
      "Accuracy 0.9259746909516495 precision 0.9260425745693847 specificity 0.805458690481732 recall 0.9259746909516495 f1 0.9231467132602944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 14.707385301589966 s\n",
      "Accuracy 0.9272913466461854 precision 0.9269450329780492 specificity 0.8072192659982612 recall 0.9272913466461854 f1 0.9246585713120421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 14.964393377304077 s\n",
      "Accuracy 0.9253895106429668 precision 0.9246014700155636 specificity 0.799515884350797 recall 0.9253895106429668 f1 0.9226814834251417\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 14.858390092849731 s\n",
      "Accuracy 0.9283154121863799 precision 0.9280437805569158 specificity 0.8043887033919872 recall 0.9283154121863799 f1 0.9256107304431546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 14.87039065361023 s\n",
      "Accuracy 0.9261941335674054 precision 0.9260495969722198 specificity 0.8017681727929802 recall 0.9261941335674054 f1 0.9233403777293147\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 14.568381071090698 s\n",
      "Accuracy 0.9280228220320387 precision 0.9273456983246949 specificity 0.8088184527617941 recall 0.9280228220320387 f1 0.9255601906798485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 14.84139084815979 s\n",
      "Accuracy 0.9278033794162827 precision 0.9272480407343623 specificity 0.8112781247570059 recall 0.9278033794162827 f1 0.9253514382644878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 14.767385721206665 s\n",
      "Accuracy 0.9253163631043816 precision 0.9252268075853586 specificity 0.7958884154524737 recall 0.9253163631043816 f1 0.9222779377394987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 14.896392345428467 s\n",
      "Accuracy 0.9272913466461854 precision 0.92683115904362 specificity 0.8065064735944715 recall 0.9272913466461854 f1 0.9246791279963575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 14.72238802909851 s\n",
      "Accuracy 0.9293394777265745 precision 0.9295934799660621 specificity 0.8090260767714275 recall 0.9293394777265745 f1 0.9266156539109331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 14.807388305664062 s\n",
      "Accuracy 0.9283154121863799 precision 0.9278433876039216 specificity 0.8092992204216302 recall 0.9283154121863799 f1 0.9257956724933454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 14.939393758773804 s\n",
      "Accuracy 0.9254626581815522 precision 0.9254434532523783 specificity 0.7965934017522524 recall 0.9254626581815522 f1 0.9224249521172675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 14.645383834838867 s\n",
      "Accuracy 0.9258283958744788 precision 0.9252772599569742 specificity 0.8053105185590487 recall 0.9258283958744788 f1 0.9231891134337261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 14.69938611984253 s\n",
      "Accuracy 0.9322653792699875 precision 0.9321167962546274 specificity 0.8176575949520521 recall 0.9322653792699875 f1 0.9299109864552321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 15.135395050048828 s\n",
      "Accuracy 0.9261209860288201 precision 0.9259879277802336 specificity 0.7965719868405348 recall 0.9261209860288201 f1 0.9231315070596992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 14.659383773803711 s\n",
      "Accuracy 0.9280959695706239 precision 0.9281431602138176 specificity 0.8083717707282729 recall 0.9280959695706239 f1 0.9253877620412999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 14.749387741088867 s\n",
      "Accuracy 0.9281691171092092 precision 0.9281704484718163 specificity 0.8097596015401968 recall 0.9281691171092092 f1 0.925508864595657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 14.784388065338135 s\n",
      "Accuracy 0.9260478384902348 precision 0.9256698890583939 specificity 0.804170356043712 recall 0.9260478384902348 f1 0.923324901156259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 14.937393426895142 s\n",
      "Accuracy 0.9289737400336479 precision 0.9285353381066271 specificity 0.8080613633030477 recall 0.9289737400336479 f1 0.9264258095956055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 14.819387912750244 s\n",
      "Accuracy 0.9261209860288201 precision 0.9262785244086498 specificity 0.8015137885213988 recall 0.9261209860288201 f1 0.9231723132279042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 15.081396102905273 s\n",
      "Accuracy 0.9266330187989175 precision 0.9265252855541988 specificity 0.8013299902365137 recall 0.9266330187989175 f1 0.9237667168347977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 14.634382486343384 s\n",
      "Accuracy 0.9280228220320387 precision 0.927154684440707 specificity 0.8168061807408894 recall 0.9280228220320387 f1 0.9258354414485508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 14.737387418746948 s\n",
      "Accuracy 0.9244385926413576 precision 0.9239823722836147 specificity 0.8012598851046451 recall 0.9244385926413576 f1 0.9216350578623608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 14.859390497207642 s\n",
      "Accuracy 0.9272181991076001 precision 0.9270593353542397 specificity 0.8109903977402306 recall 0.9272181991076001 f1 0.9246171279736115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 14.53038215637207 s\n",
      "Accuracy 0.9303635432667691 precision 0.9302402913894892 specificity 0.8119804914881197 recall 0.9303635432667691 f1 0.9278354397747411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 14.621385335922241 s\n",
      "Accuracy 0.9286811498793066 precision 0.9281043565349588 specificity 0.8128544253314892 recall 0.9286811498793066 f1 0.9262914231945598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 15.085396528244019 s\n",
      "Accuracy 0.9262672811059908 precision 0.9258501121500713 specificity 0.8022972095909503 recall 0.9262672811059908 f1 0.9235148540006767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 14.835390090942383 s\n",
      "Accuracy 0.9289005924950625 precision 0.9288155426212323 specificity 0.8057339076626164 recall 0.9289005924950625 f1 0.9261838526290188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 14.63038420677185 s\n",
      "Accuracy 0.9304366908053544 precision 0.9302650268410354 specificity 0.8151202648551104 recall 0.9304366908053544 f1 0.927997349950106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 14.894392251968384 s\n",
      "Accuracy 0.9272913466461854 precision 0.9270785087539799 specificity 0.8035977592791596 recall 0.9272913466461854 f1 0.9245271822866942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 14.63038682937622 s\n",
      "Accuracy 0.9313144612683784 precision 0.9305661754439993 specificity 0.817571889075406 recall 0.9313144612683784 f1 0.9291513303339575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 14.831388473510742 s\n",
      "Accuracy 0.9298515104966718 precision 0.9295736874070971 specificity 0.8069575940036415 recall 0.9298515104966718 f1 0.9272429858489196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 14.951393127441406 s\n",
      "Accuracy 0.9302903957281837 precision 0.9298569177750343 specificity 0.8158214930171603 recall 0.9302903957281837 f1 0.9279494103103197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 14.601383447647095 s\n",
      "Accuracy 0.9264867237217468 precision 0.9260383584703006 specificity 0.8119339764475412 recall 0.9264867237217468 f1 0.9239894196828837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 15.007394552230835 s\n",
      "Accuracy 0.9270719040304294 precision 0.9269543819191853 specificity 0.8007792470260197 recall 0.9270719040304294 f1 0.924204483723669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 14.820388793945312 s\n",
      "Accuracy 0.9259746909516495 precision 0.925622203558854 specificity 0.8031154808839499 recall 0.9259746909516495 f1 0.9232153964356093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 15.029394149780273 s\n",
      "Accuracy 0.9281691171092092 precision 0.928075353462188 specificity 0.8050458655049723 recall 0.9281691171092092 f1 0.9254228438283212\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 14.725383520126343 s\n",
      "Accuracy 0.924511740179943 precision 0.9241130847618576 specificity 0.8013890324456824 recall 0.924511740179943 f1 0.9216937162669621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 14.727386474609375 s\n",
      "Accuracy 0.9298515104966718 precision 0.9296343832380004 specificity 0.8100544077377189 recall 0.9298515104966718 f1 0.9272968135870129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 14.68738603591919 s\n",
      "Accuracy 0.9315339038841343 precision 0.9311307875425552 specificity 0.8208064431467983 recall 0.9315339038841343 f1 0.929319011957322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 14.934391975402832 s\n",
      "Accuracy 0.9263404286445761 precision 0.926048531764593 specificity 0.8095042893438418 recall 0.9263404286445761 f1 0.9237282576028214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 14.735387802124023 s\n",
      "Accuracy 0.9233413795625777 precision 0.9232637839709287 specificity 0.791391313292566 recall 0.9233413795625777 f1 0.9201363339816807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 14.71538496017456 s\n",
      "Accuracy 0.9298515104966718 precision 0.9296398323871081 specificity 0.81241088403086 recall 0.9298515104966718 f1 0.9273503578357957\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 14.819389820098877 s\n",
      "Accuracy 0.9275107892619413 precision 0.9269589174968461 specificity 0.8057746889928067 recall 0.9275107892619413 f1 0.9249169786980933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 14.741386890411377 s\n",
      "Accuracy 0.9241460024870163 precision 0.9234419336145707 specificity 0.7986563760874282 recall 0.9241460024870163 f1 0.921356940919173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 15.013393878936768 s\n",
      "Accuracy 0.9298515104966718 precision 0.9296576092822251 specificity 0.8069785459880651 recall 0.9298515104966718 f1 0.9272173293938654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 14.985391616821289 s\n",
      "Accuracy 0.9254626581815522 precision 0.9249750066558717 specificity 0.8040672735754425 recall 0.9254626581815522 f1 0.92276241000846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 15.00639295578003 s\n",
      "Accuracy 0.927437641723356 precision 0.9268810932262038 specificity 0.8024606420559445 recall 0.927437641723356 f1 0.9247621000097317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 14.841390609741211 s\n",
      "Accuracy 0.9286080023407213 precision 0.9284593332824128 specificity 0.8087132136429089 recall 0.9286080023407213 f1 0.9259755182355863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 14.912298679351807 s\n",
      "Accuracy 0.9252432155657963 precision 0.9245942476137584 specificity 0.8001984291113622 recall 0.9252432155657963 f1 0.9224969994165114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 14.81827712059021 s\n",
      "Accuracy 0.9273644941847707 precision 0.926521285872266 specificity 0.8089928752171976 recall 0.9273644941847707 f1 0.9249599908727033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 14.8522789478302 s\n",
      "Accuracy 0.9264867237217468 precision 0.9264028952907722 specificity 0.8017804803980059 recall 0.9264867237217468 f1 0.9236213841705397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 14.727278470993042 s\n",
      "Accuracy 0.9313144612683784 precision 0.9311815124948923 specificity 0.8106189422696097 recall 0.9313144612683784 f1 0.9287771992934498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 14.830277919769287 s\n",
      "Accuracy 0.9265598712603321 precision 0.9261572508914989 specificity 0.8071011969152648 recall 0.9265598712603321 f1 0.9239284795582412\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 14.90927767753601 s\n",
      "Accuracy 0.9250969204886256 precision 0.925263348774391 specificity 0.8024254697777284 recall 0.9250969204886256 f1 0.9221472072036877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 14.904280185699463 s\n",
      "Accuracy 0.9282422646477946 precision 0.9277350658348081 specificity 0.8118472022818527 recall 0.9282422646477946 f1 0.9257950506559731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 14.993281841278076 s\n",
      "Accuracy 0.9267061663375027 precision 0.9262678652028888 specificity 0.8141921784969581 recall 0.9267061663375027 f1 0.9242649411250741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 14.853277206420898 s\n",
      "Accuracy 0.9283154121863799 precision 0.9278564372355144 specificity 0.8090045125796855 recall 0.9283154121863799 f1 0.9257840452482333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 14.964281558990479 s\n",
      "Accuracy 0.9267061663375027 precision 0.9265280751307754 specificity 0.7993620936770208 recall 0.9267061663375027 f1 0.9238136568888698\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 14.784276008605957 s\n",
      "Accuracy 0.9256089532587228 precision 0.9251598486919923 specificity 0.8027618702166528 recall 0.9256089532587228 f1 0.9228653447101965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 14.786279439926147 s\n",
      "Accuracy 0.9267061663375027 precision 0.9259539319709367 specificity 0.8141117976265211 recall 0.9267061663375027 f1 0.9243802601253021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 14.954280853271484 s\n",
      "Accuracy 0.9302903957281837 precision 0.9300448138620832 specificity 0.8042185053499509 recall 0.9302903957281837 f1 0.9276169160602815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 14.860275983810425 s\n",
      "Accuracy 0.9284617072635506 precision 0.9278879491474452 specificity 0.8103658988096338 recall 0.9284617072635506 f1 0.9260066986439477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 14.757277727127075 s\n",
      "Accuracy 0.9294857728037451 precision 0.9293476469057288 specificity 0.8091567690612201 recall 0.9294857728037451 f1 0.9268783902159095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 14.780276775360107 s\n",
      "Accuracy 0.9289737400336479 precision 0.9288817647420251 specificity 0.8111687475396445 recall 0.9289737400336479 f1 0.9263900288729463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 14.964281558990479 s\n",
      "Accuracy 0.9286811498793066 precision 0.9286648708369822 specificity 0.8092165535467781 recall 0.9286811498793066 f1 0.926023056055467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 14.496271848678589 s\n",
      "Accuracy 0.9307292809596958 precision 0.9305288635772287 specificity 0.8053461811467226 recall 0.9307292809596958 f1 0.9280780758949736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 15.196284770965576 s\n",
      "Accuracy 0.9259746909516495 precision 0.9257917141897791 specificity 0.8010198912035896 recall 0.9259746909516495 f1 0.9231091492021049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 15.023279666900635 s\n",
      "Accuracy 0.9256821007973082 precision 0.9249984694848756 specificity 0.8037871278922044 recall 0.9256821007973082 f1 0.9230497518423832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 14.868280172348022 s\n",
      "Accuracy 0.9261209860288201 precision 0.9257155815061022 specificity 0.8133289231660363 recall 0.9261209860288201 f1 0.9236373156021312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 14.587273836135864 s\n",
      "Accuracy 0.9269256089532587 precision 0.9264185400340301 specificity 0.8045949055474759 recall 0.9269256089532587 f1 0.924274875443238\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 14.934280395507812 s\n",
      "Accuracy 0.9286811498793066 precision 0.9285920323499489 specificity 0.806664457819463 recall 0.9286811498793066 f1 0.9259832616362064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 14.726276159286499 s\n",
      "Accuracy 0.9272913466461854 precision 0.9265101046301027 specificity 0.814807393800761 recall 0.9272913466461854 f1 0.9250046125479812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 14.590272665023804 s\n",
      "Accuracy 0.9259746909516495 precision 0.9257819860272367 specificity 0.8036633722391082 recall 0.9259746909516495 f1 0.9231785495251631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 14.953281164169312 s\n",
      "Accuracy 0.9253895106429668 precision 0.9248360546566354 specificity 0.8052129665928962 recall 0.9253895106429668 f1 0.9227400235258443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 14.932281732559204 s\n",
      "Accuracy 0.926779313876088 precision 0.9263929722318843 specificity 0.8059689023751964 recall 0.926779313876088 f1 0.9241187076514534\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 14.934279918670654 s\n",
      "Accuracy 0.9280228220320387 precision 0.9274056137848169 specificity 0.8100140198205485 recall 0.9280228220320387 f1 0.9255668483957614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 14.633274793624878 s\n",
      "Accuracy 0.9296320678809158 precision 0.929402993583009 specificity 0.8115420345926152 recall 0.9296320678809158 f1 0.9271116825855781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 14.698275804519653 s\n",
      "Accuracy 0.9282422646477946 precision 0.9280402287831311 specificity 0.8074944049177487 recall 0.9282422646477946 f1 0.9255894138102629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 14.790278911590576 s\n",
      "Accuracy 0.9309487235754517 precision 0.9304712215103959 specificity 0.8106629334204758 recall 0.9309487235754517 f1 0.928515877559891\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 14.807276725769043 s\n",
      "Accuracy 0.9280959695706239 precision 0.9277580959239451 specificity 0.8082337007432596 recall 0.9280959695706239 f1 0.925501109981363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 14.826278686523438 s\n",
      "Accuracy 0.9297052154195011 precision 0.9293600803527122 specificity 0.8059870069500487 recall 0.9297052154195011 f1 0.9270922172611645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 14.939282655715942 s\n",
      "Accuracy 0.9343135103503767 precision 0.9340183272836898 specificity 0.8203634997089796 recall 0.9343135103503767 f1 0.9321029854275629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 14.749276161193848 s\n",
      "Accuracy 0.9245848877185283 precision 0.9245499562199517 specificity 0.8045608998641155 recall 0.9245848877185283 f1 0.9217364272359505\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 15.046282768249512 s\n",
      "Accuracy 0.9298515104966718 precision 0.9293427973376028 specificity 0.8072998991391503 recall 0.9298515104966718 f1 0.9273278775507369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 14.872278451919556 s\n",
      "Accuracy 0.9289737400336479 precision 0.9286392417399045 specificity 0.8132331828961666 recall 0.9289737400336479 f1 0.926514512262584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 14.843278408050537 s\n",
      "Accuracy 0.9239997074098456 precision 0.9238122793414523 specificity 0.7969064672174052 recall 0.9239997074098456 f1 0.9209874526110089\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 15.121285438537598 s\n",
      "Accuracy 0.9279496744934533 precision 0.9274331328811192 specificity 0.8083747843044058 recall 0.9279496744934533 f1 0.9254158634634368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 14.553272008895874 s\n",
      "Accuracy 0.9253895106429668 precision 0.9246130506196438 specificity 0.7966036348938957 recall 0.9253895106429668 f1 0.9226016247770429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 14.776278257369995 s\n",
      "Accuracy 0.9293394777265745 precision 0.9290849769930536 specificity 0.8057714020821833 recall 0.9293394777265745 f1 0.9266845551374191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 15.028282165527344 s\n",
      "Accuracy 0.9264867237217468 precision 0.9263140810520465 specificity 0.8069675332054287 recall 0.9264867237217468 f1 0.9237770496896069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 14.83427906036377 s\n",
      "Accuracy 0.9311681661912077 precision 0.9308861698036269 specificity 0.8117675836901402 recall 0.9311681661912077 f1 0.9287002705281644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 15.081283330917358 s\n",
      "Accuracy 0.9267061663375027 precision 0.926695192577832 specificity 0.8030782223506431 recall 0.9267061663375027 f1 0.9238564736701637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 15.086284399032593 s\n",
      "Accuracy 0.924511740179943 precision 0.9239700134585863 specificity 0.8039943160231038 recall 0.924511740179943 f1 0.9218098617426584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 14.942280530929565 s\n",
      "Accuracy 0.9269256089532587 precision 0.9270268899314852 specificity 0.8028845684255986 recall 0.9269256089532587 f1 0.9240439340885055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 14.847278594970703 s\n",
      "Accuracy 0.924292297564187 precision 0.9236003166157993 specificity 0.7997699740190287 recall 0.924292297564187 f1 0.921530943615667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 14.887279510498047 s\n",
      "Accuracy 0.9241460024870163 precision 0.9235728126324133 specificity 0.8028587791045252 recall 0.9241460024870163 f1 0.9214187844429088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 14.893276929855347 s\n",
      "Accuracy 0.9266330187989175 precision 0.9263338236317339 specificity 0.8104383167914629 recall 0.9266330187989175 f1 0.9240516674662494\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 14.847275257110596 s\n",
      "Accuracy 0.9260478384902348 precision 0.9259890164287018 specificity 0.8062045732494929 recall 0.9260478384902348 f1 0.9232764559084651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 15.109283208847046 s\n",
      "Accuracy 0.9265598712603321 precision 0.9261635235102746 specificity 0.8073990882775496 recall 0.9265598712603321 f1 0.9239337835565051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 14.654276132583618 s\n",
      "Accuracy 0.9256821007973082 precision 0.9253315136298125 specificity 0.8019258407180212 recall 0.9256821007973082 f1 0.9228861150246324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 14.824278831481934 s\n",
      "Accuracy 0.9277302318776973 precision 0.9274060461636114 specificity 0.8022446610047718 recall 0.9277302318776973 f1 0.9249773916038444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 14.845279216766357 s\n",
      "Accuracy 0.9258283958744788 precision 0.9254801387697962 specificity 0.807472826033884 recall 0.9258283958744788 f1 0.9231742913596285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 15.008280515670776 s\n",
      "Accuracy 0.9288274449564772 precision 0.9284413358503812 specificity 0.8138352280486549 recall 0.9288274449564772 f1 0.9263969610687101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 14.778280258178711 s\n",
      "Accuracy 0.9305829858825251 precision 0.9301648601044483 specificity 0.8081991042552857 recall 0.9305829858825251 f1 0.9280648987195778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 14.798279047012329 s\n",
      "Accuracy 0.9311681661912077 precision 0.9311388424874454 specificity 0.8119974041948111 recall 0.9311681661912077 f1 0.9286289983127953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 14.977271318435669 s\n",
      "Accuracy 0.9299978055738425 precision 0.9295326280523977 specificity 0.8166596510918583 recall 0.9299978055738425 f1 0.9276821035688996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 14.94028115272522 s\n",
      "Accuracy 0.9269256089532587 precision 0.9263053023306327 specificity 0.8055357472212589 recall 0.9269256089532587 f1 0.9243387827908169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 14.84927749633789 s\n",
      "Accuracy 0.9257552483358935 precision 0.9256257876109406 specificity 0.8014794533350916 recall 0.9257552483358935 f1 0.9228803720011598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 14.945279836654663 s\n",
      "Accuracy 0.9286811498793066 precision 0.9284210122414036 specificity 0.8117101221195369 recall 0.9286811498793066 f1 0.9261562376076421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 14.838276863098145 s\n",
      "Accuracy 0.9245848877185283 precision 0.9237930464424997 specificity 0.801369145906578 recall 0.9245848877185283 f1 0.9219096563961239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 14.896278381347656 s\n",
      "Accuracy 0.9248774778728696 precision 0.9242992585398084 specificity 0.8020139305781213 recall 0.9248774778728696 f1 0.9221447802116113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 15.017282247543335 s\n",
      "Accuracy 0.9289737400336479 precision 0.9285609764733335 specificity 0.8093391365308674 recall 0.9289737400336479 f1 0.9264477141403579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 14.850280284881592 s\n",
      "Accuracy 0.927876526954868 precision 0.9273765447645339 specificity 0.8088793409587242 recall 0.927876526954868 f1 0.9253477707968416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 15.065282344818115 s\n",
      "Accuracy 0.9280228220320387 precision 0.9274414884629835 specificity 0.8082324699390284 recall 0.9280228220320387 f1 0.9255101642958857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 14.85127854347229 s\n",
      "Accuracy 0.9254626581815522 precision 0.9251419630068487 specificity 0.7993817895781633 recall 0.9254626581815522 f1 0.9225877904222987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 15.023282766342163 s\n",
      "Accuracy 0.9315339038841343 precision 0.9310445992604897 specificity 0.8144426622524916 recall 0.9315339038841343 f1 0.9292039660727465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 14.966280460357666 s\n",
      "Accuracy 0.9248043303342842 precision 0.9241929387232843 specificity 0.7992972027535835 recall 0.9248043303342842 f1 0.9220118878188448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 14.59327483177185 s\n",
      "Accuracy 0.9266330187989175 precision 0.9264520514641899 specificity 0.8041686649447625 recall 0.9266330187989175 f1 0.9238593979709724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 14.93228030204773 s\n",
      "Accuracy 0.9268524614146734 precision 0.9264190824662936 specificity 0.804988904614536 recall 0.9268524614146734 f1 0.9241847591136991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 14.845277309417725 s\n",
      "Accuracy 0.9261941335674054 precision 0.9262653751379104 specificity 0.8011576641514833 recall 0.9261941335674054 f1 0.9232621411835275\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 14.842278242111206 s\n",
      "Accuracy 0.9287542974178918 precision 0.928122871396177 specificity 0.8155567771240525 recall 0.9287542974178918 f1 0.9264513303399706\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 14.85727834701538 s\n",
      "Accuracy 0.9259746909516495 precision 0.9253850540184304 specificity 0.8022965600407256 recall 0.9259746909516495 f1 0.9232758506886366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 14.773276805877686 s\n",
      "Accuracy 0.9286080023407213 precision 0.9280903581308756 specificity 0.8101160338211192 recall 0.9286080023407213 f1 0.926129636954207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 14.656274557113647 s\n",
      "Accuracy 0.9313144612683784 precision 0.9308117237093068 specificity 0.8183652072216653 recall 0.9313144612683784 f1 0.9290750176313848\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 14.629275560379028 s\n",
      "Accuracy 0.9261941335674054 precision 0.9259862514420283 specificity 0.8049661893275617 recall 0.9261941335674054 f1 0.9234397261464554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 14.72627854347229 s\n",
      "Accuracy 0.9280228220320387 precision 0.9274809822645294 specificity 0.8110505513286203 recall 0.9280228220320387 f1 0.9255645555172758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 14.775278568267822 s\n",
      "Accuracy 0.9319727891156463 precision 0.9318648720002202 specificity 0.816257085148941 recall 0.9319727891156463 f1 0.9295692237351093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 14.755276679992676 s\n",
      "Accuracy 0.9284617072635506 precision 0.9282808791066564 specificity 0.8074786523482145 recall 0.9284617072635506 f1 0.9258064220907813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 14.76527738571167 s\n",
      "Accuracy 0.9259015434130642 precision 0.9250725903010839 specificity 0.8060463027186171 recall 0.9259015434130642 f1 0.9233883358565653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 14.915280103683472 s\n",
      "Accuracy 0.9281691171092092 precision 0.9277777750856502 specificity 0.8126320682834913 recall 0.9281691171092092 f1 0.9256995754528857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 14.964280366897583 s\n",
      "Accuracy 0.9275107892619413 precision 0.9271781573068543 specificity 0.8028909903650224 recall 0.9275107892619413 f1 0.9247717785425713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 14.728277444839478 s\n",
      "Accuracy 0.9249506254114549 precision 0.92461233810489 specificity 0.7992919963707044 recall 0.9249506254114549 f1 0.9220680873496239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 14.63627552986145 s\n",
      "Accuracy 0.9332162972715968 precision 0.9326960835230624 specificity 0.8179584905248344 recall 0.9332162972715968 f1 0.9310091477034729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 14.431271314620972 s\n",
      "Accuracy 0.9253163631043816 precision 0.9248709170570888 specificity 0.8072395662741119 recall 0.9253163631043816 f1 0.9226792852371021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 14.966273784637451 s\n",
      "Accuracy 0.9272913466461854 precision 0.9269357080296464 specificity 0.8067692299730592 recall 0.9272913466461854 f1 0.9246505726656241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 14.787276983261108 s\n",
      "Accuracy 0.9259746909516495 precision 0.9256814930780851 specificity 0.800944759561697 recall 0.9259746909516495 f1 0.9231416470902424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 14.852278232574463 s\n",
      "Accuracy 0.9297052154195011 precision 0.9290068726119736 specificity 0.8166340234555722 recall 0.9297052154195011 f1 0.9274708191801312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 14.684273719787598 s\n",
      "Accuracy 0.9270719040304294 precision 0.9266850985205197 specificity 0.8052835165749346 recall 0.9270719040304294 f1 0.9244003833782239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 14.892279386520386 s\n",
      "Accuracy 0.9264135761831614 precision 0.926034296901969 specificity 0.800810013776293 recall 0.9264135761831614 f1 0.9236144120930496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 14.588273763656616 s\n",
      "Accuracy 0.9299246580352571 precision 0.9296666262447096 specificity 0.813448524133987 recall 0.9299246580352571 f1 0.9274636995919817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 14.963280200958252 s\n",
      "Accuracy 0.9287542974178918 precision 0.9285183051046597 specificity 0.8122414613939865 recall 0.9287542974178918 f1 0.9262358208775456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 14.856278419494629 s\n",
      "Accuracy 0.9284617072635506 precision 0.9275514447082805 specificity 0.8132905565747364 recall 0.9284617072635506 f1 0.926213882757376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 14.668275594711304 s\n",
      "Accuracy 0.9287542974178918 precision 0.9282597856193547 specificity 0.8136702236139145 recall 0.9287542974178918 f1 0.9263558494404084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 14.865276575088501 s\n",
      "Accuracy 0.9289737400336479 precision 0.9290270435668209 specificity 0.8074587702000694 recall 0.9289737400336479 f1 0.9262598397769349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 14.904278755187988 s\n",
      "Accuracy 0.9254626581815522 precision 0.9250698091474368 specificity 0.803821382265238 recall 0.9254626581815522 f1 0.9227240850425134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 14.763278245925903 s\n",
      "Accuracy 0.9268524614146734 precision 0.9265129554284309 specificity 0.8075635165367678 recall 0.9268524614146734 f1 0.9242173435021954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 14.892278671264648 s\n",
      "Accuracy 0.9284617072635506 precision 0.9283490841683436 specificity 0.8066063768259154 recall 0.9284617072635506 f1 0.9257648378350768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 14.97028112411499 s\n",
      "Accuracy 0.9283154121863799 precision 0.927650597887458 specificity 0.8088276888879044 recall 0.9283154121863799 f1 0.9258540546569669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 14.815277814865112 s\n",
      "Accuracy 0.9295589203423305 precision 0.9295634248001459 specificity 0.8090651373390942 recall 0.9295589203423305 f1 0.926909040813044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 14.9972825050354 s\n",
      "Accuracy 0.9273644941847707 precision 0.9271088137282925 specificity 0.8049538639582338 recall 0.9273644941847707 f1 0.9246485456058468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 15.028280973434448 s\n",
      "Accuracy 0.9248774778728696 precision 0.9244143867677288 specificity 0.8099431051564455 recall 0.9248774778728696 f1 0.9223071972839865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 14.813275814056396 s\n",
      "Accuracy 0.926998756491844 precision 0.926790299892538 specificity 0.8086034984490449 recall 0.926998756491844 f1 0.9243503850822509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 14.893279552459717 s\n",
      "Accuracy 0.9261941335674054 precision 0.9260433237390535 specificity 0.8025231462421403 recall 0.9261941335674054 f1 0.9233611793058866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 14.59227466583252 s\n",
      "Accuracy 0.9266330187989175 precision 0.9264004214557512 specificity 0.8057858412834665 recall 0.9266330187989175 f1 0.9239154789949875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 14.89927887916565 s\n",
      "Accuracy 0.9287542974178918 precision 0.9285844064287508 specificity 0.8104363157066834 recall 0.9287542974178918 f1 0.926172337238631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 14.905280828475952 s\n",
      "Accuracy 0.9294126252651598 precision 0.9290988339328929 specificity 0.8152325065724675 recall 0.9294126252651598 f1 0.9270019180835997\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 14.734276294708252 s\n",
      "Accuracy 0.9256821007973082 precision 0.9257468115986348 specificity 0.795983416595846 recall 0.9256821007973082 f1 0.9226099217832111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 14.786278247833252 s\n",
      "Accuracy 0.927437641723356 precision 0.9271891531543491 specificity 0.8076610369024014 recall 0.927437641723356 f1 0.9247872181512482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 14.750276327133179 s\n",
      "Accuracy 0.9261941335674054 precision 0.9258756027664209 specificity 0.8017317754209307 recall 0.9261941335674054 f1 0.9233936588845316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 14.799278736114502 s\n",
      "Accuracy 0.9302903957281837 precision 0.9300701251717135 specificity 0.8129772262984402 recall 0.9302903957281837 f1 0.9278136132430502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 14.49527621269226 s\n",
      "Accuracy 0.9273644941847707 precision 0.9270148421422916 specificity 0.8083455759266579 recall 0.9273644941847707 f1 0.9247618578962382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 15.057278633117676 s\n",
      "Accuracy 0.9310950186526223 precision 0.9306057496855025 specificity 0.8163351943174318 recall 0.9310950186526223 f1 0.9288001833253405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 14.783278465270996 s\n",
      "Accuracy 0.9271450515690147 precision 0.9269583977443291 specificity 0.8041893465724113 recall 0.9271450515690147 f1 0.9243843116759854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 14.827276468276978 s\n",
      "Accuracy 0.9279496744934533 precision 0.927576374459894 specificity 0.8087800506209359 recall 0.9279496744934533 f1 0.925376812696028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 14.69727897644043 s\n",
      "Accuracy 0.9270719040304294 precision 0.9270937655515533 specificity 0.8075535481664861 recall 0.9270719040304294 f1 0.9243306428402187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 15.326286315917969 s\n",
      "Accuracy 0.9292663301879892 precision 0.9290642765308181 specificity 0.8132572871920463 recall 0.9292663301879892 f1 0.9267709534804631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 14.60927438735962 s\n",
      "Accuracy 0.9275107892619413 precision 0.9268747702025205 specificity 0.8088299882490815 recall 0.9275107892619413 f1 0.9250229729741672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 14.807276248931885 s\n",
      "Accuracy 0.9288274449564772 precision 0.9286287096979832 specificity 0.811397809083968 recall 0.9288274449564772 f1 0.9262786659678124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 14.993280172348022 s\n",
      "Accuracy 0.9263404286445761 precision 0.9261312830274421 specificity 0.8075780370877346 recall 0.9263404286445761 f1 0.9236543245588257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 14.72827696800232 s\n",
      "Accuracy 0.9269256089532587 precision 0.926489609289165 specificity 0.8032574503875485 recall 0.9269256089532587 f1 0.9242173084885187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 15.121283531188965 s\n",
      "Accuracy 0.9278033794162827 precision 0.9276666422661327 specificity 0.8044210233259494 recall 0.9278033794162827 f1 0.9250470093991953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 14.831276893615723 s\n",
      "Accuracy 0.9242191500256016 precision 0.9239279006798773 specificity 0.792099953007737 recall 0.9242191500256016 f1 0.9211188550096121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 14.729275226593018 s\n",
      "Accuracy 0.9292663301879892 precision 0.9288625987702499 specificity 0.8110533990131054 recall 0.9292663301879892 f1 0.9267838587431558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 14.83127760887146 s\n",
      "Accuracy 0.9259746909516495 precision 0.9253501423561631 specificity 0.8110395401666575 recall 0.9259746909516495 f1 0.9235093548362395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 14.800277709960938 s\n",
      "Accuracy 0.9255358057201375 precision 0.9253264566925453 specificity 0.7945367889008033 recall 0.9255358057201375 f1 0.9225041405440613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 14.687276840209961 s\n",
      "Accuracy 0.9264135761831614 precision 0.9265349413271465 specificity 0.8057917640174589 recall 0.9264135761831614 f1 0.9235877099197586\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 14.610274076461792 s\n",
      "Accuracy 0.9287542974178918 precision 0.9280460508135638 specificity 0.8075125765450041 recall 0.9287542974178918 f1 0.926286369190349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 15.038282632827759 s\n",
      "Accuracy 0.9302903957281837 precision 0.9300215153341422 specificity 0.8125372876877099 recall 0.9302903957281837 f1 0.9278186682557354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 14.958279132843018 s\n",
      "Accuracy 0.9280959695706239 precision 0.9273134730430815 specificity 0.8073216184703047 recall 0.9280959695706239 f1 0.9256393214093647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 14.925280809402466 s\n",
      "Accuracy 0.9285348548021359 precision 0.9282828854457591 specificity 0.8114536214410362 recall 0.9285348548021359 f1 0.9259984597203919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 14.633274793624878 s\n",
      "Accuracy 0.9250237729500402 precision 0.9248001773984496 specificity 0.8059083083978231 recall 0.9250237729500402 f1 0.922275076580932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 15.008280754089355 s\n",
      "Accuracy 0.9297783629580865 precision 0.9294680618466123 specificity 0.8060137377139237 recall 0.9297783629580865 f1 0.9271563312517609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 14.708276510238647 s\n",
      "Accuracy 0.9316070514227196 precision 0.9313326883650127 specificity 0.8172439042850318 recall 0.9316070514227196 f1 0.929270168483808\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 14.956279516220093 s\n",
      "Accuracy 0.9257552483358935 precision 0.9257725037685502 specificity 0.7975160718782585 recall 0.9257552483358935 f1 0.9227371406178202\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 14.691274881362915 s\n",
      "Accuracy 0.9277302318776973 precision 0.927666024388887 specificity 0.7999084937756223 recall 0.9277302318776973 f1 0.9248404163991153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 14.9962797164917 s\n",
      "Accuracy 0.9296320678809158 precision 0.9292182496640752 specificity 0.8092213653515056 recall 0.9296320678809158 f1 0.9271168278175137\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 14.758137702941895 s\n",
      "Accuracy 0.9294126252651598 precision 0.9292609437865077 specificity 0.807036591890105 recall 0.9294126252651598 f1 0.9267576552866668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 14.7561194896698 s\n",
      "Accuracy 0.9265598712603321 precision 0.9258444272610189 specificity 0.8056423908820498 recall 0.9265598712603321 f1 0.92400420317154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 14.840120553970337 s\n",
      "Accuracy 0.9251700680272109 precision 0.9243385796194936 specificity 0.8033013991755481 recall 0.9251700680272109 f1 0.9225727829745495\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 14.804118156433105 s\n",
      "Accuracy 0.9268524614146734 precision 0.9266514311793609 specificity 0.805250553820872 recall 0.9268524614146734 f1 0.9241162956268517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 14.787120819091797 s\n",
      "Accuracy 0.9263404286445761 precision 0.9263617139697582 specificity 0.8006083873113288 recall 0.9263404286445761 f1 0.9234120654566862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 14.68711805343628 s\n",
      "Accuracy 0.9241460024870163 precision 0.9241354107340045 specificity 0.798311395561066 recall 0.9241460024870163 f1 0.9211206522840263\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 15.371124744415283 s\n",
      "Accuracy 0.9260478384902348 precision 0.9256508091144978 specificity 0.8070602133069211 recall 0.9260478384902348 f1 0.9234036981980076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 15.026121616363525 s\n",
      "Accuracy 0.9253163631043816 precision 0.9247160544586136 specificity 0.8070981594145544 recall 0.9253163631043816 f1 0.9227303861885406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 15.055123805999756 s\n",
      "Accuracy 0.9275839368005266 precision 0.9271105191654463 specificity 0.8070972363309775 recall 0.9275839368005266 f1 0.9249966220920223\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 15.06312108039856 s\n",
      "Accuracy 0.9264135761831614 precision 0.9262339868424829 specificity 0.7979112163184434 recall 0.9264135761831614 f1 0.923478603371023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 14.81011962890625 s\n",
      "Accuracy 0.9261941335674054 precision 0.9260737811475706 specificity 0.8018604075146596 recall 0.9261941335674054 f1 0.9233354110343931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 14.894120931625366 s\n",
      "Accuracy 0.9264135761831614 precision 0.9261447824767467 specificity 0.8070527640962656 recall 0.9264135761831614 f1 0.9237345517461002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 14.906120300292969 s\n",
      "Accuracy 0.9278033794162827 precision 0.9274679767720241 specificity 0.806070625092702 recall 0.9278033794162827 f1 0.9251492543964281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 14.93012022972107 s\n",
      "Accuracy 0.9261941335674054 precision 0.9257423357304271 specificity 0.7983874712599945 recall 0.9261941335674054 f1 0.9233532631599538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 14.78712010383606 s\n",
      "Accuracy 0.9278033794162827 precision 0.9274485333260327 specificity 0.8090429917354757 recall 0.9278033794162827 f1 0.925227971414215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 14.94511866569519 s\n",
      "Accuracy 0.926779313876088 precision 0.9262870944472487 specificity 0.8119346267810839 recall 0.926779313876088 f1 0.9243024458750951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 14.724119663238525 s\n",
      "Accuracy 0.9287542974178918 precision 0.9284326611704742 specificity 0.8069781073126306 recall 0.9287542974178918 f1 0.9261372396587242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 15.067121982574463 s\n",
      "Accuracy 0.9243654451027723 precision 0.9234380549752944 specificity 0.8007843531886373 recall 0.9243654451027723 f1 0.9217256783102146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 14.867120027542114 s\n",
      "Accuracy 0.9302172481895984 precision 0.929946792426453 specificity 0.8090237512215318 recall 0.9302172481895984 f1 0.9276625990100379\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 14.734118700027466 s\n",
      "Accuracy 0.9273644941847707 precision 0.9270025236774747 specificity 0.8115471848272171 recall 0.9273644941847707 f1 0.9248441856744201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 15.001118898391724 s\n",
      "Accuracy 0.9264135761831614 precision 0.9258538081314069 specificity 0.810741302737638 recall 0.9264135761831614 f1 0.9239246943535188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 14.904120683670044 s\n",
      "Accuracy 0.9282422646477946 precision 0.9277295613599515 specificity 0.80319693871385 recall 0.9282422646477946 f1 0.9255868603752028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 14.950121879577637 s\n",
      "Accuracy 0.9293394777265745 precision 0.9289357035490108 specificity 0.8142101293535912 recall 0.9293394777265745 f1 0.9269331831061955\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 14.945120334625244 s\n",
      "Accuracy 0.9279496744934533 precision 0.9275613478421206 specificity 0.8109049552849008 recall 0.9279496744934533 f1 0.9254333354310368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 14.92212176322937 s\n",
      "Accuracy 0.9241460024870163 precision 0.9239451338589222 specificity 0.797990144507597 recall 0.9241460024870163 f1 0.9211692252626597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 14.901118755340576 s\n",
      "Accuracy 0.9304366908053544 precision 0.93006557719341 specificity 0.8129520398274331 recall 0.9304366908053544 f1 0.9280106463546984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 14.921124458312988 s\n",
      "Accuracy 0.9310950186526223 precision 0.9306734716450186 specificity 0.8151522542299497 recall 0.9310950186526223 f1 0.9287494320898413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 14.785118341445923 s\n",
      "Accuracy 0.927437641723356 precision 0.9272875052430027 specificity 0.808362374034723 recall 0.927437641723356 f1 0.9247739679097156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 14.616117238998413 s\n",
      "Accuracy 0.9257552483358935 precision 0.9253614604848255 specificity 0.803125001046553 recall 0.9257552483358935 f1 0.9230052789666916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 14.927120447158813 s\n",
      "Accuracy 0.9252432155657963 precision 0.9248486395499812 specificity 0.8028023868363615 recall 0.9252432155657963 f1 0.9224749112687879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 14.645118236541748 s\n",
      "Accuracy 0.927657084339112 precision 0.9274653319632135 specificity 0.8063214628376746 recall 0.927657084339112 f1 0.9249607246592767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 14.759119272232056 s\n",
      "Accuracy 0.9289005924950625 precision 0.9284295547943615 specificity 0.8172044677904297 recall 0.9289005924950625 f1 0.926580733032882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 14.618118524551392 s\n",
      "Accuracy 0.9299978055738425 precision 0.9294164355042579 specificity 0.8089409979651444 recall 0.9299978055738425 f1 0.9275420243585504\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 15.23812460899353 s\n",
      "Accuracy 0.9285348548021359 precision 0.928285762743297 specificity 0.8075480122112672 recall 0.9285348548021359 f1 0.9259038859602364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 14.667117834091187 s\n",
      "Accuracy 0.9242191500256016 precision 0.9236939733956043 specificity 0.8026793584170497 recall 0.9242191500256016 f1 0.9214717263748572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 14.77212142944336 s\n",
      "Accuracy 0.9265598712603321 precision 0.9262273317105004 specificity 0.8056470230970078 recall 0.9265598712603321 f1 0.9238692463701564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 14.777108669281006 s\n",
      "Accuracy 0.9226830517153097 precision 0.9223578792606856 specificity 0.795863983090491 recall 0.9226830517153097 f1 0.9196580517390375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 14.868120193481445 s\n",
      "Accuracy 0.9270719040304294 precision 0.9269368812700908 specificity 0.8114625429122042 recall 0.9270719040304294 f1 0.9244724415772286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 14.54411506652832 s\n",
      "Accuracy 0.9332894448101822 precision 0.9326622558439801 specificity 0.8222745431718774 recall 0.9332894448101822 f1 0.9312199200644483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 14.844118595123291 s\n",
      "Accuracy 0.9299978055738425 precision 0.929689178621466 specificity 0.8141957636306169 recall 0.9299978055738425 f1 0.9275718749915038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 15.104120969772339 s\n",
      "Accuracy 0.9272181991076001 precision 0.9273667693986077 specificity 0.8043934334268728 recall 0.9272181991076001 f1 0.9243668465814766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 14.67411732673645 s\n",
      "Accuracy 0.9286811498793066 precision 0.9281861197370163 specificity 0.8096938075191512 recall 0.9286811498793066 f1 0.9261860848214799\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 14.768118381500244 s\n",
      "Accuracy 0.9280228220320387 precision 0.9274978306831909 specificity 0.8073436986897107 recall 0.9280228220320387 f1 0.9254683014502891\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 15.299123048782349 s\n",
      "Accuracy 0.9239265598712604 precision 0.9235750494785191 specificity 0.7981391184255905 recall 0.9239265598712604 f1 0.9209966055346462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 15.040120840072632 s\n",
      "Accuracy 0.9266330187989175 precision 0.926333596670119 specificity 0.8065701695791451 recall 0.9266330187989175 f1 0.9239560723274572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 15.157120704650879 s\n",
      "Accuracy 0.9306561334211104 precision 0.9303980425160205 specificity 0.8147623615527081 recall 0.9306561334211104 f1 0.9282395476653373\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 15.48012399673462 s\n",
      "Accuracy 0.9228293467924804 precision 0.92249236719723 specificity 0.8016917572241798 recall 0.9228293467924804 f1 0.9199655424403358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 16.713135719299316 s\n",
      "Accuracy 0.9220247238680418 precision 0.9217111893728273 specificity 0.801149812654905 recall 0.9220247238680418 f1 0.9191234741375975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 15.356123447418213 s\n",
      "Accuracy 0.9299978055738425 precision 0.9293409680787552 specificity 0.8131496048934994 recall 0.9299978055738425 f1 0.9276698563919519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 14.912120819091797 s\n",
      "Accuracy 0.9298515104966718 precision 0.9294819459110001 specificity 0.8084583236425316 recall 0.9298515104966718 f1 0.9273080068844954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 15.177124261856079 s\n",
      "Accuracy 0.9242191500256016 precision 0.9243428561285791 specificity 0.7937154354963226 recall 0.9242191500256016 f1 0.9210378817917818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 15.08012080192566 s\n",
      "Accuracy 0.923853412332675 precision 0.9230025798909665 specificity 0.8008842460399273 recall 0.923853412332675 f1 0.9211741894602872\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 15.142122745513916 s\n",
      "Accuracy 0.926998756491844 precision 0.926466355166901 specificity 0.8109076145848821 recall 0.926998756491844 f1 0.9245147144932077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 15.008125066757202 s\n",
      "Accuracy 0.9287542974178918 precision 0.9286013573867163 specificity 0.8091913331770403 recall 0.9287542974178918 f1 0.9261374665427667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 14.864115238189697 s\n",
      "Accuracy 0.9299246580352571 precision 0.9296724641303196 specificity 0.8147472965113287 recall 0.9299246580352571 f1 0.9274921760507527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 14.84812045097351 s\n",
      "Accuracy 0.9215858386365299 precision 0.9215080220431036 specificity 0.7917033824019459 recall 0.9215858386365299 f1 0.9183485610141227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 14.936119079589844 s\n",
      "Accuracy 0.9242191500256016 precision 0.9240958109566841 specificity 0.799819928525502 recall 0.9242191500256016 f1 0.9212677067044586\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 14.760117530822754 s\n",
      "Accuracy 0.9253895106429668 precision 0.9247658187151412 specificity 0.8001637574058418 recall 0.9253895106429668 f1 0.9226362860353585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 15.012121438980103 s\n",
      "Accuracy 0.9295589203423305 precision 0.929185873599886 specificity 0.8049420192626475 recall 0.9295589203423305 f1 0.9269270634386604\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 15.10711932182312 s\n",
      "Accuracy 0.9285348548021359 precision 0.9283858511505241 specificity 0.8155361165591031 recall 0.9285348548021359 f1 0.9260639381123632\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 14.937121152877808 s\n",
      "Accuracy 0.9275839368005266 precision 0.9270544064379844 specificity 0.8071559016027086 recall 0.9275839368005266 f1 0.925017650142631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 17.60414409637451 s\n",
      "Accuracy 0.9272913466461854 precision 0.9266565751893223 specificity 0.8122834045431567 recall 0.9272913466461854 f1 0.9248841291813972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 16.266130685806274 s\n",
      "Accuracy 0.9266330187989175 precision 0.9263080423416855 specificity 0.8072977747303255 recall 0.9266330187989175 f1 0.9239823460217543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 15.199122428894043 s\n",
      "Accuracy 0.9257552483358935 precision 0.9250345922261541 specificity 0.8023361634654912 recall 0.9257552483358935 f1 0.9231013898148117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 15.366124153137207 s\n",
      "Accuracy 0.9256089532587228 precision 0.9254547201282968 specificity 0.8006777955794204 recall 0.9256089532587228 f1 0.9227181945690156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 15.415125370025635 s\n",
      "Accuracy 0.9250969204886256 precision 0.9245262712424194 specificity 0.8014508358497051 recall 0.9250969204886256 f1 0.922351537139291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 14.783119678497314 s\n",
      "Accuracy 0.9259746909516495 precision 0.9254096495062117 specificity 0.8034528804648626 recall 0.9259746909516495 f1 0.9232963187929998\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 15.162122249603271 s\n",
      "Accuracy 0.9289737400336479 precision 0.9286338691849934 specificity 0.8120004196720089 recall 0.9289737400336479 f1 0.9264869665098316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 15.656128406524658 s\n",
      "Accuracy 0.9275107892619413 precision 0.9269526069641142 specificity 0.8054692721867363 recall 0.9275107892619413 f1 0.9249117000531802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 15.999128103256226 s\n",
      "Accuracy 0.9292663301879892 precision 0.929391246821055 specificity 0.8114459708202657 recall 0.9292663301879892 f1 0.9266329957792434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 14.775120496749878 s\n",
      "Accuracy 0.9249506254114549 precision 0.9246608462506813 specificity 0.8015394545892107 recall 0.9249506254114549 f1 0.9221100711104303\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 14.879120826721191 s\n",
      "Accuracy 0.9282422646477946 precision 0.9277472925884979 specificity 0.8097200445041766 recall 0.9282422646477946 f1 0.9257392735159851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 15.135119915008545 s\n",
      "Accuracy 0.9284617072635506 precision 0.928258117247127 specificity 0.8073960825842007 recall 0.9284617072635506 f1 0.9258114301823664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 15.076119184494019 s\n",
      "Accuracy 0.9322653792699875 precision 0.9318458690196885 specificity 0.8193320353791774 recall 0.9322653792699875 f1 0.9300357290561713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 14.989118576049805 s\n",
      "Accuracy 0.9272181991076001 precision 0.9270699268125536 specificity 0.8084592820352846 recall 0.9272181991076001 f1 0.924552060065856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 14.865118980407715 s\n",
      "Accuracy 0.9272913466461854 precision 0.9272499141569361 specificity 0.8022475143102757 recall 0.9272913466461854 f1 0.9244425352728368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 14.993120670318604 s\n",
      "Accuracy 0.9305098383439397 precision 0.9301968694139738 specificity 0.8142855191518835 recall 0.9305098383439397 f1 0.9280970509639275\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 14.723120927810669 s\n",
      "Accuracy 0.9299246580352571 precision 0.9290564863951617 specificity 0.8158643727204369 recall 0.9299246580352571 f1 0.927747434734166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 15.01911973953247 s\n",
      "Accuracy 0.9286080023407213 precision 0.928897030908867 specificity 0.8019000743622822 recall 0.9286080023407213 f1 0.9256887269486518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 14.675116777420044 s\n",
      "Accuracy 0.9287542974178918 precision 0.9282640350098986 specificity 0.8102342908894397 recall 0.9287542974178918 f1 0.9262719840549257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 14.835119724273682 s\n",
      "Accuracy 0.9278033794162827 precision 0.9275664212881075 specificity 0.8026897139333627 recall 0.9278033794162827 f1 0.9250354300245928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 14.711118698120117 s\n",
      "Accuracy 0.9275107892619413 precision 0.9271425792495135 specificity 0.8118736741034465 recall 0.9275107892619413 f1 0.9250031687685846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 15.004122495651245 s\n",
      "Accuracy 0.9314607563455489 precision 0.9310768937011733 specificity 0.814829759220958 recall 0.9314607563455489 f1 0.9291020268703284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 14.840118885040283 s\n",
      "Accuracy 0.9221710189452125 precision 0.922078694833319 specificity 0.7989225483069332 recall 0.9221710189452125 f1 0.9191446069364886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 14.873120069503784 s\n",
      "Accuracy 0.9259746909516495 precision 0.925758660665353 specificity 0.8015316487634688 recall 0.9259746909516495 f1 0.9231322006350139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 14.845117807388306 s\n",
      "Accuracy 0.927437641723356 precision 0.9269098665116358 specificity 0.8084609506397245 recall 0.927437641723356 f1 0.9248999268015018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 14.967121601104736 s\n",
      "Accuracy 0.926998756491844 precision 0.9265444248402999 specificity 0.8146283335535431 recall 0.926998756491844 f1 0.9245787210984199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 15.02512001991272 s\n",
      "Accuracy 0.9304366908053544 precision 0.9305980766133547 specificity 0.8088770240735141 recall 0.9304366908053544 f1 0.9277570618447444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 14.663118839263916 s\n",
      "Accuracy 0.9246580352571137 precision 0.924441079366475 specificity 0.796487441161478 recall 0.9246580352571137 f1 0.9216585907728239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 15.02212119102478 s\n",
      "Accuracy 0.9277302318776973 precision 0.9274983472329341 specificity 0.8097931302665998 recall 0.9277302318776973 f1 0.925132202361547\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 14.797117948532104 s\n",
      "Accuracy 0.9303635432667691 precision 0.9306637372579382 specificity 0.8071093597055439 recall 0.9303635432667691 f1 0.9276043316426138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 14.848121166229248 s\n",
      "Accuracy 0.926998756491844 precision 0.9267547998859823 specificity 0.8068977293863536 recall 0.926998756491844 f1 0.9243195150167287\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 14.825117111206055 s\n",
      "Accuracy 0.9277302318776973 precision 0.9274511412097706 specificity 0.8054741153880065 recall 0.9277302318776973 f1 0.9250419790312423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 14.899119853973389 s\n",
      "Accuracy 0.9283885597249653 precision 0.9275886566401456 specificity 0.8107955767052379 recall 0.9283885597249653 f1 0.926030246854925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 15.069119691848755 s\n",
      "Accuracy 0.9278033794162827 precision 0.927788553905635 specificity 0.8015824053835426 recall 0.9278033794162827 f1 0.9249418346502543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 14.82211685180664 s\n",
      "Accuracy 0.9263404286445761 precision 0.9259377013642236 specificity 0.811691752073466 recall 0.9263404286445761 f1 0.9238189883101443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 14.791114807128906 s\n",
      "Accuracy 0.9313876088069637 precision 0.9314870960694239 specificity 0.814188884925431 recall 0.9313876088069637 f1 0.9288665520687303\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 14.893119812011719 s\n",
      "Accuracy 0.9283154121863799 precision 0.9280418226681756 specificity 0.8133338581739209 recall 0.9283154121863799 f1 0.925826840570803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 14.922119617462158 s\n",
      "Accuracy 0.9285348548021359 precision 0.9283308592173509 specificity 0.8097847573048712 recall 0.9285348548021359 f1 0.9259435121711155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 14.62111520767212 s\n",
      "Accuracy 0.9275839368005266 precision 0.927177994948081 specificity 0.8046310412590624 recall 0.9275839368005266 f1 0.9249132632127026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 15.00512146949768 s\n",
      "Accuracy 0.9278033794162827 precision 0.9275502649035863 specificity 0.8070756609115735 recall 0.9278033794162827 f1 0.9251474315980215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 14.935118913650513 s\n",
      "Accuracy 0.9288274449564772 precision 0.9282341069246672 specificity 0.8134840855751001 recall 0.9288274449564772 f1 0.9264616465644383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 14.879120826721191 s\n",
      "Accuracy 0.9256821007973082 precision 0.9255595083213349 specificity 0.7993317545039521 recall 0.9256821007973082 f1 0.9227493210021427\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 14.984119176864624 s\n",
      "Accuracy 0.927437641723356 precision 0.927009252626283 specificity 0.8095906300897043 recall 0.927437641723356 f1 0.9248931504073781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 14.837120771408081 s\n",
      "Accuracy 0.9275839368005266 precision 0.9273417472963252 specificity 0.8076233797387866 recall 0.9275839368005266 f1 0.9249335093463542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 15.115121841430664 s\n",
      "Accuracy 0.9305098383439397 precision 0.9300606684323877 specificity 0.8131306346222366 recall 0.9305098383439397 f1 0.9281157709110907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 15.053122997283936 s\n",
      "Accuracy 0.923633969716919 precision 0.9231347226002362 specificity 0.7987408136199198 recall 0.923633969716919 f1 0.9207629355649776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 14.848120927810669 s\n",
      "Accuracy 0.926779313876088 precision 0.9267302001782256 specificity 0.8026882637153439 recall 0.926779313876088 f1 0.9239325938703146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 14.874119758605957 s\n",
      "Accuracy 0.9289737400336479 precision 0.9285791716174596 specificity 0.8073158772151632 recall 0.9289737400336479 f1 0.9263932171126976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 14.88711929321289 s\n",
      "Accuracy 0.9257552483358935 precision 0.9256109137463358 specificity 0.7931731150886842 recall 0.9257552483358935 f1 0.922674290092906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 14.726119756698608 s\n",
      "Accuracy 0.9275107892619413 precision 0.9270743143140849 specificity 0.8085772478129191 recall 0.9275107892619413 f1 0.9249456441544599\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 15.027120113372803 s\n",
      "Accuracy 0.9272913466461854 precision 0.92720917013098 specificity 0.8078446477785595 recall 0.9272913466461854 f1 0.9245917998391535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 14.806119441986084 s\n",
      "Accuracy 0.9253895106429668 precision 0.9247848020913038 specificity 0.8019433159092227 recall 0.9253895106429668 f1 0.9226749921886265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 14.871119737625122 s\n",
      "Accuracy 0.9309487235754517 precision 0.9304187189676948 specificity 0.8126961738345809 recall 0.9309487235754517 f1 0.9285815470926523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 14.88211965560913 s\n",
      "Accuracy 0.9293394777265745 precision 0.9288205383597473 specificity 0.8157316951939113 recall 0.9293394777265745 f1 0.9270093224894351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 14.8621187210083 s\n",
      "Accuracy 0.9244385926413576 precision 0.9238588387903094 specificity 0.800182016456234 recall 0.9244385926413576 f1 0.9216500728755807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 14.844122886657715 s\n",
      "Accuracy 0.9254626581815522 precision 0.9252501723579589 specificity 0.8003837463224409 recall 0.9254626581815522 f1 0.9225791598660144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 14.851118087768555 s\n",
      "Accuracy 0.9263404286445761 precision 0.9260796872320507 specificity 0.8128636495321211 recall 0.9263404286445761 f1 0.9238014508173544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 14.768118858337402 s\n",
      "Accuracy 0.9315339038841343 precision 0.9308636929785774 specificity 0.8166566728077442 recall 0.9315339038841343 f1 0.9293220774313413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 15.024125814437866 s\n",
      "Accuracy 0.9287542974178918 precision 0.9286226480498824 specificity 0.8091975362051018 recall 0.9287542974178918 f1 0.9261311881445737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 14.55811595916748 s\n",
      "Accuracy 0.9282422646477946 precision 0.9280705700091998 specificity 0.8079512709549929 recall 0.9282422646477946 f1 0.9255911244674492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 15.288120746612549 s\n",
      "Accuracy 0.9259746909516495 precision 0.9254947790272431 specificity 0.8074494169272588 recall 0.9259746909516495 f1 0.9233671070435829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 14.616119861602783 s\n",
      "Accuracy 0.9302903957281837 precision 0.9300298447718273 specificity 0.8098707285656813 recall 0.9302903957281837 f1 0.9277539096164041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 15.240121126174927 s\n",
      "Accuracy 0.9257552483358935 precision 0.925568829589245 specificity 0.8029522937630529 recall 0.9257552483358935 f1 0.9229347996665537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 14.887119770050049 s\n",
      "Accuracy 0.9291200351108185 precision 0.9285524382532131 specificity 0.805095129826263 recall 0.9291200351108185 f1 0.9265489858029353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 15.149122953414917 s\n",
      "Accuracy 0.9255358057201375 precision 0.9253078719485394 specificity 0.8050492009014775 recall 0.9255358057201375 f1 0.9227766404000366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 14.998122692108154 s\n",
      "Accuracy 0.9305829858825251 precision 0.9299750182455304 specificity 0.8153217632633353 recall 0.9305829858825251 f1 0.9282985242865108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 16.379130601882935 s\n",
      "Accuracy 0.9296320678809158 precision 0.9289250828955509 specificity 0.8142890639670043 recall 0.9296320678809158 f1 0.9273439372997881\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 15.947126865386963 s\n",
      "Accuracy 0.9290468875722332 precision 0.9288650311846088 specificity 0.8080665058333139 recall 0.9290468875722332 f1 0.9264179519911047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 14.838121175765991 s\n",
      "Accuracy 0.9249506254114549 precision 0.9243087569242606 specificity 0.8071410412378999 recall 0.9249506254114549 f1 0.9223743253559225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 15.165122985839844 s\n",
      "Accuracy 0.9272913466461854 precision 0.9271147605423967 specificity 0.8063981361126406 recall 0.9272913466461854 f1 0.9245847985127854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 15.385124683380127 s\n",
      "Accuracy 0.9273644941847707 precision 0.9274396384939635 specificity 0.7968064662381598 recall 0.9273644941847707 f1 0.9243497649650921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 16.179129123687744 s\n",
      "Accuracy 0.9275839368005266 precision 0.9272660478148631 specificity 0.8098768577660908 recall 0.9275839368005266 f1 0.925012548682955\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 15.533125400543213 s\n",
      "Accuracy 0.9283885597249653 precision 0.928250000458187 specificity 0.8027757825966377 recall 0.9283885597249653 f1 0.9256054565790711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 15.194122552871704 s\n",
      "Accuracy 0.9275107892619413 precision 0.9272871285417488 specificity 0.8141060869861165 recall 0.9275107892619413 f1 0.9250107309152399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 15.517126321792603 s\n",
      "Accuracy 0.9261941335674054 precision 0.9255866619446359 specificity 0.8084870969976143 recall 0.9261941335674054 f1 0.9236622668976793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 15.753886699676514 s\n",
      "Accuracy 0.9244385926413576 precision 0.9242392454770206 specificity 0.8024229435336687 recall 0.9244385926413576 f1 0.92158190660501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 15.125679969787598 s\n",
      "Accuracy 0.9278033794162827 precision 0.9276090657987441 specificity 0.8068751447103601 recall 0.9278033794162827 f1 0.9251242592462843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 15.207385301589966 s\n",
      "Accuracy 0.9255358057201375 precision 0.9250907385299756 specificity 0.8035801786599087 recall 0.9255358057201375 f1 0.9228100953438132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 15.032503128051758 s\n",
      "Accuracy 0.9245848877185283 precision 0.9238618807408049 specificity 0.8011821341520545 recall 0.9245848877185283 f1 0.9218781074274841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 15.19807505607605 s\n",
      "Accuracy 0.9248043303342842 precision 0.9242752566136336 specificity 0.8003564094192872 recall 0.9248043303342842 f1 0.9220100760145901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 15.02440333366394 s\n",
      "Accuracy 0.9287542974178918 precision 0.9285214301593657 specificity 0.8062509445730592 recall 0.9287542974178918 f1 0.9260916463179721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 14.804051637649536 s\n",
      "Accuracy 0.9297052154195011 precision 0.9290889288334752 specificity 0.813189752120659 recall 0.9297052154195011 f1 0.927357262137817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 15.049726486206055 s\n",
      "Accuracy 0.9272913466461854 precision 0.9271193044637472 specificity 0.8055795879206881 recall 0.9272913466461854 f1 0.9245633380111562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 15.048066139221191 s\n",
      "Accuracy 0.9260478384902348 precision 0.9254978741680648 specificity 0.8026384975914431 recall 0.9260478384902348 f1 0.9233450345035795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 14.984217882156372 s\n",
      "Accuracy 0.9289737400336479 precision 0.9285373574999658 specificity 0.8100794912297914 recall 0.9289737400336479 f1 0.9264734091158059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 15.035455226898193 s\n",
      "Accuracy 0.927657084339112 precision 0.927743888429821 specificity 0.8092404073720438 recall 0.927657084339112 f1 0.9249500922655274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 15.262690305709839 s\n",
      "Accuracy 0.9298515104966718 precision 0.9297519200543216 specificity 0.80963101039342 recall 0.9298515104966718 f1 0.9272512342905078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 15.293561935424805 s\n",
      "Accuracy 0.9284617072635506 precision 0.9280670577344998 specificity 0.8118477354218198 recall 0.9284617072635506 f1 0.9259798131408513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 15.015383243560791 s\n",
      "Accuracy 0.9288274449564772 precision 0.9286053854138288 specificity 0.8122640351150928 recall 0.9288274449564772 f1 0.9263065207867491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 14.976516246795654 s\n",
      "Accuracy 0.927657084339112 precision 0.9270903803842245 specificity 0.8118891008085292 recall 0.927657084339112 f1 0.9252215083141173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 15.640053510665894 s\n",
      "Accuracy 0.9246580352571137 precision 0.9241780064900951 specificity 0.7992163368461986 recall 0.9246580352571137 f1 0.9218143620300899\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 15.378055095672607 s\n",
      "Accuracy 0.9317533464998903 precision 0.9311813233496319 specificity 0.8209259168955245 recall 0.9317533464998903 f1 0.9296055132464144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 15.769054412841797 s\n",
      "Accuracy 0.9256089532587228 precision 0.9255933582511755 specificity 0.8029674863270249 recall 0.9256089532587228 f1 0.9227349100692505\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 15.323054313659668 s\n",
      "Accuracy 0.9268524614146734 precision 0.9265554046201286 specificity 0.8076542152257675 recall 0.9268524614146734 f1 0.9242058509992938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 15.511053323745728 s\n",
      "Accuracy 0.9280959695706239 precision 0.9273973448424299 specificity 0.802786390677206 recall 0.9280959695706239 f1 0.9254947426816998\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 15.376053094863892 s\n",
      "Accuracy 0.9259746909516495 precision 0.9256032158269073 specificity 0.8041592573835435 recall 0.9259746909516495 f1 0.923247865014654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 15.285053730010986 s\n",
      "Accuracy 0.9289005924950625 precision 0.9282762214777639 specificity 0.8139477066695235 recall 0.9289005924950625 f1 0.9265588878959135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 15.839056253433228 s\n",
      "Accuracy 0.9253895106429668 precision 0.9252605333735524 specificity 0.8029280355341176 recall 0.9253895106429668 f1 0.922543482740492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 15.77656865119934 s\n",
      "Accuracy 0.9277302318776973 precision 0.9269674770706996 specificity 0.804390860717565 recall 0.9277302318776973 f1 0.9251856325405686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 15.493571996688843 s\n",
      "Accuracy 0.9272181991076001 precision 0.9265076360397541 specificity 0.8083659043599758 recall 0.9272181991076001 f1 0.9247416760536774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 15.00267219543457 s\n",
      "Accuracy 0.9286080023407213 precision 0.9283266597236834 specificity 0.8113228514217674 recall 0.9286080023407213 f1 0.9260791947376751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 15.097051858901978 s\n",
      "Accuracy 0.9302903957281837 precision 0.9300813289855057 specificity 0.8093530581514191 recall 0.9302903957281837 f1 0.927725764734369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 15.562085151672363 s\n",
      "Accuracy 0.9268524614146734 precision 0.9273350298803449 specificity 0.8019300748921844 recall 0.9268524614146734 f1 0.9238447923490517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 15.071565389633179 s\n",
      "Accuracy 0.9291931826494039 precision 0.9287264608297683 specificity 0.8075855975958827 recall 0.9291931826494039 f1 0.9266480427488001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 14.995051860809326 s\n",
      "Accuracy 0.9293394777265745 precision 0.9292502215020851 specificity 0.8087613888218769 recall 0.9293394777265745 f1 0.9267051853179252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 14.845052480697632 s\n",
      "Accuracy 0.9294857728037451 precision 0.9289967477807707 specificity 0.806744792040446 recall 0.9294857728037451 f1 0.9269343683086277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 14.828049659729004 s\n",
      "Accuracy 0.9250237729500402 precision 0.924386104303833 specificity 0.8033687499937627 recall 0.9250237729500402 f1 0.9223504375846872\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 15.213567018508911 s\n",
      "Accuracy 0.9287542974178918 precision 0.9287365746158823 specificity 0.8027526892004899 recall 0.9287542974178918 f1 0.9259432280313185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 14.810815811157227 s\n",
      "Accuracy 0.9259746909516495 precision 0.925570204219721 specificity 0.8045164298850518 recall 0.9259746909516495 f1 0.923267783177052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 15.82656478881836 s\n",
      "Accuracy 0.9333625923487675 precision 0.9332513824278792 specificity 0.8162954388082595 recall 0.9333625923487675 f1 0.9309880018599688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 14.892564535140991 s\n",
      "Accuracy 0.926998756491844 precision 0.9267653414263811 specificity 0.8043622618518954 recall 0.926998756491844 f1 0.9242536960873472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 15.438055992126465 s\n",
      "Accuracy 0.9296320678809158 precision 0.929572465177077 specificity 0.8083941468619995 recall 0.9296320678809158 f1 0.9269864168964869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 14.964050769805908 s\n",
      "Accuracy 0.9278033794162827 precision 0.9275146782011343 specificity 0.8053350203641567 recall 0.9278033794162827 f1 0.9251163044743509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 14.873051881790161 s\n",
      "Accuracy 0.9315339038841343 precision 0.9312562365006856 specificity 0.8083980863199594 recall 0.9315339038841343 f1 0.9289949895290616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 14.903051137924194 s\n",
      "Accuracy 0.9264867237217468 precision 0.9255829185028788 specificity 0.8099193499635667 recall 0.9264867237217468 f1 0.9241151864952001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 15.336053371429443 s\n",
      "Accuracy 0.9306561334211104 precision 0.9304908449318284 specificity 0.8122818887125557 recall 0.9306561334211104 f1 0.9281534952000088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 14.560051441192627 s\n",
      "Accuracy 0.9261941335674054 precision 0.925777585885556 specificity 0.8058261968464998 recall 0.9261941335674054 f1 0.9235284745486414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 14.836054801940918 s\n",
      "Accuracy 0.9285348548021359 precision 0.9280739180293671 specificity 0.8107650098314472 recall 0.9285348548021359 f1 0.9260508837270875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 14.860559225082397 s\n",
      "Accuracy 0.9250237729500402 precision 0.9247711137271006 specificity 0.7964985554239945 recall 0.9250237729500402 f1 0.9220439402735823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 15.025569438934326 s\n",
      "Accuracy 0.9291931826494039 precision 0.9286497453381878 specificity 0.8165425645549628 recall 0.9291931826494039 f1 0.9268885665300799\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 15.27605390548706 s\n",
      "Accuracy 0.9258283958744788 precision 0.9256978745235492 specificity 0.7985722499598229 recall 0.9258283958744788 f1 0.9228820183917839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 15.070497035980225 s\n",
      "Accuracy 0.927657084339112 precision 0.927781934426746 specificity 0.8066207684982742 recall 0.927657084339112 f1 0.9248758555204332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 15.134052753448486 s\n",
      "Accuracy 0.9280228220320387 precision 0.9280085265764428 specificity 0.8093551572850622 recall 0.9280228220320387 f1 0.925354466843634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 15.1871337890625 s\n",
      "Accuracy 0.9264135761831614 precision 0.9258811415146838 specificity 0.8012596808734993 recall 0.9264135761831614 f1 0.9236775618719723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 15.051052808761597 s\n",
      "Accuracy 0.9256821007973082 precision 0.9256292116691188 specificity 0.7993856546862438 recall 0.9256821007973082 f1 0.9227300205604552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 15.27505373954773 s\n",
      "Accuracy 0.9259015434130642 precision 0.9253523790783524 specificity 0.8048033703560291 recall 0.9259015434130642 f1 0.9232501862752255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 14.873051881790161 s\n",
      "Accuracy 0.9281691171092092 precision 0.9276601716551116 specificity 0.8087327881524325 recall 0.9281691171092092 f1 0.9256456569476004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 15.085060358047485 s\n",
      "Accuracy 0.930802428498281 precision 0.930208895262976 specificity 0.8151755645717936 recall 0.930802428498281 f1 0.9285132432253972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 14.848044633865356 s\n",
      "Accuracy 0.9309487235754517 precision 0.9305252589733695 specificity 0.8191168885058638 recall 0.9309487235754517 f1 0.9286921717529536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 15.047053098678589 s\n",
      "Accuracy 0.9240728549484309 precision 0.924053401366769 specificity 0.8059370757528481 recall 0.9240728549484309 f1 0.9212453911187571\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 14.845053434371948 s\n",
      "Accuracy 0.9277302318776973 precision 0.9275859650912063 specificity 0.8130532552948475 recall 0.9277302318776973 f1 0.9251841081345156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 14.978049993515015 s\n",
      "Accuracy 0.9287542974178918 precision 0.9281772703277933 specificity 0.8050012819330706 recall 0.9287542974178918 f1 0.926176526591314\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 15.027052879333496 s\n",
      "Accuracy 0.9257552483358935 precision 0.9254595812823913 specificity 0.7988242549229156 recall 0.9257552483358935 f1 0.9228646319711443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 14.793052196502686 s\n",
      "Accuracy 0.9280228220320387 precision 0.927682643100599 specificity 0.8107157087407711 recall 0.9280228220320387 f1 0.9254873519955396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 14.945562362670898 s\n",
      "Accuracy 0.927437641723356 precision 0.9273977462034533 specificity 0.8084813815684585 recall 0.927437641723356 f1 0.9247440831228275\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 14.877052783966064 s\n",
      "Accuracy 0.9268524614146734 precision 0.9267728981617999 specificity 0.8037412486262372 recall 0.9268524614146734 f1 0.9240423135012343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 14.852054119110107 s\n",
      "Accuracy 0.9272181991076001 precision 0.9264947136973728 specificity 0.8094041597701526 recall 0.9272181991076001 f1 0.9247725417113991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 15.210556268692017 s\n",
      "Accuracy 0.9302172481895984 precision 0.9298294750160625 specificity 0.8140537317447172 recall 0.9302172481895984 f1 0.9278182116872664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 15.100053071975708 s\n",
      "Accuracy 0.9272181991076001 precision 0.9271408469563365 specificity 0.8087807794021803 recall 0.9272181991076001 f1 0.9245386877941661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 15.04705262184143 s\n",
      "Accuracy 0.926779313876088 precision 0.9262242950962338 specificity 0.8098250807925729 recall 0.926779313876088 f1 0.9242725811099177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 14.932052612304688 s\n",
      "Accuracy 0.9289737400336479 precision 0.9283198668714623 specificity 0.8136135869148425 recall 0.9289737400336479 f1 0.9266365870264999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 15.037054061889648 s\n",
      "Accuracy 0.927876526954868 precision 0.927403946397984 specificity 0.8102122250473859 recall 0.927876526954868 f1 0.9253706821975913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 14.723051071166992 s\n",
      "Accuracy 0.9253895106429668 precision 0.9249232287102982 specificity 0.8010360359034825 recall 0.9253895106429668 f1 0.9226033043399011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 14.862051963806152 s\n",
      "Accuracy 0.9285348548021359 precision 0.9279360624271872 specificity 0.8103119764507518 recall 0.9285348548021359 f1 0.9260891221116493\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 15.316563129425049 s\n",
      "Accuracy 0.9309487235754517 precision 0.9307489574658605 specificity 0.8108091825798571 recall 0.9309487235754517 f1 0.9284285584315091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 15.40605354309082 s\n",
      "Accuracy 0.9235608221783337 precision 0.9228260949094964 specificity 0.7993073917369699 recall 0.9235608221783337 f1 0.9207882953111749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 15.398054599761963 s\n",
      "Accuracy 0.924292297564187 precision 0.9239823894663787 specificity 0.7996775310991655 recall 0.924292297564187 f1 0.9213966084667492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 15.131582498550415 s\n",
      "Accuracy 0.9295589203423305 precision 0.9291234907560948 specificity 0.8135575551560201 recall 0.9295589203423305 f1 0.9271520558822539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 15.481053590774536 s\n",
      "Accuracy 0.9261941335674054 precision 0.9259104653742108 specificity 0.8053715322371892 recall 0.9261941335674054 f1 0.9234736474603193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 14.9210524559021 s\n",
      "Accuracy 0.9260478384902348 precision 0.9256086168639491 specificity 0.806006472615087 recall 0.9260478384902348 f1 0.9233914904050731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 15.130053281784058 s\n",
      "Accuracy 0.927657084339112 precision 0.926894726386234 specificity 0.8091558972239185 recall 0.927657084339112 f1 0.9252290524464015\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 15.248053073883057 s\n",
      "Accuracy 0.9222441664837978 precision 0.9218434645125979 specificity 0.7982615693826596 recall 0.9222441664837978 f1 0.9192985938495162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 15.290053129196167 s\n",
      "Accuracy 0.9273644941847707 precision 0.9270025899826402 specificity 0.8058103172926951 recall 0.9273644941847707 f1 0.924703691769886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 15.36156678199768 s\n",
      "Accuracy 0.9279496744934533 precision 0.927860852482314 specificity 0.8096023280577521 recall 0.9279496744934533 f1 0.9253076722290479\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 15.319053888320923 s\n",
      "Accuracy 0.9258283958744788 precision 0.9253986421021543 specificity 0.801749645483027 recall 0.9258283958744788 f1 0.9230571739865138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 15.143764972686768 s\n",
      "Accuracy 0.9253895106429668 precision 0.9252010194170265 specificity 0.8042307423122018 recall 0.9253895106429668 f1 0.9225945582132361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 15.070094347000122 s\n",
      "Accuracy 0.9286811498793066 precision 0.9284493229792309 specificity 0.8090772973156485 recall 0.9286811498793066 f1 0.9260844025190006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 14.794688940048218 s\n",
      "Accuracy 0.927437641723356 precision 0.9273493002083306 specificity 0.8082411578845092 recall 0.927437641723356 f1 0.9247524771486231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 14.908052682876587 s\n",
      "Accuracy 0.9263404286445761 precision 0.9266425590400219 specificity 0.7977407379850148 recall 0.9263404286445761 f1 0.9232630475399678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 15.392054080963135 s\n",
      "Accuracy 0.927437641723356 precision 0.9270632754820207 specificity 0.8084293903506958 recall 0.927437641723356 f1 0.924846617377346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 14.820051670074463 s\n",
      "Accuracy 0.9250969204886256 precision 0.924857633078806 specificity 0.7974563772284858 recall 0.9250969204886256 f1 0.9221391188953376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 14.874567031860352 s\n",
      "Accuracy 0.9281691171092092 precision 0.9275376284658781 specificity 0.8141427768148612 recall 0.9281691171092092 f1 0.9258217295141956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 15.043518781661987 s\n",
      "Accuracy 0.9252432155657963 precision 0.9246434978338514 specificity 0.8006928140788557 recall 0.9252432155657963 f1 0.9224918139623312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 15.087474822998047 s\n",
      "Accuracy 0.9268524614146734 precision 0.9263632109868267 specificity 0.8042071905363154 recall 0.9268524614146734 f1 0.9241844077001975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 14.976173877716064 s\n",
      "Accuracy 0.931899641577061 precision 0.9315447082113165 specificity 0.8173009246772188 recall 0.931899641577061 f1 0.9295957169479028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 15.01205325126648 s\n",
      "Accuracy 0.9279496744934533 precision 0.9272619193469378 specificity 0.8138625738234085 recall 0.9279496744934533 f1 0.9256132944470942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 15.351053953170776 s\n",
      "Accuracy 0.9297783629580865 precision 0.9293008461862698 specificity 0.8142132288894266 recall 0.9297783629580865 f1 0.9274056189861382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 15.14705228805542 s\n",
      "Accuracy 0.9296320678809158 precision 0.9290946677769184 specificity 0.8096648364040382 recall 0.9296320678809158 f1 0.9271701573891592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 14.895053148269653 s\n",
      "Accuracy 0.9245848877185283 precision 0.9242240841077225 specificity 0.7956456434721361 recall 0.9245848877185283 f1 0.9216075909461396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 15.052053689956665 s\n",
      "Accuracy 0.9254626581815522 precision 0.9254478042940235 specificity 0.80121487884648 recall 0.9254626581815522 f1 0.9225410550784894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 14.919559955596924 s\n",
      "Accuracy 0.9283154121863799 precision 0.9278902628911851 specificity 0.8078180620189016 recall 0.9283154121863799 f1 0.9257438218941767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 15.023052215576172 s\n",
      "Accuracy 0.9219515763294566 precision 0.9215373737010117 specificity 0.7857631786967765 recall 0.9219515763294566 f1 0.9186664946816064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 14.96805214881897 s\n",
      "Accuracy 0.9269256089532587 precision 0.9262855072641493 specificity 0.8080778119224854 recall 0.9269256089532587 f1 0.9244094459307433\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 14.934593200683594 s\n",
      "Accuracy 0.9272181991076001 precision 0.9270715783651702 specificity 0.8064707321258291 recall 0.9272181991076001 f1 0.9245028411375713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 15.336565494537354 s\n",
      "Accuracy 0.9319727891156463 precision 0.9320659297145427 specificity 0.8203241583916601 recall 0.9319727891156463 f1 0.9296029566699244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 15.626572847366333 s\n",
      "Accuracy 0.927657084339112 precision 0.9271895133826822 specificity 0.8048511885486068 recall 0.927657084339112 f1 0.9250141527497152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 14.995561838150024 s\n",
      "Accuracy 0.9300709531124277 precision 0.929441612576741 specificity 0.8130934730240641 recall 0.9300709531124277 f1 0.9277325884866701\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 14.70505166053772 s\n",
      "Accuracy 0.9271450515690147 precision 0.9265337907108477 specificity 0.8050604236173162 recall 0.9271450515690147 f1 0.9245475282092893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 15.119508504867554 s\n",
      "Accuracy 0.9298515104966718 precision 0.9296297482711593 specificity 0.8118982615845769 recall 0.9298515104966718 f1 0.9273414892773358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 15.221818685531616 s\n",
      "Accuracy 0.9271450515690147 precision 0.9264992032343093 specificity 0.8086544887153082 recall 0.9271450515690147 f1 0.924649571665928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 14.886053323745728 s\n",
      "Accuracy 0.9269256089532587 precision 0.9263703073421291 specificity 0.8013467242583563 recall 0.9269256089532587 f1 0.9242108513394574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 14.893051624298096 s\n",
      "Accuracy 0.923853412332675 precision 0.9239043624360104 specificity 0.7919552506440173 recall 0.923853412332675 f1 0.9206380468584965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 14.994052648544312 s\n",
      "Accuracy 0.9275107892619413 precision 0.9267823542544877 specificity 0.8077698590923754 recall 0.9275107892619413 f1 0.9250321214106543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 15.002052068710327 s\n",
      "Accuracy 0.9254626581815522 precision 0.9253731621762081 specificity 0.8061467260516569 recall 0.9254626581815522 f1 0.9226875217846051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 15.03005337715149 s\n",
      "Accuracy 0.9294126252651598 precision 0.9291795192940857 specificity 0.815373467374441 recall 0.9294126252651598 f1 0.9269794386637324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 14.89405369758606 s\n",
      "Accuracy 0.9261209860288201 precision 0.9254696736443814 specificity 0.7953646007515084 recall 0.9261209860288201 f1 0.9232713619291217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 15.028053045272827 s\n",
      "Accuracy 0.923633969716919 precision 0.92322360614268 specificity 0.7951804498304738 recall 0.923633969716919 f1 0.9206394380026436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 15.602053880691528 s\n",
      "Accuracy 0.9293394777265745 precision 0.9291823222362992 specificity 0.8127785433974389 recall 0.9293394777265745 f1 0.926820414867715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 15.124533414840698 s\n",
      "Accuracy 0.9310950186526223 precision 0.9307761854199561 specificity 0.817575853468228 recall 0.9310950186526223 f1 0.9287706841563091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 14.87005066871643 s\n",
      "Accuracy 0.9308755760368663 precision 0.930571382183858 specificity 0.8133787180652208 recall 0.9308755760368663 f1 0.9284460414094019\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 15.198054313659668 s\n",
      "Accuracy 0.9253895106429668 precision 0.9253279459208618 specificity 0.7975630193518167 recall 0.9253895106429668 f1 0.922387207508958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 15.111979246139526 s\n",
      "Accuracy 0.9279496744934533 precision 0.9274124805573499 specificity 0.8091887676383663 recall 0.9279496744934533 f1 0.9254430298413895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 14.948050022125244 s\n",
      "Accuracy 0.9259015434130642 precision 0.9255333341125109 specificity 0.8039964112997756 recall 0.9259015434130642 f1 0.9231680717532684\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 15.151079654693604 s\n",
      "Accuracy 0.9304366908053544 precision 0.9302653516998381 specificity 0.8098474374025715 recall 0.9304366908053544 f1 0.9278750287029947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 15.526137828826904 s\n",
      "Accuracy 0.9292663301879892 precision 0.9292570327163303 specificity 0.8080242396256391 recall 0.9292663301879892 f1 0.9265897629040452\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 15.065051794052124 s\n",
      "Accuracy 0.9262672811059908 precision 0.9260206563598948 specificity 0.8034593810679848 recall 0.9262672811059908 f1 0.9234887890942297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 15.434054613113403 s\n",
      "Accuracy 0.9248774778728696 precision 0.9242256478109747 specificity 0.7995132246171376 recall 0.9248774778728696 f1 0.922106876711065\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 15.383564233779907 s\n",
      "Accuracy 0.9259015434130642 precision 0.925212149732304 specificity 0.807725687709448 recall 0.9259015434130642 f1 0.9233757771422554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 15.678053379058838 s\n",
      "Accuracy 0.9245848877185283 precision 0.9243551465656278 specificity 0.7976334107805014 recall 0.9245848877185283 f1 0.921617356652028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 15.492258548736572 s\n",
      "Accuracy 0.9286080023407213 precision 0.9282244307890688 specificity 0.8042550603454538 recall 0.9286080023407213 f1 0.925942492044708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 14.932572841644287 s\n",
      "Accuracy 0.9324848218857436 precision 0.9319646207298509 specificity 0.8213332526323555 recall 0.9324848218857436 f1 0.9303396637847009\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 15.577646970748901 s\n",
      "Accuracy 0.927657084339112 precision 0.9272195410023361 specificity 0.8034095064152733 recall 0.927657084339112 f1 0.9249685534744554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 15.061053037643433 s\n",
      "Accuracy 0.9267061663375027 precision 0.9261105622517443 specificity 0.8040524570829838 recall 0.9267061663375027 f1 0.924068819968483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 15.32905387878418 s\n",
      "Accuracy 0.9275839368005266 precision 0.9275279389483946 specificity 0.8073311675918936 recall 0.9275839368005266 f1 0.9248699598217109\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 14.81905198097229 s\n",
      "Accuracy 0.926998756491844 precision 0.9267478961522019 specificity 0.8035205859531932 recall 0.926998756491844 f1 0.9242383555683518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 14.827052116394043 s\n",
      "Accuracy 0.9269256089532587 precision 0.926946349883068 specificity 0.8012325441367258 recall 0.9269256089532587 f1 0.9240257881231027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 14.917052030563354 s\n",
      "Accuracy 0.9259015434130642 precision 0.9255507531456829 specificity 0.8028758351788693 recall 0.9259015434130642 f1 0.9231341566353911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 14.86605167388916 s\n",
      "Accuracy 0.9310950186526223 precision 0.9309363439435363 specificity 0.8104051174632092 recall 0.9310950186526223 f1 0.9285560319007772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 14.994051694869995 s\n",
      "Accuracy 0.9254626581815522 precision 0.9252518592050006 specificity 0.8025095043019176 recall 0.9254626581815522 f1 0.922632523587485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 15.222055673599243 s\n",
      "Accuracy 0.9264867237217468 precision 0.926358911671088 specificity 0.808086106923916 recall 0.9264867237217468 f1 0.9237911414665327\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 15.140047788619995 s\n",
      "Accuracy 0.9281691171092092 precision 0.9273162402971878 specificity 0.8128771890017547 recall 0.9281691171092092 f1 0.9258803751352073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 14.924535274505615 s\n",
      "Accuracy 0.9264135761831614 precision 0.9261375747835001 specificity 0.8086584909210396 recall 0.9264135761831614 f1 0.9237767009755913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 15.227022886276245 s\n",
      "Accuracy 0.9248043303342842 precision 0.9244596242580227 specificity 0.8041719579867149 recall 0.9248043303342842 f1 0.9220458313530854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 14.908024549484253 s\n",
      "Accuracy 0.9281691171092092 precision 0.9274325288516406 specificity 0.8090068196041482 recall 0.9281691171092092 f1 0.9257370769487037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 15.056127071380615 s\n",
      "Accuracy 0.9264867237217468 precision 0.9259591067846088 specificity 0.8036549475628104 recall 0.9264867237217468 f1 0.9238106967661569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 15.030024528503418 s\n",
      "Accuracy 0.9244385926413576 precision 0.9239587246624864 specificity 0.8001785451293043 recall 0.9244385926413576 f1 0.921615139874972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 15.024020433425903 s\n",
      "Accuracy 0.9254626581815522 precision 0.9247727965882299 specificity 0.8035092510566865 recall 0.9254626581815522 f1 0.9228211551018861\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 15.440022945404053 s\n",
      "Accuracy 0.9317533464998903 precision 0.9314173882541291 specificity 0.8166648906319476 recall 0.9317533464998903 f1 0.9294260312099346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 15.318782091140747 s\n",
      "Accuracy 0.9275107892619413 precision 0.9273023133223061 specificity 0.807914986511544 recall 0.9275107892619413 f1 0.9248555192127681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 15.007044553756714 s\n",
      "Accuracy 0.9286811498793066 precision 0.9278739387831153 specificity 0.8114859662317733 recall 0.9286811498793066 f1 0.9263483455740597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 14.784021139144897 s\n",
      "Accuracy 0.9259015434130642 precision 0.9254462890892019 specificity 0.806485075360585 recall 0.9259015434130642 f1 0.9232598472876202\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 14.871022939682007 s\n",
      "Accuracy 0.9310950186526223 precision 0.9307354702255515 specificity 0.8257330936208976 recall 0.9310950186526223 f1 0.9289699248845392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 14.857021808624268 s\n",
      "Accuracy 0.9299246580352571 precision 0.9297751415403964 specificity 0.8063232364369074 recall 0.9299246580352571 f1 0.9272631287392754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 15.321024894714355 s\n",
      "Accuracy 0.9309487235754517 precision 0.9303328031399458 specificity 0.8180680043970205 recall 0.9309487235754517 f1 0.9287378132736585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 15.207531213760376 s\n",
      "Accuracy 0.9278033794162827 precision 0.9270279269468938 specificity 0.8098694322217146 recall 0.9278033794162827 f1 0.9254010884852906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 15.210782051086426 s\n",
      "Accuracy 0.9281691171092092 precision 0.9278949106536115 specificity 0.8035903391546737 recall 0.9281691171092092 f1 0.9254427350551627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 15.07302212715149 s\n",
      "Accuracy 0.9295589203423305 precision 0.9295036659087316 specificity 0.8126384044784778 recall 0.9295589203423305 f1 0.9270103696059496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 14.968566656112671 s\n",
      "Accuracy 0.9259746909516495 precision 0.9252366154995607 specificity 0.8057179640241126 recall 0.9259746909516495 f1 0.9234181782143105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 14.840023040771484 s\n",
      "Accuracy 0.9291931826494039 precision 0.9290921217117865 specificity 0.8074527289736585 recall 0.9291931826494039 f1 0.9265283290273494\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 15.11002254486084 s\n",
      "Accuracy 0.9292663301879892 precision 0.9289552223858222 specificity 0.8137543051076285 recall 0.9292663301879892 f1 0.9268172331183508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 15.349022150039673 s\n",
      "Accuracy 0.9289737400336479 precision 0.9288754757232754 specificity 0.8020542095295566 recall 0.9289737400336479 f1 0.9261743598850459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 15.388022899627686 s\n",
      "Accuracy 0.9269256089532587 precision 0.9267502277691207 specificity 0.8118396941813614 recall 0.9269256089532587 f1 0.924345032309512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 15.12702465057373 s\n",
      "Accuracy 0.9290468875722332 precision 0.9288789048187649 specificity 0.8118990874808352 recall 0.9290468875722332 f1 0.9265047697869809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 14.864020824432373 s\n",
      "Accuracy 0.9282422646477946 precision 0.9276320322279984 specificity 0.8085876753755694 recall 0.9282422646477946 f1 0.9257531828989954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 15.131024360656738 s\n",
      "Accuracy 0.9280959695706239 precision 0.9280115043804152 specificity 0.8125965714606285 recall 0.9280959695706239 f1 0.9255275569713497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 14.896934509277344 s\n",
      "Accuracy 0.927657084339112 precision 0.9275635173660974 specificity 0.805842847361058 recall 0.927657084339112 f1 0.9249194113862157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 15.059020519256592 s\n",
      "Accuracy 0.9257552483358935 precision 0.9254076119062721 specificity 0.8004106816356915 recall 0.9257552483358935 f1 0.9229215034628979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 14.750532865524292 s\n",
      "Accuracy 0.9287542974178918 precision 0.9284414753125534 specificity 0.8123758971222401 recall 0.9287542974178918 f1 0.9262635243724109\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 15.21702265739441 s\n",
      "Accuracy 0.926779313876088 precision 0.9262436292336004 specificity 0.8044743817700645 recall 0.926779313876088 f1 0.9241326094104942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 14.994022607803345 s\n",
      "Accuracy 0.9273644941847707 precision 0.9268487931175959 specificity 0.8050701967154567 recall 0.9273644941847707 f1 0.9247375521577005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 15.023022651672363 s\n",
      "Accuracy 0.9259746909516495 precision 0.925878829935331 specificity 0.8030492243524787 recall 0.9259746909516495 f1 0.9231338428730163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 14.823023796081543 s\n",
      "Accuracy 0.9283154121863799 precision 0.9278036478599385 specificity 0.8073468452807081 recall 0.9283154121863799 f1 0.9257622129581082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 15.212022066116333 s\n",
      "Accuracy 0.9292663301879892 precision 0.9289329332861916 specificity 0.8086840720076792 recall 0.9292663301879892 f1 0.9267043258759172\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 15.090127229690552 s\n",
      "Accuracy 0.9297052154195011 precision 0.9291841466523589 specificity 0.8135401640098808 recall 0.9297052154195011 f1 0.9273306610823221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 14.900022268295288 s\n",
      "Accuracy 0.9297783629580865 precision 0.9289797156872374 specificity 0.815037597595678 recall 0.9297783629580865 f1 0.9275483924688963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 15.142022132873535 s\n",
      "Accuracy 0.9266330187989175 precision 0.9260614209433329 specificity 0.8075762788733296 recall 0.9266330187989175 f1 0.9240735728431173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 15.094022512435913 s\n",
      "Accuracy 0.9259015434130642 precision 0.9252429592709734 specificity 0.8058047657048544 recall 0.9259015434130642 f1 0.9233154217759806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 15.269023180007935 s\n",
      "Accuracy 0.9256089532587228 precision 0.9250358836920517 specificity 0.7988356486166427 recall 0.9256089532587228 f1 0.9228083311313501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 15.08002233505249 s\n",
      "Accuracy 0.9291931826494039 precision 0.9290087283966372 specificity 0.8086244952422404 recall 0.9291931826494039 f1 0.9265813015205975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 15.077022314071655 s\n",
      "Accuracy 0.9256821007973082 precision 0.9254498769849331 specificity 0.8035106091049133 recall 0.9256821007973082 f1 0.9228884051894205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 15.272025108337402 s\n",
      "Accuracy 0.9255358057201375 precision 0.9247524222441281 specificity 0.8027945433839168 recall 0.9255358057201375 f1 0.9229135586981421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 14.973020315170288 s\n",
      "Accuracy 0.9261209860288201 precision 0.9255380218739716 specificity 0.809352350544512 recall 0.9261209860288201 f1 0.9236005064247227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 14.855024099349976 s\n",
      "Accuracy 0.9288274449564772 precision 0.9282939189752573 specificity 0.8111398419175916 recall 0.9288274449564772 f1 0.9263835784785771\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 14.84653091430664 s\n",
      "Accuracy 0.9261209860288201 precision 0.9264552958691266 specificity 0.7993651137202892 recall 0.9261209860288201 f1 0.9230709466980737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 15.06302285194397 s\n",
      "Accuracy 0.9299246580352571 precision 0.929897788726288 specificity 0.8104060618389519 recall 0.9299246580352571 f1 0.9273227400014759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 15.1390221118927 s\n",
      "Accuracy 0.9265598712603321 precision 0.9260052506353875 specificity 0.8098393841715259 recall 0.9265598712603321 f1 0.9240493138315413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 14.852564811706543 s\n",
      "Accuracy 0.9291200351108185 precision 0.9290798005481768 specificity 0.8057237547400504 recall 0.9291200351108185 f1 0.9263946342993119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 14.954085350036621 s\n",
      "Accuracy 0.9278033794162827 precision 0.9274395926033271 specificity 0.806661425102602 recall 0.9278033794162827 f1 0.9251729296887299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 15.199022769927979 s\n",
      "Accuracy 0.9275839368005266 precision 0.9272622197213612 specificity 0.8077426795684925 recall 0.9275839368005266 f1 0.9249617561357361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 14.883022546768188 s\n",
      "Accuracy 0.9288274449564772 precision 0.9283048991424473 specificity 0.8080081225901975 recall 0.9288274449564772 f1 0.926304397414046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 14.929024457931519 s\n",
      "Accuracy 0.9272181991076001 precision 0.9268640345472258 specificity 0.8122261657163642 recall 0.9272181991076001 f1 0.924709250699918\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 15.150022745132446 s\n",
      "Accuracy 0.9260478384902348 precision 0.9256359513192943 specificity 0.8054245551891814 recall 0.9260478384902348 f1 0.9233676696527928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 14.982020378112793 s\n",
      "Accuracy 0.9270719040304294 precision 0.9267586802475263 specificity 0.8126225708008397 recall 0.9270719040304294 f1 0.9245566312204572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 14.88802170753479 s\n",
      "Accuracy 0.9257552483358935 precision 0.9258125055049258 specificity 0.8005519458104327 recall 0.9257552483358935 f1 0.9228024784504654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 14.877022743225098 s\n",
      "Accuracy 0.9279496744934533 precision 0.9277883857025145 specificity 0.8039058915740334 recall 0.9279496744934533 f1 0.9251912954139301\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 14.878025770187378 s\n",
      "Accuracy 0.9289737400336479 precision 0.9287059284138989 specificity 0.8086224549724687 recall 0.9289737400336479 f1 0.9263833071007485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 15.004019498825073 s\n",
      "Accuracy 0.9247311827956989 precision 0.923963933612072 specificity 0.8046657340743102 recall 0.9247311827956989 f1 0.9221349875842749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 15.081022500991821 s\n",
      "Accuracy 0.9280228220320387 precision 0.9274283131725941 specificity 0.8111201814540729 recall 0.9280228220320387 f1 0.925585418298027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 15.016022443771362 s\n",
      "Accuracy 0.9273644941847707 precision 0.9268666994496716 specificity 0.8105059713305469 recall 0.9273644941847707 f1 0.9248650249196966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 14.774532079696655 s\n",
      "Accuracy 0.9300709531124277 precision 0.9293654191303039 specificity 0.8126685930732441 recall 0.9300709531124277 f1 0.9277519690279884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 15.088022470474243 s\n",
      "Accuracy 0.9252432155657963 precision 0.9250368417805687 specificity 0.7954617908290414 recall 0.9252432155657963 f1 0.9222274540413814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 15.276633024215698 s\n",
      "Accuracy 0.9250969204886256 precision 0.9249197517302922 specificity 0.8003554090575147 recall 0.9250969204886256 f1 0.9221940541083898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 14.90302300453186 s\n",
      "Accuracy 0.9272181991076001 precision 0.9269164779990776 specificity 0.8030790783372168 recall 0.9272181991076001 f1 0.9244676331612455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 14.977022647857666 s\n",
      "Accuracy 0.9299978055738425 precision 0.9294901011940505 specificity 0.8126788816767616 recall 0.9299978055738425 f1 0.9276037528881308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 15.281023263931274 s\n",
      "Accuracy 0.9259746909516495 precision 0.9256770927229353 specificity 0.804723849874181 recall 0.9259746909516495 f1 0.9232380652845444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 15.45805549621582 s\n",
      "Accuracy 0.9288274449564772 precision 0.9283262722373171 specificity 0.8109198262050223 recall 0.9288274449564772 f1 0.926366822465182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 15.200022220611572 s\n",
      "Accuracy 0.9267061663375027 precision 0.9258851602482837 specificity 0.8085063450932716 recall 0.9267061663375027 f1 0.9242676353915646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 14.913024187088013 s\n",
      "Accuracy 0.9282422646477946 precision 0.927456688365588 specificity 0.8109706633097596 recall 0.9282422646477946 f1 0.9258795730837605\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 15.357022523880005 s\n",
      "Accuracy 0.926998756491844 precision 0.9266469526348978 specificity 0.8017042117411286 recall 0.926998756491844 f1 0.924225595831459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 14.890536546707153 s\n",
      "Accuracy 0.9289005924950625 precision 0.9287820796179097 specificity 0.8062502781757406 recall 0.9289005924950625 f1 0.9262061326011654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 14.962024927139282 s\n",
      "Accuracy 0.9302903957281837 precision 0.9296669343317265 specificity 0.812498005877441 recall 0.9302903957281837 f1 0.9279400070515776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 14.981431245803833 s\n",
      "Accuracy 0.9246580352571137 precision 0.9244393623836543 specificity 0.7964078403952172 recall 0.9246580352571137 f1 0.9216570674917491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 15.014178037643433 s\n",
      "Accuracy 0.923414527101163 precision 0.9232378152319302 specificity 0.7967764567940759 recall 0.923414527101163 f1 0.9203828571875224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 14.985065221786499 s\n",
      "Accuracy 0.9233413795625777 precision 0.9232309005994178 specificity 0.7973681968549714 recall 0.9233413795625777 f1 0.920303615633073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 15.18502163887024 s\n",
      "Accuracy 0.9304366908053544 precision 0.9302961042689247 specificity 0.8177440917405128 recall 0.9304366908053544 f1 0.9280484240784914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 14.96602463722229 s\n",
      "Accuracy 0.9270719040304294 precision 0.9263476365482044 specificity 0.8144408698668054 recall 0.9270719040304294 f1 0.9247490723822674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 14.853021144866943 s\n",
      "Accuracy 0.9280228220320387 precision 0.9274932898045002 specificity 0.8107587033647483 recall 0.9280228220320387 f1 0.9255530563214026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 14.904021263122559 s\n",
      "Accuracy 0.9282422646477946 precision 0.9279751904862682 specificity 0.806347284232706 recall 0.9282422646477946 f1 0.9255820051348707\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 14.950023412704468 s\n",
      "Accuracy 0.9280959695706239 precision 0.9275348249231024 specificity 0.8121651786141071 recall 0.9280959695706239 f1 0.9256731115165219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 15.06702470779419 s\n",
      "Accuracy 0.9283154121863799 precision 0.9282856605556512 specificity 0.8056339502732192 recall 0.9283154121863799 f1 0.9255676856657071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 15.030012130737305 s\n",
      "Accuracy 0.9262672811059908 precision 0.9258895665282143 specificity 0.8060832575059338 recall 0.9262672811059908 f1 0.9235965389889023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 14.90807843208313 s\n",
      "Accuracy 0.9302903957281837 precision 0.9295921896548716 specificity 0.8155445825369092 recall 0.9302903957281837 f1 0.928040678334923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 15.045022249221802 s\n",
      "Accuracy 0.9296320678809158 precision 0.9292382027144147 specificity 0.8072580709280394 recall 0.9296320678809158 f1 0.9270636519929103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 14.902023077011108 s\n",
      "Accuracy 0.9271450515690147 precision 0.9268295066281393 specificity 0.8051055475180098 recall 0.9271450515690147 f1 0.924447363092925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 15.028022527694702 s\n",
      "Accuracy 0.927876526954868 precision 0.9270469199849137 specificity 0.8098934707992236 recall 0.927876526954868 f1 0.9254985522895119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 14.998023986816406 s\n",
      "Accuracy 0.9248043303342842 precision 0.9244176795856526 specificity 0.79838409892134 recall 0.9248043303342842 f1 0.9219110685466487\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 14.905021667480469 s\n",
      "Accuracy 0.9280228220320387 precision 0.9276579660860227 specificity 0.8035960416721096 recall 0.9280228220320387 f1 0.9253225602750367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 15.020533561706543 s\n",
      "Accuracy 0.927876526954868 precision 0.9273630676005916 specificity 0.7976689586732494 recall 0.927876526954868 f1 0.9250773915516908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 15.06202244758606 s\n",
      "Accuracy 0.9285348548021359 precision 0.9281008481435314 specificity 0.8083219221247484 recall 0.9285348548021359 f1 0.9259828321143213\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 15.016649961471558 s\n",
      "Accuracy 0.9277302318776973 precision 0.9273430224015867 specificity 0.8032168597238649 recall 0.9277302318776973 f1 0.925021754480858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 14.991020679473877 s\n",
      "Accuracy 0.9262672811059908 precision 0.9260710880572726 specificity 0.807860098294439 recall 0.9262672811059908 f1 0.9235827755947952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 15.161559343338013 s\n",
      "Accuracy 0.9248774778728696 precision 0.9245470534780162 specificity 0.8041947153105061 recall 0.9248774778728696 f1 0.9221163436249323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 15.021020889282227 s\n",
      "Accuracy 0.9289737400336479 precision 0.9288154818227302 specificity 0.8034998598714305 recall 0.9289737400336479 f1 0.9262269689379368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 14.968022584915161 s\n",
      "Accuracy 0.9300709531124277 precision 0.9296195034536358 specificity 0.8111419952122313 recall 0.9300709531124277 f1 0.9276225897792103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 14.758021831512451 s\n",
      "Accuracy 0.9256821007973082 precision 0.9252744110800196 specificity 0.805942030713711 recall 0.9256821007973082 f1 0.9230064019084587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 14.90002179145813 s\n",
      "Accuracy 0.9297783629580865 precision 0.9295425736392406 specificity 0.8087624704500957 recall 0.9297783629580865 f1 0.9271976110398861\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 15.416535377502441 s\n",
      "Accuracy 0.923853412332675 precision 0.9234257464900537 specificity 0.7982180391925915 recall 0.923853412332675 f1 0.9209490457409654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 15.413022756576538 s\n",
      "Accuracy 0.9289737400336479 precision 0.9284131534076848 specificity 0.8085714451571963 recall 0.9289737400336479 f1 0.9264807604663607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 15.19002366065979 s\n",
      "Accuracy 0.9297783629580865 precision 0.9295382305629286 specificity 0.8116556369538841 recall 0.9297783629580865 f1 0.9272669657487432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 15.16802191734314 s\n",
      "Accuracy 0.9259746909516495 precision 0.9262356024551318 specificity 0.7950028467981232 recall 0.9259746909516495 f1 0.9228305939968416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 15.359150409698486 s\n",
      "Accuracy 0.9284617072635506 precision 0.9285246134625686 specificity 0.8087538711922855 recall 0.9284617072635506 f1 0.9257655915322021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 15.19402265548706 s\n",
      "Accuracy 0.9237802647940897 precision 0.9236173470736323 specificity 0.7959769844833168 recall 0.9237802647940897 f1 0.920731442712171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 15.65502381324768 s\n",
      "Accuracy 0.9240728549484309 precision 0.9237725534700457 specificity 0.8030326192638964 recall 0.9240728549484309 f1 0.921256414791181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 14.911022186279297 s\n",
      "Accuracy 0.9280228220320387 precision 0.9278220216932791 specificity 0.8044348462514342 recall 0.9280228220320387 f1 0.9252909386884807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 15.084022760391235 s\n",
      "Accuracy 0.9273644941847707 precision 0.9267409728077743 specificity 0.8017148193728344 recall 0.9273644941847707 f1 0.9246929065778178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 15.03402304649353 s\n",
      "Accuracy 0.9266330187989175 precision 0.9264159019534982 specificity 0.8034695951529692 recall 0.9266330187989175 f1 0.9238531728234451\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 15.277023553848267 s\n",
      "Accuracy 0.9278033794162827 precision 0.9276975692897387 specificity 0.8059424864027763 recall 0.9278033794162827 f1 0.9250747902901714\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 15.1410231590271 s\n",
      "Accuracy 0.9250237729500402 precision 0.924413729272585 specificity 0.7993348688694761 recall 0.9250237729500402 f1 0.9222364981202031\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 15.691022634506226 s\n",
      "Accuracy 0.9278033794162827 precision 0.9273869567717183 specificity 0.8107869288750652 recall 0.9278033794162827 f1 0.9252908882238248\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 15.579025030136108 s\n",
      "Accuracy 0.926998756491844 precision 0.9266237951957256 specificity 0.8102918044336823 recall 0.926998756491844 f1 0.9244453038742205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 15.420021533966064 s\n",
      "Accuracy 0.9269256089532587 precision 0.9264885870172788 specificity 0.8041708912507926 recall 0.9269256089532587 f1 0.9242403338729315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 15.09202265739441 s\n",
      "Accuracy 0.927437641723356 precision 0.9271447895529276 specificity 0.8044980338095804 recall 0.927437641723356 f1 0.9247237932447756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 15.691554307937622 s\n",
      "Accuracy 0.9289005924950625 precision 0.9290913974705688 specificity 0.8070539448281809 recall 0.9289005924950625 f1 0.9261376169770105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 14.882022142410278 s\n",
      "Accuracy 0.927876526954868 precision 0.9276714372652495 specificity 0.8003140530139449 recall 0.927876526954868 f1 0.9250422382675374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 15.153022766113281 s\n",
      "Accuracy 0.9254626581815522 precision 0.9248579489394358 specificity 0.8040052037295674 recall 0.9254626581815522 f1 0.9228022810621881\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 15.600578784942627 s\n",
      "Accuracy 0.9302903957281837 precision 0.9298462810211479 specificity 0.8085724802406219 recall 0.9302903957281837 f1 0.927783684721605\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 14.948054790496826 s\n",
      "Accuracy 0.9283885597249653 precision 0.9281061967561167 specificity 0.807277668525743 recall 0.9283885597249653 f1 0.9257586155273786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 15.489532470703125 s\n",
      "Accuracy 0.927876526954868 precision 0.9282174301814324 specificity 0.8055191924039956 recall 0.927876526954868 f1 0.9250152955361729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 15.299424409866333 s\n",
      "Accuracy 0.9263404286445761 precision 0.9256363691857976 specificity 0.8001374598993135 recall 0.9263404286445761 f1 0.9236367097556821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 15.124130725860596 s\n",
      "Accuracy 0.9308755760368663 precision 0.9305796077858043 specificity 0.8127897364393739 recall 0.9308755760368663 f1 0.9284298201620669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 15.794025182723999 s\n",
      "Accuracy 0.9277302318776973 precision 0.9269766227326717 specificity 0.8106623233891765 recall 0.9277302318776973 f1 0.9253373400093137\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 15.65853476524353 s\n",
      "Accuracy 0.9262672811059908 precision 0.9254456915966162 specificity 0.8053103754950695 recall 0.9262672811059908 f1 0.9237394553518428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 14.958021879196167 s\n",
      "Accuracy 0.9291931826494039 precision 0.9289350360741295 specificity 0.8059649274848286 recall 0.9291931826494039 f1 0.9265408839948247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 14.903533935546875 s\n",
      "Accuracy 0.9271450515690147 precision 0.9277433078581794 specificity 0.7989210376132191 recall 0.9271450515690147 f1 0.9240406775143736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 14.96053671836853 s\n",
      "Accuracy 0.9289005924950625 precision 0.9279422530882782 specificity 0.8123531132770211 recall 0.9289005924950625 f1 0.9266597818392158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 15.06702208518982 s\n",
      "Accuracy 0.9308755760368663 precision 0.9306517772474792 specificity 0.8185376841929455 recall 0.9308755760368663 f1 0.9285389102465489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 15.259021043777466 s\n",
      "Accuracy 0.9294857728037451 precision 0.9291527117332892 specificity 0.8106791866998864 recall 0.9294857728037451 f1 0.9269753416929976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 15.45053243637085 s\n",
      "Accuracy 0.9266330187989175 precision 0.9263722265073691 specificity 0.8064399649800107 recall 0.9266330187989175 f1 0.9239405482878617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 15.90102243423462 s\n",
      "Accuracy 0.9248774778728696 precision 0.9244759843385351 specificity 0.8009169327205248 recall 0.9248774778728696 f1 0.9220557768125023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 15.126533508300781 s\n",
      "Accuracy 0.926998756491844 precision 0.9267172389518881 specificity 0.8050907587434889 recall 0.926998756491844 f1 0.9242868270156016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 15.312533140182495 s\n",
      "Accuracy 0.9270719040304294 precision 0.9268831552403046 specificity 0.7994889487645643 recall 0.9270719040304294 f1 0.9241940425822037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 15.516023635864258 s\n",
      "Accuracy 0.9250237729500402 precision 0.9246554992400383 specificity 0.8030794787549002 recall 0.9250237729500402 f1 0.9222494272320598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 14.988022327423096 s\n",
      "Accuracy 0.9278033794162827 precision 0.9274361805028705 specificity 0.8122429592216053 recall 0.9278033794162827 f1 0.9253097107944804\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 15.596077680587769 s\n",
      "Accuracy 0.9304366908053544 precision 0.9300781107289035 specificity 0.8193276284216945 recall 0.9304366908053544 f1 0.9281541349195289\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 15.094223022460938 s\n",
      "Accuracy 0.9261941335674054 precision 0.9262446073635796 specificity 0.8057086739431637 recall 0.9261941335674054 f1 0.9233816996526478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 15.0640230178833 s\n",
      "Accuracy 0.9294857728037451 precision 0.9290619793221903 specificity 0.8147620954304792 recall 0.9294857728037451 f1 0.9271019879893235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 15.382017135620117 s\n",
      "Accuracy 0.9294857728037451 precision 0.9294844240545963 specificity 0.8128443556469567 recall 0.9294857728037451 f1 0.9269250504123377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 15.332010269165039 s\n",
      "Accuracy 0.9279496744934533 precision 0.9279600719433786 specificity 0.809128985553932 recall 0.9279496744934533 f1 0.9252673224845448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 14.783947229385376 s\n",
      "Accuracy 0.9261209860288201 precision 0.926428142157516 specificity 0.7992663140685483 recall 0.9261209860288201 f1 0.9230756009004709\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 14.835008382797241 s\n",
      "Accuracy 0.9280228220320387 precision 0.927364227229319 specificity 0.8079953262243564 recall 0.9280228220320387 f1 0.9255329748327756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 15.4090096950531 s\n",
      "Accuracy 0.9243654451027723 precision 0.9242953989601805 specificity 0.801912897844783 recall 0.9243654451027723 f1 0.9214550804900102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 15.045008659362793 s\n",
      "Accuracy 0.9273644941847707 precision 0.9269707617466268 specificity 0.8022918023292145 recall 0.9273644941847707 f1 0.9246275326520216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 15.177008867263794 s\n",
      "Accuracy 0.9280228220320387 precision 0.9275728724472802 specificity 0.8063088270877975 recall 0.9280228220320387 f1 0.9254170684583555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 15.267009258270264 s\n",
      "Accuracy 0.9248774778728696 precision 0.9243304844627925 specificity 0.8016542516369743 recall 0.9248774778728696 f1 0.9221244427747836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 15.409523487091064 s\n",
      "Accuracy 0.9309487235754517 precision 0.9306448169084177 specificity 0.810655777344299 recall 0.9309487235754517 f1 0.9284577581254346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 15.202142000198364 s\n",
      "Accuracy 0.9299978055738425 precision 0.9290594955193813 specificity 0.8063446583119341 recall 0.9299978055738425 f1 0.9276228097455255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 15.067008972167969 s\n",
      "Accuracy 0.926779313876088 precision 0.9263916683181923 specificity 0.8068616227456725 recall 0.926779313876088 f1 0.9241412619534028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 15.107010126113892 s\n",
      "Accuracy 0.927876526954868 precision 0.9276240213306595 specificity 0.8064198628881214 recall 0.927876526954868 f1 0.9252059237044418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 15.176953315734863 s\n",
      "Accuracy 0.930144100651013 precision 0.9294747426127238 specificity 0.8172869324772258 recall 0.930144100651013 f1 0.9279214086195994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 15.228008508682251 s\n",
      "Accuracy 0.9226099041767245 precision 0.9225201318886637 specificity 0.7959401694861673 recall 0.9226099041767245 f1 0.919512517999706\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 15.064008712768555 s\n",
      "Accuracy 0.9258283958744788 precision 0.9257291643537833 specificity 0.8011321755806503 recall 0.9258283958744788 f1 0.9229372745270715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 14.9430091381073 s\n",
      "Accuracy 0.9293394777265745 precision 0.9288528033376122 specificity 0.8109972262805683 recall 0.9293394777265745 f1 0.9268855240115678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 14.963009119033813 s\n",
      "Accuracy 0.9272913466461854 precision 0.9270407146105213 specificity 0.8048656297087468 recall 0.9272913466461854 f1 0.9245701313641291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 15.043517351150513 s\n",
      "Accuracy 0.9283154121863799 precision 0.928033770193786 specificity 0.8028458459285074 recall 0.9283154121863799 f1 0.9255764950310751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 15.153533220291138 s\n",
      "Accuracy 0.9302903957281837 precision 0.92996372575171 specificity 0.8145789508051564 recall 0.9302903957281837 f1 0.9278847352415495\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 14.768009185791016 s\n",
      "Accuracy 0.9275839368005266 precision 0.9272786200033214 specificity 0.8035324755373469 recall 0.9275839368005266 f1 0.9248534640134011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 15.090027332305908 s\n",
      "Accuracy 0.926779313876088 precision 0.9268448566444832 specificity 0.8015462781984353 recall 0.926779313876088 f1 0.9238713455938985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 15.01701021194458 s\n",
      "Accuracy 0.9272913466461854 precision 0.9270158251574402 specificity 0.8076905548508381 recall 0.9272913466461854 f1 0.9246473138974319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 15.081007480621338 s\n",
      "Accuracy 0.9269256089532587 precision 0.9265706872153758 specificity 0.800215855395082 recall 0.9269256089532587 f1 0.9241148704782097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 14.990009546279907 s\n",
      "Accuracy 0.9263404286445761 precision 0.9259877385727735 specificity 0.806629393920038 recall 0.9263404286445761 f1 0.9236765001738158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 15.243008852005005 s\n",
      "Accuracy 0.9255358057201375 precision 0.9247428124320313 specificity 0.8031719108372734 recall 0.9255358057201375 f1 0.9229270733223096\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 14.894008874893188 s\n",
      "Accuracy 0.9258283958744788 precision 0.9254645823607045 specificity 0.8019434366593087 recall 0.9258283958744788 f1 0.9230402260099541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 15.217009544372559 s\n",
      "Accuracy 0.9271450515690147 precision 0.9272477711611081 specificity 0.8029217061580322 recall 0.9271450515690147 f1 0.9242686093259864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 15.157009363174438 s\n",
      "Accuracy 0.9240728549484309 precision 0.9243105641005188 specificity 0.800561004930575 recall 0.9240728549484309 f1 0.9210346446437909\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 15.032007694244385 s\n",
      "Accuracy 0.9295589203423305 precision 0.92951781561741 specificity 0.8089776902585724 recall 0.9295589203423305 f1 0.9269201241470141\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 15.018009662628174 s\n",
      "Accuracy 0.9228293467924804 precision 0.9226060689229064 specificity 0.8039104728432612 recall 0.9228293467924804 f1 0.9199876753390488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 15.285033464431763 s\n",
      "Accuracy 0.9291931826494039 precision 0.9285632022061844 specificity 0.8130972082280137 recall 0.9291931826494039 f1 0.9268385893077083\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 15.16059684753418 s\n",
      "Accuracy 0.9313876088069637 precision 0.9304630770211961 specificity 0.8170913370573459 recall 0.9313876088069637 f1 0.9292925435305691\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 15.137073516845703 s\n",
      "Accuracy 0.9316070514227196 precision 0.9312088788932051 specificity 0.8185718150880215 recall 0.9316070514227196 f1 0.9293410659653968\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 15.169010400772095 s\n",
      "Accuracy 0.926779313876088 precision 0.9265890664137729 specificity 0.8033610775508804 recall 0.926779313876088 f1 0.9239915477804436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 14.960009813308716 s\n",
      "Accuracy 0.9336551825031087 precision 0.9336893586281597 specificity 0.8189598853669217 recall 0.9336551825031087 f1 0.9313027270687174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 15.102009057998657 s\n",
      "Accuracy 0.9285348548021359 precision 0.9288117169853024 specificity 0.8046264574761693 recall 0.9285348548021359 f1 0.925682893672352\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 14.956008672714233 s\n",
      "Accuracy 0.9273644941847707 precision 0.9267107147920917 specificity 0.8082662348688625 recall 0.9273644941847707 f1 0.9248666002469997\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 14.960009098052979 s\n",
      "Accuracy 0.9289005924950625 precision 0.9288810687142514 specificity 0.8033962501698616 recall 0.9289005924950625 f1 0.9261087628254833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 14.727011680603027 s\n",
      "Accuracy 0.9306561334211104 precision 0.9305059447684743 specificity 0.8064990516264642 recall 0.9306561334211104 f1 0.9280148712492675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 15.10500717163086 s\n",
      "Accuracy 0.9313144612683784 precision 0.9306495645582743 specificity 0.811729007155419 recall 0.9313144612683784 f1 0.9289822117209044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 15.306008338928223 s\n",
      "Accuracy 0.9256089532587228 precision 0.9253456660834434 specificity 0.8027262359316237 recall 0.9256089532587228 f1 0.9228037147812099\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 14.786009073257446 s\n",
      "Accuracy 0.9275839368005266 precision 0.9270303796631987 specificity 0.8104849157374772 recall 0.9275839368005266 f1 0.9251078819888695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 14.971010446548462 s\n",
      "Accuracy 0.9240728549484309 precision 0.9240572916747393 specificity 0.8019877798892984 recall 0.9240728549484309 f1 0.9211425202154884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 15.306520938873291 s\n",
      "Accuracy 0.9259015434130642 precision 0.9257785769989335 specificity 0.797104816241753 recall 0.9259015434130642 f1 0.9229174426091447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 15.122603178024292 s\n",
      "Accuracy 0.9273644941847707 precision 0.9272932249307854 specificity 0.8044445928739842 recall 0.9273644941847707 f1 0.9245799603314532\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 15.797080993652344 s\n",
      "Accuracy 0.9265598712603321 precision 0.9260750211458323 specificity 0.8105092060757938 recall 0.9265598712603321 f1 0.9240412050725693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 15.132009983062744 s\n",
      "Accuracy 0.9256089532587228 precision 0.9251787509667373 specificity 0.8007914063363222 recall 0.9256089532587228 f1 0.9228089669097994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 15.604536056518555 s\n",
      "Accuracy 0.9273644941847707 precision 0.9273775716038611 specificity 0.8019110511444547 recall 0.9273644941847707 f1 0.9244932643723306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 15.62847375869751 s\n",
      "Accuracy 0.9290468875722332 precision 0.9292754663137899 specificity 0.8049224885536687 recall 0.9290468875722332 f1 0.9262260255751886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 15.431100606918335 s\n",
      "Accuracy 0.9226830517153097 precision 0.9223840382743433 specificity 0.7920627086651495 recall 0.9226830517153097 f1 0.91954833362176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 14.995049715042114 s\n",
      "Accuracy 0.9247311827956989 precision 0.9245554462127786 specificity 0.7997708529646927 recall 0.9247311827956989 f1 0.9218051624212993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 15.077006340026855 s\n",
      "Accuracy 0.9297783629580865 precision 0.9292734014211891 specificity 0.8128293367068861 recall 0.9297783629580865 f1 0.9273826834999193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 15.097009658813477 s\n",
      "Accuracy 0.9297783629580865 precision 0.9291320687482606 specificity 0.8084202168348066 recall 0.9297783629580865 f1 0.927329699303521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 14.92000961303711 s\n",
      "Accuracy 0.9290468875722332 precision 0.9290637504911592 specificity 0.8104876859024036 recall 0.9290468875722332 f1 0.926416807233858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 14.887009382247925 s\n",
      "Accuracy 0.9293394777265745 precision 0.9286737485258748 specificity 0.8066063218510248 recall 0.9293394777265745 f1 0.926845525554983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 15.099009275436401 s\n",
      "Accuracy 0.9269256089532587 precision 0.9267280037136393 specificity 0.8077861406638606 recall 0.9269256089532587 f1 0.924252371648779\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 14.979029178619385 s\n",
      "Accuracy 0.9237071172555044 precision 0.9228674395004466 specificity 0.7992541059834318 recall 0.9237071172555044 f1 0.9209771593973823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 15.194008827209473 s\n",
      "Accuracy 0.9275839368005266 precision 0.927042178032257 specificity 0.80564394522891 recall 0.9275839368005266 f1 0.9249848080597073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 14.857009649276733 s\n",
      "Accuracy 0.9258283958744788 precision 0.9256441650461174 specificity 0.8023631428451226 recall 0.9258283958744788 f1 0.9229939552250789\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 14.983008623123169 s\n",
      "Accuracy 0.9316070514227196 precision 0.931362967296137 specificity 0.8168060447190046 recall 0.9316070514227196 f1 0.9292506356723245\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 14.891009092330933 s\n",
      "Accuracy 0.9277302318776973 precision 0.9271686322264803 specificity 0.8071094494153386 recall 0.9277302318776973 f1 0.9251771470232815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 15.16336727142334 s\n",
      "Accuracy 0.9272913466461854 precision 0.9273143715007751 specificity 0.8076000378743778 recall 0.9272913466461854 f1 0.9245552329223734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 14.877007007598877 s\n",
      "Accuracy 0.9288274449564772 precision 0.9278930719730986 specificity 0.8147558207366765 recall 0.9288274449564772 f1 0.9266335252336119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 14.933008909225464 s\n",
      "Accuracy 0.9252432155657963 precision 0.9248374132822038 specificity 0.8003630087952577 recall 0.9252432155657963 f1 0.9224164322553663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 15.221009492874146 s\n",
      "Accuracy 0.926779313876088 precision 0.9262713773222733 specificity 0.8011106667728307 recall 0.926779313876088 f1 0.9240389379247517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 14.992009162902832 s\n",
      "Accuracy 0.9234876746397483 precision 0.9233572146383365 specificity 0.7950485370237176 recall 0.9234876746397483 f1 0.9203981848595397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 14.926518440246582 s\n",
      "Accuracy 0.9280959695706239 precision 0.9276593747911377 specificity 0.8091730103711893 recall 0.9280959695706239 f1 0.9255567378180569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 15.082009077072144 s\n",
      "Accuracy 0.9313144612683784 precision 0.9312139519142657 specificity 0.8112185392050217 recall 0.9313144612683784 f1 0.9287812631272542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 15.498009204864502 s\n",
      "Accuracy 0.9268524614146734 precision 0.9264141327674855 specificity 0.7958699771526055 recall 0.9268524614146734 f1 0.9239589028689842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 14.940009117126465 s\n",
      "Accuracy 0.9275107892619413 precision 0.9272133308106703 specificity 0.8124611197570152 recall 0.9275107892619413 f1 0.9249942984216388\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 14.863518476486206 s\n",
      "Accuracy 0.9273644941847707 precision 0.9266964563764021 specificity 0.8142449544498968 recall 0.9273644941847707 f1 0.9250196288515414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 15.150165557861328 s\n",
      "Accuracy 0.9281691171092092 precision 0.9272866294289905 specificity 0.815144477361461 recall 0.9281691171092092 f1 0.9259494918366364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 15.529009103775024 s\n",
      "Accuracy 0.9278033794162827 precision 0.9275918725114917 specificity 0.804990947437103 recall 0.9278033794162827 f1 0.925083699848674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 15.507522583007812 s\n",
      "Accuracy 0.9280959695706239 precision 0.9281334876132662 specificity 0.8133390918469348 recall 0.9280959695706239 f1 0.9255099980551187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 15.12900972366333 s\n",
      "Accuracy 0.9307292809596958 precision 0.9302090580482215 specificity 0.8113516952167079 recall 0.9307292809596958 f1 0.9283229965049797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 15.228522300720215 s\n",
      "Accuracy 0.9245848877185283 precision 0.9240614110868757 specificity 0.8024477350159479 recall 0.9245848877185283 f1 0.921838132236976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 15.607572078704834 s\n",
      "Accuracy 0.9300709531124277 precision 0.9299048903112134 specificity 0.8094514450098464 recall 0.9300709531124277 f1 0.9274909201958047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 15.098630905151367 s\n",
      "Accuracy 0.9305098383439397 precision 0.9301474968497274 specificity 0.810750287414631 recall 0.9305098383439397 f1 0.9280311276079584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 15.509008646011353 s\n",
      "Accuracy 0.9278033794162827 precision 0.927912818506907 specificity 0.8019669404601242 recall 0.9278033794162827 f1 0.9249160690720626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 15.643011569976807 s\n",
      "Accuracy 0.9283154121863799 precision 0.9277695222711992 specificity 0.8056686037954526 recall 0.9283154121863799 f1 0.9257334634814842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 15.64400863647461 s\n",
      "Accuracy 0.9244385926413576 precision 0.9237646551064312 specificity 0.7994227454855706 recall 0.9244385926413576 f1 0.9216645192653398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 15.793036699295044 s\n",
      "Accuracy 0.9256821007973082 precision 0.924933711311275 specificity 0.8057933826243535 recall 0.9256821007973082 f1 0.9231258588064826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 15.252009868621826 s\n",
      "Accuracy 0.9285348548021359 precision 0.9276768446276976 specificity 0.8168495665160602 recall 0.9285348548021359 f1 0.9263526485117727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 15.575401306152344 s\n",
      "Accuracy 0.9260478384902348 precision 0.9252714270946761 specificity 0.8016763335879409 recall 0.9260478384902348 f1 0.9234048028987424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 15.7791166305542 s\n",
      "Accuracy 0.9302903957281837 precision 0.9297416763026661 specificity 0.8154171283278944 recall 0.9302903957281837 f1 0.9279807931931175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 15.248008966445923 s\n",
      "Accuracy 0.9258283958744788 precision 0.925503647541143 specificity 0.8066780758707478 recall 0.9258283958744788 f1 0.9231466870631535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 15.275009155273438 s\n",
      "Accuracy 0.9298515104966718 precision 0.9297296262417069 specificity 0.8106625778037843 recall 0.9298515104966718 f1 0.9272820611064603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 15.596521139144897 s\n",
      "Accuracy 0.9308755760368663 precision 0.9303791872458316 specificity 0.8103396942488621 recall 0.9308755760368663 f1 0.9284403128136909\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 15.397499084472656 s\n",
      "Accuracy 0.9272913466461854 precision 0.9267721092065773 specificity 0.804595881439302 recall 0.9272913466461854 f1 0.9246524149621204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 15.437008380889893 s\n",
      "Accuracy 0.9282422646477946 precision 0.9277095938406109 specificity 0.8106008136308495 recall 0.9282422646477946 f1 0.9257739367424374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 15.43651270866394 s\n",
      "Accuracy 0.9317533464998903 precision 0.9317290621280019 specificity 0.814077491433073 recall 0.9317533464998903 f1 0.9292718464237433\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 15.335546016693115 s\n",
      "Accuracy 0.927657084339112 precision 0.9271204529704911 specificity 0.8061933101100848 recall 0.927657084339112 f1 0.9250711374574822\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 15.39852261543274 s\n",
      "Accuracy 0.9239997074098456 precision 0.9238294650827652 specificity 0.7976925708297667 recall 0.9239997074098456 f1 0.921002650168125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 15.597008228302002 s\n",
      "Accuracy 0.9298515104966718 precision 0.9291262242150853 specificity 0.8125252092743005 recall 0.9298515104966718 f1 0.9275327280758199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 15.488592624664307 s\n",
      "Accuracy 0.9280228220320387 precision 0.9273760967332652 specificity 0.7976183638741245 recall 0.9280228220320387 f1 0.9252730323621698\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 15.57252025604248 s\n",
      "Accuracy 0.9205617730963354 precision 0.9200702868000953 specificity 0.8050342772000257 recall 0.9205617730963354 f1 0.917798565583545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 15.845523834228516 s\n",
      "Accuracy 0.9233413795625777 precision 0.9231979024703484 specificity 0.7958758296670622 recall 0.9233413795625777 f1 0.9202743315456969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 15.02200722694397 s\n",
      "Accuracy 0.9281691171092092 precision 0.9281269102749009 specificity 0.8031691344050466 recall 0.9281691171092092 f1 0.9253622286168454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 14.953009366989136 s\n",
      "Accuracy 0.9305829858825251 precision 0.930092556786985 specificity 0.8150666292788686 recall 0.9305829858825251 f1 0.9282497127270992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 15.565113067626953 s\n",
      "Accuracy 0.9267061663375027 precision 0.9262810394930628 specificity 0.8028365785366388 recall 0.9267061663375027 f1 0.9239791238682864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 15.965010404586792 s\n",
      "Accuracy 0.9309487235754517 precision 0.9307717495841584 specificity 0.8119987291901914 recall 0.9309487235754517 f1 0.9284489629405818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 15.5740327835083 s\n",
      "Accuracy 0.9288274449564772 precision 0.9282750645547504 specificity 0.8083809932239029 recall 0.9288274449564772 f1 0.9263239875323449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 15.350008010864258 s\n",
      "Accuracy 0.9266330187989175 precision 0.9262413504970745 specificity 0.8079335293770035 recall 0.9266330187989175 f1 0.9240200363393118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 15.06701135635376 s\n",
      "Accuracy 0.9289005924950625 precision 0.9285475055085151 specificity 0.8040230598776381 recall 0.9289005924950625 f1 0.9262258543824109\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 15.651008367538452 s\n",
      "Accuracy 0.9284617072635506 precision 0.9279117049300043 specificity 0.8069986793823247 recall 0.9284617072635506 f1 0.9259165624923115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 15.879008531570435 s\n",
      "Accuracy 0.927876526954868 precision 0.927455320200016 specificity 0.8136188243935136 recall 0.927876526954868 f1 0.925435659551049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 15.444009065628052 s\n",
      "Accuracy 0.9273644941847707 precision 0.9266331121847885 specificity 0.8053824018440416 recall 0.9273644941847707 f1 0.92482470655318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 15.636520624160767 s\n",
      "Accuracy 0.9280228220320387 precision 0.9275930204624888 specificity 0.8110639407505308 recall 0.9280228220320387 f1 0.9255257015650284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 16.02467179298401 s\n",
      "Accuracy 0.9271450515690147 precision 0.9267706561300584 specificity 0.8042466410352949 recall 0.9271450515690147 f1 0.9244453260442299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 15.572011470794678 s\n",
      "Accuracy 0.9267061663375027 precision 0.9261584371329685 specificity 0.8081197627590718 recall 0.9267061663375027 f1 0.9241530787553002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 15.229008913040161 s\n",
      "Accuracy 0.9248774778728696 precision 0.9249349972719613 specificity 0.7984541448407074 recall 0.9248774778728696 f1 0.9218521583362943\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 15.09800934791565 s\n",
      "Accuracy 0.9285348548021359 precision 0.9282428047754484 specificity 0.8074598481101813 recall 0.9285348548021359 f1 0.9259153676701478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 15.065009117126465 s\n",
      "Accuracy 0.9304366908053544 precision 0.9299424273992082 specificity 0.8178928585000166 recall 0.9304366908053544 f1 0.9281677592010538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 15.157010555267334 s\n",
      "Accuracy 0.9275107892619413 precision 0.9274527939281084 specificity 0.8002679452524732 recall 0.9275107892619413 f1 0.9246229879980474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 15.221830368041992 s\n",
      "Accuracy 0.9240728549484309 precision 0.9237872511047093 specificity 0.8008009569813285 recall 0.9240728549484309 f1 0.9211939591504302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 15.329091310501099 s\n",
      "Accuracy 0.9285348548021359 precision 0.9282740691576102 specificity 0.8079925742802845 recall 0.9285348548021359 f1 0.9259182512184181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 15.832008123397827 s\n",
      "Accuracy 0.9261941335674054 precision 0.9257357387228564 specificity 0.8084626419511135 recall 0.9261941335674054 f1 0.9236086238122682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 15.476009607315063 s\n",
      "Accuracy 0.9257552483358935 precision 0.9254977856885168 specificity 0.8006267994559638 recall 0.9257552483358935 f1 0.922898185034334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 15.337009191513062 s\n",
      "Accuracy 0.9222441664837978 precision 0.9215724519218679 specificity 0.7935981545505763 recall 0.9222441664837978 f1 0.9192673573857946\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 15.435522079467773 s\n",
      "Accuracy 0.9290468875722332 precision 0.9287182745372144 specificity 0.8059084081012017 recall 0.9290468875722332 f1 0.9264125804845833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 15.736552476882935 s\n",
      "Accuracy 0.9255358057201375 precision 0.925054128861758 specificity 0.8028042972705558 recall 0.9255358057201375 f1 0.9228028914427673\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 15.644009828567505 s\n",
      "Accuracy 0.9298515104966718 precision 0.9294922868071512 specificity 0.8119638690918441 recall 0.9298515104966718 f1 0.9273870807557615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 15.580007791519165 s\n",
      "Accuracy 0.9250969204886256 precision 0.924547462639854 specificity 0.797833102418664 recall 0.9250969204886256 f1 0.9222510340891321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 15.58100962638855 s\n",
      "Accuracy 0.927876526954868 precision 0.927048249980636 specificity 0.8051102532364554 recall 0.927876526954868 f1 0.9253791781966091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 15.9190092086792 s\n",
      "Accuracy 0.9293394777265745 precision 0.9293274534035534 specificity 0.8104800120051121 recall 0.9293394777265745 f1 0.9267232859958522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 15.593010902404785 s\n",
      "Accuracy 0.927657084339112 precision 0.9272103928071238 specificity 0.8114676800550862 recall 0.927657084339112 f1 0.9251687641595329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 15.256008386611938 s\n",
      "Accuracy 0.9268524614146734 precision 0.9268670743256207 specificity 0.8072116552687678 recall 0.9268524614146734 f1 0.9241005427754209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 15.187010288238525 s\n",
      "Accuracy 0.9320459366542316 precision 0.931746199849649 specificity 0.8117412176580691 recall 0.9320459366542316 f1 0.9296011053011678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 15.644168853759766 s\n",
      "Accuracy 0.9281691171092092 precision 0.9279116724077016 specificity 0.8095304112681103 recall 0.9281691171092092 f1 0.925581230023042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 15.315531253814697 s\n",
      "Accuracy 0.9225367566381392 precision 0.9218534948309579 specificity 0.7951068301200709 recall 0.9225367566381392 f1 0.9196112699003276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 15.3830087184906 s\n",
      "Accuracy 0.927437641723356 precision 0.9275294326556266 specificity 0.8038721240832433 recall 0.927437641723356 f1 0.9245938772008424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 15.534366369247437 s\n",
      "Accuracy 0.926998756491844 precision 0.9268739926351736 specificity 0.7989746034256588 recall 0.926998756491844 f1 0.9240871234237384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 15.019092798233032 s\n",
      "Accuracy 0.9261209860288201 precision 0.9259629341817469 specificity 0.8028837392686523 recall 0.9261209860288201 f1 0.9232977266048615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 14.926040172576904 s\n",
      "Accuracy 0.9275107892619413 precision 0.9272980766010133 specificity 0.8087223182749192 recall 0.9275107892619413 f1 0.9248765174495975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 15.419009685516357 s\n",
      "Accuracy 0.9308755760368663 precision 0.930600602977268 specificity 0.8107846636403999 recall 0.9308755760368663 f1 0.9283768496863133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 15.411010980606079 s\n",
      "Accuracy 0.9264867237217468 precision 0.9259361810035973 specificity 0.807102099462104 recall 0.9264867237217468 f1 0.9239050622472004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 15.726518154144287 s\n",
      "Accuracy 0.9285348548021359 precision 0.9285065166919299 specificity 0.8122255667199327 recall 0.9285348548021359 f1 0.9259492549627918\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 16.22154974937439 s\n",
      "Accuracy 0.9257552483358935 precision 0.9252501691420378 specificity 0.807167165412153 recall 0.9257552483358935 f1 0.9231451802089277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 14.905008316040039 s\n",
      "Accuracy 0.9302172481895984 precision 0.9297146673562867 specificity 0.8091570642755963 recall 0.9302172481895984 f1 0.9277429467100299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 14.829008340835571 s\n",
      "Accuracy 0.9270719040304294 precision 0.9267637723264233 specificity 0.8109792153232634 recall 0.9270719040304294 f1 0.9245147498189282\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 15.434010982513428 s\n",
      "Accuracy 0.9304366908053544 precision 0.9306436720768053 specificity 0.8025554688710264 recall 0.9304366908053544 f1 0.9275972013137016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 15.108007192611694 s\n",
      "Accuracy 0.9241460024870163 precision 0.9238029762261496 specificity 0.7955340952998751 recall 0.9241460024870163 f1 0.9211501756099594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 14.869009017944336 s\n",
      "Accuracy 0.9280959695706239 precision 0.9272206130479104 specificity 0.8092144024315969 recall 0.9280959695706239 f1 0.9257248047505785\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 15.12200927734375 s\n",
      "Accuracy 0.927657084339112 precision 0.9275552983826265 specificity 0.8096732806303671 recall 0.927657084339112 f1 0.9250150109101933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 14.897518634796143 s\n",
      "Accuracy 0.927657084339112 precision 0.927090470163354 specificity 0.8127565893106028 recall 0.927657084339112 f1 0.9252426750790517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 15.309534311294556 s\n",
      "Accuracy 0.9290468875722332 precision 0.929102383173594 specificity 0.810207367162261 recall 0.9290468875722332 f1 0.9263992147232335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 14.868064641952515 s\n",
      "Accuracy 0.9254626581815522 precision 0.9252584345146806 specificity 0.8007715508099706 recall 0.9254626581815522 f1 0.9225864479978304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 14.78100872039795 s\n",
      "Accuracy 0.9295589203423305 precision 0.929132470801632 specificity 0.8158608142741055 recall 0.9295589203423305 f1 0.9272032426345925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 14.892009496688843 s\n",
      "Accuracy 0.9239265598712604 precision 0.9233259690513528 specificity 0.8075755160175444 recall 0.9239265598712604 f1 0.9213277344043524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 15.12100863456726 s\n",
      "Accuracy 0.9324848218857436 precision 0.932087466759987 specificity 0.812654702166849 recall 0.9324848218857436 f1 0.9301017116313842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 14.854008197784424 s\n",
      "Accuracy 0.9266330187989175 precision 0.9265737482786626 specificity 0.8025810535856494 recall 0.9266330187989175 f1 0.9237834965112793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 15.075011014938354 s\n",
      "Accuracy 0.9289737400336479 precision 0.9285242466938306 specificity 0.8103745718765853 recall 0.9289737400336479 f1 0.9264849436333906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 15.099007606506348 s\n",
      "Accuracy 0.9253895106429668 precision 0.9250111475922403 specificity 0.8003295194446483 recall 0.9253895106429668 f1 0.9225559198789648\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 15.609010934829712 s\n",
      "Accuracy 0.9265598712603321 precision 0.9262739631806051 specificity 0.7956273086016995 recall 0.9265598712603321 f1 0.9236039052589848\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 15.59600830078125 s\n",
      "Accuracy 0.924511740179943 precision 0.9243977017696973 specificity 0.7974161206564934 recall 0.924511740179943 f1 0.9215017028615772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 15.22609567642212 s\n",
      "Accuracy 0.9282422646477946 precision 0.92802804312028 specificity 0.806892404465197 recall 0.9282422646477946 f1 0.9255786468196592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 15.38400936126709 s\n",
      "Accuracy 0.9258283958744788 precision 0.9255959355693799 specificity 0.8011149583262712 recall 0.9258283958744788 f1 0.9229774016048559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 15.001519680023193 s\n",
      "Accuracy 0.9294126252651598 precision 0.9290441451288216 specificity 0.8124920057789198 recall 0.9294126252651598 f1 0.9269552658226996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 15.006009101867676 s\n",
      "Accuracy 0.9283154121863799 precision 0.9278243414647773 specificity 0.8055313683598698 recall 0.9283154121863799 f1 0.9257109149443165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 15.421011447906494 s\n",
      "Accuracy 0.9287542974178918 precision 0.9285802024578022 specificity 0.8091853394362768 recall 0.9287542974178918 f1 0.9261437596768255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 15.035008668899536 s\n",
      "Accuracy 0.9281691171092092 precision 0.9280209466427027 specificity 0.8077201123247326 recall 0.9281691171092092 f1 0.9255037791967465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 15.273009538650513 s\n",
      "Accuracy 0.9250237729500402 precision 0.9242815253637057 specificity 0.7923047278395692 recall 0.9250237729500402 f1 0.9221025799172212\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 14.855010509490967 s\n",
      "Accuracy 0.9289005924950625 precision 0.9283640919633271 specificity 0.8121905845064822 recall 0.9289005924950625 f1 0.9264843744957506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 15.23900842666626 s\n",
      "Accuracy 0.9255358057201375 precision 0.9252824802004943 specificity 0.796717042198616 recall 0.9255358057201375 f1 0.9225733793545372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 15.404517412185669 s\n",
      "Accuracy 0.9277302318776973 precision 0.9272833769808607 specificity 0.8090005713461689 recall 0.9277302318776973 f1 0.9251832146996404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 15.067518949508667 s\n",
      "Accuracy 0.927657084339112 precision 0.9274777882616764 specificity 0.8089889844556456 recall 0.927657084339112 f1 0.9250218289077989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 15.271009683609009 s\n",
      "Accuracy 0.9261209860288201 precision 0.9259824759339286 specificity 0.8058796930732888 recall 0.9261209860288201 f1 0.9233667010022542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 15.100538730621338 s\n",
      "Accuracy 0.9280228220320387 precision 0.9273006577838994 specificity 0.810824340839633 recall 0.9280228220320387 f1 0.9256268835028277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 14.90107274055481 s\n",
      "Accuracy 0.9281691171092092 precision 0.9278981051539411 specificity 0.8088638122493633 recall 0.9281691171092092 f1 0.9255694399047883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 15.101006984710693 s\n",
      "Accuracy 0.9242191500256016 precision 0.9238220371465781 specificity 0.805790697586279 recall 0.9242191500256016 f1 0.9215083416577557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 14.851009130477905 s\n",
      "Accuracy 0.9281691171092092 precision 0.9277295935489568 specificity 0.8093398771006324 recall 0.9281691171092092 f1 0.9256363494423923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 14.952589511871338 s\n",
      "Accuracy 0.924292297564187 precision 0.9240763293463101 specificity 0.7927425024530305 recall 0.924292297564187 f1 0.9211870123866307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 15.09700870513916 s\n",
      "Accuracy 0.9257552483358935 precision 0.9256221456522582 specificity 0.799179583734262 recall 0.9257552483358935 f1 0.9228233825517083\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 15.236010789871216 s\n",
      "Accuracy 0.9240728549484309 precision 0.9237786138285918 specificity 0.7984375127237481 recall 0.9240728549484309 f1 0.9211353714493303\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 14.939007997512817 s\n",
      "Accuracy 0.9264135761831614 precision 0.9265821482785287 specificity 0.805820540848238 recall 0.9264135761831614 f1 0.923575420643342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 15.054008960723877 s\n",
      "Accuracy 0.9270719040304294 precision 0.9267499038078069 specificity 0.8054627140779679 recall 0.9270719040304294 f1 0.9243836114319947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 14.91900897026062 s\n",
      "Accuracy 0.9272913466461854 precision 0.9268583803730669 specificity 0.8115128057658946 recall 0.9272913466461854 f1 0.9247927461731799\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 15.21252155303955 s\n",
      "Accuracy 0.9255358057201375 precision 0.9251182466806908 specificity 0.8067158507362757 recall 0.9255358057201375 f1 0.9228801479383362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 15.194539070129395 s\n",
      "Accuracy 0.9268524614146734 precision 0.926877470212502 specificity 0.8066297625983828 recall 0.9268524614146734 f1 0.9240832345902679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 15.00900936126709 s\n",
      "Accuracy 0.9281691171092092 precision 0.9281041322897898 specificity 0.803156969090904 recall 0.9281691171092092 f1 0.9253685860152938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 15.072530746459961 s\n",
      "Accuracy 0.9279496744934533 precision 0.9274246715935741 specificity 0.8097824965868481 recall 0.9279496744934533 f1 0.9254531585223347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 14.995070934295654 s\n",
      "Accuracy 0.9297783629580865 precision 0.9294825435207822 specificity 0.8088266468266211 recall 0.9297783629580865 f1 0.9272180885706353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 15.143006801605225 s\n",
      "Accuracy 0.9302903957281837 precision 0.9299895951763085 specificity 0.8139246841529613 recall 0.9302903957281837 f1 0.927861138832337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 15.15700888633728 s\n",
      "Accuracy 0.9239265598712604 precision 0.9234357670628474 specificity 0.7984830380472633 recall 0.9239265598712604 f1 0.9210520131912814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 14.835010290145874 s\n",
      "Accuracy 0.9275107892619413 precision 0.9268639412440444 specificity 0.8083070199500558 recall 0.9275107892619413 f1 0.9250141329473911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 14.915009498596191 s\n",
      "Accuracy 0.927657084339112 precision 0.9270297287530256 specificity 0.8063194940146668 recall 0.927657084339112 f1 0.9251070501693776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 14.922008991241455 s\n",
      "Accuracy 0.927437641723356 precision 0.9273478709726092 specificity 0.8049756678946527 recall 0.927437641723356 f1 0.9246731138550658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 14.911008358001709 s\n",
      "Accuracy 0.9279496744934533 precision 0.9277920242482671 specificity 0.8103799838966019 recall 0.9279496744934533 f1 0.9253471279988593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 15.215519189834595 s\n",
      "Accuracy 0.9261941335674054 precision 0.9259946295101906 specificity 0.8033233762477656 recall 0.9261941335674054 f1 0.9233960810118023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 14.784008264541626 s\n",
      "Accuracy 0.9275107892619413 precision 0.9272246499176136 specificity 0.8041368200839615 recall 0.9275107892619413 f1 0.9247874752376627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 15.077543497085571 s\n",
      "Accuracy 0.9264867237217468 precision 0.9263510164591753 specificity 0.802507450585305 recall 0.9264867237217468 f1 0.9236549887760536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 15.115007400512695 s\n",
      "Accuracy 0.9259746909516495 precision 0.9255126323611562 specificity 0.810074706161118 recall 0.9259746909516495 f1 0.9234267372693644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 15.1520094871521 s\n",
      "Accuracy 0.9259746909516495 precision 0.9253719278448308 specificity 0.8052455410246349 recall 0.9259746909516495 f1 0.9233552255495979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 14.913009405136108 s\n",
      "Accuracy 0.9284617072635506 precision 0.9283384422045394 specificity 0.806075982594829 recall 0.9284617072635506 f1 0.9257552531500859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 15.540539264678955 s\n",
      "Accuracy 0.927876526954868 precision 0.927351696649259 specificity 0.8048812757549357 recall 0.927876526954868 f1 0.9252587520224455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 15.413009405136108 s\n",
      "Accuracy 0.9226099041767245 precision 0.9221876199265424 specificity 0.790245630887123 recall 0.9226099041767245 f1 0.9194646961298335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 15.245008945465088 s\n",
      "Accuracy 0.9281691171092092 precision 0.9279639253886041 specificity 0.8130891500612039 recall 0.9281691171092092 f1 0.925650485830203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 15.147011041641235 s\n",
      "Accuracy 0.9302172481895984 precision 0.930428660774901 specificity 0.8127239055043344 recall 0.9302172481895984 f1 0.9276091196872415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 15.018025636672974 s\n",
      "Accuracy 0.9294857728037451 precision 0.9292361724641283 specificity 0.8128833636607018 recall 0.9294857728037451 f1 0.9270005744139098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 15.142008781433105 s\n",
      "Accuracy 0.9315339038841343 precision 0.9313690452108578 specificity 0.8132816316568622 recall 0.9315339038841343 f1 0.9290715328560107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 14.839587926864624 s\n",
      "Accuracy 0.9269256089532587 precision 0.9265049682628062 specificity 0.8087289732290864 recall 0.9269256089532587 f1 0.9243476065149013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 15.254038095474243 s\n",
      "Accuracy 0.9302903957281837 precision 0.9298937993919043 specificity 0.8148767904753103 recall 0.9302903957281837 f1 0.927914864785003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 14.75300908088684 s\n",
      "Accuracy 0.9269256089532587 precision 0.9262583659012998 specificity 0.7987696649221708 recall 0.9269256089532587 f1 0.9241866364087092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 15.030008554458618 s\n",
      "Accuracy 0.9293394777265745 precision 0.9285532228554614 specificity 0.8108744246462981 recall 0.9293394777265745 f1 0.9269958219237338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 15.01500916481018 s\n",
      "Accuracy 0.9267061663375027 precision 0.9261952886698077 specificity 0.8025621563922585 recall 0.9267061663375027 f1 0.9240015280464993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 15.073010206222534 s\n",
      "Accuracy 0.9291200351108185 precision 0.9288082351450233 specificity 0.8029217615187864 recall 0.9291200351108185 f1 0.9264103887524966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 15.029007911682129 s\n",
      "Accuracy 0.9261209860288201 precision 0.9254967557301058 specificity 0.8021542524165588 recall 0.9261209860288201 f1 0.9234341171344947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 14.975010633468628 s\n",
      "Accuracy 0.9283154121863799 precision 0.9278826003790449 specificity 0.8074410417037251 recall 0.9283154121863799 f1 0.9257372886740284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 15.489007472991943 s\n",
      "Accuracy 0.9297783629580865 precision 0.9295215364490329 specificity 0.8148452553876078 recall 0.9297783629580865 f1 0.9273469373738956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 16.04601001739502 s\n",
      "Accuracy 0.9320459366542316 precision 0.9315097364605364 specificity 0.8195987936340303 recall 0.9320459366542316 f1 0.9298597949002633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 15.509459495544434 s\n",
      "Accuracy 0.9291931826494039 precision 0.9287924968259273 specificity 0.8174321649833799 recall 0.9291931826494039 f1 0.9268593525904419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 15.223010540008545 s\n",
      "Accuracy 0.9298515104966718 precision 0.9297149958665615 specificity 0.8120540553782241 recall 0.9298515104966718 f1 0.9273190344079136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 15.403043746948242 s\n",
      "Accuracy 0.9286811498793066 precision 0.9282294296648975 specificity 0.8118337461490593 recall 0.9286811498793066 f1 0.9262224407842552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 15.473519563674927 s\n",
      "Accuracy 0.9250969204886256 precision 0.92427473362286 specificity 0.8089462822962205 recall 0.9250969204886256 f1 0.9226405102196943\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 15.191008567810059 s\n",
      "Accuracy 0.9287542974178918 precision 0.9286804131392189 specificity 0.8066866937223123 recall 0.9287542974178918 f1 0.9260539775831182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 15.266011238098145 s\n",
      "Accuracy 0.9297052154195011 precision 0.9293555217597238 specificity 0.8108141153502032 recall 0.9297052154195011 f1 0.9272077392723878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 15.054007053375244 s\n",
      "Accuracy 0.9275839368005266 precision 0.9274578298302629 specificity 0.811236198478949 recall 0.9275839368005266 f1 0.9249856816820498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 15.043519735336304 s\n",
      "Accuracy 0.9261941335674054 precision 0.9258493785391034 specificity 0.802478528883628 recall 0.9261941335674054 f1 0.9234208717751763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 15.328731536865234 s\n",
      "Accuracy 0.9264135761831614 precision 0.9258830603983422 specificity 0.8004073287643078 recall 0.9264135761831614 f1 0.9236554422068717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 15.466530323028564 s\n",
      "Accuracy 0.9284617072635506 precision 0.9282352701422751 specificity 0.8062617238307414 recall 0.9284617072635506 f1 0.9257911976316089\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 15.641010284423828 s\n",
      "Accuracy 0.9293394777265745 precision 0.9289165544816609 specificity 0.8104070901555139 recall 0.9293394777265745 f1 0.9268495686457802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 15.66803789138794 s\n",
      "Accuracy 0.9313144612683784 precision 0.9311303513975548 specificity 0.8112144811866242 recall 0.9313144612683784 f1 0.9288063220562578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 14.879369497299194 s\n",
      "Accuracy 0.927437641723356 precision 0.927937719826368 specificity 0.8009551653289885 recall 0.927437641723356 f1 0.9244145887874086\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 15.009008169174194 s\n",
      "Accuracy 0.923414527101163 precision 0.9228091964069037 specificity 0.7993852068644942 recall 0.923414527101163 f1 0.9205932045222013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 15.794010639190674 s\n",
      "Accuracy 0.9286080023407213 precision 0.9287065448856048 specificity 0.8090211689270146 recall 0.9286080023407213 f1 0.9259112695102887\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 15.400317907333374 s\n",
      "Accuracy 0.9261941335674054 precision 0.9260159961331714 specificity 0.8093725857558363 recall 0.9261941335674054 f1 0.9235402635491426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 15.298784732818604 s\n",
      "Accuracy 0.9275107892619413 precision 0.927095747494667 specificity 0.8096130574340398 recall 0.9275107892619413 f1 0.9249637135780996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 15.505519390106201 s\n",
      "Accuracy 0.9261941335674054 precision 0.9260479777927129 specificity 0.8016909536245672 recall 0.9261941335674054 f1 0.9233389325856807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 15.125507116317749 s\n",
      "Accuracy 0.9259746909516495 precision 0.9255498766273971 specificity 0.8045057552556156 recall 0.9259746909516495 f1 0.9232743252730944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 15.248010158538818 s\n",
      "Accuracy 0.9289005924950625 precision 0.9283780857893968 specificity 0.8064331535348109 recall 0.9289005924950625 f1 0.9263411137689662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 14.93000864982605 s\n",
      "Accuracy 0.9255358057201375 precision 0.9252409764211703 specificity 0.8038939086310368 recall 0.9255358057201375 f1 0.9227686087262119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 15.16001009941101 s\n",
      "Accuracy 0.9267061663375027 precision 0.9267886782291533 specificity 0.8020033222793457 recall 0.9267061663375027 f1 0.9238031803004658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 15.071007013320923 s\n",
      "Accuracy 0.9291931826494039 precision 0.9287250984587249 specificity 0.8158879823467152 recall 0.9291931826494039 f1 0.9268461004348706\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 15.434010028839111 s\n",
      "Accuracy 0.9334357398873528 precision 0.9327911540070482 specificity 0.8193194449058709 recall 0.9334357398873528 f1 0.9313098399811153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 14.964008808135986 s\n",
      "Accuracy 0.9272181991076001 precision 0.9271241297999139 specificity 0.7970560619021362 recall 0.9272181991076001 f1 0.9242549238736574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 14.927009105682373 s\n",
      "Accuracy 0.9250969204886256 precision 0.9245823900097047 specificity 0.8075955355280767 recall 0.9250969204886256 f1 0.9224887719574543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 15.05452036857605 s\n",
      "Accuracy 0.9268524614146734 precision 0.9267866484531277 specificity 0.8022340010995147 recall 0.9268524614146734 f1 0.9240009471986352\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 14.980672836303711 s\n",
      "Accuracy 0.9279496744934533 precision 0.9276163392926924 specificity 0.8087909552577751 recall 0.9279496744934533 f1 0.9253639592967038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 14.931002140045166 s\n",
      "Accuracy 0.9258283958744788 precision 0.9253111974768703 specificity 0.8051022434233206 recall 0.9258283958744788 f1 0.9231718697961032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 15.156001567840576 s\n",
      "Accuracy 0.9280228220320387 precision 0.927464034684841 specificity 0.8038275396643031 recall 0.9280228220320387 f1 0.9253943085192071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 15.203001022338867 s\n",
      "Accuracy 0.9291931826494039 precision 0.9290096789226983 specificity 0.8107687787500917 recall 0.9291931826494039 f1 0.9266318626272454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 15.059001207351685 s\n",
      "Accuracy 0.9280959695706239 precision 0.9276645736364001 specificity 0.8140408339343888 recall 0.9280959695706239 f1 0.925672663723645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 15.23400330543518 s\n",
      "Accuracy 0.9231219369468218 precision 0.9225553413092951 specificity 0.7990677268497952 recall 0.9231219369468218 f1 0.9202724311350656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 14.705002307891846 s\n",
      "Accuracy 0.9271450515690147 precision 0.9264853024408879 specificity 0.8096864512559389 recall 0.9271450515690147 f1 0.9246804162036815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 15.260000944137573 s\n",
      "Accuracy 0.9231950844854071 precision 0.9225706011560288 specificity 0.803683950912047 recall 0.9231950844854071 f1 0.920489844720009\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 15.012999773025513 s\n",
      "Accuracy 0.9244385926413576 precision 0.9239547155561393 specificity 0.7923274995263553 recall 0.9244385926413576 f1 0.9214123201865184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 15.10651683807373 s\n",
      "Accuracy 0.9267061663375027 precision 0.9264262705625473 specificity 0.8028402879737662 recall 0.9267061663375027 f1 0.9239318897693082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 15.024001121520996 s\n",
      "Accuracy 0.9278033794162827 precision 0.927657056364434 specificity 0.8050214084250071 recall 0.9278033794162827 f1 0.9250645253593733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 15.819128513336182 s\n",
      "Accuracy 0.926998756491844 precision 0.9268093602244694 specificity 0.8012614513791236 recall 0.926998756491844 f1 0.9241633995782391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 14.967428207397461 s\n",
      "Accuracy 0.9278033794162827 precision 0.9277968237291879 specificity 0.8097433972701055 recall 0.9278033794162827 f1 0.925137907120583\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 15.060147523880005 s\n",
      "Accuracy 0.9278033794162827 precision 0.9277471712349684 specificity 0.8073047514360743 recall 0.9278033794162827 f1 0.925093234712165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 15.049519777297974 s\n",
      "Accuracy 0.9277302318776973 precision 0.9272815278126431 specificity 0.810761068543714 recall 0.9277302318776973 f1 0.9252267516052618\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 14.994999885559082 s\n",
      "Accuracy 0.9306561334211104 precision 0.9303272937136651 specificity 0.8090629482238073 recall 0.9306561334211104 f1 0.9281302400178513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 15.397002696990967 s\n",
      "Accuracy 0.9306561334211104 precision 0.9301891664875522 specificity 0.8147216886019825 recall 0.9306561334211104 f1 0.9283079890525637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 15.132001399993896 s\n",
      "Accuracy 0.9288274449564772 precision 0.9285705022761661 specificity 0.8115329497907856 recall 0.9288274449564772 f1 0.926300075713546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 14.963001012802124 s\n",
      "Accuracy 0.9299246580352571 precision 0.9292086377683628 specificity 0.8181584113042389 recall 0.9299246580352571 f1 0.9277374035981186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 15.347513198852539 s\n",
      "Accuracy 0.9255358057201375 precision 0.92502033037518 specificity 0.8048907176660416 recall 0.9255358057201375 f1 0.9228675744889016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 15.199002027511597 s\n",
      "Accuracy 0.9313876088069637 precision 0.9310292712378234 specificity 0.8098046980185767 recall 0.9313876088069637 f1 0.9289038451101777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 15.038002014160156 s\n",
      "Accuracy 0.9283885597249653 precision 0.9282312054782963 specificity 0.801836576435679 recall 0.9283885597249653 f1 0.9255883753548669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 15.267001152038574 s\n",
      "Accuracy 0.9265598712603321 precision 0.9262462509827651 specificity 0.8065476324942493 recall 0.9265598712603321 f1 0.9238854953967885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 15.356001377105713 s\n",
      "Accuracy 0.9299246580352571 precision 0.9298117121969123 specificity 0.8070946367085885 recall 0.9299246580352571 f1 0.9272703193397621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 15.18200159072876 s\n",
      "Accuracy 0.9272913466461854 precision 0.9269186454955445 specificity 0.8078769870150233 recall 0.9272913466461854 f1 0.92468338781001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 14.895004272460938 s\n",
      "Accuracy 0.9253895106429668 precision 0.9250087247706295 specificity 0.8021579337892439 recall 0.9253895106429668 f1 0.9226032400411232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 15.15050983428955 s\n",
      "Accuracy 0.930144100651013 precision 0.9298570686238717 specificity 0.814961746784463 recall 0.930144100651013 f1 0.9277317789542011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 15.540092468261719 s\n",
      "Accuracy 0.9266330187989175 precision 0.9266093291421097 specificity 0.8053779607113812 recall 0.9266330187989175 f1 0.9238424856910493\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 15.37500286102295 s\n",
      "Accuracy 0.9268524614146734 precision 0.9265897546187812 specificity 0.8063382029107583 recall 0.9268524614146734 f1 0.9241624259302116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 15.02500033378601 s\n",
      "Accuracy 0.9258283958744788 precision 0.9255569903592104 specificity 0.8091754891294063 recall 0.9258283958744788 f1 0.9231920908992656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 15.055001258850098 s\n",
      "Accuracy 0.9261209860288201 precision 0.9259455975003404 specificity 0.7988891415136704 recall 0.9261209860288201 f1 0.9232027029441674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 15.532020092010498 s\n",
      "Accuracy 0.9248043303342842 precision 0.924701795839422 specificity 0.8014286455681428 recall 0.9248043303342842 f1 0.9219001933393051\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, seed in enumerate(seeds):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.927145     0.803388   0.926878  0.927145  0.924390\n1  0.930364     0.819016   0.930023  0.930364  0.928066\n2  0.926340     0.805278   0.925959  0.926340  0.923652\n3  0.927072     0.803830   0.926479  0.927072  0.924436\n4  0.927072     0.804962   0.926638  0.927072  0.924408\n5  0.927364     0.811370   0.926811  0.927364  0.924906\n6  0.931461     0.811285   0.931588  0.931461  0.928868\n7  0.926852     0.802903   0.926497  0.926852  0.924107\n8  0.924219     0.794124   0.923795  0.924219  0.921215\n9  0.929559     0.814212   0.929100  0.929559  0.927176",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.927145</td>\n      <td>0.803388</td>\n      <td>0.926878</td>\n      <td>0.927145</td>\n      <td>0.924390</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.930364</td>\n      <td>0.819016</td>\n      <td>0.930023</td>\n      <td>0.930364</td>\n      <td>0.928066</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.926340</td>\n      <td>0.805278</td>\n      <td>0.925959</td>\n      <td>0.926340</td>\n      <td>0.923652</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.927072</td>\n      <td>0.803830</td>\n      <td>0.926479</td>\n      <td>0.927072</td>\n      <td>0.924436</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.927072</td>\n      <td>0.804962</td>\n      <td>0.926638</td>\n      <td>0.927072</td>\n      <td>0.924408</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.927364</td>\n      <td>0.811370</td>\n      <td>0.926811</td>\n      <td>0.927364</td>\n      <td>0.924906</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.931461</td>\n      <td>0.811285</td>\n      <td>0.931588</td>\n      <td>0.931461</td>\n      <td>0.928868</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.926852</td>\n      <td>0.802903</td>\n      <td>0.926497</td>\n      <td>0.926852</td>\n      <td>0.924107</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.924219</td>\n      <td>0.794124</td>\n      <td>0.923795</td>\n      <td>0.924219</td>\n      <td>0.921215</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.929559</td>\n      <td>0.814212</td>\n      <td>0.929100</td>\n      <td>0.929559</td>\n      <td>0.927176</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.9275567259161729\n",
      "Precision 0.9272157845465229\n",
      "Specificity 0.8067636254303853\n",
      "Recall 0.9275567259161729\n",
      "F1 0.924917757764894\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_8beats_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}