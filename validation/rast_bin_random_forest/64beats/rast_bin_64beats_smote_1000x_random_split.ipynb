{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 64 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id        dw_1        dw_2        dw_3       dw_4       dw_5     mfw_1  \\\n0  e0106  267.535629  270.981533  270.243834  76.791207  11.207306  0.483334   \n1  e0106  277.949875  283.546637  283.543383  80.370321  11.621628  0.480582   \n2  e0106  280.952321  289.729213  288.768479  81.676148  11.842770  0.479468   \n3  e0106  266.093352  277.366979  279.066959  79.365536  11.515873  0.479998   \n4  e0106  279.838160  290.933842  289.849559  81.839924  11.791220  0.479852   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.435149 -0.637676 -0.096703  ... -0.047331  0.034527 -0.042788  0.048729   \n1 -0.437337 -0.666380 -0.138188  ... -0.053865  0.034099 -0.034026  0.038144   \n2 -0.434101 -0.641674 -0.075015  ... -0.041838  0.031072 -0.035728  0.040951   \n3 -0.433339 -0.648197 -0.093792  ... -0.047719  0.029625 -0.035988  0.049478   \n4 -0.432266 -0.660649 -0.107788  ... -0.050448  0.030725 -0.035125  0.042994   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.072291  0.006842 -0.025811 -0.008343 -0.007415    NSR  \n1 -0.071427  0.011442 -0.027634 -0.009450 -0.002719    NSR  \n2 -0.067828  0.007170 -0.022649 -0.013308 -0.001871    NSR  \n3 -0.081219  0.019213 -0.029185 -0.014198 -0.000186    NSR  \n4 -0.070263  0.010677 -0.027446 -0.011952 -0.001447    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>267.535629</td>\n      <td>270.981533</td>\n      <td>270.243834</td>\n      <td>76.791207</td>\n      <td>11.207306</td>\n      <td>0.483334</td>\n      <td>-0.435149</td>\n      <td>-0.637676</td>\n      <td>-0.096703</td>\n      <td>...</td>\n      <td>-0.047331</td>\n      <td>0.034527</td>\n      <td>-0.042788</td>\n      <td>0.048729</td>\n      <td>-0.072291</td>\n      <td>0.006842</td>\n      <td>-0.025811</td>\n      <td>-0.008343</td>\n      <td>-0.007415</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>277.949875</td>\n      <td>283.546637</td>\n      <td>283.543383</td>\n      <td>80.370321</td>\n      <td>11.621628</td>\n      <td>0.480582</td>\n      <td>-0.437337</td>\n      <td>-0.666380</td>\n      <td>-0.138188</td>\n      <td>...</td>\n      <td>-0.053865</td>\n      <td>0.034099</td>\n      <td>-0.034026</td>\n      <td>0.038144</td>\n      <td>-0.071427</td>\n      <td>0.011442</td>\n      <td>-0.027634</td>\n      <td>-0.009450</td>\n      <td>-0.002719</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>280.952321</td>\n      <td>289.729213</td>\n      <td>288.768479</td>\n      <td>81.676148</td>\n      <td>11.842770</td>\n      <td>0.479468</td>\n      <td>-0.434101</td>\n      <td>-0.641674</td>\n      <td>-0.075015</td>\n      <td>...</td>\n      <td>-0.041838</td>\n      <td>0.031072</td>\n      <td>-0.035728</td>\n      <td>0.040951</td>\n      <td>-0.067828</td>\n      <td>0.007170</td>\n      <td>-0.022649</td>\n      <td>-0.013308</td>\n      <td>-0.001871</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>266.093352</td>\n      <td>277.366979</td>\n      <td>279.066959</td>\n      <td>79.365536</td>\n      <td>11.515873</td>\n      <td>0.479998</td>\n      <td>-0.433339</td>\n      <td>-0.648197</td>\n      <td>-0.093792</td>\n      <td>...</td>\n      <td>-0.047719</td>\n      <td>0.029625</td>\n      <td>-0.035988</td>\n      <td>0.049478</td>\n      <td>-0.081219</td>\n      <td>0.019213</td>\n      <td>-0.029185</td>\n      <td>-0.014198</td>\n      <td>-0.000186</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>279.838160</td>\n      <td>290.933842</td>\n      <td>289.849559</td>\n      <td>81.839924</td>\n      <td>11.791220</td>\n      <td>0.479852</td>\n      <td>-0.432266</td>\n      <td>-0.660649</td>\n      <td>-0.107788</td>\n      <td>...</td>\n      <td>-0.050448</td>\n      <td>0.030725</td>\n      <td>-0.035125</td>\n      <td>0.042994</td>\n      <td>-0.070263</td>\n      <td>0.010677</td>\n      <td>-0.027446</td>\n      <td>-0.011952</td>\n      <td>-0.001447</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_64beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    6531\nST     1990\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAHsCAYAAAAHPnNYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ/UlEQVR4nO3dfdBmd13f8c8XFlARSUJijEk0saRqfADSnSSMFluiITyMSS1SUMs2kxrbRgcfWhuc1liQinUoyghoKtHFKiGiNClSMQ0+9EFCFgkoIGaLZJJtQlY2iUYEGvz2j/us3oTd7L3Jfvd+4PWauec+53d+17l+105m551zruva6u4AADDnEeu9AACArU5wAQAME1wAAMMEFwDAMMEFADBMcAEADBNcAADDBBewoVTVt1XVrqq6r6ruqKr/VlVfv4bHdVU98WisEeBwCS5gw6iq70/yk0n+fZITk3xJktckuXAdl/Wgqmrbeq8B2PgEF7AhVNXjk7wkyWXd/Wvd/Rfd/f+6+79297+qqrOr6veq6p7lytdPV9Wjl8f+7nKa9yxXxv7RMv6cqrp5ecz/rqqvXfV8Z1XVu6vqz6vqV6rqjVX1o6uOf2dV7a6qfVV1XVV98apjXVWXVdUtSW6pqldX1Sse8Hquq6rvm/sTAzYTwQVsFE9N8jlJ3nyQ459K8n1Jjl/mnpfkXyRJdz9tmfOk7v787n5jVT0lyVVJvivJE5L8bJLrquoxS6i9OckvJDkuyRuS/IP9T1RVT0/yY0mel+SkJLcmufoB67koyTlJzkyyM8kLquoRy+OPT/KNSX75Ifw5AFuQ4AI2iick+dPuvv9AB7v7Xd39ju6+v7s/nJWA+oYHOd+lSX62u2/s7k91984kn0hy7vKzLcmrlqtov5bknase++1Jruru3+/uTyR5cZKnVtVpq+b8WHfv6+6/7O53Jrk3KxGYJM9P8tvd/ZHD+yMAtirBBWwUH01y/MHeE1VVf7uq3lJVd1bVn2XlfV7HP8j5vjTJDyy3E++pqnuSnJrki5efPd3dq+bftmr7i7NyVStJ0t33Les7+SDzk5WrXN+xbH9Hkl98kLUBn2UEF7BR/F5WrkBddJDjr03yR0nO6O4vSPJDSepBzndbkpd19zGrfj6vu9+Q5I4kJ1fV6sefumr7/2Yl2JIkVfXYrFyB27NqzupYS5L/nOTCqnpSkq9M8l8eZG3AZxnBBWwI3X1vkh9O8uqquqiqPq+qHlVVz6yq/5DkcUn+LMl9VfUVSf75A07xkSRftmr/PyX5Z1V1Tq14bFU9u6oel5W4+1SS766qbVV1YZKzVz32DUkurqonV9VjsnI17cblVubB1n97kpuycmXrV7v7Lx/6nwaw1QguYMPo7lck+f4k/ybJ3qxcpfrurFwt+pdJvi3Jn2clpt74gIf/SJKdy+3D53X3riTfmeSnk9ydZHeSf7I8zyeTfEuSS5Lck5VbgG/JyhW2dPd/T/Jvk/xqVq6G/a2svC/rUHYm+Zq4nQg8QH36WxgAPjtV1Y1Jfqa7f/5hnONpWbm1+KXtL1dgFVe4gM9KVfUNVfVFyy3FHUm+NslvPIzzPSrJi5L8nNgCHsg3JAOfrb48yTVJHpvkQ0me2913PJQTVdVXJtmV5D1JLj5iKwS2DLcUAQCGuaUIADBsQ99SPP744/u0005b72UAABzSu971rj/t7hMOdGxDB9dpp52WXbt2rfcyAAAOqapuPdgxtxQBAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBg2Lb1XgCH77TLf329l8Am8uGXP3u9lwDwWc8VLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBg2JqCq6qOqao3VdUfVdUHquqpVXVcVV1fVbcsv49d5lZVvaqqdlfVe6vqrFXn2bHMv6Wqdky9KACAjWStV7h+KslvdPdXJHlSkg8kuTzJDd19RpIblv0keWaSM5afS5O8Nkmq6rgkVyQ5J8nZSa7YH2kAAFvZIYOrqh6f5GlJXpck3f3J7r4nyYVJdi7Tdia5aNm+MMnre8U7khxTVScleUaS67t7X3ffneT6JBccwdcCALAhreUK1+lJ9ib5+ap6d1X9XFU9NsmJ3X3HMufOJCcu2ycnuW3V429fxg42/mmq6tKq2lVVu/bu3Xt4rwYAYANaS3BtS3JWktd291OS/EX+5vZhkqS7O0kfiQV195Xdvb27t59wwglH4pQAAOtqLcF1e5Lbu/vGZf9NWQmwjyy3CrP8vms5vifJqasef8oydrBxAIAt7ZDB1d13Jrmtqr58GTovyfuTXJdk/ycNdyS5dtm+LskLl08rnpvk3uXW49uSnF9Vxy5vlj9/GQMA2NK2rXHe9yT5pap6dJIPJbk4K7F2TVVdkuTWJM9b5r41ybOS7E7ysWVuuntfVb00yU3LvJd0974j8ioAADawNQVXd9+cZPsBDp13gLmd5LKDnOeqJFcdxvoAADY93zQPADBMcAEADBNcAADDBBcAwDDBBQAwTHABAAwTXAAAwwQXAMAwwQUAMExwAQAME1wAAMMEFwDAMMEFADBMcAEADBNcAADDBBcAwDDBBQAwTHABAAwTXAAAwwQXAMAwwQUAMExwAQAME1wAAMMEFwDAMMEFADBMcAEADBNcAADDBBcAwDDBBQAwTHABAAwTXAAAwwQXAMAwwQUAMExwAQAME1wAAMMEFwDAMMEFADBMcAEADBNcAADDBBcAwDDBBQAwTHABAAwTXAAAwwQXAMAwwQUAMExwAQAME1wAAMMEFwDAMMEFADBMcAEADBNcAADDBBcAwDDBBQAwTHABAAxbU3BV1Yer6g+q6uaq2rWMHVdV11fVLcvvY5fxqqpXVdXuqnpvVZ216jw7lvm3VNWOmZcEALCxHM4Vrr/f3U/u7u3L/uVJbujuM5LcsOwnyTOTnLH8XJrktclKoCW5Isk5Sc5OcsX+SAMA2Moezi3FC5PsXLZ3Jrlo1fjre8U7khxTVScleUaS67t7X3ffneT6JBc8jOcHANgU1hpcneQ3q+pdVXXpMnZid9+xbN+Z5MRl++Qkt6167O3L2MHGP01VXVpVu6pq1969e9e4PACAjWvbGud9fXfvqaovTHJ9Vf3R6oPd3VXVR2JB3X1lkiuTZPv27UfknAAA62lNV7i6e8/y+64kb87Ke7A+stwqzPL7rmX6niSnrnr4KcvYwcYBALa0QwZXVT22qh63fzvJ+Un+MMl1SfZ/0nBHkmuX7euSvHD5tOK5Se5dbj2+Lcn5VXXs8mb585cxAIAtbS23FE9M8uaq2j//l7v7N6rqpiTXVNUlSW5N8rxl/luTPCvJ7iQfS3JxknT3vqp6aZKblnkv6e59R+yVAABsUIcMru7+UJInHWD8o0nOO8B4J7nsIOe6KslVh79MAIDNyzfNAwAME1wAAMMEFwDAMMEFADBMcAEADBNcAADDBBcAwDDBBQAwTHABAAwTXAAAwwQXAMAwwQUAMExwAQAME1wAAMMEFwDAMMEFADBMcAEADBNcAADDBBcAwDDBBQAwTHABAAwTXAAAwwQXAMAwwQUAMExwAQAME1wAAMMEFwDAMMEFADBMcAEADBNcAADDBBcAwDDBBQAwTHABAAwTXAAAwwQXAMAwwQUAMExwAQAME1wAAMMEFwDAMMEFADBMcAEADBNcAADDBBcAwDDBBQAwTHABAAwTXAAAwwQXAMAwwQUAMExwAQAME1wAAMMEFwDAMMEFADBMcAEADBNcAADD1hxcVfXIqnp3Vb1l2T+9qm6sqt1V9caqevQy/phlf/dy/LRV53jxMv7BqnrGEX81AAAb0OFc4XpRkg+s2v/xJK/s7icmuTvJJcv4JUnuXsZfucxLVZ2Z5PlJvirJBUleU1WPfHjLBwDY+NYUXFV1SpJnJ/m5Zb+SPD3Jm5YpO5NctGxfuOxnOX7eMv/CJFd39ye6+0+S7E5y9hF4DQAAG9par3D9ZJIfTPJXy/4TktzT3fcv+7cnOXnZPjnJbUmyHL93mf/X4wd4DADAlnXI4Kqq5yS5q7vfdRTWk6q6tKp2VdWuvXv3Ho2nBAAYtZYrXF+X5Jur6sNJrs7KrcSfSnJMVW1b5pySZM+yvSfJqUmyHH98ko+uHj/AY/5ad1/Z3du7e/sJJ5xw2C8IAGCjOWRwdfeLu/uU7j4tK296f3t3f3uS30ry3GXajiTXLtvXLftZjr+9u3sZf/7yKcbTk5yR5J1H7JUAAGxQ2w495aD+dZKrq+pHk7w7yeuW8dcl+cWq2p1kX1YiLd39vqq6Jsn7k9yf5LLu/tTDeH4AgE3hsIKru387yW8v2x/KAT5l2N0fT/KtB3n8y5K87HAXCQCwmfmmeQCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABh2yOCqqs+pqndW1Xuq6n1V9e+W8dOr6saq2l1Vb6yqRy/jj1n2dy/HT1t1rhcv4x+sqmeMvSoAgA1kLVe4PpHk6d39pCRPTnJBVZ2b5MeTvLK7n5jk7iSXLPMvSXL3Mv7KZV6q6swkz0/yVUkuSPKaqnrkEXwtAAAb0iGDq1fct+w+avnpJE9P8qZlfGeSi5btC5f9LMfPq6paxq/u7k90958k2Z3k7CPxIgAANrI1vYerqh5ZVTcnuSvJ9Un+T5J7uvv+ZcrtSU5etk9OcluSLMfvTfKE1eMHeMzq57q0qnZV1a69e/ce9gsCANho1hRc3f2p7n5yklOyclXqK6YW1N1Xdvf27t5+wgknTD0NAMBRc1ifUuzue5L8VpKnJjmmqrYth05JsmfZ3pPk1CRZjj8+yUdXjx/gMQAAW9ZaPqV4QlUds2x/bpJvSvKBrITXc5dpO5Jcu2xft+xnOf727u5l/PnLpxhPT3JGknceodcBALBhbTv0lJyUZOfyicJHJLmmu99SVe9PcnVV/WiSdyd53TL/dUl+sap2J9mXlU8mprvfV1XXJHl/kvuTXNbdnzqyLwcAYOM5ZHB193uTPOUA4x/KAT5l2N0fT/KtBznXy5K87PCXCQCwefmmeQCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBg2CGDq6pOrarfqqr3V9X7qupFy/hxVXV9Vd2y/D52Ga+qelVV7a6q91bVWavOtWOZf0tV7Zh7WQAAG8darnDdn+QHuvvMJOcmuayqzkxyeZIbuvuMJDcs+0nyzCRnLD+XJnltshJoSa5Ick6Ss5NcsT/SAAC2skMGV3ff0d2/v2z/eZIPJDk5yYVJdi7Tdia5aNm+MMnre8U7khxTVScleUaS67t7X3ffneT6JBccyRcDALARHdZ7uKrqtCRPSXJjkhO7+47l0J1JTly2T05y26qH3b6MHWz8gc9xaVXtqqpde/fuPZzlAQBsSNvWOrGqPj/Jryb53u7+s6r662Pd3VXVR2JB3X1lkiuTZPv27UfknAAc2mmX//p6L4FN5MMvf/Z6L2FTWdMVrqp6VFZi65e6+9eW4Y8stwqz/L5rGd+T5NRVDz9lGTvYOADAlraWTylWktcl+UB3/8dVh65Lsv+ThjuSXLtq/IXLpxXPTXLvcuvxbUnOr6pjlzfLn7+MAQBsaWu5pfh1Sf5xkj+oqpuXsR9K8vIk11TVJUluTfK85dhbkzwrye4kH0tycZJ0976qemmSm5Z5L+nufUfiRQAAbGSHDK7u/p9J6iCHzzvA/E5y2UHOdVWSqw5ngQAAm51vmgcAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhhwyuqrqqqu6qqj9cNXZcVV1fVbcsv49dxquqXlVVu6vqvVV11qrH7Fjm31JVO2ZeDgDAxrOWK1y/kOSCB4xdnuSG7j4jyQ3LfpI8M8kZy8+lSV6brARakiuSnJPk7CRX7I80AICt7pDB1d2/m2TfA4YvTLJz2d6Z5KJV46/vFe9IckxVnZTkGUmu7+593X13kuvzmREHALAlPdT3cJ3Y3Xcs23cmOXHZPjnJbavm3b6MHWz8M1TVpVW1q6p27d279yEuDwBg43jYb5rv7k7SR2At+893ZXdv7+7tJ5xwwpE6LQDAunmowfWR5VZhlt93LeN7kpy6at4py9jBxgEAtryHGlzXJdn/ScMdSa5dNf7C5dOK5ya5d7n1+LYk51fVscub5c9fxgAAtrxth5pQVW9I8veSHF9Vt2fl04YvT3JNVV2S5NYkz1umvzXJs5LsTvKxJBcnSXfvq6qXJrlpmfeS7n7gG/EBALakQwZXd7/gIIfOO8DcTnLZQc5zVZKrDmt1AABbgG+aBwAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGHfXgqqoLquqDVbW7qi4/2s8PAHC0HdXgqqpHJnl1kmcmOTPJC6rqzKO5BgCAo+1oX+E6O8nu7v5Qd38yydVJLjzKawAAOKq2HeXnOznJbav2b09yzuoJVXVpkkuX3fuq6oNHaW1sfscn+dP1XsRGUz++3iuATc/fLQfg75YD+tKDHTjawXVI3X1lkivXex1sPlW1q7u3r/c6gK3F3y0cCUf7luKeJKeu2j9lGQMA2LKOdnDdlOSMqjq9qh6d5PlJrjvKawAAOKqO6i3F7r6/qr47yduSPDLJVd39vqO5BrY0t6KBCf5u4WGr7l7vNQAAbGm+aR4AYJjgAgAYJrgAAIYJLgBIUlXnrvca2LoEF1tOVX3Jeq8B2JRes94LYOsSXGxaVfXUqnpuVX3hsv+1VfXLSf7XOi8NAD6Nr4VgU6qqn0jynCQ3J3liVr7b7Z8m+bEkP9vdH1+/1QGbUVXdk+R3D3a8u7/56K2GrWbD/VuKsEbPTvKU7v54VR2blX8U/au7+8PruyxgE9ub5BXrvQi2JsHFZvXx/VexuvvuqrpFbAEP033d/TvrvQi2JsHFZvVlVbX63+E8ffW+S//AQ3B3VX1Rd9+ZJFX1wiT/MMmtSX6ku/et6+rY1LyHi02pqr7hwY77v1TgcFXV7yf5xu7eV1VPS3J1ku9J8uQkX9ndz13P9bG5CS62hKp6VJKvTrKnu+9a7/UAm09V3dzdT162X51kb3f/yAOPwUPhayHYlKrqZ6rqq5btxyd5T5LXJ3l3Vb1gXRcHbFbbqmr/W23OS/L21cfWYT1sIYKLzervdvf7lu2Lk/xxd39Nkr+T5AfXb1nAJvaGJL9TVdcm+csk/yNJquqJSe5dz4Wx+Sl2NqtPrtr+piS/kiTdfWdVrc+KgE2tu19WVTckOSnJb/bfvOfmEVl5Lxc8ZIKLzeqeqnpOkj1Jvi7JJUmy3A743PVcGLB5dfc7DjD2x+uxFrYWwcVm9V1JXpXki5J87/6PcWflfRe/vm6rAoAD8ClFAIBhrnCxKVXVDz/I4e7ulx61xQDAIbjCxaZUVT9wgOHPy8o/YP2E7v78o7wkADgowcWmV1WPS/KirLxx/pokr/DlpwBsJG4psmlV1XFJvj/JtyfZmeSs7r57fVcFAJ9JcLEpVdVPJPmWJFcm+Zruvm+dlwQAB+WWIptSVf1Vkk8kuT/J6v+IKytvmv+CdVkYAByA4AIAGObfUgQAGCa4AACGCS4AgGGCCwBg2P8H/taToNKlc7QAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.273382  0.122628  0.083674  0.051094  0.221600 -0.049649   \ndw_2    0.273382  1.000000  0.838009  0.506753  0.191967  0.386284 -0.517805   \ndw_3    0.122628  0.838009  1.000000  0.707121  0.290188  0.236678 -0.561877   \ndw_4    0.083674  0.506753  0.707121  1.000000  0.871892 -0.017655 -0.285199   \ndw_5    0.051094  0.191967  0.290188  0.871892  1.000000 -0.129453 -0.030009   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.092294  0.039959  0.069581  0.051053  0.013172 -0.160514  0.118367   \ncfr_13 -0.054016  0.136143  0.038555  0.026543  0.024296  0.066207 -0.006270   \ncfr_14 -0.072729  0.005734 -0.024726 -0.037506 -0.044898 -0.013333  0.037817   \ncfr_15 -0.130987 -0.118431 -0.136079 -0.119712 -0.070291  0.043544  0.078133   \ncfr_16 -0.124267 -0.066128 -0.044854 -0.043279 -0.028559  0.051793 -0.022612   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.078730 -0.012908  0.013862  ... -0.117220 -0.037767 -0.071736   \ndw_2   -0.334992 -0.004812  0.033948  ... -0.102493  0.182840  0.234210   \ndw_3   -0.475222  0.011125  0.014124  ... -0.197277  0.158323  0.273116   \ndw_4   -0.270161  0.009232  0.003634  ... -0.149766  0.073674  0.107847   \ndw_5   -0.050190  0.002565 -0.000720  ... -0.059404  0.011401 -0.015802   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.127268 -0.005908  0.006278  ... -0.134908 -0.218479 -0.043561   \ncfr_13  0.019160  0.007572 -0.003219  ...  0.180735  0.047865 -0.208494   \ncfr_14  0.030309  0.006547 -0.008574  ...  0.131588  0.237481  0.033791   \ncfr_15  0.032731  0.009685 -0.019258  ...  0.301428  0.154375 -0.085936   \ncfr_16 -0.002994  0.010071 -0.004850  ...  0.273929  0.119418  0.205876   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.046960 -0.038058 -0.092294 -0.054016 -0.072729 -0.130987 -0.124267  \ndw_2    0.178912  0.060450  0.039959  0.136143  0.005734 -0.118431 -0.066128  \ndw_3    0.121813 -0.051209  0.069581  0.038555 -0.024726 -0.136079 -0.044854  \ndw_4    0.080194 -0.042344  0.051053  0.026543 -0.037506 -0.119712 -0.043279  \ndw_5    0.062258  0.002897  0.013172  0.024296 -0.044898 -0.070291 -0.028559  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.050509  0.078646  1.000000  0.025204  0.020729 -0.368802 -0.228329  \ncfr_13 -0.263557  0.025616  0.025204  1.000000  0.246144  0.176991 -0.125499  \ncfr_14 -0.177838 -0.278564  0.020729  0.246144  1.000000  0.233453 -0.128832  \ncfr_15 -0.131212 -0.053772 -0.368802  0.176991  0.233453  1.000000  0.371065  \ncfr_16  0.195965  0.020836 -0.228329 -0.125499 -0.128832  0.371065  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.273382</td>\n      <td>0.122628</td>\n      <td>0.083674</td>\n      <td>0.051094</td>\n      <td>0.221600</td>\n      <td>-0.049649</td>\n      <td>0.078730</td>\n      <td>-0.012908</td>\n      <td>0.013862</td>\n      <td>...</td>\n      <td>-0.117220</td>\n      <td>-0.037767</td>\n      <td>-0.071736</td>\n      <td>-0.046960</td>\n      <td>-0.038058</td>\n      <td>-0.092294</td>\n      <td>-0.054016</td>\n      <td>-0.072729</td>\n      <td>-0.130987</td>\n      <td>-0.124267</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.273382</td>\n      <td>1.000000</td>\n      <td>0.838009</td>\n      <td>0.506753</td>\n      <td>0.191967</td>\n      <td>0.386284</td>\n      <td>-0.517805</td>\n      <td>-0.334992</td>\n      <td>-0.004812</td>\n      <td>0.033948</td>\n      <td>...</td>\n      <td>-0.102493</td>\n      <td>0.182840</td>\n      <td>0.234210</td>\n      <td>0.178912</td>\n      <td>0.060450</td>\n      <td>0.039959</td>\n      <td>0.136143</td>\n      <td>0.005734</td>\n      <td>-0.118431</td>\n      <td>-0.066128</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.122628</td>\n      <td>0.838009</td>\n      <td>1.000000</td>\n      <td>0.707121</td>\n      <td>0.290188</td>\n      <td>0.236678</td>\n      <td>-0.561877</td>\n      <td>-0.475222</td>\n      <td>0.011125</td>\n      <td>0.014124</td>\n      <td>...</td>\n      <td>-0.197277</td>\n      <td>0.158323</td>\n      <td>0.273116</td>\n      <td>0.121813</td>\n      <td>-0.051209</td>\n      <td>0.069581</td>\n      <td>0.038555</td>\n      <td>-0.024726</td>\n      <td>-0.136079</td>\n      <td>-0.044854</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.083674</td>\n      <td>0.506753</td>\n      <td>0.707121</td>\n      <td>1.000000</td>\n      <td>0.871892</td>\n      <td>-0.017655</td>\n      <td>-0.285199</td>\n      <td>-0.270161</td>\n      <td>0.009232</td>\n      <td>0.003634</td>\n      <td>...</td>\n      <td>-0.149766</td>\n      <td>0.073674</td>\n      <td>0.107847</td>\n      <td>0.080194</td>\n      <td>-0.042344</td>\n      <td>0.051053</td>\n      <td>0.026543</td>\n      <td>-0.037506</td>\n      <td>-0.119712</td>\n      <td>-0.043279</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.051094</td>\n      <td>0.191967</td>\n      <td>0.290188</td>\n      <td>0.871892</td>\n      <td>1.000000</td>\n      <td>-0.129453</td>\n      <td>-0.030009</td>\n      <td>-0.050190</td>\n      <td>0.002565</td>\n      <td>-0.000720</td>\n      <td>...</td>\n      <td>-0.059404</td>\n      <td>0.011401</td>\n      <td>-0.015802</td>\n      <td>0.062258</td>\n      <td>0.002897</td>\n      <td>0.013172</td>\n      <td>0.024296</td>\n      <td>-0.044898</td>\n      <td>-0.070291</td>\n      <td>-0.028559</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.092294</td>\n      <td>0.039959</td>\n      <td>0.069581</td>\n      <td>0.051053</td>\n      <td>0.013172</td>\n      <td>-0.160514</td>\n      <td>0.118367</td>\n      <td>0.127268</td>\n      <td>-0.005908</td>\n      <td>0.006278</td>\n      <td>...</td>\n      <td>-0.134908</td>\n      <td>-0.218479</td>\n      <td>-0.043561</td>\n      <td>0.050509</td>\n      <td>0.078646</td>\n      <td>1.000000</td>\n      <td>0.025204</td>\n      <td>0.020729</td>\n      <td>-0.368802</td>\n      <td>-0.228329</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.054016</td>\n      <td>0.136143</td>\n      <td>0.038555</td>\n      <td>0.026543</td>\n      <td>0.024296</td>\n      <td>0.066207</td>\n      <td>-0.006270</td>\n      <td>0.019160</td>\n      <td>0.007572</td>\n      <td>-0.003219</td>\n      <td>...</td>\n      <td>0.180735</td>\n      <td>0.047865</td>\n      <td>-0.208494</td>\n      <td>-0.263557</td>\n      <td>0.025616</td>\n      <td>0.025204</td>\n      <td>1.000000</td>\n      <td>0.246144</td>\n      <td>0.176991</td>\n      <td>-0.125499</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.072729</td>\n      <td>0.005734</td>\n      <td>-0.024726</td>\n      <td>-0.037506</td>\n      <td>-0.044898</td>\n      <td>-0.013333</td>\n      <td>0.037817</td>\n      <td>0.030309</td>\n      <td>0.006547</td>\n      <td>-0.008574</td>\n      <td>...</td>\n      <td>0.131588</td>\n      <td>0.237481</td>\n      <td>0.033791</td>\n      <td>-0.177838</td>\n      <td>-0.278564</td>\n      <td>0.020729</td>\n      <td>0.246144</td>\n      <td>1.000000</td>\n      <td>0.233453</td>\n      <td>-0.128832</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.130987</td>\n      <td>-0.118431</td>\n      <td>-0.136079</td>\n      <td>-0.119712</td>\n      <td>-0.070291</td>\n      <td>0.043544</td>\n      <td>0.078133</td>\n      <td>0.032731</td>\n      <td>0.009685</td>\n      <td>-0.019258</td>\n      <td>...</td>\n      <td>0.301428</td>\n      <td>0.154375</td>\n      <td>-0.085936</td>\n      <td>-0.131212</td>\n      <td>-0.053772</td>\n      <td>-0.368802</td>\n      <td>0.176991</td>\n      <td>0.233453</td>\n      <td>1.000000</td>\n      <td>0.371065</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.124267</td>\n      <td>-0.066128</td>\n      <td>-0.044854</td>\n      <td>-0.043279</td>\n      <td>-0.028559</td>\n      <td>0.051793</td>\n      <td>-0.022612</td>\n      <td>-0.002994</td>\n      <td>0.010071</td>\n      <td>-0.004850</td>\n      <td>...</td>\n      <td>0.273929</td>\n      <td>0.119418</td>\n      <td>0.205876</td>\n      <td>0.195965</td>\n      <td>0.020836</td>\n      <td>-0.228329</td>\n      <td>-0.125499</td>\n      <td>-0.128832</td>\n      <td>0.371065</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_188', 'fft_229', 'fft_207', 'fft_212', 'fft_199', 'mfw_9', 'fft_171', 'fft_153', 'fft_155', 'fft_192', 'fft_147', 'fft_246', 'fft_215', 'fft_186', 'fft_185', 'fft_195', 'fft_249', 'fft_181', 'fft_189', 'fft_227', 'fft_134', 'mfw_15', 'fft_240', 'fft_235', 'fft_255', 'fft_164', 'fft_167', 'fft_256', 'fft_248', 'fft_233', 'fft_160', 'fft_178', 'fft_250', 'fft_169', 'fft_163', 'fft_190', 'fft_202', 'fft_175', 'fft_183', 'fft_173', 'fft_146', 'fft_151', 'fft_133', 'fft_154', 'fft_137', 'fft_132', 'fft_140', 'fft_223', 'fft_217', 'mfw_5', 'fft_245', 'fft_168', 'fft_216', 'fft_177', 'fft_222', 'fft_221', 'fft_152', 'fft_211', 'fft_209', 'mfw_13', 'fft_193', 'mfw_11', 'fft_172', 'fft_170', 'fft_236', 'fft_243', 'fft_180', 'fft_130', 'fft_150', 'fft_158', 'fft_176', 'fft_187', 'fft_231', 'cfr_16', 'fft_203', 'fft_184', 'fft_135', 'fft_253', 'mfw_14', 'fft_237', 'fft_157', 'mfw_10', 'fft_241', 'fft_162', 'fft_198', 'fft_148', 'fft_225', 'fft_174', 'mfw_16', 'fft_244', 'fft_224', 'mfw_6', 'fft_194', 'fft_201', 'fft_218', 'fft_214', 'fft_213', 'fft_196', 'fft_254', 'fft_141', 'fft_219', 'fft_138', 'fft_191', 'fft_210', 'fft_230', 'fft_228', 'fft_251', 'fft_143', 'fft_242', 'mfw_7', 'fft_204', 'fft_238', 'fft_159', 'fft_232', 'fft_247', 'fft_131', 'fft_179', 'fft_139', 'fft_197', 'fft_161', 'fft_239', 'fft_144', 'fft_145', 'fft_234', 'mfw_12', 'mfw_8', 'fft_206', 'fft_226', 'fft_142', 'fft_149', 'fft_136', 'fft_205', 'fft_166', 'fft_220', 'fft_208', 'fft_165', 'fft_200', 'fft_252', 'fft_182', 'fft_156'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_19\n",
      "fft_20\n",
      "fft_22\n",
      "fft_30\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_37\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_13\n",
      "ar_14\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 66\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         dw_1        dw_2        dw_3       dw_4       dw_5     mfw_1  \\\n0  267.535629  270.981533  270.243834  76.791207  11.207306  0.483334   \n1  277.949875  283.546637  283.543383  80.370321  11.621628  0.480582   \n2  280.952321  289.729213  288.768479  81.676148  11.842770  0.479468   \n3  266.093352  277.366979  279.066959  79.365536  11.515873  0.479998   \n4  279.838160  290.933842  289.849559  81.839924  11.791220  0.479852   \n\n      mfw_2     mfw_3     mfw_4      fft_1  ...     cfr_6     cfr_7     cfr_8  \\\n0 -0.435149 -0.637676 -0.096703  -1.065012  ...  0.016873  0.040724 -0.047331   \n1 -0.437337 -0.666380 -0.138188  -2.207264  ...  0.011581  0.052652 -0.053865   \n2 -0.434101 -0.641674 -0.075015  -0.855778  ...  0.031430  0.033720 -0.041838   \n3 -0.433339 -0.648197 -0.093792  -1.105237  ...  0.018259  0.048839 -0.047719   \n4 -0.432266 -0.660649 -0.107788  14.855103  ...  0.015173  0.050778 -0.050448   \n\n      cfr_9    cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0  0.034527 -0.042788  0.048729 -0.072291  0.006842 -0.025811 -0.008343  \n1  0.034099 -0.034026  0.038144 -0.071427  0.011442 -0.027634 -0.009450  \n2  0.031072 -0.035728  0.040951 -0.067828  0.007170 -0.022649 -0.013308  \n3  0.029625 -0.035988  0.049478 -0.081219  0.019213 -0.029185 -0.014198  \n4  0.030725 -0.035125  0.042994 -0.070263  0.010677 -0.027446 -0.011952  \n\n[5 rows x 66 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>267.535629</td>\n      <td>270.981533</td>\n      <td>270.243834</td>\n      <td>76.791207</td>\n      <td>11.207306</td>\n      <td>0.483334</td>\n      <td>-0.435149</td>\n      <td>-0.637676</td>\n      <td>-0.096703</td>\n      <td>-1.065012</td>\n      <td>...</td>\n      <td>0.016873</td>\n      <td>0.040724</td>\n      <td>-0.047331</td>\n      <td>0.034527</td>\n      <td>-0.042788</td>\n      <td>0.048729</td>\n      <td>-0.072291</td>\n      <td>0.006842</td>\n      <td>-0.025811</td>\n      <td>-0.008343</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>277.949875</td>\n      <td>283.546637</td>\n      <td>283.543383</td>\n      <td>80.370321</td>\n      <td>11.621628</td>\n      <td>0.480582</td>\n      <td>-0.437337</td>\n      <td>-0.666380</td>\n      <td>-0.138188</td>\n      <td>-2.207264</td>\n      <td>...</td>\n      <td>0.011581</td>\n      <td>0.052652</td>\n      <td>-0.053865</td>\n      <td>0.034099</td>\n      <td>-0.034026</td>\n      <td>0.038144</td>\n      <td>-0.071427</td>\n      <td>0.011442</td>\n      <td>-0.027634</td>\n      <td>-0.009450</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>280.952321</td>\n      <td>289.729213</td>\n      <td>288.768479</td>\n      <td>81.676148</td>\n      <td>11.842770</td>\n      <td>0.479468</td>\n      <td>-0.434101</td>\n      <td>-0.641674</td>\n      <td>-0.075015</td>\n      <td>-0.855778</td>\n      <td>...</td>\n      <td>0.031430</td>\n      <td>0.033720</td>\n      <td>-0.041838</td>\n      <td>0.031072</td>\n      <td>-0.035728</td>\n      <td>0.040951</td>\n      <td>-0.067828</td>\n      <td>0.007170</td>\n      <td>-0.022649</td>\n      <td>-0.013308</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>266.093352</td>\n      <td>277.366979</td>\n      <td>279.066959</td>\n      <td>79.365536</td>\n      <td>11.515873</td>\n      <td>0.479998</td>\n      <td>-0.433339</td>\n      <td>-0.648197</td>\n      <td>-0.093792</td>\n      <td>-1.105237</td>\n      <td>...</td>\n      <td>0.018259</td>\n      <td>0.048839</td>\n      <td>-0.047719</td>\n      <td>0.029625</td>\n      <td>-0.035988</td>\n      <td>0.049478</td>\n      <td>-0.081219</td>\n      <td>0.019213</td>\n      <td>-0.029185</td>\n      <td>-0.014198</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>279.838160</td>\n      <td>290.933842</td>\n      <td>289.849559</td>\n      <td>81.839924</td>\n      <td>11.791220</td>\n      <td>0.479852</td>\n      <td>-0.432266</td>\n      <td>-0.660649</td>\n      <td>-0.107788</td>\n      <td>14.855103</td>\n      <td>...</td>\n      <td>0.015173</td>\n      <td>0.050778</td>\n      <td>-0.050448</td>\n      <td>0.030725</td>\n      <td>-0.035125</td>\n      <td>0.042994</td>\n      <td>-0.070263</td>\n      <td>0.010677</td>\n      <td>-0.027446</td>\n      <td>-0.011952</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 66 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 1.858999490737915 s\n",
      "Accuracy 0.9190615835777126 precision 0.9195511815906906 specificity 0.8508030780764226 recall 0.9190615835777126 f1 0.9192912774724769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 1.7659997940063477 s\n",
      "Accuracy 0.9196480938416423 precision 0.919852711354313 specificity 0.8639447366893213 recall 0.9196480938416423 f1 0.9197467851734374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 1.7600007057189941 s\n",
      "Accuracy 0.92316715542522 precision 0.9225986714697995 specificity 0.850531674869902 recall 0.92316715542522 f1 0.9228484638891308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 1.6985526084899902 s\n",
      "Accuracy 0.9155425219941349 precision 0.9177279709537773 specificity 0.8545654127933825 recall 0.9155425219941349 f1 0.9164355458865158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 1.7620000839233398 s\n",
      "Accuracy 0.9126099706744868 precision 0.9143826020609386 specificity 0.8541371448202736 recall 0.9126099706744868 f1 0.9133512883390836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 1.7169997692108154 s\n",
      "Accuracy 0.9272727272727272 precision 0.9277300942180298 specificity 0.8633843598433475 recall 0.9272727272727272 f1 0.9274858515307954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 1.7545089721679688 s\n",
      "Accuracy 0.9219941348973607 precision 0.9216963105348037 specificity 0.8632060450396613 recall 0.9219941348973607 f1 0.9218350766002014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 1.768359899520874 s\n",
      "Accuracy 0.9214076246334311 precision 0.9223562017425738 specificity 0.8666688109715217 recall 0.9214076246334311 f1 0.9218229013812935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 1.7469995021820068 s\n",
      "Accuracy 0.9290322580645162 precision 0.9298248671363244 specificity 0.8794275914443954 recall 0.9290322580645162 f1 0.9293780422458756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 1.7489993572235107 s\n",
      "Accuracy 0.9202346041055719 precision 0.9197149726572673 specificity 0.8486319530497088 recall 0.9202346041055719 f1 0.91994800548279\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 1.7240302562713623 s\n",
      "Accuracy 0.9219941348973607 precision 0.9220624450424234 specificity 0.8616648689340569 recall 0.9219941348973607 f1 0.922027878317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 1.7470283508300781 s\n",
      "Accuracy 0.9243401759530792 precision 0.9233672967362194 specificity 0.8436251920122887 recall 0.9243401759530792 f1 0.9237281572896198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 1.686000108718872 s\n",
      "Accuracy 0.9149560117302052 precision 0.9139051245549622 specificity 0.8244211089581437 recall 0.9149560117302052 f1 0.9143342197301987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 1.6961188316345215 s\n",
      "Accuracy 0.9319648093841643 precision 0.9324602730853516 specificity 0.889016726743904 recall 0.9319648093841643 f1 0.9321863388994699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 1.7569994926452637 s\n",
      "Accuracy 0.9243401759530792 precision 0.9238073481354416 specificity 0.8571828125526679 recall 0.9243401759530792 f1 0.9240397468161005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 1.8040008544921875 s\n",
      "Accuracy 0.9302052785923753 precision 0.9302699554044257 specificity 0.8714559736516313 recall 0.9302052785923753 f1 0.9302371902134705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 1.841045618057251 s\n",
      "Accuracy 0.9219941348973607 precision 0.9219280004082011 specificity 0.8610615191260351 recall 0.9219941348973607 f1 0.9219606563844234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 1.7569992542266846 s\n",
      "Accuracy 0.9079178885630499 precision 0.9067828353186864 specificity 0.8239087913005814 recall 0.9079178885630499 f1 0.9072326737217593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 1.7170286178588867 s\n",
      "Accuracy 0.9260997067448681 precision 0.9269998586815339 specificity 0.8752749642115519 recall 0.9260997067448681 f1 0.9264901908510672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 1.7805094718933105 s\n",
      "Accuracy 0.9114369501466275 precision 0.9105748136374829 specificity 0.8334748235936881 recall 0.9114369501466275 f1 0.910936949618788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 1.7815089225769043 s\n",
      "Accuracy 0.9161290322580645 precision 0.9151412980047419 specificity 0.8316674279881996 recall 0.9161290322580645 f1 0.915539906119063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 1.7419986724853516 s\n",
      "Accuracy 0.9260997067448681 precision 0.9263907325190409 specificity 0.8635419642080313 recall 0.9260997067448681 f1 0.9262384073945723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 1.7370002269744873 s\n",
      "Accuracy 0.9278592375366569 precision 0.9282010075868968 specificity 0.872539381311319 recall 0.9278592375366569 f1 0.9280196434560004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 1.6899998188018799 s\n",
      "Accuracy 0.9266862170087976 precision 0.9265012056542159 specificity 0.8662052766564527 recall 0.9266862170087976 f1 0.9265899429115764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 1.8720288276672363 s\n",
      "Accuracy 0.9196480938416423 precision 0.9201906942462402 specificity 0.858545544276516 recall 0.9196480938416423 f1 0.919899214873203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 1.9889979362487793 s\n",
      "Accuracy 0.910850439882698 precision 0.9097942201168007 specificity 0.8359418431561413 recall 0.910850439882698 f1 0.9101921688741869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 1.7701747417449951 s\n",
      "Accuracy 0.9096774193548387 precision 0.9087323069249602 specificity 0.8290690193916 recall 0.9096774193548387 f1 0.9091249990853147\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 1.8350000381469727 s\n",
      "Accuracy 0.9167155425219942 precision 0.9156777390644023 specificity 0.8313503940430778 recall 0.9167155425219942 f1 0.9160877860521885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 1.7635102272033691 s\n",
      "Accuracy 0.9249266862170088 precision 0.9243060211533655 specificity 0.8632704603458966 recall 0.9249266862170088 f1 0.9245571305631078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 1.7323739528656006 s\n",
      "Accuracy 0.9178885630498533 precision 0.9180347524185123 specificity 0.8544217259621538 recall 0.9178885630498533 f1 0.9179600233557806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 1.8135018348693848 s\n",
      "Accuracy 0.9190615835777126 precision 0.9187896923649009 specificity 0.8512840235704997 recall 0.9190615835777126 f1 0.9189190258881478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 1.803999423980713 s\n",
      "Accuracy 0.9196480938416423 precision 0.9189689667624169 specificity 0.8475003693561914 recall 0.9196480938416423 f1 0.9192581311289575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 1.7085707187652588 s\n",
      "Accuracy 0.9173020527859238 precision 0.9166026866657381 specificity 0.8437583398021719 recall 0.9173020527859238 f1 0.9169022872570861\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 1.7239995002746582 s\n",
      "Accuracy 0.92316715542522 precision 0.9218286034716717 specificity 0.8377920912570155 recall 0.92316715542522 f1 0.9219712836525531\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 1.7210206985473633 s\n",
      "Accuracy 0.9313782991202346 precision 0.9308253954422829 specificity 0.8698277787525099 recall 0.9313782991202346 f1 0.9310504842046313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 1.7450006008148193 s\n",
      "Accuracy 0.9266862170087976 precision 0.9279326148580859 specificity 0.8711331318913054 recall 0.9266862170087976 f1 0.9272136995487615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 1.7049131393432617 s\n",
      "Accuracy 0.9173020527859238 precision 0.9168317230517806 specificity 0.8459326035332816 recall 0.9173020527859238 f1 0.9170466492043579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 1.7029991149902344 s\n",
      "Accuracy 0.9202346041055719 precision 0.9193166357220893 specificity 0.8446630870243503 recall 0.9202346041055719 f1 0.9196681758120988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 1.721001148223877 s\n",
      "Accuracy 0.92316715542522 precision 0.9226083424813691 specificity 0.8522218937896997 recall 0.92316715542522 f1 0.9228534908159525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 1.7599990367889404 s\n",
      "Accuracy 0.9278592375366569 precision 0.9272509687457676 specificity 0.8605615637328029 recall 0.9278592375366569 f1 0.9275035386552095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 1.7341225147247314 s\n",
      "Accuracy 0.9249266862170088 precision 0.9239040293760614 specificity 0.8516332930246343 recall 0.9249266862170088 f1 0.924210829091808\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 1.7539989948272705 s\n",
      "Accuracy 0.92316715542522 precision 0.9228631287169777 specificity 0.8619625647595124 recall 0.92316715542522 f1 0.923004855142699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 1.6520006656646729 s\n",
      "Accuracy 0.918475073313783 precision 0.9176910202540991 specificity 0.8454090672370242 recall 0.918475073313783 f1 0.9180129882970155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 1.6870307922363281 s\n",
      "Accuracy 0.9237536656891495 precision 0.9236216481000296 specificity 0.8603027648838527 recall 0.9237536656891495 f1 0.9236859858379074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 1.7070519924163818 s\n",
      "Accuracy 0.9290322580645162 precision 0.9284384323192585 specificity 0.8630574944470853 recall 0.9290322580645162 f1 0.9286837261635699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 1.7419993877410889 s\n",
      "Accuracy 0.9131964809384164 precision 0.9130642557886341 specificity 0.8544046431915904 recall 0.9131964809384164 f1 0.9131287981616818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 1.7400002479553223 s\n",
      "Accuracy 0.9102639296187683 precision 0.909316838878103 specificity 0.834283125343337 recall 0.9102639296187683 f1 0.9096997119281317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 1.7465105056762695 s\n",
      "Accuracy 0.918475073313783 precision 0.9190066532432124 specificity 0.8598426822582623 recall 0.918475073313783 f1 0.9187209619272521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 1.6929988861083984 s\n",
      "Accuracy 0.9225806451612903 precision 0.9220886792178484 specificity 0.8549097762946484 recall 0.9225806451612903 f1 0.9223079261029924\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 1.745999813079834 s\n",
      "Accuracy 0.9278592375366569 precision 0.928474375567787 specificity 0.8796973769351133 recall 0.9278592375366569 f1 0.9281335374034515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 1.7395131587982178 s\n",
      "Accuracy 0.9325513196480938 precision 0.9323696260381735 specificity 0.8706703762437591 recall 0.9325513196480938 f1 0.9324565650942683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 1.7634589672088623 s\n",
      "Accuracy 0.9155425219941349 precision 0.9155425219941349 specificity 0.8484649676345748 recall 0.9155425219941349 f1 0.9155425219941349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 1.730144739151001 s\n",
      "Accuracy 0.9243401759530792 precision 0.9246802776385814 specificity 0.8706956304715294 recall 0.9243401759530792 f1 0.9244999983686913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 1.6851813793182373 s\n",
      "Accuracy 0.9196480938416423 precision 0.9195791243477642 specificity 0.8557446264648711 recall 0.9196480938416423 f1 0.9196131982367957\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 1.6134519577026367 s\n",
      "Accuracy 0.9096774193548387 precision 0.9103676793128898 specificity 0.8419779777652958 recall 0.9096774193548387 f1 0.9099968518074055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 1.753509283065796 s\n",
      "Accuracy 0.9126099706744868 precision 0.9128317758219657 specificity 0.85181105197186 recall 0.9126099706744868 f1 0.9127173065024977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 1.7330000400543213 s\n",
      "Accuracy 0.9214076246334311 precision 0.9223358823968316 specificity 0.8687842096760503 recall 0.9214076246334311 f1 0.9218131854529251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 1.7039995193481445 s\n",
      "Accuracy 0.9073313782991203 precision 0.9095936321742774 specificity 0.8432321078015559 recall 0.9073313782991203 f1 0.908269096494903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 1.6999998092651367 s\n",
      "Accuracy 0.9202346041055719 precision 0.9189916694399586 specificity 0.8373193637355616 recall 0.9202346041055719 f1 0.9193679615336964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 1.7359988689422607 s\n",
      "Accuracy 0.9243401759530792 precision 0.925836756921801 specificity 0.8811536504966592 recall 0.9243401759530792 f1 0.9249427456958902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 1.714000940322876 s\n",
      "Accuracy 0.9155425219941349 precision 0.9156939521508621 specificity 0.8493967870628213 recall 0.9155425219941349 f1 0.9156166066451329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 1.7609984874725342 s\n",
      "Accuracy 0.9173020527859238 precision 0.916643779955608 specificity 0.8495789521672301 recall 0.9173020527859238 f1 0.9169237282814218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 1.7880029678344727 s\n",
      "Accuracy 0.92316715542522 precision 0.9232371440929441 specificity 0.8599760638396723 recall 0.92316715542522 f1 0.9232017316253724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 1.7115075588226318 s\n",
      "Accuracy 0.9155425219941349 precision 0.9164277313865945 specificity 0.8465855100138672 recall 0.9155425219941349 f1 0.9159435910993866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 1.7319722175598145 s\n",
      "Accuracy 0.9284457478005865 precision 0.9285771602427357 specificity 0.8709173963055769 recall 0.9284457478005865 f1 0.9285097675970058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 1.6870007514953613 s\n",
      "Accuracy 0.9302052785923753 precision 0.9306827983126068 specificity 0.8779635120874912 recall 0.9302052785923753 f1 0.9304234056197893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 1.7169983386993408 s\n",
      "Accuracy 0.9278592375366569 precision 0.9276802507836991 specificity 0.8697302697302696 recall 0.9278592375366569 f1 0.927765986870295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 1.6745595932006836 s\n",
      "Accuracy 0.9214076246334311 precision 0.9226743597180785 specificity 0.8732954423755922 recall 0.9214076246334311 f1 0.9219378359693486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 1.7280454635620117 s\n",
      "Accuracy 0.9161290322580645 precision 0.9157936063243035 specificity 0.8492987271263369 recall 0.9161290322580645 f1 0.9159511666245469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 1.7350008487701416 s\n",
      "Accuracy 0.9266862170087976 precision 0.9259263006127813 specificity 0.8507970645133837 recall 0.9266862170087976 f1 0.9262327148071919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 1.7359991073608398 s\n",
      "Accuracy 0.9137829912023461 precision 0.9143467008191255 specificity 0.8506258026182125 recall 0.9137829912023461 f1 0.9140450903073623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 1.742999792098999 s\n",
      "Accuracy 0.9202346041055719 precision 0.9214945198728304 specificity 0.8728339417959053 recall 0.9202346041055719 f1 0.9207622647261127\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 1.710052728652954 s\n",
      "Accuracy 0.9202346041055719 precision 0.9206722702622101 specificity 0.8632227800414226 recall 0.9202346041055719 f1 0.9204387965017027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 1.7275078296661377 s\n",
      "Accuracy 0.9149560117302052 precision 0.9153339377572265 specificity 0.8545121744046474 recall 0.9149560117302052 f1 0.9151349522353299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 1.7433326244354248 s\n",
      "Accuracy 0.918475073313783 precision 0.9186786274120865 specificity 0.8636784456818413 recall 0.918475073313783 f1 0.9185732629217793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 1.6221833229064941 s\n",
      "Accuracy 0.930791788856305 precision 0.931787355019997 specificity 0.8871809621341289 recall 0.930791788856305 f1 0.9312084471111584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 1.726999282836914 s\n",
      "Accuracy 0.9225806451612903 precision 0.9240122147923817 specificity 0.8771349531760538 recall 0.9225806451612903 f1 0.9231659251608222\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 1.7109994888305664 s\n",
      "Accuracy 0.9155425219941349 precision 0.9143712297466993 specificity 0.8333644849773882 recall 0.9155425219941349 f1 0.9147898647619369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 1.7169983386993408 s\n",
      "Accuracy 0.9114369501466275 precision 0.9113583711459243 specificity 0.8375644021079072 recall 0.9114369501466275 f1 0.9113972527843965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 1.743999719619751 s\n",
      "Accuracy 0.9225806451612903 precision 0.922082385717033 specificity 0.8536963250818944 recall 0.9225806451612903 f1 0.9223046708428178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 1.7209994792938232 s\n",
      "Accuracy 0.9114369501466275 precision 0.9109213634167935 specificity 0.8336012177923038 recall 0.9114369501466275 f1 0.9111590686110106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 1.7089993953704834 s\n",
      "Accuracy 0.9237536656891495 precision 0.9256911026516301 specificity 0.8751034771679932 recall 0.9237536656891495 f1 0.9245221432697396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 1.7500004768371582 s\n",
      "Accuracy 0.9214076246334311 precision 0.9202601435135505 specificity 0.8469300614030726 recall 0.9214076246334311 f1 0.9205527762751651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 1.7150003910064697 s\n",
      "Accuracy 0.9208211143695014 precision 0.919060870188205 specificity 0.813759310559449 recall 0.9208211143695014 f1 0.9193856535976653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 1.7895090579986572 s\n",
      "Accuracy 0.9120234604105572 precision 0.9125249496388362 specificity 0.8436160485790584 recall 0.9120234604105572 f1 0.9122595990039071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 1.662811040878296 s\n",
      "Accuracy 0.9120234604105572 precision 0.9113305259097741 specificity 0.8347943111115578 recall 0.9120234604105572 f1 0.9116360753845659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 1.6720404624938965 s\n",
      "Accuracy 0.918475073313783 precision 0.9191167059252812 specificity 0.86917547328618 recall 0.918475073313783 f1 0.9187639346542905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 1.7499980926513672 s\n",
      "Accuracy 0.9243401759530792 precision 0.9248519295272355 specificity 0.8675385410206948 recall 0.9243401759530792 f1 0.9245756987907494\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 1.7200005054473877 s\n",
      "Accuracy 0.9325513196480938 precision 0.9321449652462365 specificity 0.8661676475813004 recall 0.9325513196480938 f1 0.9323266616343752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 1.737999677658081 s\n",
      "Accuracy 0.9260997067448681 precision 0.9249194996696387 specificity 0.8446899723314623 recall 0.9260997067448681 f1 0.9252159424153559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 1.7210009098052979 s\n",
      "Accuracy 0.918475073313783 precision 0.9188715891898895 specificity 0.8517104878216659 recall 0.918475073313783 f1 0.9186629364330213\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 1.6760401725769043 s\n",
      "Accuracy 0.9208211143695014 precision 0.921534715734713 specificity 0.860612222118008 recall 0.9208211143695014 f1 0.9211443565240901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 1.7080001831054688 s\n",
      "Accuracy 0.9249266862170088 precision 0.9252278699495821 specificity 0.8593039250913506 recall 0.9249266862170088 f1 0.9250704356198413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 1.7169995307922363 s\n",
      "Accuracy 0.9249266862170088 precision 0.9260061435975413 specificity 0.8752597770917613 recall 0.9249266862170088 f1 0.925385840726743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 1.7329988479614258 s\n",
      "Accuracy 0.9225806451612903 precision 0.9212115449915111 specificity 0.8359455114966142 recall 0.9225806451612903 f1 0.9213387607281638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 1.7069997787475586 s\n",
      "Accuracy 0.9266862170087976 precision 0.9266215944023126 specificity 0.8657523419187764 recall 0.9266862170087976 f1 0.9266534848618269\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 1.6430001258850098 s\n",
      "Accuracy 0.9255131964809384 precision 0.9248536162600289 specificity 0.8630988807079547 recall 0.9255131964809384 f1 0.9251136283279542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 1.6685104370117188 s\n",
      "Accuracy 0.9167155425219942 precision 0.9171591962967796 specificity 0.859563049099697 recall 0.9167155425219942 f1 0.9169229573618306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 1.7371137142181396 s\n",
      "Accuracy 0.9149560117302052 precision 0.9144014882787529 specificity 0.8495787538702645 recall 0.9149560117302052 f1 0.914646311397363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 1.7580008506774902 s\n",
      "Accuracy 0.9260997067448681 precision 0.9277302327250049 specificity 0.8812496354715229 recall 0.9260997067448681 f1 0.9267505135885332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 1.7320005893707275 s\n",
      "Accuracy 0.9208211143695014 precision 0.9204815223876807 specificity 0.8502620483486422 recall 0.9208211143695014 f1 0.9206408208917849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 1.7347455024719238 s\n",
      "Accuracy 0.9260997067448681 precision 0.9256598613019784 specificity 0.8663635374915214 recall 0.9260997067448681 f1 0.9258533492365121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 1.714017391204834 s\n",
      "Accuracy 0.9178885630498533 precision 0.9188592852787352 specificity 0.8617038742340427 recall 0.9178885630498533 f1 0.918315636902956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 1.7230010032653809 s\n",
      "Accuracy 0.930791788856305 precision 0.9299615271315117 specificity 0.856121928655681 recall 0.930791788856305 f1 0.930263832904622\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 1.7159984111785889 s\n",
      "Accuracy 0.9260997067448681 precision 0.9256893766044431 specificity 0.8496758777889682 recall 0.9260997067448681 f1 0.9258787311184407\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 1.7109999656677246 s\n",
      "Accuracy 0.9143695014662757 precision 0.914225451429986 specificity 0.8467081305790983 recall 0.9143695014662757 f1 0.9142958548498005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 1.6846294403076172 s\n",
      "Accuracy 0.9208211143695014 precision 0.9213687240842888 specificity 0.8583705526592507 recall 0.9208211143695014 f1 0.9210745301840804\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 1.6329877376556396 s\n",
      "Accuracy 0.9243401759530792 precision 0.9240311391596538 specificity 0.861031517512643 recall 0.9243401759530792 f1 0.9241752369183172\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 1.7219984531402588 s\n",
      "Accuracy 0.9237536656891495 precision 0.9232721415996591 specificity 0.857397367770147 recall 0.9237536656891495 f1 0.9234861377827676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 1.7260005474090576 s\n",
      "Accuracy 0.9155425219941349 precision 0.9140043178923672 specificity 0.8273639877658352 recall 0.9155425219941349 f1 0.9142880462800397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 1.7095088958740234 s\n",
      "Accuracy 0.92316715542522 precision 0.9223872941457406 specificity 0.8473505398073042 recall 0.92316715542522 f1 0.9227049866762306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 1.7430007457733154 s\n",
      "Accuracy 0.9155425219941349 precision 0.9146573935558986 specificity 0.8466249577343794 recall 0.9155425219941349 f1 0.9149968105671146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 1.7360444068908691 s\n",
      "Accuracy 0.9296187683284457 precision 0.928689572941328 specificity 0.8597647611187126 recall 0.9296187683284457 f1 0.9289476522735699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 1.7360014915466309 s\n",
      "Accuracy 0.9243401759530792 precision 0.9235287022349935 specificity 0.8532209725758112 recall 0.9243401759530792 f1 0.9238394607247814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 1.7135112285614014 s\n",
      "Accuracy 0.9278592375366569 precision 0.9281997127107652 specificity 0.8728872225096617 recall 0.9278592375366569 f1 0.9280190100922814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 1.7599999904632568 s\n",
      "Accuracy 0.9178885630498533 precision 0.9178885630498533 specificity 0.854259904130744 recall 0.9178885630498533 f1 0.9178885630498533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 1.6214392185211182 s\n",
      "Accuracy 0.9178885630498533 precision 0.9166856498629607 specificity 0.836266656469024 recall 0.9178885630498533 f1 0.9170836379543086\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 1.648228406906128 s\n",
      "Accuracy 0.9219941348973607 precision 0.922866507306735 specificity 0.8650188521156263 recall 0.9219941348973607 f1 0.9223802797891412\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 1.7153213024139404 s\n",
      "Accuracy 0.9290322580645162 precision 0.9290954726295098 specificity 0.8728521320551682 recall 0.9290322580645162 f1 0.9290634454461986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 1.7639529705047607 s\n",
      "Accuracy 0.9196480938416423 precision 0.9195838720728486 specificity 0.8624440829873767 recall 0.9196480938416423 f1 0.9196155812396504\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 1.7210016250610352 s\n",
      "Accuracy 0.9278592375366569 precision 0.9292038494650444 specificity 0.8804872540559081 recall 0.9278592375366569 f1 0.9284111370368024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 1.687042236328125 s\n",
      "Accuracy 0.9225806451612903 precision 0.9230244483823922 specificity 0.8634094104105143 recall 0.9225806451612903 f1 0.9227876259001448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 1.7240166664123535 s\n",
      "Accuracy 0.9143695014662757 precision 0.9143695014662757 specificity 0.8459410077812151 recall 0.9143695014662757 f1 0.9143695014662757\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 1.7250206470489502 s\n",
      "Accuracy 0.9219941348973607 precision 0.9235820347020057 specificity 0.8582265433130756 recall 0.9219941348973607 f1 0.9226644541652375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 1.7500200271606445 s\n",
      "Accuracy 0.9284457478005865 precision 0.9285692585873988 specificity 0.8763683112507608 recall 0.9284457478005865 f1 0.9285058523123229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 1.7249867916107178 s\n",
      "Accuracy 0.9219941348973607 precision 0.9234255200543743 specificity 0.8694840619660269 recall 0.9219941348973607 f1 0.9225909042755668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 1.6959989070892334 s\n",
      "Accuracy 0.9225806451612903 precision 0.9223148012774042 specificity 0.8552066312115589 recall 0.9225806451612903 f1 0.9224410080291349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 1.706954002380371 s\n",
      "Accuracy 0.9260997067448681 precision 0.9255999950797851 specificity 0.8547579925990634 recall 0.9260997067448681 f1 0.9258223054454595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 1.7153611183166504 s\n",
      "Accuracy 0.9167155425219942 precision 0.9167155425219942 specificity 0.8575299220599716 recall 0.9167155425219942 f1 0.9167155425219942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 1.7140002250671387 s\n",
      "Accuracy 0.9325513196480938 precision 0.9317194920250226 specificity 0.8639439476837046 recall 0.9325513196480938 f1 0.9319791617190426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 1.7135097980499268 s\n",
      "Accuracy 0.9442815249266863 precision 0.9443331520072731 specificity 0.8978526302610739 recall 0.9442815249266863 f1 0.9443068995642907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 1.7475097179412842 s\n",
      "Accuracy 0.9202346041055719 precision 0.9199533963256308 specificity 0.8483803381296748 recall 0.9202346041055719 f1 0.92008726430627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 1.7339997291564941 s\n",
      "Accuracy 0.9249266862170088 precision 0.9256036561804639 specificity 0.8543600839234199 recall 0.9249266862170088 f1 0.925237144236626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 1.7130002975463867 s\n",
      "Accuracy 0.9255131964809384 precision 0.9258496571685377 specificity 0.8724307950114403 recall 0.9255131964809384 f1 0.9256711610645519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 1.698000192642212 s\n",
      "Accuracy 0.9149560117302052 precision 0.9142846223630902 specificity 0.8295951371624475 recall 0.9149560117302052 f1 0.9145859246915858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 1.7509987354278564 s\n",
      "Accuracy 0.9161290322580645 precision 0.9154180757523986 specificity 0.841676338432611 recall 0.9161290322580645 f1 0.9157235962961939\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 1.7539994716644287 s\n",
      "Accuracy 0.9249266862170088 precision 0.9236557081854195 specificity 0.8385551480969914 recall 0.9249266862170088 f1 0.9235991747258225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 1.6469993591308594 s\n",
      "Accuracy 0.9260997067448681 precision 0.9259713549214849 specificity 0.8641716016297984 recall 0.9260997067448681 f1 0.9260338492370507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 1.6449997425079346 s\n",
      "Accuracy 0.9260997067448681 precision 0.9255453572169116 specificity 0.8617628779640971 recall 0.9260997067448681 f1 0.9257806617346492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 1.7019987106323242 s\n",
      "Accuracy 0.9284457478005865 precision 0.92950940523609 specificity 0.8794530977709502 recall 0.9284457478005865 f1 0.9288956654914977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 1.7269995212554932 s\n",
      "Accuracy 0.9260997067448681 precision 0.925852805015592 specificity 0.8639119429342851 recall 0.9260997067448681 f1 0.925969545376135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 1.7139999866485596 s\n",
      "Accuracy 0.9155425219941349 precision 0.9163921506158941 specificity 0.8512776689500393 recall 0.9155425219941349 f1 0.9159263850628647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 1.7230446338653564 s\n",
      "Accuracy 0.9208211143695014 precision 0.9212144143984807 specificity 0.8540542491535562 recall 0.9208211143695014 f1 0.9210072455030694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 1.7169983386993408 s\n",
      "Accuracy 0.9325513196480938 precision 0.9321733044338221 specificity 0.8725118837350782 recall 0.9325513196480938 f1 0.9323413574284655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 1.7209985256195068 s\n",
      "Accuracy 0.9090909090909091 precision 0.9111755094264969 specificity 0.8473454174283112 recall 0.9090909090909091 f1 0.9099568788136961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 1.748342514038086 s\n",
      "Accuracy 0.9120234604105572 precision 0.9116089931573802 specificity 0.8425540957441829 recall 0.9120234604105572 f1 0.9118017634410375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 1.7305552959442139 s\n",
      "Accuracy 0.9255131964809384 precision 0.9250287001253165 specificity 0.8659643318386951 recall 0.9255131964809384 f1 0.9252376553432478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 1.7331557273864746 s\n",
      "Accuracy 0.9178885630498533 precision 0.9192013118285047 specificity 0.8669986166144682 recall 0.9178885630498533 f1 0.9184425151918566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 1.697056531906128 s\n",
      "Accuracy 0.9219941348973607 precision 0.921930570852771 specificity 0.8646946708658009 recall 0.9219941348973607 f1 0.9219619467905484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 1.6579997539520264 s\n",
      "Accuracy 0.92316715542522 precision 0.923532357514894 specificity 0.8632073845455569 recall 0.92316715542522 f1 0.9233393525925134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 1.6880252361297607 s\n",
      "Accuracy 0.9190615835777126 precision 0.9187688730496781 specificity 0.8435302734232805 recall 0.9190615835777126 f1 0.9189084543145365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 1.7629995346069336 s\n",
      "Accuracy 0.9343108504398827 precision 0.9340922058344175 specificity 0.8783090280062615 recall 0.9343108504398827 f1 0.9341946931844038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 1.7309999465942383 s\n",
      "Accuracy 0.9255131964809384 precision 0.9254464657820004 specificity 0.8620900414996994 recall 0.9255131964809384 f1 0.9254794090293887\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 1.7085130214691162 s\n",
      "Accuracy 0.9208211143695014 precision 0.9201957429269257 specificity 0.8555988146154003 recall 0.9208211143695014 f1 0.9204588887800846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 1.742999792098999 s\n",
      "Accuracy 0.9225806451612903 precision 0.9218893257128417 specificity 0.8530831625722886 recall 0.9225806451612903 f1 0.922174785371436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 1.755070686340332 s\n",
      "Accuracy 0.9255131964809384 precision 0.9253354373102604 specificity 0.8691141995265279 recall 0.9255131964809384 f1 0.9254206259161267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 1.7610399723052979 s\n",
      "Accuracy 0.9155425219941349 precision 0.9149302017555296 specificity 0.8485870615139585 recall 0.9155425219941349 f1 0.9151960635686028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 1.7240023612976074 s\n",
      "Accuracy 0.9049853372434018 precision 0.906789629243374 specificity 0.8530290844122821 recall 0.9049853372434018 f1 0.9057349318811259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 1.748999834060669 s\n",
      "Accuracy 0.9173020527859238 precision 0.9166146870126995 specificity 0.8454673378404391 recall 0.9173020527859238 f1 0.9169085486967478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 1.6110098361968994 s\n",
      "Accuracy 0.9208211143695014 precision 0.9215674719457102 specificity 0.8558105435449772 recall 0.9208211143695014 f1 0.9211601944771637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 1.7260005474090576 s\n",
      "Accuracy 0.9202346041055719 precision 0.920704874241459 specificity 0.8559424170228329 recall 0.9202346041055719 f1 0.9204547358799557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 1.7580502033233643 s\n",
      "Accuracy 0.9173020527859238 precision 0.9173794168178081 specificity 0.846223817898181 recall 0.9173020527859238 f1 0.9173403180787055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 1.7039976119995117 s\n",
      "Accuracy 0.9114369501466275 precision 0.9101762652009128 specificity 0.8214597500414447 recall 0.9114369501466275 f1 0.9106552379159389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 1.7390000820159912 s\n",
      "Accuracy 0.9260997067448681 precision 0.9260997067448681 specificity 0.8629244008574528 recall 0.9260997067448681 f1 0.9260997067448681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 1.7045090198516846 s\n",
      "Accuracy 0.9278592375366569 precision 0.928631756053531 specificity 0.8807997662947608 recall 0.9278592375366569 f1 0.9281958140431594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 1.7230010032653809 s\n",
      "Accuracy 0.9173020527859238 precision 0.9161383631031724 specificity 0.8370011816080966 recall 0.9173020527859238 f1 0.9165358420412261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 1.6179993152618408 s\n",
      "Accuracy 0.9131964809384164 precision 0.9144376692396714 specificity 0.851818230316381 recall 0.9131964809384164 f1 0.9137379760026922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 1.7249984741210938 s\n",
      "Accuracy 0.9190615835777126 precision 0.918109233495148 specificity 0.8407993123325963 recall 0.9190615835777126 f1 0.9184776464796088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 1.694000482559204 s\n",
      "Accuracy 0.9120234604105572 precision 0.9124713644988787 specificity 0.8554856425784895 recall 0.9120234604105572 f1 0.9122333167914473\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 1.6850659847259521 s\n",
      "Accuracy 0.9243401759530792 precision 0.9241458397878072 specificity 0.860479613398549 recall 0.9243401759530792 f1 0.9242392375940777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 1.6730425357818604 s\n",
      "Accuracy 0.9255131964809384 precision 0.9263304160286471 specificity 0.8739762108585397 recall 0.9255131964809384 f1 0.9258718495844539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 1.7400033473968506 s\n",
      "Accuracy 0.9225806451612903 precision 0.9241811974900689 specificity 0.8797889344158814 recall 0.9225806451612903 f1 0.9232208216494463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 1.767507791519165 s\n",
      "Accuracy 0.9079178885630499 precision 0.909139568643775 specificity 0.8393525146535015 recall 0.9079178885630499 f1 0.9084608821741738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 1.8440327644348145 s\n",
      "Accuracy 0.9137829912023461 precision 0.9138543836397215 specificity 0.8525685993333956 recall 0.9137829912023461 f1 0.9138182895618931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 1.7340328693389893 s\n",
      "Accuracy 0.9319648093841643 precision 0.9314554735588992 specificity 0.8710010419687838 recall 0.9319648093841643 f1 0.931667588830988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 1.9235107898712158 s\n",
      "Accuracy 0.9214076246334311 precision 0.9218627679549837 specificity 0.8601069244641367 recall 0.9214076246334311 f1 0.9216202539028493\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 1.9139997959136963 s\n",
      "Accuracy 0.9178885630498533 precision 0.9183790674997391 specificity 0.8498514560089299 recall 0.9178885630498533 f1 0.9181188098712371\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 1.8610005378723145 s\n",
      "Accuracy 0.9202346041055719 precision 0.9197301272034883 specificity 0.851543496947108 recall 0.9202346041055719 f1 0.9199558317246617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 1.817579984664917 s\n",
      "Accuracy 0.9249266862170088 precision 0.9243570990384397 specificity 0.8589315035988981 recall 0.9249266862170088 f1 0.9246000105327696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 1.7660002708435059 s\n",
      "Accuracy 0.9284457478005865 precision 0.9278500426968636 specificity 0.867827824437881 recall 0.9284457478005865 f1 0.9280879428479742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 1.667999029159546 s\n",
      "Accuracy 0.9202346041055719 precision 0.9227047001307641 specificity 0.8707977772778603 recall 0.9202346041055719 f1 0.9211923128010342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 1.7170429229736328 s\n",
      "Accuracy 0.9173020527859238 precision 0.9171021614215952 specificity 0.8541924360959454 recall 0.9173020527859238 f1 0.9171984674231907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 1.705000638961792 s\n",
      "Accuracy 0.9237536656891495 precision 0.9241863443913796 specificity 0.8666562517688037 recall 0.9237536656891495 f1 0.9239551059026649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 1.7196216583251953 s\n",
      "Accuracy 0.9266862170087976 precision 0.9267470646412972 specificity 0.874755948559593 recall 0.9266862170087976 f1 0.9267162326206575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 1.71751070022583 s\n",
      "Accuracy 0.9190615835777126 precision 0.9181680527894087 specificity 0.8468681050368587 recall 0.9190615835777126 f1 0.9185090629764173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 1.7229995727539062 s\n",
      "Accuracy 0.9219941348973607 precision 0.9216515271663895 specificity 0.8498702197582032 recall 0.9219941348973607 f1 0.9218122194052888\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 1.70499849319458 s\n",
      "Accuracy 0.9202346041055719 precision 0.9192647590580701 specificity 0.8464006722858022 recall 0.9202346041055719 f1 0.9196147452285753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 1.7519989013671875 s\n",
      "Accuracy 0.92316715542522 precision 0.9223507413121889 specificity 0.8589297978793068 recall 0.92316715542522 f1 0.9226407136866874\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 1.7345402240753174 s\n",
      "Accuracy 0.9096774193548387 precision 0.9079621159578696 specificity 0.8178133307794335 recall 0.9096774193548387 f1 0.9083411116339978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 1.7639970779418945 s\n",
      "Accuracy 0.9067448680351906 precision 0.9068214141460733 specificity 0.8412876706053776 recall 0.9067448680351906 f1 0.9067827497653325\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 1.660829782485962 s\n",
      "Accuracy 0.918475073313783 precision 0.917222521939778 specificity 0.8345804822417725 recall 0.918475073313783 f1 0.91762453408068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 1.62099027633667 s\n",
      "Accuracy 0.9243401759530792 precision 0.9233718160798303 specificity 0.8440842466940038 recall 0.9243401759530792 f1 0.9237306020348902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 1.7479991912841797 s\n",
      "Accuracy 0.9102639296187683 precision 0.9099063143149164 specificity 0.8399102864091061 recall 0.9102639296187683 f1 0.9100751165340505\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 1.7140493392944336 s\n",
      "Accuracy 0.9143695014662757 precision 0.9153579121004803 specificity 0.8572206530931704 recall 0.9143695014662757 f1 0.9148061926126442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 1.7289998531341553 s\n",
      "Accuracy 0.9243401759530792 precision 0.9232452541287816 specificity 0.8436615928050665 recall 0.9243401759530792 f1 0.923602058688201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 1.7639994621276855 s\n",
      "Accuracy 0.9120234604105572 precision 0.9134836567792869 specificity 0.851071777684681 recall 0.9120234604105572 f1 0.912650674770722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 1.6839721202850342 s\n",
      "Accuracy 0.9208211143695014 precision 0.9192708440705933 specificity 0.8255323406515778 recall 0.9208211143695014 f1 0.9195678158545475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 1.6214659214019775 s\n",
      "Accuracy 0.9249266862170088 precision 0.925381649284465 specificity 0.8624254262335619 recall 0.9249266862170088 f1 0.925138885587084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 1.5999994277954102 s\n",
      "Accuracy 0.930791788856305 precision 0.9301381177626656 specificity 0.8606324727329819 recall 0.930791788856305 f1 0.9304021060785643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 1.6209995746612549 s\n",
      "Accuracy 0.9266862170087976 precision 0.9256607104926268 specificity 0.8530328357848274 recall 0.9266862170087976 f1 0.925948115596767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 1.556999683380127 s\n",
      "Accuracy 0.9120234604105572 precision 0.91218925746785 specificity 0.8372763977835708 recall 0.9120234604105572 f1 0.9121047139763487\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 1.5980396270751953 s\n",
      "Accuracy 0.9225806451612903 precision 0.9218321946963187 specificity 0.8557793062723513 recall 0.9225806451612903 f1 0.9221254273838767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 1.584010124206543 s\n",
      "Accuracy 0.9372434017595308 precision 0.9368687458932206 specificity 0.8750207491838655 recall 0.9372434017595308 f1 0.9370343721293751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 1.6259994506835938 s\n",
      "Accuracy 0.9167155425219942 precision 0.9170479205183093 specificity 0.8434930574989384 recall 0.9167155425219942 f1 0.9168750145157616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 1.611520528793335 s\n",
      "Accuracy 0.9313782991202346 precision 0.930639214148519 specificity 0.8629939952520598 recall 0.9313782991202346 f1 0.9309113937858288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 1.6708977222442627 s\n",
      "Accuracy 0.9155425219941349 precision 0.9176677094304466 specificity 0.8578181022759404 recall 0.9155425219941349 f1 0.9164074246179104\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 1.638998031616211 s\n",
      "Accuracy 0.9255131964809384 precision 0.9266522527584705 specificity 0.8788327843356306 recall 0.9255131964809384 f1 0.9259908348761567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 1.6345930099487305 s\n",
      "Accuracy 0.9272727272727272 precision 0.9268605443144072 specificity 0.872120655080214 recall 0.9272727272727272 f1 0.9270405118963293\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 1.6389987468719482 s\n",
      "Accuracy 0.9343108504398827 precision 0.9333257815561085 specificity 0.8462924385475527 recall 0.9343108504398827 f1 0.9336660740749334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 1.6362013816833496 s\n",
      "Accuracy 0.9296187683284457 precision 0.9289485801636627 specificity 0.8580435693338919 recall 0.9296187683284457 f1 0.9292208945095549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 1.6408510208129883 s\n",
      "Accuracy 0.9260997067448681 precision 0.9253442223041328 specificity 0.855988415860496 recall 0.9260997067448681 f1 0.9256387041901468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 1.6784424781799316 s\n",
      "Accuracy 0.9296187683284457 precision 0.9286114005624688 specificity 0.8572480747513376 recall 0.9296187683284457 f1 0.9288256311726835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 1.6504912376403809 s\n",
      "Accuracy 0.9260997067448681 precision 0.9257225286515705 specificity 0.8582391139112625 recall 0.9260997067448681 f1 0.9258957611303653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 1.8250503540039062 s\n",
      "Accuracy 0.9284457478005865 precision 0.9288374542505149 specificity 0.8787969672472442 recall 0.9284457478005865 f1 0.9286267714469911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 1.765998125076294 s\n",
      "Accuracy 0.9114369501466275 precision 0.911002088214142 specificity 0.8506328006504313 recall 0.9114369501466275 f1 0.9112003984888888\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 1.707000970840454 s\n",
      "Accuracy 0.9296187683284457 precision 0.9307340289128988 specificity 0.875892324318679 recall 0.9296187683284457 f1 0.9300923416047084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 1.7430524826049805 s\n",
      "Accuracy 0.9214076246334311 precision 0.9201074442146956 specificity 0.8382843703456547 recall 0.9214076246334311 f1 0.9204231890753769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 1.6849989891052246 s\n",
      "Accuracy 0.9249266862170088 precision 0.9250622437795697 specificity 0.8659613222862284 recall 0.9249266862170088 f1 0.9249927999281113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 1.748000144958496 s\n",
      "Accuracy 0.9284457478005865 precision 0.9281665006993879 specificity 0.852688081195696 recall 0.9284457478005865 f1 0.9282989967846206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 1.7049992084503174 s\n",
      "Accuracy 0.9214076246334311 precision 0.9220346767027328 specificity 0.8603950084527623 recall 0.9214076246334311 f1 0.9216945267263615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 1.771045446395874 s\n",
      "Accuracy 0.9255131964809384 precision 0.9271133057467408 specificity 0.8759412645599979 recall 0.9255131964809384 f1 0.9261628563594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 1.7609996795654297 s\n",
      "Accuracy 0.9225806451612903 precision 0.9230080418544891 specificity 0.8670457916203189 recall 0.9225806451612903 f1 0.9227796137265437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 1.671999454498291 s\n",
      "Accuracy 0.9296187683284457 precision 0.9286469212480881 specificity 0.8585009802805691 recall 0.9296187683284457 f1 0.9288866417231268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 1.903001070022583 s\n",
      "Accuracy 0.9120234604105572 precision 0.9113334764883791 specificity 0.8352493848794929 recall 0.9120234604105572 f1 0.9116376028532757\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 1.7580008506774902 s\n",
      "Accuracy 0.9202346041055719 precision 0.9211350717814882 specificity 0.8707498698690604 recall 0.9202346041055719 f1 0.9206272569878415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 1.828000545501709 s\n",
      "Accuracy 0.9249266862170088 precision 0.9246786801899392 specificity 0.8629387728347484 recall 0.9249266862170088 f1 0.9247960159433133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 1.7370002269744873 s\n",
      "Accuracy 0.9202346041055719 precision 0.9197806119800529 specificity 0.8610688816541596 recall 0.9202346041055719 f1 0.9199819017489802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 1.7340006828308105 s\n",
      "Accuracy 0.9302052785923753 precision 0.9305317355984765 specificity 0.878162679664461 recall 0.9302052785923753 f1 0.9303580334933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 1.705998420715332 s\n",
      "Accuracy 0.92316715542522 precision 0.9230940098621495 specificity 0.8515267942808833 recall 0.92316715542522 f1 0.9231301538125092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 1.772000789642334 s\n",
      "Accuracy 0.9237536656891495 precision 0.9256390316175261 specificity 0.8777655136538035 recall 0.9237536656891495 f1 0.9244981440528135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 1.6870245933532715 s\n",
      "Accuracy 0.9278592375366569 precision 0.9275322012183194 specificity 0.8571131935410374 recall 0.9278592375366569 f1 0.927684828702365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 1.754040002822876 s\n",
      "Accuracy 0.9161290322580645 precision 0.9146194128786901 specificity 0.8274591123289916 recall 0.9161290322580645 f1 0.9149682193978886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 1.6810657978057861 s\n",
      "Accuracy 0.9219941348973607 precision 0.9210595975563134 specificity 0.8526955074965618 recall 0.9219941348973607 f1 0.9213777415879626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 1.680999517440796 s\n",
      "Accuracy 0.9249266862170088 precision 0.9253696794848191 specificity 0.8651235975922366 recall 0.9249266862170088 f1 0.9251330466302582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 1.7780003547668457 s\n",
      "Accuracy 0.9243401759530792 precision 0.923382116968981 specificity 0.8510535524549041 recall 0.9243401759530792 f1 0.9237084381637942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 1.7589988708496094 s\n",
      "Accuracy 0.9278592375366569 precision 0.9270193558616646 specificity 0.8577368867691448 recall 0.9278592375366569 f1 0.9273160108475338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 1.731999158859253 s\n",
      "Accuracy 0.9143695014662757 precision 0.9136034685801807 specificity 0.840345376003602 recall 0.9143695014662757 f1 0.9139276217674241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 1.6720306873321533 s\n",
      "Accuracy 0.9155425219941349 precision 0.9145468013139132 specificity 0.8354153324119954 recall 0.9155425219941349 f1 0.9149380071951593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 1.7450006008148193 s\n",
      "Accuracy 0.92316715542522 precision 0.923803254622218 specificity 0.8733523390340904 recall 0.92316715542522 f1 0.9234524921013969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 1.7080011367797852 s\n",
      "Accuracy 0.9260997067448681 precision 0.92595588962768 specificity 0.8527336939252349 recall 0.9260997067448681 f1 0.9260260482027256\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 1.6559982299804688 s\n",
      "Accuracy 0.9348973607038124 precision 0.9358121974454884 specificity 0.8896659208497398 recall 0.9348973607038124 f1 0.9352827880939529\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 1.769052505493164 s\n",
      "Accuracy 0.9225806451612903 precision 0.9222229943140524 specificity 0.8615875270139134 recall 0.9225806451612903 f1 0.9223870785475821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 1.6869981288909912 s\n",
      "Accuracy 0.9243401759530792 precision 0.9248796623940879 specificity 0.8622594910497865 recall 0.9243401759530792 f1 0.9245891780473189\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 1.6609995365142822 s\n",
      "Accuracy 0.9214076246334311 precision 0.9208900160058252 specificity 0.8494882051379291 recall 0.9214076246334311 f1 0.9211218599044879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 1.6985116004943848 s\n",
      "Accuracy 0.9114369501466275 precision 0.9110665706257474 specificity 0.8367300516565737 recall 0.9114369501466275 f1 0.9112415806389454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 1.7520463466644287 s\n",
      "Accuracy 0.9167155425219942 precision 0.916226730476003 specificity 0.8529565037111994 recall 0.9167155425219942 f1 0.9164454203745069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 1.7760026454925537 s\n",
      "Accuracy 0.9208211143695014 precision 0.921474333984298 specificity 0.8692543992592345 recall 0.9208211143695014 f1 0.9211151636159436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 1.7319977283477783 s\n",
      "Accuracy 0.9055718475073313 precision 0.9065443199183406 specificity 0.8414448132946515 recall 0.9055718475073313 f1 0.9060106777368649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 1.6889991760253906 s\n",
      "Accuracy 0.918475073313783 precision 0.9191074490177058 specificity 0.8704556706509851 recall 0.918475073313783 f1 0.9187594520644186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 1.733999490737915 s\n",
      "Accuracy 0.9343108504398827 precision 0.9336576912823248 specificity 0.87027527029841 recall 0.9343108504398827 f1 0.9338994445350243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 1.7485089302062988 s\n",
      "Accuracy 0.9173020527859238 precision 0.9173616460799442 specificity 0.8705686864792379 recall 0.9173020527859238 f1 0.9173314648379682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 1.7390003204345703 s\n",
      "Accuracy 0.9131964809384164 precision 0.9121571846251094 specificity 0.8381685034538083 recall 0.9131964809384164 f1 0.9125453932377614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 1.7009997367858887 s\n",
      "Accuracy 0.9219941348973607 precision 0.922693118663058 specificity 0.8635554453703094 recall 0.9219941348973607 f1 0.9223100716269993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 1.7339990139007568 s\n",
      "Accuracy 0.9243401759530792 precision 0.9229804583890062 specificity 0.8363782148515185 recall 0.9243401759530792 f1 0.9231848897731335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 1.7309989929199219 s\n",
      "Accuracy 0.9137829912023461 precision 0.913563889965477 specificity 0.8431169155323313 recall 0.9137829912023461 f1 0.9136697728640135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 1.788511037826538 s\n",
      "Accuracy 0.918475073313783 precision 0.9184061862521801 specificity 0.8552214738966644 recall 0.918475073313783 f1 0.9184402220083051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 1.8059983253479004 s\n",
      "Accuracy 0.9255131964809384 precision 0.9249367614047768 specificity 0.8643489881180884 recall 0.9255131964809384 f1 0.9251751003514903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 1.8320002555847168 s\n",
      "Accuracy 0.9225806451612903 precision 0.9212721133490439 specificity 0.8355231675747714 recall 0.9225806451612903 f1 0.921632379226267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 1.7319989204406738 s\n",
      "Accuracy 0.918475073313783 precision 0.9183986433845714 specificity 0.8443427558190423 recall 0.918475073313783 f1 0.918436436389648\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 1.92099928855896 s\n",
      "Accuracy 0.9290322580645162 precision 0.9293727214851562 specificity 0.8736472149646269 recall 0.9290322580645162 f1 0.9291919420423203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 1.7580006122589111 s\n",
      "Accuracy 0.9255131964809384 precision 0.9252017004623407 specificity 0.8608333104279416 recall 0.9255131964809384 f1 0.9253469171743263\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 1.7950451374053955 s\n",
      "Accuracy 0.9225806451612903 precision 0.9219615107084521 specificity 0.8502638747915429 recall 0.9225806451612903 f1 0.9222287706816215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 1.7949998378753662 s\n",
      "Accuracy 0.9249266862170088 precision 0.9245508921719324 specificity 0.8580959507841704 recall 0.9249266862170088 f1 0.9247235776611467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 1.6899998188018799 s\n",
      "Accuracy 0.9272727272727272 precision 0.9296854569540982 specificity 0.880176477042262 recall 0.9272727272727272 f1 0.9281925565029295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 1.687997817993164 s\n",
      "Accuracy 0.9319648093841643 precision 0.9311644179406134 specificity 0.868418982284513 recall 0.9319648093841643 f1 0.931395564782793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 1.6635551452636719 s\n",
      "Accuracy 0.918475073313783 precision 0.9176260759243978 specificity 0.837342801235785 recall 0.918475073313783 f1 0.9179787791724423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 1.7939999103546143 s\n",
      "Accuracy 0.9143695014662757 precision 0.9130760824441888 specificity 0.8286081770368531 recall 0.9143695014662757 f1 0.913520042245665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 1.6979992389678955 s\n",
      "Accuracy 0.9260997067448681 precision 0.9252233389867799 specificity 0.8607293373727791 recall 0.9260997067448681 f1 0.9254957770110654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 1.8110015392303467 s\n",
      "Accuracy 0.9296187683284457 precision 0.9290697083952216 specificity 0.8638395368218105 recall 0.9296187683284457 f1 0.9293014112099112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 1.801999568939209 s\n",
      "Accuracy 0.930791788856305 precision 0.9305458643961694 specificity 0.8664384470425921 recall 0.930791788856305 f1 0.9306618945970581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 1.700042486190796 s\n",
      "Accuracy 0.9208211143695014 precision 0.9206071400489827 specificity 0.8490978706322562 recall 0.9208211143695014 f1 0.9207103237314728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 1.8479993343353271 s\n",
      "Accuracy 0.9219941348973607 precision 0.9215531912992788 specificity 0.8543283712147802 recall 0.9219941348973607 f1 0.9217532222991461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 1.7510015964508057 s\n",
      "Accuracy 0.9202346041055719 precision 0.9193124373183024 specificity 0.8442269414171245 recall 0.9202346041055719 f1 0.9196659297523555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 1.6769979000091553 s\n",
      "Accuracy 0.9196480938416423 precision 0.9183178611885707 specificity 0.8371322544114607 recall 0.9196480938416423 f1 0.9186281018729472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 1.6539990901947021 s\n",
      "Accuracy 0.9178885630498533 precision 0.9172144113090275 specificity 0.839917283130439 recall 0.9178885630498533 f1 0.9175093797428262\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 1.707998514175415 s\n",
      "Accuracy 0.918475073313783 precision 0.9178605739295196 specificity 0.8561738190229583 recall 0.918475073313783 f1 0.9181192474806161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 1.7189979553222656 s\n",
      "Accuracy 0.9208211143695014 precision 0.9203555617262941 specificity 0.8484584020583039 recall 0.9208211143695014 f1 0.9205676985549226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 1.760002613067627 s\n",
      "Accuracy 0.9155425219941349 precision 0.915415494270788 specificity 0.8593539438204615 recall 0.9155425219941349 f1 0.9154774362039708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 1.7529985904693604 s\n",
      "Accuracy 0.9237536656891495 precision 0.9241996323976766 specificity 0.8636922217567379 recall 0.9237536656891495 f1 0.9239615915180448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 1.7290003299713135 s\n",
      "Accuracy 0.9161290322580645 precision 0.9173716769710394 specificity 0.8629799192938628 recall 0.9161290322580645 f1 0.9166605347099839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 1.7079999446868896 s\n",
      "Accuracy 0.92316715542522 precision 0.9229606308979167 specificity 0.8539055325636774 recall 0.92316715542522 f1 0.9230600752904481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 1.7539997100830078 s\n",
      "Accuracy 0.9319648093841643 precision 0.9323590273219391 specificity 0.880621716890575 recall 0.9319648093841643 f1 0.932146701548612\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 1.7320001125335693 s\n",
      "Accuracy 0.9214076246334311 precision 0.9200157090256748 specificity 0.8320891636741465 recall 0.9214076246334311 f1 0.9203709422942098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 1.7200002670288086 s\n",
      "Accuracy 0.9079178885630499 precision 0.906675182397928 specificity 0.8332933379671352 recall 0.9079178885630499 f1 0.9070873474609813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 1.6399996280670166 s\n",
      "Accuracy 0.9219941348973607 precision 0.9211091750370508 specificity 0.8519200311799415 recall 0.9219941348973607 f1 0.9214316814744471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 1.6589999198913574 s\n",
      "Accuracy 0.9143695014662757 precision 0.9136742276888757 specificity 0.8353279477982933 recall 0.9143695014662757 f1 0.9139803069660358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 1.7655093669891357 s\n",
      "Accuracy 0.9149560117302052 precision 0.9134558020300276 specificity 0.8151793266156593 recall 0.9149560117302052 f1 0.913975268709607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 1.7799999713897705 s\n",
      "Accuracy 0.930791788856305 precision 0.9304378558303023 specificity 0.8661300431172029 recall 0.930791788856305 f1 0.9305992651356272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 1.8289995193481445 s\n",
      "Accuracy 0.9219941348973607 precision 0.9220674547617675 specificity 0.8545885167787839 recall 0.9219941348973607 f1 0.9220303732126907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 1.6310007572174072 s\n",
      "Accuracy 0.9255131964809384 precision 0.923991082343941 specificity 0.8258135122130104 recall 0.9255131964809384 f1 0.9241313339760536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 1.7209997177124023 s\n",
      "Accuracy 0.9219941348973607 precision 0.922693118663058 specificity 0.8635554453703094 recall 0.9219941348973607 f1 0.9223100716269993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 1.8350281715393066 s\n",
      "Accuracy 0.9313782991202346 precision 0.9308547378456734 specificity 0.8612617410706723 recall 0.9313782991202346 f1 0.9310808739432542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 1.8109991550445557 s\n",
      "Accuracy 0.9249266862170088 precision 0.9252130967278767 specificity 0.8644136446192738 recall 0.9249266862170088 f1 0.9250631708636683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 1.7999999523162842 s\n",
      "Accuracy 0.9272727272727272 precision 0.9275582781197741 specificity 0.8661504670506688 recall 0.9272727272727272 f1 0.9274086825386869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 1.7150001525878906 s\n",
      "Accuracy 0.9155425219941349 precision 0.9144407927571634 specificity 0.8392427916061516 recall 0.9155425219941349 f1 0.9148274917903477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 1.6420087814331055 s\n",
      "Accuracy 0.9278592375366569 precision 0.9268584512783232 specificity 0.8550764079703008 recall 0.9278592375366569 f1 0.9271329457472185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 1.8688132762908936 s\n",
      "Accuracy 0.9360703812316715 precision 0.936347627807194 specificity 0.8949747205750818 recall 0.9360703812316715 f1 0.9361987105754556\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 1.7980010509490967 s\n",
      "Accuracy 0.9284457478005865 precision 0.9286945942400168 specificity 0.8793156965598719 recall 0.9284457478005865 f1 0.928563620100385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 1.8105120658874512 s\n",
      "Accuracy 0.9208211143695014 precision 0.9208890965089153 specificity 0.8614390945573741 recall 0.9208211143695014 f1 0.9208546973912146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 1.7661991119384766 s\n",
      "Accuracy 0.9249266862170088 precision 0.9240930262345692 specificity 0.8546233276246352 recall 0.9249266862170088 f1 0.924401938205884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 1.7820229530334473 s\n",
      "Accuracy 0.9190615835777126 precision 0.9173700353527705 specificity 0.8182173805734131 recall 0.9190615835777126 f1 0.9175117853284237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 1.6833765506744385 s\n",
      "Accuracy 0.9202346041055719 precision 0.9199646819394046 specificity 0.8525775510595244 recall 0.9202346041055719 f1 0.9200929970322036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 1.7320170402526855 s\n",
      "Accuracy 0.9243401759530792 precision 0.9233957268864667 specificity 0.8522924570874593 recall 0.9243401759530792 f1 0.9237158757525012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 1.7139997482299805 s\n",
      "Accuracy 0.9278592375366569 precision 0.9272972051860414 specificity 0.8672841266176348 recall 0.9278592375366569 f1 0.9275279113055037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 1.7330009937286377 s\n",
      "Accuracy 0.9243401759530792 precision 0.9245544753126271 specificity 0.8624094813080742 recall 0.9243401759530792 f1 0.9244435442136367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 1.6765131950378418 s\n",
      "Accuracy 0.910850439882698 precision 0.9114978395134532 specificity 0.8498333208010628 recall 0.910850439882698 f1 0.9111488025703132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 1.6655120849609375 s\n",
      "Accuracy 0.9272727272727272 precision 0.9265422921442175 specificity 0.8592686883009465 recall 0.9272727272727272 f1 0.9268243936693135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 1.6950006484985352 s\n",
      "Accuracy 0.9178885630498533 precision 0.9171565275123981 specificity 0.8460726246401479 recall 0.9178885630498533 f1 0.9174631697028949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 1.6900436878204346 s\n",
      "Accuracy 0.9143695014662757 precision 0.9142195582029992 specificity 0.8424572843588345 recall 0.9143695014662757 f1 0.9142928876115444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 1.6939990520477295 s\n",
      "Accuracy 0.9214076246334311 precision 0.9211596868864792 specificity 0.8612125599256736 recall 0.9214076246334311 f1 0.9212771383022664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 1.6960535049438477 s\n",
      "Accuracy 0.9243401759530792 precision 0.9241293094534632 specificity 0.8522914029942892 recall 0.9243401759530792 f1 0.9242308658453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 1.710024356842041 s\n",
      "Accuracy 0.9354838709677419 precision 0.9353740963194129 specificity 0.8824966206256497 recall 0.9354838709677419 f1 0.9354272785260074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 1.6979999542236328 s\n",
      "Accuracy 0.9173020527859238 precision 0.9180275105182221 specificity 0.8564329574509877 recall 0.9173020527859238 f1 0.917631729815334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 1.6860196590423584 s\n",
      "Accuracy 0.9255131964809384 precision 0.9252275253527886 specificity 0.8685094507709563 recall 0.9255131964809384 f1 0.9253601180711103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 1.6820001602172852 s\n",
      "Accuracy 0.92316715542522 precision 0.9223907623961104 specificity 0.8477885566193756 recall 0.92316715542522 f1 0.9227068232064246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 1.7030177116394043 s\n",
      "Accuracy 0.9214076246334311 precision 0.9207963547961094 specificity 0.8510827968225075 recall 0.9214076246334311 f1 0.9210601899853471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 1.6449954509735107 s\n",
      "Accuracy 0.92316715542522 precision 0.9226519578236541 specificity 0.8597528244514874 recall 0.92316715542522 f1 0.922876161141714\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 1.697019100189209 s\n",
      "Accuracy 0.9337243401759531 precision 0.9331499148774315 specificity 0.876376647357002 recall 0.9337243401759531 f1 0.9333660173538296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 1.7330405712127686 s\n",
      "Accuracy 0.9302052785923753 precision 0.9301438045004683 specificity 0.8721534534873119 recall 0.9302052785923753 f1 0.9301741175884592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 1.7230007648468018 s\n",
      "Accuracy 0.9296187683284457 precision 0.9294976928727297 specificity 0.871268253146811 recall 0.9296187683284457 f1 0.9295565412272965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 1.6970016956329346 s\n",
      "Accuracy 0.9173020527859238 precision 0.917105352598125 specificity 0.8557155992174384 recall 0.9173020527859238 f1 0.9172000808688254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 1.7159981727600098 s\n",
      "Accuracy 0.9290322580645162 precision 0.9294873444183579 specificity 0.8813049850592205 recall 0.9290322580645162 f1 0.9292396736726364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 1.7090017795562744 s\n",
      "Accuracy 0.9225806451612903 precision 0.9220802687932157 specificity 0.8532872777654561 recall 0.9225806451612903 f1 0.9223035758784264\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 1.7000408172607422 s\n",
      "Accuracy 0.92316715542522 precision 0.9223104709162872 specificity 0.8375492167085614 recall 0.92316715542522 f1 0.9226643105321961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 1.6689984798431396 s\n",
      "Accuracy 0.9155425219941349 precision 0.9146757550741097 specificity 0.827349269946694 recall 0.9155425219941349 f1 0.9150475237173316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 1.6380000114440918 s\n",
      "Accuracy 0.9190615835777126 precision 0.9187724656705746 specificity 0.8448790396571202 recall 0.9190615835777126 f1 0.9189102785236605\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 1.6740503311157227 s\n",
      "Accuracy 0.9237536656891495 precision 0.9238734433746093 specificity 0.8759491174408791 recall 0.9237536656891495 f1 0.9238119662615392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 1.6509995460510254 s\n",
      "Accuracy 0.9313782991202346 precision 0.9318665481160252 specificity 0.8767458029663073 recall 0.9313782991202346 f1 0.9316014508514769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 1.8099994659423828 s\n",
      "Accuracy 0.9161290322580645 precision 0.9160614249948029 specificity 0.8557125861700551 recall 0.9161290322580645 f1 0.91609482874454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 1.6949996948242188 s\n",
      "Accuracy 0.9219941348973607 precision 0.9223673814436694 specificity 0.8602791395416335 recall 0.9219941348973607 f1 0.9221703527654991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 1.7240524291992188 s\n",
      "Accuracy 0.9243401759530792 precision 0.9236343370521354 specificity 0.8450953298663659 recall 0.9243401759530792 f1 0.9239345102758335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 1.7049992084503174 s\n",
      "Accuracy 0.9255131964809384 precision 0.9267825735179529 specificity 0.8835915714913934 recall 0.9255131964809384 f1 0.9260316261289816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 1.6869983673095703 s\n",
      "Accuracy 0.9237536656891495 precision 0.9231609961531817 specificity 0.8548659307752119 recall 0.9237536656891495 f1 0.9234152664329387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 1.6939990520477295 s\n",
      "Accuracy 0.9173020527859238 precision 0.9161161206857208 specificity 0.8291969042666401 recall 0.9173020527859238 f1 0.9165544020793994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 1.7039995193481445 s\n",
      "Accuracy 0.918475073313783 precision 0.9175592146036328 specificity 0.8401696551157999 recall 0.918475073313783 f1 0.9179225706745822\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 1.7470197677612305 s\n",
      "Accuracy 0.9284457478005865 precision 0.9287042133493747 specificity 0.8761091991877707 recall 0.9284457478005865 f1 0.9285683445933187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 1.7146122455596924 s\n",
      "Accuracy 0.92316715542522 precision 0.9225787751923318 specificity 0.8470333029011752 recall 0.92316715542522 f1 0.9228381221355625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 1.5859363079071045 s\n",
      "Accuracy 0.9202346041055719 precision 0.9210305803846587 specificity 0.8615877482958821 recall 0.9202346041055719 f1 0.9205914357577449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 1.6680266857147217 s\n",
      "Accuracy 0.9155425219941349 precision 0.915985264928003 specificity 0.8589771094792956 recall 0.9155425219941349 f1 0.915749583617153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 1.711000680923462 s\n",
      "Accuracy 0.9266862170087976 precision 0.9258450955655256 specificity 0.862128535616657 recall 0.9266862170087976 f1 0.9261159203834608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 1.6990199089050293 s\n",
      "Accuracy 0.9272727272727272 precision 0.9271246839889247 specificity 0.8500772988096931 recall 0.9272727272727272 f1 0.9271969212251991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 1.7189977169036865 s\n",
      "Accuracy 0.9208211143695014 precision 0.9199941114310837 specificity 0.8407589722105852 recall 0.9208211143695014 f1 0.920335235574971\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 1.719999074935913 s\n",
      "Accuracy 0.9214076246334311 precision 0.9208931644675874 specificity 0.8659441540226953 recall 0.9214076246334311 f1 0.9211106537155602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 1.7125084400177002 s\n",
      "Accuracy 0.9219941348973607 precision 0.9216799811238077 specificity 0.8584047255014997 recall 0.9219941348973607 f1 0.9218267423326741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 1.7319984436035156 s\n",
      "Accuracy 0.9096774193548387 precision 0.9099911857652653 specificity 0.8455892594061029 recall 0.9096774193548387 f1 0.9098279711655007\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 1.7290194034576416 s\n",
      "Accuracy 0.9161290322580645 precision 0.9152772481906469 specificity 0.8463782749248038 recall 0.9161290322580645 f1 0.915611940621716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 1.6770005226135254 s\n",
      "Accuracy 0.9137829912023461 precision 0.9154473168336972 specificity 0.8619087805869755 recall 0.9137829912023461 f1 0.9144723440724328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 1.629512071609497 s\n",
      "Accuracy 0.92316715542522 precision 0.9245373751442345 specificity 0.8747362028607192 recall 0.92316715542522 f1 0.9237344000383115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 1.6770498752593994 s\n",
      "Accuracy 0.9190615835777126 precision 0.9193519535024911 specificity 0.8594082693972119 recall 0.9190615835777126 f1 0.919200258638344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 1.6969997882843018 s\n",
      "Accuracy 0.9208211143695014 precision 0.920365239672581 specificity 0.8505770883553995 recall 0.9208211143695014 f1 0.9205726772350095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 1.7309999465942383 s\n",
      "Accuracy 0.9196480938416423 precision 0.9194208036255649 specificity 0.8419172975061946 recall 0.9196480938416423 f1 0.9195305965947443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 1.7050259113311768 s\n",
      "Accuracy 0.9237536656891495 precision 0.9250381758812612 specificity 0.8739101125008949 recall 0.9237536656891495 f1 0.9242908395918574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 1.7139990329742432 s\n",
      "Accuracy 0.9325513196480938 precision 0.9328652300509771 specificity 0.8830380778977199 recall 0.9325513196480938 f1 0.9326977793034722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 1.6829984188079834 s\n",
      "Accuracy 0.930791788856305 precision 0.9296474914300473 specificity 0.8468861066773815 recall 0.930791788856305 f1 0.9299164674920802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 1.7260019779205322 s\n",
      "Accuracy 0.9190615835777126 precision 0.918646824076795 specificity 0.8456964664453377 recall 0.9190615835777126 f1 0.9188391012571782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 1.7310011386871338 s\n",
      "Accuracy 0.9249266862170088 precision 0.9252109026165695 specificity 0.8651656041336007 recall 0.9249266862170088 f1 0.9250620919209168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 1.6969988346099854 s\n",
      "Accuracy 0.9178885630498533 precision 0.9181967785069267 specificity 0.852592992806094 recall 0.9178885630498533 f1 0.9180360770468736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 1.6834297180175781 s\n",
      "Accuracy 0.9161290322580645 precision 0.9156533469268453 specificity 0.8442636880484489 recall 0.9161290322580645 f1 0.9158710275550558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 1.6524686813354492 s\n",
      "Accuracy 0.92316715542522 precision 0.9236939677129976 specificity 0.8638987250698952 recall 0.92316715542522 f1 0.9234101505907583\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 1.6999988555908203 s\n",
      "Accuracy 0.918475073313783 precision 0.9178591096106543 specificity 0.8405353247346679 recall 0.918475073313783 f1 0.918132853342983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 1.7140183448791504 s\n",
      "Accuracy 0.9167155425219942 precision 0.9168570318090403 specificity 0.856954294562477 recall 0.9167155425219942 f1 0.9167846808019396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 1.6889996528625488 s\n",
      "Accuracy 0.9202346041055719 precision 0.921507756909898 specificity 0.8718572521433764 recall 0.9202346041055719 f1 0.9207685162834096\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 1.820535659790039 s\n",
      "Accuracy 0.9120234604105572 precision 0.9114971642430337 specificity 0.8438142691113829 recall 0.9120234604105572 f1 0.9117347450559471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 1.827791452407837 s\n",
      "Accuracy 0.9290322580645162 precision 0.9286533792256998 specificity 0.87085473694443 recall 0.9290322580645162 f1 0.928822382737348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 2.1080007553100586 s\n",
      "Accuracy 0.9155425219941349 precision 0.9165122233018713 specificity 0.8600529984073154 recall 0.9155425219941349 f1 0.9159698565036802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 1.8816146850585938 s\n",
      "Accuracy 0.9214076246334311 precision 0.920015531034016 specificity 0.8337456320715498 recall 0.9214076246334311 f1 0.9203231519213925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 1.7040696144104004 s\n",
      "Accuracy 0.9208211143695014 precision 0.9203229713007874 specificity 0.8616202091179361 recall 0.9208211143695014 f1 0.9205394660489324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 1.7400031089782715 s\n",
      "Accuracy 0.9149560117302052 precision 0.9160211585009218 specificity 0.859872637505601 recall 0.9149560117302052 f1 0.9154212570435292\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 1.6471824645996094 s\n",
      "Accuracy 0.9190615835777126 precision 0.9194747610667733 specificity 0.8677644308747611 recall 0.9190615835777126 f1 0.9192538975035011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 1.708024024963379 s\n",
      "Accuracy 0.9260997067448681 precision 0.9259703165308464 specificity 0.8634148805066358 recall 0.9260997067448681 f1 0.926033325446209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 1.6579999923706055 s\n",
      "Accuracy 0.9343108504398827 precision 0.9344299447466661 specificity 0.882937192849324 recall 0.9343108504398827 f1 0.9343686999370973\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 1.7190415859222412 s\n",
      "Accuracy 0.9237536656891495 precision 0.923132084495334 specificity 0.8502758766164654 recall 0.9237536656891495 f1 0.9234001616822552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 1.7085087299346924 s\n",
      "Accuracy 0.9266862170087976 precision 0.9267551860546581 specificity 0.8633910704506887 recall 0.9266862170087976 f1 0.926720275575837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 1.7225110530853271 s\n",
      "Accuracy 0.92316715542522 precision 0.9240187880388392 specificity 0.8682832668872835 recall 0.92316715542522 f1 0.9235430008394865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 1.7090001106262207 s\n",
      "Accuracy 0.9219941348973607 precision 0.9223617306160002 specificity 0.8618115851273972 recall 0.9219941348973607 f1 0.9221675819483582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 1.6899995803833008 s\n",
      "Accuracy 0.9348973607038124 precision 0.9340127921984894 specificity 0.8624626343223779 recall 0.9348973607038124 f1 0.9342596990316023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 1.7320358753204346 s\n",
      "Accuracy 0.9178885630498533 precision 0.9166798224652021 specificity 0.8358039809652713 recall 0.9178885630498533 f1 0.9170804443081673\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 1.7089979648590088 s\n",
      "Accuracy 0.9313782991202346 precision 0.9308834722109507 specificity 0.8664004907757118 recall 0.9313782991202346 f1 0.9310959214982751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 1.6770002841949463 s\n",
      "Accuracy 0.9208211143695014 precision 0.9217447919557223 specificity 0.8581542416836027 recall 0.9208211143695014 f1 0.9212322425802582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 1.6419999599456787 s\n",
      "Accuracy 0.9131964809384164 precision 0.9130462510852422 specificity 0.8416418180175296 recall 0.9131964809384164 f1 0.9131197341803321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 1.7220430374145508 s\n",
      "Accuracy 0.9225806451612903 precision 0.9217596566470744 specificity 0.855319816949698 recall 0.9225806451612903 f1 0.922064467524735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 1.7280001640319824 s\n",
      "Accuracy 0.9161290322580645 precision 0.9149433847548879 specificity 0.8290303710762437 recall 0.9161290322580645 f1 0.9153828058153292\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 1.6900017261505127 s\n",
      "Accuracy 0.9126099706744868 precision 0.9120867593927809 specificity 0.8324486990606971 recall 0.9126099706744868 f1 0.9123280408423063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 1.7139992713928223 s\n",
      "Accuracy 0.9260997067448681 precision 0.9275231958039606 specificity 0.8806859030825669 recall 0.9260997067448681 f1 0.9266785352228794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 1.7209994792938232 s\n",
      "Accuracy 0.9296187683284457 precision 0.9292787737330688 specificity 0.8692030707520141 recall 0.9296187683284457 f1 0.9294335567009506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 1.6860013008117676 s\n",
      "Accuracy 0.9260997067448681 precision 0.9255080853107783 specificity 0.8558472193354707 recall 0.9260997067448681 f1 0.9257611466918808\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 1.6900014877319336 s\n",
      "Accuracy 0.9272727272727272 precision 0.9263997796816058 specificity 0.8570498095782798 recall 0.9272727272727272 f1 0.9266985712274922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 1.6596014499664307 s\n",
      "Accuracy 0.9243401759530792 precision 0.9242765664084694 specificity 0.8659352276556578 recall 0.9243401759530792 f1 0.9243079590001311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 1.7310526371002197 s\n",
      "Accuracy 0.9155425219941349 precision 0.9177005146228192 specificity 0.8687712034960612 recall 0.9155425219941349 f1 0.9163938383570904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 1.6740005016326904 s\n",
      "Accuracy 0.9126099706744868 precision 0.9134988384563937 specificity 0.8562235778200785 recall 0.9126099706744868 f1 0.9130066346373827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 1.7099981307983398 s\n",
      "Accuracy 0.9284457478005865 precision 0.928322093069602 specificity 0.8687907001654005 recall 0.9284457478005865 f1 0.928382232863267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 1.7230010032653809 s\n",
      "Accuracy 0.92316715542522 precision 0.9223275270672538 specificity 0.8566683497138571 recall 0.92316715542522 f1 0.9226281861479964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 1.7009997367858887 s\n",
      "Accuracy 0.9249266862170088 precision 0.9240775046379427 specificity 0.8529910925025934 recall 0.9249266862170088 f1 0.9243935772349166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 1.7070469856262207 s\n",
      "Accuracy 0.9255131964809384 precision 0.9253361529461871 specificity 0.8694571856143553 recall 0.9255131964809384 f1 0.9254209884456344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 1.6909992694854736 s\n",
      "Accuracy 0.9272727272727272 precision 0.9285489155737489 specificity 0.8774567147374845 recall 0.9272727272727272 f1 0.9278037102506875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 1.7020008563995361 s\n",
      "Accuracy 0.9260997067448681 precision 0.9252363777049584 specificity 0.8517445397132548 recall 0.9260997067448681 f1 0.9255580106600885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 1.7139990329742432 s\n",
      "Accuracy 0.9266862170087976 precision 0.9264950946583326 specificity 0.863207783076843 recall 0.9266862170087976 f1 0.9265868460305241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 1.7019999027252197 s\n",
      "Accuracy 0.9225806451612903 precision 0.9219277639922802 specificity 0.8581736334034354 recall 0.9225806451612903 f1 0.9221950288393406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 1.7180006504058838 s\n",
      "Accuracy 0.9219941348973607 precision 0.920530988145542 specificity 0.8282223153190895 recall 0.9219941348973607 f1 0.9208914904173486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 1.6725013256072998 s\n",
      "Accuracy 0.9272727272727272 precision 0.9262620146688957 specificity 0.8528335885087356 recall 0.9272727272727272 f1 0.9265597936166732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 1.642526388168335 s\n",
      "Accuracy 0.9266862170087976 precision 0.9255754154020921 specificity 0.848807106871623 recall 0.9266862170087976 f1 0.9258614030738601\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 1.7459986209869385 s\n",
      "Accuracy 0.9284457478005865 precision 0.9278374489784695 specificity 0.8538853922343143 recall 0.9284457478005865 f1 0.9280976734640956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 1.67799973487854 s\n",
      "Accuracy 0.9202346041055719 precision 0.9190684446411774 specificity 0.839502779582282 recall 0.9202346041055719 f1 0.9194464578929217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 1.7300283908843994 s\n",
      "Accuracy 0.92316715542522 precision 0.9217914269061285 specificity 0.83390886614868 recall 0.92316715542522 f1 0.9221111721533549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 1.7190017700195312 s\n",
      "Accuracy 0.9137829912023461 precision 0.9131006887840275 specificity 0.844795717639338 recall 0.9137829912023461 f1 0.9133931836610986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 1.6949985027313232 s\n",
      "Accuracy 0.9225806451612903 precision 0.9233704630907716 specificity 0.8640675801555963 recall 0.9225806451612903 f1 0.9229339201264656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 1.7200007438659668 s\n",
      "Accuracy 0.9173020527859238 precision 0.9173749830423872 specificity 0.8524956734120132 recall 0.9173020527859238 f1 0.9173381092260809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 1.7580490112304688 s\n",
      "Accuracy 0.9290322580645162 precision 0.9282298090901523 specificity 0.8617575736738847 recall 0.9290322580645162 f1 0.9285083145669278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 1.7029998302459717 s\n",
      "Accuracy 0.9255131964809384 precision 0.9261344320235935 specificity 0.8771353688794913 recall 0.9255131964809384 f1 0.9257909081753739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 1.6750009059906006 s\n",
      "Accuracy 0.9225806451612903 precision 0.9218222729344832 specificity 0.844044019580398 recall 0.9225806451612903 f1 0.9221394691455134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 1.6445088386535645 s\n",
      "Accuracy 0.9225806451612903 precision 0.9220028285405011 specificity 0.8567573215748019 recall 0.9225806451612903 f1 0.9222503339322552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 1.6489977836608887 s\n",
      "Accuracy 0.9161290322580645 precision 0.9157693449610896 specificity 0.8421012401963609 recall 0.9161290322580645 f1 0.9159388115662696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 1.6469995975494385 s\n",
      "Accuracy 0.9120234604105572 precision 0.9128328564750898 specificity 0.8539769112281038 recall 0.9120234604105572 f1 0.9123886273821004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 1.661027193069458 s\n",
      "Accuracy 0.9219941348973607 precision 0.921685103473527 specificity 0.859918992574039 recall 0.9219941348973607 f1 0.9218293567479312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 1.6939995288848877 s\n",
      "Accuracy 0.9155425219941349 precision 0.916168210839189 specificity 0.856599209566534 recall 0.9155425219941349 f1 0.9158296613780483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 1.7035143375396729 s\n",
      "Accuracy 0.9272727272727272 precision 0.9268942420271875 specificity 0.858385129523092 recall 0.9272727272727272 f1 0.9270679786945923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 1.6959989070892334 s\n",
      "Accuracy 0.9413489736070382 precision 0.941456550550027 specificity 0.8950971413312105 recall 0.9413489736070382 f1 0.9414010350310705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 1.7225115299224854 s\n",
      "Accuracy 0.918475073313783 precision 0.9183958099829574 specificity 0.8401763230804205 recall 0.918475073313783 f1 0.9184350143853701\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 1.798508882522583 s\n",
      "Accuracy 0.9302052785923753 precision 0.9296359227759511 specificity 0.8670297444490993 recall 0.9302052785923753 f1 0.9298692178103414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 1.7680015563964844 s\n",
      "Accuracy 0.9208211143695014 precision 0.9208862468685187 specificity 0.8653671203980583 recall 0.9208211143695014 f1 0.9208532781026407\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 1.6989984512329102 s\n",
      "Accuracy 0.9225806451612903 precision 0.9217249946446768 specificity 0.8517371730644334 recall 0.9225806451612903 f1 0.9220458649536853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 1.6860604286193848 s\n",
      "Accuracy 0.9272727272727272 precision 0.9265014482816727 specificity 0.8543997590734093 recall 0.9272727272727272 f1 0.9268025399720139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 1.7566912174224854 s\n",
      "Accuracy 0.9243401759530792 precision 0.9242684530600622 specificity 0.8542061899617078 recall 0.9243401759530792 f1 0.9243038851543298\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 1.7795093059539795 s\n",
      "Accuracy 0.9266862170087976 precision 0.9255702841422868 specificity 0.8509794600216971 recall 0.9266862170087976 f1 0.9257701366143217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 1.8400523662567139 s\n",
      "Accuracy 0.9190615835777126 precision 0.9178723501601139 specificity 0.8465372314421272 recall 0.9190615835777126 f1 0.9181000139487705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 1.7920279502868652 s\n",
      "Accuracy 0.9173020527859238 precision 0.9165078644991304 specificity 0.8437741065939707 recall 0.9173020527859238 f1 0.9168351648758217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 1.7905089855194092 s\n",
      "Accuracy 0.9384164222873901 precision 0.9378311760542016 specificity 0.8821215435293653 recall 0.9384164222873901 f1 0.9380276894659124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 1.7650198936462402 s\n",
      "Accuracy 0.9208211143695014 precision 0.9208940671761289 specificity 0.854458947426423 recall 0.9208211143695014 f1 0.9208571730650448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 1.7300007343292236 s\n",
      "Accuracy 0.9155425219941349 precision 0.9161799475675421 specificity 0.8546807188173412 recall 0.9155425219941349 f1 0.9158353726362625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 1.7259986400604248 s\n",
      "Accuracy 0.9243401759530792 precision 0.925583015047016 specificity 0.8695244857010561 recall 0.9243401759530792 f1 0.9248674025708493\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 1.7320003509521484 s\n",
      "Accuracy 0.9255131964809384 precision 0.9245643001553469 specificity 0.8589092775967081 recall 0.9255131964809384 f1 0.9248199898355496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 1.6690678596496582 s\n",
      "Accuracy 0.9208211143695014 precision 0.9203496463174202 specificity 0.8471579314794672 recall 0.9208211143695014 f1 0.9205646554923465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 1.7309997081756592 s\n",
      "Accuracy 0.9173020527859238 precision 0.915989118044335 specificity 0.8336147191151597 recall 0.9173020527859238 f1 0.9163826530043206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 1.751028060913086 s\n",
      "Accuracy 0.9214076246334311 precision 0.9203021117804627 specificity 0.8476955808510973 recall 0.9214076246334311 f1 0.9206154274623475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 1.700042486190796 s\n",
      "Accuracy 0.9243401759530792 precision 0.9238974651072404 specificity 0.8549130169883267 recall 0.9243401759530792 f1 0.9240980230635926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 1.7310574054718018 s\n",
      "Accuracy 0.92316715542522 precision 0.9222605698152003 specificity 0.8554600253898867 recall 0.92316715542522 f1 0.9225647779977348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 1.7030003070831299 s\n",
      "Accuracy 0.9085043988269794 precision 0.9080500813262928 specificity 0.8310608235705151 recall 0.9085043988269794 f1 0.9082626705707607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 1.6610004901885986 s\n",
      "Accuracy 0.9131964809384164 precision 0.912131345814837 specificity 0.8416724486073445 recall 0.9131964809384164 f1 0.9125035802185187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 1.711045503616333 s\n",
      "Accuracy 0.9325513196480938 precision 0.9321501319983776 specificity 0.8673325496377022 recall 0.9325513196480938 f1 0.9323293410369499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 1.7020251750946045 s\n",
      "Accuracy 0.9243401759530792 precision 0.9233543409868106 specificity 0.848514230177189 recall 0.9243401759530792 f1 0.9236932578876289\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 1.6870012283325195 s\n",
      "Accuracy 0.9278592375366569 precision 0.927237447874145 specificity 0.8585719762283617 recall 0.9278592375366569 f1 0.927496410449752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 1.7149269580841064 s\n",
      "Accuracy 0.9219941348973607 precision 0.9210926058229154 specificity 0.8502913910467018 recall 0.9219941348973607 f1 0.9214227534430408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 1.6609985828399658 s\n",
      "Accuracy 0.9237536656891495 precision 0.9228712067276981 specificity 0.8492179252417867 recall 0.9237536656891495 f1 0.9232035800170231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 1.7167181968688965 s\n",
      "Accuracy 0.9319648093841643 precision 0.9319648093841643 specificity 0.8658474989372424 recall 0.9319648093841643 f1 0.9319648093841643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 1.7190465927124023 s\n",
      "Accuracy 0.9155425219941349 precision 0.9155425219941349 specificity 0.8364143836500779 recall 0.9155425219941349 f1 0.9155425219941349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 1.6810004711151123 s\n",
      "Accuracy 0.9202346041055719 precision 0.9191239228084561 specificity 0.8439342963967597 recall 0.9202346041055719 f1 0.9194769988114648\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 1.7069995403289795 s\n",
      "Accuracy 0.9190615835777126 precision 0.9198473629813206 specificity 0.8620564067191507 recall 0.9190615835777126 f1 0.9194137807997829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 1.7230477333068848 s\n",
      "Accuracy 0.9266862170087976 precision 0.9270331521927174 specificity 0.8703938220745346 recall 0.9266862170087976 f1 0.926849231154472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 1.7029991149902344 s\n",
      "Accuracy 0.9272727272727272 precision 0.9266144972729095 specificity 0.8590267886696471 recall 0.9272727272727272 f1 0.9268823114650555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 1.691512107849121 s\n",
      "Accuracy 0.9243401759530792 precision 0.9239085136377351 specificity 0.8573421939645849 recall 0.9243401759530792 f1 0.9241037189233615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 1.7109999656677246 s\n",
      "Accuracy 0.9290322580645162 precision 0.9278969040389262 specificity 0.8468329094212825 recall 0.9290322580645162 f1 0.9281880462738344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 1.692533016204834 s\n",
      "Accuracy 0.9249266862170088 precision 0.9248013706312412 specificity 0.8657579356656253 recall 0.9249266862170088 f1 0.9248623731454116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 1.6389992237091064 s\n",
      "Accuracy 0.9143695014662757 precision 0.9129372549213567 specificity 0.8266408409207685 recall 0.9143695014662757 f1 0.913369567300761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 1.692051887512207 s\n",
      "Accuracy 0.9173020527859238 precision 0.9162633032712556 specificity 0.8262853684154384 recall 0.9173020527859238 f1 0.9166850958447466\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 1.7140278816223145 s\n",
      "Accuracy 0.9272727272727272 precision 0.9275443510737629 specificity 0.8709227123654281 recall 0.9272727272727272 f1 0.9274018396043278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 1.7190001010894775 s\n",
      "Accuracy 0.9026392961876832 precision 0.9020837299056871 specificity 0.8339136845227993 recall 0.9026392961876832 f1 0.9023368231106824\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 1.685046911239624 s\n",
      "Accuracy 0.9167155425219942 precision 0.9165738517193821 specificity 0.8496446107347108 recall 0.9167155425219942 f1 0.9166430613545535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 1.6950170993804932 s\n",
      "Accuracy 0.9348973607038124 precision 0.9353736804247103 specificity 0.8813981573343331 recall 0.9348973607038124 f1 0.9351142045257493\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 1.724043607711792 s\n",
      "Accuracy 0.9120234604105572 precision 0.911003617585244 specificity 0.8319649050240135 recall 0.9120234604105572 f1 0.9114085213350204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 1.7240402698516846 s\n",
      "Accuracy 0.9202346041055719 precision 0.9206942729833332 specificity 0.8583292202687873 recall 0.9202346041055719 f1 0.9204495530726581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 1.780001163482666 s\n",
      "Accuracy 0.9155425219941349 precision 0.9157043702900004 specificity 0.8420695953106722 recall 0.9155425219941349 f1 0.9156217795082515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 1.67099928855896 s\n",
      "Accuracy 0.9296187683284457 precision 0.9290324659731528 specificity 0.869484621976962 recall 0.9296187683284457 f1 0.9292654440931117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 1.6490278244018555 s\n",
      "Accuracy 0.9290322580645162 precision 0.9289674394400752 specificity 0.8666934390084086 recall 0.9290322580645162 f1 0.9289994204728381\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 1.6590430736541748 s\n",
      "Accuracy 0.9302052785923753 precision 0.9314331576742443 specificity 0.875536150569128 recall 0.9302052785923753 f1 0.9307217834923593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 1.669999122619629 s\n",
      "Accuracy 0.9348973607038124 precision 0.9347230151403519 specificity 0.8754303728117488 recall 0.9348973607038124 f1 0.9348062661792109\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 1.6948180198669434 s\n",
      "Accuracy 0.9225806451612903 precision 0.9227119272790408 specificity 0.867491068944991 recall 0.9225806451612903 f1 0.9226446628101058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 1.7035088539123535 s\n",
      "Accuracy 0.9266862170087976 precision 0.9262105537590593 specificity 0.8679606565854444 recall 0.9266862170087976 f1 0.9264150151016217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 1.7250196933746338 s\n",
      "Accuracy 0.9237536656891495 precision 0.9246949039966068 specificity 0.8692117022762184 recall 0.9237536656891495 f1 0.9241645975379911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 1.7380006313323975 s\n",
      "Accuracy 0.9173020527859238 precision 0.9168257838676155 specificity 0.8446451503377499 recall 0.9173020527859238 f1 0.9170435997534415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 1.7019984722137451 s\n",
      "Accuracy 0.9225806451612903 precision 0.9219694872140258 specificity 0.8515259671806162 recall 0.9225806451612903 f1 0.922232933596886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 1.7040481567382812 s\n",
      "Accuracy 0.9278592375366569 precision 0.9276816942468334 specificity 0.8704313607539415 recall 0.9278592375366569 f1 0.92776671860341\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 1.7193186283111572 s\n",
      "Accuracy 0.9173020527859238 precision 0.9186397834957878 specificity 0.8720600467751112 recall 0.9173020527859238 f1 0.9178576997195894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 1.7320005893707275 s\n",
      "Accuracy 0.9237536656891495 precision 0.9226113711574759 specificity 0.8488782520856191 recall 0.9237536656891495 f1 0.9228534934583942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 1.638000726699829 s\n",
      "Accuracy 0.9243401759530792 precision 0.9239579596887824 specificity 0.8680035740469209 recall 0.9243401759530792 f1 0.9241292076597813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 1.698997974395752 s\n",
      "Accuracy 0.9237536656891495 precision 0.9241847170256513 specificity 0.867017125778595 recall 0.9237536656891495 f1 0.923954311618936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 1.725999116897583 s\n",
      "Accuracy 0.9272727272727272 precision 0.9263163897284118 specificity 0.8595471256684493 recall 0.9272727272727272 f1 0.9265538994772348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 1.7089996337890625 s\n",
      "Accuracy 0.9114369501466275 precision 0.9107806329238269 specificity 0.8308848552279148 recall 0.9114369501466275 f1 0.9110753978107543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 1.749000072479248 s\n",
      "Accuracy 0.9278592375366569 precision 0.9270450280291724 specificity 0.8648173327005076 recall 0.9278592375366569 f1 0.9273024475785351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 1.74204421043396 s\n",
      "Accuracy 0.9249266862170088 precision 0.9257522615948105 specificity 0.8819272785316928 recall 0.9249266862170088 f1 0.9252820496008186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 1.6949992179870605 s\n",
      "Accuracy 0.9190615835777126 precision 0.9189245427680026 specificity 0.8542275861360398 recall 0.9190615835777126 f1 0.9189914214447028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 1.676999568939209 s\n",
      "Accuracy 0.910850439882698 precision 0.9097893665293236 specificity 0.83550640297302 recall 0.910850439882698 f1 0.9101895820707129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 1.7180004119873047 s\n",
      "Accuracy 0.9225806451612903 precision 0.923558859881686 specificity 0.8644314719186489 recall 0.9225806451612903 f1 0.9230096639886693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 1.7070212364196777 s\n",
      "Accuracy 0.9131964809384164 precision 0.9120385781792989 specificity 0.8388710107733203 recall 0.9131964809384164 f1 0.9124222576001967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 1.647998332977295 s\n",
      "Accuracy 0.9290322580645162 precision 0.9297673206789276 specificity 0.8858561495068183 recall 0.9290322580645162 f1 0.9293506138442439\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 1.694026231765747 s\n",
      "Accuracy 0.9319648093841643 precision 0.9315214166952532 specificity 0.867996192858207 recall 0.9319648093841643 f1 0.9317154572181546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 1.68399977684021 s\n",
      "Accuracy 0.9167155425219942 precision 0.9160273023014172 specificity 0.8513267368897706 recall 0.9167155425219942 f1 0.9163135209830782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 1.6749999523162842 s\n",
      "Accuracy 0.9243401759530792 precision 0.9253086659805384 specificity 0.8762536937787215 recall 0.9243401759530792 f1 0.9247557142336709\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 1.7639999389648438 s\n",
      "Accuracy 0.9319648093841643 precision 0.9319648093841643 specificity 0.8741583197795125 recall 0.9319648093841643 f1 0.9319648093841644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 1.7645080089569092 s\n",
      "Accuracy 0.9120234604105572 precision 0.9106126938151399 specificity 0.8278663313144825 recall 0.9120234604105572 f1 0.9110398240946204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 1.767043113708496 s\n",
      "Accuracy 0.9255131964809384 precision 0.9255794979063903 specificity 0.8665036102417507 recall 0.9255131964809384 f1 0.9255459303443571\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 1.7735307216644287 s\n",
      "Accuracy 0.9255131964809384 precision 0.9264360403106326 specificity 0.8616639134537902 recall 0.9255131964809384 f1 0.9259223605586814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 1.7369999885559082 s\n",
      "Accuracy 0.9155425219941349 precision 0.9155425219941349 specificity 0.8480514049348971 recall 0.9155425219941349 f1 0.9155425219941349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 1.6840007305145264 s\n",
      "Accuracy 0.9225806451612903 precision 0.9229832379321369 specificity 0.8724471790315844 recall 0.9225806451612903 f1 0.9227675002427583\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 1.679999828338623 s\n",
      "Accuracy 0.9173020527859238 precision 0.9175148303243643 specificity 0.8588068086887913 recall 0.9173020527859238 f1 0.9174048279799275\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 1.7520275115966797 s\n",
      "Accuracy 0.9249266862170088 precision 0.9258356627763495 specificity 0.8734632673423384 recall 0.9249266862170088 f1 0.9253218043556651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 1.7660009860992432 s\n",
      "Accuracy 0.9155425219941349 precision 0.9161590043003528 specificity 0.8580947049764255 recall 0.9155425219941349 f1 0.915825181382402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 1.8019993305206299 s\n",
      "Accuracy 0.9337243401759531 precision 0.9328520984818347 specificity 0.8550914944943129 recall 0.9337243401759531 f1 0.9331571264123012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 1.7190003395080566 s\n",
      "Accuracy 0.9131964809384164 precision 0.9137611812948021 specificity 0.8297664820245465 recall 0.9131964809384164 f1 0.9134635196723875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 1.8160011768341064 s\n",
      "Accuracy 0.9173020527859238 precision 0.9164266559729729 specificity 0.8442306811122475 recall 0.9173020527859238 f1 0.9167717613392641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 1.7680227756500244 s\n",
      "Accuracy 0.9196480938416423 precision 0.9188299733565082 specificity 0.8511366769431286 recall 0.9196480938416423 f1 0.9191468321673989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 1.7239177227020264 s\n",
      "Accuracy 0.9208211143695014 precision 0.9199499181170736 specificity 0.8457018741362456 recall 0.9208211143695014 f1 0.920290853588573\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 1.753000259399414 s\n",
      "Accuracy 0.9260997067448681 precision 0.9262347734953917 specificity 0.8669936920769608 recall 0.9260997067448681 f1 0.9261655642526853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 1.7380001544952393 s\n",
      "Accuracy 0.9255131964809384 precision 0.9255816141238523 specificity 0.8635203771673876 recall 0.9255131964809384 f1 0.9255469839324879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 1.8070001602172852 s\n",
      "Accuracy 0.9120234604105572 precision 0.9116289635274167 specificity 0.8474171299790159 recall 0.9120234604105572 f1 0.9118119548331673\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 1.680999994277954 s\n",
      "Accuracy 0.9313782991202346 precision 0.9307119878635985 specificity 0.8639827032532781 recall 0.9313782991202346 f1 0.9309720378171135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 1.7079992294311523 s\n",
      "Accuracy 0.9208211143695014 precision 0.9207555501438701 specificity 0.8612221860621445 recall 0.9208211143695014 f1 0.9207879250935818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 1.7379992008209229 s\n",
      "Accuracy 0.9208211143695014 precision 0.9207520751576435 specificity 0.8562776039056874 recall 0.9208211143695014 f1 0.9207861807489227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 1.7569994926452637 s\n",
      "Accuracy 0.9196480938416423 precision 0.9191668989989747 specificity 0.8445436513570678 recall 0.9196480938416423 f1 0.9193867965153159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 1.751042366027832 s\n",
      "Accuracy 0.9190615835777126 precision 0.9182454830015362 specificity 0.8468612851842873 recall 0.9190615835777126 f1 0.9185723812287103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 1.7080228328704834 s\n",
      "Accuracy 0.9161290322580645 precision 0.9165285164258562 specificity 0.8494307188329707 recall 0.9161290322580645 f1 0.9163184995899727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 1.781019687652588 s\n",
      "Accuracy 0.9190615835777126 precision 0.9201589547630603 specificity 0.8690564672742596 recall 0.9190615835777126 f1 0.9195319186370602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 1.7439990043640137 s\n",
      "Accuracy 0.9278592375366569 precision 0.9269269708160628 specificity 0.8539630337278524 recall 0.9278592375366569 f1 0.9272374952195589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 1.721999168395996 s\n",
      "Accuracy 0.9260997067448681 precision 0.925182875243355 specificity 0.8460078017198972 recall 0.9260997067448681 f1 0.9255291331050217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 1.7200002670288086 s\n",
      "Accuracy 0.9302052785923753 precision 0.9309810767732584 specificity 0.8822200290331564 recall 0.9302052785923753 f1 0.9305426693578482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 1.6939988136291504 s\n",
      "Accuracy 0.9225806451612903 precision 0.9223201862651477 specificity 0.8572050564694417 recall 0.9225806451612903 f1 0.9224437455387619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 1.6770007610321045 s\n",
      "Accuracy 0.9173020527859238 precision 0.9183459037919426 specificity 0.8636941157964517 recall 0.9173020527859238 f1 0.9177562457902912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 1.7099997997283936 s\n",
      "Accuracy 0.9237536656891495 precision 0.9233344865277118 specificity 0.846481162988156 recall 0.9237536656891495 f1 0.9235284208862959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 1.7100186347961426 s\n",
      "Accuracy 0.918475073313783 precision 0.9191860576236935 specificity 0.8593491180535484 recall 0.918475073313783 f1 0.9187975147558047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 1.746999979019165 s\n",
      "Accuracy 0.9319648093841643 precision 0.9319648093841643 specificity 0.875557564266507 recall 0.9319648093841643 f1 0.9319648093841643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 1.7560019493103027 s\n",
      "Accuracy 0.9243401759530792 precision 0.9242729191165349 specificity 0.8607131743526972 recall 0.9243401759530792 f1 0.924306127633845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 1.706998348236084 s\n",
      "Accuracy 0.9155425219941349 precision 0.9160180768799212 specificity 0.8517203247755543 recall 0.9155425219941349 f1 0.9157656557691058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 1.7539985179901123 s\n",
      "Accuracy 0.9196480938416423 precision 0.9214389468122781 specificity 0.8728844403187421 recall 0.9196480938416423 f1 0.920366606815532\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 1.7220191955566406 s\n",
      "Accuracy 0.9219941348973607 precision 0.9219236431681296 specificity 0.8548033775814164 recall 0.9219941348973607 f1 0.9219584689679013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 1.7303602695465088 s\n",
      "Accuracy 0.9202346041055719 precision 0.9196440360164235 specificity 0.8538570319631777 recall 0.9202346041055719 f1 0.9198982760193555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 1.706571102142334 s\n",
      "Accuracy 0.9155425219941349 precision 0.9163643547688959 specificity 0.8548947846878676 recall 0.9155425219941349 f1 0.9159129452491254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 1.7187902927398682 s\n",
      "Accuracy 0.9243401759530792 precision 0.9253546757901597 specificity 0.8719195237720544 recall 0.9243401759530792 f1 0.9247775755087524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 1.6923389434814453 s\n",
      "Accuracy 0.918475073313783 precision 0.9173664169259949 specificity 0.8417198523126296 recall 0.918475073313783 f1 0.9177374074733762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 1.6980259418487549 s\n",
      "Accuracy 0.9202346041055719 precision 0.9200894566395926 specificity 0.8489279512441434 recall 0.9202346041055719 f1 0.9201603447893889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 1.673999547958374 s\n",
      "Accuracy 0.9096774193548387 precision 0.9092421208750465 specificity 0.836311348056243 recall 0.9096774193548387 f1 0.9094452893620428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 1.724998950958252 s\n",
      "Accuracy 0.9131964809384164 precision 0.9124319237589452 specificity 0.8504973028056677 recall 0.9131964809384164 f1 0.9127372841161566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 1.7280004024505615 s\n",
      "Accuracy 0.9096774193548387 precision 0.9083239800852358 specificity 0.8278341611528508 recall 0.9096774193548387 f1 0.9087669838000114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 1.7120003700256348 s\n",
      "Accuracy 0.9131964809384164 precision 0.9117931186307026 specificity 0.8247936663926425 recall 0.9131964809384164 f1 0.9122533699043166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 1.7009999752044678 s\n",
      "Accuracy 0.9249266862170088 precision 0.9245477396503788 specificity 0.8572946795975322 recall 0.9249266862170088 f1 0.9247219592470195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 1.6852045059204102 s\n",
      "Accuracy 0.9208211143695014 precision 0.9208896293165058 specificity 0.8606984413436026 recall 0.9208211143695014 f1 0.9208549627597138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 1.730039358139038 s\n",
      "Accuracy 0.9290322580645162 precision 0.9280716276387866 specificity 0.8555668270447964 recall 0.9290322580645162 f1 0.9283615853577396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 1.594998836517334 s\n",
      "Accuracy 0.9237536656891495 precision 0.9230749402990129 specificity 0.8551540290772524 recall 0.9237536656891495 f1 0.9233539552900507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 1.5799992084503174 s\n",
      "Accuracy 0.918475073313783 precision 0.9190592713177843 specificity 0.8497764221495088 recall 0.918475073313783 f1 0.9187466164781909\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 1.7380003929138184 s\n",
      "Accuracy 0.9079178885630499 precision 0.9073137393382308 specificity 0.8381423084547601 recall 0.9079178885630499 f1 0.907583868726253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 1.7470266819000244 s\n",
      "Accuracy 0.9202346041055719 precision 0.9194612636858245 specificity 0.8521534277617074 recall 0.9202346041055719 f1 0.9197674309499638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 1.7600009441375732 s\n",
      "Accuracy 0.9149560117302052 precision 0.9148823754815497 specificity 0.8465389150844341 recall 0.9149560117302052 f1 0.9149187857459462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 1.7039988040924072 s\n",
      "Accuracy 0.9225806451612903 precision 0.9231766220703931 specificity 0.8663048820527605 recall 0.9225806451612903 f1 0.9228522888816166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 1.6855101585388184 s\n",
      "Accuracy 0.9225806451612903 precision 0.9224340442594979 specificity 0.8489958911605543 recall 0.9225806451612903 f1 0.9225056264066016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 1.640998125076294 s\n",
      "Accuracy 0.9243401759530792 precision 0.924846215211065 specificity 0.8686142707669605 recall 0.9243401759530792 f1 0.9245729214543948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 1.702998161315918 s\n",
      "Accuracy 0.9360703812316715 precision 0.9352749516836907 specificity 0.8634231639520425 recall 0.9360703812316715 f1 0.9355427697006076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 1.6499991416931152 s\n",
      "Accuracy 0.9278592375366569 precision 0.9279237332540765 specificity 0.8703821384416985 recall 0.9278592375366569 f1 0.9278910659465176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 1.6800010204315186 s\n",
      "Accuracy 0.92316715542522 precision 0.9243561867311119 specificity 0.8729396931112962 recall 0.92316715542522 f1 0.9236696441125182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 1.6599998474121094 s\n",
      "Accuracy 0.9202346041055719 precision 0.919199376763127 specificity 0.8402483769656445 recall 0.9202346041055719 f1 0.9195794396247015\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 1.6905109882354736 s\n",
      "Accuracy 0.9102639296187683 precision 0.9094816905587504 specificity 0.8293830428103244 recall 0.9102639296187683 f1 0.9098232239919521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 1.7280001640319824 s\n",
      "Accuracy 0.9237536656891495 precision 0.9251536614508875 specificity 0.8801508333047526 recall 0.9237536656891495 f1 0.9243233261647569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 1.7069997787475586 s\n",
      "Accuracy 0.930791788856305 precision 0.9309185257789833 specificity 0.8755521500901798 recall 0.930791788856305 f1 0.9308534649350545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 1.7345128059387207 s\n",
      "Accuracy 0.9214076246334311 precision 0.9200230065741923 specificity 0.8342262966982091 recall 0.9214076246334311 f1 0.920327456845329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 1.7430427074432373 s\n",
      "Accuracy 0.9173020527859238 precision 0.9168747389476066 specificity 0.8551211407806948 recall 0.9173020527859238 f1 0.9170687353203055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 1.6799993515014648 s\n",
      "Accuracy 0.9260997067448681 precision 0.9250608610521622 specificity 0.8464166235661391 recall 0.9260997067448681 f1 0.9254062034963466\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 1.7060003280639648 s\n",
      "Accuracy 0.9237536656891495 precision 0.9227230541963398 specificity 0.8508434148049437 recall 0.9237536656891495 f1 0.9230351680924002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 1.6879985332489014 s\n",
      "Accuracy 0.9214076246334311 precision 0.9206415658251029 specificity 0.8533728137040746 recall 0.9214076246334311 f1 0.9209436897145035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 1.7859985828399658 s\n",
      "Accuracy 0.9255131964809384 precision 0.9252275253527886 specificity 0.8685094507709563 recall 0.9255131964809384 f1 0.9253601180711103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 1.6940009593963623 s\n",
      "Accuracy 0.9249266862170088 precision 0.9254555437579786 specificity 0.8786965910904792 recall 0.9249266862170088 f1 0.9251654561437104\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 1.643998622894287 s\n",
      "Accuracy 0.9266862170087976 precision 0.9260606599405943 specificity 0.8576504338753458 recall 0.9266862170087976 f1 0.926321856755128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 1.698000431060791 s\n",
      "Accuracy 0.9266862170087976 precision 0.9261236801070074 specificity 0.8527922072003421 recall 0.9266862170087976 f1 0.9263697274848195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 1.7439994812011719 s\n",
      "Accuracy 0.9178885630498533 precision 0.9178885630498533 specificity 0.8595365428760285 recall 0.9178885630498533 f1 0.9178885630498533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 1.639000654220581 s\n",
      "Accuracy 0.9237536656891495 precision 0.9237536656891495 specificity 0.8628241850106708 recall 0.9237536656891495 f1 0.9237536656891494\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 1.6510000228881836 s\n",
      "Accuracy 0.918475073313783 precision 0.9177215688125437 specificity 0.8363361644053691 recall 0.918475073313783 f1 0.9180466498950668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 1.7590293884277344 s\n",
      "Accuracy 0.9225806451612903 precision 0.9227236225492395 specificity 0.8594123850541323 recall 0.9225806451612903 f1 0.9226504637273679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 1.6949996948242188 s\n",
      "Accuracy 0.9143695014662757 precision 0.9152930600778375 specificity 0.8406517636221036 recall 0.9143695014662757 f1 0.914789417184038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 1.656998872756958 s\n",
      "Accuracy 0.930791788856305 precision 0.9313683858334615 specificity 0.8751731234243968 recall 0.930791788856305 f1 0.931052617248689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 1.7109990119934082 s\n",
      "Accuracy 0.9120234604105572 precision 0.9106103296201623 specificity 0.8304518315930367 recall 0.9120234604105572 f1 0.9109969707924075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 1.726508378982544 s\n",
      "Accuracy 0.9343108504398827 precision 0.9340211672139583 specificity 0.8839678228971565 recall 0.9343108504398827 f1 0.9341510598737637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 1.6915161609649658 s\n",
      "Accuracy 0.930791788856305 precision 0.9304363633142554 specificity 0.8657450076804916 recall 0.930791788856305 f1 0.9305984962244764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 1.7025139331817627 s\n",
      "Accuracy 0.9149560117302052 precision 0.9136370357260474 specificity 0.835712454724765 recall 0.9149560117302052 f1 0.9139972961389528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 1.7419986724853516 s\n",
      "Accuracy 0.9255131964809384 precision 0.9253116091800736 specificity 0.8574665457359016 recall 0.9255131964809384 f1 0.9254085544954095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 1.684999942779541 s\n",
      "Accuracy 0.910850439882698 precision 0.9093579846574547 specificity 0.818035053708678 recall 0.910850439882698 f1 0.9098623965226734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 1.6969997882843018 s\n",
      "Accuracy 0.9202346041055719 precision 0.919646569178307 specificity 0.8542483380454189 recall 0.9202346041055719 f1 0.9198995953516311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 1.6800012588500977 s\n",
      "Accuracy 0.9225806451612903 precision 0.922192004753844 specificity 0.8538285430718133 recall 0.9225806451612903 f1 0.9223711894630575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 1.7045905590057373 s\n",
      "Accuracy 0.9278592375366569 precision 0.926893558333347 specificity 0.8578702337290828 recall 0.9278592375366569 f1 0.9271527122661898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 1.7750003337860107 s\n",
      "Accuracy 0.9255131964809384 precision 0.9248172527630507 specificity 0.8585829181236508 recall 0.9255131964809384 f1 0.9250943213995526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 1.7220003604888916 s\n",
      "Accuracy 0.9266862170087976 precision 0.9270055200754382 specificity 0.8777257351047864 recall 0.9266862170087976 f1 0.9268357078895866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 1.6960010528564453 s\n",
      "Accuracy 0.9255131964809384 precision 0.9252004094907691 specificity 0.8604447462682321 recall 0.9255131964809384 f1 0.9253462572424173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 1.6820309162139893 s\n",
      "Accuracy 0.9149560117302052 precision 0.9153638585136192 specificity 0.8464076246334311 recall 0.9149560117302052 f1 0.9151496602803453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 1.653996467590332 s\n",
      "Accuracy 0.9266862170087976 precision 0.9294586583995944 specificity 0.8913202176767694 recall 0.9266862170087976 f1 0.927681049346752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 1.7420005798339844 s\n",
      "Accuracy 0.9302052785923753 precision 0.930548267958607 specificity 0.8737168720014283 recall 0.9302052785923753 f1 0.9303661110469751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 1.6979992389678955 s\n",
      "Accuracy 0.9243401759530792 precision 0.9237185511954047 specificity 0.8574357024894659 recall 0.9243401759530792 f1 0.9239787389948497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 1.7480006217956543 s\n",
      "Accuracy 0.9049853372434018 precision 0.9041126537908375 specificity 0.8229922279166114 recall 0.9049853372434018 f1 0.9044911517848113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 1.7409999370574951 s\n",
      "Accuracy 0.9272727272727272 precision 0.9275695876232071 specificity 0.8622214550942461 recall 0.9272727272727272 f1 0.9274142394619891\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 1.690000057220459 s\n",
      "Accuracy 0.9214076246334311 precision 0.921554420922865 specificity 0.8560537116748885 recall 0.9214076246334311 f1 0.9214793501566636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 1.726999282836914 s\n",
      "Accuracy 0.9219941348973607 precision 0.9233619310980026 specificity 0.873918513667718 recall 0.9219941348973607 f1 0.9225610327512128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 1.7210209369659424 s\n",
      "Accuracy 0.9302052785923753 precision 0.9293150096637752 specificity 0.8581723401824474 recall 0.9302052785923753 f1 0.9296037555376221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 1.6659996509552002 s\n",
      "Accuracy 0.9260997067448681 precision 0.9252366882600753 specificity 0.8577704871846216 recall 0.9260997067448681 f1 0.9255321719967985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 1.6459975242614746 s\n",
      "Accuracy 0.9249266862170088 precision 0.9244287587174461 specificity 0.8546734106723732 recall 0.9249266862170088 f1 0.9246504424217035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 1.6590003967285156 s\n",
      "Accuracy 0.9237536656891495 precision 0.9226319247472077 specificity 0.8388202491404266 recall 0.9237536656891495 f1 0.9230178068282366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 1.7092242240905762 s\n",
      "Accuracy 0.910850439882698 precision 0.9095719440578481 specificity 0.8291234090012097 recall 0.910850439882698 f1 0.9100136514358088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 1.71700119972229 s\n",
      "Accuracy 0.9219941348973607 precision 0.921788552068064 specificity 0.8538065698947569 recall 0.9219941348973607 f1 0.9218875614194217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 1.8159990310668945 s\n",
      "Accuracy 0.9208211143695014 precision 0.91996352587481 specificity 0.8542616062187338 recall 0.9208211143695014 f1 0.920274330906134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 1.6949987411499023 s\n",
      "Accuracy 0.9161290322580645 precision 0.9155348916823322 specificity 0.8433964409133005 recall 0.9161290322580645 f1 0.9157986195564006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 1.7230002880096436 s\n",
      "Accuracy 0.9225806451612903 precision 0.9224387377661999 specificity 0.8524726808768824 recall 0.9225806451612903 f1 0.9225079924400166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 1.6899991035461426 s\n",
      "Accuracy 0.9208211143695014 precision 0.9219022970196011 specificity 0.8628035132372512 recall 0.9208211143695014 f1 0.9212917437394337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 1.7720003128051758 s\n",
      "Accuracy 0.9196480938416423 precision 0.9185738947601394 specificity 0.8396870740935095 recall 0.9196480938416423 f1 0.918958326757786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 1.7840001583099365 s\n",
      "Accuracy 0.92316715542522 precision 0.9223245117224355 specificity 0.8494650376148072 recall 0.92316715542522 f1 0.9226505639233398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 1.7549996376037598 s\n",
      "Accuracy 0.9161290322580645 precision 0.9156727767549827 specificity 0.8484344859639902 recall 0.9161290322580645 f1 0.9158809977805021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 1.7930006980895996 s\n",
      "Accuracy 0.9319648093841643 precision 0.9322094471555181 specificity 0.8829944249299088 recall 0.9319648093841643 f1 0.9320804627471295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 1.7229993343353271 s\n",
      "Accuracy 0.92316715542522 precision 0.9236880622683625 specificity 0.8650182002135077 recall 0.92316715542522 f1 0.9234072784553985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 1.6949992179870605 s\n",
      "Accuracy 0.9284457478005865 precision 0.927857943027683 specificity 0.8688814438762565 recall 0.9284457478005865 f1 0.9280921309011911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 1.7320001125335693 s\n",
      "Accuracy 0.9178885630498533 precision 0.918910035531836 specificity 0.85633189375253 recall 0.9178885630498533 f1 0.9183399764538364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 1.8670337200164795 s\n",
      "Accuracy 0.9225806451612903 precision 0.9220607716429639 specificity 0.8494998306986964 recall 0.9225806451612903 f1 0.9222934911372287\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 1.7989997863769531 s\n",
      "Accuracy 0.9196480938416423 precision 0.9187070594628128 specificity 0.8376872313907786 recall 0.9196480938416423 f1 0.9190814279461131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 1.699002981185913 s\n",
      "Accuracy 0.9214076246334311 precision 0.9219027679763835 specificity 0.851011103642995 recall 0.9214076246334311 f1 0.9216398000456033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 1.7419962882995605 s\n",
      "Accuracy 0.9149560117302052 precision 0.9144750198103087 specificity 0.8426036933016935 recall 0.9149560117302052 f1 0.9146954298403928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 1.7209997177124023 s\n",
      "Accuracy 0.9260997067448681 precision 0.9266446204894824 specificity 0.8770019591823136 recall 0.9260997067448681 f1 0.926346064253224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 1.744999885559082 s\n",
      "Accuracy 0.9219941348973607 precision 0.9216694607122128 specificity 0.8552726750457139 recall 0.9219941348973607 f1 0.9218213727030677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 1.8110005855560303 s\n",
      "Accuracy 0.9266862170087976 precision 0.9260715414062616 specificity 0.8592430011361052 recall 0.9266862170087976 f1 0.9263275858883141\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 1.6299982070922852 s\n",
      "Accuracy 0.918475073313783 precision 0.9196760906059946 specificity 0.8682016734206951 recall 0.918475073313783 f1 0.9189856536478216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 1.9210262298583984 s\n",
      "Accuracy 0.9196480938416423 precision 0.9187363521910141 specificity 0.8409291382476298 recall 0.9196480938416423 f1 0.9190970150067643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 1.7989990711212158 s\n",
      "Accuracy 0.9214076246334311 precision 0.9215466297807667 specificity 0.8614850956730823 recall 0.9214076246334311 f1 0.921475485000684\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 1.8240525722503662 s\n",
      "Accuracy 0.9102639296187683 precision 0.9103384875333949 specificity 0.8461191767013689 recall 0.9102639296187683 f1 0.9103008130781441\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 1.845000982284546 s\n",
      "Accuracy 0.9173020527859238 precision 0.9168414453157305 specificity 0.8480307833416552 recall 0.9173020527859238 f1 0.9170516410928117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 1.786999225616455 s\n",
      "Accuracy 0.9290322580645162 precision 0.9288467792213608 specificity 0.8671264628090336 recall 0.9290322580645162 f1 0.928935684482528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 2.0155117511749268 s\n",
      "Accuracy 0.9225806451612903 precision 0.9231592241083001 specificity 0.869124906909453 recall 0.9225806451612903 f1 0.9228438562632112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 1.8649451732635498 s\n",
      "Accuracy 0.9161290322580645 precision 0.9167942356147021 specificity 0.8641932937320751 recall 0.9161290322580645 f1 0.9164297146428645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 1.8349981307983398 s\n",
      "Accuracy 0.92316715542522 precision 0.9239884317847881 specificity 0.8717561989134205 recall 0.92316715542522 f1 0.9235284556496344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 1.8289999961853027 s\n",
      "Accuracy 0.9196480938416423 precision 0.9200483952006996 specificity 0.8513963644776829 recall 0.9196480938416423 f1 0.9198377388412168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 1.683000087738037 s\n",
      "Accuracy 0.92316715542522 precision 0.92272060783791 specificity 0.8535923297854676 recall 0.92316715542522 f1 0.9229231940624564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 1.6970553398132324 s\n",
      "Accuracy 0.9243401759530792 precision 0.9241466267469864 specificity 0.8608648151342649 recall 0.9243401759530792 f1 0.9242396361497838\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 1.7140278816223145 s\n",
      "Accuracy 0.9208211143695014 precision 0.9208926456989155 specificity 0.856470723919508 recall 0.9208211143695014 f1 0.9208564650882302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 1.7079994678497314 s\n",
      "Accuracy 0.9260997067448681 precision 0.9257225286515705 specificity 0.8582391139112625 recall 0.9260997067448681 f1 0.9258957611303653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 1.7069995403289795 s\n",
      "Accuracy 0.9079178885630499 precision 0.9085590509197548 specificity 0.8318758938079743 recall 0.9079178885630499 f1 0.9082185278499475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 1.7482779026031494 s\n",
      "Accuracy 0.9225806451612903 precision 0.9236345097364956 specificity 0.8755864963391846 recall 0.9225806451612903 f1 0.9230287687029995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 1.7009992599487305 s\n",
      "Accuracy 0.9237536656891495 precision 0.9234984341320283 specificity 0.85970263647969 recall 0.9237536656891495 f1 0.9236193722134726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 1.730027437210083 s\n",
      "Accuracy 0.9196480938416423 precision 0.9189660117483074 specificity 0.8470760440893921 recall 0.9196480938416423 f1 0.919256586132169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 1.7419977188110352 s\n",
      "Accuracy 0.9302052785923753 precision 0.9302679534112833 specificity 0.8742819381252076 recall 0.9302052785923753 f1 0.930236193932407\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 1.7195122241973877 s\n",
      "Accuracy 0.9225806451612903 precision 0.9239315898436226 specificity 0.8822154848142423 recall 0.9225806451612903 f1 0.9231282020872866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 1.7239999771118164 s\n",
      "Accuracy 0.9266862170087976 precision 0.926752782509729 specificity 0.866800802575689 recall 0.9266862170087976 f1 0.9267190790636247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 1.6299998760223389 s\n",
      "Accuracy 0.9225806451612903 precision 0.9214677385329001 specificity 0.8394934127066743 recall 0.9225806451612903 f1 0.9218512098266571\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 1.7269976139068604 s\n",
      "Accuracy 0.9102639296187683 precision 0.9104820838883598 specificity 0.8519593481860127 recall 0.9102639296187683 f1 0.9103695010299702\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 1.763000726699829 s\n",
      "Accuracy 0.9243401759530792 precision 0.9239157131279401 specificity 0.8589165290277637 recall 0.9243401759530792 f1 0.9241074304517637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 1.7380485534667969 s\n",
      "Accuracy 0.9214076246334311 precision 0.9216743743265646 specificity 0.8688125072517513 recall 0.9214076246334311 f1 0.9215345783334671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 1.7019989490509033 s\n",
      "Accuracy 0.9255131964809384 precision 0.9243719961260857 specificity 0.8397499614137983 recall 0.9255131964809384 f1 0.9247476749107695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 1.731027603149414 s\n",
      "Accuracy 0.9190615835777126 precision 0.9185657854142973 specificity 0.8526965857414323 recall 0.9190615835777126 f1 0.9187874886662607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 1.6819977760314941 s\n",
      "Accuracy 0.9173020527859238 precision 0.9164025418942807 specificity 0.8491729355777738 recall 0.9173020527859238 f1 0.9167354246551368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 1.7230002880096436 s\n",
      "Accuracy 0.9278592375366569 precision 0.9280788864683467 specificity 0.8619768653543061 recall 0.9278592375366569 f1 0.927965153344453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 1.713047742843628 s\n",
      "Accuracy 0.9272727272727272 precision 0.9269036513665467 specificity 0.8607993302983183 recall 0.9272727272727272 f1 0.927072815622392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 1.708885669708252 s\n",
      "Accuracy 0.9208211143695014 precision 0.9207590809424699 specificity 0.8661602939648462 recall 0.9208211143695014 f1 0.9207896974385156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 1.6661429405212402 s\n",
      "Accuracy 0.9196480938416423 precision 0.9198733820307609 specificity 0.8545203928001318 recall 0.9196480938416423 f1 0.91975700443383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 1.6689989566802979 s\n",
      "Accuracy 0.9302052785923753 precision 0.9295722281067369 specificity 0.8575667817235312 recall 0.9302052785923753 f1 0.9298355449203266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 1.7200274467468262 s\n",
      "Accuracy 0.9243401759530792 precision 0.9250179783990375 specificity 0.8682690157985764 recall 0.9243401759530792 f1 0.9246453987183123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 1.7419993877410889 s\n",
      "Accuracy 0.9196480938416423 precision 0.9190917372233965 specificity 0.8512802822870208 recall 0.9196480938416423 f1 0.9193365001516041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 1.7320520877838135 s\n",
      "Accuracy 0.9202346041055719 precision 0.9214414909882509 specificity 0.860315181548735 recall 0.9202346041055719 f1 0.9207564969007077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 1.6938631534576416 s\n",
      "Accuracy 0.9272727272727272 precision 0.9280344825250779 specificity 0.8710818315461024 recall 0.9272727272727272 f1 0.9276112623906192\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 1.7509984970092773 s\n",
      "Accuracy 0.9225806451612903 precision 0.922111048854025 specificity 0.859189606458576 recall 0.9225806451612903 f1 0.9223194962943458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 1.739999771118164 s\n",
      "Accuracy 0.9196480938416423 precision 0.9202031085558623 specificity 0.8561761774776264 recall 0.9196480938416423 f1 0.9199052639645853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 1.7200021743774414 s\n",
      "Accuracy 0.9173020527859238 precision 0.9167649203295236 specificity 0.8535308957610613 recall 0.9173020527859238 f1 0.9170008959105391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 1.7169992923736572 s\n",
      "Accuracy 0.9196480938416423 precision 0.9188978636594829 specificity 0.8499567076565697 recall 0.9196480938416423 f1 0.919203300095901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 1.7049996852874756 s\n",
      "Accuracy 0.9190615835777126 precision 0.9183419934604871 specificity 0.8481270225939445 recall 0.9190615835777126 f1 0.9186422672785679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 1.6440002918243408 s\n",
      "Accuracy 0.9143695014662757 precision 0.912816443868175 specificity 0.8257639283223265 recall 0.9143695014662757 f1 0.9128590061139484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 1.6899993419647217 s\n",
      "Accuracy 0.9260997067448681 precision 0.9248966005846535 specificity 0.8404587348135736 recall 0.9260997067448681 f1 0.9252438462850987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 1.6930274963378906 s\n",
      "Accuracy 0.9202346041055719 precision 0.9191029013556198 specificity 0.8375548153711712 recall 0.9202346041055719 f1 0.9194979051090623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 1.75600004196167 s\n",
      "Accuracy 0.9143695014662757 precision 0.9128617079566016 specificity 0.8294797506951446 recall 0.9143695014662757 f1 0.913079868007307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 1.7219994068145752 s\n",
      "Accuracy 0.9225806451612903 precision 0.9215694063458513 specificity 0.8483904073908545 recall 0.9225806451612903 f1 0.921906876562547\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 1.7150022983551025 s\n",
      "Accuracy 0.9249266862170088 precision 0.9242890439344843 specificity 0.8480724405876945 recall 0.9249266862170088 f1 0.9245644172393286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 1.700998306274414 s\n",
      "Accuracy 0.9161290322580645 precision 0.9157693449610896 specificity 0.8421012401963609 recall 0.9161290322580645 f1 0.9159388115662696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 1.719029426574707 s\n",
      "Accuracy 0.9237536656891495 precision 0.9236298495112282 specificity 0.8662033509739446 recall 0.9237536656891495 f1 0.9236901210937403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 1.7152235507965088 s\n",
      "Accuracy 0.9278592375366569 precision 0.9268222365902768 specificity 0.8521757372440826 recall 0.9278592375366569 f1 0.9271125499776366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 1.7002241611480713 s\n",
      "Accuracy 0.9208211143695014 precision 0.9201147507959294 specificity 0.8439578662878814 recall 0.9208211143695014 f1 0.9204164985930732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 1.5992622375488281 s\n",
      "Accuracy 0.9190615835777126 precision 0.9176513855208304 specificity 0.8343307336244263 recall 0.9190615835777126 f1 0.917868827316547\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 1.6289994716644287 s\n",
      "Accuracy 0.9155425219941349 precision 0.914279492234709 specificity 0.8311747741040388 recall 0.9155425219941349 f1 0.9147080142395643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 1.753000259399414 s\n",
      "Accuracy 0.9126099706744868 precision 0.9115615210176509 specificity 0.8335301180695139 recall 0.9126099706744868 f1 0.9119673234418093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 1.7030003070831299 s\n",
      "Accuracy 0.9249266862170088 precision 0.9241095812660284 specificity 0.8483634370219446 recall 0.9249266862170088 f1 0.9244335283513937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 1.7373387813568115 s\n",
      "Accuracy 0.9343108504398827 precision 0.9338444506079213 specificity 0.8641653678552343 recall 0.9343108504398827 f1 0.9340489534011541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 1.7080020904541016 s\n",
      "Accuracy 0.9032258064516129 precision 0.9031432032426356 specificity 0.8273748357708893 recall 0.9032258064516129 f1 0.9031841089991748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 1.7220532894134521 s\n",
      "Accuracy 0.9325513196480938 precision 0.9319253370203939 specificity 0.8694692404369823 recall 0.9325513196480938 f1 0.9321659879487951\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 1.7299997806549072 s\n",
      "Accuracy 0.9190615835777126 precision 0.9183260698580212 specificity 0.8460212906161684 recall 0.9190615835777126 f1 0.9186339105090183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 1.7239983081817627 s\n",
      "Accuracy 0.9243401759530792 precision 0.9236705770474886 specificity 0.8504486677952084 recall 0.9243401759530792 f1 0.9239535431000477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 1.7080013751983643 s\n",
      "Accuracy 0.92316715542522 precision 0.9240941429114892 specificity 0.8594642083040789 recall 0.92316715542522 f1 0.9235791104928105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 1.7129991054534912 s\n",
      "Accuracy 0.9202346041055719 precision 0.9203817961791501 specificity 0.8550972810961378 recall 0.9202346041055719 f1 0.9203065383857731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 1.6489992141723633 s\n",
      "Accuracy 0.9143695014662757 precision 0.915010146109109 specificity 0.8533501218992128 recall 0.9143695014662757 f1 0.9146640879321768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 1.7230007648468018 s\n",
      "Accuracy 0.9202346041055719 precision 0.9200771187306127 specificity 0.839757266914615 recall 0.9202346041055719 f1 0.9201541276290469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 1.7059988975524902 s\n",
      "Accuracy 0.9266862170087976 precision 0.9271798603900409 specificity 0.8725370137915195 recall 0.9266862170087976 f1 0.926912638623661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 1.7320587635040283 s\n",
      "Accuracy 0.9214076246334311 precision 0.9220139548993831 specificity 0.8638034514192291 recall 0.9214076246334311 f1 0.9216844757986729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 1.7330002784729004 s\n",
      "Accuracy 0.9190615835777126 precision 0.9193368951097916 specificity 0.8644538735998349 recall 0.9190615835777126 f1 0.9191928401141676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 1.7390475273132324 s\n",
      "Accuracy 0.9208211143695014 precision 0.921045843676827 specificity 0.8554775869291998 recall 0.9208211143695014 f1 0.9209297211471782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 1.774000644683838 s\n",
      "Accuracy 0.9202346041055719 precision 0.9198229502748486 specificity 0.8469857164019703 recall 0.9202346041055719 f1 0.9200135944066191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 1.6979990005493164 s\n",
      "Accuracy 0.9196480938416423 precision 0.919072445939728 specificity 0.8479677205016889 recall 0.9196480938416423 f1 0.9193264995350559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 1.7269995212554932 s\n",
      "Accuracy 0.9390029325513196 precision 0.9394819540501123 specificity 0.8967299885038549 recall 0.9390029325513196 f1 0.9392152717460751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 1.689000129699707 s\n",
      "Accuracy 0.9243401759530792 precision 0.9237630373431298 specificity 0.8637970764138185 recall 0.9243401759530792 f1 0.9240020993803043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 1.678835391998291 s\n",
      "Accuracy 0.9255131964809384 precision 0.9263892053085616 specificity 0.8671890231649808 recall 0.9255131964809384 f1 0.925899961538465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 1.5679988861083984 s\n",
      "Accuracy 0.9278592375366569 precision 0.9276658699705754 specificity 0.8626581262029344 recall 0.9278592375366569 f1 0.9277586966467566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 1.661001205444336 s\n",
      "Accuracy 0.9120234604105572 precision 0.912637631933602 specificity 0.8560156426508501 recall 0.9120234604105572 f1 0.912305467847077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 1.5600004196166992 s\n",
      "Accuracy 0.9202346041055719 precision 0.9195149476759679 specificity 0.8485235194912615 recall 0.9202346041055719 f1 0.9198147910832495\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 1.5109989643096924 s\n",
      "Accuracy 0.9196480938416423 precision 0.9194377783377407 specificity 0.850334427656137 recall 0.9196480938416423 f1 0.9195391832494544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 1.598050594329834 s\n",
      "Accuracy 0.9131964809384164 precision 0.9127434760197677 specificity 0.8334929957023107 recall 0.9131964809384164 f1 0.9129550105090917\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 1.5911955833435059 s\n",
      "Accuracy 0.9319648093841643 precision 0.9315663937165999 specificity 0.8767771351381111 recall 0.9319648093841643 f1 0.9317388927511028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 1.6160001754760742 s\n",
      "Accuracy 0.9167155425219942 precision 0.9155350426588008 specificity 0.8378516189674298 recall 0.9167155425219942 f1 0.915924513464912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 1.590998649597168 s\n",
      "Accuracy 0.9225806451612903 precision 0.9214298368551402 specificity 0.8361384329295155 recall 0.9225806451612903 f1 0.9218304576144035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 1.536611557006836 s\n",
      "Accuracy 0.9260997067448681 precision 0.9260997067448681 specificity 0.8593517809033375 recall 0.9260997067448681 f1 0.9260997067448681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 1.609116792678833 s\n",
      "Accuracy 0.9173020527859238 precision 0.9165524368105012 specificity 0.836526998112268 recall 0.9173020527859238 f1 0.9168760692700304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 1.5809996128082275 s\n",
      "Accuracy 0.9214076246334311 precision 0.9207638507927784 specificity 0.8459486756115807 recall 0.9214076246334311 f1 0.921043243580171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 1.5929992198944092 s\n",
      "Accuracy 0.9272727272727272 precision 0.9261727477184439 specificity 0.8454017893584539 recall 0.9272727272727272 f1 0.9265098756645752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 1.5829999446868896 s\n",
      "Accuracy 0.9249266862170088 precision 0.9260978280410581 specificity 0.883178850473011 recall 0.9249266862170088 f1 0.9254098670337342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 1.573007345199585 s\n",
      "Accuracy 0.9219941348973607 precision 0.9223507306471888 specificity 0.8647717844953016 recall 0.9219941348973607 f1 0.9221621882662785\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 1.5890114307403564 s\n",
      "Accuracy 0.9219941348973607 precision 0.9222173948018478 specificity 0.8568558550300774 recall 0.9219941348973607 f1 0.9221019872492687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 1.581998586654663 s\n",
      "Accuracy 0.9196480938416423 precision 0.9205174101501791 specificity 0.8636441236225171 recall 0.9196480938416423 f1 0.9200334630282877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 1.5959985256195068 s\n",
      "Accuracy 0.9296187683284457 precision 0.9292885686042167 specificity 0.8716763634751606 recall 0.9296187683284457 f1 0.9294385985671538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 1.5980420112609863 s\n",
      "Accuracy 0.9348973607038124 precision 0.9349563477460232 specificity 0.8821460979591654 recall 0.9348973607038124 f1 0.9349264268503223\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 1.7000012397766113 s\n",
      "Accuracy 0.9272727272727272 precision 0.9265153137099279 specificity 0.8560589955990477 recall 0.9272727272727272 f1 0.9268099590176475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 1.5981674194335938 s\n",
      "Accuracy 0.9243401759530792 precision 0.9234135950171006 specificity 0.8539134091562546 recall 0.9243401759530792 f1 0.9237256396241132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 1.5910084247589111 s\n",
      "Accuracy 0.9296187683284457 precision 0.929307288486963 specificity 0.8763450028438853 recall 0.9296187683284457 f1 0.929448233507502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 1.583855390548706 s\n",
      "Accuracy 0.918475073313783 precision 0.9185469827087333 specificity 0.8546003266393106 recall 0.918475073313783 f1 0.9185106183150729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 1.584686279296875 s\n",
      "Accuracy 0.910850439882698 precision 0.9102769243537168 specificity 0.8344335893081287 recall 0.910850439882698 f1 0.9105376380229282\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 1.624000072479248 s\n",
      "Accuracy 0.9208211143695014 precision 0.9211981652944846 specificity 0.8585020114475304 recall 0.9208211143695014 f1 0.9209992741794479\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 1.5837836265563965 s\n",
      "Accuracy 0.9290322580645162 precision 0.9289622599862912 specificity 0.859068334861266 recall 0.9290322580645162 f1 0.9289968186562078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 1.6101548671722412 s\n",
      "Accuracy 0.9284457478005865 precision 0.9278883295442724 specificity 0.8621068368696453 recall 0.9284457478005865 f1 0.9281243780213642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 1.632035732269287 s\n",
      "Accuracy 0.9290322580645162 precision 0.9289742846027508 specificity 0.8765057772113155 recall 0.9290322580645162 f1 0.9290028590137491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 1.5099992752075195 s\n",
      "Accuracy 0.9243401759530792 precision 0.9236936182097473 specificity 0.8538195727949048 recall 0.9243401759530792 f1 0.9239656444415026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 1.589510440826416 s\n",
      "Accuracy 0.9266862170087976 precision 0.9267543736822185 specificity 0.8645475492249686 recall 0.9266862170087976 f1 0.9267198711674415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 1.5409772396087646 s\n",
      "Accuracy 0.9266862170087976 precision 0.9265099733212179 specificity 0.870455372284102 recall 0.9266862170087976 f1 0.926594386013467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 1.5819692611694336 s\n",
      "Accuracy 0.918475073313783 precision 0.9179983115613614 specificity 0.8450338717722484 recall 0.918475073313783 f1 0.9182162135471864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 1.552999496459961 s\n",
      "Accuracy 0.9149560117302052 precision 0.9135609551738584 specificity 0.8306758071000907 recall 0.9149560117302052 f1 0.913954870147115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 1.5794384479522705 s\n",
      "Accuracy 0.9137829912023461 precision 0.914908274059021 specificity 0.8531902313853817 recall 0.9137829912023461 f1 0.9142774960092075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 1.638298749923706 s\n",
      "Accuracy 0.9155425219941349 precision 0.9140089626893145 specificity 0.827361889770571 recall 0.9155425219941349 f1 0.9141068250745669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 1.5959997177124023 s\n",
      "Accuracy 0.9219941348973607 precision 0.9226677695064792 specificity 0.8672003307676932 recall 0.9219941348973607 f1 0.9222978256741136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 1.5750000476837158 s\n",
      "Accuracy 0.9167155425219942 precision 0.915557876483887 specificity 0.8431571878112196 recall 0.9167155425219942 f1 0.9159019944744063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 1.5719995498657227 s\n",
      "Accuracy 0.9120234604105572 precision 0.911745244994655 specificity 0.8454408877148893 recall 0.9120234604105572 f1 0.9118779657541581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 1.5880019664764404 s\n",
      "Accuracy 0.9173020527859238 precision 0.9170726146986311 specificity 0.8397586835280324 recall 0.9173020527859238 f1 0.9171835288447092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 1.5910062789916992 s\n",
      "Accuracy 0.9120234604105572 precision 0.9113622722782133 specificity 0.8396641179614085 recall 0.9120234604105572 f1 0.9116525103154657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 1.575000524520874 s\n",
      "Accuracy 0.9114369501466275 precision 0.9108756204907393 specificity 0.8468302637156615 recall 0.9114369501466275 f1 0.9111243759683637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 1.6320016384124756 s\n",
      "Accuracy 0.9237536656891495 precision 0.9234899322519327 specificity 0.8565427172688305 recall 0.9237536656891495 f1 0.9236150484698862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 1.8169984817504883 s\n",
      "Accuracy 0.9202346041055719 precision 0.9197105533762425 specificity 0.847778801219321 recall 0.9202346041055719 f1 0.91994572324828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 1.6179993152618408 s\n",
      "Accuracy 0.9196480938416423 precision 0.9193156728492814 specificity 0.8518710562541177 recall 0.9196480938416423 f1 0.9194715371767462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 1.6409995555877686 s\n",
      "Accuracy 0.9337243401759531 precision 0.9331037005814198 specificity 0.8704614835788362 recall 0.9337243401759531 f1 0.9333411917279603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 1.5775573253631592 s\n",
      "Accuracy 0.918475073313783 precision 0.9176699651931536 specificity 0.8428098388133956 recall 0.918475073313783 f1 0.9180018973971718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 1.6215147972106934 s\n",
      "Accuracy 0.9214076246334311 precision 0.920752605657451 specificity 0.8441582345641465 recall 0.9214076246334311 f1 0.9210373809408521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 1.5629980564117432 s\n",
      "Accuracy 0.9290322580645162 precision 0.9297968036599036 specificity 0.8825871426578104 recall 0.9290322580645162 f1 0.9293646670906709\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 1.568000316619873 s\n",
      "Accuracy 0.9313782991202346 precision 0.9314371137921016 specificity 0.8803450045199281 recall 0.9313782991202346 f1 0.9314072901630664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 1.5595309734344482 s\n",
      "Accuracy 0.9249266862170088 precision 0.9247863768494987 specificity 0.8547969101520417 recall 0.9249266862170088 f1 0.9248548115155925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 1.5610477924346924 s\n",
      "Accuracy 0.9255131964809384 precision 0.9247854454936166 specificity 0.8545864037316654 recall 0.9255131964809384 f1 0.9250774307828321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 1.5909998416900635 s\n",
      "Accuracy 0.92316715542522 precision 0.9236470874223615 specificity 0.8726582336999582 recall 0.92316715542522 f1 0.9233873499538238\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 1.5689976215362549 s\n",
      "Accuracy 0.9173020527859238 precision 0.9171069279537334 specificity 0.8564646481390504 recall 0.9173020527859238 f1 0.917200877357806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 1.5799996852874756 s\n",
      "Accuracy 0.9284457478005865 precision 0.9273825541878719 specificity 0.8531732220695512 recall 0.9284457478005865 f1 0.9276233129470625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 1.5550003051757812 s\n",
      "Accuracy 0.9190615835777126 precision 0.9196637174737446 specificity 0.8628620582379934 recall 0.9190615835777126 f1 0.9193367588206299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 1.6125106811523438 s\n",
      "Accuracy 0.9249266862170088 precision 0.9250550904485365 specificity 0.8708847629664861 recall 0.9249266862170088 f1 0.924989253203258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 1.6670010089874268 s\n",
      "Accuracy 0.9266862170087976 precision 0.9259976688913131 specificity 0.8598664895439088 recall 0.9266862170087976 f1 0.9262706729289709\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 1.6549971103668213 s\n",
      "Accuracy 0.9219941348973607 precision 0.921123480313426 specificity 0.8460646037496132 recall 0.9219941348973607 f1 0.9214633792608137\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 1.7420027256011963 s\n",
      "Accuracy 0.9243401759530792 precision 0.9250462733747192 specificity 0.8641666200701666 recall 0.9243401759530792 f1 0.9246590456255178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 1.6295130252838135 s\n",
      "Accuracy 0.9325513196480938 precision 0.9319903417852407 specificity 0.8690031523475308 recall 0.9325513196480938 f1 0.9322187556532445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 1.73935866355896 s\n",
      "Accuracy 0.9161290322580645 precision 0.9157127016129033 specificity 0.8568427317290176 recall 0.9161290322580645 f1 0.9159014837933275\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 1.6239986419677734 s\n",
      "Accuracy 0.9243401759530792 precision 0.924279037651039 specificity 0.8694209149220493 recall 0.9243401759530792 f1 0.9243091998416398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 1.7359983921051025 s\n",
      "Accuracy 0.9225806451612903 precision 0.9240727874276261 specificity 0.873228132526303 recall 0.9225806451612903 f1 0.9231942630424604\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 1.6820437908172607 s\n",
      "Accuracy 0.9173020527859238 precision 0.9173749830423872 specificity 0.8524956734120132 recall 0.9173020527859238 f1 0.9173381092260809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 1.6045184135437012 s\n",
      "Accuracy 0.9237536656891495 precision 0.9229505243210742 specificity 0.8381945298894774 recall 0.9237536656891495 f1 0.9232883457430765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 1.625999927520752 s\n",
      "Accuracy 0.9196480938416423 precision 0.919228986657628 specificity 0.8579698738441386 recall 0.9196480938416423 f1 0.9194187150341598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 1.6120014190673828 s\n",
      "Accuracy 0.9319648093841643 precision 0.9324882015634705 specificity 0.8846144278615392 recall 0.9319648093841643 f1 0.9321997885662937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 1.6266975402832031 s\n",
      "Accuracy 0.9354838709677419 precision 0.9362564743315529 specificity 0.8955424742122527 recall 0.9354838709677419 f1 0.9358103070514224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 1.5709998607635498 s\n",
      "Accuracy 0.9319648093841643 precision 0.9320924125201616 specificity 0.8756359401238238 recall 0.9319648093841643 f1 0.9320269001356193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 1.6959993839263916 s\n",
      "Accuracy 0.9313782991202346 precision 0.9316889571194591 specificity 0.883120829501313 recall 0.9313782991202346 f1 0.9315232543343943\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 1.8050007820129395 s\n",
      "Accuracy 0.9313782991202346 precision 0.9315690098835111 specificity 0.8775166602344135 recall 0.9313782991202346 f1 0.9314698478644452\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 1.7050259113311768 s\n",
      "Accuracy 0.9102639296187683 precision 0.9096173052891439 specificity 0.8320636565881282 recall 0.9102639296187683 f1 0.9099076066888635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 1.837001085281372 s\n",
      "Accuracy 0.9167155425219942 precision 0.9179847043923068 specificity 0.8692736149277539 recall 0.9167155425219942 f1 0.9172494766018051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 1.824021577835083 s\n",
      "Accuracy 0.9225806451612903 precision 0.9240624671411489 specificity 0.8738989103977379 recall 0.9225806451612903 f1 0.9231894348460717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 1.8290011882781982 s\n",
      "Accuracy 0.9225806451612903 precision 0.924236432703112 specificity 0.8766795006335089 recall 0.9225806451612903 f1 0.9232464912828473\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 1.7320005893707275 s\n",
      "Accuracy 0.9290322580645162 precision 0.9289707245201466 specificity 0.8714437893553532 recall 0.9290322580645162 f1 0.9290010706828337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 1.778998851776123 s\n",
      "Accuracy 0.9196480938416423 precision 0.919584377462721 specificity 0.8631479039349003 recall 0.9196480938416423 f1 0.919615834905682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 1.7179999351501465 s\n",
      "Accuracy 0.9260997067448681 precision 0.9265061728017403 specificity 0.8739942211597378 recall 0.9260997067448681 f1 0.9262881419655613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 1.7390446662902832 s\n",
      "Accuracy 0.9255131964809384 precision 0.9257218701816502 specificity 0.8657116728356008 recall 0.9255131964809384 f1 0.925613757795886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 1.7940239906311035 s\n",
      "Accuracy 0.9237536656891495 precision 0.9229956692006434 specificity 0.8444165209972563 recall 0.9237536656891495 f1 0.923312150372602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 1.7662084102630615 s\n",
      "Accuracy 0.9255131964809384 precision 0.924878508588186 specificity 0.8559357467327107 recall 0.9255131964809384 f1 0.9251444716594638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 1.756577730178833 s\n",
      "Accuracy 0.9225806451612903 precision 0.9220907582136644 specificity 0.8553097515463272 recall 0.9225806451612903 f1 0.9223090014409641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 1.7869999408721924 s\n",
      "Accuracy 0.9155425219941349 precision 0.9142672273299803 specificity 0.8374900106546889 recall 0.9155425219941349 f1 0.9146274798202415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 1.6790437698364258 s\n",
      "Accuracy 0.9208211143695014 precision 0.919817525243957 specificity 0.839904418646961 recall 0.9208211143695014 f1 0.9201957990786579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 1.7350006103515625 s\n",
      "Accuracy 0.9120234604105572 precision 0.9139499182695264 specificity 0.8651392972941728 recall 0.9120234604105572 f1 0.9127989808609865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 1.7405126094818115 s\n",
      "Accuracy 0.918475073313783 precision 0.9197181542676438 specificity 0.8449619697337781 recall 0.918475073313783 f1 0.9190240421211285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 1.7159998416900635 s\n",
      "Accuracy 0.9331378299120234 precision 0.9335677975284679 specificity 0.8733924505377801 recall 0.9331378299120234 f1 0.9333369535897607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 1.719510793685913 s\n",
      "Accuracy 0.9296187683284457 precision 0.9306533010145023 specificity 0.8829100968681508 recall 0.9296187683284457 f1 0.9300543580364913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 1.73101806640625 s\n",
      "Accuracy 0.930791788856305 precision 0.9306723155543882 specificity 0.8730346678061744 recall 0.930791788856305 f1 0.9307303563759466\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 1.652787685394287 s\n",
      "Accuracy 0.9131964809384164 precision 0.9131964809384164 specificity 0.8362176203525468 recall 0.9131964809384164 f1 0.9131964809384164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 1.725998878479004 s\n",
      "Accuracy 0.9090909090909091 precision 0.9086026714603975 specificity 0.8383640269322532 recall 0.9090909090909091 f1 0.9088272895034529\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 1.6979994773864746 s\n",
      "Accuracy 0.9337243401759531 precision 0.9355646676933617 specificity 0.8951478402751748 recall 0.9337243401759531 f1 0.9344213007072657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 1.6761016845703125 s\n",
      "Accuracy 0.9360703812316715 precision 0.936015921169425 specificity 0.8853614685916229 recall 0.9360703812316715 f1 0.9360427268501627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 1.7640974521636963 s\n",
      "Accuracy 0.9214076246334311 precision 0.9206890128722787 specificity 0.8652458160636554 recall 0.9214076246334311 f1 0.9209470911334491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 1.7335093021392822 s\n",
      "Accuracy 0.9278592375366569 precision 0.9274303839293995 specificity 0.8593701996927803 recall 0.9278592375366569 f1 0.9276237048469217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 1.6699986457824707 s\n",
      "Accuracy 0.9290322580645162 precision 0.9284735992905617 specificity 0.8542260565141285 recall 0.9290322580645162 f1 0.9287171466717528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 1.71140718460083 s\n",
      "Accuracy 0.9214076246334311 precision 0.9214076246334311 specificity 0.8426671378614058 recall 0.9214076246334311 f1 0.9214076246334311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 1.7199993133544922 s\n",
      "Accuracy 0.9214076246334311 precision 0.9201730680925534 specificity 0.8380188112952559 recall 0.9214076246334311 f1 0.9205434904029494\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 1.7120003700256348 s\n",
      "Accuracy 0.9331378299120234 precision 0.9332534890491617 specificity 0.8845859030659468 recall 0.9331378299120234 f1 0.9331939931443017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 1.7470579147338867 s\n",
      "Accuracy 0.9137829912023461 precision 0.9126521761277223 specificity 0.8389234733816318 recall 0.9137829912023461 f1 0.9130388131690557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 1.6819994449615479 s\n",
      "Accuracy 0.9173020527859238 precision 0.9172384874658802 specificity 0.8619941218055179 recall 0.9173020527859238 f1 0.9172698749645979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 1.7449979782104492 s\n",
      "Accuracy 0.9161290322580645 precision 0.9150982749933004 specificity 0.8427647976474386 recall 0.9161290322580645 f1 0.9154662935870576\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 1.6489996910095215 s\n",
      "Accuracy 0.9161290322580645 precision 0.9153866371176851 specificity 0.8371758311953138 recall 0.9161290322580645 f1 0.9157072088968661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 1.716998815536499 s\n",
      "Accuracy 0.9272727272727272 precision 0.9259832313168005 specificity 0.8365138654734421 recall 0.9272727272727272 f1 0.9259185868011597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 1.747999668121338 s\n",
      "Accuracy 0.9214076246334311 precision 0.9211408117450274 specificity 0.8542905104520844 recall 0.9214076246334311 f1 0.9212675467596609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 1.8880012035369873 s\n",
      "Accuracy 0.92316715542522 precision 0.9229751918158826 specificity 0.8610487565727336 recall 0.92316715542522 f1 0.9230674474258349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 1.7519986629486084 s\n",
      "Accuracy 0.9219941348973607 precision 0.920721847540133 specificity 0.8392481691946934 recall 0.9219941348973607 f1 0.9210463247084452\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 1.6970000267028809 s\n",
      "Accuracy 0.918475073313783 precision 0.9177015522544858 specificity 0.8334046259343373 recall 0.918475073313783 f1 0.9180361972429963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 1.710998773574829 s\n",
      "Accuracy 0.9214076246334311 precision 0.9207250228250339 specificity 0.8538361544404904 recall 0.9214076246334311 f1 0.9210068259100518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 1.75 s\n",
      "Accuracy 0.9196480938416423 precision 0.9188225440572505 specificity 0.8503360918717909 recall 0.9196480938416423 f1 0.9191428793081964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 1.7290434837341309 s\n",
      "Accuracy 0.9214076246334311 precision 0.9223877306770202 specificity 0.8633514368282971 recall 0.9214076246334311 f1 0.9218379777728264\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 1.691999912261963 s\n",
      "Accuracy 0.9202346041055719 precision 0.9194957535133488 specificity 0.845966799386983 recall 0.9202346041055719 f1 0.9198047061713992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 1.687058687210083 s\n",
      "Accuracy 0.9237536656891495 precision 0.9228057755519955 specificity 0.8540854542552335 recall 0.9237536656891495 f1 0.923113207777204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 1.7347395420074463 s\n",
      "Accuracy 0.9319648093841643 precision 0.9313416524213205 specificity 0.8651659240973472 recall 0.9319648093841643 f1 0.9315907811351497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 1.7439992427825928 s\n",
      "Accuracy 0.918475073313783 precision 0.9184106680316045 specificity 0.8615158250812267 recall 0.918475073313783 f1 0.9184424713275764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 1.7180252075195312 s\n",
      "Accuracy 0.9284457478005865 precision 0.9292136790260948 specificity 0.8711355936041828 recall 0.9284457478005865 f1 0.9287869057778393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 1.6820356845855713 s\n",
      "Accuracy 0.9190615835777126 precision 0.9205861756614971 specificity 0.8681250004066852 recall 0.9190615835777126 f1 0.9196930427748002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 1.7211103439331055 s\n",
      "Accuracy 0.9155425219941349 precision 0.9150354491265279 specificity 0.8490110973888095 recall 0.9155425219941349 f1 0.9152631722538489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 1.716998815536499 s\n",
      "Accuracy 0.9319648093841643 precision 0.9309434515404547 specificity 0.8560524319951461 recall 0.9319648093841643 f1 0.9311576296152486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 1.7039198875427246 s\n",
      "Accuracy 0.9137829912023461 precision 0.9144953839945491 specificity 0.8558466384272836 recall 0.9137829912023461 f1 0.9141069709538727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 1.7299985885620117 s\n",
      "Accuracy 0.9131964809384164 precision 0.9141716235094843 specificity 0.8577299990746289 recall 0.9131964809384164 f1 0.9136271451213577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 1.7039990425109863 s\n",
      "Accuracy 0.930791788856305 precision 0.930791788856305 specificity 0.8705318642841617 recall 0.930791788856305 f1 0.930791788856305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 1.7755086421966553 s\n",
      "Accuracy 0.9196480938416423 precision 0.9185988498305214 specificity 0.8419328682514927 recall 0.9196480938416423 f1 0.9189718532525522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 1.674001932144165 s\n",
      "Accuracy 0.9348973607038124 precision 0.9343279899839616 specificity 0.8683983590791804 recall 0.9348973607038124 f1 0.9345593219527459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 1.6939988136291504 s\n",
      "Accuracy 0.9272727272727272 precision 0.9267756179284328 specificity 0.8556922797448999 recall 0.9272727272727272 f1 0.9269964352224426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 1.7159998416900635 s\n",
      "Accuracy 0.9202346041055719 precision 0.9201059307891333 specificity 0.8608375928374339 recall 0.9202346041055719 f1 0.9201686465280041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 1.7040021419525146 s\n",
      "Accuracy 0.9190615835777126 precision 0.918790799343385 specificity 0.8516918697339738 recall 0.9190615835777126 f1 0.9189195879966329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 1.698507308959961 s\n",
      "Accuracy 0.9255131964809384 precision 0.9250889685994217 specificity 0.8594583679023907 recall 0.9255131964809384 f1 0.9252804054516813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 1.6999998092651367 s\n",
      "Accuracy 0.9149560117302052 precision 0.9135266156933254 specificity 0.8206500488758552 recall 0.9149560117302052 f1 0.9140140241089044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 1.7193212509155273 s\n",
      "Accuracy 0.9126099706744868 precision 0.9118013246862858 specificity 0.8403503939530659 recall 0.9126099706744868 f1 0.912137491909032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 1.711214542388916 s\n",
      "Accuracy 0.930791788856305 precision 0.9302041993463366 specificity 0.8579400407176299 recall 0.930791788856305 f1 0.9304537691996917\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 1.7385094165802002 s\n",
      "Accuracy 0.9214076246334311 precision 0.9203672823362021 specificity 0.8497055090565668 recall 0.9214076246334311 f1 0.920687126682406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 1.7260260581970215 s\n",
      "Accuracy 0.9225806451612903 precision 0.9241258154909777 specificity 0.8697498172719973 recall 0.9225806451612903 f1 0.9232190726897807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 1.7440319061279297 s\n",
      "Accuracy 0.9178885630498533 precision 0.9186502156843632 specificity 0.8642761942283863 recall 0.9178885630498533 f1 0.9182293855566271\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 1.702000617980957 s\n",
      "Accuracy 0.9190615835777126 precision 0.9184425996079919 specificity 0.8489915978088022 recall 0.9190615835777126 f1 0.918710772912664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 1.6725096702575684 s\n",
      "Accuracy 0.9243401759530792 precision 0.9241335895164782 specificity 0.8544284437092844 recall 0.9243401759530792 f1 0.92423303344967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 1.739999532699585 s\n",
      "Accuracy 0.9173020527859238 precision 0.9167296114801616 specificity 0.8475753053117734 recall 0.9173020527859238 f1 0.9169826224632361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 1.7455096244812012 s\n",
      "Accuracy 0.930791788856305 precision 0.9300110130777841 specificity 0.8665930995344675 recall 0.930791788856305 f1 0.9302644540810118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 1.722217321395874 s\n",
      "Accuracy 0.9372434017595308 precision 0.9372996332630626 specificity 0.8873580090047942 recall 0.9372434017595308 f1 0.9372710898884342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 1.7839982509613037 s\n",
      "Accuracy 0.9219941348973607 precision 0.921685103473527 specificity 0.859918992574039 recall 0.9219941348973607 f1 0.9218293567479312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 1.6477382183074951 s\n",
      "Accuracy 0.9319648093841643 precision 0.9318502275277458 specificity 0.8771913645980581 recall 0.9319648093841643 f1 0.9319058325187358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 1.765059471130371 s\n",
      "Accuracy 0.9249266862170088 precision 0.9267405751347811 specificity 0.8824458160894528 recall 0.9249266862170088 f1 0.9256369220800031\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 1.7260639667510986 s\n",
      "Accuracy 0.9260997067448681 precision 0.9273262140925398 specificity 0.8801492526653547 recall 0.9260997067448681 f1 0.9266081710558753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 1.7360002994537354 s\n",
      "Accuracy 0.9202346041055719 precision 0.9192185698809853 specificity 0.8540557027344637 recall 0.9202346041055719 f1 0.9194940765574803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 1.7260518074035645 s\n",
      "Accuracy 0.9096774193548387 precision 0.9099682215220821 specificity 0.8532251926373451 recall 0.9096774193548387 f1 0.9098166306282454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 1.7003147602081299 s\n",
      "Accuracy 0.918475073313783 precision 0.9174921159312418 specificity 0.8475557416082932 recall 0.918475073313783 f1 0.9178359094785127\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 1.712998867034912 s\n",
      "Accuracy 0.9302052785923753 precision 0.9298396530813648 specificity 0.8742435814082982 recall 0.9302052785923753 f1 0.9300020907701639\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 1.683028221130371 s\n",
      "Accuracy 0.9290322580645162 precision 0.9289666527853413 specificity 0.8655455345150368 recall 0.9290322580645162 f1 0.9289990253079571\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 1.7404286861419678 s\n",
      "Accuracy 0.9173020527859238 precision 0.9173674505945233 specificity 0.8628665795449392 recall 0.9173020527859238 f1 0.9173343566567436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 1.762026071548462 s\n",
      "Accuracy 0.9196480938416423 precision 0.9185719912411119 specificity 0.8446042364868677 recall 0.9196480938416423 f1 0.9189267470368954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 1.7040009498596191 s\n",
      "Accuracy 0.92316715542522 precision 0.9232402507957493 specificity 0.8555551311350303 recall 0.92316715542522 f1 0.9232032786526234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 1.7069995403289795 s\n",
      "Accuracy 0.9348973607038124 precision 0.9341565006343264 specificity 0.8690873136256897 recall 0.9348973607038124 f1 0.9344012751241441\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 1.6377527713775635 s\n",
      "Accuracy 0.9120234604105572 precision 0.911481511897745 specificity 0.8408938032468998 recall 0.9120234604105572 f1 0.911726700334484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 1.733048439025879 s\n",
      "Accuracy 0.9260997067448681 precision 0.9260997067448681 specificity 0.8732558550371438 recall 0.9260997067448681 f1 0.9260997067448681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 1.7049994468688965 s\n",
      "Accuracy 0.9237536656891495 precision 0.923148036122994 specificity 0.8528147693025451 recall 0.9237536656891495 f1 0.9234084955471649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 1.7001044750213623 s\n",
      "Accuracy 0.9208211143695014 precision 0.9206262000226619 specificity 0.8584198326264826 recall 0.9208211143695014 f1 0.9207199681218736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 1.788999319076538 s\n",
      "Accuracy 0.9302052785923753 precision 0.9311206079734797 specificity 0.8858347463654507 recall 0.9302052785923753 f1 0.9305931560713268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 1.649022102355957 s\n",
      "Accuracy 0.9366568914956012 precision 0.9359232056160245 specificity 0.872091003717512 recall 0.9366568914956012 f1 0.9361488478638675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 1.7449982166290283 s\n",
      "Accuracy 0.9190615835777126 precision 0.9192024232646736 specificity 0.858816819174169 recall 0.9190615835777126 f1 0.9191303773884418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 1.7430005073547363 s\n",
      "Accuracy 0.9249266862170088 precision 0.9245809057728139 specificity 0.8656320885864005 recall 0.9249266862170088 f1 0.9247389852582614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 1.7470016479492188 s\n",
      "Accuracy 0.910850439882698 precision 0.9094379899960328 specificity 0.8187569044547512 recall 0.910850439882698 f1 0.9099411188065024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 1.7130193710327148 s\n",
      "Accuracy 0.9266862170087976 precision 0.9268794682704171 specificity 0.873465729809816 recall 0.9266862170087976 f1 0.9267791370178746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 1.7079994678497314 s\n",
      "Accuracy 0.918475073313783 precision 0.918014022984301 specificity 0.848450214042539 recall 0.918475073313783 f1 0.9182242855255437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 1.6999986171722412 s\n",
      "Accuracy 0.9214076246334311 precision 0.9212783417989614 specificity 0.8610390471733026 recall 0.9214076246334311 f1 0.9213413482164414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 1.7770001888275146 s\n",
      "Accuracy 0.9272727272727272 precision 0.9266635378994929 specificity 0.8533926153290602 recall 0.9272727272727272 f1 0.9269245841877422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 1.811997890472412 s\n",
      "Accuracy 0.9266862170087976 precision 0.925855130902056 specificity 0.8515718838030415 recall 0.9266862170087976 f1 0.9261732973882941\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 1.774073839187622 s\n",
      "Accuracy 0.9126099706744868 precision 0.9114565761755556 specificity 0.8233586083359165 recall 0.9126099706744868 f1 0.9119114963614089\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 1.8220820426940918 s\n",
      "Accuracy 0.9214076246334311 precision 0.9218234941927516 specificity 0.8687787869160373 recall 0.9214076246334311 f1 0.9216010639210199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 1.852003574371338 s\n",
      "Accuracy 0.9272727272727272 precision 0.9268894361924812 specificity 0.857146339261533 recall 0.9272727272727272 f1 0.9270655082350139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 1.8080008029937744 s\n",
      "Accuracy 0.9284457478005865 precision 0.9279995796934194 specificity 0.8661175065340335 recall 0.9284457478005865 f1 0.9281956725765347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 1.9010002613067627 s\n",
      "Accuracy 0.9225806451612903 precision 0.9228778004448743 specificity 0.8592765337435798 recall 0.9225806451612903 f1 0.9227225179453992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 1.7569997310638428 s\n",
      "Accuracy 0.9243401759530792 precision 0.9246652735740477 specificity 0.8746430847737813 recall 0.9243401759530792 f1 0.9244926478531033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 1.7649993896484375 s\n",
      "Accuracy 0.9178885630498533 precision 0.9168428634776373 specificity 0.8387789818045392 recall 0.9178885630498533 f1 0.9172299879716801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 1.8270013332366943 s\n",
      "Accuracy 0.9249266862170088 precision 0.9252055043748143 specificity 0.8670076214848469 recall 0.9249266862170088 f1 0.9250594373661273\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 1.7860004901885986 s\n",
      "Accuracy 0.9255131964809384 precision 0.9247636097942181 specificity 0.8603691959520746 recall 0.9255131964809384 f1 0.9250448589207367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 1.8340227603912354 s\n",
      "Accuracy 0.9167155425219942 precision 0.9154113123542614 specificity 0.8378770525293256 recall 0.9167155425219942 f1 0.9157399750499889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 1.8919978141784668 s\n",
      "Accuracy 0.9255131964809384 precision 0.9249030252365511 specificity 0.8595010485333064 recall 0.9255131964809384 f1 0.92515736319648\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 1.6360464096069336 s\n",
      "Accuracy 0.918475073313783 precision 0.9181653025523632 specificity 0.857956277436634 recall 0.918475073313783 f1 0.9183101371211966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 1.5949993133544922 s\n",
      "Accuracy 0.9255131964809384 precision 0.9243405508397932 specificity 0.8412346361524856 recall 0.9255131964809384 f1 0.9246947368301406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 1.6150009632110596 s\n",
      "Accuracy 0.9278592375366569 precision 0.9276900970863816 specificity 0.8744777748410186 recall 0.9278592375366569 f1 0.9277709781206392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 1.5325415134429932 s\n",
      "Accuracy 0.9202346041055719 precision 0.9203729211681894 specificity 0.861256374052073 recall 0.9202346041055719 f1 0.9203021347359295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 1.6080009937286377 s\n",
      "Accuracy 0.9237536656891495 precision 0.9234148349960808 specificity 0.8667846534902027 recall 0.9237536656891495 f1 0.9235696417452797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 1.6083598136901855 s\n",
      "Accuracy 0.9237536656891495 precision 0.9241626736213816 specificity 0.8718568684242646 recall 0.9237536656891495 f1 0.923943552514352\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 1.6050009727478027 s\n",
      "Accuracy 0.9167155425219942 precision 0.9161156108441711 specificity 0.8509702088213447 recall 0.9167155425219942 f1 0.9163752329100895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 1.5920002460479736 s\n",
      "Accuracy 0.9225806451612903 precision 0.9231613654241263 specificity 0.8687795080954146 recall 0.9225806451612903 f1 0.9228448941445185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 1.5880076885223389 s\n",
      "Accuracy 0.9178885630498533 precision 0.9193025445137383 specificity 0.8593110717232554 recall 0.9178885630498533 f1 0.9184904475884973\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 1.5119998455047607 s\n",
      "Accuracy 0.9178885630498533 precision 0.9167117580831143 specificity 0.8332991612819428 recall 0.9178885630498533 f1 0.9171301964357995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 1.5800120830535889 s\n",
      "Accuracy 0.910850439882698 precision 0.9106916403538737 specificity 0.8342152339282585 recall 0.910850439882698 f1 0.9107694021237438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 1.5940067768096924 s\n",
      "Accuracy 0.9266862170087976 precision 0.9260795739724532 specificity 0.8604143507586582 recall 0.9266862170087976 f1 0.9263318149442253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 1.5873639583587646 s\n",
      "Accuracy 0.9290322580645162 precision 0.928541607858211 specificity 0.8662984559784692 recall 0.9290322580645162 f1 0.9287526780861852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 1.5882763862609863 s\n",
      "Accuracy 0.9313782991202346 precision 0.9307848633006034 specificity 0.863823723054932 recall 0.9313782991202346 f1 0.9310290265542044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 1.551023244857788 s\n",
      "Accuracy 0.9249266862170088 precision 0.9249266862170088 specificity 0.869554903386532 recall 0.9249266862170088 f1 0.9249266862170088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 1.5518825054168701 s\n",
      "Accuracy 0.9243401759530792 precision 0.9238274850844372 specificity 0.860659371271407 recall 0.9243401759530792 f1 0.9240502233765461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 1.5570290088653564 s\n",
      "Accuracy 0.9219941348973607 precision 0.9216414074193036 specificity 0.8467892213392568 recall 0.9219941348973607 f1 0.9218070544231869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 1.5809998512268066 s\n",
      "Accuracy 0.92316715542522 precision 0.9219354788115338 specificity 0.8442029014185212 recall 0.92316715542522 f1 0.922144928048991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 1.59303617477417 s\n",
      "Accuracy 0.9284457478005865 precision 0.9272316061342593 specificity 0.8445714935787239 recall 0.9284457478005865 f1 0.9273883680644199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 1.5640232563018799 s\n",
      "Accuracy 0.92316715542522 precision 0.9225229376290336 specificity 0.853763218027651 recall 0.92316715542522 f1 0.922794271371485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 1.5225739479064941 s\n",
      "Accuracy 0.9225806451612903 precision 0.9221887496667555 specificity 0.8530035611239634 recall 0.9225806451612903 f1 0.9223695204734891\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 1.551999807357788 s\n",
      "Accuracy 0.9237536656891495 precision 0.927044366002716 specificity 0.8856986974016231 recall 0.9237536656891495 f1 0.9249272441718975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 1.5889983177185059 s\n",
      "Accuracy 0.918475073313783 precision 0.9185453152980035 specificity 0.8569280819133461 recall 0.918475073313783 f1 0.9185097877049442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 1.5539982318878174 s\n",
      "Accuracy 0.9255131964809384 precision 0.9280207575879885 specificity 0.8800378155820344 recall 0.9255131964809384 f1 0.9264625288948672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 1.6041123867034912 s\n",
      "Accuracy 0.9278592375366569 precision 0.9277969197763482 specificity 0.8696901005847074 recall 0.9278592375366569 f1 0.9278276596327683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 1.571000099182129 s\n",
      "Accuracy 0.9167155425219942 precision 0.9167155425219942 specificity 0.8463843643265917 recall 0.9167155425219942 f1 0.9167155425219942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 1.519749641418457 s\n",
      "Accuracy 0.9208211143695014 precision 0.9203633218508334 specificity 0.850158143530269 recall 0.9208211143695014 f1 0.9205716906355763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 1.5649566650390625 s\n",
      "Accuracy 0.9178885630498533 precision 0.9186557821307185 specificity 0.8635723847359321 recall 0.9178885630498533 f1 0.9182320727230947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 1.5870001316070557 s\n",
      "Accuracy 0.9325513196480938 precision 0.9321466957377238 specificity 0.8665581949858397 recall 0.9325513196480938 f1 0.9323275590442897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 1.5863893032073975 s\n",
      "Accuracy 0.9173020527859238 precision 0.9182508610552649 specificity 0.8526397527629611 recall 0.9173020527859238 f1 0.9177263398960042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 1.5643234252929688 s\n",
      "Accuracy 0.9266862170087976 precision 0.9260068591494098 specificity 0.861019574637082 recall 0.9266862170087976 f1 0.9262755602802396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 1.5661215782165527 s\n",
      "Accuracy 0.9173020527859238 precision 0.9162649958207026 specificity 0.8358385974135499 recall 0.9173020527859238 f1 0.9166618106139438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 1.5459997653961182 s\n",
      "Accuracy 0.9302052785923753 precision 0.9296180701019411 specificity 0.864400442483934 recall 0.9302052785923753 f1 0.9298597805313086\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 1.5790011882781982 s\n",
      "Accuracy 0.9178885630498533 precision 0.9169925070038314 specificity 0.8372352851791346 recall 0.9178885630498533 f1 0.9173577064200157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 1.6530003547668457 s\n",
      "Accuracy 0.9290322580645162 precision 0.9280587973309298 specificity 0.8601313448766604 recall 0.9290322580645162 f1 0.9282384836938068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 1.5779988765716553 s\n",
      "Accuracy 0.9284457478005865 precision 0.9290510434735828 specificity 0.8688110595685805 recall 0.9284457478005865 f1 0.9287208713229868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 1.5849988460540771 s\n",
      "Accuracy 0.9302052785923753 precision 0.9302681996774644 specificity 0.8739357876274472 recall 0.9302052785923753 f1 0.9302363164857118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 1.5650088787078857 s\n",
      "Accuracy 0.9214076246334311 precision 0.9211493860643534 specificity 0.8574532993887833 recall 0.9214076246334311 f1 0.9212719038989252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 1.562103033065796 s\n",
      "Accuracy 0.9155425219941349 precision 0.9170213750116528 specificity 0.8523994635022393 recall 0.9155425219941349 f1 0.9161765821070688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 1.587925672531128 s\n",
      "Accuracy 0.9243401759530792 precision 0.9244054328785513 specificity 0.867282414438166 recall 0.9243401759530792 f1 0.9243723929060274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 1.5690011978149414 s\n",
      "Accuracy 0.9149560117302052 precision 0.915354598250924 specificity 0.8489382297066911 recall 0.9149560117302052 f1 0.9151451081391876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 1.5960426330566406 s\n",
      "Accuracy 0.9208211143695014 precision 0.9203709409663527 specificity 0.8518198256019702 recall 0.9208211143695014 f1 0.920575610198664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 1.5947237014770508 s\n",
      "Accuracy 0.9167155425219942 precision 0.9159678064871077 specificity 0.8435907939171766 recall 0.9167155425219942 f1 0.9162823676138471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 1.5320048332214355 s\n",
      "Accuracy 0.9167155425219942 precision 0.9158179316347891 specificity 0.8457511912030491 recall 0.9167155425219942 f1 0.91616243628243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 1.5979995727539062 s\n",
      "Accuracy 0.9161290322580645 precision 0.9156840342590402 specificity 0.850828433278726 recall 0.9161290322580645 f1 0.9158867744015305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 1.5430386066436768 s\n",
      "Accuracy 0.9214076246334311 precision 0.9211556201663729 specificity 0.8597338978996971 recall 0.9214076246334311 f1 0.9212750717994519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 1.5410006046295166 s\n",
      "Accuracy 0.9208211143695014 precision 0.920264606655379 specificity 0.8517244463915437 recall 0.9208211143695014 f1 0.9205091862945041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 1.5830004215240479 s\n",
      "Accuracy 0.9149560117302052 precision 0.9151875778969338 specificity 0.8488086032084361 recall 0.9149560117302052 f1 0.915068131656088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 1.5770628452301025 s\n",
      "Accuracy 0.92316715542522 precision 0.9221218648693411 specificity 0.8477277764866611 recall 0.92316715542522 f1 0.9224580935491193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 1.547071933746338 s\n",
      "Accuracy 0.9243401759530792 precision 0.9242742480962786 specificity 0.8626261257191049 recall 0.9243401759530792 f1 0.9243067949378594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 1.6179981231689453 s\n",
      "Accuracy 0.9214076246334311 precision 0.9206817229691131 specificity 0.8480771965406652 recall 0.9214076246334311 f1 0.9209840487277021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 1.5830001831054688 s\n",
      "Accuracy 0.9272727272727272 precision 0.9281736637559361 specificity 0.8760953447868878 recall 0.9272727272727272 f1 0.9276631430803993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 1.5959994792938232 s\n",
      "Accuracy 0.9214076246334311 precision 0.9210270725192236 specificity 0.8553456007973582 recall 0.9214076246334311 f1 0.9212024314692683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 1.593052864074707 s\n",
      "Accuracy 0.9196480938416423 precision 0.9188499230973012 specificity 0.8440344179632553 recall 0.9196480938416423 f1 0.9191780158838426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 1.5730555057525635 s\n",
      "Accuracy 0.918475073313783 precision 0.9179942928056631 specificity 0.8441553254382889 recall 0.918475073313783 f1 0.9182141488824759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 1.5350000858306885 s\n",
      "Accuracy 0.9219941348973607 precision 0.9216640567329506 specificity 0.8536528582137918 recall 0.9219941348973607 f1 0.9218186144920061\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 1.5939998626708984 s\n",
      "Accuracy 0.9260997067448681 precision 0.9255080853107783 specificity 0.8558472193354707 recall 0.9260997067448681 f1 0.9257611466918808\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 1.61848783493042 s\n",
      "Accuracy 0.9290322580645162 precision 0.9297647085599403 specificity 0.8861431538121222 recall 0.9290322580645162 f1 0.9293493686482818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 1.6019988059997559 s\n",
      "Accuracy 0.9225806451612903 precision 0.9236919687604872 specificity 0.8706239955718675 recall 0.9225806451612903 f1 0.9230560216718612\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 1.5829992294311523 s\n",
      "Accuracy 0.9249266862170088 precision 0.9258900116117456 specificity 0.8677750681689561 recall 0.9249266862170088 f1 0.9253477089761101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 1.5409083366394043 s\n",
      "Accuracy 0.9260997067448681 precision 0.9245879756777144 specificity 0.8265218452138915 recall 0.9260997067448681 f1 0.9248166592539758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 1.5229992866516113 s\n",
      "Accuracy 0.9149560117302052 precision 0.9151911908391606 specificity 0.8471417199572683 recall 0.9149560117302052 f1 0.9150699196016638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 1.5799446105957031 s\n",
      "Accuracy 0.9249266862170088 precision 0.9242721060857253 specificity 0.8453283775489328 recall 0.9249266862170088 f1 0.9245555591348045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 1.5689990520477295 s\n",
      "Accuracy 0.930791788856305 precision 0.9312287781716131 specificity 0.8702818376471183 recall 0.930791788856305 f1 0.930994600650273\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 1.5920078754425049 s\n",
      "Accuracy 0.9202346041055719 precision 0.9197258460843807 specificity 0.8507232503005584 recall 0.9202346041055719 f1 0.919953620833386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 1.547081708908081 s\n",
      "Accuracy 0.9337243401759531 precision 0.9345558564237416 specificity 0.8785123388822873 recall 0.9337243401759531 f1 0.9340869300000114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 1.5210201740264893 s\n",
      "Accuracy 0.9096774193548387 precision 0.9093819639947959 specificity 0.8380045793027114 recall 0.9096774193548387 f1 0.9095232741146223\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 1.6060006618499756 s\n",
      "Accuracy 0.9196480938416423 precision 0.9186471072101571 specificity 0.8538510737578869 recall 0.9196480938416423 f1 0.9189345991268258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 1.5780484676361084 s\n",
      "Accuracy 0.9137829912023461 precision 0.9150958718700654 specificity 0.8553892813919799 recall 0.9137829912023461 f1 0.9143490828940078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 1.5629992485046387 s\n",
      "Accuracy 0.9296187683284457 precision 0.9300208211852781 specificity 0.877324771049696 recall 0.9296187683284457 f1 0.9298047131409216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 1.5839591026306152 s\n",
      "Accuracy 0.9208211143695014 precision 0.9206338990217406 specificity 0.8621110184705058 recall 0.9208211143695014 f1 0.9207238637870755\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 1.558000087738037 s\n",
      "Accuracy 0.9190615835777126 precision 0.9187994800898027 specificity 0.854873368323341 recall 0.9190615835777126 f1 0.9189239959562541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 1.5599989891052246 s\n",
      "Accuracy 0.9219941348973607 precision 0.9214493668814199 specificity 0.8542081574339638 recall 0.9219941348973607 f1 0.9216880387351745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 1.5780003070831299 s\n",
      "Accuracy 0.9266862170087976 precision 0.927035800671262 specificity 0.8696800404825488 recall 0.9266862170087976 f1 0.9268505272829326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 1.5804212093353271 s\n",
      "Accuracy 0.9214076246334311 precision 0.9211451373459234 specificity 0.8558897535747232 recall 0.9214076246334311 f1 0.9212697448662958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 1.5760009288787842 s\n",
      "Accuracy 0.9284457478005865 precision 0.9281845388033224 specificity 0.8596067792954545 recall 0.9284457478005865 f1 0.9283081860393865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 1.5590028762817383 s\n",
      "Accuracy 0.9278592375366569 precision 0.9290886180351906 specificity 0.8882681000599083 recall 0.9278592375366569 f1 0.9283574180255028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 1.587451457977295 s\n",
      "Accuracy 0.9266862170087976 precision 0.9269032442574509 specificity 0.862526815572656 recall 0.9266862170087976 f1 0.9267908713630143\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 1.5439996719360352 s\n",
      "Accuracy 0.9319648093841643 precision 0.9316427477277388 specificity 0.8747699186620455 recall 0.9319648093841643 f1 0.9317885749975672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 1.56600022315979 s\n",
      "Accuracy 0.9249266862170088 precision 0.9250575949289171 specificity 0.8691711516989887 recall 0.9249266862170088 f1 0.9249904949689894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 1.5899999141693115 s\n",
      "Accuracy 0.9243401759530792 precision 0.9252023447647849 specificity 0.8679340903678603 recall 0.9243401759530792 f1 0.9247207019222723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 1.5757477283477783 s\n",
      "Accuracy 0.92316715542522 precision 0.9232308789135948 specificity 0.8687048533160846 recall 0.92316715542522 f1 0.9231986117864491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 1.6040000915527344 s\n",
      "Accuracy 0.9178885630498533 precision 0.9169989675972887 specificity 0.8469244312751836 recall 0.9178885630498533 f1 0.9173389475726674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 1.534001350402832 s\n",
      "Accuracy 0.9214076246334311 precision 0.9207339584645982 specificity 0.8550136793027754 recall 0.9214076246334311 f1 0.9210115260478893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 1.5359995365142822 s\n",
      "Accuracy 0.9114369501466275 precision 0.9112125580937989 specificity 0.8393580690104605 recall 0.9114369501466275 f1 0.9113211092431437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 1.5674619674682617 s\n",
      "Accuracy 0.9243401759530792 precision 0.9248596707399882 specificity 0.8660745282308882 recall 0.9243401759530792 f1 0.924579461268762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 1.5832746028900146 s\n",
      "Accuracy 0.9208211143695014 precision 0.9205159676695361 specificity 0.8604829675067294 recall 0.9208211143695014 f1 0.920658393225196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 1.577394962310791 s\n",
      "Accuracy 0.9202346041055719 precision 0.919361599758599 specificity 0.8493063969514075 recall 0.9202346041055719 f1 0.919692229713735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 1.5535128116607666 s\n",
      "Accuracy 0.9260997067448681 precision 0.9262358301460369 specificity 0.8662567327598605 recall 0.9260997067448681 f1 0.926166088043527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 1.527000904083252 s\n",
      "Accuracy 0.9208211143695014 precision 0.9202252041216351 specificity 0.8448869310566536 recall 0.9208211143695014 f1 0.9204887424554153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 1.5970005989074707 s\n",
      "Accuracy 0.9137829912023461 precision 0.9130248717710644 specificity 0.8468344020748295 recall 0.9137829912023461 f1 0.9133365234188551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 1.5950331687927246 s\n",
      "Accuracy 0.9260997067448681 precision 0.9252403590494942 specificity 0.8521687249876665 recall 0.9260997067448681 f1 0.9255601595253274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 1.5670084953308105 s\n",
      "Accuracy 0.9161290322580645 precision 0.9169060279358258 specificity 0.8480614439324117 recall 0.9161290322580645 f1 0.9164839222860675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 1.578995943069458 s\n",
      "Accuracy 0.9190615835777126 precision 0.9182082309382315 specificity 0.8425467642055803 recall 0.9190615835777126 f1 0.9185526602879933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 1.5799996852874756 s\n",
      "Accuracy 0.9225806451612903 precision 0.9220760058477538 specificity 0.852462236817437 recall 0.9225806451612903 f1 0.9223013708969799\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 1.5289981365203857 s\n",
      "Accuracy 0.9085043988269794 precision 0.9093674348437566 specificity 0.844574307635709 recall 0.9085043988269794 f1 0.9088963066070246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 1.6046366691589355 s\n",
      "Accuracy 0.92316715542522 precision 0.9217770747459658 specificity 0.8347673794033528 recall 0.92316715542522 f1 0.9219986197928931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 1.596999168395996 s\n",
      "Accuracy 0.9190615835777126 precision 0.9194856860306283 specificity 0.8654045668432051 recall 0.9190615835777126 f1 0.919259241378007\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 1.5509982109069824 s\n",
      "Accuracy 0.9313782991202346 precision 0.9315712302480565 specificity 0.876499432730587 recall 0.9313782991202346 f1 0.9314709422214069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 1.6155097484588623 s\n",
      "Accuracy 0.9167155425219942 precision 0.9160785508551593 specificity 0.8452840251636451 recall 0.9167155425219942 f1 0.9163559838596842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 1.6859979629516602 s\n",
      "Accuracy 0.9131964809384164 precision 0.9117469662172957 specificity 0.8161233246296943 recall 0.9131964809384164 f1 0.9122637758520324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 1.635047435760498 s\n",
      "Accuracy 0.9249266862170088 precision 0.9254574780058651 specificity 0.8783933906407596 recall 0.9249266862170088 f1 0.9251663924120005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 1.6419992446899414 s\n",
      "Accuracy 0.9214076246334311 precision 0.9218933033575818 specificity 0.853184945464757 recall 0.9214076246334311 f1 0.9216351748350364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 1.6520006656646729 s\n",
      "Accuracy 0.9167155425219942 precision 0.9167155425219942 specificity 0.8455179755695102 recall 0.9167155425219942 f1 0.9167155425219942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 1.6780624389648438 s\n",
      "Accuracy 0.9208211143695014 precision 0.9194150710137428 specificity 0.8226201558330936 recall 0.9208211143695014 f1 0.919881654102473\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 1.5848937034606934 s\n",
      "Accuracy 0.9219941348973607 precision 0.9223760553355006 specificity 0.8579120588525898 recall 0.9219941348973607 f1 0.9221746059590623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 1.5699992179870605 s\n",
      "Accuracy 0.9325513196480938 precision 0.93173163096437 specificity 0.8650935046633972 recall 0.9325513196480938 f1 0.9319859125298351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 1.5730290412902832 s\n",
      "Accuracy 0.9278592375366569 precision 0.9279237332540765 specificity 0.8703821384416985 recall 0.9278592375366569 f1 0.9278910659465176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 1.562185287475586 s\n",
      "Accuracy 0.9243401759530792 precision 0.9237554202013493 specificity 0.8627166912824702 recall 0.9243401759530792 f1 0.9239980999474947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 1.5859999656677246 s\n",
      "Accuracy 0.9161290322580645 precision 0.9160543704220878 specificity 0.8456942596952068 recall 0.9161290322580645 f1 0.9160912887724016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 1.6324145793914795 s\n",
      "Accuracy 0.9167155425219942 precision 0.9162982655897809 specificity 0.8440342883795423 recall 0.9167155425219942 f1 0.9164919979869562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 1.6120026111602783 s\n",
      "Accuracy 0.910850439882698 precision 0.909627886564987 specificity 0.8373033762857578 recall 0.910850439882698 f1 0.9100097464205625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 1.4950001239776611 s\n",
      "Accuracy 0.9219941348973607 precision 0.9216901376730146 specificity 0.8614000434697936 recall 0.9219941348973607 f1 0.9218319261317295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 1.592005968093872 s\n",
      "Accuracy 0.9296187683284457 precision 0.9293059878741526 specificity 0.8760232550178577 recall 0.9296187683284457 f1 0.929447564150461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 1.5670006275177002 s\n",
      "Accuracy 0.9243401759530792 precision 0.9236706827789884 specificity 0.8614760182288739 recall 0.9243401759530792 f1 0.9239359043101159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 1.572554588317871 s\n",
      "Accuracy 0.9196480938416423 precision 0.9187197318810222 specificity 0.8390922785869432 recall 0.9196480938416423 f1 0.9190881709995143\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 1.5584769248962402 s\n",
      "Accuracy 0.9278592375366569 precision 0.9283457348873074 specificity 0.8746766282948242 recall 0.9278592375366569 f1 0.9280820364056824\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 1.5645208358764648 s\n",
      "Accuracy 0.9137829912023461 precision 0.9129516877819741 specificity 0.8380389385856856 recall 0.9137829912023461 f1 0.9132981515412144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 1.5219991207122803 s\n",
      "Accuracy 0.9079178885630499 precision 0.9066357612933169 specificity 0.8097403133416211 recall 0.9079178885630499 f1 0.9071548711616624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 1.6070003509521484 s\n",
      "Accuracy 0.9126099706744868 precision 0.9134988384563937 specificity 0.8562235778200785 recall 0.9126099706744868 f1 0.9130066346373827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 1.5927045345306396 s\n",
      "Accuracy 0.9208211143695014 precision 0.9206222231833542 specificity 0.8564955632615742 recall 0.9208211143695014 f1 0.9207179558296262\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 1.5975873470306396 s\n",
      "Accuracy 0.918475073313783 precision 0.9180101485109323 specificity 0.8476105191473752 recall 0.918475073313783 f1 0.9182222949452908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 1.581000566482544 s\n",
      "Accuracy 0.9208211143695014 precision 0.9210259794333643 specificity 0.8645689517357237 recall 0.9208211143695014 f1 0.9209199031666152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 1.6085717678070068 s\n",
      "Accuracy 0.9131964809384164 precision 0.9131964809384164 specificity 0.8450985382186716 recall 0.9131964809384164 f1 0.9131964809384164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 1.5400097370147705 s\n",
      "Accuracy 0.9073313782991203 precision 0.9081396508234408 specificity 0.850738825140158 recall 0.9073313782991203 f1 0.9076969213631954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 1.6040444374084473 s\n",
      "Accuracy 0.918475073313783 precision 0.9184070010949762 specificity 0.8563760489949666 recall 0.918475073313783 f1 0.9184406309637518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 1.5719985961914062 s\n",
      "Accuracy 0.9143695014662757 precision 0.914060168894188 specificity 0.8351547271894323 recall 0.9143695014662757 f1 0.9142081415286143\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 1.6120004653930664 s\n",
      "Accuracy 0.9155425219941349 precision 0.9145646513717824 specificity 0.8372447475091414 recall 0.9155425219941349 f1 0.9149474985942125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 1.6003310680389404 s\n",
      "Accuracy 0.9219941348973607 precision 0.9223349398605598 specificity 0.8689650741791556 recall 0.9219941348973607 f1 0.9221544453580469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 1.4990003108978271 s\n",
      "Accuracy 0.9173020527859238 precision 0.9169373409539031 specificity 0.8411176261189464 recall 0.9173020527859238 f1 0.9171091950086144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 1.5970003604888916 s\n",
      "Accuracy 0.9243401759530792 precision 0.9244110396997002 specificity 0.8593900689879272 recall 0.9243401759530792 f1 0.9243751846251986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 1.584212064743042 s\n",
      "Accuracy 0.9137829912023461 precision 0.9126893448057886 specificity 0.8418708676997727 recall 0.9137829912023461 f1 0.9130589456525642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 1.5819990634918213 s\n",
      "Accuracy 0.9202346041055719 precision 0.920851362034669 specificity 0.861288010896355 recall 0.9202346041055719 f1 0.920516700297449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 1.5641367435455322 s\n",
      "Accuracy 0.9237536656891495 precision 0.9228912622002928 specificity 0.8513260932615772 recall 0.9237536656891495 f1 0.923214364145855\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 1.5698671340942383 s\n",
      "Accuracy 0.9190615835777126 precision 0.9194872730294863 specificity 0.8650597869086252 recall 0.9190615835777126 f1 0.9192600176331049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 1.553999662399292 s\n",
      "Accuracy 0.930791788856305 precision 0.9304241643356931 specificity 0.8625833030231492 recall 0.930791788856305 f1 0.9305922115470229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 1.5605134963989258 s\n",
      "Accuracy 0.9202346041055719 precision 0.9189133729737379 specificity 0.8346445539733929 recall 0.9202346041055719 f1 0.9192844863695695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 1.5830106735229492 s\n",
      "Accuracy 0.9290322580645162 precision 0.9281778980714749 specificity 0.8493298756695185 recall 0.9290322580645162 f1 0.9285049478730467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 1.5759987831115723 s\n",
      "Accuracy 0.9219941348973607 precision 0.9211953517376209 specificity 0.853956177982064 recall 0.9219941348973607 f1 0.9215017399901559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 1.5999975204467773 s\n",
      "Accuracy 0.9225806451612903 precision 0.9227079435075098 specificity 0.8701885564852277 recall 0.9225806451612903 f1 0.9226426867973246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 1.5544872283935547 s\n",
      "Accuracy 0.9255131964809384 precision 0.9260829904228904 specificity 0.8571488748300236 recall 0.9255131964809384 f1 0.9257767585460169\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "split_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "smote_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, (split_seed, smote_seed) in enumerate(zip(split_seeds, smote_seeds)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=split_seed)\n",
    "    smote = SMOTE(random_state=smote_seed, n_jobs=THREADS_TO_USE)\n",
    "    x_smote, y_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_smote, y_smote)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(split_seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.919062     0.850803   0.919551  0.919062  0.919291\n1  0.919648     0.863945   0.919853  0.919648  0.919747\n2  0.923167     0.850532   0.922599  0.923167  0.922848\n3  0.915543     0.854565   0.917728  0.915543  0.916436\n4  0.912610     0.854137   0.914383  0.912610  0.913351\n5  0.927273     0.863384   0.927730  0.927273  0.927486\n6  0.921994     0.863206   0.921696  0.921994  0.921835\n7  0.921408     0.866669   0.922356  0.921408  0.921823\n8  0.929032     0.879428   0.929825  0.929032  0.929378\n9  0.920235     0.848632   0.919715  0.920235  0.919948",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.919062</td>\n      <td>0.850803</td>\n      <td>0.919551</td>\n      <td>0.919062</td>\n      <td>0.919291</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.919648</td>\n      <td>0.863945</td>\n      <td>0.919853</td>\n      <td>0.919648</td>\n      <td>0.919747</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.923167</td>\n      <td>0.850532</td>\n      <td>0.922599</td>\n      <td>0.923167</td>\n      <td>0.922848</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.915543</td>\n      <td>0.854565</td>\n      <td>0.917728</td>\n      <td>0.915543</td>\n      <td>0.916436</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.912610</td>\n      <td>0.854137</td>\n      <td>0.914383</td>\n      <td>0.912610</td>\n      <td>0.913351</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.927273</td>\n      <td>0.863384</td>\n      <td>0.927730</td>\n      <td>0.927273</td>\n      <td>0.927486</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.921994</td>\n      <td>0.863206</td>\n      <td>0.921696</td>\n      <td>0.921994</td>\n      <td>0.921835</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.921408</td>\n      <td>0.866669</td>\n      <td>0.922356</td>\n      <td>0.921408</td>\n      <td>0.921823</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.929032</td>\n      <td>0.879428</td>\n      <td>0.929825</td>\n      <td>0.929032</td>\n      <td>0.929378</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.920235</td>\n      <td>0.848632</td>\n      <td>0.919715</td>\n      <td>0.920235</td>\n      <td>0.919948</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.922057478005865\n",
      "Precision 0.9218906573641339\n",
      "Specificity 0.856287963741497\n",
      "Recall 0.922057478005865\n",
      "F1 0.9219017558678317\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_64beats_smote_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}