{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Paper CHF - 64 beats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sU5Wt4HhzLod"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id        dw_1        dw_2        dw_3       dw_4       dw_5     mfw_1  \\\n0  e0106  267.535629  270.981533  270.243834  76.791207  11.207306  0.483334   \n1  e0106  277.949875  283.546637  283.543383  80.370321  11.621628  0.480582   \n2  e0106  280.952321  289.729213  288.768479  81.676148  11.842770  0.479468   \n3  e0106  266.093352  277.366979  279.066959  79.365536  11.515873  0.479998   \n4  e0106  279.838160  290.933842  289.849559  81.839924  11.791220  0.479852   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.435149 -0.637676 -0.096703  ... -0.047331  0.034527 -0.042788  0.048729   \n1 -0.437337 -0.666380 -0.138188  ... -0.053865  0.034099 -0.034026  0.038144   \n2 -0.434101 -0.641674 -0.075015  ... -0.041838  0.031072 -0.035728  0.040951   \n3 -0.433339 -0.648197 -0.093792  ... -0.047719  0.029625 -0.035988  0.049478   \n4 -0.432266 -0.660649 -0.107788  ... -0.050448  0.030725 -0.035125  0.042994   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.072291  0.006842 -0.025811 -0.008343 -0.007415    NSR  \n1 -0.071427  0.011442 -0.027634 -0.009450 -0.002719    NSR  \n2 -0.067828  0.007170 -0.022649 -0.013308 -0.001871    NSR  \n3 -0.081219  0.019213 -0.029185 -0.014198 -0.000186    NSR  \n4 -0.070263  0.010677 -0.027446 -0.011952 -0.001447    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>267.535629</td>\n      <td>270.981533</td>\n      <td>270.243834</td>\n      <td>76.791207</td>\n      <td>11.207306</td>\n      <td>0.483334</td>\n      <td>-0.435149</td>\n      <td>-0.637676</td>\n      <td>-0.096703</td>\n      <td>...</td>\n      <td>-0.047331</td>\n      <td>0.034527</td>\n      <td>-0.042788</td>\n      <td>0.048729</td>\n      <td>-0.072291</td>\n      <td>0.006842</td>\n      <td>-0.025811</td>\n      <td>-0.008343</td>\n      <td>-0.007415</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>277.949875</td>\n      <td>283.546637</td>\n      <td>283.543383</td>\n      <td>80.370321</td>\n      <td>11.621628</td>\n      <td>0.480582</td>\n      <td>-0.437337</td>\n      <td>-0.666380</td>\n      <td>-0.138188</td>\n      <td>...</td>\n      <td>-0.053865</td>\n      <td>0.034099</td>\n      <td>-0.034026</td>\n      <td>0.038144</td>\n      <td>-0.071427</td>\n      <td>0.011442</td>\n      <td>-0.027634</td>\n      <td>-0.009450</td>\n      <td>-0.002719</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>280.952321</td>\n      <td>289.729213</td>\n      <td>288.768479</td>\n      <td>81.676148</td>\n      <td>11.842770</td>\n      <td>0.479468</td>\n      <td>-0.434101</td>\n      <td>-0.641674</td>\n      <td>-0.075015</td>\n      <td>...</td>\n      <td>-0.041838</td>\n      <td>0.031072</td>\n      <td>-0.035728</td>\n      <td>0.040951</td>\n      <td>-0.067828</td>\n      <td>0.007170</td>\n      <td>-0.022649</td>\n      <td>-0.013308</td>\n      <td>-0.001871</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>266.093352</td>\n      <td>277.366979</td>\n      <td>279.066959</td>\n      <td>79.365536</td>\n      <td>11.515873</td>\n      <td>0.479998</td>\n      <td>-0.433339</td>\n      <td>-0.648197</td>\n      <td>-0.093792</td>\n      <td>...</td>\n      <td>-0.047719</td>\n      <td>0.029625</td>\n      <td>-0.035988</td>\n      <td>0.049478</td>\n      <td>-0.081219</td>\n      <td>0.019213</td>\n      <td>-0.029185</td>\n      <td>-0.014198</td>\n      <td>-0.000186</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>279.838160</td>\n      <td>290.933842</td>\n      <td>289.849559</td>\n      <td>81.839924</td>\n      <td>11.791220</td>\n      <td>0.479852</td>\n      <td>-0.432266</td>\n      <td>-0.660649</td>\n      <td>-0.107788</td>\n      <td>...</td>\n      <td>-0.050448</td>\n      <td>0.030725</td>\n      <td>-0.035125</td>\n      <td>0.042994</td>\n      <td>-0.070263</td>\n      <td>0.010677</td>\n      <td>-0.027446</td>\n      <td>-0.011952</td>\n      <td>-0.001447</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_64beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    6531\nST     1990\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.273382  0.122628  0.083674  0.051094  0.221600 -0.049649   \ndw_2    0.273382  1.000000  0.838009  0.506753  0.191967  0.386284 -0.517805   \ndw_3    0.122628  0.838009  1.000000  0.707121  0.290188  0.236678 -0.561877   \ndw_4    0.083674  0.506753  0.707121  1.000000  0.871892 -0.017655 -0.285199   \ndw_5    0.051094  0.191967  0.290188  0.871892  1.000000 -0.129453 -0.030009   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.092294  0.039959  0.069581  0.051053  0.013172 -0.160514  0.118367   \ncfr_13 -0.054016  0.136143  0.038555  0.026543  0.024296  0.066207 -0.006270   \ncfr_14 -0.072729  0.005734 -0.024726 -0.037506 -0.044898 -0.013333  0.037817   \ncfr_15 -0.130987 -0.118431 -0.136079 -0.119712 -0.070291  0.043544  0.078133   \ncfr_16 -0.124267 -0.066128 -0.044854 -0.043279 -0.028559  0.051793 -0.022612   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.078730 -0.012908  0.013862  ... -0.117220 -0.037767 -0.071736   \ndw_2   -0.334992 -0.004812  0.033948  ... -0.102493  0.182840  0.234210   \ndw_3   -0.475222  0.011125  0.014124  ... -0.197277  0.158323  0.273116   \ndw_4   -0.270161  0.009232  0.003634  ... -0.149766  0.073674  0.107847   \ndw_5   -0.050190  0.002565 -0.000720  ... -0.059404  0.011401 -0.015802   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.127268 -0.005908  0.006278  ... -0.134908 -0.218479 -0.043561   \ncfr_13  0.019160  0.007572 -0.003219  ...  0.180735  0.047865 -0.208494   \ncfr_14  0.030309  0.006547 -0.008574  ...  0.131588  0.237481  0.033791   \ncfr_15  0.032731  0.009685 -0.019258  ...  0.301428  0.154375 -0.085936   \ncfr_16 -0.002994  0.010071 -0.004850  ...  0.273929  0.119418  0.205876   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.046960 -0.038058 -0.092294 -0.054016 -0.072729 -0.130987 -0.124267  \ndw_2    0.178912  0.060450  0.039959  0.136143  0.005734 -0.118431 -0.066128  \ndw_3    0.121813 -0.051209  0.069581  0.038555 -0.024726 -0.136079 -0.044854  \ndw_4    0.080194 -0.042344  0.051053  0.026543 -0.037506 -0.119712 -0.043279  \ndw_5    0.062258  0.002897  0.013172  0.024296 -0.044898 -0.070291 -0.028559  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.050509  0.078646  1.000000  0.025204  0.020729 -0.368802 -0.228329  \ncfr_13 -0.263557  0.025616  0.025204  1.000000  0.246144  0.176991 -0.125499  \ncfr_14 -0.177838 -0.278564  0.020729  0.246144  1.000000  0.233453 -0.128832  \ncfr_15 -0.131212 -0.053772 -0.368802  0.176991  0.233453  1.000000  0.371065  \ncfr_16  0.195965  0.020836 -0.228329 -0.125499 -0.128832  0.371065  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.273382</td>\n      <td>0.122628</td>\n      <td>0.083674</td>\n      <td>0.051094</td>\n      <td>0.221600</td>\n      <td>-0.049649</td>\n      <td>0.078730</td>\n      <td>-0.012908</td>\n      <td>0.013862</td>\n      <td>...</td>\n      <td>-0.117220</td>\n      <td>-0.037767</td>\n      <td>-0.071736</td>\n      <td>-0.046960</td>\n      <td>-0.038058</td>\n      <td>-0.092294</td>\n      <td>-0.054016</td>\n      <td>-0.072729</td>\n      <td>-0.130987</td>\n      <td>-0.124267</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.273382</td>\n      <td>1.000000</td>\n      <td>0.838009</td>\n      <td>0.506753</td>\n      <td>0.191967</td>\n      <td>0.386284</td>\n      <td>-0.517805</td>\n      <td>-0.334992</td>\n      <td>-0.004812</td>\n      <td>0.033948</td>\n      <td>...</td>\n      <td>-0.102493</td>\n      <td>0.182840</td>\n      <td>0.234210</td>\n      <td>0.178912</td>\n      <td>0.060450</td>\n      <td>0.039959</td>\n      <td>0.136143</td>\n      <td>0.005734</td>\n      <td>-0.118431</td>\n      <td>-0.066128</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.122628</td>\n      <td>0.838009</td>\n      <td>1.000000</td>\n      <td>0.707121</td>\n      <td>0.290188</td>\n      <td>0.236678</td>\n      <td>-0.561877</td>\n      <td>-0.475222</td>\n      <td>0.011125</td>\n      <td>0.014124</td>\n      <td>...</td>\n      <td>-0.197277</td>\n      <td>0.158323</td>\n      <td>0.273116</td>\n      <td>0.121813</td>\n      <td>-0.051209</td>\n      <td>0.069581</td>\n      <td>0.038555</td>\n      <td>-0.024726</td>\n      <td>-0.136079</td>\n      <td>-0.044854</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.083674</td>\n      <td>0.506753</td>\n      <td>0.707121</td>\n      <td>1.000000</td>\n      <td>0.871892</td>\n      <td>-0.017655</td>\n      <td>-0.285199</td>\n      <td>-0.270161</td>\n      <td>0.009232</td>\n      <td>0.003634</td>\n      <td>...</td>\n      <td>-0.149766</td>\n      <td>0.073674</td>\n      <td>0.107847</td>\n      <td>0.080194</td>\n      <td>-0.042344</td>\n      <td>0.051053</td>\n      <td>0.026543</td>\n      <td>-0.037506</td>\n      <td>-0.119712</td>\n      <td>-0.043279</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.051094</td>\n      <td>0.191967</td>\n      <td>0.290188</td>\n      <td>0.871892</td>\n      <td>1.000000</td>\n      <td>-0.129453</td>\n      <td>-0.030009</td>\n      <td>-0.050190</td>\n      <td>0.002565</td>\n      <td>-0.000720</td>\n      <td>...</td>\n      <td>-0.059404</td>\n      <td>0.011401</td>\n      <td>-0.015802</td>\n      <td>0.062258</td>\n      <td>0.002897</td>\n      <td>0.013172</td>\n      <td>0.024296</td>\n      <td>-0.044898</td>\n      <td>-0.070291</td>\n      <td>-0.028559</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.092294</td>\n      <td>0.039959</td>\n      <td>0.069581</td>\n      <td>0.051053</td>\n      <td>0.013172</td>\n      <td>-0.160514</td>\n      <td>0.118367</td>\n      <td>0.127268</td>\n      <td>-0.005908</td>\n      <td>0.006278</td>\n      <td>...</td>\n      <td>-0.134908</td>\n      <td>-0.218479</td>\n      <td>-0.043561</td>\n      <td>0.050509</td>\n      <td>0.078646</td>\n      <td>1.000000</td>\n      <td>0.025204</td>\n      <td>0.020729</td>\n      <td>-0.368802</td>\n      <td>-0.228329</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.054016</td>\n      <td>0.136143</td>\n      <td>0.038555</td>\n      <td>0.026543</td>\n      <td>0.024296</td>\n      <td>0.066207</td>\n      <td>-0.006270</td>\n      <td>0.019160</td>\n      <td>0.007572</td>\n      <td>-0.003219</td>\n      <td>...</td>\n      <td>0.180735</td>\n      <td>0.047865</td>\n      <td>-0.208494</td>\n      <td>-0.263557</td>\n      <td>0.025616</td>\n      <td>0.025204</td>\n      <td>1.000000</td>\n      <td>0.246144</td>\n      <td>0.176991</td>\n      <td>-0.125499</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.072729</td>\n      <td>0.005734</td>\n      <td>-0.024726</td>\n      <td>-0.037506</td>\n      <td>-0.044898</td>\n      <td>-0.013333</td>\n      <td>0.037817</td>\n      <td>0.030309</td>\n      <td>0.006547</td>\n      <td>-0.008574</td>\n      <td>...</td>\n      <td>0.131588</td>\n      <td>0.237481</td>\n      <td>0.033791</td>\n      <td>-0.177838</td>\n      <td>-0.278564</td>\n      <td>0.020729</td>\n      <td>0.246144</td>\n      <td>1.000000</td>\n      <td>0.233453</td>\n      <td>-0.128832</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.130987</td>\n      <td>-0.118431</td>\n      <td>-0.136079</td>\n      <td>-0.119712</td>\n      <td>-0.070291</td>\n      <td>0.043544</td>\n      <td>0.078133</td>\n      <td>0.032731</td>\n      <td>0.009685</td>\n      <td>-0.019258</td>\n      <td>...</td>\n      <td>0.301428</td>\n      <td>0.154375</td>\n      <td>-0.085936</td>\n      <td>-0.131212</td>\n      <td>-0.053772</td>\n      <td>-0.368802</td>\n      <td>0.176991</td>\n      <td>0.233453</td>\n      <td>1.000000</td>\n      <td>0.371065</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.124267</td>\n      <td>-0.066128</td>\n      <td>-0.044854</td>\n      <td>-0.043279</td>\n      <td>-0.028559</td>\n      <td>0.051793</td>\n      <td>-0.022612</td>\n      <td>-0.002994</td>\n      <td>0.010071</td>\n      <td>-0.004850</td>\n      <td>...</td>\n      <td>0.273929</td>\n      <td>0.119418</td>\n      <td>0.205876</td>\n      <td>0.195965</td>\n      <td>0.020836</td>\n      <td>-0.228329</td>\n      <td>-0.125499</td>\n      <td>-0.128832</td>\n      <td>0.371065</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows Ã— 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()\n",
    "patient_ids = data[\"id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_201', 'fft_224', 'fft_196', 'fft_230', 'fft_190', 'fft_147', 'fft_235', 'fft_207', 'fft_251', 'fft_151', 'fft_156', 'fft_163', 'fft_252', 'fft_136', 'fft_211', 'fft_248', 'mfw_9', 'fft_172', 'fft_177', 'fft_157', 'fft_132', 'fft_242', 'fft_161', 'fft_168', 'fft_240', 'fft_144', 'fft_206', 'fft_137', 'fft_228', 'fft_179', 'fft_139', 'fft_135', 'fft_250', 'fft_204', 'fft_241', 'fft_187', 'fft_253', 'mfw_11', 'fft_155', 'mfw_5', 'fft_226', 'fft_244', 'fft_186', 'fft_209', 'fft_146', 'fft_171', 'fft_256', 'fft_243', 'fft_138', 'fft_232', 'fft_219', 'fft_158', 'fft_198', 'fft_175', 'mfw_13', 'fft_183', 'fft_254', 'fft_165', 'fft_130', 'fft_150', 'fft_176', 'fft_238', 'fft_145', 'fft_229', 'fft_202', 'fft_234', 'fft_154', 'fft_181', 'fft_199', 'fft_222', 'fft_225', 'fft_173', 'fft_212', 'fft_189', 'mfw_12', 'mfw_14', 'fft_255', 'fft_214', 'mfw_15', 'fft_249', 'mfw_10', 'fft_184', 'fft_223', 'fft_227', 'fft_231', 'fft_216', 'mfw_16', 'fft_217', 'mfw_6', 'fft_213', 'fft_210', 'fft_143', 'cfr_16', 'fft_141', 'fft_167', 'fft_131', 'fft_142', 'fft_239', 'fft_148', 'fft_149', 'fft_152', 'fft_159', 'fft_237', 'fft_169', 'fft_203', 'fft_192', 'fft_166', 'fft_246', 'fft_162', 'fft_182', 'fft_133', 'fft_208', 'fft_180', 'fft_215', 'fft_247', 'fft_160', 'fft_218', 'fft_200', 'fft_236', 'fft_233', 'fft_245', 'mfw_8', 'mfw_7', 'fft_221', 'fft_205', 'fft_153', 'fft_164', 'fft_140', 'fft_185', 'fft_197', 'fft_188', 'fft_134', 'fft_174', 'fft_191', 'fft_195', 'fft_170', 'fft_178', 'fft_194', 'fft_220', 'fft_193'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_19\n",
      "fft_20\n",
      "fft_22\n",
      "fft_30\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_37\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_13\n",
      "ar_14\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 66\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization best features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "         dw_1        dw_2        dw_3       dw_4       dw_5     mfw_1  \\\n0  267.535629  270.981533  270.243834  76.791207  11.207306  0.483334   \n1  277.949875  283.546637  283.543383  80.370321  11.621628  0.480582   \n2  280.952321  289.729213  288.768479  81.676148  11.842770  0.479468   \n3  266.093352  277.366979  279.066959  79.365536  11.515873  0.479998   \n4  279.838160  290.933842  289.849559  81.839924  11.791220  0.479852   \n\n      mfw_2     mfw_3     mfw_4      fft_1  ...     cfr_6     cfr_7     cfr_8  \\\n0 -0.435149 -0.637676 -0.096703  -1.065012  ...  0.016873  0.040724 -0.047331   \n1 -0.437337 -0.666380 -0.138188  -2.207264  ...  0.011581  0.052652 -0.053865   \n2 -0.434101 -0.641674 -0.075015  -0.855778  ...  0.031430  0.033720 -0.041838   \n3 -0.433339 -0.648197 -0.093792  -1.105237  ...  0.018259  0.048839 -0.047719   \n4 -0.432266 -0.660649 -0.107788  14.855103  ...  0.015173  0.050778 -0.050448   \n\n      cfr_9    cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0  0.034527 -0.042788  0.048729 -0.072291  0.006842 -0.025811 -0.008343  \n1  0.034099 -0.034026  0.038144 -0.071427  0.011442 -0.027634 -0.009450  \n2  0.031072 -0.035728  0.040951 -0.067828  0.007170 -0.022649 -0.013308  \n3  0.029625 -0.035988  0.049478 -0.081219  0.019213 -0.029185 -0.014198  \n4  0.030725 -0.035125  0.042994 -0.070263  0.010677 -0.027446 -0.011952  \n\n[5 rows x 66 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>267.535629</td>\n      <td>270.981533</td>\n      <td>270.243834</td>\n      <td>76.791207</td>\n      <td>11.207306</td>\n      <td>0.483334</td>\n      <td>-0.435149</td>\n      <td>-0.637676</td>\n      <td>-0.096703</td>\n      <td>-1.065012</td>\n      <td>...</td>\n      <td>0.016873</td>\n      <td>0.040724</td>\n      <td>-0.047331</td>\n      <td>0.034527</td>\n      <td>-0.042788</td>\n      <td>0.048729</td>\n      <td>-0.072291</td>\n      <td>0.006842</td>\n      <td>-0.025811</td>\n      <td>-0.008343</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>277.949875</td>\n      <td>283.546637</td>\n      <td>283.543383</td>\n      <td>80.370321</td>\n      <td>11.621628</td>\n      <td>0.480582</td>\n      <td>-0.437337</td>\n      <td>-0.666380</td>\n      <td>-0.138188</td>\n      <td>-2.207264</td>\n      <td>...</td>\n      <td>0.011581</td>\n      <td>0.052652</td>\n      <td>-0.053865</td>\n      <td>0.034099</td>\n      <td>-0.034026</td>\n      <td>0.038144</td>\n      <td>-0.071427</td>\n      <td>0.011442</td>\n      <td>-0.027634</td>\n      <td>-0.009450</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>280.952321</td>\n      <td>289.729213</td>\n      <td>288.768479</td>\n      <td>81.676148</td>\n      <td>11.842770</td>\n      <td>0.479468</td>\n      <td>-0.434101</td>\n      <td>-0.641674</td>\n      <td>-0.075015</td>\n      <td>-0.855778</td>\n      <td>...</td>\n      <td>0.031430</td>\n      <td>0.033720</td>\n      <td>-0.041838</td>\n      <td>0.031072</td>\n      <td>-0.035728</td>\n      <td>0.040951</td>\n      <td>-0.067828</td>\n      <td>0.007170</td>\n      <td>-0.022649</td>\n      <td>-0.013308</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>266.093352</td>\n      <td>277.366979</td>\n      <td>279.066959</td>\n      <td>79.365536</td>\n      <td>11.515873</td>\n      <td>0.479998</td>\n      <td>-0.433339</td>\n      <td>-0.648197</td>\n      <td>-0.093792</td>\n      <td>-1.105237</td>\n      <td>...</td>\n      <td>0.018259</td>\n      <td>0.048839</td>\n      <td>-0.047719</td>\n      <td>0.029625</td>\n      <td>-0.035988</td>\n      <td>0.049478</td>\n      <td>-0.081219</td>\n      <td>0.019213</td>\n      <td>-0.029185</td>\n      <td>-0.014198</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>279.838160</td>\n      <td>290.933842</td>\n      <td>289.849559</td>\n      <td>81.839924</td>\n      <td>11.791220</td>\n      <td>0.479852</td>\n      <td>-0.432266</td>\n      <td>-0.660649</td>\n      <td>-0.107788</td>\n      <td>14.855103</td>\n      <td>...</td>\n      <td>0.015173</td>\n      <td>0.050778</td>\n      <td>-0.050448</td>\n      <td>0.030725</td>\n      <td>-0.035125</td>\n      <td>0.042994</td>\n      <td>-0.070263</td>\n      <td>0.010677</td>\n      <td>-0.027446</td>\n      <td>-0.011952</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 66 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest - L1SO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['e0106', 'e0110', 'e0115', 'e0129', 'e0133', 'e0151', 'e0202',\n       'e0203', 'e0204', 'e0205', 'e0206', 'e0207', 'e0208', 'e0210',\n       'e0211', 'e0212', 'e0213', 'e0302', 'e0303', 'e0304', 'e0305',\n       'e0306', 'e0403', 'e0404', 'e0405', 'e0406', 'e0408', 'e0409',\n       'e0410', 'e0411', 'e0413', 'e0415', 'e0417', 'e0418', 'e0515',\n       'e0601', 'e0602', 'e0603', 'e0605', 'e0606', 'e0607', 'e0609',\n       'e0610', 'e0611', 'e0612', 'e0613', 'e0614', 'e0615', 'e0704',\n       'e0801', 'e0808', 'e0817', 'e0818', 'e1301', 'e1302', 'e1304'],\n      dtype=object)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvds = X_fsel.copy()\n",
    "cvds[\"patient_id\"] = patient_ids\n",
    "cvds[\"label\"] = y\n",
    "\n",
    "patients = np.unique(cvds[\"patient_id\"].values)\n",
    "patients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def eval_metrics(tp, tn, fp, fn):\n",
    "    acc = (tp + tn) /(tp + tn + fp + fn)\n",
    "    sens = tp / (tp+fn)\n",
    "    spec = tn / (tn+fp)\n",
    "    precision = tp / (tp+fp)\n",
    "    recall = tp / (tp+fn)\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "    return acc, sens, spec, precision, recall, f1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 56 - 1.3710026741027832 s\n",
      "Accuracy 0.8214285714285714 precision 0.8533163265306122 specificity 0.17857142857142858 recall 0.8214285714285714 f1 0.7408963585434174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 56 - 1.293997049331665 s\n",
      "Accuracy 0.8090909090909091 precision 0.8455371900826447 specificity 0.19090909090909092 recall 0.8090909090909091 f1 0.723709456372773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 56 - 1.332000494003296 s\n",
      "Accuracy 0.9209039548022598 precision 0.9271601391681829 specificity 0.07909604519774012 recall 0.9209039548022598 f1 0.882984380192755\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 56 - 1.2540247440338135 s\n",
      "Accuracy 0.8651685393258427 precision 0.8833480621133695 specificity 0.1348314606741573 recall 0.8651685393258427 f1 0.8026262352781914\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "5 of 56 - 1.2690010070800781 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "6 of 56 - 1.3640000820159912 s\n",
      "Accuracy 0.95 precision 1.0 specificity 0.0 recall 0.95 f1 0.9743589743589743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 56 - 1.487044334411621 s\n",
      "Accuracy 0.7115384615384616 precision 0.7947485207100592 specificity 0.28846153846153844 recall 0.7115384615384616 f1 0.5916162489196197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 56 - 1.3779995441436768 s\n",
      "Accuracy 0.7610062893081762 precision 0.8195982958003651 specificity 0.33423180592991913 recall 0.7610062893081762 f1 0.6789859093760556\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 56 - 1.3800008296966553 s\n",
      "Accuracy 0.861878453038674 precision 0.9897687742991611 specificity 0.9984567424920522 recall 0.861878453038674 f1 0.9162288598371662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 56 - 1.371553897857666 s\n",
      "Accuracy 0.6542553191489362 precision 0.7737947034857402 specificity 0.34574468085106386 recall 0.6542553191489362 f1 0.5175138537319559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 56 - 1.3759982585906982 s\n",
      "Accuracy 0.8023255813953488 precision 0.7822827417380659 specificity 0.46964411557434815 recall 0.8023255813953488 f1 0.7763402118135166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 56 - 1.36199951171875 s\n",
      "Accuracy 0.7522123893805309 precision 0.8136110893570364 specificity 0.24778761061946902 recall 0.7522123893805309 f1 0.6458389201752033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 56 - 1.3950016498565674 s\n",
      "Accuracy 0.8978102189781022 precision 0.9082529703234056 specificity 0.10218978102189781 recall 0.8978102189781022 f1 0.8494665918023583\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 56 - 1.4400031566619873 s\n",
      "Accuracy 0.8102189781021898 precision 0.8462358143747669 specificity 0.1897810218978102 recall 0.8102189781021898 f1 0.7252766658817988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 56 - 1.4049980640411377 s\n",
      "Accuracy 0.8177966101694916 precision 0.6751172015867292 specificity 0.17704875065525072 recall 0.8177966101694916 f1 0.7396388921812652\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 56 - 1.4059996604919434 s\n",
      "Accuracy 0.9473684210526315 precision 0.9501385041551246 specificity 0.05263157894736842 recall 0.9473684210526315 f1 0.9217638691322904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 56 - 1.4095275402069092 s\n",
      "Accuracy 0.7329545454545454 precision 0.7248151697699892 specificity 0.38030035650623883 recall 0.7329545454545454 f1 0.6620222420247771\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 56 - 1.3799984455108643 s\n",
      "Accuracy 0.9538461538461539 precision 0.933045770428948 specificity 0.03341499265066144 recall 0.9538461538461539 f1 0.9433313143549366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 56 - 1.4256772994995117 s\n",
      "Accuracy 0.8561151079136691 precision 0.8768179700843641 specificity 0.14388489208633093 recall 0.8561151079136691 f1 0.7897495956722993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 56 - 1.379516839981079 s\n",
      "Accuracy 0.9847328244274809 precision 0.9771869790295693 specificity 0.011406171711515221 recall 0.9847328244274809 f1 0.9809453904873753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 56 - 1.4269990921020508 s\n",
      "Accuracy 0.8108108108108109 precision 0.8466033601168736 specificity 0.1891891891891892 recall 0.8108108108108109 f1 0.7260992335619201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 56 - 1.5370008945465088 s\n",
      "Accuracy 0.6774193548387096 precision 0.781477627471384 specificity 0.3225806451612903 recall 0.6774193548387096 f1 0.5471464019851118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 56 - 1.6200191974639893 s\n",
      "Accuracy 0.32413793103448274 precision 0.10804597701149427 specificity 0.6550287356321839 recall 0.32413793103448274 f1 0.16206896551724137\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 56 - 1.564051866531372 s\n",
      "Accuracy 0.7614678899082569 precision 0.7005504587155963 specificity 0.14070602313522138 recall 0.7614678899082569 f1 0.7297400611620796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 56 - 1.565000057220459 s\n",
      "Accuracy 0.7028571428571428 precision 0.7414595660749508 specificity 0.3780252100840336 recall 0.7028571428571428 f1 0.6088351254480286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 56 - 1.5530035495758057 s\n",
      "Accuracy 0.6879432624113475 precision 0.5248752298397689 specificity 0.2538043104041865 recall 0.6879432624113475 f1 0.5954466893140236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 56 - 1.560999870300293 s\n",
      "Accuracy 0.3971631205673759 precision 0.7298749578525668 specificity 0.10733631700292783 recall 0.3971631205673759 f1 0.5103749271027334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 56 - 1.5029988288879395 s\n",
      "Accuracy 0.16417910447761194 precision 0.9530437699144726 specificity 0.9562397436899274 recall 0.16417910447761194 f1 0.2095517639482049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 56 - 1.4970238208770752 s\n",
      "Accuracy 0.1440677966101695 precision 0.8766877334099397 specificity 0.8559322033898306 recall 0.1440677966101695 f1 0.036283741368487124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 56 - 1.4600005149841309 s\n",
      "Accuracy 0.9230769230769231 precision 0.8956043956043956 specificity 0.15331196581196582 recall 0.9230769230769231 f1 0.8968950512574674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 56 - 1.5029997825622559 s\n",
      "Accuracy 0.9140625 precision 0.9170680607769424 specificity 0.6491482023411371 recall 0.9140625 f1 0.9154662987223031\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 56 - 1.6750023365020752 s\n",
      "Accuracy 0.6793478260869565 precision 0.7546077504725897 specificity 0.6960513460005656 recall 0.6793478260869565 f1 0.6582395019567729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 56 - 1.4790012836456299 s\n",
      "Accuracy 0.8541666666666666 precision 0.8310688405797102 specificity 0.30321745119175947 recall 0.8541666666666666 f1 0.8162084498291394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 56 - 1.552999496459961 s\n",
      "Accuracy 0.7431693989071039 precision 0.9015726625494984 specificity 0.5170645192215512 recall 0.7431693989071039 f1 0.8047077861838206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 56 - 1.6199991703033447 s\n",
      "Accuracy 0.9415204678362573 precision 0.9080937056645557 specificity 0.04620959351343594 recall 0.9415204678362573 f1 0.9245050376946381\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "36 of 56 - 1.503000020980835 s\n",
      "Accuracy 0.95 precision 1.0 specificity 0.0 recall 0.95 f1 0.9743589743589743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 56 - 1.531001091003418 s\n",
      "Accuracy 0.64 precision 0.8477202797202796 specificity 0.565237084217976 recall 0.64 f1 0.7102423175849465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 56 - 1.4869985580444336 s\n",
      "Accuracy 0.048 precision 0.9543039999999999 specificity 0.952 recall 0.048 f1 0.0043969465648854966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 56 - 1.4580037593841553 s\n",
      "Accuracy 0.7486338797814208 precision 0.5749177308818646 specificity 0.23697763100994612 recall 0.7486338797814208 f1 0.6503756830601094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 56 - 1.4885075092315674 s\n",
      "Accuracy 0.8092105263157895 precision 0.6645172533983966 specificity 0.18272495755517826 recall 0.8092105263157895 f1 0.7297607655502393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 56 - 1.5179989337921143 s\n",
      "Accuracy 0.4012345679012346 precision 0.7735438429882875 specificity 0.6570178592832315 recall 0.4012345679012346 f1 0.2698817585809976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 56 - 1.6030011177062988 s\n",
      "Accuracy 0.9319727891156463 precision 0.8934083978418953 specificity 0.053638721675720646 recall 0.9319727891156463 f1 0.9122832231484143\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 56 - 1.4669995307922363 s\n",
      "Accuracy 0.8571428571428571 precision 0.8775510204081632 specificity 0.14285714285714285 recall 0.8571428571428571 f1 0.7912087912087911\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "44 of 56 - 1.489001989364624 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 56 - 1.595001220703125 s\n",
      "Accuracy 0.6272727272727273 precision 0.6082965578111209 specificity 0.42384772090654443 recall 0.6272727272727273 f1 0.5323004480899218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 56 - 1.4850010871887207 s\n",
      "Accuracy 0.753968253968254 precision 0.8144998740236835 specificity 0.24603174603174602 recall 0.753968253968254 f1 0.6482080011491776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 56 - 1.5109992027282715 s\n",
      "Accuracy 0.7415730337078652 precision 0.7391743982377371 specificity 0.7076115716411238 recall 0.7415730337078652 f1 0.7388241762017661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 56 - 1.530000925064087 s\n",
      "Accuracy 0.9736842105263158 precision 0.9794531373478743 specificity 0.5084586466165414 recall 0.9736842105263158 f1 0.9762567854614113\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "49 of 56 - 1.4900014400482178 s\n",
      "Accuracy 0.9869281045751634 precision 1.0 specificity 0.0 recall 0.9869281045751634 f1 0.993421052631579\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "50 of 56 - 1.4899978637695312 s\n",
      "Accuracy 0.9668874172185431 precision 1.0 specificity 0.0 recall 0.9668874172185431 f1 0.9831649831649832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 56 - 1.566002368927002 s\n",
      "Accuracy 0.14689265536723164 precision 0.7694060675117503 specificity 0.8439498354752591 recall 0.14689265536723164 f1 0.0897320244963244\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "52 of 56 - 1.4339990615844727 s\n",
      "Accuracy 0.4959349593495935 precision 1.0 specificity 0.0 recall 0.4959349593495935 f1 0.6630434782608696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 56 - 1.5469989776611328 s\n",
      "Accuracy 0.7391304347826086 precision 0.8089171974522293 specificity 0.34782608695652173 recall 0.7391304347826086 f1 0.6497058823529411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 56 - 1.4830400943756104 s\n",
      "Accuracy 0.8686131386861314 precision 0.886002576212967 specificity 0.18401844026123704 recall 0.8686131386861314 f1 0.8141444910627048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 56 - 1.5699985027313232 s\n",
      "Accuracy 0.9015151515151515 precision 0.9112144168962351 specificity 0.09848484848484848 recall 0.9015151515151515 f1 0.854823131715562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 56 - 1.5469989776611328 s\n",
      "Accuracy 0.7741935483870968 precision 0.8251821019771071 specificity 0.22580645161290322 recall 0.7741935483870968 f1 0.6756598240469208\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "tot = len(patients)\n",
    "for i, patient in enumerate(patients):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    df1 = cvds.loc[cvds[\"patient_id\"] != patient]\n",
    "    df2 = cvds.loc[cvds[\"patient_id\"] == patient]\n",
    "\n",
    "    y_train = df1[\"label\"].values\n",
    "    x_train = df1.loc[:, ~df1.columns.isin(['patient_id', 'label'])]\n",
    "    y_test = df2[\"label\"].values\n",
    "    x_test = df2.loc[:, ~df2.columns.isin(['patient_id', 'label'])]\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, zero_division=1, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(patients), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.821429     0.178571   0.853316  0.821429  0.740896\n1  0.809091     0.190909   0.845537  0.809091  0.723709\n2  0.920904     0.079096   0.927160  0.920904  0.882984\n3  0.865169     0.134831   0.883348  0.865169  0.802626\n4  1.000000     0.000000   1.000000  1.000000  1.000000\n5  0.950000     0.000000   1.000000  0.950000  0.974359\n6  0.711538     0.288462   0.794749  0.711538  0.591616\n7  0.761006     0.334232   0.819598  0.761006  0.678986\n8  0.861878     0.998457   0.989769  0.861878  0.916229\n9  0.654255     0.345745   0.773795  0.654255  0.517514",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.821429</td>\n      <td>0.178571</td>\n      <td>0.853316</td>\n      <td>0.821429</td>\n      <td>0.740896</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.809091</td>\n      <td>0.190909</td>\n      <td>0.845537</td>\n      <td>0.809091</td>\n      <td>0.723709</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.920904</td>\n      <td>0.079096</td>\n      <td>0.927160</td>\n      <td>0.920904</td>\n      <td>0.882984</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.865169</td>\n      <td>0.134831</td>\n      <td>0.883348</td>\n      <td>0.865169</td>\n      <td>0.802626</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.950000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.950000</td>\n      <td>0.974359</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.711538</td>\n      <td>0.288462</td>\n      <td>0.794749</td>\n      <td>0.711538</td>\n      <td>0.591616</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.761006</td>\n      <td>0.334232</td>\n      <td>0.819598</td>\n      <td>0.761006</td>\n      <td>0.678986</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.861878</td>\n      <td>0.998457</td>\n      <td>0.989769</td>\n      <td>0.861878</td>\n      <td>0.916229</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.654255</td>\n      <td>0.345745</td>\n      <td>0.773795</td>\n      <td>0.654255</td>\n      <td>0.517514</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.7499791032161683\n",
      "Precision 0.835241413782187\n",
      "Specificity 0.30283439759130365\n",
      "Recall 0.7499791032161683\n",
      "F1 0.7083331382835754\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_64beats_l1so.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}