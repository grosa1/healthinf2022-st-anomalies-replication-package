{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 64 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id        dw_1        dw_2        dw_3       dw_4       dw_5     mfw_1  \\\n0  e0106  267.535629  270.981533  270.243834  76.791207  11.207306  0.483334   \n1  e0106  277.949875  283.546637  283.543383  80.370321  11.621628  0.480582   \n2  e0106  280.952321  289.729213  288.768479  81.676148  11.842770  0.479468   \n3  e0106  266.093352  277.366979  279.066959  79.365536  11.515873  0.479998   \n4  e0106  279.838160  290.933842  289.849559  81.839924  11.791220  0.479852   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.435149 -0.637676 -0.096703  ... -0.047331  0.034527 -0.042788  0.048729   \n1 -0.437337 -0.666380 -0.138188  ... -0.053865  0.034099 -0.034026  0.038144   \n2 -0.434101 -0.641674 -0.075015  ... -0.041838  0.031072 -0.035728  0.040951   \n3 -0.433339 -0.648197 -0.093792  ... -0.047719  0.029625 -0.035988  0.049478   \n4 -0.432266 -0.660649 -0.107788  ... -0.050448  0.030725 -0.035125  0.042994   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.072291  0.006842 -0.025811 -0.008343 -0.007415    NSR  \n1 -0.071427  0.011442 -0.027634 -0.009450 -0.002719    NSR  \n2 -0.067828  0.007170 -0.022649 -0.013308 -0.001871    NSR  \n3 -0.081219  0.019213 -0.029185 -0.014198 -0.000186    NSR  \n4 -0.070263  0.010677 -0.027446 -0.011952 -0.001447    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>267.535629</td>\n      <td>270.981533</td>\n      <td>270.243834</td>\n      <td>76.791207</td>\n      <td>11.207306</td>\n      <td>0.483334</td>\n      <td>-0.435149</td>\n      <td>-0.637676</td>\n      <td>-0.096703</td>\n      <td>...</td>\n      <td>-0.047331</td>\n      <td>0.034527</td>\n      <td>-0.042788</td>\n      <td>0.048729</td>\n      <td>-0.072291</td>\n      <td>0.006842</td>\n      <td>-0.025811</td>\n      <td>-0.008343</td>\n      <td>-0.007415</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>277.949875</td>\n      <td>283.546637</td>\n      <td>283.543383</td>\n      <td>80.370321</td>\n      <td>11.621628</td>\n      <td>0.480582</td>\n      <td>-0.437337</td>\n      <td>-0.666380</td>\n      <td>-0.138188</td>\n      <td>...</td>\n      <td>-0.053865</td>\n      <td>0.034099</td>\n      <td>-0.034026</td>\n      <td>0.038144</td>\n      <td>-0.071427</td>\n      <td>0.011442</td>\n      <td>-0.027634</td>\n      <td>-0.009450</td>\n      <td>-0.002719</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>280.952321</td>\n      <td>289.729213</td>\n      <td>288.768479</td>\n      <td>81.676148</td>\n      <td>11.842770</td>\n      <td>0.479468</td>\n      <td>-0.434101</td>\n      <td>-0.641674</td>\n      <td>-0.075015</td>\n      <td>...</td>\n      <td>-0.041838</td>\n      <td>0.031072</td>\n      <td>-0.035728</td>\n      <td>0.040951</td>\n      <td>-0.067828</td>\n      <td>0.007170</td>\n      <td>-0.022649</td>\n      <td>-0.013308</td>\n      <td>-0.001871</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>266.093352</td>\n      <td>277.366979</td>\n      <td>279.066959</td>\n      <td>79.365536</td>\n      <td>11.515873</td>\n      <td>0.479998</td>\n      <td>-0.433339</td>\n      <td>-0.648197</td>\n      <td>-0.093792</td>\n      <td>...</td>\n      <td>-0.047719</td>\n      <td>0.029625</td>\n      <td>-0.035988</td>\n      <td>0.049478</td>\n      <td>-0.081219</td>\n      <td>0.019213</td>\n      <td>-0.029185</td>\n      <td>-0.014198</td>\n      <td>-0.000186</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>279.838160</td>\n      <td>290.933842</td>\n      <td>289.849559</td>\n      <td>81.839924</td>\n      <td>11.791220</td>\n      <td>0.479852</td>\n      <td>-0.432266</td>\n      <td>-0.660649</td>\n      <td>-0.107788</td>\n      <td>...</td>\n      <td>-0.050448</td>\n      <td>0.030725</td>\n      <td>-0.035125</td>\n      <td>0.042994</td>\n      <td>-0.070263</td>\n      <td>0.010677</td>\n      <td>-0.027446</td>\n      <td>-0.011952</td>\n      <td>-0.001447</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_64beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    6531\nST     1990\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.273382  0.122628  0.083674  0.051094  0.221600 -0.049649   \ndw_2    0.273382  1.000000  0.838009  0.506753  0.191967  0.386284 -0.517805   \ndw_3    0.122628  0.838009  1.000000  0.707121  0.290188  0.236678 -0.561877   \ndw_4    0.083674  0.506753  0.707121  1.000000  0.871892 -0.017655 -0.285199   \ndw_5    0.051094  0.191967  0.290188  0.871892  1.000000 -0.129453 -0.030009   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.092294  0.039959  0.069581  0.051053  0.013172 -0.160514  0.118367   \ncfr_13 -0.054016  0.136143  0.038555  0.026543  0.024296  0.066207 -0.006270   \ncfr_14 -0.072729  0.005734 -0.024726 -0.037506 -0.044898 -0.013333  0.037817   \ncfr_15 -0.130987 -0.118431 -0.136079 -0.119712 -0.070291  0.043544  0.078133   \ncfr_16 -0.124267 -0.066128 -0.044854 -0.043279 -0.028559  0.051793 -0.022612   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.078730 -0.012908  0.013862  ... -0.117220 -0.037767 -0.071736   \ndw_2   -0.334992 -0.004812  0.033948  ... -0.102493  0.182840  0.234210   \ndw_3   -0.475222  0.011125  0.014124  ... -0.197277  0.158323  0.273116   \ndw_4   -0.270161  0.009232  0.003634  ... -0.149766  0.073674  0.107847   \ndw_5   -0.050190  0.002565 -0.000720  ... -0.059404  0.011401 -0.015802   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.127268 -0.005908  0.006278  ... -0.134908 -0.218479 -0.043561   \ncfr_13  0.019160  0.007572 -0.003219  ...  0.180735  0.047865 -0.208494   \ncfr_14  0.030309  0.006547 -0.008574  ...  0.131588  0.237481  0.033791   \ncfr_15  0.032731  0.009685 -0.019258  ...  0.301428  0.154375 -0.085936   \ncfr_16 -0.002994  0.010071 -0.004850  ...  0.273929  0.119418  0.205876   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.046960 -0.038058 -0.092294 -0.054016 -0.072729 -0.130987 -0.124267  \ndw_2    0.178912  0.060450  0.039959  0.136143  0.005734 -0.118431 -0.066128  \ndw_3    0.121813 -0.051209  0.069581  0.038555 -0.024726 -0.136079 -0.044854  \ndw_4    0.080194 -0.042344  0.051053  0.026543 -0.037506 -0.119712 -0.043279  \ndw_5    0.062258  0.002897  0.013172  0.024296 -0.044898 -0.070291 -0.028559  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.050509  0.078646  1.000000  0.025204  0.020729 -0.368802 -0.228329  \ncfr_13 -0.263557  0.025616  0.025204  1.000000  0.246144  0.176991 -0.125499  \ncfr_14 -0.177838 -0.278564  0.020729  0.246144  1.000000  0.233453 -0.128832  \ncfr_15 -0.131212 -0.053772 -0.368802  0.176991  0.233453  1.000000  0.371065  \ncfr_16  0.195965  0.020836 -0.228329 -0.125499 -0.128832  0.371065  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.273382</td>\n      <td>0.122628</td>\n      <td>0.083674</td>\n      <td>0.051094</td>\n      <td>0.221600</td>\n      <td>-0.049649</td>\n      <td>0.078730</td>\n      <td>-0.012908</td>\n      <td>0.013862</td>\n      <td>...</td>\n      <td>-0.117220</td>\n      <td>-0.037767</td>\n      <td>-0.071736</td>\n      <td>-0.046960</td>\n      <td>-0.038058</td>\n      <td>-0.092294</td>\n      <td>-0.054016</td>\n      <td>-0.072729</td>\n      <td>-0.130987</td>\n      <td>-0.124267</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.273382</td>\n      <td>1.000000</td>\n      <td>0.838009</td>\n      <td>0.506753</td>\n      <td>0.191967</td>\n      <td>0.386284</td>\n      <td>-0.517805</td>\n      <td>-0.334992</td>\n      <td>-0.004812</td>\n      <td>0.033948</td>\n      <td>...</td>\n      <td>-0.102493</td>\n      <td>0.182840</td>\n      <td>0.234210</td>\n      <td>0.178912</td>\n      <td>0.060450</td>\n      <td>0.039959</td>\n      <td>0.136143</td>\n      <td>0.005734</td>\n      <td>-0.118431</td>\n      <td>-0.066128</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.122628</td>\n      <td>0.838009</td>\n      <td>1.000000</td>\n      <td>0.707121</td>\n      <td>0.290188</td>\n      <td>0.236678</td>\n      <td>-0.561877</td>\n      <td>-0.475222</td>\n      <td>0.011125</td>\n      <td>0.014124</td>\n      <td>...</td>\n      <td>-0.197277</td>\n      <td>0.158323</td>\n      <td>0.273116</td>\n      <td>0.121813</td>\n      <td>-0.051209</td>\n      <td>0.069581</td>\n      <td>0.038555</td>\n      <td>-0.024726</td>\n      <td>-0.136079</td>\n      <td>-0.044854</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.083674</td>\n      <td>0.506753</td>\n      <td>0.707121</td>\n      <td>1.000000</td>\n      <td>0.871892</td>\n      <td>-0.017655</td>\n      <td>-0.285199</td>\n      <td>-0.270161</td>\n      <td>0.009232</td>\n      <td>0.003634</td>\n      <td>...</td>\n      <td>-0.149766</td>\n      <td>0.073674</td>\n      <td>0.107847</td>\n      <td>0.080194</td>\n      <td>-0.042344</td>\n      <td>0.051053</td>\n      <td>0.026543</td>\n      <td>-0.037506</td>\n      <td>-0.119712</td>\n      <td>-0.043279</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.051094</td>\n      <td>0.191967</td>\n      <td>0.290188</td>\n      <td>0.871892</td>\n      <td>1.000000</td>\n      <td>-0.129453</td>\n      <td>-0.030009</td>\n      <td>-0.050190</td>\n      <td>0.002565</td>\n      <td>-0.000720</td>\n      <td>...</td>\n      <td>-0.059404</td>\n      <td>0.011401</td>\n      <td>-0.015802</td>\n      <td>0.062258</td>\n      <td>0.002897</td>\n      <td>0.013172</td>\n      <td>0.024296</td>\n      <td>-0.044898</td>\n      <td>-0.070291</td>\n      <td>-0.028559</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.092294</td>\n      <td>0.039959</td>\n      <td>0.069581</td>\n      <td>0.051053</td>\n      <td>0.013172</td>\n      <td>-0.160514</td>\n      <td>0.118367</td>\n      <td>0.127268</td>\n      <td>-0.005908</td>\n      <td>0.006278</td>\n      <td>...</td>\n      <td>-0.134908</td>\n      <td>-0.218479</td>\n      <td>-0.043561</td>\n      <td>0.050509</td>\n      <td>0.078646</td>\n      <td>1.000000</td>\n      <td>0.025204</td>\n      <td>0.020729</td>\n      <td>-0.368802</td>\n      <td>-0.228329</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.054016</td>\n      <td>0.136143</td>\n      <td>0.038555</td>\n      <td>0.026543</td>\n      <td>0.024296</td>\n      <td>0.066207</td>\n      <td>-0.006270</td>\n      <td>0.019160</td>\n      <td>0.007572</td>\n      <td>-0.003219</td>\n      <td>...</td>\n      <td>0.180735</td>\n      <td>0.047865</td>\n      <td>-0.208494</td>\n      <td>-0.263557</td>\n      <td>0.025616</td>\n      <td>0.025204</td>\n      <td>1.000000</td>\n      <td>0.246144</td>\n      <td>0.176991</td>\n      <td>-0.125499</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.072729</td>\n      <td>0.005734</td>\n      <td>-0.024726</td>\n      <td>-0.037506</td>\n      <td>-0.044898</td>\n      <td>-0.013333</td>\n      <td>0.037817</td>\n      <td>0.030309</td>\n      <td>0.006547</td>\n      <td>-0.008574</td>\n      <td>...</td>\n      <td>0.131588</td>\n      <td>0.237481</td>\n      <td>0.033791</td>\n      <td>-0.177838</td>\n      <td>-0.278564</td>\n      <td>0.020729</td>\n      <td>0.246144</td>\n      <td>1.000000</td>\n      <td>0.233453</td>\n      <td>-0.128832</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.130987</td>\n      <td>-0.118431</td>\n      <td>-0.136079</td>\n      <td>-0.119712</td>\n      <td>-0.070291</td>\n      <td>0.043544</td>\n      <td>0.078133</td>\n      <td>0.032731</td>\n      <td>0.009685</td>\n      <td>-0.019258</td>\n      <td>...</td>\n      <td>0.301428</td>\n      <td>0.154375</td>\n      <td>-0.085936</td>\n      <td>-0.131212</td>\n      <td>-0.053772</td>\n      <td>-0.368802</td>\n      <td>0.176991</td>\n      <td>0.233453</td>\n      <td>1.000000</td>\n      <td>0.371065</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.124267</td>\n      <td>-0.066128</td>\n      <td>-0.044854</td>\n      <td>-0.043279</td>\n      <td>-0.028559</td>\n      <td>0.051793</td>\n      <td>-0.022612</td>\n      <td>-0.002994</td>\n      <td>0.010071</td>\n      <td>-0.004850</td>\n      <td>...</td>\n      <td>0.273929</td>\n      <td>0.119418</td>\n      <td>0.205876</td>\n      <td>0.195965</td>\n      <td>0.020836</td>\n      <td>-0.228329</td>\n      <td>-0.125499</td>\n      <td>-0.128832</td>\n      <td>0.371065</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_235', 'fft_227', 'fft_253', 'fft_143', 'fft_152', 'fft_180', 'fft_207', 'fft_242', 'fft_140', 'fft_158', 'fft_195', 'fft_224', 'fft_177', 'fft_182', 'mfw_16', 'fft_232', 'mfw_7', 'fft_234', 'fft_190', 'fft_155', 'fft_239', 'fft_171', 'fft_188', 'fft_147', 'fft_206', 'fft_244', 'fft_254', 'fft_173', 'fft_139', 'fft_230', 'fft_162', 'fft_172', 'fft_191', 'fft_240', 'mfw_8', 'fft_186', 'fft_176', 'fft_205', 'fft_219', 'fft_246', 'fft_202', 'fft_211', 'fft_215', 'fft_236', 'fft_243', 'fft_245', 'fft_200', 'fft_233', 'fft_131', 'fft_250', 'fft_214', 'fft_134', 'mfw_6', 'mfw_14', 'fft_204', 'fft_198', 'fft_209', 'mfw_15', 'fft_187', 'fft_133', 'fft_225', 'fft_222', 'fft_189', 'fft_151', 'fft_237', 'cfr_16', 'mfw_9', 'fft_221', 'fft_183', 'fft_170', 'fft_132', 'fft_156', 'fft_145', 'fft_184', 'fft_165', 'fft_161', 'fft_166', 'fft_252', 'fft_169', 'fft_220', 'fft_229', 'fft_163', 'fft_197', 'fft_137', 'fft_159', 'fft_213', 'fft_248', 'fft_141', 'fft_136', 'fft_160', 'fft_192', 'fft_193', 'fft_168', 'fft_228', 'fft_178', 'fft_208', 'fft_194', 'fft_154', 'fft_212', 'fft_255', 'fft_238', 'fft_135', 'fft_164', 'fft_203', 'fft_231', 'fft_179', 'fft_153', 'fft_256', 'mfw_5', 'fft_167', 'fft_201', 'fft_226', 'fft_216', 'fft_157', 'fft_218', 'fft_148', 'fft_249', 'mfw_13', 'fft_142', 'fft_130', 'fft_181', 'fft_174', 'mfw_12', 'fft_196', 'fft_217', 'fft_138', 'mfw_10', 'fft_146', 'fft_223', 'mfw_11', 'fft_247', 'fft_149', 'fft_150', 'fft_199', 'fft_185', 'fft_144', 'fft_175', 'fft_251', 'fft_241', 'fft_210'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_19\n",
      "fft_20\n",
      "fft_22\n",
      "fft_30\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_37\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_13\n",
      "ar_14\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 66\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         dw_1        dw_2        dw_3       dw_4       dw_5     mfw_1  \\\n0  267.535629  270.981533  270.243834  76.791207  11.207306  0.483334   \n1  277.949875  283.546637  283.543383  80.370321  11.621628  0.480582   \n2  280.952321  289.729213  288.768479  81.676148  11.842770  0.479468   \n3  266.093352  277.366979  279.066959  79.365536  11.515873  0.479998   \n4  279.838160  290.933842  289.849559  81.839924  11.791220  0.479852   \n\n      mfw_2     mfw_3     mfw_4      fft_1  ...     cfr_6     cfr_7     cfr_8  \\\n0 -0.435149 -0.637676 -0.096703  -1.065012  ...  0.016873  0.040724 -0.047331   \n1 -0.437337 -0.666380 -0.138188  -2.207264  ...  0.011581  0.052652 -0.053865   \n2 -0.434101 -0.641674 -0.075015  -0.855778  ...  0.031430  0.033720 -0.041838   \n3 -0.433339 -0.648197 -0.093792  -1.105237  ...  0.018259  0.048839 -0.047719   \n4 -0.432266 -0.660649 -0.107788  14.855103  ...  0.015173  0.050778 -0.050448   \n\n      cfr_9    cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0  0.034527 -0.042788  0.048729 -0.072291  0.006842 -0.025811 -0.008343  \n1  0.034099 -0.034026  0.038144 -0.071427  0.011442 -0.027634 -0.009450  \n2  0.031072 -0.035728  0.040951 -0.067828  0.007170 -0.022649 -0.013308  \n3  0.029625 -0.035988  0.049478 -0.081219  0.019213 -0.029185 -0.014198  \n4  0.030725 -0.035125  0.042994 -0.070263  0.010677 -0.027446 -0.011952  \n\n[5 rows x 66 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>267.535629</td>\n      <td>270.981533</td>\n      <td>270.243834</td>\n      <td>76.791207</td>\n      <td>11.207306</td>\n      <td>0.483334</td>\n      <td>-0.435149</td>\n      <td>-0.637676</td>\n      <td>-0.096703</td>\n      <td>-1.065012</td>\n      <td>...</td>\n      <td>0.016873</td>\n      <td>0.040724</td>\n      <td>-0.047331</td>\n      <td>0.034527</td>\n      <td>-0.042788</td>\n      <td>0.048729</td>\n      <td>-0.072291</td>\n      <td>0.006842</td>\n      <td>-0.025811</td>\n      <td>-0.008343</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>277.949875</td>\n      <td>283.546637</td>\n      <td>283.543383</td>\n      <td>80.370321</td>\n      <td>11.621628</td>\n      <td>0.480582</td>\n      <td>-0.437337</td>\n      <td>-0.666380</td>\n      <td>-0.138188</td>\n      <td>-2.207264</td>\n      <td>...</td>\n      <td>0.011581</td>\n      <td>0.052652</td>\n      <td>-0.053865</td>\n      <td>0.034099</td>\n      <td>-0.034026</td>\n      <td>0.038144</td>\n      <td>-0.071427</td>\n      <td>0.011442</td>\n      <td>-0.027634</td>\n      <td>-0.009450</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>280.952321</td>\n      <td>289.729213</td>\n      <td>288.768479</td>\n      <td>81.676148</td>\n      <td>11.842770</td>\n      <td>0.479468</td>\n      <td>-0.434101</td>\n      <td>-0.641674</td>\n      <td>-0.075015</td>\n      <td>-0.855778</td>\n      <td>...</td>\n      <td>0.031430</td>\n      <td>0.033720</td>\n      <td>-0.041838</td>\n      <td>0.031072</td>\n      <td>-0.035728</td>\n      <td>0.040951</td>\n      <td>-0.067828</td>\n      <td>0.007170</td>\n      <td>-0.022649</td>\n      <td>-0.013308</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>266.093352</td>\n      <td>277.366979</td>\n      <td>279.066959</td>\n      <td>79.365536</td>\n      <td>11.515873</td>\n      <td>0.479998</td>\n      <td>-0.433339</td>\n      <td>-0.648197</td>\n      <td>-0.093792</td>\n      <td>-1.105237</td>\n      <td>...</td>\n      <td>0.018259</td>\n      <td>0.048839</td>\n      <td>-0.047719</td>\n      <td>0.029625</td>\n      <td>-0.035988</td>\n      <td>0.049478</td>\n      <td>-0.081219</td>\n      <td>0.019213</td>\n      <td>-0.029185</td>\n      <td>-0.014198</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>279.838160</td>\n      <td>290.933842</td>\n      <td>289.849559</td>\n      <td>81.839924</td>\n      <td>11.791220</td>\n      <td>0.479852</td>\n      <td>-0.432266</td>\n      <td>-0.660649</td>\n      <td>-0.107788</td>\n      <td>14.855103</td>\n      <td>...</td>\n      <td>0.015173</td>\n      <td>0.050778</td>\n      <td>-0.050448</td>\n      <td>0.030725</td>\n      <td>-0.035125</td>\n      <td>0.042994</td>\n      <td>-0.070263</td>\n      <td>0.010677</td>\n      <td>-0.027446</td>\n      <td>-0.011952</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 66 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 1.344999074935913 s\n",
      "Accuracy 0.906158357771261 precision 0.9057527972192487 specificity 0.7620424852810053 recall 0.906158357771261 f1 0.9017406143295984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 1.2920000553131104 s\n",
      "Accuracy 0.8997067448680351 precision 0.8991919215243389 specificity 0.7406110236309791 recall 0.8997067448680351 f1 0.8943619621114333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 1.2619996070861816 s\n",
      "Accuracy 0.9055718475073313 precision 0.9069815124756913 specificity 0.7424858590721781 recall 0.9055718475073313 f1 0.8999469678902846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 1.25700044631958 s\n",
      "Accuracy 0.9049853372434018 precision 0.9055925138368518 specificity 0.7416350688218771 recall 0.9049853372434018 f1 0.8995159658314538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 1.2709989547729492 s\n",
      "Accuracy 0.9155425219941349 precision 0.9144107881067854 specificity 0.7707725823256982 recall 0.9155425219941349 f1 0.9119185067545713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 1.2690019607543945 s\n",
      "Accuracy 0.9143695014662757 precision 0.91578239751267 specificity 0.7591347720379978 recall 0.9143695014662757 f1 0.9096000551614422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 1.2509989738464355 s\n",
      "Accuracy 0.9173020527859238 precision 0.9160979458193651 specificity 0.7738968980876242 recall 0.9173020527859238 f1 0.9138511605392249\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 1.29599928855896 s\n",
      "Accuracy 0.9137829912023461 precision 0.9144506207324544 specificity 0.758592487724857 recall 0.9137829912023461 f1 0.9091601857950882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 1.2619996070861816 s\n",
      "Accuracy 0.9014662756598241 precision 0.903236782152431 specificity 0.7432910776580428 recall 0.9014662756598241 f1 0.895644563832223\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 1.2639992237091064 s\n",
      "Accuracy 0.9055718475073313 precision 0.9051475688000379 specificity 0.7439396467455422 recall 0.9055718475073313 f1 0.9005087749184297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 1.2780003547668457 s\n",
      "Accuracy 0.9090909090909091 precision 0.9087301927535824 specificity 0.7680829024342615 recall 0.9090909090909091 f1 0.904936596478885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 1.2139997482299805 s\n",
      "Accuracy 0.9073313782991203 precision 0.9058282979026867 specificity 0.7490827619289833 recall 0.9073313782991203 f1 0.9029028464784353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 1.2140004634857178 s\n",
      "Accuracy 0.9073313782991203 precision 0.9063781716701568 specificity 0.7548812653790408 recall 0.9073313782991203 f1 0.9028881657714197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 1.2250025272369385 s\n",
      "Accuracy 0.906158357771261 precision 0.9048271501455398 specificity 0.7631249471052642 recall 0.906158357771261 f1 0.9021200588639429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 1.2969996929168701 s\n",
      "Accuracy 0.9002932551319648 precision 0.9005722119612838 specificity 0.7600794863061017 recall 0.9002932551319648 f1 0.895451308977338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 1.1980006694793701 s\n",
      "Accuracy 0.9102639296187683 precision 0.9086730118310877 specificity 0.7551670377816813 recall 0.9102639296187683 f1 0.9061770655410604\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 1.3219988346099854 s\n",
      "Accuracy 0.9085043988269794 precision 0.9093455774691295 specificity 0.7478966978862938 recall 0.9085043988269794 f1 0.9033121248967755\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 1.2359986305236816 s\n",
      "Accuracy 0.9143695014662757 precision 0.9137160038595763 specificity 0.7555659538094937 recall 0.9143695014662757 f1 0.9100607280403293\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 1.228999137878418 s\n",
      "Accuracy 0.9090909090909091 precision 0.910045244948327 specificity 0.7551419562229239 recall 0.9090909090909091 f1 0.904133834895158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 1.2500004768371582 s\n",
      "Accuracy 0.9079178885630499 precision 0.9071314166241083 specificity 0.7558215358819725 recall 0.9079178885630499 f1 0.9034639242118735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 1.2769994735717773 s\n",
      "Accuracy 0.9167155425219942 precision 0.9185847619635631 specificity 0.7691104381825088 recall 0.9167155425219942 f1 0.9122258016064229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 1.2729992866516113 s\n",
      "Accuracy 0.906158357771261 precision 0.9074870517062165 specificity 0.7631121828604126 recall 0.906158357771261 f1 0.9012954555403725\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 1.241999626159668 s\n",
      "Accuracy 0.9137829912023461 precision 0.9129994350140862 specificity 0.7561865541103576 recall 0.9137829912023461 f1 0.909519672764956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 1.2400009632110596 s\n",
      "Accuracy 0.9126099706744868 precision 0.9121264181340715 specificity 0.770485945754763 recall 0.9126099706744868 f1 0.9086624817223676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 1.2189996242523193 s\n",
      "Accuracy 0.9102639296187683 precision 0.9089266693213848 specificity 0.7642843359141334 recall 0.9102639296187683 f1 0.9063742823286762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 1.255000114440918 s\n",
      "Accuracy 0.9143695014662757 precision 0.912958270030053 specificity 0.7559764477000488 recall 0.9143695014662757 f1 0.9103606086759762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 1.3029987812042236 s\n",
      "Accuracy 0.9038123167155425 precision 0.903066481599371 specificity 0.7416666104875227 recall 0.9038123167155425 f1 0.8987164484129131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 1.2710013389587402 s\n",
      "Accuracy 0.9167155425219942 precision 0.915903835835924 specificity 0.7505899922573627 recall 0.9167155425219942 f1 0.9123871868524723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 1.2279984951019287 s\n",
      "Accuracy 0.9173020527859238 precision 0.9167870480016698 specificity 0.7564824083669586 recall 0.9173020527859238 f1 0.9130733317583114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 1.2259995937347412 s\n",
      "Accuracy 0.9102639296187683 precision 0.9088932089122975 specificity 0.7689379034478185 recall 0.9102639296187683 f1 0.9065446956315525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 1.2720003128051758 s\n",
      "Accuracy 0.8991202346041056 precision 0.8989634454261806 specificity 0.71761433801282 recall 0.8991202346041056 f1 0.8927439312632676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 1.2609987258911133 s\n",
      "Accuracy 0.9178885630498533 precision 0.9174078633363509 specificity 0.7919192895395188 recall 0.9178885630498533 f1 0.9147059492145763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 1.2680003643035889 s\n",
      "Accuracy 0.9090909090909091 precision 0.9091117731407603 specificity 0.758046300457521 recall 0.9090909090909091 f1 0.9044857573492946\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 1.196000576019287 s\n",
      "Accuracy 0.910850439882698 precision 0.9087543577864842 specificity 0.7498018328076936 recall 0.910850439882698 f1 0.9068468141828845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 1.2219998836517334 s\n",
      "Accuracy 0.9225806451612903 precision 0.9206695961254167 specificity 0.7838648410450616 recall 0.9225806451612903 f1 0.919973379683196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 1.306999683380127 s\n",
      "Accuracy 0.9143695014662757 precision 0.9135986442976071 specificity 0.7589899326745267 recall 0.9143695014662757 f1 0.9102088297534217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 1.2389986515045166 s\n",
      "Accuracy 0.9014662756598241 precision 0.9009157694457894 specificity 0.7389240207788915 recall 0.9014662756598241 f1 0.8961256173436447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 1.2619988918304443 s\n",
      "Accuracy 0.893841642228739 precision 0.8910270347883164 specificity 0.7409805248514926 recall 0.893841642228739 f1 0.8893877694462035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 1.239001750946045 s\n",
      "Accuracy 0.9149560117302052 precision 0.912902680062945 specificity 0.7615416370123832 recall 0.9149560117302052 f1 0.9114721761748386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 1.2589976787567139 s\n",
      "Accuracy 0.9114369501466275 precision 0.9098217474698739 specificity 0.7518096918654437 recall 0.9114369501466275 f1 0.9072840139544248\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 1.3179988861083984 s\n",
      "Accuracy 0.9102639296187683 precision 0.9100246224350492 specificity 0.7619924858884237 recall 0.9102639296187683 f1 0.9059018650658609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 1.205000877380371 s\n",
      "Accuracy 0.8997067448680351 precision 0.900601396347514 specificity 0.72570829935304 recall 0.8997067448680351 f1 0.8933708206252728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 1.255997896194458 s\n",
      "Accuracy 0.8944281524926686 precision 0.8938584642293185 specificity 0.7189687575144108 recall 0.8944281524926686 f1 0.888052102640842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 1.2810003757476807 s\n",
      "Accuracy 0.9085043988269794 precision 0.9101192315271032 specificity 0.7662544868180013 recall 0.9085043988269794 f1 0.9037440760804155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 1.249000072479248 s\n",
      "Accuracy 0.8932551319648094 precision 0.89327951733779 specificity 0.7311782024697363 recall 0.8932551319648094 f1 0.8871585059675717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 1.2600011825561523 s\n",
      "Accuracy 0.9008797653958944 precision 0.9008372569887948 specificity 0.7369298211941799 recall 0.9008797653958944 f1 0.8952834430936735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 1.250999927520752 s\n",
      "Accuracy 0.9043988269794722 precision 0.9038531156075368 specificity 0.7351544260493701 recall 0.9043988269794722 f1 0.899018067995993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 1.2249979972839355 s\n",
      "Accuracy 0.9173020527859238 precision 0.9181193846461608 specificity 0.7508268625382047 recall 0.9173020527859238 f1 0.9125233322397177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 1.2400009632110596 s\n",
      "Accuracy 0.9026392961876832 precision 0.9011502514878359 specificity 0.7407658637311495 recall 0.9026392961876832 f1 0.897750705888668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 1.2189974784851074 s\n",
      "Accuracy 0.8973607038123167 precision 0.898148031897637 specificity 0.7208142655821649 recall 0.8973607038123167 f1 0.8907675937901784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 1.2430002689361572 s\n",
      "Accuracy 0.9073313782991203 precision 0.9084087072504271 specificity 0.7504068839924037 recall 0.9073313782991203 f1 0.9021261109341099\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 1.2839996814727783 s\n",
      "Accuracy 0.910850439882698 precision 0.9125383358330909 specificity 0.7229330755095563 recall 0.910850439882698 f1 0.904690811171935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 1.266000747680664 s\n",
      "Accuracy 0.9073313782991203 precision 0.9078931304796078 specificity 0.741826019617132 recall 0.9073313782991203 f1 0.9019633057255166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 1.3240008354187012 s\n",
      "Accuracy 0.9120234604105572 precision 0.9125023979661439 specificity 0.7522475630913955 recall 0.9120234604105572 f1 0.9071904142179626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 1.1689996719360352 s\n",
      "Accuracy 0.9102639296187683 precision 0.909711969280406 specificity 0.7584944901672972 recall 0.9102639296187683 f1 0.9058877654125023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 1.268998146057129 s\n",
      "Accuracy 0.9032258064516129 precision 0.902539661166818 specificity 0.7413697117364185 recall 0.9032258064516129 f1 0.8980793882378969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 1.258000135421753 s\n",
      "Accuracy 0.9067448680351906 precision 0.9085416142496984 specificity 0.7522173769794326 recall 0.9067448680351906 f1 0.9014110346217499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 1.2420001029968262 s\n",
      "Accuracy 0.9202346041055719 precision 0.9198198203195244 specificity 0.7818324380343152 recall 0.9202346041055719 f1 0.9167977428241357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 1.2660002708435059 s\n",
      "Accuracy 0.9120234604105572 precision 0.9101863365092417 specificity 0.7722813090984018 recall 0.9120234604105572 f1 0.9086950796860674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 1.2529990673065186 s\n",
      "Accuracy 0.9161290322580645 precision 0.9152588904528693 specificity 0.7619841752891052 recall 0.9161290322580645 f1 0.9121515641961476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 1.2330005168914795 s\n",
      "Accuracy 0.9085043988269794 precision 0.9076870493544077 specificity 0.763860570148159 recall 0.9085043988269794 f1 0.9043503924651781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 1.2689995765686035 s\n",
      "Accuracy 0.9073313782991203 precision 0.9060308533676876 specificity 0.7496578815700051 recall 0.9073313782991203 f1 0.9028394883083558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 1.2159996032714844 s\n",
      "Accuracy 0.9026392961876832 precision 0.9041457308254639 specificity 0.7299805383983289 recall 0.9026392961876832 f1 0.8964241791187503\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 1.2460033893585205 s\n",
      "Accuracy 0.9085043988269794 precision 0.9071592517954109 specificity 0.7520350562483833 recall 0.9085043988269794 f1 0.904149972624521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 1.167999267578125 s\n",
      "Accuracy 0.9143695014662757 precision 0.9134619540052478 specificity 0.7457377968432699 recall 0.9143695014662757 f1 0.9098373856157868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 1.2809998989105225 s\n",
      "Accuracy 0.906158357771261 precision 0.9055282959441863 specificity 0.7615167770341739 recall 0.906158357771261 f1 0.9017976145553576\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 1.2360002994537354 s\n",
      "Accuracy 0.8973607038123167 precision 0.8977868816323261 specificity 0.7190152883301801 recall 0.8973607038123167 f1 0.8907959526882199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 1.1969993114471436 s\n",
      "Accuracy 0.9120234604105572 precision 0.9119706666045918 specificity 0.7510540795194509 recall 0.9120234604105572 f1 0.907302430626841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 1.244999647140503 s\n",
      "Accuracy 0.9120234604105572 precision 0.9135894550257336 specificity 0.725205759335618 recall 0.9120234604105572 f1 0.9060241148522137\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 1.217000961303711 s\n",
      "Accuracy 0.9090909090909091 precision 0.9100215057486758 specificity 0.764079705676944 recall 0.9090909090909091 f1 0.9044381896425832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 1.2619996070861816 s\n",
      "Accuracy 0.9126099706744868 precision 0.9119264732494202 specificity 0.7553094750443025 recall 0.9126099706744868 f1 0.9082463365277318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 1.218000888824463 s\n",
      "Accuracy 0.9114369501466275 precision 0.9108257901601066 specificity 0.7684205997109222 recall 0.9114369501466275 f1 0.907436474765621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 1.1889991760253906 s\n",
      "Accuracy 0.9173020527859238 precision 0.9174545861513057 specificity 0.7556150599163781 recall 0.9173020527859238 f1 0.9128448330319034\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 1.3340001106262207 s\n",
      "Accuracy 0.9167155425219942 precision 0.9169239956563673 specificity 0.7744645093801983 recall 0.9167155425219942 f1 0.9127869456519535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 1.1889991760253906 s\n",
      "Accuracy 0.9208211143695014 precision 0.9213806873722563 specificity 0.7709016115737568 recall 0.9208211143695014 f1 0.9168139631367915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 1.2559990882873535 s\n",
      "Accuracy 0.9067448680351906 precision 0.9058427823888981 specificity 0.7544961257678586 recall 0.9067448680351906 f1 0.902252559372092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 1.2319986820220947 s\n",
      "Accuracy 0.9149560117302052 precision 0.9132087924701561 specificity 0.7630884993975767 recall 0.9149560117302052 f1 0.9113524705915947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 1.23699951171875 s\n",
      "Accuracy 0.9190615835777126 precision 0.9192901028861439 specificity 0.767831392723457 recall 0.9190615835777126 f1 0.9150010276603533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 1.2169997692108154 s\n",
      "Accuracy 0.9073313782991203 precision 0.9054390349582724 specificity 0.75297808836388 recall 0.9073313782991203 f1 0.9032218251319398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 1.241999864578247 s\n",
      "Accuracy 0.9073313782991203 precision 0.9063558864408575 specificity 0.7541174198064039 recall 0.9073313782991203 f1 0.9028699426737512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 1.2050001621246338 s\n",
      "Accuracy 0.8926686217008798 precision 0.8922172820820062 specificity 0.7301484895651312 recall 0.8926686217008798 f1 0.8866607718665005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 1.2010002136230469 s\n",
      "Accuracy 0.9096774193548387 precision 0.9105783972377488 specificity 0.7562271151438436 recall 0.9096774193548387 f1 0.9047884213993479\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 1.2469995021820068 s\n",
      "Accuracy 0.9219941348973607 precision 0.9219279225916132 specificity 0.7881867537714784 recall 0.9219941348973607 f1 0.9186677252366403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 1.2289998531341553 s\n",
      "Accuracy 0.9149560117302052 precision 0.9134868767855482 specificity 0.7556685454112058 recall 0.9149560117302052 f1 0.9109814951107023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 1.2519989013671875 s\n",
      "Accuracy 0.9090909090909091 precision 0.9082853885579855 specificity 0.7729862367015631 recall 0.9090909090909091 f1 0.9052512752558322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 1.2650010585784912 s\n",
      "Accuracy 0.9155425219941349 precision 0.9143889783108798 specificity 0.7485918740358525 recall 0.9155425219941349 f1 0.9112346581991758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 1.2249996662139893 s\n",
      "Accuracy 0.910850439882698 precision 0.9116623569454885 specificity 0.76871611214842 recall 0.910850439882698 f1 0.9064270427409308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 1.2869987487792969 s\n",
      "Accuracy 0.906158357771261 precision 0.9057033188945135 specificity 0.7530054285111694 recall 0.906158357771261 f1 0.9014430792254682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 1.270998239517212 s\n",
      "Accuracy 0.9102639296187683 precision 0.9087676382448351 specificity 0.7699696791288719 recall 0.9102639296187683 f1 0.9066365285695085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 1.2390007972717285 s\n",
      "Accuracy 0.9137829912023461 precision 0.9158793050187528 specificity 0.7722729664671333 recall 0.9137829912023461 f1 0.9092572137942188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 1.2109990119934082 s\n",
      "Accuracy 0.9043988269794722 precision 0.9044032529247663 specificity 0.7533644034299891 recall 0.9043988269794722 f1 0.8995013848587032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 1.3120002746582031 s\n",
      "Accuracy 0.9167155425219942 precision 0.9166250213030291 specificity 0.7712153458687653 recall 0.9167155425219942 f1 0.9127769586646812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 1.1319999694824219 s\n",
      "Accuracy 0.9079178885630499 precision 0.9072558286914878 specificity 0.7288227077745553 recall 0.9079178885630499 f1 0.9024833529972264\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 1.2239973545074463 s\n",
      "Accuracy 0.9090909090909091 precision 0.9088760421048823 specificity 0.7657389236044138 recall 0.9090909090909091 f1 0.9048128691077748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 1.1920006275177002 s\n",
      "Accuracy 0.9219941348973607 precision 0.9217943028902142 specificity 0.7634801033858664 recall 0.9219941348973607 f1 0.9180285038806396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 1.2450017929077148 s\n",
      "Accuracy 0.9073313782991203 precision 0.9077173247627792 specificity 0.7451559193494678 recall 0.9073313782991203 f1 0.9021273781568986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 1.2479994297027588 s\n",
      "Accuracy 0.8991202346041056 precision 0.8990343451896805 specificity 0.736287661757551 recall 0.8991202346041056 f1 0.8934537410168791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 1.241999626159668 s\n",
      "Accuracy 0.8979472140762463 precision 0.8976760996323324 specificity 0.7483250800711054 recall 0.8979472140762463 f1 0.892768866447644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 1.1869995594024658 s\n",
      "Accuracy 0.9032258064516129 precision 0.9029099184661868 specificity 0.7379295067750398 recall 0.9032258064516129 f1 0.8978314437062269\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 1.227001428604126 s\n",
      "Accuracy 0.9143695014662757 precision 0.9146140891336815 specificity 0.7735669599107706 recall 0.9143695014662757 f1 0.9103417678758662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 1.2020001411437988 s\n",
      "Accuracy 0.9096774193548387 precision 0.909888303299571 specificity 0.758975799879065 recall 0.9096774193548387 f1 0.9050651571326777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 1.248000144958496 s\n",
      "Accuracy 0.918475073313783 precision 0.9173646138807429 specificity 0.7936059205206494 recall 0.918475073313783 f1 0.9155962326270317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 1.2320003509521484 s\n",
      "Accuracy 0.8991202346041056 precision 0.8988604371853854 specificity 0.722891259648768 recall 0.8991202346041056 f1 0.8929845012184848\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 1.3000009059906006 s\n",
      "Accuracy 0.9155425219941349 precision 0.9165743734578163 specificity 0.7616200164450432 recall 0.9155425219941349 f1 0.9109786126265118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 1.2659986019134521 s\n",
      "Accuracy 0.9073313782991203 precision 0.905724154943664 specificity 0.7628202642068383 recall 0.9073313782991203 f1 0.903435259112941\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 1.217000961303711 s\n",
      "Accuracy 0.9090909090909091 precision 0.9081924599676598 specificity 0.7759653936929507 recall 0.9090909090909091 f1 0.9053844651100968\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 1.2360002994537354 s\n",
      "Accuracy 0.9120234604105572 precision 0.9121985620340394 specificity 0.7685511797354119 recall 0.9120234604105572 f1 0.9077973336470847\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 1.23699951171875 s\n",
      "Accuracy 0.9067448680351906 precision 0.9074754066774798 specificity 0.7348561302778452 recall 0.9067448680351906 f1 0.9010649669321533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 1.2120006084442139 s\n",
      "Accuracy 0.910850439882698 precision 0.9113625481960171 specificity 0.7475826303150781 recall 0.910850439882698 f1 0.9058154692971552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 1.2029993534088135 s\n",
      "Accuracy 0.9120234604105572 precision 0.9108794383972894 specificity 0.7580162540850374 recall 0.9120234604105572 f1 0.9078976592657921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 1.1730015277862549 s\n",
      "Accuracy 0.9067448680351906 precision 0.9065680503902398 specificity 0.7491824080129369 recall 0.9067448680351906 f1 0.9018260676704699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 1.2609977722167969 s\n",
      "Accuracy 0.9008797653958944 precision 0.9003936853121142 specificity 0.7386636001384458 recall 0.9008797653958944 f1 0.8954888127194431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 1.2079997062683105 s\n",
      "Accuracy 0.910850439882698 precision 0.9103314651542133 specificity 0.7765350554477458 recall 0.910850439882698 f1 0.9070647290659399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 1.2149991989135742 s\n",
      "Accuracy 0.9255131964809384 precision 0.9270709172894396 specificity 0.7881050371372952 recall 0.9255131964809384 f1 0.9218776196572595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 1.2170002460479736 s\n",
      "Accuracy 0.9043988269794722 precision 0.9051510998337489 specificity 0.7437582056819421 recall 0.9043988269794722 f1 0.8989468177402823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 1.222998857498169 s\n",
      "Accuracy 0.9143695014662757 precision 0.9146140891336815 specificity 0.7735669599107706 recall 0.9143695014662757 f1 0.9103417678758662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 1.1630001068115234 s\n",
      "Accuracy 0.8997067448680351 precision 0.8996165798573117 specificity 0.7606728235944819 recall 0.8997067448680351 f1 0.8949835567810748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 1.2189972400665283 s\n",
      "Accuracy 0.9137829912023461 precision 0.9142940442993802 specificity 0.7415167050969458 recall 0.9137829912023461 f1 0.9086592656905628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 1.3409996032714844 s\n",
      "Accuracy 0.9096774193548387 precision 0.910650870214087 specificity 0.7376764253668147 recall 0.9096774193548387 f1 0.904145712066373\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 1.182997465133667 s\n",
      "Accuracy 0.9038123167155425 precision 0.9043541467548816 specificity 0.7337866434640629 recall 0.9038123167155425 f1 0.8980340257502384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 1.2529971599578857 s\n",
      "Accuracy 0.9161290322580645 precision 0.9165148625829742 specificity 0.7788068368264114 recall 0.9161290322580645 f1 0.9122652866732969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 1.1989991664886475 s\n",
      "Accuracy 0.9079178885630499 precision 0.9090074994065039 specificity 0.7435256062137783 recall 0.9079178885630499 f1 0.9024917667989032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 1.2159979343414307 s\n",
      "Accuracy 0.9131964809384164 precision 0.9125711037826737 specificity 0.7747616679976731 recall 0.9131964809384164 f1 0.9094458930839177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 1.2289988994598389 s\n",
      "Accuracy 0.9032258064516129 precision 0.9039424907633886 specificity 0.736859164419829 recall 0.9032258064516129 f1 0.8974914905034908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 1.2310001850128174 s\n",
      "Accuracy 0.906158357771261 precision 0.9060905813886052 specificity 0.7504039201854112 recall 0.906158357771261 f1 0.9012305775969986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 1.2200000286102295 s\n",
      "Accuracy 0.910850439882698 precision 0.9096882806560226 specificity 0.753218824186566 recall 0.910850439882698 f1 0.9065367514899252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 1.2289986610412598 s\n",
      "Accuracy 0.9067448680351906 precision 0.9066932875400819 specificity 0.745099447556199 recall 0.9067448680351906 f1 0.9016456773465219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 1.246000051498413 s\n",
      "Accuracy 0.9126099706744868 precision 0.9115440251533811 specificity 0.7759165565617179 recall 0.9126099706744868 f1 0.9090463564561041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 1.2300004959106445 s\n",
      "Accuracy 0.9049853372434018 precision 0.9041144501868462 specificity 0.7099418195970263 recall 0.9049853372434018 f1 0.8988034708387459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 1.188000202178955 s\n",
      "Accuracy 0.9067448680351906 precision 0.9074555407948813 specificity 0.7234860731315749 recall 0.9067448680351906 f1 0.9006648220494426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 1.2289977073669434 s\n",
      "Accuracy 0.9055718475073313 precision 0.9050053097062336 specificity 0.7543333714850922 recall 0.9055718475073313 f1 0.9009230325638697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 1.2199993133544922 s\n",
      "Accuracy 0.9020527859237537 precision 0.9015732841612608 specificity 0.7358475054054789 recall 0.9020527859237537 f1 0.8965930369632721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 1.2329983711242676 s\n",
      "Accuracy 0.9090909090909091 precision 0.9080635604061142 specificity 0.7445253538412131 recall 0.9090909090909091 f1 0.9043739035695159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 1.2239997386932373 s\n",
      "Accuracy 0.9067448680351906 precision 0.9064286956199825 specificity 0.752426453595317 recall 0.9067448680351906 f1 0.9019822129423416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 1.1819977760314941 s\n",
      "Accuracy 0.9038123167155425 precision 0.9025422794522965 specificity 0.7246683188355996 recall 0.9038123167155425 f1 0.8982742379809828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 1.2499992847442627 s\n",
      "Accuracy 0.9079178885630499 precision 0.9081145016824246 specificity 0.7503252263467317 recall 0.9079178885630499 f1 0.9029647830958416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 1.2240009307861328 s\n",
      "Accuracy 0.9131964809384164 precision 0.9132451175511466 specificity 0.7603779712767528 recall 0.9131964809384164 f1 0.9087817189357482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 1.1999990940093994 s\n",
      "Accuracy 0.9190615835777126 precision 0.9178207574036469 specificity 0.7650218608631186 recall 0.9190615835777126 f1 0.9154113415235544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 1.238999366760254 s\n",
      "Accuracy 0.9120234604105572 precision 0.9109557142096724 specificity 0.7538222595406205 recall 0.9120234604105572 f1 0.9077309673414498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 1.2109999656677246 s\n",
      "Accuracy 0.9155425219941349 precision 0.9146462802807717 specificity 0.750799509146629 recall 0.9155425219941349 f1 0.9112087452435998\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 1.2339999675750732 s\n",
      "Accuracy 0.9149560117302052 precision 0.916694678140474 specificity 0.7645242366573033 recall 0.9149560117302052 f1 0.9102998416897266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 1.2160007953643799 s\n",
      "Accuracy 0.9208211143695014 precision 0.9213872392264351 specificity 0.7818847818847818 recall 0.9208211143695014 f1 0.9171192443919715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 1.2119998931884766 s\n",
      "Accuracy 0.9149560117302052 precision 0.9137358141810004 specificity 0.7585266900292363 recall 0.9149560117302052 f1 0.910968092870143\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 1.248000144958496 s\n",
      "Accuracy 0.9073313782991203 precision 0.9093844334364204 specificity 0.7539094305244093 recall 0.9073313782991203 f1 0.902017302390804\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 1.2040026187896729 s\n",
      "Accuracy 0.9214076246334311 precision 0.9220955148826505 specificity 0.7688442251271882 recall 0.9214076246334311 f1 0.9173285601179338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 1.2749981880187988 s\n",
      "Accuracy 0.9167155425219942 precision 0.9185047596980217 specificity 0.7654847084342093 recall 0.9167155425219942 f1 0.9121333767785382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 1.1710002422332764 s\n",
      "Accuracy 0.8991202346041056 precision 0.9010553068477641 specificity 0.7462805937901699 recall 0.8991202346041056 f1 0.893299103338727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 1.2330002784729004 s\n",
      "Accuracy 0.9243401759530792 precision 0.924173325410671 specificity 0.7764386851326837 recall 0.9243401759530792 f1 0.9207923033120583\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 1.2000000476837158 s\n",
      "Accuracy 0.918475073313783 precision 0.9189638318670577 specificity 0.7760186050508631 recall 0.918475073313783 f1 0.9145638324532749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 1.2650001049041748 s\n",
      "Accuracy 0.9143695014662757 precision 0.9134646731925767 specificity 0.7754139157290864 recall 0.9143695014662757 f1 0.9107692900663884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 1.186999797821045 s\n",
      "Accuracy 0.9026392961876832 precision 0.9024651156684164 specificity 0.7400958889203832 recall 0.9026392961876832 f1 0.8972607348477399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 1.2359983921051025 s\n",
      "Accuracy 0.9178885630498533 precision 0.9173349323170332 specificity 0.7817107414902102 recall 0.9178885630498533 f1 0.9144363055431121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 1.254997968673706 s\n",
      "Accuracy 0.9020527859237537 precision 0.9022546962350763 specificity 0.7237854281497546 recall 0.9020527859237537 f1 0.895928909509135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 1.2230005264282227 s\n",
      "Accuracy 0.9155425219941349 precision 0.9154459177211369 specificity 0.756427174975562 recall 0.9155425219941349 f1 0.9111223809164093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 1.2300004959106445 s\n",
      "Accuracy 0.9161290322580645 precision 0.9159167295104149 specificity 0.7544767274241599 recall 0.9161290322580645 f1 0.9117037567441625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 1.221998929977417 s\n",
      "Accuracy 0.9131964809384164 precision 0.9130199208380472 specificity 0.7844427721494376 recall 0.9131964809384164 f1 0.909597933287559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 1.215001106262207 s\n",
      "Accuracy 0.9120234604105572 precision 0.9109701553053592 specificity 0.7680368543353583 recall 0.9120234604105572 f1 0.9081877383558437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 1.2409989833831787 s\n",
      "Accuracy 0.9008797653958944 precision 0.9003234483832425 specificity 0.7207904631481735 recall 0.9008797653958944 f1 0.894826654159719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 1.1909995079040527 s\n",
      "Accuracy 0.9178885630498533 precision 0.917433359524343 specificity 0.7857296705683803 recall 0.9178885630498533 f1 0.9145194008800849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 1.2370009422302246 s\n",
      "Accuracy 0.9055718475073313 precision 0.9061510848843838 specificity 0.7434995389501042 recall 0.9055718475073313 f1 0.9001966667613022\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 1.240999460220337 s\n",
      "Accuracy 0.9055718475073313 precision 0.9066089728659601 specificity 0.7593666622587646 recall 0.9055718475073313 f1 0.9006348922572918\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 1.2869977951049805 s\n",
      "Accuracy 0.9096774193548387 precision 0.9085218935600325 specificity 0.7688657424171417 recall 0.9096774193548387 f1 0.9058500528095209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 1.2509987354278564 s\n",
      "Accuracy 0.9131964809384164 precision 0.9132120079014989 specificity 0.7841472690615835 recall 0.9131964809384164 f1 0.9095308209105178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 1.2389981746673584 s\n",
      "Accuracy 0.9090909090909091 precision 0.9094078032520243 specificity 0.7600838973169352 recall 0.9090909090909091 f1 0.9044684564777031\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 1.2420003414154053 s\n",
      "Accuracy 0.9149560117302052 precision 0.9145179253201475 specificity 0.7580959363217429 recall 0.9149560117302052 f1 0.9106740685745224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 1.228001356124878 s\n",
      "Accuracy 0.9126099706744868 precision 0.9142176906245325 specificity 0.7565545075771961 recall 0.9126099706744868 f1 0.9076557322642783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 1.2369985580444336 s\n",
      "Accuracy 0.9202346041055719 precision 0.919444840859176 specificity 0.7736888349676422 recall 0.9202346041055719 f1 0.9166965492122467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 1.2520017623901367 s\n",
      "Accuracy 0.906158357771261 precision 0.9076803876233668 specificity 0.7497523333534379 recall 0.906158357771261 f1 0.9007835367101312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 1.230999231338501 s\n",
      "Accuracy 0.9102639296187683 precision 0.9109089075297093 specificity 0.7496354018072678 recall 0.9102639296187683 f1 0.9052412635303881\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 1.0849978923797607 s\n",
      "Accuracy 0.9137829912023461 precision 0.9144254678797714 specificity 0.7676841902648354 recall 0.9137829912023461 f1 0.9094509041259423\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 1.1800005435943604 s\n",
      "Accuracy 0.9043988269794722 precision 0.9029165935429226 specificity 0.7466012696482214 recall 0.9043988269794722 f1 0.8997803806532205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 1.2309999465942383 s\n",
      "Accuracy 0.9090909090909091 precision 0.9105399127644578 specificity 0.7526119988148076 recall 0.9090909090909091 f1 0.9039275571381902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 1.2799999713897705 s\n",
      "Accuracy 0.896774193548387 precision 0.8959567721822389 specificity 0.7347316648163683 recall 0.896774193548387 f1 0.8912094442445803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 1.1419990062713623 s\n",
      "Accuracy 0.9178885630498533 precision 0.9174194120104181 specificity 0.7609310682942693 recall 0.9178885630498533 f1 0.9137976413427629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 1.2809979915618896 s\n",
      "Accuracy 0.9102639296187683 precision 0.9103785737274565 specificity 0.7491665092234353 recall 0.9102639296187683 f1 0.9053724626933464\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 1.199000358581543 s\n",
      "Accuracy 0.9178885630498533 precision 0.9174957068433225 specificity 0.7806554982528287 recall 0.9178885630498533 f1 0.9143521041405089\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 1.2139980792999268 s\n",
      "Accuracy 0.9020527859237537 precision 0.902886710514211 specificity 0.7148725447568811 recall 0.9020527859237537 f1 0.8954121695116434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 1.2319998741149902 s\n",
      "Accuracy 0.9143695014662757 precision 0.9143459053768614 specificity 0.7717418308583242 recall 0.9143695014662757 f1 0.91036297741778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 1.2099990844726562 s\n",
      "Accuracy 0.9043988269794722 precision 0.903125169707831 specificity 0.7406246431854407 recall 0.9043988269794722 f1 0.8994769271507776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 1.2410004138946533 s\n",
      "Accuracy 0.9090909090909091 precision 0.9070850684194817 specificity 0.7484228753702438 recall 0.9090909090909091 f1 0.904930682976403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 1.2250003814697266 s\n",
      "Accuracy 0.9102639296187683 precision 0.90838595568093 specificity 0.7710061793387524 recall 0.9102639296187683 f1 0.9068707737752472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 1.230999231338501 s\n",
      "Accuracy 0.9090909090909091 precision 0.9091108057105352 specificity 0.7662352895774854 recall 0.9090909090909091 f1 0.90475791636654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 1.2100005149841309 s\n",
      "Accuracy 0.9067448680351906 precision 0.9059987717593422 specificity 0.7527760232871692 recall 0.9067448680351906 f1 0.9021371609244092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 1.2360002994537354 s\n",
      "Accuracy 0.906158357771261 precision 0.9066326238544609 specificity 0.7329855208643559 recall 0.906158357771261 f1 0.9004588074796803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 1.2129995822906494 s\n",
      "Accuracy 0.9255131964809384 precision 0.92508241572586 specificity 0.778867766676297 recall 0.9255131964809384 f1 0.922146515542796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 1.2110025882720947 s\n",
      "Accuracy 0.918475073313783 precision 0.9193039291769193 specificity 0.769705945849746 recall 0.918475073313783 f1 0.9142941823542788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 1.1999986171722412 s\n",
      "Accuracy 0.9131964809384164 precision 0.9136476512133173 specificity 0.7667798992722751 recall 0.9131964809384164 f1 0.9088701985680039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 1.2189984321594238 s\n",
      "Accuracy 0.9079178885630499 precision 0.9065698528697873 specificity 0.7433601417968368 recall 0.9079178885630499 f1 0.9032427683490962\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 1.1989986896514893 s\n",
      "Accuracy 0.9120234604105572 precision 0.9093286485636294 specificity 0.7518037109251766 recall 0.9120234604105572 f1 0.9085501550873056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 1.2399988174438477 s\n",
      "Accuracy 0.9085043988269794 precision 0.9103481975454477 specificity 0.7529701926056324 recall 0.9085043988269794 f1 0.9032426574353645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 1.2059991359710693 s\n",
      "Accuracy 0.910850439882698 precision 0.9100266203478012 specificity 0.7583968894315388 recall 0.910850439882698 f1 0.9065822269558403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 1.2490012645721436 s\n",
      "Accuracy 0.9178885630498533 precision 0.9192680704308611 specificity 0.7672703640445576 recall 0.9178885630498533 f1 0.9134877040919168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 1.2509987354278564 s\n",
      "Accuracy 0.9038123167155425 precision 0.9059604776566217 specificity 0.7479439729717816 recall 0.9038123167155425 f1 0.8981520829309124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 1.2489993572235107 s\n",
      "Accuracy 0.9167155425219942 precision 0.9195893021653058 specificity 0.7741234806883059 recall 0.9167155425219942 f1 0.9121780226469512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 1.237999677658081 s\n",
      "Accuracy 0.9090909090909091 precision 0.9110159358738905 specificity 0.747771283897475 recall 0.9090909090909091 f1 0.9036534791505134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 1.2590012550354004 s\n",
      "Accuracy 0.906158357771261 precision 0.9059102418084366 specificity 0.7357817389071667 recall 0.906158357771261 f1 0.9007696920410394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 1.272998332977295 s\n",
      "Accuracy 0.9026392961876832 precision 0.9012612684504065 specificity 0.7503806468322597 recall 0.9026392961876832 f1 0.8980653696515246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 1.2269995212554932 s\n",
      "Accuracy 0.918475073313783 precision 0.9179266481319267 specificity 0.7843027044639947 recall 0.918475073313783 f1 0.9151098819740203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 1.2079994678497314 s\n",
      "Accuracy 0.9067448680351906 precision 0.9054688939150433 specificity 0.7418113077456451 recall 0.9067448680351906 f1 0.9019463008928575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 1.298999309539795 s\n",
      "Accuracy 0.9120234604105572 precision 0.9138198091776081 specificity 0.7606979897585001 recall 0.9120234604105572 f1 0.9071416153272437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 1.1790006160736084 s\n",
      "Accuracy 0.9155425219941349 precision 0.9148963958596043 specificity 0.7897717583831884 recall 0.9155425219941349 f1 0.9123081604304015\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 1.288001537322998 s\n",
      "Accuracy 0.9214076246334311 precision 0.9214631897110891 specificity 0.7721188231334122 recall 0.9214076246334311 f1 0.917588925938072\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 1.219998836517334 s\n",
      "Accuracy 0.9073313782991203 precision 0.9074370139923762 specificity 0.7694286353345946 recall 0.9073313782991203 f1 0.9030359915037942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 1.237999439239502 s\n",
      "Accuracy 0.9149560117302052 precision 0.9142293308538633 specificity 0.7776706477582312 recall 0.9149560117302052 f1 0.9113734742489629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 1.1779999732971191 s\n",
      "Accuracy 0.8961876832844575 precision 0.8974944084105307 specificity 0.7215156695612163 recall 0.8961876832844575 f1 0.889438559164892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 1.1989984512329102 s\n",
      "Accuracy 0.9143695014662757 precision 0.9140164565046774 specificity 0.7751282933512612 recall 0.9143695014662757 f1 0.9105681714280689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 1.2769999504089355 s\n",
      "Accuracy 0.9032258064516129 precision 0.9065395061316982 specificity 0.7376302760952712 recall 0.9032258064516129 f1 0.8969154368732154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 1.2060003280639648 s\n",
      "Accuracy 0.9120234604105572 precision 0.9118288033244044 specificity 0.7711615183610144 recall 0.9120234604105572 f1 0.9079897783408512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 1.222999095916748 s\n",
      "Accuracy 0.9073313782991203 precision 0.9102258484096994 specificity 0.7491943569949974 recall 0.9073313782991203 f1 0.901674238056572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 1.2449994087219238 s\n",
      "Accuracy 0.9155425219941349 precision 0.9154611459554601 specificity 0.7747993583477454 recall 0.9155425219941349 f1 0.9116767870575281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 1.235999345779419 s\n",
      "Accuracy 0.9120234604105572 precision 0.9116756277364255 specificity 0.7488536367780022 recall 0.9120234604105572 f1 0.907321182668296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 1.2310009002685547 s\n",
      "Accuracy 0.9032258064516129 precision 0.9035170117315654 specificity 0.7410062304633509 recall 0.9032258064516129 f1 0.8977619414819891\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 1.2430000305175781 s\n",
      "Accuracy 0.9114369501466275 precision 0.9112331556317922 specificity 0.7516729244201069 recall 0.9114369501466275 f1 0.9067620999590128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 1.2659990787506104 s\n",
      "Accuracy 0.8973607038123167 precision 0.8970093164507463 specificity 0.736490600237611 recall 0.8973607038123167 f1 0.8917284276323805\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 1.3750016689300537 s\n",
      "Accuracy 0.9143695014662757 precision 0.9149511364870604 specificity 0.7582227230925331 recall 0.9143695014662757 f1 0.9097765654855787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 1.4219987392425537 s\n",
      "Accuracy 0.9085043988269794 precision 0.9068667949000936 specificity 0.7597444315505637 recall 0.9085043988269794 f1 0.9045459117789609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 1.244999647140503 s\n",
      "Accuracy 0.9131964809384164 precision 0.912509328680346 specificity 0.7651685784876151 recall 0.9131964809384164 f1 0.9091662014423726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 1.2939987182617188 s\n",
      "Accuracy 0.906158357771261 precision 0.906844990761029 specificity 0.740467238685387 recall 0.906158357771261 f1 0.900667089678228\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 1.2509996891021729 s\n",
      "Accuracy 0.9032258064516129 precision 0.9018871308108614 specificity 0.7474710709866932 recall 0.9032258064516129 f1 0.8985448885029244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 1.246000051498413 s\n",
      "Accuracy 0.9102639296187683 precision 0.9103082154886144 specificity 0.7555818224344727 recall 0.9102639296187683 f1 0.9056054322379045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 1.2470002174377441 s\n",
      "Accuracy 0.910850439882698 precision 0.9099418707798917 specificity 0.7553190053741998 recall 0.910850439882698 f1 0.9065112389466815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 1.2390003204345703 s\n",
      "Accuracy 0.9255131964809384 precision 0.9266103243490178 specificity 0.7901904547065837 recall 0.9255131964809384 f1 0.9220306965761512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 1.279000997543335 s\n",
      "Accuracy 0.9096774193548387 precision 0.9113980590919633 specificity 0.7432666221669153 recall 0.9096774193548387 f1 0.9041545711303788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 1.2749996185302734 s\n",
      "Accuracy 0.9161290322580645 precision 0.9166443625558404 specificity 0.7647658784085047 recall 0.9161290322580645 f1 0.9118101170695363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 1.2130002975463867 s\n",
      "Accuracy 0.906158357771261 precision 0.9061106350526446 specificity 0.7667870551283414 recall 0.906158357771261 f1 0.9017911608474081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 1.3040006160736084 s\n",
      "Accuracy 0.9049853372434018 precision 0.9044411929906634 specificity 0.7453527650311045 recall 0.9049853372434018 f1 0.8999927661566672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 1.234997272491455 s\n",
      "Accuracy 0.9167155425219942 precision 0.914694522628741 specificity 0.7620742137770559 recall 0.9167155425219942 f1 0.913287138294151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 1.1950011253356934 s\n",
      "Accuracy 0.9026392961876832 precision 0.9031472972036854 specificity 0.7454611413864385 recall 0.9026392961876832 f1 0.8972585816824074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 1.3040001392364502 s\n",
      "Accuracy 0.9126099706744868 precision 0.9121136260526463 specificity 0.7542739188275837 recall 0.9126099706744868 f1 0.9081504324805503\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 1.1759989261627197 s\n",
      "Accuracy 0.9161290322580645 precision 0.9148186909973745 specificity 0.7837356889710396 recall 0.9161290322580645 f1 0.912996208600149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 1.2250003814697266 s\n",
      "Accuracy 0.9120234604105572 precision 0.9107534626987814 specificity 0.7781272994771149 recall 0.9120234604105572 f1 0.9086035995253715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 1.266000747680664 s\n",
      "Accuracy 0.9120234604105572 precision 0.9112451341351058 specificity 0.7645281229478111 recall 0.9120234604105572 f1 0.9079720741794846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 1.287998914718628 s\n",
      "Accuracy 0.9167155425219942 precision 0.9169663684468418 specificity 0.7567693059628543 recall 0.9167155425219942 f1 0.912245436027131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 1.2750000953674316 s\n",
      "Accuracy 0.9126099706744868 precision 0.914777397794656 specificity 0.7547448806513027 recall 0.9126099706744868 f1 0.907473925350142\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 1.2809991836547852 s\n",
      "Accuracy 0.92316715542522 precision 0.9232307623918746 specificity 0.7606030507069151 recall 0.92316715542522 f1 0.9190854533367201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 1.3650007247924805 s\n",
      "Accuracy 0.906158357771261 precision 0.9059065262223533 specificity 0.7441194200065168 recall 0.906158357771261 f1 0.9010664546304484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 1.2410001754760742 s\n",
      "Accuracy 0.9008797653958944 precision 0.9010689622552267 specificity 0.71811917755849 recall 0.9008797653958944 f1 0.8944934553760763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 1.2540004253387451 s\n",
      "Accuracy 0.9178885630498533 precision 0.9182146561221789 specificity 0.7758370661596468 recall 0.9178885630498533 f1 0.9139994816378129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 1.2480006217956543 s\n",
      "Accuracy 0.9237536656891495 precision 0.922550425516311 specificity 0.7948593022517915 recall 0.9237536656891495 f1 0.9210656302645438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 1.2639989852905273 s\n",
      "Accuracy 0.9102639296187683 precision 0.9105878632208616 specificity 0.7569127921490182 recall 0.9102639296187683 f1 0.9055692893421158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 1.231999158859253 s\n",
      "Accuracy 0.9126099706744868 precision 0.9135052248677418 specificity 0.750671213127576 recall 0.9126099706744868 f1 0.9076372149224736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 1.2739996910095215 s\n",
      "Accuracy 0.9131964809384164 precision 0.9114596663793026 specificity 0.779039324274758 recall 0.9131964809384164 f1 0.9100683067591666\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 1.2410006523132324 s\n",
      "Accuracy 0.9149560117302052 precision 0.9145450925781955 specificity 0.7674674108226984 recall 0.9149560117302052 f1 0.9109543505396392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 1.2319984436035156 s\n",
      "Accuracy 0.9020527859237537 precision 0.9050544525899938 specificity 0.7316057632952103 recall 0.9020527859237537 f1 0.8955346562836263\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 1.2829985618591309 s\n",
      "Accuracy 0.9008797653958944 precision 0.8997999754130794 specificity 0.7413329601501645 recall 0.9008797653958944 f1 0.8957968671580976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 1.2120006084442139 s\n",
      "Accuracy 0.918475073313783 precision 0.9176285097772521 specificity 0.7792240589861098 recall 0.918475073313783 f1 0.9150700177900629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 1.23699951171875 s\n",
      "Accuracy 0.9014662756598241 precision 0.9021586917272831 specificity 0.7370399940558218 recall 0.9014662756598241 f1 0.8956833806906163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 1.2430005073547363 s\n",
      "Accuracy 0.9014662756598241 precision 0.8994360787936495 specificity 0.7320835078899595 recall 0.9014662756598241 f1 0.8964401565025417\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 1.2290005683898926 s\n",
      "Accuracy 0.9202346041055719 precision 0.9191558680473894 specificity 0.7613803532172841 recall 0.9202346041055719 f1 0.9164499175673649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 1.2770004272460938 s\n",
      "Accuracy 0.9055718475073313 precision 0.9040854281243851 specificity 0.7560756620712127 recall 0.9055718475073313 f1 0.9013338378582916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 1.2059993743896484 s\n",
      "Accuracy 0.9014662756598241 precision 0.9020047113119561 specificity 0.7410631790372878 recall 0.9014662756598241 f1 0.8958765566486057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 1.203002691268921 s\n",
      "Accuracy 0.9090909090909091 precision 0.9073947155342503 specificity 0.7537611758195123 recall 0.9090909090909091 f1 0.9049677651083933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 1.2169995307922363 s\n",
      "Accuracy 0.9131964809384164 precision 0.9131963400940909 specificity 0.749196916477588 recall 0.9131964809384164 f1 0.9084404345327904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 1.3160004615783691 s\n",
      "Accuracy 0.9008797653958944 precision 0.9016737524089466 specificity 0.7181834158508135 recall 0.9008797653958944 f1 0.8943262534265943\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 1.3149998188018799 s\n",
      "Accuracy 0.9002932551319648 precision 0.9000023940652908 specificity 0.7267182391209087 recall 0.9002932551319648 f1 0.894361745080539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 1.2049987316131592 s\n",
      "Accuracy 0.9149560117302052 precision 0.9158402781115373 specificity 0.7401457285802888 recall 0.9149560117302052 f1 0.9097380761818884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 1.2039995193481445 s\n",
      "Accuracy 0.9161290322580645 precision 0.9149750928375462 specificity 0.7507376042090813 recall 0.9161290322580645 f1 0.9119098228391467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 1.2129991054534912 s\n",
      "Accuracy 0.9173020527859238 precision 0.9170763889062588 specificity 0.7593538297302723 recall 0.9173020527859238 f1 0.9130681380481699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 1.202998399734497 s\n",
      "Accuracy 0.9043988269794722 precision 0.9044995254351926 specificity 0.7399208509529637 recall 0.9043988269794722 f1 0.8989906152146784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 1.3370025157928467 s\n",
      "Accuracy 0.8944281524926686 precision 0.8923759780605359 specificity 0.7170676117970352 recall 0.8944281524926686 f1 0.8885316826403538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 1.257997989654541 s\n",
      "Accuracy 0.9032258064516129 precision 0.9056843918544798 specificity 0.7190083794874561 recall 0.9032258064516129 f1 0.8963972627035806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 1.2250010967254639 s\n",
      "Accuracy 0.9096774193548387 precision 0.9077475169406842 specificity 0.7287581392175536 recall 0.9096774193548387 f1 0.9047987416518398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 1.2580010890960693 s\n",
      "Accuracy 0.9190615835777126 precision 0.9183557738696523 specificity 0.7725521198465635 recall 0.9190615835777126 f1 0.9154273541197173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 1.2699992656707764 s\n",
      "Accuracy 0.9114369501466275 precision 0.9109443108649393 specificity 0.749489282929092 recall 0.9114369501466275 f1 0.9067818175533519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 1.162999153137207 s\n",
      "Accuracy 0.9067448680351906 precision 0.9057837132053889 specificity 0.759199378581191 recall 0.9067448680351906 f1 0.9024377857903968\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 1.253997802734375 s\n",
      "Accuracy 0.9155425219941349 precision 0.9145744387815247 specificity 0.7771830530843813 recall 0.9155425219941349 f1 0.9120498692734419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 1.2410001754760742 s\n",
      "Accuracy 0.9137829912023461 precision 0.9120108803381716 specificity 0.7695574787011518 recall 0.9137829912023461 f1 0.9103721479952606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 1.2560005187988281 s\n",
      "Accuracy 0.9137829912023461 precision 0.9141548000860718 specificity 0.7467148442954895 recall 0.9137829912023461 f1 0.908863287727868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 1.24299955368042 s\n",
      "Accuracy 0.9073313782991203 precision 0.9066915357453151 specificity 0.7356339896662477 recall 0.9073313782991203 f1 0.9021068427581892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 1.2509994506835938 s\n",
      "Accuracy 0.9049853372434018 precision 0.9047669807760469 specificity 0.7402924405343759 recall 0.9049853372434018 f1 0.8997070131369028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 1.2650001049041748 s\n",
      "Accuracy 0.9043988269794722 precision 0.9057880802433949 specificity 0.7459717492665904 recall 0.9043988269794722 f1 0.898863989915624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 1.2410001754760742 s\n",
      "Accuracy 0.9155425219941349 precision 0.916187604248377 specificity 0.75647746650393 recall 0.9155425219941349 f1 0.9109178397570253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 1.2689990997314453 s\n",
      "Accuracy 0.9038123167155425 precision 0.9030912664627544 specificity 0.7496659211486085 recall 0.9038123167155425 f1 0.898998792141869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 1.255000352859497 s\n",
      "Accuracy 0.9020527859237537 precision 0.9020211871681993 specificity 0.7422210860830943 recall 0.9020527859237537 f1 0.896690162497823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 1.2609999179840088 s\n",
      "Accuracy 0.9120234604105572 precision 0.9122525935224423 specificity 0.7524368739212624 recall 0.9120234604105572 f1 0.9072655646473814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 1.2010002136230469 s\n",
      "Accuracy 0.9032258064516129 precision 0.9026187235593608 specificity 0.7363723372892798 recall 0.9032258064516129 f1 0.8978684021128842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 1.2400000095367432 s\n",
      "Accuracy 0.9085043988269794 precision 0.9098661060769169 specificity 0.7221888890862177 recall 0.9085043988269794 f1 0.9022893475249768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 1.261000156402588 s\n",
      "Accuracy 0.9090909090909091 precision 0.9087332265724225 specificity 0.7606713030441843 recall 0.9090909090909091 f1 0.9046897684498217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 1.346999168395996 s\n",
      "Accuracy 0.9178885630498533 precision 0.9205381750210383 specificity 0.7389593724989886 recall 0.9178885630498533 f1 0.9123603495026729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 1.2160005569458008 s\n",
      "Accuracy 0.9079178885630499 precision 0.9083848942640473 specificity 0.7412960464525022 recall 0.9079178885630499 f1 0.9025783344641002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 1.2829978466033936 s\n",
      "Accuracy 0.9049853372434018 precision 0.9043313750298322 specificity 0.7630868334065573 recall 0.9049853372434018 f1 0.9006581190752233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 1.3269994258880615 s\n",
      "Accuracy 0.8920821114369502 precision 0.891526230156502 specificity 0.7385749104710537 recall 0.8920821114369502 f1 0.8864448623464664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 1.1869986057281494 s\n",
      "Accuracy 0.9073313782991203 precision 0.9099925359236787 specificity 0.7530236447909199 recall 0.9073313782991203 f1 0.901856196937448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 1.1469991207122803 s\n",
      "Accuracy 0.9014662756598241 precision 0.9016377165664486 specificity 0.7379230826737914 recall 0.9014662756598241 f1 0.8958634785870456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 1.2140002250671387 s\n",
      "Accuracy 0.9137829912023461 precision 0.913552160429531 specificity 0.75223432481497 recall 0.9137829912023461 f1 0.9092132387149194\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 1.2689995765686035 s\n",
      "Accuracy 0.9038123167155425 precision 0.9027799193196903 specificity 0.7530258618866617 recall 0.9038123167155425 f1 0.8992326447195313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 1.2729995250701904 s\n",
      "Accuracy 0.9173020527859238 precision 0.9166912746301625 specificity 0.7770162388364552 recall 0.9173020527859238 f1 0.9137174758715254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 1.240999698638916 s\n",
      "Accuracy 0.9126099706744868 precision 0.9135052248677418 specificity 0.750671213127576 recall 0.9126099706744868 f1 0.9076372149224736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 1.2380006313323975 s\n",
      "Accuracy 0.9067448680351906 precision 0.9066885283792959 specificity 0.7613326684633984 recall 0.9067448680351906 f1 0.9022084105377318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 1.2239997386932373 s\n",
      "Accuracy 0.9102639296187683 precision 0.9108827694083023 specificity 0.7678241413589513 recall 0.9102639296187683 f1 0.9058462046642382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 1.228999137878418 s\n",
      "Accuracy 0.9020527859237537 precision 0.9044020632667441 specificity 0.7331688222153021 recall 0.9020527859237537 f1 0.895736768830607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 1.2559988498687744 s\n",
      "Accuracy 0.9067448680351906 precision 0.9063450654525382 specificity 0.7645633559046123 recall 0.9067448680351906 f1 0.9024266298006615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 1.2170000076293945 s\n",
      "Accuracy 0.9155425219941349 precision 0.915000227842333 specificity 0.7477483007115414 recall 0.9155425219941349 f1 0.910992510961369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 1.1800003051757812 s\n",
      "Accuracy 0.9167155425219942 precision 0.9153426381202272 specificity 0.7515541431409277 recall 0.9167155425219942 f1 0.9126303741195757\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 1.2510004043579102 s\n",
      "Accuracy 0.92316715542522 precision 0.9224419007977801 specificity 0.7880882558301913 recall 0.92316715542522 f1 0.9200827254788577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 1.2500004768371582 s\n",
      "Accuracy 0.9149560117302052 precision 0.9152375982224943 specificity 0.7687982975977298 recall 0.9149560117302052 f1 0.9107881968579612\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 1.2599992752075195 s\n",
      "Accuracy 0.910850439882698 precision 0.9113270125524752 specificity 0.7358010078841454 recall 0.910850439882698 f1 0.9054324940283943\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 1.2939999103546143 s\n",
      "Accuracy 0.9002932551319648 precision 0.9006883776053405 specificity 0.7398531481723332 recall 0.9002932551319648 f1 0.8946599017752199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 1.2719991207122803 s\n",
      "Accuracy 0.9002932551319648 precision 0.8994601584444629 specificity 0.7533795754671873 recall 0.9002932551319648 f1 0.8955591170519904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 1.2370023727416992 s\n",
      "Accuracy 0.9178885630498533 precision 0.9177925073695354 specificity 0.7674846564124105 recall 0.9178885630498533 f1 0.9138753653412351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 1.212998867034912 s\n",
      "Accuracy 0.9049853372434018 precision 0.9042921013412816 specificity 0.7478564446306382 recall 0.9049853372434018 f1 0.900132527523412\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 1.2629992961883545 s\n",
      "Accuracy 0.8961876832844575 precision 0.8936344780849219 specificity 0.7186085569375965 recall 0.8961876832844575 f1 0.8906623010882526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 1.1749975681304932 s\n",
      "Accuracy 0.9120234604105572 precision 0.910900330255169 specificity 0.7587877679402838 recall 0.9120234604105572 f1 0.9079147103755433\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 1.244999647140503 s\n",
      "Accuracy 0.8932551319648094 precision 0.8944591330946496 specificity 0.7140794972262476 recall 0.8932551319648094 f1 0.886105049113365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 1.2179994583129883 s\n",
      "Accuracy 0.8997067448680351 precision 0.8984835309514774 specificity 0.7456656833708515 recall 0.8997067448680351 f1 0.8948091005693929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 1.1820006370544434 s\n",
      "Accuracy 0.9255131964809384 precision 0.9256528532282102 specificity 0.7871636150792304 recall 0.9255131964809384 f1 0.9221903133309216\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 1.187000036239624 s\n",
      "Accuracy 0.9055718475073313 precision 0.9057904258740396 specificity 0.7575743448217404 recall 0.9055718475073313 f1 0.9007927308895586\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 1.2370007038116455 s\n",
      "Accuracy 0.906158357771261 precision 0.904586247661122 specificity 0.7366023175018274 recall 0.906158357771261 f1 0.9012705032640879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 1.244999885559082 s\n",
      "Accuracy 0.9143695014662757 precision 0.9133726920402233 specificity 0.7718815488034064 recall 0.9143695014662757 f1 0.9106950169239726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 1.1889982223510742 s\n",
      "Accuracy 0.9120234604105572 precision 0.9139352705945081 specificity 0.7768814060088783 recall 0.9120234604105572 f1 0.9076357678578167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 1.1619985103607178 s\n",
      "Accuracy 0.9043988269794722 precision 0.9076168689535697 specificity 0.7419382116457216 recall 0.9043988269794722 f1 0.898311162430925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 1.2149991989135742 s\n",
      "Accuracy 0.9043988269794722 precision 0.9047352846750897 specificity 0.7478256030208645 recall 0.9043988269794722 f1 0.899207049978197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 1.2280006408691406 s\n",
      "Accuracy 0.9161290322580645 precision 0.9165683894091802 specificity 0.7715822687865698 recall 0.9161290322580645 f1 0.9120354300077802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 1.199998140335083 s\n",
      "Accuracy 0.906158357771261 precision 0.9052790214172731 specificity 0.7386658739506352 recall 0.906158357771261 f1 0.9010805766023983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 1.2060003280639648 s\n",
      "Accuracy 0.8932551319648094 precision 0.8928467006132285 specificity 0.7335187650940143 recall 0.8932551319648094 f1 0.8873924182724364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 1.2090001106262207 s\n",
      "Accuracy 0.9155425219941349 precision 0.9150521945594083 specificity 0.7585508486800948 recall 0.9155425219941349 f1 0.9113104720260996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 1.2259984016418457 s\n",
      "Accuracy 0.9155425219941349 precision 0.9153668165092596 specificity 0.7532393447740297 recall 0.9155425219941349 f1 0.9110478210016694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 1.2180001735687256 s\n",
      "Accuracy 0.910850439882698 precision 0.9111899645577156 specificity 0.750926309203206 recall 0.910850439882698 f1 0.9059731193727852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 1.2150006294250488 s\n",
      "Accuracy 0.9137829912023461 precision 0.9122375295937246 specificity 0.7489492171854629 recall 0.9137829912023461 f1 0.9095836712481359\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 1.238999843597412 s\n",
      "Accuracy 0.8956011730205279 precision 0.8953594214479655 specificity 0.725281248382246 recall 0.8956011730205279 f1 0.8894238339781276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 1.2719991207122803 s\n",
      "Accuracy 0.9126099706744868 precision 0.9125841866361635 specificity 0.7720456431985713 recall 0.9126099706744868 f1 0.9085678088144897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 1.1689975261688232 s\n",
      "Accuracy 0.9096774193548387 precision 0.911237744009005 specificity 0.748935502858328 recall 0.9096774193548387 f1 0.9043836080129039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 1.2219994068145752 s\n",
      "Accuracy 0.9038123167155425 precision 0.9056515858302673 specificity 0.7369647450197707 recall 0.9038123167155425 f1 0.8978212841729425\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 1.2279987335205078 s\n",
      "Accuracy 0.8944281524926686 precision 0.893504486371158 specificity 0.7162941378209208 recall 0.8944281524926686 f1 0.8880599033918379\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 1.2100012302398682 s\n",
      "Accuracy 0.9143695014662757 precision 0.9131545032807304 specificity 0.781982027686303 recall 0.9143695014662757 f1 0.9110998186540883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 1.231999397277832 s\n",
      "Accuracy 0.9079178885630499 precision 0.9086135432469769 specificity 0.7395485945795184 recall 0.9079178885630499 f1 0.9024559706781142\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 1.2290003299713135 s\n",
      "Accuracy 0.9131964809384164 precision 0.9116220471418991 specificity 0.7459651966857791 recall 0.9131964809384164 f1 0.9088902935437705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 1.2290005683898926 s\n",
      "Accuracy 0.9090909090909091 precision 0.9089073881373569 specificity 0.7589847166118352 recall 0.9090909090909091 f1 0.9045787907178122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 1.1859991550445557 s\n",
      "Accuracy 0.9114369501466275 precision 0.9121438846131006 specificity 0.758033753222381 recall 0.9114369501466275 f1 0.9067119297478196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 1.2519984245300293 s\n",
      "Accuracy 0.9043988269794722 precision 0.9036450948458012 specificity 0.7282970841166243 recall 0.9043988269794722 f1 0.8988356221816669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 1.20499849319458 s\n",
      "Accuracy 0.8991202346041056 precision 0.8987745022379997 specificity 0.7202613659320255 recall 0.8991202346041056 f1 0.8929076977322177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 1.2779991626739502 s\n",
      "Accuracy 0.8926686217008798 precision 0.8928442949543569 specificity 0.725396384587315 recall 0.8926686217008798 f1 0.8862645315181006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 1.2279994487762451 s\n",
      "Accuracy 0.9178885630498533 precision 0.916851691857228 specificity 0.7692495355425366 recall 0.9178885630498533 f1 0.9142464477184895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 1.2349998950958252 s\n",
      "Accuracy 0.9090909090909091 precision 0.9088043358804963 specificity 0.7291557113430815 recall 0.9090909090909091 f1 0.903596101856341\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 1.2569999694824219 s\n",
      "Accuracy 0.9102639296187683 precision 0.911663665712178 specificity 0.7460636138055492 recall 0.9102639296187683 f1 0.9049323394122473\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 1.1489989757537842 s\n",
      "Accuracy 0.9114369501466275 precision 0.9109927452556084 specificity 0.7427109830233575 recall 0.9114369501466275 f1 0.906542615693441\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 1.260998249053955 s\n",
      "Accuracy 0.9214076246334311 precision 0.9208238465259584 specificity 0.7795074807160516 recall 0.9214076246334311 f1 0.917993221503559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 1.2189981937408447 s\n",
      "Accuracy 0.9020527859237537 precision 0.9033948291072417 specificity 0.7518718585778223 recall 0.9020527859237537 f1 0.8966715748338617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 1.2719998359680176 s\n",
      "Accuracy 0.9202346041055719 precision 0.9197215655840721 specificity 0.7776260649058895 recall 0.9202346041055719 f1 0.9167118504363029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 1.2420001029968262 s\n",
      "Accuracy 0.92316715542522 precision 0.9228686365069623 specificity 0.7741996857447526 recall 0.92316715542522 f1 0.9195642770068188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 1.1570003032684326 s\n",
      "Accuracy 0.9079178885630499 precision 0.9073712442992663 specificity 0.7492470872879428 recall 0.9079178885630499 f1 0.9031565949520978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 1.195000410079956 s\n",
      "Accuracy 0.9149560117302052 precision 0.9137989726431979 specificity 0.7741964199964839 recall 0.9149560117302052 f1 0.9114329980972881\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 1.2070000171661377 s\n",
      "Accuracy 0.9102639296187683 precision 0.9092059136956138 specificity 0.7477488921600856 recall 0.9102639296187683 f1 0.9057079207478452\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 1.2379999160766602 s\n",
      "Accuracy 0.9102639296187683 precision 0.9100659994073688 specificity 0.7376230320303474 recall 0.9102639296187683 f1 0.9050785094516086\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 1.227998971939087 s\n",
      "Accuracy 0.9167155425219942 precision 0.9152617586263995 specificity 0.7741401322407149 recall 0.9167155425219942 f1 0.9133686630361084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 1.178999900817871 s\n",
      "Accuracy 0.9190615835777126 precision 0.9189786134158897 specificity 0.78237749883066 recall 0.9190615835777126 f1 0.9155071466911797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 1.214998722076416 s\n",
      "Accuracy 0.9155425219941349 precision 0.9161799619278246 specificity 0.7449242108757758 recall 0.9155425219941349 f1 0.9105615896928088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 1.2569975852966309 s\n",
      "Accuracy 0.918475073313783 precision 0.9212430142258672 specificity 0.7501953651586357 recall 0.918475073313783 f1 0.9132921492403746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 1.226001262664795 s\n",
      "Accuracy 0.9055718475073313 precision 0.903768901660151 specificity 0.713277908461538 recall 0.9055718475073313 f1 0.8998886628724261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 1.1979990005493164 s\n",
      "Accuracy 0.9073313782991203 precision 0.9078650911258362 specificity 0.7200469732401051 recall 0.9073313782991203 f1 0.9012018502959305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 1.245997428894043 s\n",
      "Accuracy 0.9120234604105572 precision 0.9124616036348224 specificity 0.7506685871302681 recall 0.9120234604105572 f1 0.9071502917643778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 1.2459981441497803 s\n",
      "Accuracy 0.9167155425219942 precision 0.9166126832176372 specificity 0.779248006551374 recall 0.9167155425219942 f1 0.9130183585122313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 1.2279994487762451 s\n",
      "Accuracy 0.9137829912023461 precision 0.9128466351205643 specificity 0.7652069668750645 recall 0.9137829912023461 f1 0.9098603497591098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 1.263000249862671 s\n",
      "Accuracy 0.9073313782991203 precision 0.9072427336328308 specificity 0.728353931165533 recall 0.9073313782991203 f1 0.9016757842353149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 1.3040008544921875 s\n",
      "Accuracy 0.9126099706744868 precision 0.9129610994260147 specificity 0.7502337273530868 recall 0.9126099706744868 f1 0.9077668162918247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 1.290999412536621 s\n",
      "Accuracy 0.9090909090909091 precision 0.9082019794293268 specificity 0.7566205815229455 recall 0.9090909090909091 f1 0.9047350597717094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 1.2440016269683838 s\n",
      "Accuracy 0.910850439882698 precision 0.9120465026126796 specificity 0.7527900881646098 recall 0.910850439882698 f1 0.9058119886426004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 1.2629995346069336 s\n",
      "Accuracy 0.9079178885630499 precision 0.9073352917662152 specificity 0.7556175007787911 recall 0.9079178885630499 f1 0.9033866933435926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 1.311000108718872 s\n",
      "Accuracy 0.9173020527859238 precision 0.91635963605564 specificity 0.7709253790838719 recall 0.9173020527859238 f1 0.9136568377935876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 1.3010001182556152 s\n",
      "Accuracy 0.9143695014662757 precision 0.9125725568771919 specificity 0.7701280848627556 recall 0.9143695014662757 f1 0.9110074532776112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 1.1719970703125 s\n",
      "Accuracy 0.906158357771261 precision 0.906442566336786 specificity 0.7540639267155234 recall 0.906158357771261 f1 0.9012550122418092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 1.3079993724822998 s\n",
      "Accuracy 0.9014662756598241 precision 0.9014318122488945 specificity 0.7313471474761797 recall 0.9014662756598241 f1 0.8956766608991343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 1.193000078201294 s\n",
      "Accuracy 0.9190615835777126 precision 0.9191045261171489 specificity 0.7696422083914078 recall 0.9190615835777126 f1 0.9151057172649317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 1.1810023784637451 s\n",
      "Accuracy 0.9049853372434018 precision 0.9066733586696877 specificity 0.7381941430049858 recall 0.9049853372434018 f1 0.8991181933651304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 1.2389984130859375 s\n",
      "Accuracy 0.898533724340176 precision 0.8998595250066111 specificity 0.7133060487899198 recall 0.898533724340176 f1 0.8915452714504503\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 1.251999855041504 s\n",
      "Accuracy 0.918475073313783 precision 0.9179623464585006 specificity 0.7701612903225806 recall 0.918475073313783 f1 0.9146884471067542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 1.290001630783081 s\n",
      "Accuracy 0.9190615835777126 precision 0.9190470692629698 specificity 0.7764863325584388 recall 0.9190615835777126 f1 0.915319004363064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 1.3559997081756592 s\n",
      "Accuracy 0.9102639296187683 precision 0.9091696384750197 specificity 0.7535827541126112 recall 0.9102639296187683 f1 0.9059178222244384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 1.273000955581665 s\n",
      "Accuracy 0.9085043988269794 precision 0.9084050301707348 specificity 0.7332718754601768 recall 0.9085043988269794 f1 0.903071699476009\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 1.294999599456787 s\n",
      "Accuracy 0.9225806451612903 precision 0.9221651462049143 specificity 0.8134341133557881 recall 0.9225806451612903 f1 0.9200471489076739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 1.2979979515075684 s\n",
      "Accuracy 0.9085043988269794 precision 0.9080336522282583 specificity 0.7542750023632965 recall 0.9085043988269794 f1 0.903907916993908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 1.299999713897705 s\n",
      "Accuracy 0.9126099706744868 precision 0.9128560572243866 specificity 0.7559343102088969 recall 0.9126099706744868 f1 0.9079790876069256\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 1.2989988327026367 s\n",
      "Accuracy 0.9131964809384164 precision 0.9137572340176834 specificity 0.7614254777985794 recall 0.9131964809384164 f1 0.908672571650444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 1.2529997825622559 s\n",
      "Accuracy 0.8956011730205279 precision 0.8972984866607419 specificity 0.7305182980237037 recall 0.8956011730205279 f1 0.8890983306770252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 1.265002727508545 s\n",
      "Accuracy 0.9126099706744868 precision 0.9108123820529195 specificity 0.7486274694024103 recall 0.9126099706744868 f1 0.9084736643275155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 1.3739988803863525 s\n",
      "Accuracy 0.9102639296187683 precision 0.909880222756682 specificity 0.7567539212872103 recall 0.9102639296187683 f1 0.9057752894305677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 1.2829980850219727 s\n",
      "Accuracy 0.9096774193548387 precision 0.9088034619443787 specificity 0.752152490294151 recall 0.9096774193548387 f1 0.9051834282099936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 1.2590000629425049 s\n",
      "Accuracy 0.9002932551319648 precision 0.9010743100151758 specificity 0.7520052724616061 recall 0.9002932551319648 f1 0.8950114051847284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 1.3259985446929932 s\n",
      "Accuracy 0.9161290322580645 precision 0.9153237117133419 specificity 0.7484591112169444 recall 0.9161290322580645 f1 0.9117112718076682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 1.2339978218078613 s\n",
      "Accuracy 0.9014662756598241 precision 0.9015870532959188 specificity 0.7363038803968031 recall 0.9014662756598241 f1 0.8958175024407881\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 1.181999683380127 s\n",
      "Accuracy 0.906158357771261 precision 0.9067098861418685 specificity 0.7453640090783316 recall 0.906158357771261 f1 0.9008763880080068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 1.2430002689361572 s\n",
      "Accuracy 0.8991202346041056 precision 0.8992497653767478 specificity 0.7176476138193429 recall 0.8991202346041056 f1 0.8926590171371956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 1.3160004615783691 s\n",
      "Accuracy 0.906158357771261 precision 0.9063047659117778 specificity 0.7112123641571017 recall 0.906158357771261 f1 0.8997625651568839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 1.266000509262085 s\n",
      "Accuracy 0.893841642228739 precision 0.892448469831352 specificity 0.7337571249329309 recall 0.893841642228739 f1 0.8883591858170408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 1.2789978981018066 s\n",
      "Accuracy 0.9008797653958944 precision 0.9005458386234475 specificity 0.743415373376057 recall 0.9008797653958944 f1 0.8956189005535798\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 1.2630000114440918 s\n",
      "Accuracy 0.9067448680351906 precision 0.9062876376477973 specificity 0.7395356548365628 recall 0.9067448680351906 f1 0.9015766697342288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 1.2999999523162842 s\n",
      "Accuracy 0.9126099706744868 precision 0.9126869567427411 specificity 0.7675531508578578 recall 0.9126099706744868 f1 0.9083963588716631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 1.323000431060791 s\n",
      "Accuracy 0.910850439882698 precision 0.9126616152872716 specificity 0.7540570931572799 recall 0.910850439882698 f1 0.9057100887989574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 1.3090007305145264 s\n",
      "Accuracy 0.910850439882698 precision 0.911445984112483 specificity 0.7507587555196009 recall 0.910850439882698 f1 0.9058979382519088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 1.2039999961853027 s\n",
      "Accuracy 0.910850439882698 precision 0.9113625481960171 specificity 0.7475826303150781 recall 0.910850439882698 f1 0.9058154692971552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 1.2769989967346191 s\n",
      "Accuracy 0.9143695014662757 precision 0.9154718001125626 specificity 0.7578055058008327 recall 0.9143695014662757 f1 0.909632034720559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 1.187002420425415 s\n",
      "Accuracy 0.9149560117302052 precision 0.9146732299958106 specificity 0.7462469957885918 recall 0.9149560117302052 f1 0.9102549752635939\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 1.2559993267059326 s\n",
      "Accuracy 0.9085043988269794 precision 0.9082459244167298 specificity 0.7617423322958898 recall 0.9085043988269794 f1 0.9040913878504728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 1.304999828338623 s\n",
      "Accuracy 0.9126099706744868 precision 0.9131019143659989 specificity 0.755730098487699 recall 0.9126099706744868 f1 0.9079049534342731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 1.2589993476867676 s\n",
      "Accuracy 0.9131964809384164 precision 0.9135723136918327 specificity 0.7438716334950936 recall 0.9131964809384164 f1 0.9081626953253024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 1.274998664855957 s\n",
      "Accuracy 0.9026392961876832 precision 0.9035513583391487 specificity 0.7204402386565574 recall 0.9026392961876832 f1 0.8962161414032513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 1.2309999465942383 s\n",
      "Accuracy 0.9043988269794722 precision 0.9037502869924948 specificity 0.731761843781959 recall 0.9043988269794722 f1 0.8989278453051359\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 1.20400071144104 s\n",
      "Accuracy 0.9096774193548387 precision 0.909636275470898 specificity 0.7584227107186927 recall 0.9096774193548387 f1 0.9051204304829045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 1.2320008277893066 s\n",
      "Accuracy 0.910850439882698 precision 0.909744238711961 specificity 0.7481503609990651 recall 0.910850439882698 f1 0.9063458078715271\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 1.1259996891021729 s\n",
      "Accuracy 0.9096774193548387 precision 0.9090597921231627 specificity 0.7376115578050421 recall 0.9096774193548387 f1 0.904602466597071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 1.2260005474090576 s\n",
      "Accuracy 0.9126099706744868 precision 0.9118990063237893 specificity 0.7461839831458422 recall 0.9126099706744868 f1 0.9079601054537316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 1.2489995956420898 s\n",
      "Accuracy 0.9161290322580645 precision 0.9162984850071154 specificity 0.7604918120433882 recall 0.9161290322580645 f1 0.9117751332295003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 1.2530004978179932 s\n",
      "Accuracy 0.910850439882698 precision 0.9095733001383357 specificity 0.7622342547720109 recall 0.910850439882698 f1 0.9068831199748947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 1.2629988193511963 s\n",
      "Accuracy 0.9049853372434018 precision 0.9064267492276934 specificity 0.7175066194690872 recall 0.9049853372434018 f1 0.8984206878165822\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 1.2690012454986572 s\n",
      "Accuracy 0.9096774193548387 precision 0.9089860443245069 specificity 0.7511476113428935 recall 0.9096774193548387 f1 0.9050857327503231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 1.2299997806549072 s\n",
      "Accuracy 0.9026392961876832 precision 0.9041207243757883 specificity 0.7397960364008318 recall 0.9026392961876832 f1 0.8967965480442995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 1.2330000400543213 s\n",
      "Accuracy 0.9173020527859238 precision 0.9177621696641156 specificity 0.7686179835087863 recall 0.9173020527859238 f1 0.9131484494036973\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 1.2769994735717773 s\n",
      "Accuracy 0.906158357771261 precision 0.9048099519140574 specificity 0.7440983209544874 recall 0.906158357771261 f1 0.9014504668525833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 1.2859997749328613 s\n",
      "Accuracy 0.906158357771261 precision 0.9066345532887979 specificity 0.7606629640144901 recall 0.906158357771261 f1 0.901429902930278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 1.2770006656646729 s\n",
      "Accuracy 0.9120234604105572 precision 0.9128214095788004 specificity 0.7544045682870903 recall 0.9120234604105572 f1 0.9071761710495194\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 1.2650012969970703 s\n",
      "Accuracy 0.910850439882698 precision 0.9108095017318555 specificity 0.7636397108422026 recall 0.910850439882698 f1 0.9064979086948148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 1.313997745513916 s\n",
      "Accuracy 0.910850439882698 precision 0.9114527521660064 specificity 0.76082718885108 recall 0.910850439882698 f1 0.9062258754955722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 1.2040011882781982 s\n",
      "Accuracy 0.9038123167155425 precision 0.9030142709700809 specificity 0.7324421453631147 recall 0.9038123167155425 f1 0.8983951532338631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 1.2859992980957031 s\n",
      "Accuracy 0.9038123167155425 precision 0.9031209751030344 specificity 0.7280478152620071 recall 0.9038123167155425 f1 0.8981960152840711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 1.299999475479126 s\n",
      "Accuracy 0.9120234604105572 precision 0.9125350894788432 specificity 0.7431930187791039 recall 0.9120234604105572 f1 0.9068865993451869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 1.1850018501281738 s\n",
      "Accuracy 0.9079178885630499 precision 0.9077377886347872 specificity 0.7457383559003954 recall 0.9079178885630499 f1 0.902919220684308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 1.1859984397888184 s\n",
      "Accuracy 0.8991202346041056 precision 0.8966881100008143 specificity 0.7295594190755482 recall 0.8991202346041056 f1 0.8941072210521926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 1.3150010108947754 s\n",
      "Accuracy 0.9161290322580645 precision 0.9150310139905605 specificity 0.7921797345794339 recall 0.9161290322580645 f1 0.9131566972484711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 1.1279988288879395 s\n",
      "Accuracy 0.9155425219941349 precision 0.9149365758562972 specificity 0.7452132023295754 recall 0.9155425219941349 f1 0.9109341095623184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 1.2010009288787842 s\n",
      "Accuracy 0.906158357771261 precision 0.9059703104054575 specificity 0.7543560132542846 recall 0.906158357771261 f1 0.9014051953467555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 1.3659992218017578 s\n",
      "Accuracy 0.8991202346041056 precision 0.8980599898687913 specificity 0.7289814130832599 recall 0.8991202346041056 f1 0.8934929442737832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 1.2850003242492676 s\n",
      "Accuracy 0.9043988269794722 precision 0.9055217050406078 specificity 0.7468054400118462 recall 0.9043988269794722 f1 0.898960247951517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 1.2619984149932861 s\n",
      "Accuracy 0.9090909090909091 precision 0.9085367300713094 specificity 0.7457789358930044 recall 0.9090909090909091 f1 0.9042522602675103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 1.2999999523162842 s\n",
      "Accuracy 0.9085043988269794 precision 0.906360661893938 specificity 0.7736694754968791 recall 0.9085043988269794 f1 0.9053402231936828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 1.2750005722045898 s\n",
      "Accuracy 0.9102639296187683 precision 0.9089500830782435 specificity 0.7818739424792234 recall 0.9102639296187683 f1 0.9069496513236679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 1.2649998664855957 s\n",
      "Accuracy 0.9032258064516129 precision 0.9025865324495572 specificity 0.7501039919441271 recall 0.9032258064516129 f1 0.8983829646821451\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 1.225998878479004 s\n",
      "Accuracy 0.9067448680351906 precision 0.9054350591435448 specificity 0.765708153265851 recall 0.9067448680351906 f1 0.9028024694252561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 1.3570020198822021 s\n",
      "Accuracy 0.9085043988269794 precision 0.9076277381963637 specificity 0.7683835022850217 recall 0.9085043988269794 f1 0.9045240608703358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 1.3169996738433838 s\n",
      "Accuracy 0.9096774193548387 precision 0.9098138439207785 specificity 0.7472277669621123 recall 0.9096774193548387 f1 0.9046949509116409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 1.2629992961883545 s\n",
      "Accuracy 0.9143695014662757 precision 0.9143385332769541 specificity 0.7627377050526957 recall 0.9143695014662757 f1 0.9100875603691854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 1.2539987564086914 s\n",
      "Accuracy 0.9090909090909091 precision 0.9076950387741755 specificity 0.7643701221556066 recall 0.9090909090909091 f1 0.9051984271793723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 1.2340011596679688 s\n",
      "Accuracy 0.9149560117302052 precision 0.9149722694322278 specificity 0.748509728091046 recall 0.9149560117302052 f1 0.9102363498748307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 1.2399992942810059 s\n",
      "Accuracy 0.9208211143695014 precision 0.9210923363853224 specificity 0.7787799381727275 recall 0.9208211143695014 f1 0.9171106904368403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 1.2100000381469727 s\n",
      "Accuracy 0.9143695014662757 precision 0.9151691689765048 specificity 0.7564683573987594 recall 0.9143695014662757 f1 0.9096653365054836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 1.28999924659729 s\n",
      "Accuracy 0.9161290322580645 precision 0.9155343417434537 specificity 0.7481790960950077 recall 0.9161290322580645 f1 0.9116311730066661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 1.2880003452301025 s\n",
      "Accuracy 0.9014662756598241 precision 0.9027870307672863 specificity 0.7574450736900424 recall 0.9014662756598241 f1 0.8962790480196953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 1.305999994277954 s\n",
      "Accuracy 0.9102639296187683 precision 0.910716538635095 specificity 0.7423756867761522 recall 0.9102639296187683 f1 0.9050506354318756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 1.1980006694793701 s\n",
      "Accuracy 0.9137829912023461 precision 0.9115341992226791 specificity 0.7560041411020993 recall 0.9137829912023461 f1 0.9101908018439253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 1.2180001735687256 s\n",
      "Accuracy 0.9073313782991203 precision 0.9064342067720602 specificity 0.7698427131253591 recall 0.9073313782991203 f1 0.9033803905521834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 1.2930002212524414 s\n",
      "Accuracy 0.8979472140762463 precision 0.8994371546129173 specificity 0.7358981741364894 recall 0.8979472140762463 f1 0.8917923033723106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 1.3010010719299316 s\n",
      "Accuracy 0.9114369501466275 precision 0.9107072809258031 specificity 0.7640745698478456 recall 0.9114369501466275 f1 0.9073374482689852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 1.3080003261566162 s\n",
      "Accuracy 0.8961876832844575 precision 0.8962081176803658 specificity 0.7352688777229562 recall 0.8961876832844575 f1 0.8903532833882458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 1.2409989833831787 s\n",
      "Accuracy 0.9043988269794722 precision 0.9056264551345735 specificity 0.729690893260464 recall 0.9043988269794722 f1 0.8983119786195349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 1.2350006103515625 s\n",
      "Accuracy 0.9002932551319648 precision 0.9026638414212581 specificity 0.72353690311708 recall 0.9002932551319648 f1 0.8935319079206713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 1.1889982223510742 s\n",
      "Accuracy 0.898533724340176 precision 0.8991312039011818 specificity 0.7295361162881802 recall 0.898533724340176 f1 0.8923844838147295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 1.2850010395050049 s\n",
      "Accuracy 0.9067448680351906 precision 0.9067618788924114 specificity 0.7474757999962551 recall 0.9067448680351906 f1 0.9017080811066629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 1.1939992904663086 s\n",
      "Accuracy 0.910850439882698 precision 0.9109972929929675 specificity 0.7436744505307229 recall 0.910850439882698 f1 0.9057876541801967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 1.2040002346038818 s\n",
      "Accuracy 0.9090909090909091 precision 0.9094174695165839 specificity 0.7418904396683207 recall 0.9090909090909091 f1 0.9038531964470239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 1.2360002994537354 s\n",
      "Accuracy 0.9055718475073313 precision 0.9051910093855126 specificity 0.7372822530939843 recall 0.9055718475073313 f1 0.9002571101064718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 1.2519991397857666 s\n",
      "Accuracy 0.9137829912023461 precision 0.9164633651577625 specificity 0.7422554161186162 recall 0.9137829912023461 f1 0.9081784040430804\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 1.2330002784729004 s\n",
      "Accuracy 0.9131964809384164 precision 0.9122268650837171 specificity 0.7468335716536195 recall 0.9131964809384164 f1 0.9086794589984882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 1.2109990119934082 s\n",
      "Accuracy 0.9043988269794722 precision 0.9021633050133548 specificity 0.7534055992660187 recall 0.9043988269794722 f1 0.900405848199858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 1.2370002269744873 s\n",
      "Accuracy 0.9043988269794722 precision 0.9034779691673093 specificity 0.7453138166986888 recall 0.9043988269794722 f1 0.8995161376079112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 1.2599985599517822 s\n",
      "Accuracy 0.9067448680351906 precision 0.9052429001344933 specificity 0.7591599399265208 recall 0.9067448680351906 f1 0.9026557197231485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 1.2599999904632568 s\n",
      "Accuracy 0.9090909090909091 precision 0.9103376666950501 specificity 0.7557581092297927 recall 0.9090909090909091 f1 0.9040820439733603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 1.2460041046142578 s\n",
      "Accuracy 0.9173020527859238 precision 0.9183958325674975 specificity 0.774498396226362 recall 0.9173020527859238 f1 0.9131636243647421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 1.228996992111206 s\n",
      "Accuracy 0.9178885630498533 precision 0.9172506182961686 specificity 0.7782650299372491 recall 0.9178885630498533 f1 0.9143650847216176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 1.2200000286102295 s\n",
      "Accuracy 0.9067448680351906 precision 0.9063658104589953 specificity 0.7652691474129808 recall 0.9067448680351906 f1 0.9024439656192591\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 1.30899977684021 s\n",
      "Accuracy 0.8991202346041056 precision 0.8987660257404365 specificity 0.7503528352457992 recall 0.8991202346041056 f1 0.8940778067673284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 1.2810008525848389 s\n",
      "Accuracy 0.9002932551319648 precision 0.8999499468495316 specificity 0.7407985071750989 recall 0.9002932551319648 f1 0.8949182131907878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 1.2720003128051758 s\n",
      "Accuracy 0.906158357771261 precision 0.9093747522681476 specificity 0.7401358797681127 recall 0.906158357771261 f1 0.9000710999089367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 1.2799994945526123 s\n",
      "Accuracy 0.9196480938416423 precision 0.9201810413612297 specificity 0.7631441139505655 recall 0.9196480938416423 f1 0.9153892088703672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 1.2359988689422607 s\n",
      "Accuracy 0.9032258064516129 precision 0.9037861171001366 specificity 0.7114186390442236 recall 0.9032258064516129 f1 0.8965814435538155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 1.2270028591156006 s\n",
      "Accuracy 0.9043988269794722 precision 0.9051279511519572 specificity 0.7429686258471748 recall 0.9043988269794722 f1 0.8989245420804876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 1.1999988555908203 s\n",
      "Accuracy 0.9038123167155425 precision 0.9046903349398322 specificity 0.7251942231592061 recall 0.9038123167155425 f1 0.897625923674126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 1.2229986190795898 s\n",
      "Accuracy 0.9085043988269794 precision 0.90635757595534 specificity 0.7657905075910747 recall 0.9085043988269794 f1 0.9050428828735101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 1.2560021877288818 s\n",
      "Accuracy 0.8932551319648094 precision 0.8944004207780538 specificity 0.730597396104678 recall 0.8932551319648094 f1 0.886816327353393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 1.271998405456543 s\n",
      "Accuracy 0.9020527859237537 precision 0.9017942744344448 specificity 0.7349553672134317 recall 0.9020527859237537 f1 0.8964890417449772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 1.1949982643127441 s\n",
      "Accuracy 0.9114369501466275 precision 0.9106110200995615 specificity 0.75313979090257 recall 0.9114369501466275 f1 0.9070147437294463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 1.2089993953704834 s\n",
      "Accuracy 0.9043988269794722 precision 0.904601690477028 specificity 0.7599387753874005 recall 0.9043988269794722 f1 0.8996756779856313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 1.2369985580444336 s\n",
      "Accuracy 0.9002932551319648 precision 0.8990322089655473 specificity 0.7337318820305118 recall 0.9002932551319648 f1 0.8949673108174776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 1.2140002250671387 s\n",
      "Accuracy 0.9032258064516129 precision 0.9018364117121874 specificity 0.7576744666437821 recall 0.9032258064516129 f1 0.8989421125125167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 1.2839992046356201 s\n",
      "Accuracy 0.8956011730205279 precision 0.8965063397889524 specificity 0.7254660865681326 recall 0.8956011730205279 f1 0.8890972842921869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 1.1689996719360352 s\n",
      "Accuracy 0.9202346041055719 precision 0.9191554289727336 specificity 0.7688533602632914 recall 0.9202346041055719 f1 0.9166674759015964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 1.1839990615844727 s\n",
      "Accuracy 0.9149560117302052 precision 0.9145074368086915 specificity 0.7659926011910384 recall 0.9149560117302052 f1 0.9109213085947836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 1.3380000591278076 s\n",
      "Accuracy 0.9102639296187683 precision 0.9123251167953395 specificity 0.7604440226001644 recall 0.9102639296187683 f1 0.9052612107303523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 1.2550010681152344 s\n",
      "Accuracy 0.896774193548387 precision 0.8947170244518425 specificity 0.7292337854007683 recall 0.896774193548387 f1 0.8914808314814707\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 1.2359988689422607 s\n",
      "Accuracy 0.906158357771261 precision 0.9088074778319296 specificity 0.744909378170493 recall 0.906158357771261 f1 0.9003594996133644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 1.2500026226043701 s\n",
      "Accuracy 0.9026392961876832 precision 0.9027021850669642 specificity 0.7309047651149988 recall 0.9026392961876832 f1 0.8968473510786439\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 1.2749972343444824 s\n",
      "Accuracy 0.9014662756598241 precision 0.9008642642705321 specificity 0.7373035967155765 recall 0.9014662756598241 f1 0.8960816952877607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 1.2790002822875977 s\n",
      "Accuracy 0.9155425219941349 precision 0.9151444918129082 specificity 0.7535039884306156 recall 0.9155425219941349 f1 0.9111249549695896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 1.2609996795654297 s\n",
      "Accuracy 0.9155425219941349 precision 0.9167355826197687 specificity 0.756824388858668 recall 0.9155425219941349 f1 0.91079223886418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 1.249000072479248 s\n",
      "Accuracy 0.9090909090909091 precision 0.907651561305759 specificity 0.7441224769332794 recall 0.9090909090909091 f1 0.9045197964465752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 1.2429990768432617 s\n",
      "Accuracy 0.9190615835777126 precision 0.9181380761401611 specificity 0.7634529543015958 recall 0.9190615835777126 f1 0.9152403092508664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 1.251999855041504 s\n",
      "Accuracy 0.910850439882698 precision 0.9106853089366497 specificity 0.7505041340638049 recall 0.910850439882698 f1 0.9061059483693981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 1.278001070022583 s\n",
      "Accuracy 0.9055718475073313 precision 0.9040476732658161 specificity 0.7489229703416105 recall 0.9055718475073313 f1 0.9010919357500702\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 1.1900007724761963 s\n",
      "Accuracy 0.9202346041055719 precision 0.9214726609157166 specificity 0.7755572848450449 recall 0.9202346041055719 f1 0.9161772625543638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 1.2159981727600098 s\n",
      "Accuracy 0.9143695014662757 precision 0.9123765861312246 specificity 0.7573949638782347 recall 0.9143695014662757 f1 0.910690178552831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 1.276000738143921 s\n",
      "Accuracy 0.9237536656891495 precision 0.923697852331368 specificity 0.7787568905985196 recall 0.9237536656891495 f1 0.9202173538036916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 1.3120012283325195 s\n",
      "Accuracy 0.9085043988269794 precision 0.9095384696647977 specificity 0.7446089716953149 recall 0.9085043988269794 f1 0.9031504124362723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 1.3349995613098145 s\n",
      "Accuracy 0.9073313782991203 precision 0.9082752438901557 specificity 0.7350341460077994 recall 0.9073313782991203 f1 0.9016245130330837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 1.2759995460510254 s\n",
      "Accuracy 0.8973607038123167 precision 0.8959578761244584 specificity 0.7326154759732253 recall 0.8973607038123167 f1 0.8919469298259889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 1.2669992446899414 s\n",
      "Accuracy 0.9043988269794722 precision 0.9031755944218232 specificity 0.755079665381078 recall 0.9043988269794722 f1 0.8999833904643689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 1.203000783920288 s\n",
      "Accuracy 0.9096774193548387 precision 0.9098906958144496 specificity 0.740541943031824 recall 0.9096774193548387 f1 0.9044474415548347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 1.25799560546875 s\n",
      "Accuracy 0.9002932551319648 precision 0.8997385180174524 specificity 0.7486858367590442 recall 0.9002932551319648 f1 0.8952858898992961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 1.189997911453247 s\n",
      "Accuracy 0.9149560117302052 precision 0.9152478320595989 specificity 0.7596307531294167 recall 0.9149560117302052 f1 0.910503900016877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 1.2039978504180908 s\n",
      "Accuracy 0.9114369501466275 precision 0.9103512333596036 specificity 0.7772639735536159 recall 0.9114369501466275 f1 0.9078978064874098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 1.1780002117156982 s\n",
      "Accuracy 0.9090909090909091 precision 0.9102067047816815 specificity 0.739905795933832 recall 0.9090909090909091 f1 0.9035768249697133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 1.311000108718872 s\n",
      "Accuracy 0.9055718475073313 precision 0.9074562857744937 specificity 0.748662265119585 recall 0.9055718475073313 f1 0.9000547224304207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 1.2680013179779053 s\n",
      "Accuracy 0.9038123167155425 precision 0.9041020635553004 specificity 0.7346702512580966 recall 0.9038123167155425 f1 0.898137209517476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 1.195000171661377 s\n",
      "Accuracy 0.9137829912023461 precision 0.9126039016670263 specificity 0.7755883643003154 recall 0.9137829912023461 f1 0.9102836166765786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 1.2369987964630127 s\n",
      "Accuracy 0.9038123167155425 precision 0.9032127827545535 specificity 0.7464301964719415 recall 0.9038123167155425 f1 0.8988401374951115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 1.235999345779419 s\n",
      "Accuracy 0.9208211143695014 precision 0.9206679770100649 specificity 0.7788230871665824 recall 0.9208211143695014 f1 0.9172334957349442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 1.2190003395080566 s\n",
      "Accuracy 0.9090909090909091 precision 0.9075799497210623 specificity 0.7416103060284416 recall 0.9090909090909091 f1 0.904461848636242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 1.181999921798706 s\n",
      "Accuracy 0.9120234604105572 precision 0.9115160147002689 specificity 0.7595100210852396 recall 0.9120234604105572 f1 0.907717807019429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 1.219001054763794 s\n",
      "Accuracy 0.8973607038123167 precision 0.8958911294445966 specificity 0.7367541506415208 recall 0.8973607038123167 f1 0.8921401179465697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 1.2929987907409668 s\n",
      "Accuracy 0.9008797653958944 precision 0.9011999423104659 specificity 0.7400837125536193 recall 0.9008797653958944 f1 0.8952956506795984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 1.2019999027252197 s\n",
      "Accuracy 0.9143695014662757 precision 0.9125592928481232 specificity 0.764465518642444 recall 0.9143695014662757 f1 0.9108267322049421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 1.253999948501587 s\n",
      "Accuracy 0.8909090909090909 precision 0.8902642080923515 specificity 0.7319859097861718 recall 0.8909090909090909 f1 0.8849894291754757\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 1.2769997119903564 s\n",
      "Accuracy 0.910850439882698 precision 0.9087344780744353 specificity 0.754190820432381 recall 0.910850439882698 f1 0.9070145366716339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 1.2030000686645508 s\n",
      "Accuracy 0.9002932551319648 precision 0.9004243689346765 specificity 0.7398944276274789 recall 0.9002932551319648 f1 0.894737996548324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 1.2130002975463867 s\n",
      "Accuracy 0.9167155425219942 precision 0.9162282858228809 specificity 0.7718666581855091 recall 0.9167155425219942 f1 0.9129209849785971\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 1.2360002994537354 s\n",
      "Accuracy 0.9096774193548387 precision 0.9092839240513093 specificity 0.7618091732116297 recall 0.9096774193548387 f1 0.9053418928660071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 1.2619993686676025 s\n",
      "Accuracy 0.9055718475073313 precision 0.9044394225552342 specificity 0.7493189031087945 recall 0.9055718475073313 f1 0.9009479459223348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 1.1900005340576172 s\n",
      "Accuracy 0.9020527859237537 precision 0.9034772499595412 specificity 0.7347642496604435 recall 0.9020527859237537 f1 0.8960153442478386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 1.2189996242523193 s\n",
      "Accuracy 0.910850439882698 precision 0.9100630145234461 specificity 0.7668052377729797 recall 0.910850439882698 f1 0.9068443606954494\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 1.2770023345947266 s\n",
      "Accuracy 0.9161290322580645 precision 0.9166328232539993 specificity 0.7537201626493666 recall 0.9161290322580645 f1 0.9114770646248992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 1.2329990863800049 s\n",
      "Accuracy 0.9102639296187683 precision 0.9090072718516158 specificity 0.7610224540465951 recall 0.9102639296187683 f1 0.9062312598176592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 1.244999647140503 s\n",
      "Accuracy 0.9032258064516129 precision 0.9035642614082541 specificity 0.7336051045728466 recall 0.9032258064516129 f1 0.8974760523073254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 1.2459993362426758 s\n",
      "Accuracy 0.898533724340176 precision 0.8996168529540021 specificity 0.7445807178286912 recall 0.898533724340176 f1 0.892839444824759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 1.2770004272460938 s\n",
      "Accuracy 0.8956011730205279 precision 0.8962461240921178 specificity 0.7351118737669926 recall 0.8956011730205279 f1 0.8895601389548586\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 1.2380003929138184 s\n",
      "Accuracy 0.9102639296187683 precision 0.9102253181529595 specificity 0.7435010823751995 recall 0.9102639296187683 f1 0.9052283063050797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 1.242999792098999 s\n",
      "Accuracy 0.910850439882698 precision 0.9107295272441785 specificity 0.760696960822015 recall 0.910850439882698 f1 0.9064264131031535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 1.2279999256134033 s\n",
      "Accuracy 0.9167155425219942 precision 0.9170593439651237 specificity 0.7606657580532228 recall 0.9167155425219942 f1 0.9123375100041972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 1.292001724243164 s\n",
      "Accuracy 0.9020527859237537 precision 0.9035107849724369 specificity 0.7018418330517698 recall 0.9020527859237537 f1 0.8947446521989546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 1.198998212814331 s\n",
      "Accuracy 0.9096774193548387 precision 0.9086304672253473 specificity 0.7531674670641922 recall 0.9096774193548387 f1 0.9052811236696643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 1.2460002899169922 s\n",
      "Accuracy 0.9202346041055719 precision 0.9215798549986604 specificity 0.7680346429872046 recall 0.9202346041055719 f1 0.9159385630454878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 1.1709978580474854 s\n",
      "Accuracy 0.9090909090909091 precision 0.9099425552913925 specificity 0.7513264189814147 recall 0.9090909090909091 f1 0.9040317351463669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 1.2500011920928955 s\n",
      "Accuracy 0.9073313782991203 precision 0.906716243037766 specificity 0.7521873861394766 recall 0.9073313782991203 f1 0.9026759672117783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 1.2489991188049316 s\n",
      "Accuracy 0.9073313782991203 precision 0.9089419179372605 specificity 0.7486780505962668 recall 0.9073313782991203 f1 0.9019368284844731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 1.2650010585784912 s\n",
      "Accuracy 0.9079178885630499 precision 0.9088527573826733 specificity 0.7378011427065344 recall 0.9079178885630499 f1 0.9023326549693225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 1.2250001430511475 s\n",
      "Accuracy 0.9143695014662757 precision 0.9152988295306242 specificity 0.7617897362868616 recall 0.9143695014662757 f1 0.9097988011819474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 1.2750000953674316 s\n",
      "Accuracy 0.9178885630498533 precision 0.9198238204239704 specificity 0.766803062319738 recall 0.9178885630498533 f1 0.9133524269800215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 1.1649999618530273 s\n",
      "Accuracy 0.9090909090909091 precision 0.9091325323999622 specificity 0.758790705204723 recall 0.9090909090909091 f1 0.9045044572649337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 1.2259972095489502 s\n",
      "Accuracy 0.9102639296187683 precision 0.9090694973955237 specificity 0.7632569939021553 recall 0.9102639296187683 f1 0.9062805558879511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 1.249000072479248 s\n",
      "Accuracy 0.9043988269794722 precision 0.9032687488939534 specificity 0.751867107069736 recall 0.9043988269794722 f1 0.8998309273466374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 1.2320008277893066 s\n",
      "Accuracy 0.9008797653958944 precision 0.901636203172439 specificity 0.7268880893768181 recall 0.9008797653958944 f1 0.8946722912656735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 1.2599997520446777 s\n",
      "Accuracy 0.9126099706744868 precision 0.9125525724219831 specificity 0.7624451063568611 recall 0.9126099706744868 f1 0.9082743570520557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 1.3080010414123535 s\n",
      "Accuracy 0.9079178885630499 precision 0.9069680146509661 specificity 0.7352300756871984 recall 0.9079178885630499 f1 0.902807634002403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 1.246999740600586 s\n",
      "Accuracy 0.896774193548387 precision 0.8968486411937867 specificity 0.7314356609282802 recall 0.896774193548387 f1 0.8907894631650477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 1.3070006370544434 s\n",
      "Accuracy 0.9026392961876832 precision 0.9016367566082534 specificity 0.7362920339201174 recall 0.9026392961876832 f1 0.8973955990114041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 1.2280006408691406 s\n",
      "Accuracy 0.8991202346041056 precision 0.9009138195562685 specificity 0.7417337604864577 recall 0.8991202346041056 f1 0.8931573802541546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 1.254000186920166 s\n",
      "Accuracy 0.9120234604105572 precision 0.9117464439826953 specificity 0.760020769922439 recall 0.9120234604105572 f1 0.907660212491775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 1.352999210357666 s\n",
      "Accuracy 0.9096774193548387 precision 0.9091823415403485 specificity 0.765669331226223 recall 0.9096774193548387 f1 0.9055025035218295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 1.2449991703033447 s\n",
      "Accuracy 0.9126099706744868 precision 0.912649041235094 specificity 0.7661121990885367 recall 0.9126099706744868 f1 0.9083619470249233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 1.2600009441375732 s\n",
      "Accuracy 0.9002932551319648 precision 0.9026293293254809 specificity 0.7451835042469378 recall 0.9002932551319648 f1 0.8943748226872166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 1.2559993267059326 s\n",
      "Accuracy 0.9102639296187683 precision 0.9103017134977741 specificity 0.7267847290633371 recall 0.9102639296187683 f1 0.9046397299402584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 1.2460007667541504 s\n",
      "Accuracy 0.918475073313783 precision 0.9181389788830551 specificity 0.7690669097397942 recall 0.918475073313783 f1 0.91459935001953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 1.225999116897583 s\n",
      "Accuracy 0.9173020527859238 precision 0.9170190372204713 specificity 0.7569801527698312 recall 0.9173020527859238 f1 0.913014539618119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 1.2509982585906982 s\n",
      "Accuracy 0.9038123167155425 precision 0.903761698444795 specificity 0.7568596864760294 recall 0.9038123167155425 f1 0.8990397040099518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 1.2269997596740723 s\n",
      "Accuracy 0.9202346041055719 precision 0.9192120980022501 specificity 0.7637723009740692 recall 0.9202346041055719 f1 0.9164978800690008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 1.2149982452392578 s\n",
      "Accuracy 0.9143695014662757 precision 0.9138956067688251 specificity 0.7625312369907113 recall 0.9143695014662757 f1 0.9102187676773413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 1.2569999694824219 s\n",
      "Accuracy 0.9114369501466275 precision 0.911901380939437 specificity 0.7487234518245772 recall 0.9114369501466275 f1 0.9064729339680261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 1.2830004692077637 s\n",
      "Accuracy 0.9120234604105572 precision 0.9110031018347204 specificity 0.7625844634901533 recall 0.9120234604105572 f1 0.907998610501459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 1.1909995079040527 s\n",
      "Accuracy 0.9149560117302052 precision 0.9137963832410821 specificity 0.7608738493394508 recall 0.9149560117302052 f1 0.9110178111440126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 1.2420001029968262 s\n",
      "Accuracy 0.9237536656891495 precision 0.92350140321004 specificity 0.7880041582359747 recall 0.9237536656891495 f1 0.9205221394484578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 1.2100005149841309 s\n",
      "Accuracy 0.898533724340176 precision 0.8981773353490748 specificity 0.7408970203537267 recall 0.898533724340176 f1 0.8931120806443278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 1.172001600265503 s\n",
      "Accuracy 0.9249266862170088 precision 0.9239092975239732 specificity 0.7660840307083423 recall 0.9249266862170088 f1 0.9214094777294585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 1.2990009784698486 s\n",
      "Accuracy 0.8997067448680351 precision 0.9006742401325811 specificity 0.7465286902305089 recall 0.8997067448680351 f1 0.8941522661355367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 1.2879993915557861 s\n",
      "Accuracy 0.9067448680351906 precision 0.9077928127885126 specificity 0.7562340062708087 recall 0.9067448680351906 f1 0.9017299960903045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 1.3709981441497803 s\n",
      "Accuracy 0.9178885630498533 precision 0.917166615670913 specificity 0.7820975714913155 recall 0.9178885630498533 f1 0.91450675312634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 1.2529990673065186 s\n",
      "Accuracy 0.9131964809384164 precision 0.9131414339912236 specificity 0.7372211617009083 recall 0.9131964809384164 f1 0.9080700673733617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 1.2500011920928955 s\n",
      "Accuracy 0.9008797653958944 precision 0.9011115435264369 specificity 0.7285884273880266 recall 0.9008797653958944 f1 0.8948845126034587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 1.2599999904632568 s\n",
      "Accuracy 0.910850439882698 precision 0.9098518844470234 specificity 0.7723351860440285 recall 0.910850439882698 f1 0.9071032741524191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 1.3370006084442139 s\n",
      "Accuracy 0.9137829912023461 precision 0.9134328617068865 specificity 0.7564375193300261 recall 0.9137829912023461 f1 0.9093833125814824\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 1.3080005645751953 s\n",
      "Accuracy 0.9143695014662757 precision 0.9145644465779562 specificity 0.7624826245040504 recall 0.9143695014662757 f1 0.9100143984095894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 1.2449991703033447 s\n",
      "Accuracy 0.9043988269794722 precision 0.9040246056132191 specificity 0.7632362753138423 recall 0.9043988269794722 f1 0.8999686094037219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 1.3169991970062256 s\n",
      "Accuracy 0.9055718475073313 precision 0.905265022481351 specificity 0.7478944392922888 recall 0.9055718475073313 f1 0.900611508193964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 1.289001226425171 s\n",
      "Accuracy 0.9038123167155425 precision 0.9045172927052489 specificity 0.729530595161852 recall 0.9038123167155425 f1 0.8978327835215482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 1.2059986591339111 s\n",
      "Accuracy 0.9067448680351906 precision 0.9068976114235446 specificity 0.7341674374810753 recall 0.9067448680351906 f1 0.9012008921446979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 1.2749998569488525 s\n",
      "Accuracy 0.9067448680351906 precision 0.9061412280867006 specificity 0.7502801308173712 recall 0.9067448680351906 f1 0.9020014861704607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 1.209998607635498 s\n",
      "Accuracy 0.9067448680351906 precision 0.9090777826214799 specificity 0.749049306994222 recall 0.9067448680351906 f1 0.9011806585321203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 1.2610013484954834 s\n",
      "Accuracy 0.906158357771261 precision 0.9046609477209812 specificity 0.7516608758125882 recall 0.906158357771261 f1 0.9017833683992474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 1.2980008125305176 s\n",
      "Accuracy 0.9026392961876832 precision 0.9016760796649657 specificity 0.7444942872705858 recall 0.9026392961876832 f1 0.8976869528237089\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 1.1919994354248047 s\n",
      "Accuracy 0.9178885630498533 precision 0.9188166915052162 specificity 0.7706970448905932 recall 0.9178885630498533 f1 0.9136947768720843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 1.2499990463256836 s\n",
      "Accuracy 0.9096774193548387 precision 0.9101118127731925 specificity 0.7282272479738604 recall 0.9096774193548387 f1 0.903965177243051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 1.2450006008148193 s\n",
      "Accuracy 0.9225806451612903 precision 0.9209426871427243 specificity 0.7876543878457662 recall 0.9225806451612903 f1 0.9198970072832122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 1.2450013160705566 s\n",
      "Accuracy 0.9126099706744868 precision 0.9125275045066921 specificity 0.7333640228238877 recall 0.9126099706744868 f1 0.9073414626781036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 1.2410030364990234 s\n",
      "Accuracy 0.9143695014662757 precision 0.9144512494455922 specificity 0.7671690834296591 recall 0.9143695014662757 f1 0.9101916086504909\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 1.28299880027771 s\n",
      "Accuracy 0.9120234604105572 precision 0.9132508793687941 specificity 0.7493845855664543 recall 0.9120234604105572 f1 0.9069061173831041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 1.1990065574645996 s\n",
      "Accuracy 0.906158357771261 precision 0.9077139107083503 specificity 0.715984339436154 recall 0.906158357771261 f1 0.8995641388831945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 1.3209972381591797 s\n",
      "Accuracy 0.9137829912023461 precision 0.9141887460091174 specificity 0.7679221503762591 recall 0.9137829912023461 f1 0.9095211328389323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 1.2039995193481445 s\n",
      "Accuracy 0.9131964809384164 precision 0.914461151847029 specificity 0.7458598710754853 recall 0.9131964809384164 f1 0.9079986620583699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 1.3159995079040527 s\n",
      "Accuracy 0.9137829912023461 precision 0.9119139828022654 specificity 0.7658233357432058 recall 0.9137829912023461 f1 0.9103006469807746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 1.2370002269744873 s\n",
      "Accuracy 0.9055718475073313 precision 0.9060582935787383 specificity 0.7402851094412459 recall 0.9055718475073313 f1 0.9001077394658434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 1.246999979019165 s\n",
      "Accuracy 0.910850439882698 precision 0.9100212262701272 specificity 0.7720395626873355 recall 0.910850439882698 f1 0.9070295491569589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 1.2649996280670166 s\n",
      "Accuracy 0.9067448680351906 precision 0.9088939644671226 specificity 0.7651924723017881 recall 0.9067448680351906 f1 0.9017825923010335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 1.2479989528656006 s\n",
      "Accuracy 0.9020527859237537 precision 0.9004299242203923 specificity 0.7346733523232971 recall 0.9020527859237537 f1 0.8969681625827031\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 1.2089998722076416 s\n",
      "Accuracy 0.9249266862170088 precision 0.9242381810160377 specificity 0.7813748891768397 recall 0.9249266862170088 f1 0.9216964519340075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 1.271000862121582 s\n",
      "Accuracy 0.9126099706744868 precision 0.9127504611536327 specificity 0.7420243088662998 recall 0.9126099706744868 f1 0.9075601170476449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 1.1350035667419434 s\n",
      "Accuracy 0.9255131964809384 precision 0.924252542803574 specificity 0.7918063702768305 recall 0.9255131964809384 f1 0.9228119213800642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 1.2649929523468018 s\n",
      "Accuracy 0.9126099706744868 precision 0.9119098191641852 specificity 0.7766351016186702 recall 0.9126099706744868 f1 0.9089304204954447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 1.2090013027191162 s\n",
      "Accuracy 0.9137829912023461 precision 0.9141478473265806 specificity 0.7840598032694025 recall 0.9137829912023461 f1 0.9100282390129331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 1.2249984741210938 s\n",
      "Accuracy 0.918475073313783 precision 0.9174553022419828 specificity 0.778934673660138 recall 0.918475073313783 f1 0.9151288177803916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 1.2689993381500244 s\n",
      "Accuracy 0.9178885630498533 precision 0.9176032532882492 specificity 0.7685551664509647 recall 0.9178885630498533 f1 0.9139645475125378\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 1.3209996223449707 s\n",
      "Accuracy 0.9102639296187683 precision 0.9088855253891672 specificity 0.7628047881867304 recall 0.9102639296187683 f1 0.9063422755596038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 1.2499995231628418 s\n",
      "Accuracy 0.9173020527859238 precision 0.916974041815222 specificity 0.780795548537484 recall 0.9173020527859238 f1 0.9137343991330207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 1.2370014190673828 s\n",
      "Accuracy 0.9120234604105572 precision 0.91102841176173 specificity 0.7701891832676037 recall 0.9120234604105572 f1 0.9082343972934022\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 1.3420004844665527 s\n",
      "Accuracy 0.9079178885630499 precision 0.9065698528697873 specificity 0.7433601417968368 recall 0.9079178885630499 f1 0.9032427683490962\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 1.4540002346038818 s\n",
      "Accuracy 0.896774193548387 precision 0.9000670552675333 specificity 0.7213914067775719 recall 0.896774193548387 f1 0.8895761765029729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 1.294999599456787 s\n",
      "Accuracy 0.9126099706744868 precision 0.9125731495032271 specificity 0.735133875173394 recall 0.9126099706744868 f1 0.9073862041137877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 1.2389986515045166 s\n",
      "Accuracy 0.910850439882698 precision 0.9112121719357666 specificity 0.7418636348627721 recall 0.910850439882698 f1 0.9056667952618943\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 1.409001350402832 s\n",
      "Accuracy 0.9085043988269794 precision 0.9076870493544077 specificity 0.763860570148159 recall 0.9085043988269794 f1 0.9043503924651781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 1.325000524520874 s\n",
      "Accuracy 0.8950146627565982 precision 0.8942492615158344 specificity 0.7155888132160468 recall 0.8950146627565982 f1 0.8885855205005442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 1.3219985961914062 s\n",
      "Accuracy 0.9073313782991203 precision 0.9057814623359922 specificity 0.747480517979659 recall 0.9073313782991203 f1 0.9028659906723998\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 1.2420001029968262 s\n",
      "Accuracy 0.9219941348973607 precision 0.9226031186550303 specificity 0.7902857407971492 recall 0.9219941348973607 f1 0.9185412179646344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 1.2859992980957031 s\n",
      "Accuracy 0.918475073313783 precision 0.9178657138736461 specificity 0.7741820120645762 recall 0.918475073313783 f1 0.9148382169527408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 1.1719670295715332 s\n",
      "Accuracy 0.8909090909090909 precision 0.8890583503962808 specificity 0.7237721408453115 recall 0.8909090909090909 f1 0.8850919768663731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 1.3539988994598389 s\n",
      "Accuracy 0.9055718475073313 precision 0.905653666732762 specificity 0.744494629225812 recall 0.9055718475073313 f1 0.9003726728705385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 1.1440041065216064 s\n",
      "Accuracy 0.9202346041055719 precision 0.9193395477861773 specificity 0.7692001389484742 recall 0.9202346041055719 f1 0.9166066505105346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 1.156996250152588 s\n",
      "Accuracy 0.9020527859237537 precision 0.9046559071427105 specificity 0.7170064297595364 recall 0.9020527859237537 f1 0.8950618119637023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 1.2919986248016357 s\n",
      "Accuracy 0.9155425219941349 precision 0.9158470898863507 specificity 0.7630925684056614 recall 0.9155425219941349 f1 0.9112115893939307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 1.2090013027191162 s\n",
      "Accuracy 0.9196480938416423 precision 0.9192921955062526 specificity 0.7896776421507604 recall 0.9196480938416423 f1 0.9163979193457842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 1.2459983825683594 s\n",
      "Accuracy 0.8997067448680351 precision 0.9006401031249414 specificity 0.736424439123071 recall 0.8997067448680351 f1 0.8937752642875795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 1.278001308441162 s\n",
      "Accuracy 0.9196480938416423 precision 0.9211981186992285 specificity 0.7605089401849922 recall 0.9196480938416423 f1 0.9150688971861026\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 1.2619996070861816 s\n",
      "Accuracy 0.9102639296187683 precision 0.9092285160610978 specificity 0.7485606666466871 recall 0.9102639296187683 f1 0.9057268828707914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 1.2560007572174072 s\n",
      "Accuracy 0.9032258064516129 precision 0.9032022502662972 specificity 0.7474494368717293 recall 0.9032258064516129 f1 0.8980894591203591\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 1.2629992961883545 s\n",
      "Accuracy 0.9202346041055719 precision 0.9197253341823304 specificity 0.7856477488356046 recall 0.9202346041055719 f1 0.9169359876471397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 1.2760000228881836 s\n",
      "Accuracy 0.9120234604105572 precision 0.9125982596656931 specificity 0.7456645502711822 recall 0.9120234604105572 f1 0.9069505140561575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 1.2649996280670166 s\n",
      "Accuracy 0.8979472140762463 precision 0.8973942520035194 specificity 0.7399238555276977 recall 0.8979472140762463 f1 0.8925342500466986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 1.2409999370574951 s\n",
      "Accuracy 0.9096774193548387 precision 0.9102485384963919 specificity 0.7631818087905954 recall 0.9096774193548387 f1 0.9051045615625922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 1.2169983386993408 s\n",
      "Accuracy 0.9143695014662757 precision 0.9142898928042462 specificity 0.7516012750918873 recall 0.9143695014662757 f1 0.90975422937062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 1.2270004749298096 s\n",
      "Accuracy 0.9067448680351906 precision 0.9085900996462387 specificity 0.730429461466725 recall 0.9067448680351906 f1 0.9006302545264508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 1.2609989643096924 s\n",
      "Accuracy 0.896774193548387 precision 0.8967559557733956 specificity 0.7205252068998546 recall 0.896774193548387 f1 0.89037804771753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 1.260000228881836 s\n",
      "Accuracy 0.9114369501466275 precision 0.9111763309228625 specificity 0.7580947173722984 recall 0.9114369501466275 f1 0.9069887649642432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 1.23699951171875 s\n",
      "Accuracy 0.9085043988269794 precision 0.9084824218615863 specificity 0.7539077569185095 recall 0.9085043988269794 f1 0.9037554096163818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 1.2659990787506104 s\n",
      "Accuracy 0.9079178885630499 precision 0.9063582503149581 specificity 0.766182902404317 recall 0.9079178885630499 f1 0.904132335663261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 1.2030012607574463 s\n",
      "Accuracy 0.9131964809384164 precision 0.9114067103313231 specificity 0.7723013545594192 recall 0.9131964809384164 f1 0.90987176771118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 1.2419981956481934 s\n",
      "Accuracy 0.9114369501466275 precision 0.9107481138990619 specificity 0.7793079624272221 recall 0.9114369501466275 f1 0.9078116394661487\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 1.2059998512268066 s\n",
      "Accuracy 0.910850439882698 precision 0.9116082464017874 specificity 0.7356826928485672 recall 0.910850439882698 f1 0.905353448231716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 1.262000560760498 s\n",
      "Accuracy 0.9155425219941349 precision 0.9157278432024694 specificity 0.7678003898832597 recall 0.9155425219941349 f1 0.9113880095680895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 1.249999761581421 s\n",
      "Accuracy 0.9090909090909091 precision 0.9102629882971867 specificity 0.730478636388498 recall 0.9090909090909091 f1 0.9032382247222627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 1.2660002708435059 s\n",
      "Accuracy 0.9014662756598241 precision 0.9014027207825068 specificity 0.7542653515283768 recall 0.9014662756598241 f1 0.8965411135866931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 1.2749993801116943 s\n",
      "Accuracy 0.9038123167155425 precision 0.9010623575397156 specificity 0.7349972793974244 recall 0.9038123167155425 f1 0.8993818537278948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 1.1839983463287354 s\n",
      "Accuracy 0.9202346041055719 precision 0.9187305266296144 specificity 0.787560827870595 recall 0.9202346041055719 f1 0.9174108922314119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 1.328998327255249 s\n",
      "Accuracy 0.9120234604105572 precision 0.9109415660035783 specificity 0.773325695574674 recall 0.9120234604105572 f1 0.9083694667967187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 1.2360007762908936 s\n",
      "Accuracy 0.9085043988269794 precision 0.9085660009316409 specificity 0.7651348274438258 recall 0.9085043988269794 f1 0.9041073635576996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 1.2489991188049316 s\n",
      "Accuracy 0.9131964809384164 precision 0.9131137807385952 specificity 0.7724989706106936 recall 0.9131964809384164 f1 0.9092004432987331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 1.2409999370574951 s\n",
      "Accuracy 0.9131964809384164 precision 0.9130444587334854 specificity 0.7526286918613706 recall 0.9131964809384164 f1 0.9085953894303039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 1.2789983749389648 s\n",
      "Accuracy 0.9190615835777126 precision 0.9200320904156175 specificity 0.7558612921979734 recall 0.9190615835777126 f1 0.9144599512604779\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 1.3059985637664795 s\n",
      "Accuracy 0.9055718475073313 precision 0.9045429244979132 specificity 0.745985745226732 recall 0.9055718475073313 f1 0.9007899192271088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 1.2470018863677979 s\n",
      "Accuracy 0.9137829912023461 precision 0.9127874674567201 specificity 0.762954921146252 recall 0.9137829912023461 f1 0.9098114614406712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 1.261998176574707 s\n",
      "Accuracy 0.9096774193548387 precision 0.9078107799866604 specificity 0.7602360005585812 recall 0.9096774193548387 f1 0.9058830042655939\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 1.304001808166504 s\n",
      "Accuracy 0.906158357771261 precision 0.9056492342782665 specificity 0.7434499430167593 recall 0.906158357771261 f1 0.901125003271867\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 1.2509982585906982 s\n",
      "Accuracy 0.9020527859237537 precision 0.9011605465432881 specificity 0.7376598577544073 recall 0.9020527859237537 f1 0.896801027399862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 1.1789984703063965 s\n",
      "Accuracy 0.9114369501466275 precision 0.9111905261260017 specificity 0.7500820125130195 recall 0.9114369501466275 f1 0.9067231696799618\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 1.2260005474090576 s\n",
      "Accuracy 0.9137829912023461 precision 0.9145810002234962 specificity 0.7638291355623232 recall 0.9137829912023461 f1 0.9092908280511149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 1.2870001792907715 s\n",
      "Accuracy 0.9155425219941349 precision 0.9160493268664257 specificity 0.7613312578208213 recall 0.9155425219941349 f1 0.9111031033256694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 1.2159979343414307 s\n",
      "Accuracy 0.9155425219941349 precision 0.9139619101095644 specificity 0.7766652702136574 recall 0.9155425219941349 f1 0.9123076658811481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 1.2769989967346191 s\n",
      "Accuracy 0.910850439882698 precision 0.9098333003734165 specificity 0.7513789973467392 recall 0.910850439882698 f1 0.906420334883333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 1.292001724243164 s\n",
      "Accuracy 0.9043988269794722 precision 0.9034047442627399 specificity 0.7429158958268968 recall 0.9043988269794722 f1 0.8994555731031334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 1.2739970684051514 s\n",
      "Accuracy 0.9137829912023461 precision 0.914393314066498 specificity 0.7562903416688053 recall 0.9137829912023461 f1 0.9091027098126958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 1.2659990787506104 s\n",
      "Accuracy 0.910850439882698 precision 0.9099432428871658 specificity 0.7479188115481983 recall 0.910850439882698 f1 0.9062649081027564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 1.2850005626678467 s\n",
      "Accuracy 0.9161290322580645 precision 0.9165856694351614 specificity 0.7722917688887062 recall 0.9161290322580645 f1 0.9120520699635171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 1.3239984512329102 s\n",
      "Accuracy 0.9049853372434018 precision 0.9072902344151795 specificity 0.749130617937769 recall 0.9049853372434018 f1 0.8993715436953581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 1.3009986877441406 s\n",
      "Accuracy 0.9131964809384164 precision 0.9122484910691923 specificity 0.7760980954529342 recall 0.9131964809384164 f1 0.9096058099122896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 1.2879981994628906 s\n",
      "Accuracy 0.9055718475073313 precision 0.9050404376146263 specificity 0.7322022250881488 recall 0.9055718475073313 f1 0.9001227001413088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 1.2490007877349854 s\n",
      "Accuracy 0.9161290322580645 precision 0.9155540907673031 specificity 0.7811088122027843 recall 0.9161290322580645 f1 0.9126244720494321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 1.2599999904632568 s\n",
      "Accuracy 0.9114369501466275 precision 0.9108644993953798 specificity 0.7698398582488248 recall 0.9114369501466275 f1 0.9074688159614551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 1.3020007610321045 s\n",
      "Accuracy 0.9120234604105572 precision 0.9121349879039302 specificity 0.7572914808476419 recall 0.9120234604105572 f1 0.9074558223588101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 1.1730003356933594 s\n",
      "Accuracy 0.9137829912023461 precision 0.9133152545223305 specificity 0.7682724536885949 recall 0.9137829912023461 f1 0.9097920854009325\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 1.2920002937316895 s\n",
      "Accuracy 0.9161290322580645 precision 0.9151930215802263 specificity 0.7868814140857152 recall 0.9161290322580645 f1 0.9129300170964827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 1.2649991512298584 s\n",
      "Accuracy 0.9085043988269794 precision 0.9071115343337092 specificity 0.7220334686706497 recall 0.9085043988269794 f1 0.9031130855684116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 1.1369996070861816 s\n",
      "Accuracy 0.9043988269794722 precision 0.9041245096178501 specificity 0.7441291882152097 recall 0.9043988269794722 f1 0.8992564308574661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 1.2309966087341309 s\n",
      "Accuracy 0.910850439882698 precision 0.910853281269409 specificity 0.7567233403905453 recall 0.910850439882698 f1 0.9062597399501054\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 1.2869999408721924 s\n",
      "Accuracy 0.906158357771261 precision 0.9082233334925227 specificity 0.7473202312579751 recall 0.906158357771261 f1 0.9005723435183545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 1.2790014743804932 s\n",
      "Accuracy 0.9096774193548387 precision 0.9089885567874665 specificity 0.7659149681019555 recall 0.9096774193548387 f1 0.9055766694848555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 1.223998785018921 s\n",
      "Accuracy 0.9085043988269794 precision 0.9089676885746123 specificity 0.7440323795661703 recall 0.9085043988269794 f1 0.9032809183145124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 1.2489988803863525 s\n",
      "Accuracy 0.9155425219941349 precision 0.9154352933235825 specificity 0.7651329030504895 recall 0.9155425219941349 f1 0.9113920449189393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 1.2020015716552734 s\n",
      "Accuracy 0.9114369501466275 precision 0.910320631178355 specificity 0.7424941940616193 recall 0.9114369501466275 f1 0.9067673073778333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 1.229999303817749 s\n",
      "Accuracy 0.9202346041055719 precision 0.9195799651452311 specificity 0.7794513188926283 recall 0.9202346041055719 f1 0.9168119230459839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 1.246000051498413 s\n",
      "Accuracy 0.9131964809384164 precision 0.913894047194852 specificity 0.7566789979887867 recall 0.9131964809384164 f1 0.908486470533165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 1.244999885559082 s\n",
      "Accuracy 0.8997067448680351 precision 0.8993635399488328 specificity 0.730768088940132 recall 0.8997067448680351 f1 0.893927049948937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 1.2380008697509766 s\n",
      "Accuracy 0.9131964809384164 precision 0.9132583627501427 specificity 0.7516111858246187 recall 0.9131964809384164 f1 0.9084995333572183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 1.2559990882873535 s\n",
      "Accuracy 0.9008797653958944 precision 0.9029268097041244 specificity 0.7157455447778028 recall 0.9008797653958944 f1 0.8939147524401974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 1.2260007858276367 s\n",
      "Accuracy 0.9137829912023461 precision 0.9143891255022157 specificity 0.7662421800072324 recall 0.9137829912023461 f1 0.9094155247119119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 1.2690019607543945 s\n",
      "Accuracy 0.9155425219941349 precision 0.914855244653352 specificity 0.7743680457964042 recall 0.9155425219941349 f1 0.91186022882161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 1.2319979667663574 s\n",
      "Accuracy 0.8944281524926686 precision 0.8938584642293185 specificity 0.7189687575144108 recall 0.8944281524926686 f1 0.888052102640842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 1.2470004558563232 s\n",
      "Accuracy 0.906158357771261 precision 0.906140789816893 specificity 0.7348399820785497 recall 0.906158357771261 f1 0.9006660638539197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 1.2669990062713623 s\n",
      "Accuracy 0.9055718475073313 precision 0.9063235074674072 specificity 0.767317663123737 recall 0.9055718475073313 f1 0.9009840831493372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 1.176999807357788 s\n",
      "Accuracy 0.8944281524926686 precision 0.8929432016430755 specificity 0.7387845320181078 recall 0.8944281524926686 f1 0.8892091778991672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 1.2829992771148682 s\n",
      "Accuracy 0.9038123167155425 precision 0.9044760375743228 specificity 0.7379061285654226 recall 0.9038123167155425 f1 0.8981516040167066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 1.2619993686676025 s\n",
      "Accuracy 0.9079178885630499 precision 0.9095282163632242 specificity 0.7520215871658995 recall 0.9079178885630499 f1 0.902658209601793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 1.2879996299743652 s\n",
      "Accuracy 0.9096774193548387 precision 0.9097849704734309 specificity 0.7552128782836877 recall 0.9096774193548387 f1 0.9049701083389756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 1.2350003719329834 s\n",
      "Accuracy 0.9102639296187683 precision 0.9102029404259139 specificity 0.7426746452428745 recall 0.9102639296187683 f1 0.9052072604323592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 1.242997646331787 s\n",
      "Accuracy 0.9167155425219942 precision 0.9165552591155307 specificity 0.7497448808659936 recall 0.9167155425219942 f1 0.9121505762920272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 1.1780014038085938 s\n",
      "Accuracy 0.9002932551319648 precision 0.9002702956554409 specificity 0.7350773070678658 recall 0.9002932551319648 f1 0.8946005565269536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 1.1970000267028809 s\n",
      "Accuracy 0.9073313782991203 precision 0.9068486350067867 specificity 0.7567464128973151 recall 0.9073313782991203 f1 0.9027885995078385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 1.3179984092712402 s\n",
      "Accuracy 0.9043988269794722 precision 0.9055321627609085 specificity 0.7658503908511199 recall 0.9043988269794722 f1 0.8996343415005064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 1.3090007305145264 s\n",
      "Accuracy 0.8991202346041056 precision 0.8995819108145202 specificity 0.7530565859798983 recall 0.8991202346041056 f1 0.8939341990558008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 1.1739981174468994 s\n",
      "Accuracy 0.9126099706744868 precision 0.9124132832407728 specificity 0.7571503935996946 recall 0.9126099706744868 f1 0.9081478313149868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 1.2419993877410889 s\n",
      "Accuracy 0.9143695014662757 precision 0.9136761998595807 specificity 0.7835287148944685 recall 0.9143695014662757 f1 0.9109400342383307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 1.2550008296966553 s\n",
      "Accuracy 0.9090909090909091 precision 0.9117348515634784 specificity 0.737091427091427 recall 0.9090909090909091 f1 0.9031296413293876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 1.256000280380249 s\n",
      "Accuracy 0.9079178885630499 precision 0.9071716252422087 specificity 0.7641604615640807 recall 0.9079178885630499 f1 0.9037334023936056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 1.267000436782837 s\n",
      "Accuracy 0.9049853372434018 precision 0.9078631517914519 specificity 0.7460238914541151 recall 0.9049853372434018 f1 0.8991373892340659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 1.2659995555877686 s\n",
      "Accuracy 0.9131964809384164 precision 0.9132451175511466 specificity 0.7603779712767528 recall 0.9131964809384164 f1 0.9087817189357482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 1.2609987258911133 s\n",
      "Accuracy 0.9114369501466275 precision 0.913296197768529 specificity 0.759625905126754 recall 0.9114369501466275 f1 0.9064879288595025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 1.2549998760223389 s\n",
      "Accuracy 0.8944281524926686 precision 0.8938977603066092 specificity 0.727408029444382 recall 0.8944281524926686 f1 0.8883902819472942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 1.1919996738433838 s\n",
      "Accuracy 0.9008797653958944 precision 0.9006373763356494 specificity 0.7135348397728485 recall 0.9008797653958944 f1 0.8944445207178872\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 1.3350026607513428 s\n",
      "Accuracy 0.9049853372434018 precision 0.9055767209571671 specificity 0.7211213250396691 recall 0.9049853372434018 f1 0.8987751445896482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 1.2709987163543701 s\n",
      "Accuracy 0.9049853372434018 precision 0.9056584028605347 specificity 0.7341969983287109 recall 0.9049853372434018 f1 0.8992301865282643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 1.2409987449645996 s\n",
      "Accuracy 0.9131964809384164 precision 0.9113032583757632 specificity 0.7773847379626669 recall 0.9131964809384164 f1 0.9101076058604229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 1.2270007133483887 s\n",
      "Accuracy 0.9214076246334311 precision 0.9212051343685399 specificity 0.7793897593532544 recall 0.9214076246334311 f1 0.9178666597431074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 1.2049994468688965 s\n",
      "Accuracy 0.9055718475073313 precision 0.9070842199982768 specificity 0.7351275157770444 recall 0.9055718475073313 f1 0.8996582183063517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 1.2560009956359863 s\n",
      "Accuracy 0.9149560117302052 precision 0.9152013783495465 specificity 0.7673500328740948 recall 0.9149560117302052 f1 0.9107540146794927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 1.1429996490478516 s\n",
      "Accuracy 0.9143695014662757 precision 0.9136332593124544 specificity 0.7523609602905613 recall 0.9143695014662757 f1 0.9099879472163871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 1.2370002269744873 s\n",
      "Accuracy 0.9020527859237537 precision 0.9011957445985769 specificity 0.7457524811329533 recall 0.9020527859237537 f1 0.8970911063053693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 1.2449991703033447 s\n",
      "Accuracy 0.9002932551319648 precision 0.9016420080034675 specificity 0.7333917732899058 recall 0.9002932551319648 f1 0.894158581513714\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 1.2570006847381592 s\n",
      "Accuracy 0.9032258064516129 precision 0.9042786715911674 specificity 0.7384412974996911 recall 0.9032258064516129 f1 0.8974611782726519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 1.215998888015747 s\n",
      "Accuracy 0.9178885630498533 precision 0.917342972106663 specificity 0.7577644179021067 recall 0.9178885630498533 f1 0.9137282502443793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 1.2410008907318115 s\n",
      "Accuracy 0.9073313782991203 precision 0.9090037154807117 specificity 0.7509789733119511 recall 0.9073313782991203 f1 0.9020021786845358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 1.2910006046295166 s\n",
      "Accuracy 0.9026392961876832 precision 0.9025440161009975 specificity 0.7257491545241769 recall 0.9026392961876832 f1 0.8967013474420846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 1.2890009880065918 s\n",
      "Accuracy 0.9161290322580645 precision 0.9160713330153671 specificity 0.7607647203349108 recall 0.9161290322580645 f1 0.9118490727833469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 1.259998083114624 s\n",
      "Accuracy 0.9020527859237537 precision 0.901651914898957 specificity 0.7532186611764872 recall 0.9020527859237537 f1 0.8972113714790447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 1.2149999141693115 s\n",
      "Accuracy 0.9008797653958944 precision 0.9017401158838217 specificity 0.7302625267220074 recall 0.9008797653958944 f1 0.89477354713368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 1.278001070022583 s\n",
      "Accuracy 0.9178885630498533 precision 0.9160124107480805 specificity 0.7841490432130543 recall 0.9178885630498533 f1 0.915135327368229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 1.2980012893676758 s\n",
      "Accuracy 0.9043988269794722 precision 0.9038048226458151 specificity 0.7560299310143686 recall 0.9043988269794722 f1 0.8997866727492334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 1.1959969997406006 s\n",
      "Accuracy 0.9079178885630499 precision 0.9076838058256406 specificity 0.7521908199327554 recall 0.9079178885630499 f1 0.9031571367062187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 1.2550005912780762 s\n",
      "Accuracy 0.9149560117302052 precision 0.914498035387104 specificity 0.757313260285944 recall 0.9149560117302052 f1 0.910656196184737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 1.234001636505127 s\n",
      "Accuracy 0.9067448680351906 precision 0.9062926945522594 specificity 0.7477666262176829 recall 0.9067448680351906 f1 0.9018638026496268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 1.2509996891021729 s\n",
      "Accuracy 0.9073313782991203 precision 0.9071799030018977 specificity 0.7353909789257804 recall 0.9073313782991203 f1 0.9019431161274956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 1.2439990043640137 s\n",
      "Accuracy 0.9161290322580645 precision 0.9160215114355621 specificity 0.767821107852091 recall 0.9161290322580645 f1 0.9120772664626414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 1.2500011920928955 s\n",
      "Accuracy 0.9090909090909091 precision 0.9111911275221203 specificity 0.7546676837861601 recall 0.9090909090909091 f1 0.9038490067394355\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 1.2599995136260986 s\n",
      "Accuracy 0.906158357771261 precision 0.90690872934714 specificity 0.7523123811655399 recall 0.906158357771261 f1 0.901066422029138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 1.1920008659362793 s\n",
      "Accuracy 0.9026392961876832 precision 0.9046101025075447 specificity 0.7460022921090774 recall 0.9026392961876832 f1 0.896910035161777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 1.234999418258667 s\n",
      "Accuracy 0.9214076246334311 precision 0.9210849756304302 specificity 0.7648889495101049 recall 0.9214076246334311 f1 0.9174996546007184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 1.2659988403320312 s\n",
      "Accuracy 0.9079178885630499 precision 0.9072914536666769 specificity 0.7540946414615819 recall 0.9079178885630499 f1 0.9033494903165957\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 1.2940008640289307 s\n",
      "Accuracy 0.9079178885630499 precision 0.9068991662239434 specificity 0.7404900410357389 recall 0.9079178885630499 f1 0.9030168433381675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 1.2560009956359863 s\n",
      "Accuracy 0.9114369501466275 precision 0.91456961414073 specificity 0.7452727211971901 recall 0.9114369501466275 f1 0.9057480380703825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 1.3179984092712402 s\n",
      "Accuracy 0.9208211143695014 precision 0.9202378092783035 specificity 0.7848944925130079 recall 0.9208211143695014 f1 0.9175410671940268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 1.3059990406036377 s\n",
      "Accuracy 0.9237536656891495 precision 0.9237288774352423 specificity 0.770185581869401 recall 0.9237536656891495 f1 0.9199783168932729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 1.3000006675720215 s\n",
      "Accuracy 0.9120234604105572 precision 0.9112852122441444 specificity 0.7509193070635787 recall 0.9120234604105572 f1 0.9075171109075566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 1.2450001239776611 s\n",
      "Accuracy 0.9038123167155425 precision 0.9028488953360955 specificity 0.7417932935853883 recall 0.9038123167155425 f1 0.8987977905342228\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 1.185999870300293 s\n",
      "Accuracy 0.898533724340176 precision 0.8979156812663577 specificity 0.7401699274763927 recall 0.898533724340176 f1 0.8931701439046038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 1.2649991512298584 s\n",
      "Accuracy 0.9120234604105572 precision 0.9114360854000844 specificity 0.7642537563679894 recall 0.9120234604105572 f1 0.9078969215330148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 1.2799999713897705 s\n",
      "Accuracy 0.9043988269794722 precision 0.9028561870800481 specificity 0.7250257923951978 recall 0.9043988269794722 f1 0.899002958553077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 1.2479994297027588 s\n",
      "Accuracy 0.9067448680351906 precision 0.9065679469042432 specificity 0.7721394660215573 recall 0.9067448680351906 f1 0.9026127875724145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 1.265000581741333 s\n",
      "Accuracy 0.9043988269794722 precision 0.9036191231567193 specificity 0.7427780739251632 recall 0.9043988269794722 f1 0.8993743633937699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 1.2120006084442139 s\n",
      "Accuracy 0.910850439882698 precision 0.9102583020198788 specificity 0.743378209110349 recall 0.910850439882698 f1 0.9060050884581958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 1.2530007362365723 s\n",
      "Accuracy 0.910850439882698 precision 0.9097317351100477 specificity 0.7547928298118123 recall 0.910850439882698 f1 0.9065723998739866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 1.318000316619873 s\n",
      "Accuracy 0.910850439882698 precision 0.9116472172287319 specificity 0.7584216196332639 recall 0.910850439882698 f1 0.9060966692671436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 1.2199995517730713 s\n",
      "Accuracy 0.9161290322580645 precision 0.9154298742469906 specificity 0.7687753676137914 recall 0.9161290322580645 f1 0.9122973611937959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 1.2650001049041748 s\n",
      "Accuracy 0.9090909090909091 precision 0.909182183723429 specificity 0.742847742929199 recall 0.9090909090909091 f1 0.9039529624021455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 1.1660006046295166 s\n",
      "Accuracy 0.9085043988269794 precision 0.9097336398978304 specificity 0.7293721732701249 recall 0.9085043988269794 f1 0.9025742952668561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 1.2849986553192139 s\n",
      "Accuracy 0.9208211143695014 precision 0.9215880052693566 specificity 0.7690979652834186 recall 0.9208211143695014 f1 0.9167107901117659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 1.2269997596740723 s\n",
      "Accuracy 0.9120234604105572 precision 0.9125059414723667 specificity 0.7801033782680057 recall 0.9120234604105572 f1 0.9080763720439828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 1.2660002708435059 s\n",
      "Accuracy 0.9102639296187683 precision 0.909835463612413 specificity 0.762955443600605 recall 0.9102639296187683 f1 0.9059936980038169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 1.34800124168396 s\n",
      "Accuracy 0.9096774193548387 precision 0.9098788471222488 specificity 0.7496124592467187 recall 0.9096774193548387 f1 0.9047562468082524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 1.3469998836517334 s\n",
      "Accuracy 0.9102639296187683 precision 0.9085002468312425 specificity 0.7752120347478236 recall 0.9102639296187683 f1 0.906952653235347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 1.2880003452301025 s\n",
      "Accuracy 0.9126099706744868 precision 0.9124334957890233 specificity 0.7579185828089416 recall 0.9126099706744868 f1 0.9081661939934936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 1.2549989223480225 s\n",
      "Accuracy 0.9014662756598241 precision 0.8990714937924408 specificity 0.7315029398317351 recall 0.9014662756598241 f1 0.8965981119424886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 1.2229993343353271 s\n",
      "Accuracy 0.9126099706744868 precision 0.9126182556446487 specificity 0.7368845300699538 recall 0.9126099706744868 f1 0.9074304308014511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 1.3220000267028809 s\n",
      "Accuracy 0.8997067448680351 precision 0.8999559818367159 specificity 0.7239491691104594 recall 0.8997067448680351 f1 0.8934820184661444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 1.2259995937347412 s\n",
      "Accuracy 0.9079178885630499 precision 0.9085624814716127 specificity 0.7477133852094997 recall 0.9079178885630499 f1 0.9027513144889011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 1.222999095916748 s\n",
      "Accuracy 0.9096774193548387 precision 0.9097584829062701 specificity 0.7628422721881223 recall 0.9096774193548387 f1 0.9052302264022853\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 1.2550008296966553 s\n",
      "Accuracy 0.9102639296187683 precision 0.9090587102240111 specificity 0.7496034285654845 recall 0.9102639296187683 f1 0.9058265981839339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 1.312002420425415 s\n",
      "Accuracy 0.9155425219941349 precision 0.9158230230275578 specificity 0.7806329569102035 recall 0.9155425219941349 f1 0.9117475352053098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 1.2010002136230469 s\n",
      "Accuracy 0.9079178885630499 precision 0.9068480689107146 specificity 0.7529672211093822 recall 0.9079178885630499 f1 0.9034694463960468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 1.2899994850158691 s\n",
      "Accuracy 0.918475073313783 precision 0.9180353547074364 specificity 0.781207347973987 recall 0.918475073313783 f1 0.9149843959866628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 1.2319998741149902 s\n",
      "Accuracy 0.9067448680351906 precision 0.9069613933297596 specificity 0.7543920220464442 recall 0.9067448680351906 f1 0.9018895745146166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 1.2530009746551514 s\n",
      "Accuracy 0.9143695014662757 precision 0.9147998003872352 specificity 0.7622396939360231 recall 0.9143695014662757 f1 0.9099418879044362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 1.2840018272399902 s\n",
      "Accuracy 0.9038123167155425 precision 0.904616422501784 specificity 0.7329122896420955 recall 0.9038123167155425 f1 0.8979308419830009\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 1.2069971561431885 s\n",
      "Accuracy 0.9055718475073313 precision 0.9050386514758768 specificity 0.7480379835218544 recall 0.9055718475073313 f1 0.9006898026095617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 1.2069995403289795 s\n",
      "Accuracy 0.9067448680351906 precision 0.9067618788924114 specificity 0.7474757999962551 recall 0.9067448680351906 f1 0.9017080811066629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 1.303001880645752 s\n",
      "Accuracy 0.9219941348973607 precision 0.9219682820503683 specificity 0.7809686464033669 recall 0.9219941348973607 f1 0.9184596661685006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 1.273998498916626 s\n",
      "Accuracy 0.9026392961876832 precision 0.9042661773750945 specificity 0.7341344290075554 recall 0.9026392961876832 f1 0.8965503588217097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 1.3380005359649658 s\n",
      "Accuracy 0.9120234604105572 precision 0.9128902853747483 specificity 0.7463223600001032 recall 0.9120234604105572 f1 0.9068957955297942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 1.3000006675720215 s\n",
      "Accuracy 0.8926686217008798 precision 0.8947627543691689 specificity 0.7275589118841458 recall 0.8926686217008798 f1 0.8858427009053071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 1.2439992427825928 s\n",
      "Accuracy 0.9219941348973607 precision 0.9210953477246965 specificity 0.7831366625747076 recall 0.9219941348973607 f1 0.918810436486665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 1.1590006351470947 s\n",
      "Accuracy 0.9208211143695014 precision 0.9202803986072097 specificity 0.7789160864460009 recall 0.9208211143695014 f1 0.9173597676517451\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 1.2690010070800781 s\n",
      "Accuracy 0.8979472140762463 precision 0.8969672708216437 specificity 0.7470685354142114 recall 0.8979472140762463 f1 0.89296285642788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 1.2519989013671875 s\n",
      "Accuracy 0.906158357771261 precision 0.9054546440604585 specificity 0.7368550582826846 recall 0.906158357771261 f1 0.9009553358693126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 1.1620006561279297 s\n",
      "Accuracy 0.9143695014662757 precision 0.9156186452843343 specificity 0.7396656458498804 recall 0.9143695014662757 f1 0.909022324142793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 1.263998031616211 s\n",
      "Accuracy 0.9143695014662757 precision 0.9131375840083438 specificity 0.769336437523462 recall 0.9143695014662757 f1 0.9107102644313809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 1.3840007781982422 s\n",
      "Accuracy 0.9038123167155425 precision 0.9048679964216219 specificity 0.7511693009315163 recall 0.9038123167155425 f1 0.8985294318498879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 1.356001377105713 s\n",
      "Accuracy 0.9131964809384164 precision 0.9148164073486637 specificity 0.7606560033121036 recall 0.9131964809384164 f1 0.9083897837269399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 1.3530001640319824 s\n",
      "Accuracy 0.906158357771261 precision 0.9055572406196495 specificity 0.7554438312924909 recall 0.906158357771261 f1 0.901576745994542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 1.3559980392456055 s\n",
      "Accuracy 0.9161290322580645 precision 0.9172098812157914 specificity 0.7779808420260378 recall 0.9161290322580645 f1 0.912065481876032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 1.222001075744629 s\n",
      "Accuracy 0.906158357771261 precision 0.9080327322251376 specificity 0.7402217021480958 recall 0.906158357771261 f1 0.9003636477680299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 1.2939996719360352 s\n",
      "Accuracy 0.9026392961876832 precision 0.9043474606069306 specificity 0.7257447961607317 recall 0.9026392961876832 f1 0.8962155025212942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 1.2859995365142822 s\n",
      "Accuracy 0.9296187683284457 precision 0.9295365105153337 specificity 0.7972078552820223 recall 0.9296187683284457 f1 0.9267139776060173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 1.1710007190704346 s\n",
      "Accuracy 0.9067448680351906 precision 0.905907062680211 specificity 0.7422973178286328 recall 0.9067448680351906 f1 0.9018019026529643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 1.1949989795684814 s\n",
      "Accuracy 0.9079178885630499 precision 0.9078899231527641 specificity 0.7423575003634165 recall 0.9079178885630499 f1 0.9027566267084777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 1.278998851776123 s\n",
      "Accuracy 0.9002932551319648 precision 0.8982688795518279 specificity 0.7289281286294812 recall 0.9002932551319648 f1 0.8950967370073938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 1.250999927520752 s\n",
      "Accuracy 0.9026392961876832 precision 0.9026237602936648 specificity 0.728346923086845 recall 0.9026392961876832 f1 0.8967749421842374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 1.224001407623291 s\n",
      "Accuracy 0.9173020527859238 precision 0.9163713825888915 specificity 0.7563187590371352 recall 0.9173020527859238 f1 0.9132118951051733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 1.1989991664886475 s\n",
      "Accuracy 0.9090909090909091 precision 0.9073270793592725 specificity 0.7392762819766299 recall 0.9090909090909091 f1 0.9044888418130685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 1.317002296447754 s\n",
      "Accuracy 0.9038123167155425 precision 0.9037518316325431 specificity 0.7405466576434317 recall 0.9038123167155425 f1 0.8984548564827157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 1.3109984397888184 s\n",
      "Accuracy 0.9114369501466275 precision 0.9096051351490827 specificity 0.7710100537055068 recall 0.9114369501466275 f1 0.9080467991841095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 1.255000352859497 s\n",
      "Accuracy 0.9149560117302052 precision 0.9164807553362952 specificity 0.7788795696191898 recall 0.9149560117302052 f1 0.9107879776496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 1.4120004177093506 s\n",
      "Accuracy 0.9067448680351906 precision 0.9081479906282273 specificity 0.7590405226658536 recall 0.9067448680351906 f1 0.9017397598784131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 1.3699994087219238 s\n",
      "Accuracy 0.9114369501466275 precision 0.9101357158550867 specificity 0.7806239142916689 recall 0.9114369501466275 f1 0.9080995975795658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 1.371999740600586 s\n",
      "Accuracy 0.9131964809384164 precision 0.9135729393375412 specificity 0.7638690461271107 recall 0.9131964809384164 f1 0.9087991341449329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 1.297999620437622 s\n",
      "Accuracy 0.9126099706744868 precision 0.9118990063237893 specificity 0.7461839831458422 recall 0.9126099706744868 f1 0.9079601054537316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 1.311000108718872 s\n",
      "Accuracy 0.9161290322580645 precision 0.9154112852728373 specificity 0.7680367929147354 recall 0.9161290322580645 f1 0.9122815087688714\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 1.3310017585754395 s\n",
      "Accuracy 0.910850439882698 precision 0.9107295272441785 specificity 0.760696960822015 recall 0.910850439882698 f1 0.9064264131031535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 1.2299995422363281 s\n",
      "Accuracy 0.9043988269794722 precision 0.9040276779420421 specificity 0.7409242151085592 recall 0.9043988269794722 f1 0.8991713547640444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 1.3109979629516602 s\n",
      "Accuracy 0.9190615835777126 precision 0.9189276916533476 specificity 0.7620473121827429 recall 0.9190615835777126 f1 0.9149374563372852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 1.2860000133514404 s\n",
      "Accuracy 0.9096774193548387 precision 0.9096139959644161 specificity 0.7489890775469523 recall 0.9096774193548387 f1 0.9048127846250376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 1.122999906539917 s\n",
      "Accuracy 0.8956011730205279 precision 0.8953212126570215 specificity 0.7390127975677074 recall 0.8956011730205279 f1 0.8899923383794351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 1.2950003147125244 s\n",
      "Accuracy 0.9178885630498533 precision 0.9177385829037652 specificity 0.7652302229671875 recall 0.9178885630498533 f1 0.9138251305028338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 1.2009985446929932 s\n",
      "Accuracy 0.9090909090909091 precision 0.9096145265132544 specificity 0.7491272168691523 recall 0.9090909090909091 f1 0.904044257725046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 1.213003158569336 s\n",
      "Accuracy 0.9196480938416423 precision 0.9196020352411295 specificity 0.768663594470046 recall 0.9196480938416423 f1 0.9157077374909174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 1.2789967060089111 s\n",
      "Accuracy 0.8961876832844575 precision 0.8949779275941598 specificity 0.7279718608750868 recall 0.8961876832844575 f1 0.8904718204850017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 1.1899974346160889 s\n",
      "Accuracy 0.910850439882698 precision 0.9103868564678499 specificity 0.7714849883755109 recall 0.910850439882698 f1 0.906884019191637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 1.2810001373291016 s\n",
      "Accuracy 0.9149560117302052 precision 0.9143512350729052 specificity 0.7823956288264067 recall 0.9149560117302052 f1 0.911473582334515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 1.28900146484375 s\n",
      "Accuracy 0.9079178885630499 precision 0.9064743815159344 specificity 0.7590246460265435 recall 0.9079178885630499 f1 0.9038303743425383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 1.3189997673034668 s\n",
      "Accuracy 0.9085043988269794 precision 0.9089676885746123 specificity 0.7440323795661703 recall 0.9085043988269794 f1 0.9032809183145124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 1.2599990367889404 s\n",
      "Accuracy 0.9149560117302052 precision 0.9139321064255825 specificity 0.7589894747249817 recall 0.9149560117302052 f1 0.9109060363767573\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 1.2780001163482666 s\n",
      "Accuracy 0.9131964809384164 precision 0.9130030118770652 specificity 0.751029439938995 recall 0.9131964809384164 f1 0.9085569002327186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 1.2829999923706055 s\n",
      "Accuracy 0.898533724340176 precision 0.8967648925938045 specificity 0.7254818934217193 recall 0.898533724340176 f1 0.8930218162325371\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 1.2509987354278564 s\n",
      "Accuracy 0.9178885630498533 precision 0.9162337315676026 specificity 0.7575016367374044 recall 0.9178885630498533 f1 0.9141556369246616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 1.2520010471343994 s\n",
      "Accuracy 0.918475073313783 precision 0.9194890551474163 specificity 0.766486295977307 recall 0.918475073313783 f1 0.9141549877675347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 1.2629995346069336 s\n",
      "Accuracy 0.9120234604105572 precision 0.911496989137571 specificity 0.7506861602394093 recall 0.9120234604105572 f1 0.9074382973594651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 1.2680015563964844 s\n",
      "Accuracy 0.9155425219941349 precision 0.9142229654381957 specificity 0.775845262130071 recall 0.9155425219941349 f1 0.912155898928663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 1.2319984436035156 s\n",
      "Accuracy 0.9073313782991203 precision 0.9054745870113029 specificity 0.7593942228324214 recall 0.9073313782991203 f1 0.9034359401178657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 1.2190003395080566 s\n",
      "Accuracy 0.9073313782991203 precision 0.9070211790297006 specificity 0.7550598264649658 recall 0.9073313782991203 f1 0.9026750407351498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 1.2730000019073486 s\n",
      "Accuracy 0.8903225806451613 precision 0.8889240275998602 specificity 0.7341167575901328 recall 0.8903225806451613 f1 0.884754259569841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 1.207000732421875 s\n",
      "Accuracy 0.9002932551319648 precision 0.9001697040062747 specificity 0.7399455591040879 recall 0.9002932551319648 f1 0.8948167973051052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 1.276003122329712 s\n",
      "Accuracy 0.9026392961876832 precision 0.9012426315945378 specificity 0.7373505412106907 recall 0.9026392961876832 f1 0.8975845077288851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 1.1909964084625244 s\n",
      "Accuracy 0.9090909090909091 precision 0.9085138533048838 specificity 0.7449651617321037 recall 0.9090909090909091 f1 0.9042321165268848\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 1.190000057220459 s\n",
      "Accuracy 0.9090909090909091 precision 0.9074189423991083 specificity 0.7487045228852577 recall 0.9090909090909091 f1 0.9047796674853348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 1.2399981021881104 s\n",
      "Accuracy 0.9202346041055719 precision 0.9187180303053569 specificity 0.796516603340279 recall 0.9202346041055719 f1 0.9176885843488697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 1.190000057220459 s\n",
      "Accuracy 0.8979472140762463 precision 0.8981999722194571 specificity 0.7251530153300141 recall 0.8979472140762463 f1 0.8917012710980406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 1.3379998207092285 s\n",
      "Accuracy 0.9173020527859238 precision 0.9173621737248598 specificity 0.7801118480178076 recall 0.9173020527859238 f1 0.9135967089441405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 1.318000078201294 s\n",
      "Accuracy 0.9149560117302052 precision 0.9157058269255377 specificity 0.7576312049746586 recall 0.9149560117302052 f1 0.910320307781276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 1.2059979438781738 s\n",
      "Accuracy 0.918475073313783 precision 0.9188243071232163 specificity 0.7797979445817562 recall 0.918475073313783 f1 0.9147097624205356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 1.2320003509521484 s\n",
      "Accuracy 0.9067448680351906 precision 0.9088514500533312 specificity 0.7404085870891158 recall 0.9067448680351906 f1 0.9009256676032025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 1.2559998035430908 s\n",
      "Accuracy 0.906158357771261 precision 0.9062888407330273 specificity 0.7571774332232725 recall 0.906158357771261 f1 0.9014073366884074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 1.284001350402832 s\n",
      "Accuracy 0.9143695014662757 precision 0.9131813041447584 specificity 0.7645314258615064 recall 0.9143695014662757 f1 0.9105405021402968\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 1.2679991722106934 s\n",
      "Accuracy 0.9137829912023461 precision 0.9115846074339714 specificity 0.7531521595618009 recall 0.9137829912023461 f1 0.9100580766589969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 1.248000144958496 s\n",
      "Accuracy 0.9067448680351906 precision 0.9077720288572939 specificity 0.7554949407571079 recall 0.9067448680351906 f1 0.9017097093969766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 1.2730002403259277 s\n",
      "Accuracy 0.9149560117302052 precision 0.9144502034599559 specificity 0.7637512126043954 recall 0.9149560117302052 f1 0.9108710844880794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 1.286001443862915 s\n",
      "Accuracy 0.9026392961876832 precision 0.9015760291818568 specificity 0.7413070639655734 recall 0.9026392961876832 f1 0.8976051602201123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 1.372999906539917 s\n",
      "Accuracy 0.9073313782991203 precision 0.907476465417097 specificity 0.7707893515457476 recall 0.9073313782991203 f1 0.9030701861165392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 1.3219988346099854 s\n",
      "Accuracy 0.9120234604105572 precision 0.9141848591890559 specificity 0.7505689474083916 recall 0.9120234604105572 f1 0.9067318618707575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 1.3580007553100586 s\n",
      "Accuracy 0.9002932551319648 precision 0.8995751664981727 specificity 0.7215048548203178 recall 0.9002932551319648 f1 0.8942978510105816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 1.3070001602172852 s\n",
      "Accuracy 0.9043988269794722 precision 0.9034868006581412 specificity 0.7524537112289983 recall 0.9043988269794722 f1 0.8997705306923932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 1.257002353668213 s\n",
      "Accuracy 0.9225806451612903 precision 0.9215194371691355 specificity 0.7849706999183139 recall 0.9225806451612903 f1 0.9195283548847979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 1.1340038776397705 s\n",
      "Accuracy 0.9102639296187683 precision 0.9101824815219879 specificity 0.7595556335341281 recall 0.9102639296187683 f1 0.9057735818496956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 1.2529985904693604 s\n",
      "Accuracy 0.9079178885630499 precision 0.9061850048418001 specificity 0.7547096075425949 recall 0.9079178885630499 f1 0.9038100723854697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 1.2689990997314453 s\n",
      "Accuracy 0.9026392961876832 precision 0.9015506704187476 specificity 0.7187013195024855 recall 0.9026392961876832 f1 0.8967600078891171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 1.2559969425201416 s\n",
      "Accuracy 0.9085043988269794 precision 0.906484349599449 specificity 0.7463427189675067 recall 0.9085043988269794 f1 0.9042567470025393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 1.2470006942749023 s\n",
      "Accuracy 0.906158357771261 precision 0.9064481898539987 specificity 0.7454702159326492 recall 0.906158357771261 f1 0.9009529403107314\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 1.236999750137329 s\n",
      "Accuracy 0.9143695014662757 precision 0.9137931648567639 specificity 0.7812044697174516 recall 0.9143695014662757 f1 0.910827960104485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 1.2430000305175781 s\n",
      "Accuracy 0.8956011730205279 precision 0.8939097218816715 specificity 0.7471570790571065 recall 0.8956011730205279 f1 0.8908465752801836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 1.2429993152618408 s\n",
      "Accuracy 0.9032258064516129 precision 0.9025628380227497 specificity 0.7493403485535666 recall 0.9032258064516129 f1 0.8983632597332004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 1.240999460220337 s\n",
      "Accuracy 0.918475073313783 precision 0.9194890551474163 specificity 0.766486295977307 recall 0.918475073313783 f1 0.9141549877675347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 1.2400009632110596 s\n",
      "Accuracy 0.9002932551319648 precision 0.9021248428990363 specificity 0.7390070274377705 recall 0.9002932551319648 f1 0.8942554991725051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 1.23699951171875 s\n",
      "Accuracy 0.898533724340176 precision 0.8955637709725495 specificity 0.7377621689225038 recall 0.898533724340176 f1 0.8941896749401911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 1.2990005016326904 s\n",
      "Accuracy 0.9032258064516129 precision 0.9027154175761986 specificity 0.7233499700165305 recall 0.9032258064516129 f1 0.8973510610423386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 1.193998098373413 s\n",
      "Accuracy 0.9114369501466275 precision 0.9117091103454615 specificity 0.7413519030825814 recall 0.9114369501466275 f1 0.9062833064382314\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 1.2970001697540283 s\n",
      "Accuracy 0.9008797653958944 precision 0.9023714600573706 specificity 0.7200553873046177 recall 0.9008797653958944 f1 0.8942176749206081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 1.1859991550445557 s\n",
      "Accuracy 0.9002932551319648 precision 0.9004045926735922 specificity 0.7309273337157426 recall 0.9002932551319648 f1 0.8944013231905737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 1.2290005683898926 s\n",
      "Accuracy 0.9073313782991203 precision 0.9056133063541519 specificity 0.7417351896716848 recall 0.9073313782991203 f1 0.9027337870231009\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 1.2330002784729004 s\n",
      "Accuracy 0.9008797653958944 precision 0.9004072761852818 specificity 0.7534502375914591 recall 0.9008797653958944 f1 0.896039140367392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 1.2019991874694824 s\n",
      "Accuracy 0.9161290322580645 precision 0.917876625430457 specificity 0.7724572352755714 recall 0.9161290322580645 f1 0.9117490755338198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 1.2079992294311523 s\n",
      "Accuracy 0.9085043988269794 precision 0.9082749400818826 specificity 0.7548486197954055 recall 0.9085043988269794 f1 0.9038503894005939\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 1.1950008869171143 s\n",
      "Accuracy 0.9190615835777126 precision 0.9203555497901812 specificity 0.7579926399387142 recall 0.9190615835777126 f1 0.9144458838255346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 1.2169995307922363 s\n",
      "Accuracy 0.9055718475073313 precision 0.9057204509753266 specificity 0.7379147403251902 recall 0.9055718475073313 f1 0.9001188415716398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 1.251000165939331 s\n",
      "Accuracy 0.9178885630498533 precision 0.9179492892633956 specificity 0.7740389398048948 recall 0.9178885630498533 f1 0.914021330738375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 1.2720017433166504 s\n",
      "Accuracy 0.9202346041055719 precision 0.9198220014401853 specificity 0.7736250035149177 recall 0.9202346041055719 f1 0.9165656895307983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 1.2690019607543945 s\n",
      "Accuracy 0.918475073313783 precision 0.9177287682087434 specificity 0.7833541432213158 recall 0.918475073313783 f1 0.915152621400018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 1.4359991550445557 s\n",
      "Accuracy 0.9079178885630499 precision 0.9080282034988246 specificity 0.7380964577695426 recall 0.9079178885630499 f1 0.9025682991032974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 1.303001880645752 s\n",
      "Accuracy 0.9155425219941349 precision 0.9147497926426604 specificity 0.7548783671722517 recall 0.9155425219941349 f1 0.9112992301933768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 1.2559964656829834 s\n",
      "Accuracy 0.8926686217008798 precision 0.8922683492867256 specificity 0.7244540217375531 recall 0.8926686217008798 f1 0.886404018352916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 1.2560036182403564 s\n",
      "Accuracy 0.9120234604105572 precision 0.9129912145379511 specificity 0.7503292053272943 recall 0.9120234604105572 f1 0.9070008829947234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 1.2440011501312256 s\n",
      "Accuracy 0.9196480938416423 precision 0.9182864921810127 specificity 0.7810586958764777 recall 0.9196480938416423 f1 0.9165435490355436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 1.2539989948272705 s\n",
      "Accuracy 0.9126099706744868 precision 0.9122659927753981 specificity 0.7680697806211655 recall 0.9126099706744868 f1 0.9085408111785893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 1.211998462677002 s\n",
      "Accuracy 0.9131964809384164 precision 0.9119100945019033 specificity 0.7498573235362996 recall 0.9131964809384164 f1 0.9088983915400337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 1.2619986534118652 s\n",
      "Accuracy 0.9008797653958944 precision 0.9026456489042421 specificity 0.739979987859106 recall 0.9008797653958944 f1 0.894914681476209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 1.247999906539917 s\n",
      "Accuracy 0.9090909090909091 precision 0.9074827993323291 specificity 0.7678650259015743 recall 0.9090909090909091 f1 0.9054160910344693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 1.2659997940063477 s\n",
      "Accuracy 0.9073313782991203 precision 0.9063855419213489 specificity 0.7618061721943625 recall 0.9073313782991203 f1 0.903124115445501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 1.2370002269744873 s\n",
      "Accuracy 0.9055718475073313 precision 0.9048480319314129 specificity 0.7416501063046311 recall 0.9055718475073313 f1 0.9005265429500092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 1.1949999332427979 s\n",
      "Accuracy 0.9090909090909091 precision 0.9078574386383228 specificity 0.7297006135548564 recall 0.9090909090909091 f1 0.9039358303317395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 1.2569990158081055 s\n",
      "Accuracy 0.8950146627565982 precision 0.8943256861246085 specificity 0.7250719744032096 recall 0.8950146627565982 f1 0.88895372051336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 1.1730005741119385 s\n",
      "Accuracy 0.910850439882698 precision 0.9101095800774835 specificity 0.7614110204411092 recall 0.910850439882698 f1 0.9066517305159499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 1.2700045108795166 s\n",
      "Accuracy 0.9073313782991203 precision 0.9068486350067867 specificity 0.7567464128973151 recall 0.9073313782991203 f1 0.9027885995078385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 1.2009913921356201 s\n",
      "Accuracy 0.9161290322580645 precision 0.9151571482788726 specificity 0.7653837124558769 recall 0.9161290322580645 f1 0.9122933815136414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 1.264998197555542 s\n",
      "Accuracy 0.9178885630498533 precision 0.9169723188814697 specificity 0.7937884452373244 recall 0.9178885630498533 f1 0.9149208650477226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 1.2140002250671387 s\n",
      "Accuracy 0.9202346041055719 precision 0.9196936074914603 specificity 0.7842959785859838 recall 0.9202346041055719 f1 0.9169089194398191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 1.2859976291656494 s\n",
      "Accuracy 0.9038123167155425 precision 0.9036029653308159 specificity 0.7438368733065289 recall 0.9038123167155425 f1 0.898620088511956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 1.239999771118164 s\n",
      "Accuracy 0.906158357771261 precision 0.9063741732363433 specificity 0.7600920769598717 recall 0.906158357771261 f1 0.9014833740458967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 1.2830016613006592 s\n",
      "Accuracy 0.92316715542522 precision 0.9226769454138274 specificity 0.783014237590347 recall 0.92316715542522 f1 0.9198640882721084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 1.2519986629486084 s\n",
      "Accuracy 0.9208211143695014 precision 0.9217443186110558 specificity 0.7763532151324142 recall 0.9208211143695014 f1 0.9168767538420319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 1.239999532699585 s\n",
      "Accuracy 0.918475073313783 precision 0.9199078409432467 specificity 0.7606883505847407 recall 0.918475073313783 f1 0.9138865733217363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 1.2529993057250977 s\n",
      "Accuracy 0.9143695014662757 precision 0.9139535636959865 specificity 0.7647803705653815 recall 0.9143695014662757 f1 0.9102697706286362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 1.2699995040893555 s\n",
      "Accuracy 0.9049853372434018 precision 0.9047181753072767 specificity 0.7467968218255295 recall 0.9049853372434018 f1 0.8999550617487919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 1.25700044631958 s\n",
      "Accuracy 0.9096774193548387 precision 0.9087367112527944 specificity 0.7497739266439558 recall 0.9096774193548387 f1 0.9051272458871048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 1.2489984035491943 s\n",
      "Accuracy 0.9055718475073313 precision 0.9041936493549895 specificity 0.7198558273585457 recall 0.9055718475073313 f1 0.8999678577866339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 1.260000467300415 s\n",
      "Accuracy 0.9190615835777126 precision 0.9197424048450857 specificity 0.7664751215841694 recall 0.9190615835777126 f1 0.9148419928440797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 1.2369999885559082 s\n",
      "Accuracy 0.9214076246334311 precision 0.9212943095913839 specificity 0.7645206910955653 recall 0.9214076246334311 f1 0.9174256109481917\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 1.2250008583068848 s\n",
      "Accuracy 0.9143695014662757 precision 0.9152253006902686 specificity 0.7587722609858316 recall 0.9143695014662757 f1 0.9097231398502843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 1.2949988842010498 s\n",
      "Accuracy 0.9096774193548387 precision 0.9099691291116268 specificity 0.7619186945590587 recall 0.9096774193548387 f1 0.9051394673624374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 1.2590012550354004 s\n",
      "Accuracy 0.9137829912023461 precision 0.9137720480181095 specificity 0.7607989627913726 recall 0.9137829912023461 f1 0.9094168827725775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 1.3259999752044678 s\n",
      "Accuracy 0.9114369501466275 precision 0.9101033373628324 specificity 0.7681746065255146 recall 0.9114369501466275 f1 0.9077059428197843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 1.290999412536621 s\n",
      "Accuracy 0.9161290322580645 precision 0.9158496602168523 specificity 0.7776955961694207 recall 0.9161290322580645 f1 0.912425638090708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 1.2209997177124023 s\n",
      "Accuracy 0.9120234604105572 precision 0.9129948689747034 specificity 0.7611997633773167 recall 0.9120234604105572 f1 0.9073512986790173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 1.194998025894165 s\n",
      "Accuracy 0.9155425219941349 precision 0.9170341841309518 specificity 0.7443859054925385 recall 0.9155425219941349 f1 0.9103348456932046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 1.2490012645721436 s\n",
      "Accuracy 0.8956011730205279 precision 0.895885084952401 specificity 0.7327001292443287 recall 0.8956011730205279 f1 0.8895658492976806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 1.2339997291564941 s\n",
      "Accuracy 0.9131964809384164 precision 0.9123495949066186 specificity 0.7591321980952773 recall 0.9131964809384164 f1 0.9090310209299343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 1.2559998035430908 s\n",
      "Accuracy 0.9102639296187683 precision 0.9107478137787374 specificity 0.7628333585561476 recall 0.9102639296187683 f1 0.9057195752267728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 1.3809998035430908 s\n",
      "Accuracy 0.9114369501466275 precision 0.9120294156947607 specificity 0.7634029270111826 recall 0.9114369501466275 f1 0.9069154821438021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 1.304999828338623 s\n",
      "Accuracy 0.9137829912023461 precision 0.9139241719528378 specificity 0.7667274310927659 recall 0.9137829912023461 f1 0.9095576892284156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 1.2919988632202148 s\n",
      "Accuracy 0.9085043988269794 precision 0.9067315382564649 specificity 0.7493446389254766 recall 0.9085043988269794 f1 0.9042431238892837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 1.1830005645751953 s\n",
      "Accuracy 0.906158357771261 precision 0.9049079065208244 specificity 0.7599764950302585 recall 0.906158357771261 f1 0.9019755748376963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 1.2930009365081787 s\n",
      "Accuracy 0.9126099706744868 precision 0.911622734056209 specificity 0.7589599830177806 recall 0.9126099706744868 f1 0.9084725989955048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 1.1719996929168701 s\n",
      "Accuracy 0.9131964809384164 precision 0.9127994472701879 specificity 0.7685272870214771 recall 0.9131964809384164 f1 0.9091745427079522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 1.2960007190704346 s\n",
      "Accuracy 0.9102639296187683 precision 0.9119226381027283 specificity 0.7443502733825313 recall 0.9102639296187683 f1 0.9048138464406408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 1.208998441696167 s\n",
      "Accuracy 0.9161290322580645 precision 0.9157220100897668 specificity 0.764400756624823 recall 0.9161290322580645 f1 0.9120669841705537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 1.2960002422332764 s\n",
      "Accuracy 0.9114369501466275 precision 0.9114194514006103 specificity 0.7586305957126507 recall 0.9114369501466275 f1 0.9069322290046514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 1.3470005989074707 s\n",
      "Accuracy 0.9079178885630499 precision 0.907916219523924 specificity 0.7520251313799701 recall 0.9079178885630499 f1 0.9030807874934927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 1.2109992504119873 s\n",
      "Accuracy 0.9219941348973607 precision 0.9220929025130075 specificity 0.777036777281991 recall 0.9219941348973607 f1 0.9183162980928518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 1.2430007457733154 s\n",
      "Accuracy 0.9149560117302052 precision 0.9130808198439502 specificity 0.7820136852394918 recall 0.9149560117302052 f1 0.9120573296271721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 1.2129998207092285 s\n",
      "Accuracy 0.906158357771261 precision 0.9049059029312215 specificity 0.7537590467661162 recall 0.906158357771261 f1 0.9017567163018825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 1.2679996490478516 s\n",
      "Accuracy 0.9161290322580645 precision 0.9155876763304195 specificity 0.7590162762400046 recall 0.9161290322580645 f1 0.9119469603454209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 1.1689989566802979 s\n",
      "Accuracy 0.9173020527859238 precision 0.9172413374168041 specificity 0.7566900028248011 recall 0.9173020527859238 f1 0.9129386692372515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 1.2510011196136475 s\n",
      "Accuracy 0.9237536656891495 precision 0.9221784067319454 specificity 0.7885591686991266 recall 0.9237536656891495 f1 0.921088491229662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 1.2720005512237549 s\n",
      "Accuracy 0.910850439882698 precision 0.9106815633410127 specificity 0.7413425010711249 recall 0.910850439882698 f1 0.9058031988155084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 1.233999490737915 s\n",
      "Accuracy 0.9055718475073313 precision 0.9066253798387172 specificity 0.7504056891737243 recall 0.9055718475073313 f1 0.9003164176659185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 1.2930011749267578 s\n",
      "Accuracy 0.9085043988269794 precision 0.9086850559744608 specificity 0.7433502824394665 recall 0.9085043988269794 f1 0.9033369290155016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 1.225998878479004 s\n",
      "Accuracy 0.9143695014662757 precision 0.914449288372684 specificity 0.7579166635709502 recall 0.9143695014662757 f1 0.9099052967770698\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 1.2509992122650146 s\n",
      "Accuracy 0.9196480938416423 precision 0.9213774099122396 specificity 0.782345470038885 recall 0.9196480938416423 f1 0.9156603572053206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 1.2870004177093506 s\n",
      "Accuracy 0.9085043988269794 precision 0.9075109909797088 specificity 0.7507974026247513 recall 0.9085043988269794 f1 0.9039708119671024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 1.2969996929168701 s\n",
      "Accuracy 0.8950146627565982 precision 0.8946399805605358 specificity 0.7191526632751346 recall 0.8950146627565982 f1 0.8886052568625856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 1.2480003833770752 s\n",
      "Accuracy 0.9020527859237537 precision 0.9004299242203923 specificity 0.7346733523232971 recall 0.9020527859237537 f1 0.8969681625827031\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 1.2539997100830078 s\n",
      "Accuracy 0.9190615835777126 precision 0.9174131360176226 specificity 0.7832729535096288 recall 0.9190615835777126 f1 0.9161606149483399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 1.2099978923797607 s\n",
      "Accuracy 0.9067448680351906 precision 0.907925833151896 specificity 0.7405738348700377 recall 0.9067448680351906 f1 0.9011506102893696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 1.2829997539520264 s\n",
      "Accuracy 0.9049853372434018 precision 0.9049555880534703 specificity 0.7291981753516303 recall 0.9049853372434018 f1 0.8992481759146075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 1.293999433517456 s\n",
      "Accuracy 0.906158357771261 precision 0.9059591715390659 specificity 0.7374585193365384 recall 0.906158357771261 f1 0.9008142805194899\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 1.2820022106170654 s\n",
      "Accuracy 0.9114369501466275 precision 0.9128770728754658 specificity 0.7545109353917225 recall 0.9114369501466275 f1 0.9064162118919866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 1.3719987869262695 s\n",
      "Accuracy 0.9126099706744868 precision 0.912397420254719 specificity 0.7730080981214156 recall 0.9126099706744868 f1 0.9086547370265325\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 1.2430000305175781 s\n",
      "Accuracy 0.9126099706744868 precision 0.9132542652008726 specificity 0.7713142921971445 recall 0.9126099706744868 f1 0.908358824969321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 1.3350014686584473 s\n",
      "Accuracy 0.9032258064516129 precision 0.9008595276431598 specificity 0.7367929775994543 recall 0.9032258064516129 f1 0.8986172138080343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 1.2619986534118652 s\n",
      "Accuracy 0.9020527859237537 precision 0.9030738055693656 specificity 0.7314688265607764 recall 0.9020527859237537 f1 0.8959940135097689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 1.1850008964538574 s\n",
      "Accuracy 0.930791788856305 precision 0.9291892810947117 specificity 0.7891343656824206 recall 0.930791788856305 f1 0.9283608194326196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 1.288999080657959 s\n",
      "Accuracy 0.9137829912023461 precision 0.9129750926676817 specificity 0.7769670791928563 recall 0.9137829912023461 f1 0.9101804013375281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 1.2699992656707764 s\n",
      "Accuracy 0.9202346041055719 precision 0.9201963263201903 specificity 0.7810552687173585 recall 0.9202346041055719 f1 0.9166594930898877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 1.288999319076538 s\n",
      "Accuracy 0.893841642228739 precision 0.8941970855932838 specificity 0.7273674614545573 recall 0.893841642228739 f1 0.8875075421026022\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 1.4200010299682617 s\n",
      "Accuracy 0.9137829912023461 precision 0.9137520236979653 specificity 0.7770887817931598 recall 0.9137829912023461 f1 0.9099278236816353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 1.3519988059997559 s\n",
      "Accuracy 0.9149560117302052 precision 0.914488460028185 specificity 0.7652493910706715 recall 0.9149560117302052 f1 0.9109046561619809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 1.2870001792907715 s\n",
      "Accuracy 0.9096774193548387 precision 0.9089860443245069 specificity 0.7511476113428935 recall 0.9096774193548387 f1 0.9050857327503231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 1.4449999332427979 s\n",
      "Accuracy 0.9038123167155425 precision 0.9033077917573236 specificity 0.7495260390618377 recall 0.9038123167155425 f1 0.8989204916414414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 1.4950010776519775 s\n",
      "Accuracy 0.8991202346041056 precision 0.9024035853495616 specificity 0.7357064465435097 recall 0.8991202346041056 f1 0.8925902575793981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 1.3929996490478516 s\n",
      "Accuracy 0.9202346041055719 precision 0.9212689062351246 specificity 0.7779610274233929 recall 0.9202346041055719 f1 0.916292379966162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 1.3779997825622559 s\n",
      "Accuracy 0.8944281524926686 precision 0.8939343189703904 specificity 0.7354811573549026 recall 0.8944281524926686 f1 0.8887103998048462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 1.3959996700286865 s\n",
      "Accuracy 0.8991202346041056 precision 0.8999731901378321 specificity 0.7401812359841297 recall 0.8991202346041056 f1 0.8933352912102424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 1.3529999256134033 s\n",
      "Accuracy 0.9120234604105572 precision 0.9131104826209923 specificity 0.743726167219307 recall 0.9120234604105572 f1 0.9067554007348344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 1.3190011978149414 s\n",
      "Accuracy 0.8997067448680351 precision 0.8991403743364755 specificity 0.7461240325416896 recall 0.8997067448680351 f1 0.8945896570430474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 1.255997896194458 s\n",
      "Accuracy 0.9196480938416423 precision 0.92005875567032 specificity 0.7576484297246628 recall 0.9196480938416423 f1 0.915262341656259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 1.2380025386810303 s\n",
      "Accuracy 0.9173020527859238 precision 0.915917969040481 specificity 0.7728506472224336 recall 0.9173020527859238 f1 0.9138987464136297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 1.2529983520507812 s\n",
      "Accuracy 0.9190615835777126 precision 0.9175001739279353 specificity 0.7765925155616412 recall 0.9190615835777126 f1 0.9159071389256123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 1.2609994411468506 s\n",
      "Accuracy 0.9255131964809384 precision 0.925200373704263 specificity 0.8014458550529499 recall 0.9255131964809384 f1 0.9226893172122406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 1.2619998455047607 s\n",
      "Accuracy 0.9214076246334311 precision 0.9207746547581507 specificity 0.7773597311087326 recall 0.9214076246334311 f1 0.9179504820219984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 1.187999963760376 s\n",
      "Accuracy 0.9102639296187683 precision 0.9102475722163622 specificity 0.7443231816223355 recall 0.9102639296187683 f1 0.9052492371151859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 1.2149980068206787 s\n",
      "Accuracy 0.9178885630498533 precision 0.9190535854100201 specificity 0.7697089438184352 recall 0.9178885630498533 f1 0.9136091893990687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 1.2549998760223389 s\n",
      "Accuracy 0.9131964809384164 precision 0.9125866987983247 specificity 0.768093267168451 recall 0.9131964809384164 f1 0.9092316837923381\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 1.2780020236968994 s\n",
      "Accuracy 0.9055718475073313 precision 0.9047507922601696 specificity 0.7458239993628266 recall 0.9055718475073313 f1 0.900709292644723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 1.2429983615875244 s\n",
      "Accuracy 0.9090909090909091 precision 0.9088541666666667 specificity 0.7488116458704694 recall 0.9090909090909091 f1 0.9042536410957464\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 1.3219990730285645 s\n",
      "Accuracy 0.910850439882698 precision 0.9108796437603264 specificity 0.7487217999236696 recall 0.910850439882698 f1 0.9059890307818895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 1.339000940322876 s\n",
      "Accuracy 0.9079178885630499 precision 0.9067573705137705 specificity 0.7498324063136859 recall 0.9079178885630499 f1 0.9033955053388536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 1.1879994869232178 s\n",
      "Accuracy 0.9161290322580645 precision 0.9158537975640684 specificity 0.7610502564949947 recall 0.9161290322580645 f1 0.9119236802370704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 1.1979992389678955 s\n",
      "Accuracy 0.9149560117302052 precision 0.9160588806211581 specificity 0.7612226483194224 recall 0.9149560117302052 f1 0.9103438451522365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 1.2679986953735352 s\n",
      "Accuracy 0.9155425219941349 precision 0.9156694552192347 specificity 0.7745003714385891 recall 0.9155425219941349 f1 0.9116069035066444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 1.3080003261566162 s\n",
      "Accuracy 0.9102639296187683 precision 0.9092470147323205 specificity 0.7417318599052805 recall 0.9102639296187683 f1 0.9054892358014827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 1.2839996814727783 s\n",
      "Accuracy 0.9043988269794722 precision 0.9034354706020966 specificity 0.7292591816785365 recall 0.9043988269794722 f1 0.8989436455757991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 1.307999849319458 s\n",
      "Accuracy 0.9196480938416423 precision 0.9217147522323139 specificity 0.7400826825111181 recall 0.9196480938416423 f1 0.9143526223718531\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 1.3060007095336914 s\n",
      "Accuracy 0.9260997067448681 precision 0.9272543888777636 specificity 0.7842833464520174 recall 0.9260997067448681 f1 0.9224680393040718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 1.2569985389709473 s\n",
      "Accuracy 0.9096774193548387 precision 0.9082130948998969 specificity 0.7383595898974743 recall 0.9096774193548387 f1 0.9049373510339409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 1.2620000839233398 s\n",
      "Accuracy 0.9126099706744868 precision 0.9119390724921523 specificity 0.7707765352926643 recall 0.9126099706744868 f1 0.9087354724652903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 1.2340002059936523 s\n",
      "Accuracy 0.9085043988269794 precision 0.9095654801192466 specificity 0.7346129951877418 recall 0.9085043988269794 f1 0.9027989684997024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 1.240999698638916 s\n",
      "Accuracy 0.9208211143695014 precision 0.9205892744393546 specificity 0.7840638699272474 recall 0.9208211143695014 f1 0.9174030833747114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 1.2519991397857666 s\n",
      "Accuracy 0.9167155425219942 precision 0.916675776553698 specificity 0.7642730506338993 recall 0.9167155425219942 f1 0.9125545572152174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 1.3009998798370361 s\n",
      "Accuracy 0.8997067448680351 precision 0.9010664959513376 specificity 0.7307634131670274 recall 0.8997067448680351 f1 0.893446399494416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 1.1929988861083984 s\n",
      "Accuracy 0.9237536656891495 precision 0.922784975997033 specificity 0.7865044756294405 recall 0.9237536656891495 f1 0.9207351157970777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 1.2560014724731445 s\n",
      "Accuracy 0.9167155425219942 precision 0.9160974994481759 specificity 0.7743619083331287 recall 0.9167155425219942 f1 0.9130395309218354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 1.2929983139038086 s\n",
      "Accuracy 0.906158357771261 precision 0.9046527881206633 specificity 0.7572401845262899 recall 0.906158357771261 f1 0.9019865781326555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 1.2700002193450928 s\n",
      "Accuracy 0.9102639296187683 precision 0.9104512345095073 specificity 0.7608342773901967 recall 0.9102639296187683 f1 0.9057366578163539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 1.2560009956359863 s\n",
      "Accuracy 0.9143695014662757 precision 0.9160907807772926 specificity 0.7721575340832314 recall 0.9143695014662757 f1 0.9099362877325906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 1.2319998741149902 s\n",
      "Accuracy 0.9202346041055719 precision 0.9190951525473474 specificity 0.7800533800056496 recall 0.9202346041055719 f1 0.9170158395535629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 1.245999813079834 s\n",
      "Accuracy 0.910850439882698 precision 0.9112873987523491 specificity 0.7639409753453023 recall 0.910850439882698 f1 0.9063714223317564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 1.2910020351409912 s\n",
      "Accuracy 0.9055718475073313 precision 0.9061689598997235 specificity 0.7344336025650164 recall 0.9055718475073313 f1 0.899868000459959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 1.2809979915618896 s\n",
      "Accuracy 0.9008797653958944 precision 0.9021240977494628 specificity 0.7226340047845423 recall 0.9008797653958944 f1 0.8943800605462355\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 1.2820014953613281 s\n",
      "Accuracy 0.9161290322580645 precision 0.9147703860951124 specificity 0.7571443396972118 recall 0.9161290322580645 f1 0.91219274871313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 1.2669970989227295 s\n",
      "Accuracy 0.9020527859237537 precision 0.900734410899023 specificity 0.7378759128284744 recall 0.9020527859237537 f1 0.8969673222391611\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 1.2179999351501465 s\n",
      "Accuracy 0.9214076246334311 precision 0.9222973560388718 specificity 0.7893790553547442 recall 0.9214076246334311 f1 0.917847601646791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 1.2940001487731934 s\n",
      "Accuracy 0.9002932551319648 precision 0.9015607161851898 specificity 0.7405707154562704 recall 0.9002932551319648 f1 0.8944534583842907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 1.3710002899169922 s\n",
      "Accuracy 0.9079178885630499 precision 0.9090635806556722 specificity 0.7559971576292839 recall 0.9079178885630499 f1 0.9029057018326166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 1.1929996013641357 s\n",
      "Accuracy 0.9032258064516129 precision 0.9037125786648361 specificity 0.7385325472566185 recall 0.9032258064516129 f1 0.8976160033082129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 1.2649998664855957 s\n",
      "Accuracy 0.9096774193548387 precision 0.9086742892172799 specificity 0.7547264229132186 recall 0.9096774193548387 f1 0.9053172760197388\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 1.2550008296966553 s\n",
      "Accuracy 0.9014662756598241 precision 0.9009667316986003 specificity 0.7405280702666729 recall 0.9014662756598241 f1 0.8961690857001064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 1.2119991779327393 s\n",
      "Accuracy 0.9067448680351906 precision 0.905884577494274 specificity 0.7488910558280344 recall 0.9067448680351906 f1 0.9020417309922438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 1.2910001277923584 s\n",
      "Accuracy 0.9290322580645162 precision 0.928653070730126 specificity 0.8058024889375313 recall 0.9290322580645162 f1 0.9264116151125981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 1.1620001792907715 s\n",
      "Accuracy 0.9020527859237537 precision 0.9041846067682047 specificity 0.7371980073517815 recall 0.9020527859237537 f1 0.8959382115654488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 1.2369985580444336 s\n",
      "Accuracy 0.9137829912023461 precision 0.9120066079792947 specificity 0.774312246892892 recall 0.9137829912023461 f1 0.9105332963120953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 1.2569999694824219 s\n",
      "Accuracy 0.9020527859237537 precision 0.9014897868232361 specificity 0.740800564702154 recall 0.9020527859237537 f1 0.8968057041619165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 1.278001070022583 s\n",
      "Accuracy 0.9126099706744868 precision 0.912659911014635 specificity 0.7576886759026705 recall 0.9126099706744868 f1 0.9080912907507172\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 1.1590001583099365 s\n",
      "Accuracy 0.9143695014662757 precision 0.9139262931666605 specificity 0.7372456221677627 recall 0.9143695014662757 f1 0.9094098607092842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 1.2659988403320312 s\n",
      "Accuracy 0.9014662756598241 precision 0.9012763263129833 specificity 0.7347160605225121 recall 0.9014662756598241 f1 0.8958516111039101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 1.2440009117126465 s\n",
      "Accuracy 0.9202346041055719 precision 0.9200307879764765 specificity 0.7646108786210907 recall 0.9202346041055719 f1 0.9162438551510309\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, seed in enumerate(seeds):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.906158     0.762042   0.905753  0.906158  0.901741\n1  0.899707     0.740611   0.899192  0.899707  0.894362\n2  0.905572     0.742486   0.906982  0.905572  0.899947\n3  0.904985     0.741635   0.905593  0.904985  0.899516\n4  0.915543     0.770773   0.914411  0.915543  0.911919\n5  0.914370     0.759135   0.915782  0.914370  0.909600\n6  0.917302     0.773897   0.916098  0.917302  0.913851\n7  0.913783     0.758592   0.914451  0.913783  0.909160\n8  0.901466     0.743291   0.903237  0.901466  0.895645\n9  0.905572     0.743940   0.905148  0.905572  0.900509",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.906158</td>\n      <td>0.762042</td>\n      <td>0.905753</td>\n      <td>0.906158</td>\n      <td>0.901741</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.899707</td>\n      <td>0.740611</td>\n      <td>0.899192</td>\n      <td>0.899707</td>\n      <td>0.894362</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.905572</td>\n      <td>0.742486</td>\n      <td>0.906982</td>\n      <td>0.905572</td>\n      <td>0.899947</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.904985</td>\n      <td>0.741635</td>\n      <td>0.905593</td>\n      <td>0.904985</td>\n      <td>0.899516</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.915543</td>\n      <td>0.770773</td>\n      <td>0.914411</td>\n      <td>0.915543</td>\n      <td>0.911919</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.914370</td>\n      <td>0.759135</td>\n      <td>0.915782</td>\n      <td>0.914370</td>\n      <td>0.909600</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.917302</td>\n      <td>0.773897</td>\n      <td>0.916098</td>\n      <td>0.917302</td>\n      <td>0.913851</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.913783</td>\n      <td>0.758592</td>\n      <td>0.914451</td>\n      <td>0.913783</td>\n      <td>0.909160</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.901466</td>\n      <td>0.743291</td>\n      <td>0.903237</td>\n      <td>0.901466</td>\n      <td>0.895645</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.905572</td>\n      <td>0.743940</td>\n      <td>0.905148</td>\n      <td>0.905572</td>\n      <td>0.900509</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.9096903225806452\n",
      "Precision 0.9095717181457572\n",
      "Specificity 0.7535863872276001\n",
      "Recall 0.9096903225806452\n",
      "F1 0.9049997671204685\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_64beats_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}