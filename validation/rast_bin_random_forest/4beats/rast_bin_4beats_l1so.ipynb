{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Paper CHF - 4 beats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sU5Wt4HhzLod"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3      dw_4      dw_5     mfw_1  \\\n0  e0106  13.102095  13.097001  13.072790  3.706391  0.542614  1.240982   \n1  e0106  17.487040  17.476616  17.514101  4.949534  0.713287  1.208352   \n2  e0106  17.765692  18.767421  18.563219  5.234889  0.756572  1.239086   \n3  e0106  17.472889  18.368493  18.044299  5.083577  0.745658  1.200223   \n4  e0106  16.631755  17.107590  16.986173  4.785861  0.705577  1.207803   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.895934 -2.712703 -2.663057  ... -0.069056  0.062074 -0.071315  0.072003   \n1 -0.835234 -1.803925 -2.177733  ... -0.033026  0.017482 -0.014863  0.016572   \n2 -0.727071 -1.738814 -2.078783  ... -0.036041  0.011065 -0.006174  0.017821   \n3 -0.800412 -1.813089 -2.117043  ... -0.013610 -0.003827 -0.018916  0.046067   \n4 -0.814830 -1.677964 -1.684348  ... -0.050212  0.021235 -0.011183  0.030903   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.085813  0.018093 -0.024765 -0.023205  0.019933    NSR  \n1 -0.072260  0.024719 -0.037654 -0.001608 -0.009617    NSR  \n2 -0.030732 -0.027515 -0.018567  0.002476 -0.011823    NSR  \n3 -0.068930  0.005377 -0.029879  0.006491 -0.021803    NSR  \n4 -0.061186 -0.018751  0.003333 -0.020661  0.007397    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>13.102095</td>\n      <td>13.097001</td>\n      <td>13.072790</td>\n      <td>3.706391</td>\n      <td>0.542614</td>\n      <td>1.240982</td>\n      <td>-0.895934</td>\n      <td>-2.712703</td>\n      <td>-2.663057</td>\n      <td>...</td>\n      <td>-0.069056</td>\n      <td>0.062074</td>\n      <td>-0.071315</td>\n      <td>0.072003</td>\n      <td>-0.085813</td>\n      <td>0.018093</td>\n      <td>-0.024765</td>\n      <td>-0.023205</td>\n      <td>0.019933</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>17.487040</td>\n      <td>17.476616</td>\n      <td>17.514101</td>\n      <td>4.949534</td>\n      <td>0.713287</td>\n      <td>1.208352</td>\n      <td>-0.835234</td>\n      <td>-1.803925</td>\n      <td>-2.177733</td>\n      <td>...</td>\n      <td>-0.033026</td>\n      <td>0.017482</td>\n      <td>-0.014863</td>\n      <td>0.016572</td>\n      <td>-0.072260</td>\n      <td>0.024719</td>\n      <td>-0.037654</td>\n      <td>-0.001608</td>\n      <td>-0.009617</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>17.765692</td>\n      <td>18.767421</td>\n      <td>18.563219</td>\n      <td>5.234889</td>\n      <td>0.756572</td>\n      <td>1.239086</td>\n      <td>-0.727071</td>\n      <td>-1.738814</td>\n      <td>-2.078783</td>\n      <td>...</td>\n      <td>-0.036041</td>\n      <td>0.011065</td>\n      <td>-0.006174</td>\n      <td>0.017821</td>\n      <td>-0.030732</td>\n      <td>-0.027515</td>\n      <td>-0.018567</td>\n      <td>0.002476</td>\n      <td>-0.011823</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>17.472889</td>\n      <td>18.368493</td>\n      <td>18.044299</td>\n      <td>5.083577</td>\n      <td>0.745658</td>\n      <td>1.200223</td>\n      <td>-0.800412</td>\n      <td>-1.813089</td>\n      <td>-2.117043</td>\n      <td>...</td>\n      <td>-0.013610</td>\n      <td>-0.003827</td>\n      <td>-0.018916</td>\n      <td>0.046067</td>\n      <td>-0.068930</td>\n      <td>0.005377</td>\n      <td>-0.029879</td>\n      <td>0.006491</td>\n      <td>-0.021803</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>16.631755</td>\n      <td>17.107590</td>\n      <td>16.986173</td>\n      <td>4.785861</td>\n      <td>0.705577</td>\n      <td>1.207803</td>\n      <td>-0.814830</td>\n      <td>-1.677964</td>\n      <td>-1.684348</td>\n      <td>...</td>\n      <td>-0.050212</td>\n      <td>0.021235</td>\n      <td>-0.011183</td>\n      <td>0.030903</td>\n      <td>-0.061186</td>\n      <td>-0.018751</td>\n      <td>0.003333</td>\n      <td>-0.020661</td>\n      <td>0.007397</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_4beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    104876\nST      31872\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.312273  0.162467  0.110289  0.114818  0.091114 -0.029557   \ndw_2    0.312273  1.000000  0.840060  0.440370  0.158646  0.415202 -0.437598   \ndw_3    0.162467  0.840060  1.000000  0.613108  0.233954  0.305744 -0.499972   \ndw_4    0.110289  0.440370  0.613108  1.000000  0.900298  0.029004 -0.221348   \ndw_5    0.114818  0.158646  0.233954  0.900298  1.000000 -0.093747 -0.013018   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.023458  0.025353  0.034627  0.031590  0.013505 -0.078775  0.021517   \ncfr_13 -0.014237  0.101591  0.045318  0.027101  0.011685  0.077259  0.004550   \ncfr_14 -0.036773 -0.013728 -0.033912 -0.027459 -0.024332  0.014857  0.010542   \ncfr_15 -0.059384 -0.121356 -0.133216 -0.083792 -0.037581  0.017184  0.080945   \ncfr_16 -0.038783 -0.078300 -0.044818 -0.027346 -0.015057  0.072144 -0.034046   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.006399 -0.000875  0.001703  ... -0.042191 -0.050062 -0.008514   \ndw_2   -0.206089 -0.003727  0.005025  ... -0.143619  0.102186  0.218697   \ndw_3   -0.269989 -0.004282  0.002581  ... -0.201584  0.090697  0.252037   \ndw_4   -0.125818 -0.001509  0.000622  ... -0.139370  0.027890  0.115591   \ndw_5   -0.014289  0.000039 -0.000191  ... -0.065101 -0.007436  0.022364   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.061659  0.000381  0.003797  ... -0.114312 -0.205332 -0.130827   \ncfr_13  0.003053 -0.000895  0.001937  ...  0.110173  0.020152 -0.217039   \ncfr_14  0.014576 -0.000553  0.000869  ...  0.077729  0.198416  0.039598   \ncfr_15  0.046306  0.003503 -0.004316  ...  0.231845  0.160889 -0.064172   \ncfr_16 -0.000916  0.006364 -0.004502  ...  0.210860  0.141500  0.156332   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1    0.005894  0.015042 -0.023458 -0.014237 -0.036773 -0.059384 -0.038783  \ndw_2    0.162054  0.045198  0.025353  0.101591 -0.013728 -0.121356 -0.078300  \ndw_3    0.115305 -0.043451  0.034627  0.045318 -0.033912 -0.133216 -0.044818  \ndw_4    0.036784 -0.040897  0.031590  0.027101 -0.027459 -0.083792 -0.027346  \ndw_5    0.006044 -0.015060  0.013505  0.011685 -0.024332 -0.037581 -0.015057  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12 -0.012334  0.047726  1.000000 -0.024143 -0.054066 -0.277308 -0.170496  \ncfr_13 -0.265132 -0.093551 -0.024143  1.000000  0.126068  0.040084 -0.170708  \ncfr_14 -0.185391 -0.289586 -0.054066  0.126068  1.000000  0.090389 -0.160650  \ncfr_15 -0.148376 -0.122505 -0.277308  0.040084  0.090389  1.000000  0.127273  \ncfr_16  0.069737 -0.016755 -0.170496 -0.170708 -0.160650  0.127273  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.312273</td>\n      <td>0.162467</td>\n      <td>0.110289</td>\n      <td>0.114818</td>\n      <td>0.091114</td>\n      <td>-0.029557</td>\n      <td>0.006399</td>\n      <td>-0.000875</td>\n      <td>0.001703</td>\n      <td>...</td>\n      <td>-0.042191</td>\n      <td>-0.050062</td>\n      <td>-0.008514</td>\n      <td>0.005894</td>\n      <td>0.015042</td>\n      <td>-0.023458</td>\n      <td>-0.014237</td>\n      <td>-0.036773</td>\n      <td>-0.059384</td>\n      <td>-0.038783</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.312273</td>\n      <td>1.000000</td>\n      <td>0.840060</td>\n      <td>0.440370</td>\n      <td>0.158646</td>\n      <td>0.415202</td>\n      <td>-0.437598</td>\n      <td>-0.206089</td>\n      <td>-0.003727</td>\n      <td>0.005025</td>\n      <td>...</td>\n      <td>-0.143619</td>\n      <td>0.102186</td>\n      <td>0.218697</td>\n      <td>0.162054</td>\n      <td>0.045198</td>\n      <td>0.025353</td>\n      <td>0.101591</td>\n      <td>-0.013728</td>\n      <td>-0.121356</td>\n      <td>-0.078300</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.162467</td>\n      <td>0.840060</td>\n      <td>1.000000</td>\n      <td>0.613108</td>\n      <td>0.233954</td>\n      <td>0.305744</td>\n      <td>-0.499972</td>\n      <td>-0.269989</td>\n      <td>-0.004282</td>\n      <td>0.002581</td>\n      <td>...</td>\n      <td>-0.201584</td>\n      <td>0.090697</td>\n      <td>0.252037</td>\n      <td>0.115305</td>\n      <td>-0.043451</td>\n      <td>0.034627</td>\n      <td>0.045318</td>\n      <td>-0.033912</td>\n      <td>-0.133216</td>\n      <td>-0.044818</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.110289</td>\n      <td>0.440370</td>\n      <td>0.613108</td>\n      <td>1.000000</td>\n      <td>0.900298</td>\n      <td>0.029004</td>\n      <td>-0.221348</td>\n      <td>-0.125818</td>\n      <td>-0.001509</td>\n      <td>0.000622</td>\n      <td>...</td>\n      <td>-0.139370</td>\n      <td>0.027890</td>\n      <td>0.115591</td>\n      <td>0.036784</td>\n      <td>-0.040897</td>\n      <td>0.031590</td>\n      <td>0.027101</td>\n      <td>-0.027459</td>\n      <td>-0.083792</td>\n      <td>-0.027346</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.114818</td>\n      <td>0.158646</td>\n      <td>0.233954</td>\n      <td>0.900298</td>\n      <td>1.000000</td>\n      <td>-0.093747</td>\n      <td>-0.013018</td>\n      <td>-0.014289</td>\n      <td>0.000039</td>\n      <td>-0.000191</td>\n      <td>...</td>\n      <td>-0.065101</td>\n      <td>-0.007436</td>\n      <td>0.022364</td>\n      <td>0.006044</td>\n      <td>-0.015060</td>\n      <td>0.013505</td>\n      <td>0.011685</td>\n      <td>-0.024332</td>\n      <td>-0.037581</td>\n      <td>-0.015057</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.023458</td>\n      <td>0.025353</td>\n      <td>0.034627</td>\n      <td>0.031590</td>\n      <td>0.013505</td>\n      <td>-0.078775</td>\n      <td>0.021517</td>\n      <td>0.061659</td>\n      <td>0.000381</td>\n      <td>0.003797</td>\n      <td>...</td>\n      <td>-0.114312</td>\n      <td>-0.205332</td>\n      <td>-0.130827</td>\n      <td>-0.012334</td>\n      <td>0.047726</td>\n      <td>1.000000</td>\n      <td>-0.024143</td>\n      <td>-0.054066</td>\n      <td>-0.277308</td>\n      <td>-0.170496</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.014237</td>\n      <td>0.101591</td>\n      <td>0.045318</td>\n      <td>0.027101</td>\n      <td>0.011685</td>\n      <td>0.077259</td>\n      <td>0.004550</td>\n      <td>0.003053</td>\n      <td>-0.000895</td>\n      <td>0.001937</td>\n      <td>...</td>\n      <td>0.110173</td>\n      <td>0.020152</td>\n      <td>-0.217039</td>\n      <td>-0.265132</td>\n      <td>-0.093551</td>\n      <td>-0.024143</td>\n      <td>1.000000</td>\n      <td>0.126068</td>\n      <td>0.040084</td>\n      <td>-0.170708</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.036773</td>\n      <td>-0.013728</td>\n      <td>-0.033912</td>\n      <td>-0.027459</td>\n      <td>-0.024332</td>\n      <td>0.014857</td>\n      <td>0.010542</td>\n      <td>0.014576</td>\n      <td>-0.000553</td>\n      <td>0.000869</td>\n      <td>...</td>\n      <td>0.077729</td>\n      <td>0.198416</td>\n      <td>0.039598</td>\n      <td>-0.185391</td>\n      <td>-0.289586</td>\n      <td>-0.054066</td>\n      <td>0.126068</td>\n      <td>1.000000</td>\n      <td>0.090389</td>\n      <td>-0.160650</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.059384</td>\n      <td>-0.121356</td>\n      <td>-0.133216</td>\n      <td>-0.083792</td>\n      <td>-0.037581</td>\n      <td>0.017184</td>\n      <td>0.080945</td>\n      <td>0.046306</td>\n      <td>0.003503</td>\n      <td>-0.004316</td>\n      <td>...</td>\n      <td>0.231845</td>\n      <td>0.160889</td>\n      <td>-0.064172</td>\n      <td>-0.148376</td>\n      <td>-0.122505</td>\n      <td>-0.277308</td>\n      <td>0.040084</td>\n      <td>0.090389</td>\n      <td>1.000000</td>\n      <td>0.127273</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.038783</td>\n      <td>-0.078300</td>\n      <td>-0.044818</td>\n      <td>-0.027346</td>\n      <td>-0.015057</td>\n      <td>0.072144</td>\n      <td>-0.034046</td>\n      <td>-0.000916</td>\n      <td>0.006364</td>\n      <td>-0.004502</td>\n      <td>...</td>\n      <td>0.210860</td>\n      <td>0.141500</td>\n      <td>0.156332</td>\n      <td>0.069737</td>\n      <td>-0.016755</td>\n      <td>-0.170496</td>\n      <td>-0.170708</td>\n      <td>-0.160650</td>\n      <td>0.127273</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()\n",
    "patient_ids = data[\"id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_176', 'fft_132', 'fft_177', 'fft_183', 'fft_147', 'fft_189', 'fft_221', 'fft_251', 'fft_191', 'fft_151', 'fft_255', 'fft_142', 'fft_212', 'mfw_12', 'fft_219', 'fft_209', 'fft_159', 'fft_215', 'fft_213', 'fft_162', 'fft_207', 'fft_238', 'fft_156', 'fft_256', 'fft_164', 'mfw_8', 'fft_242', 'fft_133', 'fft_173', 'fft_166', 'fft_185', 'fft_175', 'fft_204', 'fft_208', 'fft_217', 'fft_135', 'mfw_15', 'fft_168', 'fft_200', 'fft_145', 'fft_137', 'fft_144', 'fft_223', 'fft_220', 'fft_205', 'fft_222', 'fft_154', 'fft_131', 'fft_199', 'fft_226', 'mfw_9', 'fft_236', 'fft_230', 'fft_136', 'fft_195', 'fft_197', 'fft_203', 'fft_237', 'fft_193', 'fft_152', 'fft_192', 'fft_243', 'fft_169', 'fft_250', 'fft_186', 'fft_241', 'fft_239', 'fft_178', 'fft_181', 'fft_180', 'fft_211', 'fft_233', 'fft_130', 'fft_227', 'fft_172', 'fft_254', 'fft_157', 'fft_194', 'fft_228', 'fft_167', 'mfw_5', 'fft_171', 'fft_165', 'fft_202', 'fft_160', 'fft_188', 'fft_155', 'fft_158', 'fft_184', 'mfw_13', 'fft_234', 'fft_148', 'mfw_6', 'fft_240', 'fft_225', 'fft_190', 'fft_150', 'fft_196', 'fft_248', 'mfw_7', 'fft_139', 'fft_149', 'fft_163', 'fft_201', 'fft_253', 'fft_252', 'fft_198', 'fft_232', 'mfw_16', 'mfw_14', 'fft_182', 'mfw_11', 'fft_206', 'fft_179', 'fft_140', 'fft_187', 'fft_246', 'fft_170', 'fft_235', 'fft_224', 'fft_216', 'fft_247', 'fft_229', 'fft_138', 'fft_134', 'fft_249', 'fft_153', 'fft_141', 'fft_218', 'cfr_16', 'mfw_10', 'fft_244', 'fft_214', 'fft_210', 'fft_161', 'fft_143', 'fft_245', 'fft_231', 'fft_174', 'fft_146'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_24\n",
      "fft_25\n",
      "fft_26\n",
      "fft_27\n",
      "fft_28\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "fft_37\n",
      "fft_38\n",
      "fft_39\n",
      "fft_40\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 76\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization best features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYeUlEQVR4nO3de7RedX3n8ffHhJvKZRZkRgvEgGC7AK9EbOul3nCwVoIVFGoVXVRsNVXH0RG1RUSnA7Xq0gGXUqEiWkFBbNS4KIIC3jABIhgwNWAsQTpyGyRqgMB3/tj7jA+HfZKdc85znpPk/VrrrOzLb+/9fZ5z8nyeffvtVBWSJI33iFEXIEmanQwISVInA0KS1MmAkCR1MiAkSZ3mjrqA6bLHHnvUggULRl2GJG1Rrrrqqtural7XvK0mIBYsWMDy5ctHXYYkbVGS/GyieR5ikiR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHXaau6knqoFJ3xtZNtec8pLRrZtSZqIexCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqNNSASHJYklVJVic5oWP+DknOa+dfmWRBO31Bkt8kWdH+fGKYdUqSHm7usFacZA5wOnAosBZYlmRJVV0/0Ow44K6q2i/J0cCpwCvbeTdW1VOGVZ8kaeOGuQdxCLC6qm6qqvuAc4FF49osAs5uh88HXpAkQ6xJktTTMANiT+DmgfG17bTONlW1Abgb2L2dt0+Sa5JcluTZXRtIcnyS5UmW33bbbdNbvSRt42brSepbgflV9VTgbcA/J9llfKOqOqOqFlbVwnnz5s14kZK0NRtmQNwC7D0wvlc7rbNNkrnArsAdVXVvVd0BUFVXATcCTxhirZKkcYYZEMuA/ZPsk2R74Ghgybg2S4Bj2+EjgUurqpLMa09yk2RfYH/gpiHWKkkaZ2hXMVXVhiSLgYuAOcBZVbUyycnA8qpaApwJnJNkNXAnTYgAPAc4Ocn9wIPAX1bVncOqVZL0cEMLCICqWgosHTftxIHh9cBRHctdAFwwzNokSRs3W09SS5JGzICQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJnYYaEEkOS7IqyeokJ3TM3yHJee38K5MsGDd/fpJ1Sd4+zDolSQ83tIBIMgc4HXgxcABwTJIDxjU7DrirqvYDPgKcOm7+h4GvD6tGSdLEhrkHcQiwuqpuqqr7gHOBRePaLALObofPB16QJABJjgB+CqwcYo2SpAnMnWhGknuAGhtt/612uKpql02se0/g5oHxtcAzJmpTVRuS3A3snmQ98E7gUMDDS5I0AhMGRFXtPJOFjHMS8JGqWtfuUHRKcjxwPMD8+fNnpjJJ2kb0OsSU5FlJXtcO75Fknx6L3QLsPTC+Vzuts02SucCuwB00exp/n2QN8Fbg3UkWj99AVZ1RVQurauG8efP6vBRJUk8T7kGMSfJeYCHwu8A/AdsDnwWeuYlFlwH7t2FyC3A08Gfj2iwBjgW+BxwJXFpVBTx7YPsnAeuq6rQer2ertOCEr41s22tOecnIti1ptDYZEMDLgKcCVwNU1c+TbPLwU3tOYTFwETAHOKuqViY5GVheVUuAM4FzkqwG7qQJEUnSLNAnIO6rqkpSAEke1XflVbUUWDpu2okDw+uBozaxjpP6bk+SNH36nIP4QpJPArsleT3wDeAfh1uWJGnUNrkHUVX/kORQ4Jc05yFOrKqLh16ZJGmk+pykfhtwnqEgSduWPoeYdgb+NckVSRYn+S/DLkqSNHqbDIiqel9VHQi8CXgscFmSbwy9MknSSG1OX0y/AP6D5ka2/zycciRJs8UmAyLJG5N8C7gE2B14fVU9adiFSZJGq899EHsDb62qFUOuRZI0i/Q5B/Eu4NEDfTHN69kXkyRpC9bnENN7abreflc7aTuavpgkSVuxPiepXwYcDvwKmr6YaC59lSRtxfoExH1tD6ub3ReTJGnLZV9MkqRO9sUkSerU5zJX2kAwFCRpGzJhQCS5h/a8w/hZQFXVLkOrSpI0chMGRFV5pZIkbcM2py8mSdI2xICQJHUyICRJnXoFRJLHJXlhO7xTEs9PSNJWrk9fTK8Hzgc+2U7aC/jyEGuSJM0CffYg3gQ8k+ZGOarqJ/jAIEna6vUJiHur6r6xkSRz6b4/QpK0FekTEJcleTewU9vlxheBrwy3LEnSqPUJiBOA24DrgDcAS4G/GWZRkqTR69MX007AWVX1jwBJ5rTTfj3MwiRJo9VnD+ISmkAYsxNNl9+SpK1Yn4DYsarWjY20w4/ss/IkhyVZlWR1khM65u+Q5Lx2/pVJFrTTD0myov35YZKX9Xw9kqRp0icgfpXkaWMjSQ4GfrOphdpDUacDLwYOAI5JcsC4ZscBd1XVfsBHgFPb6T8CFlbVU4DDgE+2V09JkmZInw/dtwJfTPJzmq6+HwO8ssdyhwCrq+omgCTnAouA6wfaLAJOaofPB05LkqoaPL+xI15WK0kzrs8T5ZYl+T2ap8kBrKqq+3use0/g5oHxtcAzJmpTVRuS3A3sDtye5BnAWcDjgFdX1YbxG0hyPHA8wPz583uUJEnqq29nfU8HngQ8jeZQ0WuGV1Kjqq6sqgPbbb8ryY4dbc6oqoVVtXDevHnDLkmStimb3INIcg7weGAF8EA7uYDPbGLRW4C9B8b3aqd1tVnbnmPYFbhjsEFV3ZBkHXAQsHxT9UqSpkefcxALgQOqanPPAywD9k+yD00QHA382bg2S4Bjge8BRwKXVlW1y9zcHnZ6HPB7wJrN3L4kaQr6BMSPaE5M37o5K24/3BcDFwFzaG62W5nkZGB5VS0BzgTOSbIauJMmRACeBZyQ5H7gQeCNVXX75mxfkjQ1fQJiD+D6JD8A7h2bWFWHb2rBqlpK0zXH4LQTB4bXA0d1LHcOcE6P2iRJQ9InIE4adhHaci044Wsj2/aaU14ysm1L24I+l7leNhOFSJJmlz5PlPv9JMuSrEtyX5IHkvxyJoqTJI1On/sgTgOOAX5C01HfX9B0oSFJ2or1ulGuqlYDc6rqgar6J5r+kSRJW7E+J6l/nWR7YEWSv6e53LXvHdiSpC1Unw/6V7ftFgO/ornz+U+HWZQkafT6BMQRVbW+qn5ZVe+rqrcBfzLswiRJo9UnII7tmPbaaa5DkjTLTHgOIskxNH0n7ZtkycCsnWm6xZAkbcU2dpL6uzQnpPcAPjQw/R7g2mEWJUkavQkDoqp+lmQtsN67qSVp27PRcxBV9QDwYJJdZ6geSdIs0ec+iHXAdUkuprnMFYCqevPQqpIkjVyfgPhS+yNJ2ob06c317PZO6ie0k1ZV1f3DLUuSNGp9nkn9XOBsmkd+Btg7ybFVdflQK5MkjVSfQ0wfAl5UVasAkjwB+Dxw8DALkySNVp87qbcbCweAqvo3YLvhlSRJmg367EEsT/Ip4LPt+KuA5cMrSZoePg5Vmpo+AfFXwJuAsctarwA+PrSKJEmzQp+rmO5NchpwCfAgzVVM9w29MknSSPW5iuklwCeAG2muYtonyRuq6uvDLk6SNDp9r2J6XvvYUZI8HvgaYEBI0lasz1VM94yFQ+smmh5dJUlbsb5XMS0FvgAUcBSwLMmfAlSV3XBI0laoT0DsCPwf4I/a8duAnYCX0gSGASFJW6E+VzG9biYKkbYl3qOhLUGfq5j2Af4aWDDYvqoO77HsYcBHgTnAp6rqlHHzdwA+Q9Ntxx3AK6tqTZJDgVOA7YH7gHdU1aU9X5OkKTC8NKbPIaYvA2cCX6G5D6KXJHOA04FDgbU05y2WVNX1A82OA+6qqv2SHA2cCrwSuB14aVX9PMlBwEXAnn23LWnrZHjNrD4Bsb6qPjaJdR8CrK6qmwCSnAssAgYDYhFwUjt8PnBaklTVNQNtVgI7Jdmhqu6dRB2SpEnoExAfTfJe4F+B//8BXVVXb2K5PYGbB8bXAs+YqE1VbUhyN7A7zR7EmJcDV3eFQ5LjgeMB5s+f3+OlSJL66hMQTwReDTyf3x5iqnZ8qJIcSHPY6UVd86vqDOAMgIULF9aw65GkiWyNh7/6BMRRwL6T6H/pFmDvgfG92mldbdYmmQvsSnOymiR7ARcCr6mqGzdz25KkKepzJ/WPgN0mse5lwP5J9mkfWXo0sGRcmyXAse3wkcClVVVJdqPpzuOEqvrOJLYtSZqiPnsQuwE/TrKMh56D2Ohlru05hcU0VyDNAc6qqpVJTgaWV9USmqujzkmyGriTJkQAFgP7AScmObGd9qKq+kX/lyZJmoo+AfHeya68qpYCS8dNO3FgeD3NIazxy30A+MBktytJmro+d1JfNhOFSJJmlwkDIsk9NFcrPWwWUFW1y9CqkiSN3IQBUVU7z2QhkqTZpc9VTJKkbZABIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqdNQAyLJYUlWJVmd5ISO+TskOa+df2WSBe303ZN8M8m6JKcNs0ZJUrehBUSSOcDpwIuBA4BjkhwwrtlxwF1VtR/wEeDUdvp64G+Btw+rPknSxg1zD+IQYHVV3VRV9wHnAovGtVkEnN0Onw+8IEmq6ldV9W2aoJAkjcAwA2JP4OaB8bXttM42VbUBuBvYve8GkhyfZHmS5bfddtsUy5UkDdqiT1JX1RlVtbCqFs6bN2/U5UjSVmWYAXELsPfA+F7ttM42SeYCuwJ3DLEmSVJPwwyIZcD+SfZJsj1wNLBkXJslwLHt8JHApVVVQ6xJktTT3GGtuKo2JFkMXATMAc6qqpVJTgaWV9US4EzgnCSrgTtpQgSAJGuAXYDtkxwBvKiqrh9WvZKkhxpaQABU1VJg6bhpJw4MrweOmmDZBcOsTZK0cVv0SWpJ0vAYEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6jTUgEhyWJJVSVYnOaFj/g5JzmvnX5lkwcC8d7XTVyX5r8OsU5L0cEMLiCRzgNOBFwMHAMckOWBcs+OAu6pqP+AjwKntsgcARwMHAocBH2/XJ0maIcPcgzgEWF1VN1XVfcC5wKJxbRYBZ7fD5wMvSJJ2+rlVdW9V/RRY3a5PkjRD5g5x3XsCNw+MrwWeMVGbqtqQ5G5g93b698ctu+f4DSQ5Hji+HV2XZNX0lL7Z9gBun+zCOXUaK3k4a5sca5sca5ucUdb2uIlmDDMghq6qzgDOGHUdSZZX1cJR19HF2ibH2ibH2iZnttY2zENMtwB7D4zv1U7rbJNkLrArcEfPZSVJQzTMgFgG7J9knyTb05x0XjKuzRLg2Hb4SODSqqp2+tHtVU77APsDPxhirZKkcYZ2iKk9p7AYuAiYA5xVVSuTnAwsr6olwJnAOUlWA3fShAhtuy8A1wMbgDdV1QPDqnUajPww10ZY2+RY2+RY2+TMytrSfGGXJOmhvJNaktTJgJAkdTIgJEmdDIiNSPLmJDck+XySbyRZkeSVSd69ieV2TPKDJD9MsjLJ+2ag1h0Ga5ziuj6WZN0Ulp/s+7Z3km8mub59394y2Rqmu7aB5eckuSbJV6e7toFtnJTk7VNcx8uTVJJpvbZ+KrUleW2S29r3fEWSv5hFtT0nydVJNiQ5cjrrmqo0RvJZvUXfKDcD3gi8kOY+jA9U1VMA2g/Pv9vIcvcCz6+qdUm2A76d5OtV9f2NLDNVTwUYq3Gy2g+U/zTFWib7vm0A/ntVXZ1kZ+CqJBdX1fVTrGc6ahvzFuAGYJdprGlate/dW4ArR11Lh/OqavGoi+jw78BrgSkF88YkOQW4uapOb8dPovmbfx7N/7ntgL+pqn9pOy69iOZ3eDDwx8DPhlXbRNyDmECSTwD7AhcD3wGe3n7r+SKwUzv8ua5lqzH2DXy79mfSl4slWZDkx0k+neTfknwuyQuTfCfJT5IcAnx2oMZ3Jvlwu+xbktzUDu+b5Dsb2c4c4IPA/5hCrVN5326tqqvb4XtoPogf1sXKKGprl98LeAnwqemqaWDd72l/t98Gfhd4RJKr2nlPbvcG5rfjNyZ55EZW936aji/Xz8LaptV01VZVa6rqWuDBIZZ7HvCKgfFX0PRF97KqehpNUHwoSdr5+wMfr6oDq2rGwwGAqvJngh9gDU0fKc8FvjowfV2PZecAK4B1wKlTrGMBzTeNJ9KE+lXAWcBYx4ZfHqwReAywrB0+n+amxT1pbkr8XxvZzluA/9b3NQ7jfRv3mv8d2GUW/U7Pp/k295Blp6Gmg4HrgEfS7Jmspvkmu7IdX9z+Dl9F02/O9zayrqcBF7TD3wIWzqLaXgvcClzbvpd7z5baBtb5aeDI6fybG7f+G4DfAZ5M8yVlO+C09j1ZAfym/f+7APjpsOro++MhpiGp5sa+pyTZDbgwyUFV9aMprPKnVXUdQJKVwCVVVUmuo/ljGtz2fyR5dHuoYW/gn4HnAM8GvtS18iS/AxxF8+E3UkkeDVwAvLWqfjnqegCS/Anwi6q6Kslzp3n1zwYurKpft9sa63Hgu8AzaX53f0fT9X2AKyao8RHAh2k+iGdVba2vAJ+vqnuTvIHm2/PzZ0ltM+WLNL1GPIZmj+JVwDzg4Kq6P8kaYMe27a9GUuEADzENWVX9X+CbNH+kU3HvwPCDA+MP0n0u6bvA64BVNP8xng38Ac23li5PBfYDVrd/pI9Mc4f7jGrP2VwAfK6qOsNsRJ4JHN6+N+cCz0/y2SFv83Ka39vjgH+h+db5LCb+oNsZOAj4Vlvn7wNLpvtE9SRro6ruqKqxv9tP0ewBDMNm1zaDzqPpMeJImrDYleaLx/1JnsdGelYdBQNicu5vP8g6JZnX7jmQZCfgUODHM1TbmCtodrcvB66hOb55b1Xd3dW4qr5WVY+pqgVVtQD4dTUPcppOm3rfQtP9yg1V9eFp3vambLS2qnpXVe3VvjdH0/Qb9ufTtO3LgSOS7NTu9b20nX4F8OfAT6rqQZruaP4Y+PYENd5dVXsM/A6/DxxeVctHXRtAkscOjB5Oc7hlKqattplSVStpgvyWqroV+BywsD0S8Bpm/nNiozzENDlnANcmubqqXtUx/7HA2e1J30cAX6iqoV0WOYEraA4vXV5VDyS5mdH/8W3qfXsm8GrguiQr2mnvrqqls6C2oanmqq3zgB8Cv6A5bk5VrWlD8/K26beBvarqri20tjcnOZzmfNqdTPFQ2HTWluTpwIU0VxO9NMn7qurAqdS3kbqfODB8O82efZeDhrH9zWFfTJKkTh5ikiR18hDTFCTZHbikY9YLquqOma6nryQXAvuMm/zOqrpohrY/a9+32VzboCTvobnqbNAXq+p/jqKeQda29fAQkySpk4eYJEmdDAhJUicDQhonyQP5bY+jK9J0nLa56zgiyQFDKE+aMZ6klh7uNzXFXnGBI4Cv0jxXvZckc6tqwxS3K00b9yCkHpIcnOSyJFcluWjsruAkr0+yLM2zPy5I8sgkf0hzp/AH2z2Qxyf51liXF0n2aLvCGHtGwpIklwKXJHlUkrPSPE/kmiSL2nYHttNWJLk2yf6jeSe0LTEgpIcb6/p7RZIL2y44/jdNL58H0/SkO3ZZ5Jeq6ulV9WSariOOq6rvAkuAd1TVU6rqxk1s72ntuv8IeA9NNx6H0HSP8sEkjwL+Evhou2ezEFg7vS9ZejgPMUkP95BDTEkOoun24OK2q/45NN1WAxyU5APAbsCjaR7ysrkurqo72+EX0XQKOPbgmh2B+cD3gPekeSbFl6rqJ5PYjrRZDAhp0wKsrKquPnM+DRxRVT9M8lom7i59A7/dY99x3LzBbp0DvLyqVo1rc0OSK2keWLQ0yRuq6tL+L0HafB5ikjZtFTAvyR9A0yV5krGO3HYGbm0PQw128ndPO2/MGn7bvfXGnnl8EfDXY08VS/LU9t99gZuq6mM0XVg/aUqvSOrBgJA2oaruo/lQPzXJD2me/PWH7ey/pXlu8Hd4aG+55wLvaE80Px74B+CvklxD80S7ibyf5ilj16Z5MNT72+mvAH7U9nJ7EPCZaXhp0kbZ1YYkqZN7EJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSer0/wAcsQG3cwdxVQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\n0  13.102095  13.097001  13.072790  3.706391  0.542614  1.240982 -0.895934   \n1  17.487040  17.476616  17.514101  4.949534  0.713287  1.208352 -0.835234   \n2  17.765692  18.767421  18.563219  5.234889  0.756572  1.239086 -0.727071   \n3  17.472889  18.368493  18.044299  5.083577  0.745658  1.200223 -0.800412   \n4  16.631755  17.107590  16.986173  4.785861  0.705577  1.207803 -0.814830   \n\n      mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -2.712703 -2.663057  0.294201  ... -0.013426  0.064171 -0.069056  0.062074   \n1 -1.803925 -2.177733 -1.533708  ...  0.016671  0.036579 -0.033026  0.017482   \n2 -1.738814 -2.078783 -0.720965  ...  0.020868  0.035213 -0.036041  0.011065   \n3 -1.813089 -2.117043  0.838703  ...  0.026449  0.028665 -0.013610 -0.003827   \n4 -1.677964 -1.684348 -0.600837  ... -0.015116  0.060441 -0.050212  0.021235   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.071315  0.072003 -0.085813  0.018093 -0.024765 -0.023205  \n1 -0.014863  0.016572 -0.072260  0.024719 -0.037654 -0.001608  \n2 -0.006174  0.017821 -0.030732 -0.027515 -0.018567  0.002476  \n3 -0.018916  0.046067 -0.068930  0.005377 -0.029879  0.006491  \n4 -0.011183  0.030903 -0.061186 -0.018751  0.003333 -0.020661  \n\n[5 rows x 76 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.102095</td>\n      <td>13.097001</td>\n      <td>13.072790</td>\n      <td>3.706391</td>\n      <td>0.542614</td>\n      <td>1.240982</td>\n      <td>-0.895934</td>\n      <td>-2.712703</td>\n      <td>-2.663057</td>\n      <td>0.294201</td>\n      <td>...</td>\n      <td>-0.013426</td>\n      <td>0.064171</td>\n      <td>-0.069056</td>\n      <td>0.062074</td>\n      <td>-0.071315</td>\n      <td>0.072003</td>\n      <td>-0.085813</td>\n      <td>0.018093</td>\n      <td>-0.024765</td>\n      <td>-0.023205</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17.487040</td>\n      <td>17.476616</td>\n      <td>17.514101</td>\n      <td>4.949534</td>\n      <td>0.713287</td>\n      <td>1.208352</td>\n      <td>-0.835234</td>\n      <td>-1.803925</td>\n      <td>-2.177733</td>\n      <td>-1.533708</td>\n      <td>...</td>\n      <td>0.016671</td>\n      <td>0.036579</td>\n      <td>-0.033026</td>\n      <td>0.017482</td>\n      <td>-0.014863</td>\n      <td>0.016572</td>\n      <td>-0.072260</td>\n      <td>0.024719</td>\n      <td>-0.037654</td>\n      <td>-0.001608</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17.765692</td>\n      <td>18.767421</td>\n      <td>18.563219</td>\n      <td>5.234889</td>\n      <td>0.756572</td>\n      <td>1.239086</td>\n      <td>-0.727071</td>\n      <td>-1.738814</td>\n      <td>-2.078783</td>\n      <td>-0.720965</td>\n      <td>...</td>\n      <td>0.020868</td>\n      <td>0.035213</td>\n      <td>-0.036041</td>\n      <td>0.011065</td>\n      <td>-0.006174</td>\n      <td>0.017821</td>\n      <td>-0.030732</td>\n      <td>-0.027515</td>\n      <td>-0.018567</td>\n      <td>0.002476</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17.472889</td>\n      <td>18.368493</td>\n      <td>18.044299</td>\n      <td>5.083577</td>\n      <td>0.745658</td>\n      <td>1.200223</td>\n      <td>-0.800412</td>\n      <td>-1.813089</td>\n      <td>-2.117043</td>\n      <td>0.838703</td>\n      <td>...</td>\n      <td>0.026449</td>\n      <td>0.028665</td>\n      <td>-0.013610</td>\n      <td>-0.003827</td>\n      <td>-0.018916</td>\n      <td>0.046067</td>\n      <td>-0.068930</td>\n      <td>0.005377</td>\n      <td>-0.029879</td>\n      <td>0.006491</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16.631755</td>\n      <td>17.107590</td>\n      <td>16.986173</td>\n      <td>4.785861</td>\n      <td>0.705577</td>\n      <td>1.207803</td>\n      <td>-0.814830</td>\n      <td>-1.677964</td>\n      <td>-1.684348</td>\n      <td>-0.600837</td>\n      <td>...</td>\n      <td>-0.015116</td>\n      <td>0.060441</td>\n      <td>-0.050212</td>\n      <td>0.021235</td>\n      <td>-0.011183</td>\n      <td>0.030903</td>\n      <td>-0.061186</td>\n      <td>-0.018751</td>\n      <td>0.003333</td>\n      <td>-0.020661</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 76 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest - L1SO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['e0106', 'e0110', 'e0115', 'e0129', 'e0133', 'e0151', 'e0202',\n       'e0203', 'e0204', 'e0205', 'e0206', 'e0207', 'e0208', 'e0210',\n       'e0211', 'e0212', 'e0213', 'e0302', 'e0303', 'e0304', 'e0305',\n       'e0306', 'e0403', 'e0404', 'e0405', 'e0406', 'e0408', 'e0409',\n       'e0410', 'e0411', 'e0413', 'e0415', 'e0417', 'e0418', 'e0515',\n       'e0601', 'e0602', 'e0603', 'e0605', 'e0606', 'e0607', 'e0609',\n       'e0610', 'e0611', 'e0612', 'e0613', 'e0614', 'e0615', 'e0704',\n       'e0801', 'e0808', 'e0817', 'e0818', 'e1301', 'e1302', 'e1304'],\n      dtype=object)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvds = X_fsel.copy()\n",
    "cvds[\"patient_id\"] = patient_ids\n",
    "cvds[\"label\"] = y\n",
    "\n",
    "patients = np.unique(cvds[\"patient_id\"].values)\n",
    "patients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 56 - 41.40640878677368 s\n",
      "Accuracy 0.8198447893569845 precision 0.8523006892788138 specificity 0.1801552106430155 recall 0.8198447893569845 f1 0.7386844005232898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 56 - 42.21488404273987 s\n",
      "Accuracy 0.8014664410603497 precision 0.8408820150855933 specificity 0.1985335589396503 recall 0.8014664410603497 f1 0.7131395195659092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 56 - 40.90817070007324 s\n",
      "Accuracy 0.9190425906370996 precision 0.8846794502575919 specificity 0.12405978255503086 recall 0.9190425906370996 f1 0.8881012126124636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 56 - 43.40996837615967 s\n",
      "Accuracy 0.8665269042627534 precision 0.8843419715484376 specificity 0.1334730957372467 recall 0.8665269042627534 f1 0.8045626067284268\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "5 of 56 - 42.367549419403076 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "6 of 56 - 43.051491498947144 s\n",
      "Accuracy 0.9942738157209786 precision 1.0 specificity 0.0 recall 0.9942738157209786 f1 0.997128687026886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 56 - 43.3286669254303 s\n",
      "Accuracy 0.7257871662016739 precision 0.8019512476119478 specificity 0.3186572782427705 recall 0.7257871662016739 f1 0.6224612452318217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 56 - 42.52658557891846 s\n",
      "Accuracy 0.7673054360578804 precision 0.7812726831276493 specificity 0.3542099440043655 recall 0.7673054360578804 f1 0.6976989933345621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 56 - 41.24121928215027 s\n",
      "Accuracy 0.7525879917184265 precision 0.9840778582619045 specificity 0.7833803429217012 recall 0.7525879917184265 f1 0.8472110243236338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 56 - 42.63700842857361 s\n",
      "Accuracy 0.6508777740973832 precision 0.7727641027165811 specificity 0.34912222590261677 recall 0.6508777740973832 f1 0.5132322737164359\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 56 - 42.600913524627686 s\n",
      "Accuracy 0.6792589901925172 precision 0.7655645966075513 specificity 0.6861849771283066 recall 0.6792589901925172 f1 0.7027544499426794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 56 - 42.366899251937866 s\n",
      "Accuracy 0.7560706401766004 precision 0.8155721727604539 specificity 0.24392935982339956 recall 0.7560706401766004 f1 0.6510476285618747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 56 - 42.2575626373291 s\n",
      "Accuracy 0.9053013140009062 precision 0.9142691551308612 specificity 0.0946986859990938 recall 0.9053013140009062 f1 0.8603053628412891\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 56 - 42.628355741500854 s\n",
      "Accuracy 0.8104545454545454 precision 0.8463820247933883 specificity 0.18954545454545454 recall 0.8104545454545454 f1 0.7256040444616894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 56 - 41.47994947433472 s\n",
      "Accuracy 0.7478214945867441 precision 0.6748258907854116 specificity 0.18738891733156657 recall 0.7478214945867441 f1 0.7079176791699087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 56 - 42.758445262908936 s\n",
      "Accuracy 0.9463307776560789 precision 0.897561538018101 specificity 0.05251315297975928 recall 0.9463307776560789 f1 0.9213012072847588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 56 - 44.5889675617218 s\n",
      "Accuracy 0.7400568181818182 precision 0.7348576309704896 specificity 0.39024376167696456 recall 0.7400568181818182 f1 0.6738652638997557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 56 - 41.408071756362915 s\n",
      "Accuracy 0.9695110258868648 precision 0.9704406034293362 specificity 0.030488974113135187 recall 0.9695110258868648 f1 0.9545025307923255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 56 - 39.325329065322876 s\n",
      "Accuracy 0.8592493297587132 precision 0.8790600809320847 specificity 0.14075067024128687 recall 0.8592493297587132 f1 0.7942016155376138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 56 - 39.400497913360596 s\n",
      "Accuracy 0.9878339694656488 precision 0.978630547389882 specificity 0.010719201501315216 recall 0.9878339694656488 f1 0.9832107215586334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 56 - 40.35232758522034 s\n",
      "Accuracy 0.8172268907563025 precision 0.8507738538453357 specificity 0.20524501935605705 recall 0.8172268907563025 f1 0.7390915090238722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 56 - 42.075697898864746 s\n",
      "Accuracy 0.6735102653980971 precision 0.780105812198518 specificity 0.32648973460190284 recall 0.6735102653980971 f1 0.542113289623244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 56 - 43.132235288619995 s\n",
      "Accuracy 0.3777301927194861 precision 0.5457609770915073 specificity 0.6122946211762955 recall 0.3777301927194861 f1 0.31682418452241295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 56 - 42.36232876777649 s\n",
      "Accuracy 0.8430365296803652 precision 0.7584002003674649 specificity 0.16093803311772692 recall 0.8430365296803652 f1 0.7749418328706987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 56 - 41.68308115005493 s\n",
      "Accuracy 0.7042454513021762 precision 0.7789690613833058 specificity 0.381037557454179 recall 0.7042454513021762 f1 0.607523439950592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 56 - 42.91150450706482 s\n",
      "Accuracy 0.6963812886142984 precision 0.5421989549341407 specificity 0.2578521961429673 recall 0.6963812886142984 f1 0.6046107108325628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 56 - 42.39992928504944 s\n",
      "Accuracy 0.6089828269484808 precision 0.7962883221443329 specificity 0.17149496394172326 recall 0.6089828269484808 f1 0.6867601231934084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 56 - 43.243372440338135 s\n",
      "Accuracy 0.4803100775193798 precision 0.9547830810149673 specificity 0.9673622167199014 recall 0.4803100775193798 f1 0.6016275916018209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 56 - 43.94424891471863 s\n",
      "Accuracy 0.14436248682824027 precision 0.5914217900989145 specificity 0.8532052787395253 recall 0.14436248682824027 f1 0.03819519178665921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 56 - 40.279645919799805 s\n",
      "Accuracy 0.8886671987230647 precision 0.8566263227390477 specificity 0.09192712023983439 recall 0.8886671987230647 f1 0.8720889702113304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 56 - 42.85426044464111 s\n",
      "Accuracy 0.887481734047735 precision 0.9023153839584318 specificity 0.640060154321096 recall 0.887481734047735 f1 0.8937198697176206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 56 - 42.771228075027466 s\n",
      "Accuracy 0.5564981336952833 precision 0.7519735843149474 specificity 0.5888365280452068 recall 0.5564981336952833 f1 0.4640676557642515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 56 - 42.38055443763733 s\n",
      "Accuracy 0.8526997840172786 precision 0.8570483975780477 specificity 0.18865320952631293 recall 0.8526997840172786 f1 0.7916269609697615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 56 - 42.1991491317749 s\n",
      "Accuracy 0.547683923705722 precision 0.9253358872830247 specificity 0.836430769436456 recall 0.5476839237057219 f1 0.6535745205915569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 56 - 42.31081438064575 s\n",
      "Accuracy 0.9269272926561929 precision 0.90928693493322 specificity 0.13060479776688505 recall 0.9269272926561929 f1 0.9175583276788976\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "36 of 56 - 41.46069145202637 s\n",
      "Accuracy 0.9785714285714285 precision 1.0 specificity 0.0 recall 0.9785714285714285 f1 0.9891696750902528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 56 - 42.61632585525513 s\n",
      "Accuracy 0.7246531483457844 precision 0.8660334725450732 specificity 0.6253748247027914 recall 0.7246531483457844 f1 0.7741913136005674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 56 - 42.92371368408203 s\n",
      "Accuracy 0.09795102448775612 precision 0.8535834483052388 specificity 0.8128320958206228 recall 0.09795102448775612 f1 0.11316923602614017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 56 - 42.26662802696228 s\n",
      "Accuracy 0.8464687819856704 precision 0.8394325230012378 specificity 0.6671095142343356 recall 0.8464687819856704 f1 0.8406966711918081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 56 - 41.764084577560425 s\n",
      "Accuracy 0.9143442622950819 precision 0.9156754393063509 specificity 0.6646851623865166 recall 0.9143442622950819 f1 0.9064595110918813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 56 - 42.03487944602966 s\n",
      "Accuracy 0.36744901885340514 precision 0.7694257536833247 specificity 0.639797357958189 recall 0.36744901885340514 f1 0.2030208288432054\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 56 - 42.965134382247925 s\n",
      "Accuracy 0.9203727234222787 precision 0.9292142065432623 specificity 0.4676734090148373 recall 0.9203727234222787 f1 0.9244610603841282\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 56 - 42.74037027359009 s\n",
      "Accuracy 0.8572136836886465 precision 0.8776016158144123 specificity 0.1427863163113535 recall 0.8572136836886465 f1 0.7913093748519326\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "44 of 56 - 42.27660346031189 s\n",
      "Accuracy 0.9966420416386836 precision 1.0 specificity 0.0 recall 0.9966420416386836 f1 0.998318197107299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 56 - 43.96520638465881 s\n",
      "Accuracy 0.6129577464788732 precision 0.5711627262125154 specificity 0.3999179278083089 recall 0.6129577464788732 f1 0.4886418005623183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 56 - 43.40928101539612 s\n",
      "Accuracy 0.7563150074294205 precision 0.8157562649131711 specificity 0.24773357556653092 recall 0.7563150074294205 f1 0.6523795919241153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 56 - 43.64348483085632 s\n",
      "Accuracy 0.6260504201680672 precision 0.6185291310617074 specificity 0.5774456433321908 recall 0.6260504201680672 f1 0.6180781606322827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 56 - 42.92978119850159 s\n",
      "Accuracy 0.9780821917808219 precision 0.9820653090863936 specificity 0.38303663109535796 recall 0.9780821917808219 f1 0.9799411488080898\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "49 of 56 - 41.12033486366272 s\n",
      "Accuracy 0.9385929239528263 precision 1.0 specificity 0.0 recall 0.9385929239528263 f1 0.9683238934340256\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "50 of 56 - 38.952733755111694 s\n",
      "Accuracy 0.9896694214876033 precision 1.0 specificity 0.0 recall 0.9896694214876033 f1 0.9948078920041538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 56 - 39.4048535823822 s\n",
      "Accuracy 0.15327695560253699 precision 0.7901123604344944 specificity 0.8481264124808632 recall 0.15327695560253699 f1 0.09674407630757127\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "52 of 56 - 41.74369287490845 s\n",
      "Accuracy 0.888268156424581 precision 1.0 specificity 0.0 recall 0.888268156424581 f1 0.9408284023668639\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 56 - 42.90490460395813 s\n",
      "Accuracy 0.8110510046367851 precision 0.8235772927823282 specificity 0.5439369625390053 recall 0.8110510046367851 f1 0.7824818035264719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 56 - 42.36194682121277 s\n",
      "Accuracy 0.8843878015475649 precision 0.8816203279586173 specificity 0.2942011986281512 recall 0.8843878015475649 f1 0.8502942929007798\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 56 - 42.90780425071716 s\n",
      "Accuracy 0.9054373522458629 precision 0.9143794465961359 specificity 0.09456264775413711 recall 0.9054373522458629 f1 0.8605024960550013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 56 - 44.38237810134888 s\n",
      "Accuracy 0.7808425275827482 precision 0.8290902935506772 specificity 0.23933684461456117 recall 0.7808425275827482 f1 0.689152668407614\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "tot = len(patients)\n",
    "for i, patient in enumerate(patients):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    df1 = cvds.loc[cvds[\"patient_id\"] != patient]\n",
    "    df2 = cvds.loc[cvds[\"patient_id\"] == patient]\n",
    "\n",
    "    y_train = df1[\"label\"].values\n",
    "    x_train = df1.loc[:, ~df1.columns.isin(['patient_id', 'label'])]\n",
    "    y_test = df2[\"label\"].values\n",
    "    x_test = df2.loc[:, ~df2.columns.isin(['patient_id', 'label'])]\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, zero_division=1, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(patients), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.819845     0.180155   0.852301  0.819845  0.738684\n1  0.801466     0.198534   0.840882  0.801466  0.713140\n2  0.919043     0.124060   0.884679  0.919043  0.888101\n3  0.866527     0.133473   0.884342  0.866527  0.804563\n4  1.000000     0.000000   1.000000  1.000000  1.000000\n5  0.994274     0.000000   1.000000  0.994274  0.997129\n6  0.725787     0.318657   0.801951  0.725787  0.622461\n7  0.767305     0.354210   0.781273  0.767305  0.697699\n8  0.752588     0.783380   0.984078  0.752588  0.847211\n9  0.650878     0.349122   0.772764  0.650878  0.513232",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.819845</td>\n      <td>0.180155</td>\n      <td>0.852301</td>\n      <td>0.819845</td>\n      <td>0.738684</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.801466</td>\n      <td>0.198534</td>\n      <td>0.840882</td>\n      <td>0.801466</td>\n      <td>0.713140</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.919043</td>\n      <td>0.124060</td>\n      <td>0.884679</td>\n      <td>0.919043</td>\n      <td>0.888101</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.866527</td>\n      <td>0.133473</td>\n      <td>0.884342</td>\n      <td>0.866527</td>\n      <td>0.804563</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.994274</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.994274</td>\n      <td>0.997129</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.725787</td>\n      <td>0.318657</td>\n      <td>0.801951</td>\n      <td>0.725787</td>\n      <td>0.622461</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.767305</td>\n      <td>0.354210</td>\n      <td>0.781273</td>\n      <td>0.767305</td>\n      <td>0.697699</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.752588</td>\n      <td>0.783380</td>\n      <td>0.984078</td>\n      <td>0.752588</td>\n      <td>0.847211</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.650878</td>\n      <td>0.349122</td>\n      <td>0.772764</td>\n      <td>0.650878</td>\n      <td>0.513232</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.7631061341734374\n",
      "Precision 0.8456782577568969\n",
      "Specificity 0.3308757735557233\n",
      "Recall 0.7631061341734374\n",
      "F1 0.7279326203673062\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_4beats_l1so.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}