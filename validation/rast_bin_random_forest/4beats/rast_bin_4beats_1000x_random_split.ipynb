{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 4 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3      dw_4      dw_5     mfw_1  \\\n0  e0106  13.102095  13.097001  13.072790  3.706391  0.542614  1.240982   \n1  e0106  17.487040  17.476616  17.514101  4.949534  0.713287  1.208352   \n2  e0106  17.765692  18.767421  18.563219  5.234889  0.756572  1.239086   \n3  e0106  17.472889  18.368493  18.044299  5.083577  0.745658  1.200223   \n4  e0106  16.631755  17.107590  16.986173  4.785861  0.705577  1.207803   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.895934 -2.712703 -2.663057  ... -0.069056  0.062074 -0.071315  0.072003   \n1 -0.835234 -1.803925 -2.177733  ... -0.033026  0.017482 -0.014863  0.016572   \n2 -0.727071 -1.738814 -2.078783  ... -0.036041  0.011065 -0.006174  0.017821   \n3 -0.800412 -1.813089 -2.117043  ... -0.013610 -0.003827 -0.018916  0.046067   \n4 -0.814830 -1.677964 -1.684348  ... -0.050212  0.021235 -0.011183  0.030903   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.085813  0.018093 -0.024765 -0.023205  0.019933    NSR  \n1 -0.072260  0.024719 -0.037654 -0.001608 -0.009617    NSR  \n2 -0.030732 -0.027515 -0.018567  0.002476 -0.011823    NSR  \n3 -0.068930  0.005377 -0.029879  0.006491 -0.021803    NSR  \n4 -0.061186 -0.018751  0.003333 -0.020661  0.007397    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>13.102095</td>\n      <td>13.097001</td>\n      <td>13.072790</td>\n      <td>3.706391</td>\n      <td>0.542614</td>\n      <td>1.240982</td>\n      <td>-0.895934</td>\n      <td>-2.712703</td>\n      <td>-2.663057</td>\n      <td>...</td>\n      <td>-0.069056</td>\n      <td>0.062074</td>\n      <td>-0.071315</td>\n      <td>0.072003</td>\n      <td>-0.085813</td>\n      <td>0.018093</td>\n      <td>-0.024765</td>\n      <td>-0.023205</td>\n      <td>0.019933</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>17.487040</td>\n      <td>17.476616</td>\n      <td>17.514101</td>\n      <td>4.949534</td>\n      <td>0.713287</td>\n      <td>1.208352</td>\n      <td>-0.835234</td>\n      <td>-1.803925</td>\n      <td>-2.177733</td>\n      <td>...</td>\n      <td>-0.033026</td>\n      <td>0.017482</td>\n      <td>-0.014863</td>\n      <td>0.016572</td>\n      <td>-0.072260</td>\n      <td>0.024719</td>\n      <td>-0.037654</td>\n      <td>-0.001608</td>\n      <td>-0.009617</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>17.765692</td>\n      <td>18.767421</td>\n      <td>18.563219</td>\n      <td>5.234889</td>\n      <td>0.756572</td>\n      <td>1.239086</td>\n      <td>-0.727071</td>\n      <td>-1.738814</td>\n      <td>-2.078783</td>\n      <td>...</td>\n      <td>-0.036041</td>\n      <td>0.011065</td>\n      <td>-0.006174</td>\n      <td>0.017821</td>\n      <td>-0.030732</td>\n      <td>-0.027515</td>\n      <td>-0.018567</td>\n      <td>0.002476</td>\n      <td>-0.011823</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>17.472889</td>\n      <td>18.368493</td>\n      <td>18.044299</td>\n      <td>5.083577</td>\n      <td>0.745658</td>\n      <td>1.200223</td>\n      <td>-0.800412</td>\n      <td>-1.813089</td>\n      <td>-2.117043</td>\n      <td>...</td>\n      <td>-0.013610</td>\n      <td>-0.003827</td>\n      <td>-0.018916</td>\n      <td>0.046067</td>\n      <td>-0.068930</td>\n      <td>0.005377</td>\n      <td>-0.029879</td>\n      <td>0.006491</td>\n      <td>-0.021803</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>16.631755</td>\n      <td>17.107590</td>\n      <td>16.986173</td>\n      <td>4.785861</td>\n      <td>0.705577</td>\n      <td>1.207803</td>\n      <td>-0.814830</td>\n      <td>-1.677964</td>\n      <td>-1.684348</td>\n      <td>...</td>\n      <td>-0.050212</td>\n      <td>0.021235</td>\n      <td>-0.011183</td>\n      <td>0.030903</td>\n      <td>-0.061186</td>\n      <td>-0.018751</td>\n      <td>0.003333</td>\n      <td>-0.020661</td>\n      <td>0.007397</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_4beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    104876\nST      31872\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.312273  0.162467  0.110289  0.114818  0.091114 -0.029557   \ndw_2    0.312273  1.000000  0.840060  0.440370  0.158646  0.415202 -0.437598   \ndw_3    0.162467  0.840060  1.000000  0.613108  0.233954  0.305744 -0.499972   \ndw_4    0.110289  0.440370  0.613108  1.000000  0.900298  0.029004 -0.221348   \ndw_5    0.114818  0.158646  0.233954  0.900298  1.000000 -0.093747 -0.013018   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.023458  0.025353  0.034627  0.031590  0.013505 -0.078775  0.021517   \ncfr_13 -0.014237  0.101591  0.045318  0.027101  0.011685  0.077259  0.004550   \ncfr_14 -0.036773 -0.013728 -0.033912 -0.027459 -0.024332  0.014857  0.010542   \ncfr_15 -0.059384 -0.121356 -0.133216 -0.083792 -0.037581  0.017184  0.080945   \ncfr_16 -0.038783 -0.078300 -0.044818 -0.027346 -0.015057  0.072144 -0.034046   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.006399 -0.000875  0.001703  ... -0.042191 -0.050062 -0.008514   \ndw_2   -0.206089 -0.003727  0.005025  ... -0.143619  0.102186  0.218697   \ndw_3   -0.269989 -0.004282  0.002581  ... -0.201584  0.090697  0.252037   \ndw_4   -0.125818 -0.001509  0.000622  ... -0.139370  0.027890  0.115591   \ndw_5   -0.014289  0.000039 -0.000191  ... -0.065101 -0.007436  0.022364   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.061659  0.000381  0.003797  ... -0.114312 -0.205332 -0.130827   \ncfr_13  0.003053 -0.000895  0.001937  ...  0.110173  0.020152 -0.217039   \ncfr_14  0.014576 -0.000553  0.000869  ...  0.077729  0.198416  0.039598   \ncfr_15  0.046306  0.003503 -0.004316  ...  0.231845  0.160889 -0.064172   \ncfr_16 -0.000916  0.006364 -0.004502  ...  0.210860  0.141500  0.156332   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1    0.005894  0.015042 -0.023458 -0.014237 -0.036773 -0.059384 -0.038783  \ndw_2    0.162054  0.045198  0.025353  0.101591 -0.013728 -0.121356 -0.078300  \ndw_3    0.115305 -0.043451  0.034627  0.045318 -0.033912 -0.133216 -0.044818  \ndw_4    0.036784 -0.040897  0.031590  0.027101 -0.027459 -0.083792 -0.027346  \ndw_5    0.006044 -0.015060  0.013505  0.011685 -0.024332 -0.037581 -0.015057  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12 -0.012334  0.047726  1.000000 -0.024143 -0.054066 -0.277308 -0.170496  \ncfr_13 -0.265132 -0.093551 -0.024143  1.000000  0.126068  0.040084 -0.170708  \ncfr_14 -0.185391 -0.289586 -0.054066  0.126068  1.000000  0.090389 -0.160650  \ncfr_15 -0.148376 -0.122505 -0.277308  0.040084  0.090389  1.000000  0.127273  \ncfr_16  0.069737 -0.016755 -0.170496 -0.170708 -0.160650  0.127273  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.312273</td>\n      <td>0.162467</td>\n      <td>0.110289</td>\n      <td>0.114818</td>\n      <td>0.091114</td>\n      <td>-0.029557</td>\n      <td>0.006399</td>\n      <td>-0.000875</td>\n      <td>0.001703</td>\n      <td>...</td>\n      <td>-0.042191</td>\n      <td>-0.050062</td>\n      <td>-0.008514</td>\n      <td>0.005894</td>\n      <td>0.015042</td>\n      <td>-0.023458</td>\n      <td>-0.014237</td>\n      <td>-0.036773</td>\n      <td>-0.059384</td>\n      <td>-0.038783</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.312273</td>\n      <td>1.000000</td>\n      <td>0.840060</td>\n      <td>0.440370</td>\n      <td>0.158646</td>\n      <td>0.415202</td>\n      <td>-0.437598</td>\n      <td>-0.206089</td>\n      <td>-0.003727</td>\n      <td>0.005025</td>\n      <td>...</td>\n      <td>-0.143619</td>\n      <td>0.102186</td>\n      <td>0.218697</td>\n      <td>0.162054</td>\n      <td>0.045198</td>\n      <td>0.025353</td>\n      <td>0.101591</td>\n      <td>-0.013728</td>\n      <td>-0.121356</td>\n      <td>-0.078300</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.162467</td>\n      <td>0.840060</td>\n      <td>1.000000</td>\n      <td>0.613108</td>\n      <td>0.233954</td>\n      <td>0.305744</td>\n      <td>-0.499972</td>\n      <td>-0.269989</td>\n      <td>-0.004282</td>\n      <td>0.002581</td>\n      <td>...</td>\n      <td>-0.201584</td>\n      <td>0.090697</td>\n      <td>0.252037</td>\n      <td>0.115305</td>\n      <td>-0.043451</td>\n      <td>0.034627</td>\n      <td>0.045318</td>\n      <td>-0.033912</td>\n      <td>-0.133216</td>\n      <td>-0.044818</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.110289</td>\n      <td>0.440370</td>\n      <td>0.613108</td>\n      <td>1.000000</td>\n      <td>0.900298</td>\n      <td>0.029004</td>\n      <td>-0.221348</td>\n      <td>-0.125818</td>\n      <td>-0.001509</td>\n      <td>0.000622</td>\n      <td>...</td>\n      <td>-0.139370</td>\n      <td>0.027890</td>\n      <td>0.115591</td>\n      <td>0.036784</td>\n      <td>-0.040897</td>\n      <td>0.031590</td>\n      <td>0.027101</td>\n      <td>-0.027459</td>\n      <td>-0.083792</td>\n      <td>-0.027346</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.114818</td>\n      <td>0.158646</td>\n      <td>0.233954</td>\n      <td>0.900298</td>\n      <td>1.000000</td>\n      <td>-0.093747</td>\n      <td>-0.013018</td>\n      <td>-0.014289</td>\n      <td>0.000039</td>\n      <td>-0.000191</td>\n      <td>...</td>\n      <td>-0.065101</td>\n      <td>-0.007436</td>\n      <td>0.022364</td>\n      <td>0.006044</td>\n      <td>-0.015060</td>\n      <td>0.013505</td>\n      <td>0.011685</td>\n      <td>-0.024332</td>\n      <td>-0.037581</td>\n      <td>-0.015057</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.023458</td>\n      <td>0.025353</td>\n      <td>0.034627</td>\n      <td>0.031590</td>\n      <td>0.013505</td>\n      <td>-0.078775</td>\n      <td>0.021517</td>\n      <td>0.061659</td>\n      <td>0.000381</td>\n      <td>0.003797</td>\n      <td>...</td>\n      <td>-0.114312</td>\n      <td>-0.205332</td>\n      <td>-0.130827</td>\n      <td>-0.012334</td>\n      <td>0.047726</td>\n      <td>1.000000</td>\n      <td>-0.024143</td>\n      <td>-0.054066</td>\n      <td>-0.277308</td>\n      <td>-0.170496</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.014237</td>\n      <td>0.101591</td>\n      <td>0.045318</td>\n      <td>0.027101</td>\n      <td>0.011685</td>\n      <td>0.077259</td>\n      <td>0.004550</td>\n      <td>0.003053</td>\n      <td>-0.000895</td>\n      <td>0.001937</td>\n      <td>...</td>\n      <td>0.110173</td>\n      <td>0.020152</td>\n      <td>-0.217039</td>\n      <td>-0.265132</td>\n      <td>-0.093551</td>\n      <td>-0.024143</td>\n      <td>1.000000</td>\n      <td>0.126068</td>\n      <td>0.040084</td>\n      <td>-0.170708</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.036773</td>\n      <td>-0.013728</td>\n      <td>-0.033912</td>\n      <td>-0.027459</td>\n      <td>-0.024332</td>\n      <td>0.014857</td>\n      <td>0.010542</td>\n      <td>0.014576</td>\n      <td>-0.000553</td>\n      <td>0.000869</td>\n      <td>...</td>\n      <td>0.077729</td>\n      <td>0.198416</td>\n      <td>0.039598</td>\n      <td>-0.185391</td>\n      <td>-0.289586</td>\n      <td>-0.054066</td>\n      <td>0.126068</td>\n      <td>1.000000</td>\n      <td>0.090389</td>\n      <td>-0.160650</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.059384</td>\n      <td>-0.121356</td>\n      <td>-0.133216</td>\n      <td>-0.083792</td>\n      <td>-0.037581</td>\n      <td>0.017184</td>\n      <td>0.080945</td>\n      <td>0.046306</td>\n      <td>0.003503</td>\n      <td>-0.004316</td>\n      <td>...</td>\n      <td>0.231845</td>\n      <td>0.160889</td>\n      <td>-0.064172</td>\n      <td>-0.148376</td>\n      <td>-0.122505</td>\n      <td>-0.277308</td>\n      <td>0.040084</td>\n      <td>0.090389</td>\n      <td>1.000000</td>\n      <td>0.127273</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.038783</td>\n      <td>-0.078300</td>\n      <td>-0.044818</td>\n      <td>-0.027346</td>\n      <td>-0.015057</td>\n      <td>0.072144</td>\n      <td>-0.034046</td>\n      <td>-0.000916</td>\n      <td>0.006364</td>\n      <td>-0.004502</td>\n      <td>...</td>\n      <td>0.210860</td>\n      <td>0.141500</td>\n      <td>0.156332</td>\n      <td>0.069737</td>\n      <td>-0.016755</td>\n      <td>-0.170496</td>\n      <td>-0.170708</td>\n      <td>-0.160650</td>\n      <td>0.127273</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows Ã— 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_255', 'fft_170', 'fft_189', 'fft_200', 'fft_205', 'fft_245', 'fft_222', 'fft_149', 'fft_176', 'fft_231', 'fft_133', 'fft_132', 'fft_193', 'fft_156', 'fft_196', 'mfw_16', 'fft_219', 'fft_148', 'fft_213', 'fft_150', 'fft_254', 'fft_131', 'fft_230', 'fft_151', 'fft_177', 'fft_198', 'fft_240', 'fft_201', 'mfw_10', 'fft_183', 'fft_153', 'fft_187', 'fft_203', 'fft_186', 'fft_165', 'fft_135', 'fft_229', 'fft_181', 'fft_168', 'mfw_15', 'fft_251', 'fft_243', 'fft_155', 'fft_220', 'fft_241', 'fft_235', 'fft_228', 'fft_232', 'fft_253', 'fft_144', 'fft_244', 'fft_140', 'fft_161', 'fft_194', 'fft_184', 'fft_174', 'fft_224', 'fft_143', 'fft_185', 'fft_173', 'fft_246', 'fft_233', 'mfw_11', 'fft_250', 'fft_134', 'fft_141', 'fft_204', 'fft_239', 'fft_178', 'fft_130', 'fft_146', 'fft_163', 'fft_238', 'fft_162', 'fft_248', 'mfw_14', 'fft_160', 'fft_209', 'fft_214', 'fft_154', 'fft_166', 'fft_223', 'mfw_5', 'mfw_6', 'fft_171', 'fft_218', 'mfw_13', 'fft_137', 'fft_211', 'fft_242', 'fft_226', 'fft_234', 'fft_206', 'fft_247', 'fft_164', 'fft_225', 'fft_188', 'fft_236', 'fft_136', 'fft_175', 'fft_217', 'mfw_7', 'fft_182', 'fft_147', 'fft_139', 'fft_142', 'fft_145', 'fft_227', 'fft_179', 'fft_212', 'fft_215', 'cfr_16', 'fft_210', 'fft_207', 'fft_157', 'fft_191', 'mfw_8', 'fft_195', 'fft_256', 'fft_152', 'fft_208', 'fft_221', 'fft_169', 'fft_197', 'fft_180', 'fft_237', 'fft_158', 'fft_159', 'fft_216', 'mfw_12', 'mfw_9', 'fft_172', 'fft_192', 'fft_138', 'fft_167', 'fft_190', 'fft_249', 'fft_252', 'fft_202', 'fft_199'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_24\n",
      "fft_25\n",
      "fft_26\n",
      "fft_27\n",
      "fft_28\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "fft_37\n",
      "fft_38\n",
      "fft_39\n",
      "fft_40\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 76\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYeUlEQVR4nO3de7RedX3n8ffHhJvKZRZkRgvEgGC7AK9EbOul3nCwVoIVFGoVXVRsNVXH0RG1RUSnA7Xq0gGXUqEiWkFBbNS4KIIC3jABIhgwNWAsQTpyGyRqgMB3/tj7jA+HfZKdc85znpPk/VrrrOzLb+/9fZ5z8nyeffvtVBWSJI33iFEXIEmanQwISVInA0KS1MmAkCR1MiAkSZ3mjrqA6bLHHnvUggULRl2GJG1Rrrrqqtural7XvK0mIBYsWMDy5ctHXYYkbVGS/GyieR5ikiR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHXaau6knqoFJ3xtZNtec8pLRrZtSZqIexCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqNNSASHJYklVJVic5oWP+DknOa+dfmWRBO31Bkt8kWdH+fGKYdUqSHm7usFacZA5wOnAosBZYlmRJVV0/0Ow44K6q2i/J0cCpwCvbeTdW1VOGVZ8kaeOGuQdxCLC6qm6qqvuAc4FF49osAs5uh88HXpAkQ6xJktTTMANiT+DmgfG17bTONlW1Abgb2L2dt0+Sa5JcluTZXRtIcnyS5UmW33bbbdNbvSRt42brSepbgflV9VTgbcA/J9llfKOqOqOqFlbVwnnz5s14kZK0NRtmQNwC7D0wvlc7rbNNkrnArsAdVXVvVd0BUFVXATcCTxhirZKkcYYZEMuA/ZPsk2R74Ghgybg2S4Bj2+EjgUurqpLMa09yk2RfYH/gpiHWKkkaZ2hXMVXVhiSLgYuAOcBZVbUyycnA8qpaApwJnJNkNXAnTYgAPAc4Ocn9wIPAX1bVncOqVZL0cEMLCICqWgosHTftxIHh9cBRHctdAFwwzNokSRs3W09SS5JGzICQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJnYYaEEkOS7IqyeokJ3TM3yHJee38K5MsGDd/fpJ1Sd4+zDolSQ83tIBIMgc4HXgxcABwTJIDxjU7DrirqvYDPgKcOm7+h4GvD6tGSdLEhrkHcQiwuqpuqqr7gHOBRePaLALObofPB16QJABJjgB+CqwcYo2SpAnMnWhGknuAGhtt/612uKpql02se0/g5oHxtcAzJmpTVRuS3A3snmQ98E7gUMDDS5I0AhMGRFXtPJOFjHMS8JGqWtfuUHRKcjxwPMD8+fNnpjJJ2kb0OsSU5FlJXtcO75Fknx6L3QLsPTC+Vzuts02SucCuwB00exp/n2QN8Fbg3UkWj99AVZ1RVQurauG8efP6vBRJUk8T7kGMSfJeYCHwu8A/AdsDnwWeuYlFlwH7t2FyC3A08Gfj2iwBjgW+BxwJXFpVBTx7YPsnAeuq6rQer2ertOCEr41s22tOecnIti1ptDYZEMDLgKcCVwNU1c+TbPLwU3tOYTFwETAHOKuqViY5GVheVUuAM4FzkqwG7qQJEUnSLNAnIO6rqkpSAEke1XflVbUUWDpu2okDw+uBozaxjpP6bk+SNH36nIP4QpJPArsleT3wDeAfh1uWJGnUNrkHUVX/kORQ4Jc05yFOrKqLh16ZJGmk+pykfhtwnqEgSduWPoeYdgb+NckVSRYn+S/DLkqSNHqbDIiqel9VHQi8CXgscFmSbwy9MknSSG1OX0y/AP6D5ka2/zycciRJs8UmAyLJG5N8C7gE2B14fVU9adiFSZJGq899EHsDb62qFUOuRZI0i/Q5B/Eu4NEDfTHN69kXkyRpC9bnENN7abreflc7aTuavpgkSVuxPiepXwYcDvwKmr6YaC59lSRtxfoExH1tD6ub3ReTJGnLZV9MkqRO9sUkSerU5zJX2kAwFCRpGzJhQCS5h/a8w/hZQFXVLkOrSpI0chMGRFV5pZIkbcM2py8mSdI2xICQJHUyICRJnXoFRJLHJXlhO7xTEs9PSNJWrk9fTK8Hzgc+2U7aC/jyEGuSJM0CffYg3gQ8k+ZGOarqJ/jAIEna6vUJiHur6r6xkSRz6b4/QpK0FekTEJcleTewU9vlxheBrwy3LEnSqPUJiBOA24DrgDcAS4G/GWZRkqTR69MX007AWVX1jwBJ5rTTfj3MwiRJo9VnD+ISmkAYsxNNl9+SpK1Yn4DYsarWjY20w4/ss/IkhyVZlWR1khM65u+Q5Lx2/pVJFrTTD0myov35YZKX9Xw9kqRp0icgfpXkaWMjSQ4GfrOphdpDUacDLwYOAI5JcsC4ZscBd1XVfsBHgFPb6T8CFlbVU4DDgE+2V09JkmZInw/dtwJfTPJzmq6+HwO8ssdyhwCrq+omgCTnAouA6wfaLAJOaofPB05LkqoaPL+xI15WK0kzrs8T5ZYl+T2ap8kBrKqq+3use0/g5oHxtcAzJmpTVRuS3A3sDtye5BnAWcDjgFdX1YbxG0hyPHA8wPz583uUJEnqq29nfU8HngQ8jeZQ0WuGV1Kjqq6sqgPbbb8ryY4dbc6oqoVVtXDevHnDLkmStimb3INIcg7weGAF8EA7uYDPbGLRW4C9B8b3aqd1tVnbnmPYFbhjsEFV3ZBkHXAQsHxT9UqSpkefcxALgQOqanPPAywD9k+yD00QHA382bg2S4Bjge8BRwKXVlW1y9zcHnZ6HPB7wJrN3L4kaQr6BMSPaE5M37o5K24/3BcDFwFzaG62W5nkZGB5VS0BzgTOSbIauJMmRACeBZyQ5H7gQeCNVXX75mxfkjQ1fQJiD+D6JD8A7h2bWFWHb2rBqlpK0zXH4LQTB4bXA0d1LHcOcE6P2iRJQ9InIE4adhHaci044Wsj2/aaU14ysm1L24I+l7leNhOFSJJmlz5PlPv9JMuSrEtyX5IHkvxyJoqTJI1On/sgTgOOAX5C01HfX9B0oSFJ2or1ulGuqlYDc6rqgar6J5r+kSRJW7E+J6l/nWR7YEWSv6e53LXvHdiSpC1Unw/6V7ftFgO/ornz+U+HWZQkafT6BMQRVbW+qn5ZVe+rqrcBfzLswiRJo9UnII7tmPbaaa5DkjTLTHgOIskxNH0n7ZtkycCsnWm6xZAkbcU2dpL6uzQnpPcAPjQw/R7g2mEWJUkavQkDoqp+lmQtsN67qSVp27PRcxBV9QDwYJJdZ6geSdIs0ec+iHXAdUkuprnMFYCqevPQqpIkjVyfgPhS+yNJ2ob06c317PZO6ie0k1ZV1f3DLUuSNGp9nkn9XOBsmkd+Btg7ybFVdflQK5MkjVSfQ0wfAl5UVasAkjwB+Dxw8DALkySNVp87qbcbCweAqvo3YLvhlSRJmg367EEsT/Ip4LPt+KuA5cMrSZoePg5Vmpo+AfFXwJuAsctarwA+PrSKJEmzQp+rmO5NchpwCfAgzVVM9w29MknSSPW5iuklwCeAG2muYtonyRuq6uvDLk6SNDp9r2J6XvvYUZI8HvgaYEBI0lasz1VM94yFQ+smmh5dJUlbsb5XMS0FvgAUcBSwLMmfAlSV3XBI0laoT0DsCPwf4I/a8duAnYCX0gSGASFJW6E+VzG9biYKkbYl3qOhLUGfq5j2Af4aWDDYvqoO77HsYcBHgTnAp6rqlHHzdwA+Q9Ntxx3AK6tqTZJDgVOA7YH7gHdU1aU9X5OkKTC8NKbPIaYvA2cCX6G5D6KXJHOA04FDgbU05y2WVNX1A82OA+6qqv2SHA2cCrwSuB14aVX9PMlBwEXAnn23LWnrZHjNrD4Bsb6qPjaJdR8CrK6qmwCSnAssAgYDYhFwUjt8PnBaklTVNQNtVgI7Jdmhqu6dRB2SpEnoExAfTfJe4F+B//8BXVVXb2K5PYGbB8bXAs+YqE1VbUhyN7A7zR7EmJcDV3eFQ5LjgeMB5s+f3+OlSJL66hMQTwReDTyf3x5iqnZ8qJIcSHPY6UVd86vqDOAMgIULF9aw65GkiWyNh7/6BMRRwL6T6H/pFmDvgfG92mldbdYmmQvsSnOymiR7ARcCr6mqGzdz25KkKepzJ/WPgN0mse5lwP5J9mkfWXo0sGRcmyXAse3wkcClVVVJdqPpzuOEqvrOJLYtSZqiPnsQuwE/TrKMh56D2Ohlru05hcU0VyDNAc6qqpVJTgaWV9USmqujzkmyGriTJkQAFgP7AScmObGd9qKq+kX/lyZJmoo+AfHeya68qpYCS8dNO3FgeD3NIazxy30A+MBktytJmro+d1JfNhOFSJJmlwkDIsk9NFcrPWwWUFW1y9CqkiSN3IQBUVU7z2QhkqTZpc9VTJKkbZABIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqdNQAyLJYUlWJVmd5ISO+TskOa+df2WSBe303ZN8M8m6JKcNs0ZJUrehBUSSOcDpwIuBA4BjkhwwrtlxwF1VtR/wEeDUdvp64G+Btw+rPknSxg1zD+IQYHVV3VRV9wHnAovGtVkEnN0Onw+8IEmq6ldV9W2aoJAkjcAwA2JP4OaB8bXttM42VbUBuBvYve8GkhyfZHmS5bfddtsUy5UkDdqiT1JX1RlVtbCqFs6bN2/U5UjSVmWYAXELsPfA+F7ttM42SeYCuwJ3DLEmSVJPwwyIZcD+SfZJsj1wNLBkXJslwLHt8JHApVVVQ6xJktTT3GGtuKo2JFkMXATMAc6qqpVJTgaWV9US4EzgnCSrgTtpQgSAJGuAXYDtkxwBvKiqrh9WvZKkhxpaQABU1VJg6bhpJw4MrweOmmDZBcOsTZK0cVv0SWpJ0vAYEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6jTUgEhyWJJVSVYnOaFj/g5JzmvnX5lkwcC8d7XTVyX5r8OsU5L0cEMLiCRzgNOBFwMHAMckOWBcs+OAu6pqP+AjwKntsgcARwMHAocBH2/XJ0maIcPcgzgEWF1VN1XVfcC5wKJxbRYBZ7fD5wMvSJJ2+rlVdW9V/RRY3a5PkjRD5g5x3XsCNw+MrwWeMVGbqtqQ5G5g93b698ctu+f4DSQ5Hji+HV2XZNX0lL7Z9gBun+zCOXUaK3k4a5sca5sca5ucUdb2uIlmDDMghq6qzgDOGHUdSZZX1cJR19HF2ibH2ibH2iZnttY2zENMtwB7D4zv1U7rbJNkLrArcEfPZSVJQzTMgFgG7J9knyTb05x0XjKuzRLg2Hb4SODSqqp2+tHtVU77APsDPxhirZKkcYZ2iKk9p7AYuAiYA5xVVSuTnAwsr6olwJnAOUlWA3fShAhtuy8A1wMbgDdV1QPDqnUajPww10ZY2+RY2+RY2+TMytrSfGGXJOmhvJNaktTJgJAkdTIgJEmdDIiNSPLmJDck+XySbyRZkeSVSd69ieV2TPKDJD9MsjLJ+2ag1h0Ga5ziuj6WZN0Ulp/s+7Z3km8mub59394y2Rqmu7aB5eckuSbJV6e7toFtnJTk7VNcx8uTVJJpvbZ+KrUleW2S29r3fEWSv5hFtT0nydVJNiQ5cjrrmqo0RvJZvUXfKDcD3gi8kOY+jA9U1VMA2g/Pv9vIcvcCz6+qdUm2A76d5OtV9f2NLDNVTwUYq3Gy2g+U/zTFWib7vm0A/ntVXZ1kZ+CqJBdX1fVTrGc6ahvzFuAGYJdprGlate/dW4ArR11Lh/OqavGoi+jw78BrgSkF88YkOQW4uapOb8dPovmbfx7N/7ntgL+pqn9pOy69iOZ3eDDwx8DPhlXbRNyDmECSTwD7AhcD3wGe3n7r+SKwUzv8ua5lqzH2DXy79mfSl4slWZDkx0k+neTfknwuyQuTfCfJT5IcAnx2oMZ3Jvlwu+xbktzUDu+b5Dsb2c4c4IPA/5hCrVN5326tqqvb4XtoPogf1sXKKGprl98LeAnwqemqaWDd72l/t98Gfhd4RJKr2nlPbvcG5rfjNyZ55EZW936aji/Xz8LaptV01VZVa6rqWuDBIZZ7HvCKgfFX0PRF97KqehpNUHwoSdr5+wMfr6oDq2rGwwGAqvJngh9gDU0fKc8FvjowfV2PZecAK4B1wKlTrGMBzTeNJ9KE+lXAWcBYx4ZfHqwReAywrB0+n+amxT1pbkr8XxvZzluA/9b3NQ7jfRv3mv8d2GUW/U7Pp/k295Blp6Gmg4HrgEfS7Jmspvkmu7IdX9z+Dl9F02/O9zayrqcBF7TD3wIWzqLaXgvcClzbvpd7z5baBtb5aeDI6fybG7f+G4DfAZ5M8yVlO+C09j1ZAfym/f+7APjpsOro++MhpiGp5sa+pyTZDbgwyUFV9aMprPKnVXUdQJKVwCVVVUmuo/ljGtz2fyR5dHuoYW/gn4HnAM8GvtS18iS/AxxF8+E3UkkeDVwAvLWqfjnqegCS/Anwi6q6Kslzp3n1zwYurKpft9sa63Hgu8AzaX53f0fT9X2AKyao8RHAh2k+iGdVba2vAJ+vqnuTvIHm2/PzZ0ltM+WLNL1GPIZmj+JVwDzg4Kq6P8kaYMe27a9GUuEADzENWVX9X+CbNH+kU3HvwPCDA+MP0n0u6bvA64BVNP8xng38Ac23li5PBfYDVrd/pI9Mc4f7jGrP2VwAfK6qOsNsRJ4JHN6+N+cCz0/y2SFv83Ka39vjgH+h+db5LCb+oNsZOAj4Vlvn7wNLpvtE9SRro6ruqKqxv9tP0ewBDMNm1zaDzqPpMeJImrDYleaLx/1JnsdGelYdBQNicu5vP8g6JZnX7jmQZCfgUODHM1TbmCtodrcvB66hOb55b1Xd3dW4qr5WVY+pqgVVtQD4dTUPcppOm3rfQtP9yg1V9eFp3vambLS2qnpXVe3VvjdH0/Qb9ufTtO3LgSOS7NTu9b20nX4F8OfAT6rqQZruaP4Y+PYENd5dVXsM/A6/DxxeVctHXRtAkscOjB5Oc7hlKqattplSVStpgvyWqroV+BywsD0S8Bpm/nNiozzENDlnANcmubqqXtUx/7HA2e1J30cAX6iqoV0WOYEraA4vXV5VDyS5mdH/8W3qfXsm8GrguiQr2mnvrqqls6C2oanmqq3zgB8Cv6A5bk5VrWlD8/K26beBvarqri20tjcnOZzmfNqdTPFQ2HTWluTpwIU0VxO9NMn7qurAqdS3kbqfODB8O82efZeDhrH9zWFfTJKkTh5ikiR18hDTFCTZHbikY9YLquqOma6nryQXAvuMm/zOqrpohrY/a9+32VzboCTvobnqbNAXq+p/jqKeQda29fAQkySpk4eYJEmdDAhJUicDQhonyQP5bY+jK9J0nLa56zgiyQFDKE+aMZ6klh7uNzXFXnGBI4Cv0jxXvZckc6tqwxS3K00b9yCkHpIcnOSyJFcluWjsruAkr0+yLM2zPy5I8sgkf0hzp/AH2z2Qxyf51liXF0n2aLvCGHtGwpIklwKXJHlUkrPSPE/kmiSL2nYHttNWJLk2yf6jeSe0LTEgpIcb6/p7RZIL2y44/jdNL58H0/SkO3ZZ5Jeq6ulV9WSariOOq6rvAkuAd1TVU6rqxk1s72ntuv8IeA9NNx6H0HSP8sEkjwL+Evhou2ezEFg7vS9ZejgPMUkP95BDTEkOoun24OK2q/45NN1WAxyU5APAbsCjaR7ysrkurqo72+EX0XQKOPbgmh2B+cD3gPekeSbFl6rqJ5PYjrRZDAhp0wKsrKquPnM+DRxRVT9M8lom7i59A7/dY99x3LzBbp0DvLyqVo1rc0OSK2keWLQ0yRuq6tL+L0HafB5ikjZtFTAvyR9A0yV5krGO3HYGbm0PQw128ndPO2/MGn7bvfXGnnl8EfDXY08VS/LU9t99gZuq6mM0XVg/aUqvSOrBgJA2oaruo/lQPzXJD2me/PWH7ey/pXlu8Hd4aG+55wLvaE80Px74B+CvklxD80S7ibyf5ilj16Z5MNT72+mvAH7U9nJ7EPCZaXhp0kbZ1YYkqZN7EJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSer0/wAcsQG3cwdxVQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\n0  13.102095  13.097001  13.072790  3.706391  0.542614  1.240982 -0.895934   \n1  17.487040  17.476616  17.514101  4.949534  0.713287  1.208352 -0.835234   \n2  17.765692  18.767421  18.563219  5.234889  0.756572  1.239086 -0.727071   \n3  17.472889  18.368493  18.044299  5.083577  0.745658  1.200223 -0.800412   \n4  16.631755  17.107590  16.986173  4.785861  0.705577  1.207803 -0.814830   \n\n      mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -2.712703 -2.663057  0.294201  ... -0.013426  0.064171 -0.069056  0.062074   \n1 -1.803925 -2.177733 -1.533708  ...  0.016671  0.036579 -0.033026  0.017482   \n2 -1.738814 -2.078783 -0.720965  ...  0.020868  0.035213 -0.036041  0.011065   \n3 -1.813089 -2.117043  0.838703  ...  0.026449  0.028665 -0.013610 -0.003827   \n4 -1.677964 -1.684348 -0.600837  ... -0.015116  0.060441 -0.050212  0.021235   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.071315  0.072003 -0.085813  0.018093 -0.024765 -0.023205  \n1 -0.014863  0.016572 -0.072260  0.024719 -0.037654 -0.001608  \n2 -0.006174  0.017821 -0.030732 -0.027515 -0.018567  0.002476  \n3 -0.018916  0.046067 -0.068930  0.005377 -0.029879  0.006491  \n4 -0.011183  0.030903 -0.061186 -0.018751  0.003333 -0.020661  \n\n[5 rows x 76 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.102095</td>\n      <td>13.097001</td>\n      <td>13.072790</td>\n      <td>3.706391</td>\n      <td>0.542614</td>\n      <td>1.240982</td>\n      <td>-0.895934</td>\n      <td>-2.712703</td>\n      <td>-2.663057</td>\n      <td>0.294201</td>\n      <td>...</td>\n      <td>-0.013426</td>\n      <td>0.064171</td>\n      <td>-0.069056</td>\n      <td>0.062074</td>\n      <td>-0.071315</td>\n      <td>0.072003</td>\n      <td>-0.085813</td>\n      <td>0.018093</td>\n      <td>-0.024765</td>\n      <td>-0.023205</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17.487040</td>\n      <td>17.476616</td>\n      <td>17.514101</td>\n      <td>4.949534</td>\n      <td>0.713287</td>\n      <td>1.208352</td>\n      <td>-0.835234</td>\n      <td>-1.803925</td>\n      <td>-2.177733</td>\n      <td>-1.533708</td>\n      <td>...</td>\n      <td>0.016671</td>\n      <td>0.036579</td>\n      <td>-0.033026</td>\n      <td>0.017482</td>\n      <td>-0.014863</td>\n      <td>0.016572</td>\n      <td>-0.072260</td>\n      <td>0.024719</td>\n      <td>-0.037654</td>\n      <td>-0.001608</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17.765692</td>\n      <td>18.767421</td>\n      <td>18.563219</td>\n      <td>5.234889</td>\n      <td>0.756572</td>\n      <td>1.239086</td>\n      <td>-0.727071</td>\n      <td>-1.738814</td>\n      <td>-2.078783</td>\n      <td>-0.720965</td>\n      <td>...</td>\n      <td>0.020868</td>\n      <td>0.035213</td>\n      <td>-0.036041</td>\n      <td>0.011065</td>\n      <td>-0.006174</td>\n      <td>0.017821</td>\n      <td>-0.030732</td>\n      <td>-0.027515</td>\n      <td>-0.018567</td>\n      <td>0.002476</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17.472889</td>\n      <td>18.368493</td>\n      <td>18.044299</td>\n      <td>5.083577</td>\n      <td>0.745658</td>\n      <td>1.200223</td>\n      <td>-0.800412</td>\n      <td>-1.813089</td>\n      <td>-2.117043</td>\n      <td>0.838703</td>\n      <td>...</td>\n      <td>0.026449</td>\n      <td>0.028665</td>\n      <td>-0.013610</td>\n      <td>-0.003827</td>\n      <td>-0.018916</td>\n      <td>0.046067</td>\n      <td>-0.068930</td>\n      <td>0.005377</td>\n      <td>-0.029879</td>\n      <td>0.006491</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16.631755</td>\n      <td>17.107590</td>\n      <td>16.986173</td>\n      <td>4.785861</td>\n      <td>0.705577</td>\n      <td>1.207803</td>\n      <td>-0.814830</td>\n      <td>-1.677964</td>\n      <td>-1.684348</td>\n      <td>-0.600837</td>\n      <td>...</td>\n      <td>-0.015116</td>\n      <td>0.060441</td>\n      <td>-0.050212</td>\n      <td>0.021235</td>\n      <td>-0.011183</td>\n      <td>0.030903</td>\n      <td>-0.061186</td>\n      <td>-0.018751</td>\n      <td>0.003333</td>\n      <td>-0.020661</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 76 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 37.62497091293335 s\n",
      "Accuracy 0.9275319926873857 precision 0.9273096372936104 specificity 0.8077854780333081 recall 0.9275319926873857 f1 0.9248782923709613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 37.052969217300415 s\n",
      "Accuracy 0.9283363802559415 precision 0.9279923248403605 specificity 0.811835748728045 recall 0.9283363802559415 f1 0.9258350619183233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 37.20896887779236 s\n",
      "Accuracy 0.933564899451554 precision 0.933034197019557 specificity 0.8224239485148233 recall 0.933564899451554 f1 0.931466842448682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 36.79996871948242 s\n",
      "Accuracy 0.9297623400365631 precision 0.9295504571977131 specificity 0.8119278004445359 recall 0.9297623400365631 f1 0.927248202782788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 36.87197160720825 s\n",
      "Accuracy 0.9290676416819013 precision 0.9290100146621005 specificity 0.8084266157231369 recall 0.9290676416819013 f1 0.9264105467673979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 36.78096914291382 s\n",
      "Accuracy 0.9290310786106033 precision 0.9284614072898234 specificity 0.8149724602374708 recall 0.9290310786106033 f1 0.9266958396504393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 35.85497069358826 s\n",
      "Accuracy 0.9276782449725777 precision 0.9272076541520395 specificity 0.8107969113076431 recall 0.9276782449725777 f1 0.925182224307083\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 36.0299711227417 s\n",
      "Accuracy 0.9278610603290677 precision 0.9275487825669021 specificity 0.8068996372329373 recall 0.9278610603290677 f1 0.9252208252204269\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 36.60997247695923 s\n",
      "Accuracy 0.9286654478976234 precision 0.9284185569213124 specificity 0.80819661561195 recall 0.9286654478976234 f1 0.92605200751019\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 36.54296898841858 s\n",
      "Accuracy 0.9264716636197441 precision 0.9259999681511606 specificity 0.8047953496269777 recall 0.9264716636197441 f1 0.9238044718396006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 36.33496975898743 s\n",
      "Accuracy 0.929835466179159 precision 0.9294630090525483 specificity 0.8111646360482793 recall 0.929835466179159 f1 0.9273563199637768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 36.531970739364624 s\n",
      "Accuracy 0.9292504570383913 precision 0.929022413937706 specificity 0.8128338860773701 recall 0.9292504570383913 f1 0.9267528750809259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 36.873969078063965 s\n",
      "Accuracy 0.9281901279707495 precision 0.92791299335132 specificity 0.8065766257905778 recall 0.9281901279707495 f1 0.9255375284936272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 35.981969594955444 s\n",
      "Accuracy 0.9271297989031079 precision 0.9266507845554616 specificity 0.8048615721825092 recall 0.9271297989031079 f1 0.9244801559407568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 37.06197166442871 s\n",
      "Accuracy 0.9311882998171847 precision 0.9308534011043517 specificity 0.8185520309952757 recall 0.9311882998171847 f1 0.9288931995217858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 36.37396955490112 s\n",
      "Accuracy 0.92672760511883 precision 0.9264841375590676 specificity 0.80462365326868 recall 0.92672760511883 f1 0.9239865700171844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 36.19897127151489 s\n",
      "Accuracy 0.9276416819012797 precision 0.927368632940197 specificity 0.8088247310652529 recall 0.9276416819012797 f1 0.9250313973919111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 36.57896971702576 s\n",
      "Accuracy 0.9305667276051188 precision 0.9301661299900551 specificity 0.8167496461473782 recall 0.9305667276051188 f1 0.9282410566550432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 36.64196968078613 s\n",
      "Accuracy 0.9289945155393053 precision 0.9287598661425612 specificity 0.8138376393518221 recall 0.9289945155393053 f1 0.9265179895372319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 36.22396802902222 s\n",
      "Accuracy 0.9309323583180987 precision 0.9305793817657124 specificity 0.8179341300192506 recall 0.9309323583180987 f1 0.9286245456693808\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 37.15896940231323 s\n",
      "Accuracy 0.9285191956124315 precision 0.9280406310331989 specificity 0.8074260016616258 recall 0.9285191956124315 f1 0.9259604901224106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 36.34097170829773 s\n",
      "Accuracy 0.9269469835466179 precision 0.9263792349927165 specificity 0.80629373114634 recall 0.9269469835466179 f1 0.9243603546352589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 36.592971324920654 s\n",
      "Accuracy 0.9262888482632541 precision 0.9257916333768571 specificity 0.8100905162302565 recall 0.9262888482632541 f1 0.9237591932328291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 36.564977169036865 s\n",
      "Accuracy 0.9273857404021938 precision 0.9271782918128997 specificity 0.8083462328270734 recall 0.9273857404021938 f1 0.9247382296204932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 36.30997943878174 s\n",
      "Accuracy 0.9317733089579525 precision 0.9311704263685842 specificity 0.8176012044896245 recall 0.9317733089579525 f1 0.9295616306265646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 35.93497610092163 s\n",
      "Accuracy 0.9287751371115174 precision 0.9283976883594004 specificity 0.8135126007614453 recall 0.9287751371115174 f1 0.9263331123740499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 36.070979833602905 s\n",
      "Accuracy 0.9323583180987203 precision 0.9320349165475297 specificity 0.8159830519890893 recall 0.9323583180987203 f1 0.9300230593744001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 36.69497728347778 s\n",
      "Accuracy 0.9292504570383913 precision 0.9286722298347244 specificity 0.8114709298357682 recall 0.9292504570383913 f1 0.9268388086759516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 36.59397578239441 s\n",
      "Accuracy 0.9276782449725777 precision 0.9274682059102032 specificity 0.8075281028783301 recall 0.9276782449725777 f1 0.9250173499273174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 35.83597779273987 s\n",
      "Accuracy 0.9303107861060329 precision 0.9299651237870791 specificity 0.8175018050161836 recall 0.9303107861060329 f1 0.9279795391304211\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 36.286977767944336 s\n",
      "Accuracy 0.9292138939670932 precision 0.9285475965230847 specificity 0.8138588154127606 recall 0.9292138939670932 f1 0.9268918196452663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 36.94297909736633 s\n",
      "Accuracy 0.9279341864716636 precision 0.9275599508511738 specificity 0.8090895604166431 recall 0.9279341864716636 f1 0.9253688449956264\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 35.33697748184204 s\n",
      "Accuracy 0.9293235831809872 precision 0.9289032828380558 specificity 0.8060091026257155 recall 0.9293235831809872 f1 0.926727758566597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 36.01097846031189 s\n",
      "Accuracy 0.9293601462522852 precision 0.9289693016181669 specificity 0.8086427888094734 recall 0.9293601462522852 f1 0.9268179643986418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 35.605979919433594 s\n",
      "Accuracy 0.930274223034735 precision 0.929819710502931 specificity 0.8132196403276837 recall 0.930274223034735 f1 0.9278795346283573\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 36.25397706031799 s\n",
      "Accuracy 0.9277148080438757 precision 0.9275057846085824 specificity 0.8067193035734398 recall 0.9277148080438757 f1 0.925034641034191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 36.047977924346924 s\n",
      "Accuracy 0.9323583180987203 precision 0.9320872044121942 specificity 0.8167311229192453 recall 0.9323583180987203 f1 0.9300229815997288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 35.532978534698486 s\n",
      "Accuracy 0.9291042047531992 precision 0.9286418451779351 specificity 0.8125610066788247 recall 0.9291042047531992 f1 0.9266744947890441\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 35.71697950363159 s\n",
      "Accuracy 0.9275685557586837 precision 0.927451522187868 specificity 0.8089726395056798 recall 0.9275685557586837 f1 0.9249123123206044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 36.576977014541626 s\n",
      "Accuracy 0.9298720292504571 precision 0.9293338613943961 specificity 0.8155385812659531 recall 0.9298720292504571 f1 0.9275538033076702\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 36.65097761154175 s\n",
      "Accuracy 0.9269469835466179 precision 0.9266040453277952 specificity 0.8072703667269643 recall 0.9269469835466179 f1 0.9243075912400849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 35.85197854042053 s\n",
      "Accuracy 0.9297623400365631 precision 0.9295835552923476 specificity 0.8151420441879264 recall 0.9297623400365631 f1 0.9273132113766834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 35.94897675514221 s\n",
      "Accuracy 0.9282998171846435 precision 0.927908675157432 specificity 0.8084012706726043 recall 0.9282998171846435 f1 0.9257306087201858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 35.8819785118103 s\n",
      "Accuracy 0.9280438756855576 precision 0.9281152335165929 specificity 0.8103537016808378 recall 0.9280438756855576 f1 0.9253756187694099\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 35.899978160858154 s\n",
      "Accuracy 0.9272394881170019 precision 0.9270650552351655 specificity 0.8025241268758152 recall 0.9272394881170019 f1 0.9244359908363836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 35.791977643966675 s\n",
      "Accuracy 0.9270201096892139 precision 0.9267253602236529 specificity 0.8084470989629777 recall 0.9270201096892139 f1 0.9243955224861613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 35.472976207733154 s\n",
      "Accuracy 0.9324680073126143 precision 0.9321049150384298 specificity 0.8202854856817506 recall 0.9324680073126143 f1 0.9302442015052341\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 36.27897787094116 s\n",
      "Accuracy 0.9303473491773309 precision 0.9299586259075687 specificity 0.8145122425125179 recall 0.9303473491773309 f1 0.9279617537636704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 35.862977027893066 s\n",
      "Accuracy 0.9273126142595978 precision 0.9267088348831348 specificity 0.8082436837578022 recall 0.9273126142595978 f1 0.9247945543677346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 35.52497577667236 s\n",
      "Accuracy 0.9264716636197441 precision 0.9259397533495698 specificity 0.8074200175402412 recall 0.9264716636197441 f1 0.9238910236157765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 36.235976219177246 s\n",
      "Accuracy 0.9302376599634369 precision 0.9296864047404455 specificity 0.8189545982764384 recall 0.9302376599634369 f1 0.9280106696306005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 35.851975440979004 s\n",
      "Accuracy 0.9280438756855576 precision 0.9276397828935683 specificity 0.8114184250910796 recall 0.9280438756855576 f1 0.9255470167264278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 36.116978883743286 s\n",
      "Accuracy 0.9287020109689214 precision 0.928357437003047 specificity 0.8105144480934536 recall 0.9287020109689214 f1 0.926176119738192\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 36.14697599411011 s\n",
      "Accuracy 0.9277879341864717 precision 0.9274340462699602 specificity 0.807017329214742 recall 0.9277879341864717 f1 0.9251626008884568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 36.3939790725708 s\n",
      "Accuracy 0.9285191956124315 precision 0.9280615809268872 specificity 0.811730251742266 recall 0.9285191956124315 f1 0.9260569939529434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 36.45297837257385 s\n",
      "Accuracy 0.9287020109689214 precision 0.9284251471210819 specificity 0.8063568242237703 recall 0.9287020109689214 f1 0.9260546298601975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 35.23897743225098 s\n",
      "Accuracy 0.9310054844606946 precision 0.9308500260948788 specificity 0.8138672318364272 recall 0.9310054844606946 f1 0.9285432191764925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 36.05597901344299 s\n",
      "Accuracy 0.9293967093235832 precision 0.9289362724854926 specificity 0.8120278388131568 recall 0.9293967093235832 f1 0.9269592102515054\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 35.695976972579956 s\n",
      "Accuracy 0.9323583180987203 precision 0.9316640747686742 specificity 0.8171995071246888 recall 0.9323583180987203 f1 0.9301839757098305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 36.36597752571106 s\n",
      "Accuracy 0.9286288848263254 precision 0.9283904510836073 specificity 0.8109897913718256 recall 0.9286288848263254 f1 0.926078928562762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 36.06397891044617 s\n",
      "Accuracy 0.9311882998171847 precision 0.9307345322270881 specificity 0.8157196280565233 recall 0.9311882998171847 f1 0.9288686019121593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 36.03097653388977 s\n",
      "Accuracy 0.9260694698354662 precision 0.9258275968780457 specificity 0.8086842904954704 recall 0.9260694698354662 f1 0.9234159962935147\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 36.41397523880005 s\n",
      "Accuracy 0.9292138939670932 precision 0.9288027416265351 specificity 0.813248441464951 recall 0.9292138939670932 f1 0.9267850139402857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 36.27897882461548 s\n",
      "Accuracy 0.930127970749543 precision 0.9297112594859193 specificity 0.8191437114501815 recall 0.930127970749543 f1 0.9278556005151004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 35.88197875022888 s\n",
      "Accuracy 0.9305301645338209 precision 0.9301606858715461 specificity 0.8138776008643906 recall 0.9305301645338209 f1 0.9281268657091983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 36.202977657318115 s\n",
      "Accuracy 0.9291773308957952 precision 0.928974431804757 specificity 0.8122369689557769 recall 0.9291773308957952 f1 0.9266564321559332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 35.447978258132935 s\n",
      "Accuracy 0.9273126142595978 precision 0.9266390927034701 specificity 0.8083417703042235 recall 0.9273126142595978 f1 0.92482306653141\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 36.241979122161865 s\n",
      "Accuracy 0.9308957952468008 precision 0.930427720025762 specificity 0.8210581788647521 recall 0.9308957952468008 f1 0.9286984825033268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 36.138978481292725 s\n",
      "Accuracy 0.92654478976234 precision 0.9260776501185167 specificity 0.8048509663979878 recall 0.92654478976234 f1 0.9238789012161235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 35.88397669792175 s\n",
      "Accuracy 0.9295063985374772 precision 0.9292204613739922 specificity 0.8130853859979815 recall 0.9295063985374772 f1 0.9270378970701775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 36.507975816726685 s\n",
      "Accuracy 0.9275685557586837 precision 0.9270957047578894 specificity 0.8129323733865222 recall 0.9275685557586837 f1 0.925123376458775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 36.08997631072998 s\n",
      "Accuracy 0.9295795246800731 precision 0.9294730496933619 specificity 0.8138055801657522 recall 0.9295795246800731 f1 0.9270738664003214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 36.09897756576538 s\n",
      "Accuracy 0.92654478976234 precision 0.9262885265982268 specificity 0.8021591537709781 recall 0.92654478976234 f1 0.9237426779194705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 35.80197715759277 s\n",
      "Accuracy 0.9289579524680073 precision 0.928641156158807 specificity 0.8110662777982042 recall 0.9289579524680073 f1 0.9264411279899248\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 35.70297884941101 s\n",
      "Accuracy 0.9261791590493601 precision 0.9258440013967132 specificity 0.8095386345678114 recall 0.9261791590493601 f1 0.9235788964214804\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 35.97497630119324 s\n",
      "Accuracy 0.9297623400365631 precision 0.9294887378778681 specificity 0.8148568261793979 recall 0.9297623400365631 f1 0.9273362280414947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 35.78597831726074 s\n",
      "Accuracy 0.9291407678244973 precision 0.9287050740684581 specificity 0.8102931747782969 recall 0.9291407678244973 f1 0.9266485796695649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 35.542978048324585 s\n",
      "Accuracy 0.9287385740402194 precision 0.9281650908961807 specificity 0.8096468479441804 recall 0.9287385740402194 f1 0.9262714724181934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 35.618977785110474 s\n",
      "Accuracy 0.9294698354661791 precision 0.9292713717293056 specificity 0.8127915357322752 recall 0.9294698354661791 f1 0.9269662104471962\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 35.459978342056274 s\n",
      "Accuracy 0.9274954296160878 precision 0.9268937459046777 specificity 0.8125071466720625 recall 0.9274954296160878 f1 0.9250849516393903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 36.28497624397278 s\n",
      "Accuracy 0.9290676416819013 precision 0.9287232109722093 specificity 0.8149984624893252 recall 0.9290676416819013 f1 0.9266552511187969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 35.54197812080383 s\n",
      "Accuracy 0.9272394881170019 precision 0.9268526063253842 specificity 0.8102236511915918 recall 0.9272394881170019 f1 0.9246927970538071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 36.14897871017456 s\n",
      "Accuracy 0.9287385740402194 precision 0.9281500677873653 specificity 0.8115725757121254 recall 0.9287385740402194 f1 0.9263233713464814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 35.832977294921875 s\n",
      "Accuracy 0.9288482632541133 precision 0.9285251782062364 specificity 0.8127083389285158 recall 0.9288482632541133 f1 0.9263704986686293\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 36.244978189468384 s\n",
      "Accuracy 0.9304936014625228 precision 0.9299946589619198 specificity 0.8160323980838403 recall 0.9304936014625228 f1 0.9281841364359394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 36.20297908782959 s\n",
      "Accuracy 0.9277148080438757 precision 0.927585623011293 specificity 0.8095860152169133 recall 0.9277148080438757 f1 0.9250799356425032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 36.258979082107544 s\n",
      "Accuracy 0.9280073126142596 precision 0.9278972890831576 specificity 0.8077164638213226 recall 0.9280073126142596 f1 0.9253271656410917\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 36.18897795677185 s\n",
      "Accuracy 0.9319926873857404 precision 0.9319384276731608 specificity 0.8136197593183987 recall 0.9319926873857404 f1 0.9295143062030831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 36.26197648048401 s\n",
      "Accuracy 0.9284095063985375 precision 0.9280322202106934 specificity 0.8071228372439039 recall 0.9284095063985375 f1 0.9258070260777462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 35.703978538513184 s\n",
      "Accuracy 0.9284826325411335 precision 0.9280930108160722 specificity 0.8078134499086412 recall 0.9284826325411335 f1 0.9259023918312884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 36.00497889518738 s\n",
      "Accuracy 0.9302010968921389 precision 0.9298460440101265 specificity 0.8151108319330721 recall 0.9302010968921389 f1 0.9278154721893747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 35.774977684020996 s\n",
      "Accuracy 0.9281535648994516 precision 0.9279785509314077 specificity 0.8083549421554485 recall 0.9281535648994516 f1 0.9255114015773741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 35.77297830581665 s\n",
      "Accuracy 0.9313711151736745 precision 0.9307843392648301 specificity 0.8177261719255291 recall 0.9313711151736745 f1 0.9291488695221851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 35.719977378845215 s\n",
      "Accuracy 0.9296526508226691 precision 0.9292044056234202 specificity 0.8178259065214047 recall 0.9296526508226691 f1 0.9273523176332577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 35.404977798461914 s\n",
      "Accuracy 0.9276782449725777 precision 0.9272026102942675 specificity 0.8082577427576944 recall 0.9276782449725777 f1 0.9251219726828603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 36.302979946136475 s\n",
      "Accuracy 0.9289579524680073 precision 0.9286282283309572 specificity 0.8123774561682617 recall 0.9289579524680073 f1 0.9264765313051132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 35.69997692108154 s\n",
      "Accuracy 0.9288848263254114 precision 0.9286641724253948 specificity 0.8099993509202222 recall 0.9288848263254114 f1 0.9263106483503795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 35.69497895240784 s\n",
      "Accuracy 0.9284826325411335 precision 0.9283118838262284 specificity 0.8090633560515895 recall 0.9284826325411335 f1 0.9258627513689833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 35.741976737976074 s\n",
      "Accuracy 0.9295429616087751 precision 0.9289753801808052 specificity 0.8136206032989356 recall 0.9295429616087751 f1 0.9271841166734351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 35.900978326797485 s\n",
      "Accuracy 0.9306764168190128 precision 0.9301887201529426 specificity 0.8164539701987108 recall 0.9306764168190128 f1 0.928376077935845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 35.75097680091858 s\n",
      "Accuracy 0.9284095063985375 precision 0.9277361218844795 specificity 0.8125383281366801 recall 0.9284095063985375 f1 0.9260435420615107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 35.18197751045227 s\n",
      "Accuracy 0.9292138939670932 precision 0.9290099519664834 specificity 0.812862176728117 recall 0.9292138939670932 f1 0.9267087898941659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 36.15497827529907 s\n",
      "Accuracy 0.9287385740402194 precision 0.9283931685118983 specificity 0.8125659738866456 recall 0.9287385740402194 f1 0.9262626774218308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 35.69397783279419 s\n",
      "Accuracy 0.9272394881170019 precision 0.9269565907585102 specificity 0.8065450982863541 recall 0.9272394881170019 f1 0.9245686759146476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 35.882978439331055 s\n",
      "Accuracy 0.9291407678244973 precision 0.9289930157434655 specificity 0.8143169229684034 recall 0.9291407678244973 f1 0.926651428900301\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 36.33997654914856 s\n",
      "Accuracy 0.9296892138939671 precision 0.9292766146946708 specificity 0.8133229572207595 recall 0.9296892138939671 f1 0.9272714801095844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 35.38897967338562 s\n",
      "Accuracy 0.926873857404022 precision 0.9266129687083735 specificity 0.8024071548454355 recall 0.926873857404022 f1 0.9240863842981016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 35.66697716712952 s\n",
      "Accuracy 0.9297989031078611 precision 0.9296208261935287 specificity 0.8127795558736665 recall 0.9297989031078611 f1 0.9272950083655335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 36.468974113464355 s\n",
      "Accuracy 0.9284826325411335 precision 0.9280774952144394 specificity 0.8118334778380975 recall 0.9284826325411335 f1 0.9260043162302317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 35.5169780254364 s\n",
      "Accuracy 0.9323217550274223 precision 0.9322303385839062 specificity 0.8187822179194049 recall 0.9323217550274223 f1 0.9299764429948995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 36.063976526260376 s\n",
      "Accuracy 0.9295429616087751 precision 0.9292063429545585 specificity 0.8136383480570959 recall 0.9295429616087751 f1 0.9271045835942169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 35.73797655105591 s\n",
      "Accuracy 0.9300914076782449 precision 0.9293970406322647 specificity 0.8093770226644185 recall 0.9300914076782449 f1 0.9276902958850753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 36.00797700881958 s\n",
      "Accuracy 0.9288117001828153 precision 0.9285563407509617 specificity 0.8099725015121891 recall 0.9288117001828153 f1 0.926246317281813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 35.76197648048401 s\n",
      "Accuracy 0.9281901279707495 precision 0.9278376916065734 specificity 0.8131617199332223 recall 0.9281901279707495 f1 0.9257207624866075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 35.67297720909119 s\n",
      "Accuracy 0.9280073126142596 precision 0.9276254191179704 specificity 0.8085517095643375 recall 0.9280073126142596 f1 0.9254328883963618\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 35.92997670173645 s\n",
      "Accuracy 0.9274588665447898 precision 0.9268860674978073 specificity 0.8098781926599177 recall 0.9274588665447898 f1 0.924972548415969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 35.510977268218994 s\n",
      "Accuracy 0.9312248628884826 precision 0.9309592416064009 specificity 0.8188972047378745 recall 0.9312248628884826 f1 0.9289158051630375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 35.672980070114136 s\n",
      "Accuracy 0.926654478976234 precision 0.9265331041443786 specificity 0.8039262360601173 recall 0.926654478976234 f1 0.923857229728259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 36.05197763442993 s\n",
      "Accuracy 0.9321023765996344 precision 0.9317496740944817 specificity 0.8197135440800588 recall 0.9321023765996344 f1 0.9298557623674985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 35.873976707458496 s\n",
      "Accuracy 0.9325776965265082 precision 0.9321929117856931 specificity 0.8181576803120925 recall 0.9325776965265082 f1 0.9303156572009892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 36.46097707748413 s\n",
      "Accuracy 0.9306032906764168 precision 0.9303047797289782 specificity 0.8138942721282326 recall 0.9306032906764168 f1 0.9281785601097258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 35.92197561264038 s\n",
      "Accuracy 0.9295429616087751 precision 0.9291012529740688 specificity 0.8185918639100226 recall 0.9295429616087751 f1 0.9272564653135479\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 35.538978815078735 s\n",
      "Accuracy 0.9287020109689214 precision 0.9281526298306375 specificity 0.8097870731638864 recall 0.9287020109689214 f1 0.9262288659876926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 36.709970235824585 s\n",
      "Accuracy 0.9292138939670932 precision 0.9287727749447381 specificity 0.8117528048566214 recall 0.9292138939670932 f1 0.9267597176102359\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 35.27697205543518 s\n",
      "Accuracy 0.9296892138939671 precision 0.9293926113067177 specificity 0.812375063213652 recall 0.9296892138939671 f1 0.9272109100419239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 35.92897081375122 s\n",
      "Accuracy 0.9289579524680073 precision 0.9285775457864143 specificity 0.8127367315751284 recall 0.9289579524680073 f1 0.9265018082144971\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 35.77697014808655 s\n",
      "Accuracy 0.930018281535649 precision 0.9296224005315252 specificity 0.817905817502952 recall 0.930018281535649 f1 0.9277081221481148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 35.93197226524353 s\n",
      "Accuracy 0.9285923217550274 precision 0.9280169618865146 specificity 0.8111971508788135 recall 0.9285923217550274 f1 0.926160476680922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 36.11296892166138 s\n",
      "Accuracy 0.9290676416819013 precision 0.9289496763520655 specificity 0.8070238428615468 recall 0.9290676416819013 f1 0.9263949928481758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 35.65197014808655 s\n",
      "Accuracy 0.9287020109689214 precision 0.9281295865289814 specificity 0.8122210429232875 recall 0.9287020109689214 f1 0.9262958290333582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 35.83297085762024 s\n",
      "Accuracy 0.9310786106032907 precision 0.9308564865885116 specificity 0.808030219984366 recall 0.9310786106032907 f1 0.9285039914462342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 35.94497108459473 s\n",
      "Accuracy 0.9283363802559415 precision 0.928103592234176 specificity 0.8104395860382951 recall 0.9283363802559415 f1 0.9257658570438014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 35.69397187232971 s\n",
      "Accuracy 0.9304204753199269 precision 0.9302568271157184 specificity 0.8138341326731244 recall 0.9304204753199269 f1 0.9279486379433318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 35.962969064712524 s\n",
      "Accuracy 0.9309323583180987 precision 0.9307616630782047 specificity 0.8153650014671041 recall 0.9309323583180987 f1 0.9285076643561764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 35.343971729278564 s\n",
      "Accuracy 0.9292870201096892 precision 0.9290006813331333 specificity 0.8135619133969078 recall 0.9292870201096892 f1 0.9268257752813431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 35.854971408843994 s\n",
      "Accuracy 0.929945155393053 precision 0.9297584253425819 specificity 0.8082710344150862 recall 0.929945155393053 f1 0.927341150125551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 35.858970642089844 s\n",
      "Accuracy 0.9322120658135283 precision 0.9320272867944815 specificity 0.8164764324927785 recall 0.9322120658135283 f1 0.9298412287505726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 35.99097204208374 s\n",
      "Accuracy 0.9288117001828153 precision 0.9284015466864843 specificity 0.804774809431051 recall 0.9288117001828153 f1 0.9261719310778389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 36.11297082901001 s\n",
      "Accuracy 0.9293601462522852 precision 0.9291197613346966 specificity 0.8122113446875817 recall 0.9293601462522852 f1 0.9268538165598694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 35.66697025299072 s\n",
      "Accuracy 0.9296892138939671 precision 0.9294706459354245 specificity 0.810731250187232 recall 0.9296892138939671 f1 0.9271476155684681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 36.03996825218201 s\n",
      "Accuracy 0.9285557586837294 precision 0.928232893954094 specificity 0.8099641691673476 recall 0.9285557586837294 f1 0.9260067670399836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 35.53297162055969 s\n",
      "Accuracy 0.9292138939670932 precision 0.9288418597073027 specificity 0.8113894549503612 recall 0.9292138939670932 f1 0.9267277969392411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 35.93597173690796 s\n",
      "Accuracy 0.9287385740402194 precision 0.928793910844155 specificity 0.8063061838485371 recall 0.9287385740402194 f1 0.9259916310397033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 35.96997046470642 s\n",
      "Accuracy 0.929725776965265 precision 0.9292594465898402 specificity 0.8145008346064988 recall 0.929725776965265 f1 0.9273549182003759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 35.860971450805664 s\n",
      "Accuracy 0.9289579524680073 precision 0.9288209467326161 specificity 0.8077040565811466 recall 0.9289579524680073 f1 0.9263049451000023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 36.02497172355652 s\n",
      "Accuracy 0.9304204753199269 precision 0.9304983194082139 specificity 0.8143190054161997 recall 0.9304204753199269 f1 0.92788960666957\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 35.624972343444824 s\n",
      "Accuracy 0.9279707495429617 precision 0.9275829872606487 specificity 0.8109646640413213 recall 0.9279707495429617 f1 0.9254560630624156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 36.488969564437866 s\n",
      "Accuracy 0.9289945155393053 precision 0.9285128915048635 specificity 0.8134360923646002 recall 0.9289945155393053 f1 0.9265903306351377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 36.426971435546875 s\n",
      "Accuracy 0.9296526508226691 precision 0.9293435444017312 specificity 0.8110790689048711 recall 0.9296526508226691 f1 0.9271471745738944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 35.806971073150635 s\n",
      "Accuracy 0.9307495429616087 precision 0.9306381914607982 specificity 0.8138619300508679 recall 0.9307495429616087 f1 0.9282689303468419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 36.358969926834106 s\n",
      "Accuracy 0.9287385740402194 precision 0.9284957980439262 specificity 0.8112735919287719 recall 0.9287385740402194 f1 0.9261988584252514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 36.43297028541565 s\n",
      "Accuracy 0.9269104204753199 precision 0.9262611128631165 specificity 0.8141870926334034 recall 0.9269104204753199 f1 0.9245491620645198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 35.974971294403076 s\n",
      "Accuracy 0.9315173674588666 precision 0.9309978376409501 specificity 0.8196076169983393 recall 0.9315173674588666 f1 0.9293159793817587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 35.616971492767334 s\n",
      "Accuracy 0.9255575868372944 precision 0.9252068352685447 specificity 0.8047051222581963 recall 0.9255575868372944 f1 0.9228293976679914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 35.79597067832947 s\n",
      "Accuracy 0.9302376599634369 precision 0.9297408160175347 specificity 0.8182263883402714 recall 0.9302376599634369 f1 0.9279739304784448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 36.39097023010254 s\n",
      "Accuracy 0.9296160877513712 precision 0.9291819999991496 specificity 0.8138100644326738 recall 0.9296160877513712 f1 0.9272157828110973\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 36.05597114562988 s\n",
      "Accuracy 0.9282998171846435 precision 0.9276757481231367 specificity 0.8136963613289361 recall 0.9282998171846435 f1 0.925941110819636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 36.212971210479736 s\n",
      "Accuracy 0.9294332723948812 precision 0.9290425471059051 specificity 0.8123688135240484 recall 0.9294332723948812 f1 0.9269808119851908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 35.92497110366821 s\n",
      "Accuracy 0.9311882998171847 precision 0.9312322648561472 specificity 0.8130538028698698 recall 0.9311882998171847 f1 0.9286528417907332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 35.69797134399414 s\n",
      "Accuracy 0.9293601462522852 precision 0.9287885511715939 specificity 0.8122427406173447 recall 0.9293601462522852 f1 0.9269665796349534\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 35.99796938896179 s\n",
      "Accuracy 0.9274954296160878 precision 0.9271988509094824 specificity 0.8104593890721749 recall 0.9274954296160878 f1 0.9249296809603899\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 35.74197196960449 s\n",
      "Accuracy 0.9274954296160878 precision 0.9272466241084254 specificity 0.8068399840082737 recall 0.9274954296160878 f1 0.9248261883560092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 36.269970655441284 s\n",
      "Accuracy 0.9282998171846435 precision 0.9280561762556135 specificity 0.8061626067650709 recall 0.9282998171846435 f1 0.925628916527778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 36.109971046447754 s\n",
      "Accuracy 0.929945155393053 precision 0.9296237247584487 specificity 0.8132535223527916 recall 0.929945155393053 f1 0.9275003690181164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 36.169970750808716 s\n",
      "Accuracy 0.9315904936014625 precision 0.9312537476559292 specificity 0.8178088045154212 recall 0.9315904936014625 f1 0.9292863502221306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 35.403969049453735 s\n",
      "Accuracy 0.9307495429616087 precision 0.9303551757677271 specificity 0.8173832382837863 recall 0.9307495429616087 f1 0.9284396758426608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 35.8139705657959 s\n",
      "Accuracy 0.9270566727605118 precision 0.9267186934712018 specificity 0.8098999314056731 recall 0.9270566727605118 f1 0.9244824739660545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 36.12597131729126 s\n",
      "Accuracy 0.9291773308957952 precision 0.9290036735761354 specificity 0.810086317015726 recall 0.9291773308957952 f1 0.9265965130573711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 35.686970233917236 s\n",
      "Accuracy 0.929981718464351 precision 0.9295826624745767 specificity 0.8152605885786612 recall 0.929981718464351 f1 0.9276102728917572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 35.97297120094299 s\n",
      "Accuracy 0.9273857404021938 precision 0.9268909200430635 specificity 0.81201501920186 recall 0.9273857404021938 f1 0.9249225878843323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 35.75597095489502 s\n",
      "Accuracy 0.9305301645338209 precision 0.9299687575161144 specificity 0.8200212773322324 recall 0.9305301645338209 f1 0.9283367216557353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 35.368971824645996 s\n",
      "Accuracy 0.9285923217550274 precision 0.9283747395892675 specificity 0.8118553471016984 recall 0.9285923217550274 f1 0.9260558327883466\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 35.692967891693115 s\n",
      "Accuracy 0.9317733089579525 precision 0.9315498857252784 specificity 0.8165508398758448 recall 0.9317733089579525 f1 0.9294077601268279\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 36.282973527908325 s\n",
      "Accuracy 0.9308957952468008 precision 0.9303380962557569 specificity 0.820373348547668 recall 0.9308957952468008 f1 0.9287152938381806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 37.09797191619873 s\n",
      "Accuracy 0.930127970749543 precision 0.9297269436041793 specificity 0.8143698957514659 recall 0.930127970749543 f1 0.9277390933759414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 36.92678928375244 s\n",
      "Accuracy 0.9268007312614259 precision 0.9266464971022217 specificity 0.8046110157775792 recall 0.9268007312614259 f1 0.92403337835197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 36.47479033470154 s\n",
      "Accuracy 0.929945155393053 precision 0.9295110915129712 specificity 0.8133320831816743 recall 0.929945155393053 f1 0.9275397867003108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 36.45513987541199 s\n",
      "Accuracy 0.9297623400365631 precision 0.9295222346009839 specificity 0.8125457907371723 recall 0.9297623400365631 f1 0.9272715009980723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 36.5589234828949 s\n",
      "Accuracy 0.930274223034735 precision 0.9301286886837538 specificity 0.81141916908865 recall 0.930274223034735 f1 0.9277379970594578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 35.70448708534241 s\n",
      "Accuracy 0.9274954296160878 precision 0.9272276284690918 specificity 0.806422163259968 recall 0.9274954296160878 f1 0.9248219614816201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 36.93458604812622 s\n",
      "Accuracy 0.9288482632541133 precision 0.928329501424751 specificity 0.8163288307958566 recall 0.9288482632541133 f1 0.9265236480514722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 37.410972118377686 s\n",
      "Accuracy 0.9277879341864717 precision 0.9271414037780126 specificity 0.8106255035061233 recall 0.9277879341864717 f1 0.9253534806555163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 36.01800727844238 s\n",
      "Accuracy 0.9288117001828153 precision 0.9280363570692296 specificity 0.8122808667680962 recall 0.9288117001828153 f1 0.9264875517467839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 38.43597626686096 s\n",
      "Accuracy 0.9304204753199269 precision 0.9302920870087216 specificity 0.8097560858159588 recall 0.9304204753199269 f1 0.9278433877327238\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 37.136977195739746 s\n",
      "Accuracy 0.9277879341864717 precision 0.9273000025588002 specificity 0.8085802062652385 recall 0.9277879341864717 f1 0.9252459487396837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 36.755977630615234 s\n",
      "Accuracy 0.9303473491773309 precision 0.9298136142187478 specificity 0.8150132741791276 recall 0.9303473491773309 f1 0.9280239207271015\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 37.669976234436035 s\n",
      "Accuracy 0.9304936014625228 precision 0.9300847230887577 specificity 0.815541154379183 recall 0.9304936014625228 f1 0.9281414256648527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 38.894975900650024 s\n",
      "Accuracy 0.9286654478976234 precision 0.928046844123585 specificity 0.8145356876149241 recall 0.9286654478976234 f1 0.9263314768054186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 37.087977170944214 s\n",
      "Accuracy 0.9276782449725777 precision 0.9272541123735513 specificity 0.811675119291661 recall 0.9276782449725777 f1 0.9251876468580378\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 36.93997812271118 s\n",
      "Accuracy 0.9305301645338209 precision 0.9304163490157111 specificity 0.8153434063329923 recall 0.9305301645338209 f1 0.9280802392038743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 36.71297740936279 s\n",
      "Accuracy 0.9288117001828153 precision 0.928425270150264 specificity 0.8074468144887309 recall 0.9288117001828153 f1 0.9262282770613226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 36.83897662162781 s\n",
      "Accuracy 0.9280804387568555 precision 0.9277038962245675 specificity 0.8076787984448526 recall 0.9280804387568555 f1 0.9254845156199831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 36.75144028663635 s\n",
      "Accuracy 0.9297989031078611 precision 0.9293761710243422 specificity 0.8113747065018112 recall 0.9297989031078611 f1 0.9273408427822055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 37.653719425201416 s\n",
      "Accuracy 0.9282266910420476 precision 0.9280419887832795 specificity 0.8123028595174808 recall 0.9282266910420476 f1 0.9256839104807945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 36.36607885360718 s\n",
      "Accuracy 0.9311517367458867 precision 0.9306839069024107 specificity 0.8176245955216884 recall 0.9311517367458867 f1 0.9288799983086093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 36.40697884559631 s\n",
      "Accuracy 0.9269835466179159 precision 0.926310183429849 specificity 0.809620459256466 recall 0.9269835466179159 f1 0.9245194438072319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 36.29297637939453 s\n",
      "Accuracy 0.9325776965265082 precision 0.9321713089225384 specificity 0.822709736845659 recall 0.9325776965265082 f1 0.9304245312290036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 36.18956184387207 s\n",
      "Accuracy 0.9313711151736745 precision 0.9312630245828789 specificity 0.814886787218607 recall 0.9313711151736745 f1 0.9289250095284429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 36.34698176383972 s\n",
      "Accuracy 0.9306398537477149 precision 0.9303963842339646 specificity 0.8158874135839357 recall 0.9306398537477149 f1 0.9282442760826723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 36.36473321914673 s\n",
      "Accuracy 0.9295795246800731 precision 0.9293109110512308 specificity 0.8112833362358879 recall 0.9295795246800731 f1 0.9270644699808418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 37.610976696014404 s\n",
      "Accuracy 0.9294332723948812 precision 0.9289944031755812 specificity 0.8118551464811423 recall 0.9294332723948812 f1 0.9269849613066845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 36.46897649765015 s\n",
      "Accuracy 0.9289945155393053 precision 0.92875454131573 specificity 0.8090251412648946 recall 0.9289945155393053 f1 0.9264053370830433\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 35.93697738647461 s\n",
      "Accuracy 0.9306398537477149 precision 0.930439570041529 specificity 0.8135009564533576 recall 0.9306398537477149 f1 0.9281757733313456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 37.10097789764404 s\n",
      "Accuracy 0.9295429616087751 precision 0.9290903435439547 specificity 0.8116303778742234 recall 0.9295429616087751 f1 0.9270961649196358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 36.41597628593445 s\n",
      "Accuracy 0.9261425959780621 precision 0.9261921371810007 specificity 0.8053495468701085 recall 0.9261425959780621 f1 0.9233204441149518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 36.61455678939819 s\n",
      "Accuracy 0.930018281535649 precision 0.9296092840255896 specificity 0.8149138440402927 recall 0.930018281535649 f1 0.9276427713857487\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 36.60986828804016 s\n",
      "Accuracy 0.9293601462522852 precision 0.9290160641665739 specificity 0.8109924984004431 recall 0.9293601462522852 f1 0.926858262317285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 36.869515895843506 s\n",
      "Accuracy 0.9305667276051188 precision 0.9302325924978221 specificity 0.8128972509186296 recall 0.9305667276051188 f1 0.9281297599543358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 36.718040466308594 s\n",
      "Accuracy 0.9316636197440585 precision 0.9311553434411638 specificity 0.818552496165482 recall 0.9316636197440585 f1 0.9294367131484328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 35.72797727584839 s\n",
      "Accuracy 0.9315173674588666 precision 0.9312426832698321 specificity 0.8172640211324279 recall 0.9315173674588666 f1 0.929179385159693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 36.19898009300232 s\n",
      "Accuracy 0.9309689213893967 precision 0.9304187614877575 specificity 0.8166906121053062 recall 0.9309689213893967 f1 0.9287018971532004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 36.93753623962402 s\n",
      "Accuracy 0.9260329067641682 precision 0.92566361679014 specificity 0.8044543807443415 recall 0.9260329067641682 f1 0.9233139472009937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 37.53699731826782 s\n",
      "Accuracy 0.9285191956124315 precision 0.9281280190775956 specificity 0.8112625177663305 recall 0.9285191956124315 f1 0.9260231684976358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 37.061567544937134 s\n",
      "Accuracy 0.929835466179159 precision 0.929663767306634 specificity 0.8111833492738032 recall 0.929835466179159 f1 0.9272929507164759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 36.9134407043457 s\n",
      "Accuracy 0.9274588665447898 precision 0.9269580928109507 specificity 0.8093403493502664 recall 0.9274588665447898 f1 0.9249336284701354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 37.151976585388184 s\n",
      "Accuracy 0.9303107861060329 precision 0.9299635105856314 specificity 0.815505554366816 recall 0.9303107861060329 f1 0.9279337869180182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 37.031977891922 s\n",
      "Accuracy 0.9280804387568555 precision 0.9280125646555731 specificity 0.8080084309237978 recall 0.9280804387568555 f1 0.9253963300172353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 36.68897581100464 s\n",
      "Accuracy 0.9278244972577696 precision 0.9274388204910199 specificity 0.8070902449094954 recall 0.9278244972577696 f1 0.9252121555011238\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 36.97451090812683 s\n",
      "Accuracy 0.9314442413162706 precision 0.931366783592139 specificity 0.8124608395160042 recall 0.9314442413162706 f1 0.9289352720267442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 37.64251637458801 s\n",
      "Accuracy 0.9292870201096892 precision 0.9287171569090218 specificity 0.8120354982689317 recall 0.9292870201096892 f1 0.9268864887055371\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 37.61097693443298 s\n",
      "Accuracy 0.9320292504570384 precision 0.931568684042255 specificity 0.8170444191830353 recall 0.9320292504570384 f1 0.9297579124720613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 36.17298078536987 s\n",
      "Accuracy 0.9293235831809872 precision 0.9288210964835135 specificity 0.8119328732303056 recall 0.9293235831809872 f1 0.9268971216618962\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 36.53697848320007 s\n",
      "Accuracy 0.9281170018281536 precision 0.927714110342318 specificity 0.8103812827780517 recall 0.9281170018281536 f1 0.9255960330600819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 37.588977336883545 s\n",
      "Accuracy 0.9255941499085923 precision 0.9249137069302112 specificity 0.8073377670752705 recall 0.9255941499085923 f1 0.9230493592742625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 37.47797632217407 s\n",
      "Accuracy 0.926837294332724 precision 0.9267102148370181 specificity 0.8055663416406585 recall 0.926837294332724 f1 0.9240860997070571\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 35.77497458457947 s\n",
      "Accuracy 0.9296526508226691 precision 0.9291112208539347 specificity 0.811333362769626 recall 0.9296526508226691 f1 0.927232179216248\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 36.73897695541382 s\n",
      "Accuracy 0.929981718464351 precision 0.9299184784517649 specificity 0.808197816918445 recall 0.929981718464351 f1 0.927339824613961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 37.64609742164612 s\n",
      "Accuracy 0.9302376599634369 precision 0.9301692251121739 specificity 0.8086354345477181 recall 0.9302376599634369 f1 0.9276129039654059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 37.04181504249573 s\n",
      "Accuracy 0.9291773308957952 precision 0.9287770705342981 specificity 0.8126927613459459 recall 0.9291773308957952 f1 0.9267309061350543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 36.884976863861084 s\n",
      "Accuracy 0.926617915904936 precision 0.9267487821343858 specificity 0.8044099297995114 recall 0.926617915904936 f1 0.9237593035464158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 36.503347873687744 s\n",
      "Accuracy 0.9290310786106033 precision 0.928826318903039 specificity 0.81197830112575 recall 0.9290310786106033 f1 0.9265018447685796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 36.26702618598938 s\n",
      "Accuracy 0.9307861060329068 precision 0.9304890194104561 specificity 0.8172652063198095 recall 0.9307861060329068 f1 0.9284420046627774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 36.657768964767456 s\n",
      "Accuracy 0.9277879341864717 precision 0.9276010882044601 specificity 0.8050189701988067 recall 0.9277879341864717 f1 0.9250610238520806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 36.36523985862732 s\n",
      "Accuracy 0.9282632541133455 precision 0.9277663380864238 specificity 0.8101129087424987 recall 0.9282632541133455 f1 0.9257708606520718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 37.39563846588135 s\n",
      "Accuracy 0.930018281535649 precision 0.9296488253451899 specificity 0.8130950907497764 recall 0.930018281535649 f1 0.9275869669872332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 37.01897859573364 s\n",
      "Accuracy 0.9287385740402194 precision 0.9282023397941065 specificity 0.8141530272755759 recall 0.9287385740402194 f1 0.9263663022243688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 37.42797780036926 s\n",
      "Accuracy 0.9296526508226691 precision 0.9293147298481225 specificity 0.8145377542987817 recall 0.9296526508226691 f1 0.9272378723425644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 36.33897829055786 s\n",
      "Accuracy 0.9274954296160878 precision 0.9271402253918473 specificity 0.8066491402499992 recall 0.9274954296160878 f1 0.9248556518120857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 38.38645029067993 s\n",
      "Accuracy 0.9280438756855576 precision 0.92758771094548 specificity 0.8111928785436241 recall 0.9280438756855576 f1 0.9255593083758212\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 37.7629771232605 s\n",
      "Accuracy 0.9271663619744058 precision 0.9267003523850655 specificity 0.8102578490172222 recall 0.9271663619744058 f1 0.9246460468452219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 37.572531938552856 s\n",
      "Accuracy 0.9261425959780621 precision 0.9258510184404335 specificity 0.8022178961374694 recall 0.9261425959780621 f1 0.9233446131898232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 36.46704697608948 s\n",
      "Accuracy 0.9296526508226691 precision 0.9296420362074319 specificity 0.8114921651414734 recall 0.9296526508226691 f1 0.9270660748550941\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 38.37424921989441 s\n",
      "Accuracy 0.9341133455210238 precision 0.9334907764919249 specificity 0.8243715143184154 recall 0.9341133455210238 f1 0.9321027556534927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 36.207058906555176 s\n",
      "Accuracy 0.9309689213893967 precision 0.9305672162124236 specificity 0.8165316410402995 recall 0.9309689213893967 f1 0.9286459322718122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 36.1039776802063 s\n",
      "Accuracy 0.9303839122486289 precision 0.9299971274220961 specificity 0.815247735389558 recall 0.9303839122486289 f1 0.9280154353421062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 35.81697678565979 s\n",
      "Accuracy 0.929945155393053 precision 0.9297542770187865 specificity 0.8112480432474642 recall 0.929945155393053 f1 0.9274122004893501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 36.74297738075256 s\n",
      "Accuracy 0.9321023765996344 precision 0.931727935767342 specificity 0.818082214773176 recall 0.9321023765996344 f1 0.9298263398995902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 36.34297704696655 s\n",
      "Accuracy 0.9289945155393053 precision 0.9285341494897874 specificity 0.8108041624464146 recall 0.9289945155393053 f1 0.9265201282777864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 36.454978227615356 s\n",
      "Accuracy 0.9310420475319927 precision 0.9309681618428317 specificity 0.8145303083511881 recall 0.9310420475319927 f1 0.928571341327346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 35.60197830200195 s\n",
      "Accuracy 0.9255575868372944 precision 0.9253419052622416 specificity 0.7985300288447175 recall 0.9255575868372944 f1 0.9226300707374461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 36.617976665496826 s\n",
      "Accuracy 0.9295429616087751 precision 0.929323790062803 specificity 0.8115723507457381 recall 0.9295429616087751 f1 0.9270184657439733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 35.752978563308716 s\n",
      "Accuracy 0.9290676416819013 precision 0.9285801303742548 specificity 0.8111562179387414 recall 0.9290676416819013 f1 0.9266125038894479\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 36.725977659225464 s\n",
      "Accuracy 0.9275319926873857 precision 0.9271265079104776 specificity 0.813783575782904 recall 0.9275319926873857 f1 0.9250837168256796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 35.900978326797485 s\n",
      "Accuracy 0.9290310786106033 precision 0.9287378816616417 specificity 0.812075257554507 recall 0.9290310786106033 f1 0.9265320325395864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 36.689977169036865 s\n",
      "Accuracy 0.9318829981718464 precision 0.9316640543848683 specificity 0.8228427780433107 recall 0.9318829981718464 f1 0.9296595458989814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 36.909000396728516 s\n",
      "Accuracy 0.9281901279707495 precision 0.9280914303893915 specificity 0.8096748946610578 recall 0.9281901279707495 f1 0.9255574823346336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 37.65091300010681 s\n",
      "Accuracy 0.9274954296160878 precision 0.9267459856039943 specificity 0.8087181836556939 recall 0.9274954296160878 f1 0.9250482753692825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 37.65589737892151 s\n",
      "Accuracy 0.9305301645338209 precision 0.9300650709529756 specificity 0.812343582194393 recall 0.9305301645338209 f1 0.928123674919152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 37.309975385665894 s\n",
      "Accuracy 0.9278976234003656 precision 0.9276820643346539 specificity 0.8072422809056033 recall 0.9278976234003656 f1 0.9252358895219747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 37.23497939109802 s\n",
      "Accuracy 0.9314442413162706 precision 0.9309465336622972 specificity 0.816371941065881 recall 0.9314442413162706 f1 0.929159739550665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 37.06419014930725 s\n",
      "Accuracy 0.9277879341864717 precision 0.9273346151448698 specificity 0.8107207824255117 recall 0.9277879341864717 f1 0.9252861387298736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 36.48051071166992 s\n",
      "Accuracy 0.9282266910420476 precision 0.9277987539930953 specificity 0.8110292823594215 recall 0.9282266910420476 f1 0.9257319286785011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 36.63597869873047 s\n",
      "Accuracy 0.9307495429616087 precision 0.9304718842515761 specificity 0.8141210552457772 recall 0.9307495429616087 f1 0.9283261682350659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 36.355977058410645 s\n",
      "Accuracy 0.9277513711151737 precision 0.927482079575088 specificity 0.807002003507665 recall 0.9277513711151737 f1 0.9250976895927402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 36.3149778842926 s\n",
      "Accuracy 0.9263619744058501 precision 0.9259714199157281 specificity 0.8039079304806964 recall 0.9263619744058501 f1 0.9236430158869323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 36.40797758102417 s\n",
      "Accuracy 0.9272760511882998 precision 0.9271195142700234 specificity 0.8108073458245313 recall 0.9272760511882998 f1 0.9246708750607855\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 35.89700531959534 s\n",
      "Accuracy 0.9310420475319927 precision 0.9306565469658648 specificity 0.8167325246985917 recall 0.9310420475319927 f1 0.92871953905121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 37.75800085067749 s\n",
      "Accuracy 0.9292138939670932 precision 0.9286052129000539 specificity 0.8120159159662648 recall 0.9292138939670932 f1 0.9268258218278759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 37.24297618865967 s\n",
      "Accuracy 0.9271663619744058 precision 0.9266035161647693 specificity 0.8117995153611256 recall 0.9271663619744058 f1 0.9247183152794584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 37.16597890853882 s\n",
      "Accuracy 0.9297623400365631 precision 0.9292729248116696 specificity 0.8121043106528606 recall 0.9297623400365631 f1 0.9273437692777146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 36.9529767036438 s\n",
      "Accuracy 0.9290310786106033 precision 0.9285126008547923 specificity 0.8135585933962467 recall 0.9290310786106033 f1 0.9266435299643367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 37.639975786209106 s\n",
      "Accuracy 0.9305667276051188 precision 0.9302323765226528 specificity 0.8158400401870147 recall 0.9305667276051188 f1 0.9281979341071577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 36.29001784324646 s\n",
      "Accuracy 0.9285923217550274 precision 0.9282696268545314 specificity 0.8096421883582188 recall 0.9285923217550274 f1 0.9260362653078238\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 36.26610016822815 s\n",
      "Accuracy 0.9288117001828153 precision 0.9282708550210258 specificity 0.8137801457459881 recall 0.9288117001828153 f1 0.9264334814492788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 36.24366307258606 s\n",
      "Accuracy 0.9280804387568555 precision 0.9275818951203783 specificity 0.8119990936095494 recall 0.9280804387568555 f1 0.9256308548599428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 36.497997760772705 s\n",
      "Accuracy 0.9258500914076783 precision 0.9257870436080372 specificity 0.8050054192645563 recall 0.9258500914076783 f1 0.9230460476340198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 36.25800538063049 s\n",
      "Accuracy 0.9260694698354662 precision 0.9255961747047015 specificity 0.8035025120364986 recall 0.9260694698354662 f1 0.9233622310600013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 37.214085817337036 s\n",
      "Accuracy 0.9261425959780621 precision 0.9257388740789882 specificity 0.809396166274662 recall 0.9261425959780621 f1 0.9235608470417326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 36.56048083305359 s\n",
      "Accuracy 0.9307861060329068 precision 0.9304766938206609 specificity 0.8151521427183295 recall 0.9307861060329068 f1 0.928397396283269\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 36.85948896408081 s\n",
      "Accuracy 0.9297989031078611 precision 0.9294581761958781 specificity 0.8130998132644073 recall 0.9297989031078611 f1 0.927354037094467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 36.21797060966492 s\n",
      "Accuracy 0.9279707495429617 precision 0.9275414214479089 specificity 0.8089379120766298 recall 0.9279707495429617 f1 0.9254209043672558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 36.081329107284546 s\n",
      "Accuracy 0.9279707495429617 precision 0.9277398314744476 specificity 0.8057928329973507 recall 0.9279707495429617 f1 0.9252800912985724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 36.10568189620972 s\n",
      "Accuracy 0.9287385740402194 precision 0.9282702003801774 specificity 0.8130308535328383 recall 0.9287385740402194 f1 0.9263153728952355\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 36.35284876823425 s\n",
      "Accuracy 0.9291042047531992 precision 0.9288059996963607 specificity 0.811658317255664 recall 0.9291042047531992 f1 0.9265982644895681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 37.262022495269775 s\n",
      "Accuracy 0.9273491773308958 precision 0.9270971308884096 specificity 0.807028572811049 recall 0.9273491773308958 f1 0.9246826457958514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 37.01996970176697 s\n",
      "Accuracy 0.9277148080438757 precision 0.927254605652069 specificity 0.809159252693765 recall 0.9277148080438757 f1 0.9251759435004963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 37.42496991157532 s\n",
      "Accuracy 0.9286654478976234 precision 0.9284489527528037 specificity 0.8065953972359299 recall 0.9286654478976234 f1 0.9260041199774891\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 37.34296941757202 s\n",
      "Accuracy 0.9322486288848263 precision 0.9317606879153596 specificity 0.8193071665894844 recall 0.9322486288848263 f1 0.9300420848019783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 36.117971420288086 s\n",
      "Accuracy 0.9306764168190128 precision 0.9302394712460391 specificity 0.8148841942208643 recall 0.9306764168190128 f1 0.9283220210671731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 35.84197115898132 s\n",
      "Accuracy 0.929725776965265 precision 0.9290825480068247 specificity 0.8161314826145162 recall 0.929725776965265 f1 0.9274581950050386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 36.40197253227234 s\n",
      "Accuracy 0.9293235831809872 precision 0.9288990562666545 specificity 0.8106798630507287 recall 0.9293235831809872 f1 0.9268403830115937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 36.52996850013733 s\n",
      "Accuracy 0.929945155393053 precision 0.9295517065763147 specificity 0.8158572329857847 recall 0.929945155393053 f1 0.9275850930070085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 37.27451157569885 s\n",
      "Accuracy 0.9282266910420476 precision 0.927656480511726 specificity 0.8130557286185341 recall 0.9282266910420476 f1 0.9258311142627167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 37.08499050140381 s\n",
      "Accuracy 0.9312979890310786 precision 0.9309196913529209 specificity 0.8210312022175484 recall 0.9312979890310786 f1 0.9290757333441166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 36.73197293281555 s\n",
      "Accuracy 0.9317733089579525 precision 0.9313340550378003 specificity 0.8189532433080122 recall 0.9317733089579525 f1 0.9295330732057795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 36.65796947479248 s\n",
      "Accuracy 0.9288848263254114 precision 0.9285577115865784 specificity 0.8092372077977392 recall 0.9288848263254114 f1 0.9263262882380485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 36.23797130584717 s\n",
      "Accuracy 0.930127970749543 precision 0.9294932627540954 specificity 0.8151493347703569 recall 0.930127970749543 f1 0.9278411986490885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 36.30098056793213 s\n",
      "Accuracy 0.9322486288848263 precision 0.9317617937145616 specificity 0.8207311751743719 recall 0.9322486288848263 f1 0.9300737414088984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 35.96096992492676 s\n",
      "Accuracy 0.9306398537477149 precision 0.9301621084992849 specificity 0.8158969413838775 recall 0.9306398537477149 f1 0.928322427724158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 36.31197142601013 s\n",
      "Accuracy 0.9281170018281536 precision 0.9278994154871906 specificity 0.8086642162215737 recall 0.9281170018281536 f1 0.9254947009318379\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 36.67115521430969 s\n",
      "Accuracy 0.9321755027422304 precision 0.9320575674407446 specificity 0.8214332712868702 recall 0.9321755027422304 f1 0.9298945877051548\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 36.10908365249634 s\n",
      "Accuracy 0.9297989031078611 precision 0.9292051775224094 specificity 0.8176415116842662 recall 0.9297989031078611 f1 0.9275494232927585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 36.64853501319885 s\n",
      "Accuracy 0.9284460694698354 precision 0.9279423120109005 specificity 0.8105323535154041 recall 0.9284460694698354 f1 0.9259697214297569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 36.973318576812744 s\n",
      "Accuracy 0.9285923217550274 precision 0.9281323526057573 specificity 0.8114591868102581 recall 0.9285923217550274 f1 0.9261257965312021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 36.69796824455261 s\n",
      "Accuracy 0.9292138939670932 precision 0.9286906194403476 specificity 0.8136172984845383 recall 0.9292138939670932 f1 0.9268328232281099\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 36.44497108459473 s\n",
      "Accuracy 0.9286654478976234 precision 0.9283844378992764 specificity 0.8115379731520082 recall 0.9286654478976234 f1 0.9261427669665926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 36.4560329914093 s\n",
      "Accuracy 0.9295063985374772 precision 0.9292125181940817 specificity 0.8126857108805039 recall 0.9295063985374772 f1 0.9270310340497624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 36.16993832588196 s\n",
      "Accuracy 0.9266910420475319 precision 0.9263560763110467 specificity 0.8030934675736102 recall 0.9266910420475319 f1 0.9239403821286958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 36.39655661582947 s\n",
      "Accuracy 0.929981718464351 precision 0.9298736289696583 specificity 0.8140663509692754 recall 0.929981718464351 f1 0.9274901947529303\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 36.28397178649902 s\n",
      "Accuracy 0.930054844606947 precision 0.9297672312780471 specificity 0.8099327930598318 recall 0.930054844606947 f1 0.9275235891780524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 35.83697056770325 s\n",
      "Accuracy 0.9308592321755027 precision 0.9305943579763847 specificity 0.8167854353752033 recall 0.9308592321755027 f1 0.9284951113286152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 37.39732646942139 s\n",
      "Accuracy 0.930054844606947 precision 0.929676170338536 specificity 0.812300173171389 recall 0.930054844606947 f1 0.9276086980201756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 35.94397044181824 s\n",
      "Accuracy 0.9289945155393053 precision 0.9287160126337212 specificity 0.8111552526533929 recall 0.9289945155393053 f1 0.9264682075967707\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 36.914974212646484 s\n",
      "Accuracy 0.9315539305301646 precision 0.9313679880362689 specificity 0.8148793645556803 recall 0.9315539305301646 f1 0.9291347152037366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 36.22597098350525 s\n",
      "Accuracy 0.9302376599634369 precision 0.9296383601275127 specificity 0.8103215579243235 recall 0.9302376599634369 f1 0.9278259573828602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 37.86284828186035 s\n",
      "Accuracy 0.9283729433272395 precision 0.9278634189412852 specificity 0.8144291001680865 recall 0.9283729433272395 f1 0.9259912014167602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 36.7749707698822 s\n",
      "Accuracy 0.9293235831809872 precision 0.9290723908344418 specificity 0.8140058422387846 recall 0.9293235831809872 f1 0.9268622945476204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 36.51285171508789 s\n",
      "Accuracy 0.929981718464351 precision 0.9296153668039062 specificity 0.8111336877048656 recall 0.929981718464351 f1 0.9275027143297246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 37.015594482421875 s\n",
      "Accuracy 0.9329067641681902 precision 0.9325060251738512 specificity 0.8182555829123664 recall 0.9329067641681902 f1 0.9306584786793751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 39.342997789382935 s\n",
      "Accuracy 0.9297623400365631 precision 0.9295619808072645 specificity 0.8125125733025402 recall 0.9297623400365631 f1 0.9272583439187356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 37.085798025131226 s\n",
      "Accuracy 0.9311151736745886 precision 0.9309742422417364 specificity 0.8140826381401203 recall 0.9311151736745886 f1 0.9286555866868182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 37.931055784225464 s\n",
      "Accuracy 0.9300914076782449 precision 0.9297759946096734 specificity 0.8166424460545171 recall 0.9300914076782449 f1 0.9277263862252559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 36.393715381622314 s\n",
      "Accuracy 0.9287020109689214 precision 0.9282567267225786 specificity 0.8103161094246436 recall 0.9287020109689214 f1 0.9262050892583582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 37.103660583496094 s\n",
      "Accuracy 0.9281170018281536 precision 0.9279028957089984 specificity 0.8108599775159535 recall 0.9281170018281536 f1 0.9255465766726022\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 36.804431676864624 s\n",
      "Accuracy 0.9286654478976234 precision 0.9282878690719546 specificity 0.8092061723281578 recall 0.9286654478976234 f1 0.9261183651632605\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 36.22178339958191 s\n",
      "Accuracy 0.930164533820841 precision 0.9297852171816194 specificity 0.8141979041687245 recall 0.930164533820841 f1 0.9277650343398743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 35.70351195335388 s\n",
      "Accuracy 0.9302376599634369 precision 0.9300400059525951 specificity 0.8148597557653332 recall 0.9302376599634369 f1 0.9277965596678055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 34.02879810333252 s\n",
      "Accuracy 0.9306032906764168 precision 0.9300319777625814 specificity 0.821069894430825 recall 0.9306032906764168 f1 0.9284390973842434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 33.35910391807556 s\n",
      "Accuracy 0.9285923217550274 precision 0.9281470551382344 specificity 0.8103222340115428 recall 0.9285923217550274 f1 0.9260934191248459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 33.24158239364624 s\n",
      "Accuracy 0.9309323583180987 precision 0.9306230610215852 specificity 0.8138173575994186 recall 0.9309323583180987 f1 0.9285156759046322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 33.406803369522095 s\n",
      "Accuracy 0.9307495429616087 precision 0.9305148907813233 specificity 0.813790641072909 recall 0.9307495429616087 f1 0.9283049546716602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 34.092270851135254 s\n",
      "Accuracy 0.9307861060329068 precision 0.9305479023474521 specificity 0.8168276492976784 recall 0.9307861060329068 f1 0.9284131757285993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 34.3871374130249 s\n",
      "Accuracy 0.9307129798903108 precision 0.9303145920660688 specificity 0.8141601064266818 recall 0.9307129798903108 f1 0.9283293932156589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 33.53581357002258 s\n",
      "Accuracy 0.9315539305301646 precision 0.9310577242014659 specificity 0.8178224191387102 recall 0.9315539305301646 f1 0.9293040674242651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 33.21807265281677 s\n",
      "Accuracy 0.9280438756855576 precision 0.9278500930037885 specificity 0.8089854740804765 recall 0.9280438756855576 f1 0.9254205307423046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 33.9782018661499 s\n",
      "Accuracy 0.9289945155393053 precision 0.928528106600185 specificity 0.8173209588672505 recall 0.9289945155393053 f1 0.9266773885241194\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 33.61037635803223 s\n",
      "Accuracy 0.929725776965265 precision 0.9294995959311864 specificity 0.8120621331373824 recall 0.929725776965265 f1 0.9272185292993085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 33.24313402175903 s\n",
      "Accuracy 0.9302010968921389 precision 0.9298606671929176 specificity 0.8129310564549184 recall 0.9302010968921389 f1 0.9277598847453974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 33.74458026885986 s\n",
      "Accuracy 0.9287751371115174 precision 0.9280986522715204 specificity 0.8104018873021994 recall 0.9287751371115174 f1 0.9263654687600307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 33.47157311439514 s\n",
      "Accuracy 0.9307861060329068 precision 0.9306603636577061 specificity 0.8175213166602957 recall 0.9307861060329068 f1 0.9283945017826993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 33.35935306549072 s\n",
      "Accuracy 0.9306764168190128 precision 0.9303200938351706 specificity 0.8151954132165751 recall 0.9306764168190128 f1 0.9283020139945309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 33.35052180290222 s\n",
      "Accuracy 0.9284826325411335 precision 0.9280321193464321 specificity 0.8114647496510237 recall 0.9284826325411335 f1 0.9260109115399686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 33.76540470123291 s\n",
      "Accuracy 0.9295795246800731 precision 0.929359968247897 specificity 0.8142634135340734 recall 0.9295795246800731 f1 0.927119084620473\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 34.05985903739929 s\n",
      "Accuracy 0.9302376599634369 precision 0.9296046456635733 specificity 0.81860477559044 recall 0.9302376599634369 f1 0.9280333876998397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 33.60488963127136 s\n",
      "Accuracy 0.9306398537477149 precision 0.9305182674904212 specificity 0.816518327316528 recall 0.9306398537477149 f1 0.9282213301377978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 33.923433780670166 s\n",
      "Accuracy 0.9293601462522852 precision 0.9289504470121195 specificity 0.8139448882337286 recall 0.9293601462522852 f1 0.9269499688060692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 34.06285834312439 s\n",
      "Accuracy 0.9280804387568555 precision 0.9277195481790446 specificity 0.8064840904832897 recall 0.9280804387568555 f1 0.9254503649694428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 33.3166606426239 s\n",
      "Accuracy 0.9289945155393053 precision 0.9289247550298225 specificity 0.8085536817880409 recall 0.9289945155393053 f1 0.9263425073500859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 33.6548855304718 s\n",
      "Accuracy 0.9284826325411335 precision 0.9282795048439808 specificity 0.806933619877865 recall 0.9284826325411335 f1 0.9258215161139405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 33.6988844871521 s\n",
      "Accuracy 0.9251919561243145 precision 0.925047662540954 specificity 0.8078205972697073 recall 0.9251919561243145 f1 0.9224703870007117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 33.22076177597046 s\n",
      "Accuracy 0.9319561243144424 precision 0.9314120080855144 specificity 0.8165092607302307 recall 0.9319561243144424 f1 0.929701105715704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 33.43689846992493 s\n",
      "Accuracy 0.9284826325411335 precision 0.9280210730630877 specificity 0.8123014377826082 recall 0.9284826325411335 f1 0.926034844705072\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 33.63347816467285 s\n",
      "Accuracy 0.9271663619744058 precision 0.9266698762620436 specificity 0.8069693900009284 recall 0.9271663619744058 f1 0.9245756093154122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 33.802876472473145 s\n",
      "Accuracy 0.9292138939670932 precision 0.9289133235599085 specificity 0.813503379836203 recall 0.9292138939670932 f1 0.9267544878691646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 33.869391679763794 s\n",
      "Accuracy 0.9306032906764168 precision 0.9305327290038423 specificity 0.81089240592705 recall 0.9306032906764168 f1 0.9280391816776801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 33.172916889190674 s\n",
      "Accuracy 0.9257038391224863 precision 0.9250767244229374 specificity 0.804291883830633 recall 0.9257038391224863 f1 0.9230637453778626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 33.619887590408325 s\n",
      "Accuracy 0.9310054844606946 precision 0.9305891041999439 specificity 0.8164045666340972 recall 0.9310054844606946 f1 0.928685242001827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 33.49350094795227 s\n",
      "Accuracy 0.9293967093235832 precision 0.92927360398969 specificity 0.8110358745458728 recall 0.9293967093235832 f1 0.9268273834547084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 33.83673453330994 s\n",
      "Accuracy 0.930164533820841 precision 0.9298529254177168 specificity 0.8132477978974676 recall 0.930164533820841 f1 0.9277206155326643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 33.65058898925781 s\n",
      "Accuracy 0.9289579524680073 precision 0.9288010916242726 specificity 0.8093702568413881 recall 0.9289579524680073 f1 0.9263506428783929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 33.01089429855347 s\n",
      "Accuracy 0.9284095063985375 precision 0.9279637079115318 specificity 0.8090505674297357 recall 0.9284095063985375 f1 0.9258765873778151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 33.7173969745636 s\n",
      "Accuracy 0.9306398537477149 precision 0.9299529633738022 specificity 0.8140286716142054 recall 0.9306398537477149 f1 0.9283565486685377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 34.0404007434845 s\n",
      "Accuracy 0.929945155393053 precision 0.92982330263847 specificity 0.8131893640405377 recall 0.929945155393053 f1 0.9274366092815209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 33.85000157356262 s\n",
      "Accuracy 0.9311882998171847 precision 0.9307980299298747 specificity 0.816641497808528 recall 0.9311882998171847 f1 0.9288680045641796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 33.34189462661743 s\n",
      "Accuracy 0.9261791590493601 precision 0.9258407435008599 specificity 0.8060649326625707 recall 0.9261791590493601 f1 0.9234933338069614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 33.49639177322388 s\n",
      "Accuracy 0.9278610603290677 precision 0.9276556711442712 specificity 0.8075720275653323 recall 0.9278610603290677 f1 0.9252034461199692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 34.09285807609558 s\n",
      "Accuracy 0.9286288848263254 precision 0.9285309941900224 specificity 0.8091585539540093 recall 0.9286288848263254 f1 0.925992255026414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 33.85265636444092 s\n",
      "Accuracy 0.9319561243144424 precision 0.9318100830797207 specificity 0.8173150348181015 recall 0.9319561243144424 f1 0.9295874745357661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 34.12781071662903 s\n",
      "Accuracy 0.9276416819012797 precision 0.9272021431811562 specificity 0.808923744626862 recall 0.9276416819012797 f1 0.925088582027751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 33.97686409950256 s\n",
      "Accuracy 0.9283363802559415 precision 0.9280493957695155 specificity 0.8087717161619115 recall 0.9283363802559415 f1 0.9257428679248111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 33.636733293533325 s\n",
      "Accuracy 0.9319926873857404 precision 0.9316404088529237 specificity 0.8206936957397618 recall 0.9319926873857404 f1 0.9297660161819693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 33.12997889518738 s\n",
      "Accuracy 0.9272029250457038 precision 0.9270424421407797 specificity 0.8087611094339603 recall 0.9272029250457038 f1 0.9245475884585862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 33.69888353347778 s\n",
      "Accuracy 0.9277148080438757 precision 0.9275262388251664 specificity 0.8056429825554566 recall 0.9277148080438757 f1 0.9250021144625169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 33.15847039222717 s\n",
      "Accuracy 0.9274223034734917 precision 0.9273286637908936 specificity 0.8046520563162508 recall 0.9274223034734917 f1 0.9246506775390344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 33.55889296531677 s\n",
      "Accuracy 0.9289945155393053 precision 0.9288247312766745 specificity 0.8088947615923069 recall 0.9289945155393053 f1 0.9263805503596941\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 33.51634740829468 s\n",
      "Accuracy 0.9280804387568555 precision 0.9276029580253758 specificity 0.8079884221639856 recall 0.9280804387568555 f1 0.925526169355932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 33.07096004486084 s\n",
      "Accuracy 0.9295429616087751 precision 0.9293308807558236 specificity 0.8134619339151178 recall 0.9295429616087751 f1 0.9270606986184582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 33.24785041809082 s\n",
      "Accuracy 0.9292870201096892 precision 0.9291454906054079 specificity 0.8116959980388833 recall 0.9292870201096892 f1 0.926736680083976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 33.24248170852661 s\n",
      "Accuracy 0.9289579524680073 precision 0.9284381934125923 specificity 0.8167200406867664 recall 0.9289579524680073 f1 0.9266449068040572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 33.37889361381531 s\n",
      "Accuracy 0.929981718464351 precision 0.9294879826222565 specificity 0.8159969889018935 recall 0.929981718464351 f1 0.9276602902247496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 34.131855726242065 s\n",
      "Accuracy 0.9261791590493601 precision 0.9255658210605826 specificity 0.808095528469553 recall 0.9261791590493601 f1 0.9236393370222483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 33.412631034851074 s\n",
      "Accuracy 0.9304204753199269 precision 0.9300396374840062 specificity 0.8147526388778821 recall 0.9304204753199269 f1 0.9280391916095718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 33.34890389442444 s\n",
      "Accuracy 0.9251919561243145 precision 0.9246639196030922 specificity 0.8023903278154605 recall 0.9251919561243145 f1 0.9224575597842521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 33.31990909576416 s\n",
      "Accuracy 0.9312614259597807 precision 0.9308502225386636 specificity 0.8139407383074378 recall 0.9312614259597807 f1 0.9288876951895166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 33.55646347999573 s\n",
      "Accuracy 0.9286288848263254 precision 0.9281426166308374 specificity 0.8079801562122466 recall 0.9286288848263254 f1 0.9260884476151218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 34.07699799537659 s\n",
      "Accuracy 0.9302376599634369 precision 0.9299962200225236 specificity 0.810026158204497 recall 0.9302376599634369 f1 0.9276977175095598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 34.08842349052429 s\n",
      "Accuracy 0.9303107861060329 precision 0.9298354271939685 specificity 0.8155657117189982 recall 0.9303107861060329 f1 0.9279787756090844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 33.229755878448486 s\n",
      "Accuracy 0.9292870201096892 precision 0.928997919100978 specificity 0.8148879066783277 recall 0.9292870201096892 f1 0.9268579432328055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 33.326852798461914 s\n",
      "Accuracy 0.9279707495429617 precision 0.927574511431099 specificity 0.8091304824951464 recall 0.9279707495429617 f1 0.9254144352792106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 32.9599289894104 s\n",
      "Accuracy 0.9303839122486289 precision 0.9298560201273823 specificity 0.8154599865808915 recall 0.9303839122486289 f1 0.9280694773003655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 33.62088966369629 s\n",
      "Accuracy 0.9303473491773309 precision 0.9300987357334043 specificity 0.8167894730015421 recall 0.9303473491773309 f1 0.9279688765173545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 33.33990526199341 s\n",
      "Accuracy 0.9308957952468008 precision 0.9303908246864282 specificity 0.8196061507006998 recall 0.9308957952468008 f1 0.9286782983474499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 33.134918451309204 s\n",
      "Accuracy 0.9294332723948812 precision 0.929002814547601 specificity 0.8098933257022308 recall 0.9294332723948812 f1 0.9269355818677806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 32.755940675735474 s\n",
      "Accuracy 0.9291773308957952 precision 0.9286254647994466 specificity 0.8115950200412401 recall 0.9291773308957952 f1 0.92675765367871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 33.36790132522583 s\n",
      "Accuracy 0.9282632541133455 precision 0.9279849619451949 specificity 0.8078651901129743 recall 0.9282632541133455 f1 0.9256436535131509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 33.69588303565979 s\n",
      "Accuracy 0.9287020109689214 precision 0.928290511958109 specificity 0.8091352650324916 recall 0.9287020109689214 f1 0.9261652795335109\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 33.71888256072998 s\n",
      "Accuracy 0.929835466179159 precision 0.9293255098308995 specificity 0.8136708335930839 recall 0.929835466179159 f1 0.9274624728018708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 33.23291301727295 s\n",
      "Accuracy 0.92672760511883 precision 0.9263677201071853 specificity 0.805502865123565 recall 0.92672760511883 f1 0.9240456798783817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 33.372904777526855 s\n",
      "Accuracy 0.9277148080438757 precision 0.9271511938213467 specificity 0.811341921211093 recall 0.9277148080438757 f1 0.9252657898387032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 33.36390280723572 s\n",
      "Accuracy 0.9285923217550274 precision 0.928085684619417 specificity 0.8105371127062994 recall 0.9285923217550274 f1 0.9261199083664328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 33.730881214141846 s\n",
      "Accuracy 0.9310420475319927 precision 0.9305371873498751 specificity 0.8129253544126412 recall 0.9310420475319927 f1 0.9286730631840029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 33.680885553359985 s\n",
      "Accuracy 0.9281901279707495 precision 0.9281116313748461 specificity 0.8074737864830712 recall 0.9281901279707495 f1 0.9254984559152014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 33.76487922668457 s\n",
      "Accuracy 0.930054844606947 precision 0.929459859458126 specificity 0.8164480975101461 recall 0.930054844606947 f1 0.9277822552157773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 33.62188720703125 s\n",
      "Accuracy 0.9289213893967093 precision 0.9286377643229232 specificity 0.8100695232550899 recall 0.9289213893967093 f1 0.9263694429339437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 33.35390567779541 s\n",
      "Accuracy 0.9317733089579525 precision 0.9313493171136616 specificity 0.8174046144600474 recall 0.9317733089579525 f1 0.9294926918727225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 33.22791266441345 s\n",
      "Accuracy 0.9283729433272395 precision 0.928155393426792 specificity 0.8067530612212795 recall 0.9283729433272395 f1 0.9257096782304761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 33.13991928100586 s\n",
      "Accuracy 0.9297989031078611 precision 0.9293222510417121 specificity 0.8147433592420802 recall 0.9297989031078611 f1 0.927438703408787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 32.83693766593933 s\n",
      "Accuracy 0.9317367458866544 precision 0.9314397662340621 specificity 0.8210240642172988 recall 0.9317367458866544 f1 0.9294948760320925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 32.66094708442688 s\n",
      "Accuracy 0.9272760511882998 precision 0.9271217883802436 specificity 0.8083785497950543 recall 0.9272760511882998 f1 0.9246108779450568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 33.10292148590088 s\n",
      "Accuracy 0.9262157221206582 precision 0.9260119253392846 specificity 0.8072063232084467 recall 0.9262157221206582 f1 0.9235163213935935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 33.64488649368286 s\n",
      "Accuracy 0.9275319926873857 precision 0.9273184579816228 specificity 0.8071968995759167 recall 0.9275319926873857 f1 0.9248611898768206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 33.454899311065674 s\n",
      "Accuracy 0.9294332723948812 precision 0.92920242831857 specificity 0.8109902868787388 recall 0.9294332723948812 f1 0.9268965502351291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 32.62795090675354 s\n",
      "Accuracy 0.9291773308957952 precision 0.9288681510147314 specificity 0.8190960631247861 recall 0.9291773308957952 f1 0.9268519290189071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 33.33490610122681 s\n",
      "Accuracy 0.9295063985374772 precision 0.9294517117190391 specificity 0.8123518588589026 recall 0.9295063985374772 f1 0.9269499418610517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 33.153916358947754 s\n",
      "Accuracy 0.9289579524680073 precision 0.9285415453040431 specificity 0.8114220855683636 recall 0.9289579524680073 f1 0.9264825887908184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 33.80687713623047 s\n",
      "Accuracy 0.930164533820841 precision 0.9299079199104016 specificity 0.8150543937575093 recall 0.930164533820841 f1 0.9277450420561111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 32.858935832977295 s\n",
      "Accuracy 0.9290676416819013 precision 0.9285034088805357 specificity 0.8136474095722164 recall 0.9290676416819013 f1 0.9266994241149897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 33.10892152786255 s\n",
      "Accuracy 0.9295795246800731 precision 0.9293045362483517 specificity 0.8134695567753077 recall 0.9295795246800731 f1 0.9271179344947522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 32.879934310913086 s\n",
      "Accuracy 0.9274223034734917 precision 0.9276011592070437 specificity 0.8003980549677727 recall 0.9274223034734917 f1 0.9244688754703653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 32.84693479537964 s\n",
      "Accuracy 0.926435100548446 precision 0.9261924975383086 specificity 0.8083318403434006 recall 0.926435100548446 f1 0.9237799576510576\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 32.87393641471863 s\n",
      "Accuracy 0.930127970749543 precision 0.9298877900873879 specificity 0.8116631803565687 recall 0.930127970749543 f1 0.9276236357573155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 32.815937995910645 s\n",
      "Accuracy 0.930018281535649 precision 0.9296036292690485 specificity 0.8136818814096167 recall 0.930018281535649 f1 0.9276158748439566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 33.13391876220703 s\n",
      "Accuracy 0.9310420475319927 precision 0.930632048113589 specificity 0.8196890929768793 recall 0.9310420475319927 f1 0.9287955961733413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 33.639726400375366 s\n",
      "Accuracy 0.926508226691042 precision 0.9259981917984714 specificity 0.8068065931689589 recall 0.926508226691042 f1 0.9239052736781158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 33.32171869277954 s\n",
      "Accuracy 0.9278976234003656 precision 0.9276447822758528 specificity 0.8033356374121948 recall 0.9278976234003656 f1 0.9251524526222566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 33.27672028541565 s\n",
      "Accuracy 0.926873857404022 precision 0.926633517030971 specificity 0.8064464252390596 recall 0.926873857404022 f1 0.9241798800867728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 33.05972194671631 s\n",
      "Accuracy 0.9289945155393053 precision 0.9283989784751009 specificity 0.8122400693250779 recall 0.9289945155393053 f1 0.9266027787677498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 33.393717527389526 s\n",
      "Accuracy 0.9292504570383913 precision 0.9288870111749408 specificity 0.8124610242853124 recall 0.9292504570383913 f1 0.9267876212932333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 32.88972330093384 s\n",
      "Accuracy 0.9294332723948812 precision 0.928827064750995 specificity 0.816015819007995 recall 0.9294332723948812 f1 0.9271436390972653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 33.638715982437134 s\n",
      "Accuracy 0.9279707495429617 precision 0.9280813608620971 specificity 0.8039986023358614 recall 0.9279707495429617 f1 0.9251362831013257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 33.02272295951843 s\n",
      "Accuracy 0.9289213893967093 precision 0.9282498415498668 specificity 0.8116345941934927 recall 0.9289213893967093 f1 0.9265424119850029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 33.47522711753845 s\n",
      "Accuracy 0.9318829981718464 precision 0.9314742841024963 specificity 0.8143355157044257 recall 0.9318829981718464 f1 0.929529606228758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 33.08763933181763 s\n",
      "Accuracy 0.9292138939670932 precision 0.9286596349291399 specificity 0.8129648861967803 recall 0.9292138939670932 f1 0.9268284609386237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 33.051156759262085 s\n",
      "Accuracy 0.9297989031078611 precision 0.9293805537169586 specificity 0.81207586483732 recall 0.9297989031078611 f1 0.9273558635601492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 33.278594732284546 s\n",
      "Accuracy 0.9276416819012797 precision 0.9273111833947548 specificity 0.8099425170437652 recall 0.9276416819012797 f1 0.9250770845495383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 33.601418018341064 s\n",
      "Accuracy 0.929835466179159 precision 0.9291403156961788 specificity 0.8176287385452017 recall 0.929835466179159 f1 0.9276256903617279\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 33.83650302886963 s\n",
      "Accuracy 0.9284460694698354 precision 0.9282899531360559 specificity 0.8090956909814209 recall 0.9284460694698354 f1 0.9258217858608843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 33.479671478271484 s\n",
      "Accuracy 0.9287385740402194 precision 0.9283742820423203 specificity 0.8106683910302526 recall 0.9287385740402194 f1 0.9262235604531084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 33.32684326171875 s\n",
      "Accuracy 0.9302010968921389 precision 0.9298728884018009 specificity 0.8125642507368316 recall 0.9302010968921389 f1 0.9277473384691253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 33.83095836639404 s\n",
      "Accuracy 0.9314076782449726 precision 0.9311107361099745 specificity 0.8145918189441229 recall 0.9314076782449726 f1 0.9290139603489427\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 33.823057651519775 s\n",
      "Accuracy 0.9270566727605118 precision 0.9266949719458382 specificity 0.8092374259880354 recall 0.9270566727605118 f1 0.9244739899719681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 33.583451986312866 s\n",
      "Accuracy 0.9283729433272395 precision 0.9279435862390567 specificity 0.8068354241019092 recall 0.9283729433272395 f1 0.9257801628493214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 33.37204623222351 s\n",
      "Accuracy 0.9310786106032907 precision 0.930797196708167 specificity 0.8149182043497541 recall 0.9310786106032907 f1 0.9286810514149322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 34.02729249000549 s\n",
      "Accuracy 0.9283729433272395 precision 0.9278298458352349 specificity 0.8119017095723283 recall 0.9283729433272395 f1 0.9259422873870498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 33.78667950630188 s\n",
      "Accuracy 0.9303839122486289 precision 0.9300230344892184 specificity 0.8126949054777624 recall 0.9303839122486289 f1 0.9279474706203364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 33.336286306381226 s\n",
      "Accuracy 0.9273126142595978 precision 0.9267678827385432 specificity 0.811518416494208 recall 0.9273126142595978 f1 0.9248537360746251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 33.68508529663086 s\n",
      "Accuracy 0.9292504570383913 precision 0.9288406515749007 specificity 0.8106229763577767 recall 0.9292504570383913 f1 0.9267594959827296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 33.676610708236694 s\n",
      "Accuracy 0.9310786106032907 precision 0.9308255888880708 specificity 0.8163925715585209 recall 0.9310786106032907 f1 0.9287057679383482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 33.22071862220764 s\n",
      "Accuracy 0.9290310786106033 precision 0.9285896918003458 specificity 0.8109635874016816 recall 0.9290310786106033 f1 0.9265546837501389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 33.41804623603821 s\n",
      "Accuracy 0.9307861060329068 precision 0.930679360635243 specificity 0.8110124339457941 recall 0.9307861060329068 f1 0.9282391771180014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 32.76772475242615 s\n",
      "Accuracy 0.9297989031078611 precision 0.9292839136847921 specificity 0.8186015309392762 recall 0.9297989031078611 f1 0.9275429405600067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 33.36526966094971 s\n",
      "Accuracy 0.9306398537477149 precision 0.9305021893835482 specificity 0.8086865444540993 recall 0.9306398537477149 f1 0.9280452932603258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 33.913400650024414 s\n",
      "Accuracy 0.9315904936014625 precision 0.9315371849428764 specificity 0.8204403861991293 recall 0.9315904936014625 f1 0.9292580282103008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 33.83971643447876 s\n",
      "Accuracy 0.9282266910420476 precision 0.9276425449210672 specificity 0.8162014894865876 recall 0.9282266910420476 f1 0.92591234747287\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 33.10695242881775 s\n",
      "Accuracy 0.9258135283363803 precision 0.9253364292900911 specificity 0.8045772831194671 recall 0.9258135283363803 f1 0.9231295342483447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 33.629337549209595 s\n",
      "Accuracy 0.929835466179159 precision 0.9294917718258722 specificity 0.8131110184602233 recall 0.929835466179159 f1 0.9273925317451203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 34.24298572540283 s\n",
      "Accuracy 0.9300914076782449 precision 0.9301198983924888 specificity 0.8145761543606214 recall 0.9300914076782449 f1 0.9275741102113813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 33.528637647628784 s\n",
      "Accuracy 0.9312614259597807 precision 0.930872913274318 specificity 0.8131612351632079 recall 0.9312614259597807 f1 0.9288621646734898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 33.263869762420654 s\n",
      "Accuracy 0.9302010968921389 precision 0.9298076080269123 specificity 0.8131536108036838 recall 0.9302010968921389 f1 0.9277826761241821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 33.48559308052063 s\n",
      "Accuracy 0.9287751371115174 precision 0.9283175377364257 specificity 0.8132590497418487 recall 0.9287751371115174 f1 0.9263543235010596\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 33.58460068702698 s\n",
      "Accuracy 0.9310786106032907 precision 0.9307437805587109 specificity 0.8175897911807289 recall 0.9310786106032907 f1 0.9287595419178147\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 33.38174915313721 s\n",
      "Accuracy 0.9285191956124315 precision 0.9281770576419142 specificity 0.8103182145914916 recall 0.9285191956124315 f1 0.9259842709272417\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 33.40073323249817 s\n",
      "Accuracy 0.9308592321755027 precision 0.9305132928361862 specificity 0.8160486422067711 recall 0.9308592321755027 f1 0.9285044631119976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 33.75631284713745 s\n",
      "Accuracy 0.9307495429616087 precision 0.930481682719349 specificity 0.8141202876094931 recall 0.9307495429616087 f1 0.9283230300453621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 33.32827949523926 s\n",
      "Accuracy 0.9285923217550274 precision 0.9282793279810799 specificity 0.8125632352969845 recall 0.9285923217550274 f1 0.9261030616330826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 33.3809380531311 s\n",
      "Accuracy 0.9295063985374772 precision 0.9290509484459828 specificity 0.8168590729040931 recall 0.9295063985374772 f1 0.9271833233463633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 33.59122943878174 s\n",
      "Accuracy 0.9313345521023766 precision 0.9309923389297117 specificity 0.8123993778168432 recall 0.9313345521023766 f1 0.9289039518663195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 33.09172248840332 s\n",
      "Accuracy 0.9292138939670932 precision 0.9290940679277463 specificity 0.8124409768321879 recall 0.9292138939670932 f1 0.9266732160742217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 35.47354817390442 s\n",
      "Accuracy 0.9304570383912248 precision 0.9300099251160264 specificity 0.8176152442703908 recall 0.9304570383912248 f1 0.9281654181274904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 33.32247853279114 s\n",
      "Accuracy 0.9269835466179159 precision 0.9268673431899301 specificity 0.8041412928376297 recall 0.9269835466179159 f1 0.9241969172427903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 33.49700331687927 s\n",
      "Accuracy 0.9308957952468008 precision 0.9305063423034688 specificity 0.813962578795845 recall 0.9308957952468008 f1 0.9285081491911669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 33.687265396118164 s\n",
      "Accuracy 0.9296160877513712 precision 0.9292873914655702 specificity 0.8128989126473801 recall 0.9296160877513712 f1 0.9271590960191745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 33.5369656085968 s\n",
      "Accuracy 0.9291407678244973 precision 0.9285870732683786 specificity 0.8118050149173397 recall 0.9291407678244973 f1 0.9267260694815611\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 33.555397510528564 s\n",
      "Accuracy 0.9303107861060329 precision 0.9299437971286916 specificity 0.8115651125970952 recall 0.9303107861060329 f1 0.9278486073458211\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 33.278358697891235 s\n",
      "Accuracy 0.9293967093235832 precision 0.9290629875263234 specificity 0.8150659119840343 recall 0.9293967093235832 f1 0.9269883049916711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 33.280044078826904 s\n",
      "Accuracy 0.9278610603290677 precision 0.9272831432316421 specificity 0.8099160847972994 recall 0.9278610603290677 f1 0.9253851460739635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 33.09472107887268 s\n",
      "Accuracy 0.9296160877513712 precision 0.9292122951666678 specificity 0.811542186246311 recall 0.9296160877513712 f1 0.9271520072715793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 33.08283591270447 s\n",
      "Accuracy 0.929981718464351 precision 0.9298639174678415 specificity 0.8076183298009869 recall 0.929981718464351 f1 0.9273423413520582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 33.61222267150879 s\n",
      "Accuracy 0.9273857404021938 precision 0.9272864662152888 specificity 0.8089736577214841 recall 0.9273857404021938 f1 0.9247206781624739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 33.76943349838257 s\n",
      "Accuracy 0.9271663619744058 precision 0.9267723346807047 specificity 0.8109630389106353 recall 0.9271663619744058 f1 0.9246388340556901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 33.757648229599 s\n",
      "Accuracy 0.9295429616087751 precision 0.9292639677643483 specificity 0.8150743928320024 recall 0.9295429616087751 f1 0.927119665274928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 33.88629984855652 s\n",
      "Accuracy 0.9291042047531992 precision 0.9286601928039776 specificity 0.8068266002213269 recall 0.9291042047531992 f1 0.9265313002908421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 33.271196126937866 s\n",
      "Accuracy 0.9279707495429617 precision 0.9275742705979673 specificity 0.8071971876943917 recall 0.9279707495429617 f1 0.9253675464625322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 34.087703704833984 s\n",
      "Accuracy 0.9307495429616087 precision 0.9300912787447139 specificity 0.8154921677959824 recall 0.9307495429616087 f1 0.9284913943757648\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 33.64591026306152 s\n",
      "Accuracy 0.9305301645338209 precision 0.9301001473914464 specificity 0.8136660009152731 recall 0.9305301645338209 f1 0.9281423618615846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 33.32851219177246 s\n",
      "Accuracy 0.9289213893967093 precision 0.9287225529566252 specificity 0.8117676327657082 recall 0.9289213893967093 f1 0.9263832321871729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 33.62075710296631 s\n",
      "Accuracy 0.9304204753199269 precision 0.9301921083285812 specificity 0.8131062115000299 recall 0.9304204753199269 f1 0.9279517315966029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 33.80880117416382 s\n",
      "Accuracy 0.9295063985374772 precision 0.9291763097051905 specificity 0.8162032526354809 recall 0.9295063985374772 f1 0.9271255067490667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 34.179585695266724 s\n",
      "Accuracy 0.9294698354661791 precision 0.9290749201205345 specificity 0.8108720807323828 recall 0.9294698354661791 f1 0.9269840800298214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 33.2802460193634 s\n",
      "Accuracy 0.9305301645338209 precision 0.9300844097392194 specificity 0.8128590567343559 recall 0.9305301645338209 f1 0.9281289972410217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 33.54741382598877 s\n",
      "Accuracy 0.9280804387568555 precision 0.9276420390375774 specificity 0.8070617089382811 recall 0.9280804387568555 f1 0.9254902534488598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 32.91195774078369 s\n",
      "Accuracy 0.9304936014625228 precision 0.9300928140183026 specificity 0.811621507156347 recall 0.9304936014625228 f1 0.9280476346034364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 33.64371609687805 s\n",
      "Accuracy 0.9285923217550274 precision 0.9282238356486027 specificity 0.8093369006243973 recall 0.9285923217550274 f1 0.926043924421285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 33.93882417678833 s\n",
      "Accuracy 0.9280804387568555 precision 0.9278429496408237 specificity 0.8064911636040839 recall 0.9280804387568555 f1 0.9254110354870188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 33.343016386032104 s\n",
      "Accuracy 0.9253382084095064 precision 0.9250755589159666 specificity 0.8064063259710125 recall 0.9253382084095064 f1 0.9226203927261178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 33.383544921875 s\n",
      "Accuracy 0.9285923217550274 precision 0.9280932923301876 specificity 0.8140679527819105 recall 0.9285923217550274 f1 0.926202077711387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 33.17526602745056 s\n",
      "Accuracy 0.9321755027422304 precision 0.9318040928494966 specificity 0.8161162492837968 recall 0.9321755027422304 f1 0.9298555453104738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 33.07986283302307 s\n",
      "Accuracy 0.9304570383912248 precision 0.9304119983735123 specificity 0.8142468481881848 recall 0.9304570383912248 f1 0.9279601547600312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 33.62605690956116 s\n",
      "Accuracy 0.9326873857404022 precision 0.9325341988222813 specificity 0.8230248608810161 recall 0.9326873857404022 f1 0.9304612530760192\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 33.700364112854004 s\n",
      "Accuracy 0.9288482632541133 precision 0.9284100659411278 specificity 0.8117547820430344 recall 0.9288482632541133 f1 0.9263861741970422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 33.10584998130798 s\n",
      "Accuracy 0.9268007312614259 precision 0.9268562136591015 specificity 0.8072411387522554 recall 0.9268007312614259 f1 0.9240368781333989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 33.76891469955444 s\n",
      "Accuracy 0.9312614259597807 precision 0.9311199150696243 specificity 0.8152878760724925 recall 0.9312614259597807 f1 0.9288323598534115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 33.58571982383728 s\n",
      "Accuracy 0.9296526508226691 precision 0.929270484814277 specificity 0.8108517220743978 recall 0.9296526508226691 f1 0.9271657539954559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 33.50788927078247 s\n",
      "Accuracy 0.9296160877513712 precision 0.9291736109061708 specificity 0.8166102440153147 recall 0.9296160877513712 f1 0.9272845701248036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 33.56862497329712 s\n",
      "Accuracy 0.930274223034735 precision 0.9299351446449181 specificity 0.8162443469329478 recall 0.930274223034735 f1 0.9279109994424297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 33.78340196609497 s\n",
      "Accuracy 0.9279341864716636 precision 0.9276421938952334 specificity 0.8130963046305867 recall 0.9279341864716636 f1 0.9254389229087521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 33.09572148323059 s\n",
      "Accuracy 0.9280804387568555 precision 0.9276642376598881 specificity 0.8105153560654977 recall 0.9280804387568555 f1 0.9255665064005844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 32.59972524642944 s\n",
      "Accuracy 0.9305667276051188 precision 0.9304764334378584 specificity 0.8151398664195187 recall 0.9305667276051188 f1 0.928105802708223\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 33.16298794746399 s\n",
      "Accuracy 0.9292504570383913 precision 0.9291637192072724 specificity 0.8105661010786565 recall 0.9292504570383913 f1 0.9266563297239151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 33.043694734573364 s\n",
      "Accuracy 0.9273126142595978 precision 0.9266729905417175 specificity 0.8078261713634086 recall 0.9273126142595978 f1 0.9247975104763928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 33.925713300704956 s\n",
      "Accuracy 0.9292138939670932 precision 0.9289848066271365 specificity 0.8141175828713404 recall 0.9292138939670932 f1 0.9267462650013916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 33.35002088546753 s\n",
      "Accuracy 0.9314442413162706 precision 0.9311208139188395 specificity 0.8193126795373885 recall 0.9314442413162706 f1 0.9291672105292362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 33.45962309837341 s\n",
      "Accuracy 0.9277513711151737 precision 0.9272417182827459 specificity 0.8059793531618689 recall 0.9277513711151737 f1 0.9251526073502625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 33.25771903991699 s\n",
      "Accuracy 0.9304204753199269 precision 0.9299651156334336 specificity 0.817498067922319 recall 0.9304204753199269 f1 0.928128365070858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 33.82669162750244 s\n",
      "Accuracy 0.9295063985374772 precision 0.9292493340796337 specificity 0.812542775328896 recall 0.9295063985374772 f1 0.9270159319548329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 33.43371939659119 s\n",
      "Accuracy 0.9285557586837294 precision 0.9281781272799435 specificity 0.8096953469265292 recall 0.9285557586837294 f1 0.9260182829787352\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 33.22772145271301 s\n",
      "Accuracy 0.9292138939670932 precision 0.9289021045826342 specificity 0.8104761656458845 recall 0.9292138939670932 f1 0.9266864053783356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 32.983529806137085 s\n",
      "Accuracy 0.9282266910420476 precision 0.9276747361443575 specificity 0.8099853372827487 recall 0.9282266910420476 f1 0.9257500526192505\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 33.66126298904419 s\n",
      "Accuracy 0.9296160877513712 precision 0.9294278260706459 specificity 0.804995363513858 recall 0.9296160877513712 f1 0.9269282378531848\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 32.74527287483215 s\n",
      "Accuracy 0.9305667276051188 precision 0.9303380576067063 specificity 0.8106416919747138 recall 0.9305667276051188 f1 0.9280438286858823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 33.32346320152283 s\n",
      "Accuracy 0.9288848263254114 precision 0.9285109275963573 specificity 0.8136897065733217 recall 0.9288848263254114 f1 0.9264478386943754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 33.50318241119385 s\n",
      "Accuracy 0.930164533820841 precision 0.9298276223597004 specificity 0.817308368383519 recall 0.930164533820841 f1 0.9278233268553476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 33.706788063049316 s\n",
      "Accuracy 0.9279341864716636 precision 0.9278584808536422 specificity 0.8085241671130704 recall 0.9279341864716636 f1 0.9252619372959081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 33.59214472770691 s\n",
      "Accuracy 0.9292138939670932 precision 0.9287602411509431 specificity 0.8111267891384863 recall 0.9292138939670932 f1 0.9267491327370753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 33.39231777191162 s\n",
      "Accuracy 0.9320292504570384 precision 0.9316079526418357 specificity 0.8167372739706564 recall 0.9320292504570384 f1 0.9297373823835234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 33.15672159194946 s\n",
      "Accuracy 0.9284460694698354 precision 0.9275561586505219 specificity 0.8127052942832542 recall 0.9284460694698354 f1 0.9261743753453382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 33.781333208084106 s\n",
      "Accuracy 0.9281535648994516 precision 0.9276507657806607 specificity 0.8084501567907794 recall 0.9281535648994516 f1 0.9256207771732665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 33.503719091415405 s\n",
      "Accuracy 0.9286654478976234 precision 0.9284747294185901 specificity 0.8073552675977806 recall 0.9286654478976234 f1 0.9260144025421062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 33.299720287323 s\n",
      "Accuracy 0.9292870201096892 precision 0.9290941122092291 specificity 0.8132448901045412 recall 0.9292870201096892 f1 0.9267889117874656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 33.7743980884552 s\n",
      "Accuracy 0.9295063985374772 precision 0.9289145586191061 specificity 0.8100218931316316 recall 0.9295063985374772 f1 0.9270701733854013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 33.168301820755005 s\n",
      "Accuracy 0.9291773308957952 precision 0.9286794594271822 specificity 0.8106334449905971 recall 0.9291773308957952 f1 0.9267154735126509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 33.219918966293335 s\n",
      "Accuracy 0.929835466179159 precision 0.929237272046458 specificity 0.8132464139350787 recall 0.929835466179159 f1 0.92748455220436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 33.21714115142822 s\n",
      "Accuracy 0.930127970749543 precision 0.9299569475097977 specificity 0.8120727358167079 recall 0.930127970749543 f1 0.927611800024563\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 33.09593749046326 s\n",
      "Accuracy 0.9324314442413163 precision 0.9322571102400441 specificity 0.8191288192691905 recall 0.9324314442413163 f1 0.9301208155506374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 33.47216510772705 s\n",
      "Accuracy 0.9297989031078611 precision 0.9295920226925792 specificity 0.8149032132759553 recall 0.9297989031078611 f1 0.9273535412592431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 33.64042925834656 s\n",
      "Accuracy 0.9287385740402194 precision 0.9282746525288015 specificity 0.8155049629205758 recall 0.9287385740402194 f1 0.9263729489825886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 33.1649374961853 s\n",
      "Accuracy 0.9291773308957952 precision 0.9289554085463475 specificity 0.8087041316064509 recall 0.9291773308957952 f1 0.9265785777383331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 33.178935527801514 s\n",
      "Accuracy 0.9291407678244973 precision 0.928395765001667 specificity 0.8141833643080975 recall 0.9291407678244973 f1 0.9268563746450419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 33.71451497077942 s\n",
      "Accuracy 0.9246435100548446 precision 0.9242743072895309 specificity 0.8041827161536611 recall 0.9246435100548446 f1 0.9218901852526734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 33.93290877342224 s\n",
      "Accuracy 0.9282266910420476 precision 0.9278186557746372 specificity 0.8110686112755132 recall 0.9282266910420476 f1 0.925726135483095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 32.73798131942749 s\n",
      "Accuracy 0.9285923217550274 precision 0.92814808307055 specificity 0.8140662468657692 recall 0.9285923217550274 f1 0.9261828831334477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 34.230066537857056 s\n",
      "Accuracy 0.9282998171846435 precision 0.9279072112646599 specificity 0.8097713727129396 recall 0.9282998171846435 f1 0.9257641791996306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 33.965182304382324 s\n",
      "Accuracy 0.9307495429616087 precision 0.9302905203213737 specificity 0.8126355576140566 recall 0.9307495429616087 f1 0.9283520500108927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 33.48395538330078 s\n",
      "Accuracy 0.9305667276051188 precision 0.930245491678049 specificity 0.8150456744283645 recall 0.9305667276051188 f1 0.9281752867886978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 33.34316158294678 s\n",
      "Accuracy 0.9324314442413163 precision 0.9318441356375656 specificity 0.8218739944276507 recall 0.9324314442413163 f1 0.9303225620345525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 33.03136944770813 s\n",
      "Accuracy 0.9295063985374772 precision 0.9294105914426802 specificity 0.8086331209374931 recall 0.9295063985374772 f1 0.926874438756374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 33.31040143966675 s\n",
      "Accuracy 0.9297623400365631 precision 0.9295767501176475 specificity 0.8079991309167666 recall 0.9297623400365631 f1 0.9271477676803389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 33.58849024772644 s\n",
      "Accuracy 0.9312614259597807 precision 0.9312674537580261 specificity 0.8142723280862137 recall 0.9312614259597807 f1 0.928765973057988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 33.58998656272888 s\n",
      "Accuracy 0.930164533820841 precision 0.9299572993482901 specificity 0.8124829690420444 recall 0.930164533820841 f1 0.9276697626541196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 33.85799956321716 s\n",
      "Accuracy 0.9276051188299818 precision 0.9273810898642348 specificity 0.8105443268668947 recall 0.9276051188299818 f1 0.9250204986877478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 33.27494525909424 s\n",
      "Accuracy 0.9292504570383913 precision 0.9286124496458238 specificity 0.8137191252942619 recall 0.9292504570383913 f1 0.9269148476085425\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 34.04237461090088 s\n",
      "Accuracy 0.9280073126142596 precision 0.9274496337358394 specificity 0.8079144784926591 recall 0.9280073126142596 f1 0.925478042145665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 34.2462637424469 s\n",
      "Accuracy 0.9319926873857404 precision 0.9315993489370953 specificity 0.8166043602741069 recall 0.9319926873857404 f1 0.9296876195724995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 34.36247181892395 s\n",
      "Accuracy 0.9304204753199269 precision 0.9301307861187613 specificity 0.8164995573155341 recall 0.9304204753199269 f1 0.9280497316160309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 34.27663707733154 s\n",
      "Accuracy 0.9300914076782449 precision 0.929818602586366 specificity 0.8153905123352037 recall 0.9300914076782449 f1 0.9276835315737867\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 33.788121461868286 s\n",
      "Accuracy 0.9312979890310786 precision 0.9307748466778277 specificity 0.8149033489496229 recall 0.9312979890310786 f1 0.9289861153960314\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 33.58487915992737 s\n",
      "Accuracy 0.9284826325411335 precision 0.9284852587507328 specificity 0.8102166632822241 recall 0.9284826325411335 f1 0.9258390939138867\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 33.58182454109192 s\n",
      "Accuracy 0.9283363802559415 precision 0.9278957769834743 specificity 0.8122597096405508 recall 0.9283363802559415 f1 0.9258776586838107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 33.57093620300293 s\n",
      "Accuracy 0.9300914076782449 precision 0.9298413922695844 specificity 0.8125324445923541 recall 0.9300914076782449 f1 0.9276097292001624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 33.332133293151855 s\n",
      "Accuracy 0.9281170018281536 precision 0.927828223499757 specificity 0.8081978893513234 recall 0.9281170018281536 f1 0.9255058572642293\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 33.47226548194885 s\n",
      "Accuracy 0.9297623400365631 precision 0.9293323722290684 specificity 0.8122856330639189 recall 0.9297623400365631 f1 0.9273274839149239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 34.04307842254639 s\n",
      "Accuracy 0.9284460694698354 precision 0.9278853415745979 specificity 0.8126521133912057 recall 0.9284460694698354 f1 0.92604126937953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 33.549179792404175 s\n",
      "Accuracy 0.9312979890310786 precision 0.930752173588651 specificity 0.8127976147043803 recall 0.9312979890310786 f1 0.9289457716650368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 33.6493935585022 s\n",
      "Accuracy 0.9304570383912248 precision 0.930007732399281 specificity 0.8170459112328972 recall 0.9304570383912248 f1 0.9281529823142716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 33.52393412590027 s\n",
      "Accuracy 0.9282266910420476 precision 0.9279043677768222 specificity 0.8124219015523432 recall 0.9282266910420476 f1 0.9257303252548199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 33.733513832092285 s\n",
      "Accuracy 0.9311882998171847 precision 0.9311518927105343 specificity 0.8177505265860143 recall 0.9311882998171847 f1 0.928782863605765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 33.73841094970703 s\n",
      "Accuracy 0.930274223034735 precision 0.9299822426573874 specificity 0.8152356863005721 recall 0.930274223034735 f1 0.9278722655033124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 33.95923399925232 s\n",
      "Accuracy 0.930274223034735 precision 0.9299228701092126 specificity 0.8126973318908638 recall 0.930274223034735 f1 0.9278325647665231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 32.97506308555603 s\n",
      "Accuracy 0.9291042047531992 precision 0.9285757675696643 specificity 0.8092685377990247 recall 0.9291042047531992 f1 0.9266190729935935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 33.314945459365845 s\n",
      "Accuracy 0.9284095063985375 precision 0.927986324782099 specificity 0.8124996656971442 recall 0.9284095063985375 f1 0.9259519508558773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 33.89513039588928 s\n",
      "Accuracy 0.9293235831809872 precision 0.9289921539988961 specificity 0.808980196158626 recall 0.9293235831809872 f1 0.9267691355617413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 33.19141912460327 s\n",
      "Accuracy 0.9264716636197441 precision 0.926113032726877 specificity 0.8063785465663207 recall 0.9264716636197441 f1 0.9238060020770797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 33.55108308792114 s\n",
      "Accuracy 0.9246800731261426 precision 0.9244285485076795 specificity 0.8040069111920789 recall 0.9246800731261426 f1 0.921885057338639\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 33.20010495185852 s\n",
      "Accuracy 0.9305667276051188 precision 0.9303300211149748 specificity 0.8107528064491234 recall 0.9305667276051188 f1 0.9280489139664035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 34.00564098358154 s\n",
      "Accuracy 0.930054844606947 precision 0.9296815345354048 specificity 0.8154607050210675 recall 0.930054844606947 f1 0.9276807545721409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 33.08012366294861 s\n",
      "Accuracy 0.9292870201096892 precision 0.9290630365121669 specificity 0.812700154612053 recall 0.9292870201096892 f1 0.9267857018954043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 34.252777099609375 s\n",
      "Accuracy 0.929725776965265 precision 0.9292742800285313 specificity 0.8147876996591366 recall 0.929725776965265 f1 0.9273565098345625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 33.6949348449707 s\n",
      "Accuracy 0.9313711151736745 precision 0.931203555785724 specificity 0.8155061950744561 recall 0.9313711151736745 f1 0.9289570131251159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 33.871936321258545 s\n",
      "Accuracy 0.9292870201096892 precision 0.928875775988402 specificity 0.8077908060986012 recall 0.9292870201096892 f1 0.9267298806391981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 33.64393496513367 s\n",
      "Accuracy 0.9282632541133455 precision 0.927679013804588 specificity 0.8112091868315362 recall 0.9282632541133455 f1 0.9258287398249527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 34.51493525505066 s\n",
      "Accuracy 0.9251188299817185 precision 0.9246404658915662 specificity 0.8048423093309143 recall 0.9251188299817185 f1 0.9224283522418102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 34.53393340110779 s\n",
      "Accuracy 0.9295429616087751 precision 0.9291405091568895 specificity 0.8127306877180981 recall 0.9295429616087751 f1 0.9271050749726004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 33.50193691253662 s\n",
      "Accuracy 0.9287751371115174 precision 0.9285416576397865 specificity 0.8083393216224474 recall 0.9287751371115174 f1 0.9261631332236877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 33.97993302345276 s\n",
      "Accuracy 0.9260329067641682 precision 0.9257599696464446 specificity 0.8070598307574517 recall 0.9260329067641682 f1 0.9233480386160868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 33.2909369468689 s\n",
      "Accuracy 0.9277879341864717 precision 0.9275078053768383 specificity 0.8096285915351906 recall 0.9277879341864717 f1 0.9252022612623534\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 33.94493794441223 s\n",
      "Accuracy 0.9288117001828153 precision 0.9283166394337865 specificity 0.8115583194640119 recall 0.9288117001828153 f1 0.926363934296246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 33.64093351364136 s\n",
      "Accuracy 0.9315904936014625 precision 0.9312545351126637 specificity 0.8207409890149184 recall 0.9315904936014625 f1 0.9293524932899072\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 33.0479371547699 s\n",
      "Accuracy 0.9297623400365631 precision 0.9295090961949705 specificity 0.810857628447901 recall 0.9297623400365631 f1 0.9272360125081884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 34.09993290901184 s\n",
      "Accuracy 0.9277513711151737 precision 0.9277192337464917 specificity 0.8048990810347175 recall 0.9277513711151737 f1 0.924974634168174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 33.41893672943115 s\n",
      "Accuracy 0.9280073126142596 precision 0.9277328813052185 specificity 0.8053676612978177 recall 0.9280073126142596 f1 0.9253207496400594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 33.23193693161011 s\n",
      "Accuracy 0.9288848263254114 precision 0.9288038731381585 specificity 0.8063562087256 recall 0.9288848263254114 f1 0.9261814235388636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 33.6179358959198 s\n",
      "Accuracy 0.9281535648994516 precision 0.927894270063583 specificity 0.8088078804160721 recall 0.9281535648994516 f1 0.9255485213375377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 33.06693744659424 s\n",
      "Accuracy 0.9280804387568555 precision 0.927733265617305 specificity 0.8076502286139156 recall 0.9280804387568555 f1 0.9254741666820316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 33.23893713951111 s\n",
      "Accuracy 0.9292504570383913 precision 0.9291994475091221 specificity 0.8096569096187134 recall 0.9292504570383913 f1 0.9266243232749252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 33.247934103012085 s\n",
      "Accuracy 0.9296892138939671 precision 0.9293642386002181 specificity 0.8109404079874983 recall 0.9296892138939671 f1 0.9271863283502316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 33.101937770843506 s\n",
      "Accuracy 0.9280438756855576 precision 0.9278560523820535 specificity 0.807732265852777 recall 0.9280438756855576 f1 0.9253883973060778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 33.19193696975708 s\n",
      "Accuracy 0.9292138939670932 precision 0.9286235918644886 specificity 0.812932292373942 recall 0.9292138939670932 f1 0.9268408977320692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 32.9229371547699 s\n",
      "Accuracy 0.9293601462522852 precision 0.9288395486998863 specificity 0.8097918888857258 recall 0.9293601462522852 f1 0.9268898409281399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 33.21893644332886 s\n",
      "Accuracy 0.9278976234003656 precision 0.9276324161591786 specificity 0.8103538574529437 recall 0.9278976234003656 f1 0.9253268712418644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 33.97893571853638 s\n",
      "Accuracy 0.9269104204753199 precision 0.9266475459104712 specificity 0.8050261364811081 recall 0.9269104204753199 f1 0.9241891869571205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 32.946937561035156 s\n",
      "Accuracy 0.9281535648994516 precision 0.9276343773387419 specificity 0.8112906029892922 recall 0.9281535648994516 f1 0.9256954775267455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 33.044936418533325 s\n",
      "Accuracy 0.9282632541133455 precision 0.9283057565979427 specificity 0.8077991514994249 recall 0.9282632541133455 f1 0.925545942474476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 33.66193509101868 s\n",
      "Accuracy 0.9307129798903108 precision 0.9304258341566124 specificity 0.814473668033122 recall 0.9307129798903108 f1 0.9283000727997864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 33.152936935424805 s\n",
      "Accuracy 0.9276416819012797 precision 0.9274691589113668 specificity 0.8086762268852729 recall 0.9276416819012797 f1 0.924996450921012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 33.359936237335205 s\n",
      "Accuracy 0.9274954296160878 precision 0.9269651519218209 specificity 0.8094176130363158 recall 0.9274954296160878 f1 0.9249832035113618\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 33.25793671607971 s\n",
      "Accuracy 0.929981718464351 precision 0.9295453005027638 specificity 0.8161633391486538 recall 0.929981718464351 f1 0.9276441299356667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 32.897937536239624 s\n",
      "Accuracy 0.9293601462522852 precision 0.9288709716837887 specificity 0.8127502265842034 recall 0.9293601462522852 f1 0.9269491050169664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 32.97793507575989 s\n",
      "Accuracy 0.930164533820841 precision 0.9296787910859994 specificity 0.8130413629480011 recall 0.930164533820841 f1 0.9277744462433812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 33.31893467903137 s\n",
      "Accuracy 0.9295063985374772 precision 0.9288414029187483 specificity 0.812930143310095 recall 0.9295063985374772 f1 0.927167056605959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 33.361934661865234 s\n",
      "Accuracy 0.9272029250457038 precision 0.926677385694342 specificity 0.8115620040894436 recall 0.9272029250457038 f1 0.9247362515371603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 33.33593702316284 s\n",
      "Accuracy 0.9295795246800731 precision 0.929426883803095 specificity 0.8093444463034141 recall 0.9295795246800731 f1 0.926982858475558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 33.16093683242798 s\n",
      "Accuracy 0.930164533820841 precision 0.9297575156033719 specificity 0.8170394892087004 recall 0.930164533820841 f1 0.9278405631638874\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 32.855937480926514 s\n",
      "Accuracy 0.9293235831809872 precision 0.9288723507352388 specificity 0.8117118531432473 recall 0.9293235831809872 f1 0.9268740097968994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 33.63893437385559 s\n",
      "Accuracy 0.9304936014625228 precision 0.9299896843627822 specificity 0.8166818231129961 recall 0.9304936014625228 f1 0.9282010029215797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 33.297935962677 s\n",
      "Accuracy 0.92672760511883 precision 0.9260847242731827 specificity 0.8062532320761887 recall 0.92672760511883 f1 0.9241630988643141\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 33.24193859100342 s\n",
      "Accuracy 0.9294698354661791 precision 0.9287248693684994 specificity 0.8108891940544334 recall 0.9294698354661791 f1 0.9271123364946569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 33.16593408584595 s\n",
      "Accuracy 0.9287020109689214 precision 0.9284166243521383 specificity 0.8094945169863753 recall 0.9287020109689214 f1 0.9261325723553088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 33.05993413925171 s\n",
      "Accuracy 0.9302376599634369 precision 0.9298991357768444 specificity 0.8175458012471342 recall 0.9302376599634369 f1 0.9279037829869402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 33.4759361743927 s\n",
      "Accuracy 0.9284826325411335 precision 0.9280922860157568 specificity 0.8130287596954819 recall 0.9284826325411335 f1 0.9260280156557219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 33.510937213897705 s\n",
      "Accuracy 0.926435100548446 precision 0.9261589288189743 specificity 0.810126984758273 recall 0.926435100548446 f1 0.9238350593561157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 33.353936195373535 s\n",
      "Accuracy 0.9275685557586837 precision 0.9270964580807737 specificity 0.8079706033958488 recall 0.9275685557586837 f1 0.9250018857856088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 33.36993622779846 s\n",
      "Accuracy 0.929945155393053 precision 0.9297452779300203 specificity 0.8118346328501119 recall 0.929945155393053 f1 0.9274286929350687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 34.018935441970825 s\n",
      "Accuracy 0.9293601462522852 precision 0.9288314568238457 specificity 0.8130454451344756 recall 0.9293601462522852 f1 0.9269701381594988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 33.37893581390381 s\n",
      "Accuracy 0.9280073126142596 precision 0.9275469468032769 specificity 0.8080483346117935 recall 0.9280073126142596 f1 0.9254471514593047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 33.70193672180176 s\n",
      "Accuracy 0.9321389396709323 precision 0.9318738657992273 specificity 0.8129072690459428 recall 0.9321389396709323 f1 0.9297113538696627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 33.15093660354614 s\n",
      "Accuracy 0.9306398537477149 precision 0.9301283773928212 specificity 0.8123110556075857 recall 0.9306398537477149 f1 0.9282510286060105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 33.463934659957886 s\n",
      "Accuracy 0.9281170018281536 precision 0.9279151602979133 specificity 0.8089271661952281 recall 0.9281170018281536 f1 0.9254961708932813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 32.555936098098755 s\n",
      "Accuracy 0.9293967093235832 precision 0.9290734114079028 specificity 0.8126881333329043 recall 0.9293967093235832 f1 0.9269288332315051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 33.32293701171875 s\n",
      "Accuracy 0.9286288848263254 precision 0.9283317564049879 specificity 0.8095835494592806 recall 0.9286288848263254 f1 0.9260638952498572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 33.382935523986816 s\n",
      "Accuracy 0.9307495429616087 precision 0.9306160231056462 specificity 0.811628632479442 recall 0.9307495429616087 f1 0.9282240891218017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 33.4839346408844 s\n",
      "Accuracy 0.929835466179159 precision 0.9295004729405966 specificity 0.8145233071219093 recall 0.929835466179159 f1 0.927422760962182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 32.76193642616272 s\n",
      "Accuracy 0.9295429616087751 precision 0.9292599925684797 specificity 0.8088601937099722 recall 0.9295429616087751 f1 0.9269745534128135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 32.81193518638611 s\n",
      "Accuracy 0.926837294332724 precision 0.9262015095931833 specificity 0.808740069260511 recall 0.926837294332724 f1 0.9243343243598318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 33.7949378490448 s\n",
      "Accuracy 0.9306032906764168 precision 0.9301074009630529 specificity 0.817541989922476 recall 0.9306032906764168 f1 0.9283297478062129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 33.46293520927429 s\n",
      "Accuracy 0.9297989031078611 precision 0.9296588316006238 specificity 0.8120926123997242 recall 0.9297989031078611 f1 0.9272673764343065\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 33.42493295669556 s\n",
      "Accuracy 0.9285923217550274 precision 0.9281585981068822 specificity 0.813671549498567 recall 0.9285923217550274 f1 0.9261698167326012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 32.91193461418152 s\n",
      "Accuracy 0.930127970749543 precision 0.9295983098997376 specificity 0.816560080018158 recall 0.930127970749543 f1 0.9278352291529651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 33.247936487197876 s\n",
      "Accuracy 0.9308592321755027 precision 0.930556955567481 specificity 0.8128392095519742 recall 0.9308592321755027 f1 0.9284163231124486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 32.90294814109802 s\n",
      "Accuracy 0.933564899451554 precision 0.9333597106877433 specificity 0.8202081397223803 recall 0.933564899451554 f1 0.9313085032264145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 33.25896453857422 s\n",
      "Accuracy 0.9284826325411335 precision 0.9281067634063271 specificity 0.8080040398840799 recall 0.9284826325411335 f1 0.9259024249158017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 33.12896680831909 s\n",
      "Accuracy 0.9276416819012797 precision 0.9272582937500495 specificity 0.8049390632438674 recall 0.9276416819012797 f1 0.9249722785164615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 33.19596767425537 s\n",
      "Accuracy 0.92654478976234 precision 0.9260791579150998 specificity 0.8039831088195405 recall 0.92654478976234 f1 0.9238567140410429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 32.80996608734131 s\n",
      "Accuracy 0.9288117001828153 precision 0.9284782175177607 specificity 0.811059812315929 recall 0.9288117001828153 f1 0.9262973318819913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 33.2149658203125 s\n",
      "Accuracy 0.9261791590493601 precision 0.9263145774050243 specificity 0.8052254874128063 recall 0.9261791590493601 f1 0.9233305907991789\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 32.97796702384949 s\n",
      "Accuracy 0.9293235831809872 precision 0.9288481422002823 specificity 0.813284833586499 recall 0.9293235831809872 f1 0.9269197279416871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 33.30396628379822 s\n",
      "Accuracy 0.9295795246800731 precision 0.9292191205497704 specificity 0.814047530192208 recall 0.9295795246800731 f1 0.9271592943560834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 33.679964542388916 s\n",
      "Accuracy 0.9280438756855576 precision 0.9276689257389923 specificity 0.8071092802762204 recall 0.9280438756855576 f1 0.9254328677095199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 32.88496518135071 s\n",
      "Accuracy 0.9284095063985375 precision 0.9278195555620273 specificity 0.8115095980062262 recall 0.9284095063985375 f1 0.925987116893607\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 32.98496603965759 s\n",
      "Accuracy 0.9288482632541133 precision 0.9284384725819842 specificity 0.8112809953180898 recall 0.9288482632541133 f1 0.9263651973430345\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 32.83696508407593 s\n",
      "Accuracy 0.9318098720292505 precision 0.9318096266611301 specificity 0.8150193754068716 recall 0.9318098720292505 f1 0.9293438961346916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 33.537965536117554 s\n",
      "Accuracy 0.9268007312614259 precision 0.9265075725763176 specificity 0.8040850816966373 recall 0.9268007312614259 f1 0.9240635546107314\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 33.431965351104736 s\n",
      "Accuracy 0.930127970749543 precision 0.9299059153776659 specificity 0.8115541570766377 recall 0.930127970749543 f1 0.9276154307040788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 33.38796591758728 s\n",
      "Accuracy 0.9285923217550274 precision 0.9279499306434439 specificity 0.8135035049587453 recall 0.9285923217550274 f1 0.9262411722232774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 33.139963150024414 s\n",
      "Accuracy 0.9294698354661791 precision 0.9290977269579022 specificity 0.8095739690044761 recall 0.9294698354661791 f1 0.9269457516580669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 33.637961864471436 s\n",
      "Accuracy 0.9272029250457038 precision 0.926982168601696 specificity 0.8037864823419665 recall 0.9272029250457038 f1 0.9244439916532958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 33.34096145629883 s\n",
      "Accuracy 0.9313345521023766 precision 0.9307501960801288 specificity 0.818143147825527 recall 0.9313345521023766 f1 0.9291203225798907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 33.42996168136597 s\n",
      "Accuracy 0.9288482632541133 precision 0.9286775428298417 specificity 0.8133375710701751 recall 0.9288482632541133 f1 0.9263373712610568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 32.906962394714355 s\n",
      "Accuracy 0.930274223034735 precision 0.9298553312682275 specificity 0.8164383581045006 recall 0.930274223034735 f1 0.9279422870630446\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 33.196964263916016 s\n",
      "Accuracy 0.9318098720292505 precision 0.93140719029387 specificity 0.814824674096312 recall 0.9318098720292505 f1 0.9294641199108242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 33.25896143913269 s\n",
      "Accuracy 0.9270201096892139 precision 0.9267653803280188 specificity 0.8049026201261122 recall 0.9270201096892139 f1 0.9242955043531107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 32.997962951660156 s\n",
      "Accuracy 0.9322120658135283 precision 0.9322294643627146 specificity 0.8168743099163667 recall 0.9322120658135283 f1 0.9297905780441851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 33.31896352767944 s\n",
      "Accuracy 0.9291773308957952 precision 0.9286842544694817 specificity 0.8140733565166154 recall 0.9291773308957952 f1 0.9267956943273907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 33.60296320915222 s\n",
      "Accuracy 0.9290310786106033 precision 0.9289468200619762 specificity 0.811239372872884 recall 0.9290310786106033 f1 0.926447869408452\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 32.94896364212036 s\n",
      "Accuracy 0.9275685557586837 precision 0.9269225332533526 specificity 0.8058946418650055 recall 0.9275685557586837 f1 0.9250131663964609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 33.41096210479736 s\n",
      "Accuracy 0.9305301645338209 precision 0.9299904259512733 specificity 0.8127259360677833 recall 0.9305301645338209 f1 0.9281589656077024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 32.605960845947266 s\n",
      "Accuracy 0.9285923217550274 precision 0.9284079944312678 specificity 0.8089018087540005 recall 0.9285923217550274 f1 0.925974902951023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 33.01196360588074 s\n",
      "Accuracy 0.9306764168190128 precision 0.9300837728668456 specificity 0.8164200654793697 recall 0.9306764168190128 f1 0.9284135194255928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 33.22196173667908 s\n",
      "Accuracy 0.9274954296160878 precision 0.9272291783903287 specificity 0.806497465639088 recall 0.9274954296160878 f1 0.9248233130868909\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 33.016963481903076 s\n",
      "Accuracy 0.9283729433272395 precision 0.9278743796834136 specificity 0.8136401886150422 recall 0.9283729433272395 f1 0.9259683179334809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 33.135963439941406 s\n",
      "Accuracy 0.9289945155393053 precision 0.9285164104351958 specificity 0.8163003768571102 recall 0.9289945155393053 f1 0.9266572689213955\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 33.02096390724182 s\n",
      "Accuracy 0.9290310786106033 precision 0.9286192787919679 specificity 0.8133734166565658 recall 0.9290310786106033 f1 0.9266019991607541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 33.31096339225769 s\n",
      "Accuracy 0.9303473491773309 precision 0.9300423924286403 specificity 0.8149005406178487 recall 0.9303473491773309 f1 0.9279431621554943\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 33.123960971832275 s\n",
      "Accuracy 0.9295429616087751 precision 0.9290055032015827 specificity 0.8137981588268749 recall 0.9295429616087751 f1 0.9271773701776073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 33.045963764190674 s\n",
      "Accuracy 0.9274223034734917 precision 0.9267861932822795 specificity 0.8062395218452586 recall 0.9274223034734917 f1 0.924868795443159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 33.27196192741394 s\n",
      "Accuracy 0.9303839122486289 precision 0.9300076656523392 specificity 0.8109176879959097 recall 0.9303839122486289 f1 0.927911159607514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 33.25696325302124 s\n",
      "Accuracy 0.9277879341864717 precision 0.9273871036555037 specificity 0.808120131857959 recall 0.9277879341864717 f1 0.9252050119621978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 33.184964179992676 s\n",
      "Accuracy 0.9286654478976234 precision 0.9283875721472256 specificity 0.8081878988972786 recall 0.9286654478976234 f1 0.926061583305506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 33.23696231842041 s\n",
      "Accuracy 0.9319926873857404 precision 0.9316886382132914 specificity 0.8178718144618252 recall 0.9319926873857404 f1 0.9296866807528438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 33.174962759017944 s\n",
      "Accuracy 0.9283363802559415 precision 0.9279712928557615 specificity 0.8078951829184644 recall 0.9283363802559415 f1 0.9257470475841294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 33.478962659835815 s\n",
      "Accuracy 0.9291042047531992 precision 0.9289726519094301 specificity 0.8097459499499537 recall 0.9291042047531992 f1 0.9265011028611356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 32.95096802711487 s\n",
      "Accuracy 0.9290310786106033 precision 0.9286287442899428 specificity 0.8143094254578013 recall 0.9290310786106033 f1 0.9266210322277562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 32.787959575653076 s\n",
      "Accuracy 0.9290676416819013 precision 0.9288752472683057 specificity 0.8107145455941285 recall 0.9290676416819013 f1 0.9265053118422218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 33.227962017059326 s\n",
      "Accuracy 0.9306398537477149 precision 0.9304526584320961 specificity 0.8146970152616897 recall 0.9306398537477149 f1 0.928199330470731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 33.46896290779114 s\n",
      "Accuracy 0.9297623400365631 precision 0.929314615450914 specificity 0.8155902609876439 recall 0.9297623400365631 f1 0.9274112870682774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 33.26496195793152 s\n",
      "Accuracy 0.9274954296160878 precision 0.927286103479326 specificity 0.8025516656668022 recall 0.9274954296160878 f1 0.924708842550217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 32.75096344947815 s\n",
      "Accuracy 0.9319561243144424 precision 0.9316575837758286 specificity 0.8174980657173918 recall 0.9319561243144424 f1 0.9296392360006597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 32.81296443939209 s\n",
      "Accuracy 0.9288848263254114 precision 0.9286072968077872 specificity 0.8102082533477168 recall 0.9288848263254114 f1 0.9263335273921197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 33.587963581085205 s\n",
      "Accuracy 0.9328702010968921 precision 0.9325869422207479 specificity 0.822438801505252 recall 0.9328702010968921 f1 0.9306750287119641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 32.89796328544617 s\n",
      "Accuracy 0.9330895795246801 precision 0.9326900650145273 specificity 0.818144371061892 recall 0.9330895795246801 f1 0.9308418638321203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 33.136961936950684 s\n",
      "Accuracy 0.9307495429616087 precision 0.9305282068522037 specificity 0.8170261196524459 recall 0.9307495429616087 f1 0.9283752129550568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 33.83096408843994 s\n",
      "Accuracy 0.9318098720292505 precision 0.9314572103600463 specificity 0.8159807248112277 recall 0.9318098720292505 f1 0.9294736302531811\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 32.88396239280701 s\n",
      "Accuracy 0.929835466179159 precision 0.9295578847045842 specificity 0.8104681703212036 recall 0.929835466179159 f1 0.9273091504886994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 33.32796335220337 s\n",
      "Accuracy 0.9292870201096892 precision 0.9289037846181616 specificity 0.8116300934475936 recall 0.9292870201096892 f1 0.9268117668913358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 33.09596300125122 s\n",
      "Accuracy 0.9292138939670932 precision 0.9287201942675333 specificity 0.8123759856553625 recall 0.9292138939670932 f1 0.9267927909120298\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 33.005966901779175 s\n",
      "Accuracy 0.9288117001828153 precision 0.928082974628409 specificity 0.812970149532526 recall 0.9288117001828153 f1 0.9264853874491079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 33.0889618396759 s\n",
      "Accuracy 0.9287020109689214 precision 0.9284438240980405 specificity 0.8083142530600573 recall 0.9287020109689214 f1 0.9260956816075898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 32.68896293640137 s\n",
      "Accuracy 0.9281170018281536 precision 0.9278783823488013 specificity 0.8081397344542438 recall 0.9281170018281536 f1 0.9254885900618638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 32.3959641456604 s\n",
      "Accuracy 0.9288117001828153 precision 0.9286536769424074 specificity 0.8091485944716204 recall 0.9288117001828153 f1 0.9261965368362526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 33.41996240615845 s\n",
      "Accuracy 0.9308226691042047 precision 0.9305713549936266 specificity 0.8132660781992992 recall 0.9308226691042047 f1 0.9283726481532916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 32.936962604522705 s\n",
      "Accuracy 0.9291407678244973 precision 0.9284844331017207 specificity 0.8128081630983509 recall 0.9291407678244973 f1 0.9267883096105469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 33.24196434020996 s\n",
      "Accuracy 0.9307495429616087 precision 0.930488183799504 specificity 0.8189377900872103 recall 0.9307495429616087 f1 0.9284316982805484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 33.32396149635315 s\n",
      "Accuracy 0.9282632541133455 precision 0.9279827613406636 specificity 0.8067426993758734 recall 0.9282632541133455 f1 0.9256172383596873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 33.18096303939819 s\n",
      "Accuracy 0.9277513711151737 precision 0.927467197036177 specificity 0.808774549138239 recall 0.9277513711151737 f1 0.9251455417552331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 33.12796354293823 s\n",
      "Accuracy 0.9287020109689214 precision 0.9282184597735895 specificity 0.8116728237847397 recall 0.9287020109689214 f1 0.926250881454187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 32.933963775634766 s\n",
      "Accuracy 0.9270932358318099 precision 0.926544326499811 specificity 0.8095627709682875 recall 0.9270932358318099 f1 0.9245836499241484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 33.43196129798889 s\n",
      "Accuracy 0.9278610603290677 precision 0.9275014584906437 specificity 0.808520854996644 recall 0.9278610603290677 f1 0.9252756482152904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 32.75096416473389 s\n",
      "Accuracy 0.9306032906764168 precision 0.9303030137032519 specificity 0.8148020375441553 recall 0.9306032906764168 f1 0.9282001102645983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 32.537962436676025 s\n",
      "Accuracy 0.9310420475319927 precision 0.9308291158466245 specificity 0.8110401805653886 recall 0.9310420475319927 f1 0.9285331785213302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 33.75496029853821 s\n",
      "Accuracy 0.9262888482632541 precision 0.9257607065914384 specificity 0.8073031443248826 recall 0.9262888482632541 f1 0.9237004507773781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 33.419963359832764 s\n",
      "Accuracy 0.9308226691042047 precision 0.930534213494052 specificity 0.8144000530555253 recall 0.9308226691042047 f1 0.9284105770397544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 33.01296377182007 s\n",
      "Accuracy 0.9289945155393053 precision 0.928618599737252 specificity 0.8087724328225888 recall 0.9289945155393053 f1 0.9264430632038001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 33.30096364021301 s\n",
      "Accuracy 0.9286288848263254 precision 0.928619909165761 specificity 0.8103577579416621 recall 0.9286288848263254 f1 0.9259949092956306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 33.68296217918396 s\n",
      "Accuracy 0.9314808043875685 precision 0.9311030660159492 specificity 0.8213801485253519 recall 0.9314808043875685 f1 0.9292693750524428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 33.37696099281311 s\n",
      "Accuracy 0.9294332723948812 precision 0.9289488060894308 specificity 0.8123699482517841 recall 0.9294332723948812 f1 0.9270129446161046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 32.68596172332764 s\n",
      "Accuracy 0.9293235831809872 precision 0.9287785874535813 specificity 0.8164969025076827 recall 0.9293235831809872 f1 0.9270207219804362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 33.4999635219574 s\n",
      "Accuracy 0.9272029250457038 precision 0.9270592598329191 specificity 0.8080367023730102 recall 0.9272029250457038 f1 0.9245247489274465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 33.19196391105652 s\n",
      "Accuracy 0.9312614259597807 precision 0.9309059118019306 specificity 0.8158635002608453 recall 0.9312614259597807 f1 0.9289130792211626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 33.35896348953247 s\n",
      "Accuracy 0.926617915904936 precision 0.9264992473111996 specificity 0.8038834789999971 recall 0.926617915904936 f1 0.9238180355904319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 33.40696310997009 s\n",
      "Accuracy 0.9309323583180987 precision 0.9306234136048367 specificity 0.8148378108925384 recall 0.9309323583180987 f1 0.9285390303313718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 32.70996308326721 s\n",
      "Accuracy 0.929725776965265 precision 0.9295547541917926 specificity 0.8096386893159184 recall 0.929725776965265 f1 0.9271445926188361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 33.39796328544617 s\n",
      "Accuracy 0.9285191956124315 precision 0.9282021327395512 specificity 0.8105795442752599 recall 0.9285191956124315 f1 0.9259823776622894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 33.48896241188049 s\n",
      "Accuracy 0.929725776965265 precision 0.9297830443983734 specificity 0.8114173639800136 recall 0.929725776965265 f1 0.9271196037062817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 33.17996430397034 s\n",
      "Accuracy 0.9292870201096892 precision 0.9288626548521107 specificity 0.8119583937281102 recall 0.9292870201096892 f1 0.9268334057875353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 33.23096323013306 s\n",
      "Accuracy 0.9311517367458867 precision 0.9307105075257546 specificity 0.8128747471417145 recall 0.9311517367458867 f1 0.928761580066071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 33.385961294174194 s\n",
      "Accuracy 0.9285191956124315 precision 0.9282791935676852 specificity 0.810412685442901 recall 0.9285191956124315 f1 0.9259538101333405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 33.03096294403076 s\n",
      "Accuracy 0.9287751371115174 precision 0.9285343893837561 specificity 0.8058937645749135 recall 0.9287751371115174 f1 0.926106813921152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 33.142969608306885 s\n",
      "Accuracy 0.9294332723948812 precision 0.9291130999158775 specificity 0.8125171854721348 recall 0.9294332723948812 f1 0.9269610388905578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 33.13495445251465 s\n",
      "Accuracy 0.9277879341864717 precision 0.9275712205976134 specificity 0.8056461727101606 recall 0.9277879341864717 f1 0.9250855090645687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 33.372960567474365 s\n",
      "Accuracy 0.9271663619744058 precision 0.9268467745483316 specificity 0.8069224723544621 recall 0.9271663619744058 f1 0.924515135736823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 32.81096434593201 s\n",
      "Accuracy 0.929945155393053 precision 0.9297535541013139 specificity 0.8112111453128152 recall 0.929945155393053 f1 0.9274115593251462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 33.26996350288391 s\n",
      "Accuracy 0.9308592321755027 precision 0.9306321732707454 specificity 0.8177372371651498 recall 0.9308592321755027 f1 0.9285049782030801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 33.18696308135986 s\n",
      "Accuracy 0.9300914076782449 precision 0.9295715432092514 specificity 0.8105336513322895 recall 0.9300914076782449 f1 0.9276530293545229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 32.51796293258667 s\n",
      "Accuracy 0.9287751371115174 precision 0.9284097070838147 specificity 0.8122123979591334 recall 0.9287751371115174 f1 0.926298094657729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 34.43396043777466 s\n",
      "Accuracy 0.9308226691042047 precision 0.9305725831878457 specificity 0.8153730959096098 recall 0.9308226691042047 f1 0.9284207506053613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 33.6919629573822 s\n",
      "Accuracy 0.9304936014625228 precision 0.9299722377938334 specificity 0.816687636241318 recall 0.9304936014625228 f1 0.9282074022609321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 32.87796187400818 s\n",
      "Accuracy 0.9276051188299818 precision 0.926925804592785 specificity 0.8057431239146136 recall 0.9276051188299818 f1 0.925059233162647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 33.18896150588989 s\n",
      "Accuracy 0.9295063985374772 precision 0.9290408021937847 specificity 0.8131595608653029 recall 0.9295063985374772 f1 0.9270995650278818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 32.9309618473053 s\n",
      "Accuracy 0.9291407678244973 precision 0.9288651204121126 specificity 0.8084205204699313 recall 0.9291407678244973 f1 0.9265513967989449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 33.21896314620972 s\n",
      "Accuracy 0.926617915904936 precision 0.9262072367316425 specificity 0.8083082490265225 recall 0.926617915904936 f1 0.9240203068957645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 33.262962341308594 s\n",
      "Accuracy 0.9292138939670932 precision 0.9287729765563784 specificity 0.8098675659114979 recall 0.9292138939670932 f1 0.9267147893764549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 33.20796346664429 s\n",
      "Accuracy 0.9296160877513712 precision 0.9291772611004869 specificity 0.8116892337804206 recall 0.9296160877513712 f1 0.9271673661535184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 33.150963306427 s\n",
      "Accuracy 0.9315173674588666 precision 0.9312728062491932 specificity 0.8147658339549311 recall 0.9315173674588666 f1 0.9291130741456154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 33.35096335411072 s\n",
      "Accuracy 0.9289213893967093 precision 0.9283937103259517 specificity 0.8057295811665625 recall 0.9289213893967093 f1 0.9263472166609638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 32.793965339660645 s\n",
      "Accuracy 0.930164533820841 precision 0.9297162025486746 specificity 0.8125956256466778 recall 0.930164533820841 f1 0.9277510096106487\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 33.12496089935303 s\n",
      "Accuracy 0.9269835466179159 precision 0.9263598770770628 specificity 0.811992834913165 recall 0.9269835466179159 f1 0.9245594867801008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 33.40796160697937 s\n",
      "Accuracy 0.9253747714808044 precision 0.9250710531854018 specificity 0.8051406249723247 recall 0.9253747714808044 f1 0.9226387649662675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 33.33896231651306 s\n",
      "Accuracy 0.9281535648994516 precision 0.9278197862319224 specificity 0.8110609871402658 recall 0.9281535648994516 f1 0.9256268046906477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 33.21596360206604 s\n",
      "Accuracy 0.9275319926873857 precision 0.927193399871992 specificity 0.8128682602530548 recall 0.9275319926873857 f1 0.9250391604249475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 33.48596143722534 s\n",
      "Accuracy 0.9295429616087751 precision 0.929394551547332 specificity 0.8115095515519232 recall 0.9295429616087751 f1 0.9269952786993861\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 33.35796332359314 s\n",
      "Accuracy 0.9292870201096892 precision 0.9290658959563005 specificity 0.8087322505132342 recall 0.9292870201096892 f1 0.9266909179624567\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 33.52596306800842 s\n",
      "Accuracy 0.9298720292504571 precision 0.9296885098713509 specificity 0.8070058640765865 recall 0.9298720292504571 f1 0.9272357523233582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 33.73196077346802 s\n",
      "Accuracy 0.930018281535649 precision 0.9298658152812593 specificity 0.8140746271759544 recall 0.930018281535649 f1 0.9275409860240329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 33.29296374320984 s\n",
      "Accuracy 0.9302010968921389 precision 0.9300262139804095 specificity 0.8143091106370254 recall 0.9302010968921389 f1 0.927739530113349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 32.99896192550659 s\n",
      "Accuracy 0.9277879341864717 precision 0.9277169027604808 specificity 0.8091144284830869 recall 0.9277879341864717 f1 0.9251257250427503\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 32.891961336135864 s\n",
      "Accuracy 0.9277148080438757 precision 0.9270116689588004 specificity 0.8117752619945304 recall 0.9277148080438757 f1 0.9253290404880032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 33.613961935043335 s\n",
      "Accuracy 0.930127970749543 precision 0.9297361811478895 specificity 0.8148391637953659 recall 0.930127970749543 f1 0.9277469276447528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 33.4999635219574 s\n",
      "Accuracy 0.9317367458866544 precision 0.9317646411050319 specificity 0.8161470976614278 recall 0.9317367458866544 f1 0.9292868355595635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 33.22996377944946 s\n",
      "Accuracy 0.9317001828153565 precision 0.9313390104647291 specificity 0.8165250435333947 recall 0.9317001828153565 f1 0.9293770288500792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 32.97096061706543 s\n",
      "Accuracy 0.9285923217550274 precision 0.9282466674772815 specificity 0.8094896080718144 recall 0.9285923217550274 f1 0.926040083172928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 32.75496459007263 s\n",
      "Accuracy 0.9291773308957952 precision 0.928369218277971 specificity 0.8154940375427658 recall 0.9291773308957952 f1 0.926951524154279\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 33.09696364402771 s\n",
      "Accuracy 0.9306398537477149 precision 0.930258177410506 specificity 0.8137316317325572 recall 0.9306398537477149 f1 0.9282393400261328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 32.74796724319458 s\n",
      "Accuracy 0.9287385740402194 precision 0.9282945041368875 specificity 0.8146844075784823 recall 0.9287385740402194 f1 0.926346468062589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 33.10196566581726 s\n",
      "Accuracy 0.9312248628884826 precision 0.9306401751672058 specificity 0.8198498470443676 recall 0.9312248628884826 f1 0.9290480611137792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 33.19996762275696 s\n",
      "Accuracy 0.930164533820841 precision 0.9298313638071373 specificity 0.8131389408503217 recall 0.930164533820841 f1 0.9277250904071742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 33.16996645927429 s\n",
      "Accuracy 0.9285557586837294 precision 0.9282966256806878 specificity 0.813599939520074 recall 0.9285557586837294 f1 0.9260733069889739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 32.94196557998657 s\n",
      "Accuracy 0.9289579524680073 precision 0.9286850299230962 specificity 0.813249582612991 recall 0.9289579524680073 f1 0.9264789241787227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 32.98296761512756 s\n",
      "Accuracy 0.9293601462522852 precision 0.9289931690411368 specificity 0.8141955178894549 recall 0.9293601462522852 f1 0.9269415415994374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 33.207966327667236 s\n",
      "Accuracy 0.9310420475319927 precision 0.9307914348777434 specificity 0.8153365934807154 recall 0.9310420475319927 f1 0.9286435910179787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 33.628966093063354 s\n",
      "Accuracy 0.9259232175502742 precision 0.9255262563553874 specificity 0.8083301353130515 recall 0.9259232175502742 f1 0.9233085097316495\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 33.12196493148804 s\n",
      "Accuracy 0.9280804387568555 precision 0.927661123231959 specificity 0.8075171163705486 recall 0.9280804387568555 f1 0.9254948678697328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 33.40696716308594 s\n",
      "Accuracy 0.9281170018281536 precision 0.9276683331419487 specificity 0.8090832895464686 recall 0.9281170018281536 f1 0.9255801249998973\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 33.26396656036377 s\n",
      "Accuracy 0.9283729433272395 precision 0.9279795151034972 specificity 0.8056719613059005 recall 0.9283729433272395 f1 0.9257399688710178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 33.27896690368652 s\n",
      "Accuracy 0.9307129798903108 precision 0.9305128565455663 specificity 0.8154048659651432 recall 0.9307129798903108 f1 0.9282941211037059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 33.125967264175415 s\n",
      "Accuracy 0.9277513711151737 precision 0.9271176779126068 specificity 0.8144538144732815 recall 0.9277513711151737 f1 0.925405097058477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 33.01696467399597 s\n",
      "Accuracy 0.9306764168190128 precision 0.9302644844207081 specificity 0.8180378178101985 recall 0.9306764168190128 f1 0.9283863093099574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 33.25396680831909 s\n",
      "Accuracy 0.9293967093235832 precision 0.9290424228461411 specificity 0.8135574747833622 recall 0.9293967093235832 f1 0.9269595137366772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 33.195965051651 s\n",
      "Accuracy 0.929981718464351 precision 0.9296051332172635 specificity 0.8145010176145805 recall 0.929981718464351 f1 0.9275849677669685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 33.5249662399292 s\n",
      "Accuracy 0.9278244972577696 precision 0.9274868488257402 specificity 0.8074793019076575 recall 0.9278244972577696 f1 0.9252058456360017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 33.64296817779541 s\n",
      "Accuracy 0.9278244972577696 precision 0.9275540648417296 specificity 0.8082806423202242 recall 0.9278244972577696 f1 0.9252037282363047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 33.33496427536011 s\n",
      "Accuracy 0.9259597806215722 precision 0.925772620083246 specificity 0.8022528303138518 recall 0.9259597806215722 f1 0.9231262101156947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 32.849966287612915 s\n",
      "Accuracy 0.9296526508226691 precision 0.9289508258481842 specificity 0.8158026139281039 recall 0.9296526508226691 f1 0.9273989234861367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 33.44396686553955 s\n",
      "Accuracy 0.9280804387568555 precision 0.9276002501784493 specificity 0.8142296439615835 recall 0.9280804387568555 f1 0.925678350464146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 32.94396615028381 s\n",
      "Accuracy 0.9307861060329068 precision 0.9303897778718964 specificity 0.8126393991847884 recall 0.9307861060329068 f1 0.9283680591693961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 33.09796476364136 s\n",
      "Accuracy 0.9278976234003656 precision 0.9275396535990882 specificity 0.8077883816876156 recall 0.9278976234003656 f1 0.9252945914649406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 32.57996726036072 s\n",
      "Accuracy 0.930127970749543 precision 0.9297607305803793 specificity 0.8132021640741229 recall 0.930127970749543 f1 0.9277005207123225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 32.64596772193909 s\n",
      "Accuracy 0.9329433272394881 precision 0.9327346207440393 specificity 0.8202184701666471 recall 0.9329433272394881 f1 0.9306768225294557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 32.83096408843994 s\n",
      "Accuracy 0.9286288848263254 precision 0.9283020823816882 specificity 0.810093350707746 recall 0.9286288848263254 f1 0.9260856922999837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 33.34496736526489 s\n",
      "Accuracy 0.9291773308957952 precision 0.9288423377431441 specificity 0.809648234441644 recall 0.9291773308957952 f1 0.9266369766856917\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 33.208967447280884 s\n",
      "Accuracy 0.929908592321755 precision 0.9295897070472536 specificity 0.810224156107017 recall 0.929908592321755 f1 0.9273912599194806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 33.66596579551697 s\n",
      "Accuracy 0.9315173674588666 precision 0.9314980788317357 specificity 0.8181042489397927 recall 0.9315173674588666 f1 0.92912101952189\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 33.17496633529663 s\n",
      "Accuracy 0.9291407678244973 precision 0.9290437988796617 specificity 0.810058495402845 recall 0.9291407678244973 f1 0.9265354788935964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 33.259966135025024 s\n",
      "Accuracy 0.9279341864716636 precision 0.9274339494333974 specificity 0.8048468589273737 recall 0.9279341864716636 f1 0.9253081932588179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 33.59996700286865 s\n",
      "Accuracy 0.9295063985374772 precision 0.9292180296391068 specificity 0.8178165955114519 recall 0.9295063985374772 f1 0.9271497530309625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 32.737967014312744 s\n",
      "Accuracy 0.9317733089579525 precision 0.9315632916381082 specificity 0.8151727275408007 recall 0.9317733089579525 f1 0.9293724226758389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 32.53896760940552 s\n",
      "Accuracy 0.9287385740402194 precision 0.9284999394758949 specificity 0.8104709163323012 recall 0.9287385740402194 f1 0.9261784014809715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 32.86396765708923 s\n",
      "Accuracy 0.9326508226691042 precision 0.93226131823293 specificity 0.8191952396055039 recall 0.9326508226691042 f1 0.9304148948929967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 33.19696640968323 s\n",
      "Accuracy 0.9319926873857404 precision 0.9316912838572737 specificity 0.8175121260743228 recall 0.9319926873857404 f1 0.929677722384963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 32.81996464729309 s\n",
      "Accuracy 0.9287751371115174 precision 0.9287333288112039 specificity 0.8094325261885675 recall 0.9287751371115174 f1 0.9261314739929647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 33.279967308044434 s\n",
      "Accuracy 0.9323583180987203 precision 0.9320130469977016 specificity 0.8168284340479576 recall 0.9323583180987203 f1 0.930049201544363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 33.038968086242676 s\n",
      "Accuracy 0.9294698354661791 precision 0.9289333700910994 specificity 0.8122006224345518 recall 0.9294698354661791 f1 0.9270646265606125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 33.850964069366455 s\n",
      "Accuracy 0.9296892138939671 precision 0.9294371711906957 specificity 0.8110953885797328 recall 0.9296892138939671 f1 0.9271666507698527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 32.84896683692932 s\n",
      "Accuracy 0.9289213893967093 precision 0.9285560563258174 specificity 0.8089789435429536 recall 0.9289213893967093 f1 0.9263699087633038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 33.27096676826477 s\n",
      "Accuracy 0.9289213893967093 precision 0.9287622668956947 specificity 0.8080243671168805 recall 0.9289213893967093 f1 0.9262819530713994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 33.12196707725525 s\n",
      "Accuracy 0.9297989031078611 precision 0.9293476303380378 specificity 0.8132507058421575 recall 0.9297989031078611 f1 0.9273947696483489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 32.9739670753479 s\n",
      "Accuracy 0.9289579524680073 precision 0.9285562601978515 specificity 0.80928045184081 recall 0.9289579524680073 f1 0.926426491326603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 32.981964349746704 s\n",
      "Accuracy 0.9288848263254114 precision 0.928364764768075 specificity 0.8133312937941511 recall 0.9288848263254114 f1 0.9264897292196184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 33.44396686553955 s\n",
      "Accuracy 0.9282998171846435 precision 0.9279483992038424 specificity 0.8146197404707759 recall 0.9282998171846435 f1 0.9258670822142234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 33.301965951919556 s\n",
      "Accuracy 0.9292504570383913 precision 0.9286960612955173 specificity 0.811765146030315 recall 0.9292504570383913 f1 0.9268371553713095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 33.21196722984314 s\n",
      "Accuracy 0.9311151736745886 precision 0.9306961269153422 specificity 0.8162634662395456 recall 0.9311151736745886 f1 0.9287946309179933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 33.460965633392334 s\n",
      "Accuracy 0.9277148080438757 precision 0.9268703168176101 specificity 0.8112723097805344 recall 0.9277148080438757 f1 0.9253743324471985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 33.144967555999756 s\n",
      "Accuracy 0.9293235831809872 precision 0.9291156104341666 specificity 0.8090427876066677 recall 0.9293235831809872 f1 0.9267315105745353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 33.300965547561646 s\n",
      "Accuracy 0.9313345521023766 precision 0.9310738374715344 specificity 0.8171613109083964 recall 0.9313345521023766 f1 0.9289864132056802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 33.26896381378174 s\n",
      "Accuracy 0.9276416819012797 precision 0.9274188539115673 specificity 0.8025718329314842 recall 0.9276416819012797 f1 0.9248629390693067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 33.15296816825867 s\n",
      "Accuracy 0.9262888482632541 precision 0.9257612095451246 specificity 0.8104075196187425 recall 0.9262888482632541 f1 0.9237778609277486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 33.43296527862549 s\n",
      "Accuracy 0.930274223034735 precision 0.9297706446632634 specificity 0.8111876268225712 recall 0.930274223034735 f1 0.9278491072118873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 33.088966846466064 s\n",
      "Accuracy 0.9284095063985375 precision 0.9280581386061075 specificity 0.8084020031142347 recall 0.9284095063985375 f1 0.9258293595998305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 34.511964321136475 s\n",
      "Accuracy 0.9270566727605118 precision 0.926578248607 specificity 0.8078404858484788 recall 0.9270566727605118 f1 0.9244790151422517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 32.9359667301178 s\n",
      "Accuracy 0.9315539305301646 precision 0.9309495540343005 specificity 0.8217967193860662 recall 0.9315539305301646 f1 0.9294348898821926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 33.10496640205383 s\n",
      "Accuracy 0.9306398537477149 precision 0.9305160196796002 specificity 0.8158781091025191 recall 0.9306398537477149 f1 0.9282072836408095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 33.32896423339844 s\n",
      "Accuracy 0.9282266910420476 precision 0.928011853966656 specificity 0.8077656335543429 recall 0.9282266910420476 f1 0.9255840309892623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 33.201966524124146 s\n",
      "Accuracy 0.9266910420475319 precision 0.9263266613025513 specificity 0.8070548580562478 recall 0.9266910420475319 f1 0.9240483549894271\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 33.27296710014343 s\n",
      "Accuracy 0.929725776965265 precision 0.9293429764225322 specificity 0.8106503084372141 recall 0.929725776965265 f1 0.9272357876157346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 33.57596468925476 s\n",
      "Accuracy 0.9287751371115174 precision 0.9282237863983093 specificity 0.8104393525680265 recall 0.9287751371115174 f1 0.9263198285836948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 33.40796661376953 s\n",
      "Accuracy 0.9277879341864717 precision 0.9275584714003593 specificity 0.8081012957851325 recall 0.9277879341864717 f1 0.9251491951273165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 33.49096632003784 s\n",
      "Accuracy 0.929835466179159 precision 0.9296780801898833 specificity 0.8108543372749997 recall 0.929835466179159 f1 0.9272808854399357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 33.296964168548584 s\n",
      "Accuracy 0.9283363802559415 precision 0.9278733858455565 specificity 0.8074203152405565 recall 0.9283363802559415 f1 0.9257684677075076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 32.67996788024902 s\n",
      "Accuracy 0.9292138939670932 precision 0.9288706067673175 specificity 0.8123420712751626 recall 0.9292138939670932 f1 0.9267409024495807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 32.86696481704712 s\n",
      "Accuracy 0.9335283363802559 precision 0.9330798968634585 specificity 0.8216977917242664 recall 0.9335283363802559 f1 0.9313840392379343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 32.82096576690674 s\n",
      "Accuracy 0.9291407678244973 precision 0.9283033990339483 specificity 0.8119617976971176 recall 0.9291407678244973 f1 0.9268410349493252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 33.4679651260376 s\n",
      "Accuracy 0.9278976234003656 precision 0.9275819498229481 specificity 0.8088749960845658 recall 0.9278976234003656 f1 0.9253072011230995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 32.9009644985199 s\n",
      "Accuracy 0.929725776965265 precision 0.9293388972449974 specificity 0.815247045392366 recall 0.929725776965265 f1 0.9273452441364898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 33.159966707229614 s\n",
      "Accuracy 0.9320658135283364 precision 0.9319116761021748 specificity 0.8189906274228316 recall 0.9320658135283364 f1 0.9297392606037299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 32.69696855545044 s\n",
      "Accuracy 0.9294332723948812 precision 0.9290686006167841 specificity 0.8117472980790369 recall 0.9294332723948812 f1 0.9269574436701429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 32.90096616744995 s\n",
      "Accuracy 0.930274223034735 precision 0.9299228701092126 specificity 0.8126973318908638 recall 0.930274223034735 f1 0.9278325647665231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 32.930965423583984 s\n",
      "Accuracy 0.9293601462522852 precision 0.928942404150369 specificity 0.8126021556336868 recall 0.9293601462522852 f1 0.9269209305494711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 32.94496536254883 s\n",
      "Accuracy 0.929981718464351 precision 0.929847181672009 specificity 0.8111187211488123 recall 0.929981718464351 f1 0.9274293401671387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 32.93196487426758 s\n",
      "Accuracy 0.9303473491773309 precision 0.9297567818236954 specificity 0.8125644391303257 recall 0.9303473491773309 f1 0.92798735870472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 32.950966596603394 s\n",
      "Accuracy 0.9289213893967093 precision 0.9285189666656338 specificity 0.8114858730581663 recall 0.9289213893967093 f1 0.9264421290075892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 33.14696764945984 s\n",
      "Accuracy 0.9295429616087751 precision 0.929321913461087 specificity 0.8067637371431235 recall 0.9295429616087751 f1 0.926905508153232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 33.38996386528015 s\n",
      "Accuracy 0.9297623400365631 precision 0.9295245910838447 specificity 0.8161729901902143 recall 0.9297623400365631 f1 0.927355615159268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 33.02996635437012 s\n",
      "Accuracy 0.9285191956124315 precision 0.9278239517376873 specificity 0.8106222333166722 recall 0.9285191956124315 f1 0.9261171941577728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 33.89696502685547 s\n",
      "Accuracy 0.926617915904936 precision 0.9261305880913163 specificity 0.8092341926781025 recall 0.926617915904936 f1 0.9240695332214693\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 33.492966651916504 s\n",
      "Accuracy 0.9313345521023766 precision 0.9310122648651928 specificity 0.8174270267782455 recall 0.9313345521023766 f1 0.9290123074023007\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 33.32596492767334 s\n",
      "Accuracy 0.9279707495429617 precision 0.9276980828995512 specificity 0.8098234596940374 recall 0.9279707495429617 f1 0.9253909311355691\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 33.37896418571472 s\n",
      "Accuracy 0.9294698354661791 precision 0.929116115563047 specificity 0.8139050009376285 recall 0.9294698354661791 f1 0.9270420056511746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 33.19696640968323 s\n",
      "Accuracy 0.930127970749543 precision 0.9299116759064662 specificity 0.8154346819467744 recall 0.930127970749543 f1 0.9277039672013594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 33.16696739196777 s\n",
      "Accuracy 0.9295795246800731 precision 0.9291551489684364 specificity 0.8108282830531397 recall 0.9295795246800731 f1 0.927104816582212\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 33.32196354866028 s\n",
      "Accuracy 0.9288848263254114 precision 0.9287006937139345 specificity 0.8133460919940227 recall 0.9288848263254114 f1 0.9263789271246959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 32.95296788215637 s\n",
      "Accuracy 0.9306398537477149 precision 0.9300190861885675 specificity 0.8126321548565133 recall 0.9306398537477149 f1 0.928298423436735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 33.84396529197693 s\n",
      "Accuracy 0.9303473491773309 precision 0.9301835038918287 specificity 0.8081146707073718 recall 0.9303473491773309 f1 0.9277411835748282\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 32.99196696281433 s\n",
      "Accuracy 0.9282998171846435 precision 0.9278016294148623 specificity 0.8078911610666023 recall 0.9282998171846435 f1 0.9257547586279181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 33.25396704673767 s\n",
      "Accuracy 0.930164533820841 precision 0.9301622068006226 specificity 0.8105655497380702 recall 0.930164533820841 f1 0.9275641418772369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 32.93209385871887 s\n",
      "Accuracy 0.9314076782449726 precision 0.9313453324122808 specificity 0.8152931719936908 recall 0.9314076782449726 f1 0.9289580317718001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 33.36383938789368 s\n",
      "Accuracy 0.9284095063985375 precision 0.9283124468924545 specificity 0.8081468837625773 recall 0.9284095063985375 f1 0.9257439768997514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 33.161965131759644 s\n",
      "Accuracy 0.9308957952468008 precision 0.9308668197061473 specificity 0.8134005203856576 recall 0.9308957952468008 f1 0.9283832630138651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 33.10696840286255 s\n",
      "Accuracy 0.9285557586837294 precision 0.9282247678946866 specificity 0.8124784763728685 recall 0.9285557586837294 f1 0.9260696517316491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 33.61196565628052 s\n",
      "Accuracy 0.9271297989031079 precision 0.9267322679311455 specificity 0.8092448597024264 recall 0.9271297989031079 f1 0.9245605928806664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 33.37096428871155 s\n",
      "Accuracy 0.9305301645338209 precision 0.9299706338572589 specificity 0.8179686726924255 recall 0.9305301645338209 f1 0.9282883411131763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 33.24996781349182 s\n",
      "Accuracy 0.9310420475319927 precision 0.930620334350749 specificity 0.81485897115392 recall 0.9310420475319927 f1 0.9286887672895646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 33.075966596603394 s\n",
      "Accuracy 0.9311882998171847 precision 0.9306821114809369 specificity 0.8185128246872314 recall 0.9311882998171847 f1 0.9289512294953132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 32.999966621398926 s\n",
      "Accuracy 0.9313711151736745 precision 0.9310644664865256 specificity 0.8164312756410625 recall 0.9313711151736745 f1 0.9290217721171731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 33.3349666595459 s\n",
      "Accuracy 0.9314442413162706 precision 0.9309355323215305 specificity 0.8171739425297337 recall 0.9314442413162706 f1 0.9291820259347321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 33.023966789245605 s\n",
      "Accuracy 0.9280073126142596 precision 0.9275541272565118 specificity 0.8088680638003852 recall 0.9280073126142596 f1 0.9254646178155915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 33.35096764564514 s\n",
      "Accuracy 0.926873857404022 precision 0.9263554938662991 specificity 0.8028439725078328 recall 0.926873857404022 f1 0.9241823989142406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 33.57096552848816 s\n",
      "Accuracy 0.9283729433272395 precision 0.92784125143149 specificity 0.8097697224434361 recall 0.9283729433272395 f1 0.9258866470502831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 33.492963552474976 s\n",
      "Accuracy 0.9295063985374772 precision 0.9291109503170554 specificity 0.8157481926347041 recall 0.9295063985374772 f1 0.9271365771401406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 33.36696434020996 s\n",
      "Accuracy 0.9302376599634369 precision 0.9302331395594446 specificity 0.8119421620493157 recall 0.9302376599634369 f1 0.927671404728949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 33.53196620941162 s\n",
      "Accuracy 0.9270201096892139 precision 0.9268217225942962 specificity 0.8060889563947277 recall 0.9270201096892139 f1 0.9243072007953842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 33.31196355819702 s\n",
      "Accuracy 0.9288117001828153 precision 0.9285032400959553 specificity 0.8123011875475227 recall 0.9288117001828153 f1 0.9263188090457583\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 32.78496789932251 s\n",
      "Accuracy 0.9317367458866544 precision 0.9314501717148764 specificity 0.8196188605003104 recall 0.9317367458866544 f1 0.9294598311440597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 33.197965145111084 s\n",
      "Accuracy 0.930127970749543 precision 0.9296904620508218 specificity 0.8134637998327168 recall 0.930127970749543 f1 0.9277303401872485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 33.01196789741516 s\n",
      "Accuracy 0.9315904936014625 precision 0.9314215877312391 specificity 0.8148892877522143 recall 0.9315904936014625 f1 0.929167003057223\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 32.615965366363525 s\n",
      "Accuracy 0.9302376599634369 precision 0.9295768541329111 specificity 0.81636049515338 recall 0.9302376599634369 f1 0.9279914739348369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 32.923967361450195 s\n",
      "Accuracy 0.9308592321755027 precision 0.9306137227175671 specificity 0.8162821846900616 recall 0.9308592321755027 f1 0.9284774274078466\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 32.85996675491333 s\n",
      "Accuracy 0.9308592321755027 precision 0.9303293798958032 specificity 0.8141273251540572 recall 0.9308592321755027 f1 0.9285234446351562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 33.27996563911438 s\n",
      "Accuracy 0.9292870201096892 precision 0.9291094678839227 specificity 0.8129944234569441 recall 0.9292870201096892 f1 0.9267782826424219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 33.350966930389404 s\n",
      "Accuracy 0.9280073126142596 precision 0.9278346874391942 specificity 0.8133871592860118 recall 0.9280073126142596 f1 0.9254828654576388\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 34.1479651927948 s\n",
      "Accuracy 0.9312248628884826 precision 0.9309696411667004 specificity 0.8164423315663086 recall 0.9312248628884826 f1 0.9288565699008209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 33.070966958999634 s\n",
      "Accuracy 0.9297989031078611 precision 0.9294908057359722 specificity 0.8092615350024582 recall 0.9297989031078611 f1 0.9272532307608619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 33.23096680641174 s\n",
      "Accuracy 0.9276051188299818 precision 0.9272476466516952 specificity 0.8055467874762394 recall 0.9276051188299818 f1 0.9249413199714668\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 33.51296663284302 s\n",
      "Accuracy 0.926654478976234 precision 0.9262948368097242 specificity 0.8071223559241965 recall 0.926654478976234 f1 0.9240111939499235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 33.02096605300903 s\n",
      "Accuracy 0.9285191956124315 precision 0.9281392881642714 specificity 0.8099065470287846 recall 0.9285191956124315 f1 0.9259868384200083\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 33.331966161727905 s\n",
      "Accuracy 0.9287385740402194 precision 0.9283767609318756 specificity 0.8127092832128143 recall 0.9287385740402194 f1 0.926271512021718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 33.21096420288086 s\n",
      "Accuracy 0.92672760511883 precision 0.9262405116124128 specificity 0.8069786719839905 recall 0.92672760511883 f1 0.9241252088031692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 33.43996620178223 s\n",
      "Accuracy 0.9317733089579525 precision 0.9313666559195429 specificity 0.8192581175421939 recall 0.9317733089579525 f1 0.9295287456775051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 33.474966526031494 s\n",
      "Accuracy 0.9279707495429617 precision 0.9276076846483309 specificity 0.8112235190041401 recall 0.9279707495429617 f1 0.9254541142445752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 33.121968030929565 s\n",
      "Accuracy 0.9302010968921389 precision 0.9297654777109791 specificity 0.8166671376815813 recall 0.9302010968921389 f1 0.92787891772568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 33.66596555709839 s\n",
      "Accuracy 0.9306764168190128 precision 0.9302893551832776 specificity 0.8145837599557362 recall 0.9306764168190128 f1 0.9282981249257738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 33.34796738624573 s\n",
      "Accuracy 0.9303107861060329 precision 0.9300119809584331 specificity 0.8105262814034562 recall 0.9303107861060329 f1 0.9278021727998629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 33.1119658946991 s\n",
      "Accuracy 0.9281535648994516 precision 0.9274573325975305 specificity 0.8145589508457034 recall 0.9281535648994516 f1 0.9258411046324543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 33.67496466636658 s\n",
      "Accuracy 0.9287385740402194 precision 0.9283501970414079 specificity 0.8142185854084402 recall 0.9287385740402194 f1 0.9263163813675839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 33.10496497154236 s\n",
      "Accuracy 0.9269104204753199 precision 0.9264603745403988 specificity 0.8113138603459902 recall 0.9269104204753199 f1 0.9244059059552665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 33.30496406555176 s\n",
      "Accuracy 0.9290310786106033 precision 0.9287869579993434 specificity 0.8140265066699834 recall 0.9290310786106033 f1 0.9265626749750661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 33.497966051101685 s\n",
      "Accuracy 0.9288848263254114 precision 0.9283982046876078 specificity 0.8104380078008587 recall 0.9288848263254114 f1 0.9264086636410457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 33.10196805000305 s\n",
      "Accuracy 0.9326508226691042 precision 0.9323412290279517 specificity 0.8185474686076786 recall 0.9326508226691042 f1 0.9303739555023497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 33.55596375465393 s\n",
      "Accuracy 0.929908592321755 precision 0.9297264507605929 specificity 0.8120456406096505 recall 0.929908592321755 f1 0.9273908946770445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 33.42796444892883 s\n",
      "Accuracy 0.9325411334552103 precision 0.9320480873984565 specificity 0.8220565934604788 recall 0.9325411334552103 f1 0.9304032953427884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 33.44496703147888 s\n",
      "Accuracy 0.9281535648994516 precision 0.9277095107645426 specificity 0.8122422603230101 recall 0.9281535648994516 f1 0.9256922415357401\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 33.16796684265137 s\n",
      "Accuracy 0.9289945155393053 precision 0.9287774918811411 specificity 0.8086219569016956 recall 0.9289945155393053 f1 0.9263885778059255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 33.120967388153076 s\n",
      "Accuracy 0.929835466179159 precision 0.9295387470945944 specificity 0.8125278969999471 recall 0.929835466179159 f1 0.9273635994024579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 33.07096719741821 s\n",
      "Accuracy 0.9289213893967093 precision 0.928426822521197 specificity 0.8138475874527237 recall 0.9289213893967093 f1 0.9265302375884127\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 33.23296546936035 s\n",
      "Accuracy 0.9309689213893967 precision 0.9308936197847737 specificity 0.8090854945935432 recall 0.9309689213893967 f1 0.9283720661048283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 33.02596592903137 s\n",
      "Accuracy 0.9284826325411335 precision 0.9279488736267875 specificity 0.8110190055428528 recall 0.9284826325411335 f1 0.9260293708612565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 33.064966440200806 s\n",
      "Accuracy 0.930274223034735 precision 0.9296855165008934 specificity 0.8110093505999293 recall 0.930274223034735 f1 0.9278755540305007\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 33.23596692085266 s\n",
      "Accuracy 0.9287385740402194 precision 0.9282833958925439 specificity 0.8095101055709278 recall 0.9287385740402194 f1 0.926226409521983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 32.78396725654602 s\n",
      "Accuracy 0.9258866544789762 precision 0.9255494910716932 specificity 0.8033921579375589 recall 0.9258866544789762 f1 0.9231275338825736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 32.81096696853638 s\n",
      "Accuracy 0.9292138939670932 precision 0.9290594523912206 specificity 0.811746498664017 recall 0.9292138939670932 f1 0.9266672455584118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 33.27896475791931 s\n",
      "Accuracy 0.9293967093235832 precision 0.9286874467336814 specificity 0.8165053649663543 recall 0.9293967093235832 f1 0.927158197944263\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 33.57896423339844 s\n",
      "Accuracy 0.9294698354661791 precision 0.9292041119866326 specificity 0.8114362249928447 recall 0.9294698354661791 f1 0.9269553278391663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 33.74596381187439 s\n",
      "Accuracy 0.9290676416819013 precision 0.9288962951129326 specificity 0.8122835693265924 recall 0.9290676416819013 f1 0.9265360565265063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 33.19796681404114 s\n",
      "Accuracy 0.9322120658135283 precision 0.9317071738817163 specificity 0.8182592911194285 recall 0.9322120658135283 f1 0.9299872899029947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 33.3099639415741 s\n",
      "Accuracy 0.9317733089579525 precision 0.9315995725273031 specificity 0.8144384754319842 recall 0.9317733089579525 f1 0.9293446448500811\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 33.261963844299316 s\n",
      "Accuracy 0.9288117001828153 precision 0.928243785361329 specificity 0.8115576389755716 recall 0.9288117001828153 f1 0.9263899815786559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 33.388964891433716 s\n",
      "Accuracy 0.9279341864716636 precision 0.9274604399754323 specificity 0.8089554974449064 recall 0.9279341864716636 f1 0.9253992740346717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 32.953969955444336 s\n",
      "Accuracy 0.9294332723948812 precision 0.9289832345029505 specificity 0.8108215064825223 recall 0.9294332723948812 f1 0.9269642889936146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 33.83496379852295 s\n",
      "Accuracy 0.9291407678244973 precision 0.9286188690448155 specificity 0.8129391442217603 recall 0.9291407678244973 f1 0.926741700118852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 33.577964067459106 s\n",
      "Accuracy 0.9296160877513712 precision 0.9290823211144651 specificity 0.8133837977204394 recall 0.9296160877513712 f1 0.9272407214890628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 33.327967405319214 s\n",
      "Accuracy 0.9262522851919561 precision 0.925720618845641 specificity 0.8100715314990073 recall 0.9262522851919561 f1 0.9237336868847109\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 33.124967098236084 s\n",
      "Accuracy 0.929725776965265 precision 0.9291281774591699 specificity 0.8110624694802325 recall 0.929725776965265 f1 0.9273207706687293\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 33.29896664619446 s\n",
      "Accuracy 0.9290310786106033 precision 0.9288975737239046 specificity 0.8087656467641821 recall 0.9290310786106033 f1 0.9264037989244633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 33.175966024398804 s\n",
      "Accuracy 0.9312979890310786 precision 0.9309516711088552 specificity 0.8169911269593366 recall 0.9312979890310786 f1 0.928973034626122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 33.173967123031616 s\n",
      "Accuracy 0.9287751371115174 precision 0.928355409904849 specificity 0.8128254900840912 recall 0.9287751371115174 f1 0.9263309630513862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 33.35896635055542 s\n",
      "Accuracy 0.9315904936014625 precision 0.9313813594107198 specificity 0.8164497271066052 recall 0.9315904936014625 f1 0.9292147619571622\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 33.29896354675293 s\n",
      "Accuracy 0.9274223034734917 precision 0.9270346449320084 specificity 0.8114304623126003 recall 0.9274223034734917 f1 0.9249087530656326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 32.94296741485596 s\n",
      "Accuracy 0.9314808043875685 precision 0.9310899522878435 specificity 0.8202335922953271 recall 0.9314808043875685 f1 0.9292478193577713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 33.806965351104736 s\n",
      "Accuracy 0.9313345521023766 precision 0.9311744033739604 specificity 0.813053526971773 recall 0.9313345521023766 f1 0.9288615736468593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 32.596967697143555 s\n",
      "Accuracy 0.929908592321755 precision 0.9298285554811194 specificity 0.8108506990722852 recall 0.929908592321755 f1 0.9273322668389786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 34.04696345329285 s\n",
      "Accuracy 0.9308592321755027 precision 0.9303797763831896 specificity 0.8162637580535207 recall 0.9308592321755027 f1 0.9285549318290179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 33.25396704673767 s\n",
      "Accuracy 0.9322120658135283 precision 0.931971229474124 specificity 0.8150695295072826 recall 0.9322120658135283 f1 0.929827027497504\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 33.27796673774719 s\n",
      "Accuracy 0.9288848263254114 precision 0.9287458488026642 specificity 0.8109699606935106 recall 0.9288848263254114 f1 0.9263087287718079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 33.444966077804565 s\n",
      "Accuracy 0.9306032906764168 precision 0.9304865591015907 specificity 0.8176361528111198 recall 0.9306032906764168 f1 0.9282083322056481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 32.95696711540222 s\n",
      "Accuracy 0.9307861060329068 precision 0.9306453320765041 specificity 0.8135818825200865 recall 0.9307861060329068 f1 0.9283085766654944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 33.1699640750885 s\n",
      "Accuracy 0.9287751371115174 precision 0.9284711433102915 specificity 0.8103944223119792 recall 0.9287751371115174 f1 0.9262346145085503\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 33.40196442604065 s\n",
      "Accuracy 0.9321755027422304 precision 0.9314851440269851 specificity 0.8212880090283949 recall 0.9321755027422304 f1 0.9300894994271016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 33.01996660232544 s\n",
      "Accuracy 0.9294698354661791 precision 0.9288914569546214 specificity 0.8149777702912667 recall 0.9294698354661791 f1 0.9271458185244653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 33.31896471977234 s\n",
      "Accuracy 0.9256307129798903 precision 0.9249898878832945 specificity 0.8024876554970148 recall 0.9256307129798903 f1 0.9229482317340442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 32.50596809387207 s\n",
      "Accuracy 0.9256307129798903 precision 0.9252326854972208 specificity 0.8065811567170094 recall 0.9256307129798903 f1 0.9229669082437865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 33.025967597961426 s\n",
      "Accuracy 0.9295063985374772 precision 0.9293738504074383 specificity 0.8083991132735465 recall 0.9295063985374772 f1 0.9268798673949232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 33.28196454048157 s\n",
      "Accuracy 0.9303107861060329 precision 0.9302120901876166 specificity 0.8155965258019728 recall 0.9303107861060329 f1 0.9278581217607913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 33.22296595573425 s\n",
      "Accuracy 0.9293235831809872 precision 0.9291336568603191 specificity 0.8150791191104649 recall 0.9293235831809872 f1 0.9268684261277899\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 33.23596525192261 s\n",
      "Accuracy 0.9326142595978062 precision 0.9321445258811406 specificity 0.8222456421008274 recall 0.9326142595978062 f1 0.9304735523545071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 33.28996777534485 s\n",
      "Accuracy 0.9283729433272395 precision 0.9284637801573408 specificity 0.8096400553761701 recall 0.9283729433272395 f1 0.9256885001604396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 32.86496591567993 s\n",
      "Accuracy 0.9272760511882998 precision 0.9267990496948806 specificity 0.808819631996606 recall 0.9272760511882998 f1 0.9247262504259393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 33.01996636390686 s\n",
      "Accuracy 0.9304570383912248 precision 0.9300785982796642 specificity 0.8159906142316401 recall 0.9304570383912248 f1 0.9281043356576731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 33.44596719741821 s\n",
      "Accuracy 0.9279707495429617 precision 0.9276024468326619 specificity 0.8109682620155572 recall 0.9279707495429617 f1 0.9254496724211231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 33.009966135025024 s\n",
      "Accuracy 0.929981718464351 precision 0.9294337992808439 specificity 0.814600917173203 recall 0.929981718464351 f1 0.9276469912572269\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 33.240967750549316 s\n",
      "Accuracy 0.929981718464351 precision 0.9295053269836614 specificity 0.8164225390123977 recall 0.929981718464351 f1 0.927664122469686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 33.60696506500244 s\n",
      "Accuracy 0.9315173674588666 precision 0.9313699252843117 specificity 0.814062483274445 recall 0.9315173674588666 f1 0.9290671556494807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 33.19196701049805 s\n",
      "Accuracy 0.9288117001828153 precision 0.9281689841420461 specificity 0.8130652315929029 recall 0.9288117001828153 f1 0.9264541103273396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 33.398966550827026 s\n",
      "Accuracy 0.9269469835466179 precision 0.926525645234516 specificity 0.8077955181485429 recall 0.9269469835466179 f1 0.9243465796534565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 33.41196370124817 s\n",
      "Accuracy 0.9317733089579525 precision 0.9312501722918253 specificity 0.8186746693459196 recall 0.9317733089579525 f1 0.9295565337056689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 33.85296630859375 s\n",
      "Accuracy 0.9311151736745886 precision 0.9305254568158918 specificity 0.8147886492170279 recall 0.9311151736745886 f1 0.9288215058320016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 33.14496660232544 s\n",
      "Accuracy 0.9295063985374772 precision 0.9289569737472507 specificity 0.8134964288307255 recall 0.9295063985374772 f1 0.9271373069252841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 33.35496759414673 s\n",
      "Accuracy 0.929945155393053 precision 0.9295666084282711 specificity 0.8161406116910124 recall 0.929945155393053 f1 0.9275866971243342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 33.27396631240845 s\n",
      "Accuracy 0.929981718464351 precision 0.92974745474388 specificity 0.8118052997045963 recall 0.929981718464351 f1 0.9274759715235348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 33.555962324142456 s\n",
      "Accuracy 0.9325411334552103 precision 0.93209926754406 specificity 0.8178460594015761 recall 0.9325411334552103 f1 0.9302909471486149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 33.978965759277344 s\n",
      "Accuracy 0.9283363802559415 precision 0.9277964646321527 specificity 0.8105713561158857 recall 0.9283363802559415 f1 0.9258717214452644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 32.92696571350098 s\n",
      "Accuracy 0.9290310786106033 precision 0.9284685655149245 specificity 0.810922484066572 recall 0.9290310786106033 f1 0.9265963533792386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 32.78496694564819 s\n",
      "Accuracy 0.9304570383912248 precision 0.9298925163114133 specificity 0.8120744570415267 recall 0.9304570383912248 f1 0.9280781496328653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 33.18497180938721 s\n",
      "Accuracy 0.9289945155393053 precision 0.9284349551179785 specificity 0.8135870355324043 recall 0.9289945155393053 f1 0.9266218073865279\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 33.19996356964111 s\n",
      "Accuracy 0.9289579524680073 precision 0.9287132083256813 specificity 0.809644327142227 recall 0.9289579524680073 f1 0.9263842900831196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 32.92096543312073 s\n",
      "Accuracy 0.9291042047531992 precision 0.9285295574877952 specificity 0.8101637080253907 recall 0.9291042047531992 f1 0.9266571293712618\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 33.00696682929993 s\n",
      "Accuracy 0.9328702010968921 precision 0.9329457155684918 specificity 0.8205530504190154 recall 0.9328702010968921 f1 0.9305264945976277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 32.925965547561646 s\n",
      "Accuracy 0.9310786106032907 precision 0.9306091579842806 specificity 0.8190585312034916 recall 0.9310786106032907 f1 0.928839033406227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 33.03896450996399 s\n",
      "Accuracy 0.9274588665447898 precision 0.9274308090517112 specificity 0.8047692144749967 recall 0.9274588665447898 f1 0.9246716321950038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 32.68396759033203 s\n",
      "Accuracy 0.9316270566727605 precision 0.9315791931167086 specificity 0.8176853008558372 recall 0.9316270566727605 f1 0.9292315237120585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 33.709964752197266 s\n",
      "Accuracy 0.9286654478976234 precision 0.9284402220740439 specificity 0.8087601895528664 recall 0.9286654478976234 f1 0.9260587365645547\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 32.98796582221985 s\n",
      "Accuracy 0.9285191956124315 precision 0.9279143586657519 specificity 0.811211855722202 recall 0.9285191956124315 f1 0.9260971709319972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 32.765966176986694 s\n",
      "Accuracy 0.9279341864716636 precision 0.9276415030613432 specificity 0.8071852541532559 recall 0.9279341864716636 f1 0.9252960855053416\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 32.98796534538269 s\n",
      "Accuracy 0.9283729433272395 precision 0.9277046783042351 specificity 0.8088249746693487 recall 0.9283729433272395 f1 0.9259139654218637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 33.20496726036072 s\n",
      "Accuracy 0.9286288848263254 precision 0.9281507871647833 specificity 0.8102548681876486 recall 0.9286288848263254 f1 0.9261403946089161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 32.87096667289734 s\n",
      "Accuracy 0.9273126142595978 precision 0.9268828974360546 specificity 0.8070644471174886 recall 0.9273126142595978 f1 0.9247041817261847\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 33.256967306137085 s\n",
      "Accuracy 0.929908592321755 precision 0.9293988352556086 specificity 0.8171191255539042 recall 0.929908592321755 f1 0.9276178789571797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 33.091968297958374 s\n",
      "Accuracy 0.9308226691042047 precision 0.9303701115774173 specificity 0.8170337946312808 recall 0.9308226691042047 f1 0.9285260463624818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 32.945963859558105 s\n",
      "Accuracy 0.9310054844606946 precision 0.9306069462059311 specificity 0.8100138234241964 recall 0.9310054844606946 f1 0.9285318666366563\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 32.951967000961304 s\n",
      "Accuracy 0.9304936014625228 precision 0.9302054098284859 specificity 0.8077504635159881 recall 0.9304936014625228 f1 0.9279206587436386\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 33.717965602874756 s\n",
      "Accuracy 0.929981718464351 precision 0.9294355089197244 specificity 0.8177613557570589 recall 0.929981718464351 f1 0.927720563058793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 33.863964796066284 s\n",
      "Accuracy 0.9286288848263254 precision 0.9284477933713815 specificity 0.8107836994038025 recall 0.9286288848263254 f1 0.926056214752505\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 33.58796453475952 s\n",
      "Accuracy 0.9294698354661791 precision 0.9291002457255865 specificity 0.8131087251855306 recall 0.9294698354661791 f1 0.9270284886189017\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 32.88196587562561 s\n",
      "Accuracy 0.9295063985374772 precision 0.9290806209154183 specificity 0.8118771995133429 recall 0.9295063985374772 f1 0.9270555491399838\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 32.78896689414978 s\n",
      "Accuracy 0.930018281535649 precision 0.9297035428890562 specificity 0.8158709188232388 recall 0.930018281535649 f1 0.927633771568826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 33.130967140197754 s\n",
      "Accuracy 0.9270201096892139 precision 0.9264757604741769 specificity 0.8063567835091664 recall 0.9270201096892139 f1 0.9244281382618283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 33.02396512031555 s\n",
      "Accuracy 0.9296160877513712 precision 0.9291136043614439 specificity 0.8126848331460725 recall 0.9296160877513712 f1 0.9272130311812652\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 33.57696557044983 s\n",
      "Accuracy 0.926617915904936 precision 0.9261908974233913 specificity 0.8098338975096432 recall 0.926617915904936 f1 0.9240636435837385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 33.815964460372925 s\n",
      "Accuracy 0.9280804387568555 precision 0.927614257043312 specificity 0.8103973349409423 recall 0.9280804387568555 f1 0.9255807414735249\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 34.01396298408508 s\n",
      "Accuracy 0.9292504570383913 precision 0.9290099240358671 specificity 0.8111951420701643 recall 0.9292504570383913 f1 0.9267180412927754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 33.3899667263031 s\n",
      "Accuracy 0.9318098720292505 precision 0.9315476396396977 specificity 0.8157036330647515 recall 0.9318098720292505 f1 0.9294380753313654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 32.939966917037964 s\n",
      "Accuracy 0.9289945155393053 precision 0.9286569554607793 specificity 0.8145477651835961 recall 0.9289945155393053 f1 0.9265678706399585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 33.31396698951721 s\n",
      "Accuracy 0.9285923217550274 precision 0.9285281603295478 specificity 0.8074212357268601 recall 0.9285923217550274 f1 0.9259033876586396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 33.52296686172485 s\n",
      "Accuracy 0.9297623400365631 precision 0.9293962885766024 specificity 0.8173884272862112 recall 0.9297623400365631 f1 0.9274256148938631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 33.50996375083923 s\n",
      "Accuracy 0.9285557586837294 precision 0.928138669390198 specificity 0.8110868976989073 recall 0.9285557586837294 f1 0.9260649332633818\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 33.800965547561646 s\n",
      "Accuracy 0.9291042047531992 precision 0.928723063327423 specificity 0.8123804695984086 recall 0.9291042047531992 f1 0.9266425781989159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 32.987967014312744 s\n",
      "Accuracy 0.9281535648994516 precision 0.9279381169699508 specificity 0.8094463801536728 recall 0.9281535648994516 f1 0.9255501918477879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 33.32396721839905 s\n",
      "Accuracy 0.9282998171846435 precision 0.9278146447816052 specificity 0.8075936784063985 recall 0.9282998171846435 f1 0.9257430175392528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 33.312966108322144 s\n",
      "Accuracy 0.9284460694698354 precision 0.9281761572495657 specificity 0.8106059943227687 recall 0.9284460694698354 f1 0.9258933554210919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 33.100966453552246 s\n",
      "Accuracy 0.9313711151736745 precision 0.9313993438184058 specificity 0.8182266149652718 recall 0.9313711151736745 f1 0.9289613187707533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 32.9139666557312 s\n",
      "Accuracy 0.9293235831809872 precision 0.9290255388676646 specificity 0.813139085201515 recall 0.9293235831809872 f1 0.926856800129573\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 32.734970808029175 s\n",
      "Accuracy 0.9293601462522852 precision 0.9290942569835017 specificity 0.8168561911149645 recall 0.9293601462522852 f1 0.926971237783697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 33.8879599571228 s\n",
      "Accuracy 0.9296892138939671 precision 0.9289925543290679 specificity 0.8141393192019085 recall 0.9296892138939671 f1 0.9273944793010666\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 33.1329665184021 s\n",
      "Accuracy 0.9318098720292505 precision 0.9314802726340285 specificity 0.8166989869292739 recall 0.9318098720292505 f1 0.9294823054873395\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, seed in enumerate(seeds):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.927532     0.807785   0.927310  0.927532  0.924878\n1  0.928336     0.811836   0.927992  0.928336  0.925835\n2  0.933565     0.822424   0.933034  0.933565  0.931467\n3  0.929762     0.811928   0.929550  0.929762  0.927248\n4  0.929068     0.808427   0.929010  0.929068  0.926411\n5  0.929031     0.814972   0.928461  0.929031  0.926696\n6  0.927678     0.810797   0.927208  0.927678  0.925182\n7  0.927861     0.806900   0.927549  0.927861  0.925221\n8  0.928665     0.808197   0.928419  0.928665  0.926052\n9  0.926472     0.804795   0.926000  0.926472  0.923804",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.927532</td>\n      <td>0.807785</td>\n      <td>0.927310</td>\n      <td>0.927532</td>\n      <td>0.924878</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.928336</td>\n      <td>0.811836</td>\n      <td>0.927992</td>\n      <td>0.928336</td>\n      <td>0.925835</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.933565</td>\n      <td>0.822424</td>\n      <td>0.933034</td>\n      <td>0.933565</td>\n      <td>0.931467</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.929762</td>\n      <td>0.811928</td>\n      <td>0.929550</td>\n      <td>0.929762</td>\n      <td>0.927248</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.929068</td>\n      <td>0.808427</td>\n      <td>0.929010</td>\n      <td>0.929068</td>\n      <td>0.926411</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.929031</td>\n      <td>0.814972</td>\n      <td>0.928461</td>\n      <td>0.929031</td>\n      <td>0.926696</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.927678</td>\n      <td>0.810797</td>\n      <td>0.927208</td>\n      <td>0.927678</td>\n      <td>0.925182</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.927861</td>\n      <td>0.806900</td>\n      <td>0.927549</td>\n      <td>0.927861</td>\n      <td>0.925221</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.928665</td>\n      <td>0.808197</td>\n      <td>0.928419</td>\n      <td>0.928665</td>\n      <td>0.926052</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.926472</td>\n      <td>0.804795</td>\n      <td>0.926000</td>\n      <td>0.926472</td>\n      <td>0.923804</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.9292834369287021\n",
      "Precision 0.928929623375137\n",
      "Specificity 0.8120474010399105\n",
      "Recall 0.9292834369287021\n",
      "F1 0.9268089641319064\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_4beats_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}