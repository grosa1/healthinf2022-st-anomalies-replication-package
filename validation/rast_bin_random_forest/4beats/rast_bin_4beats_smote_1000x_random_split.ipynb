{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 4 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3      dw_4      dw_5     mfw_1  \\\n0  e0106  13.102095  13.097001  13.072790  3.706391  0.542614  1.240982   \n1  e0106  17.487040  17.476616  17.514101  4.949534  0.713287  1.208352   \n2  e0106  17.765692  18.767421  18.563219  5.234889  0.756572  1.239086   \n3  e0106  17.472889  18.368493  18.044299  5.083577  0.745658  1.200223   \n4  e0106  16.631755  17.107590  16.986173  4.785861  0.705577  1.207803   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.895934 -2.712703 -2.663057  ... -0.069056  0.062074 -0.071315  0.072003   \n1 -0.835234 -1.803925 -2.177733  ... -0.033026  0.017482 -0.014863  0.016572   \n2 -0.727071 -1.738814 -2.078783  ... -0.036041  0.011065 -0.006174  0.017821   \n3 -0.800412 -1.813089 -2.117043  ... -0.013610 -0.003827 -0.018916  0.046067   \n4 -0.814830 -1.677964 -1.684348  ... -0.050212  0.021235 -0.011183  0.030903   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.085813  0.018093 -0.024765 -0.023205  0.019933    NSR  \n1 -0.072260  0.024719 -0.037654 -0.001608 -0.009617    NSR  \n2 -0.030732 -0.027515 -0.018567  0.002476 -0.011823    NSR  \n3 -0.068930  0.005377 -0.029879  0.006491 -0.021803    NSR  \n4 -0.061186 -0.018751  0.003333 -0.020661  0.007397    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>13.102095</td>\n      <td>13.097001</td>\n      <td>13.072790</td>\n      <td>3.706391</td>\n      <td>0.542614</td>\n      <td>1.240982</td>\n      <td>-0.895934</td>\n      <td>-2.712703</td>\n      <td>-2.663057</td>\n      <td>...</td>\n      <td>-0.069056</td>\n      <td>0.062074</td>\n      <td>-0.071315</td>\n      <td>0.072003</td>\n      <td>-0.085813</td>\n      <td>0.018093</td>\n      <td>-0.024765</td>\n      <td>-0.023205</td>\n      <td>0.019933</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>17.487040</td>\n      <td>17.476616</td>\n      <td>17.514101</td>\n      <td>4.949534</td>\n      <td>0.713287</td>\n      <td>1.208352</td>\n      <td>-0.835234</td>\n      <td>-1.803925</td>\n      <td>-2.177733</td>\n      <td>...</td>\n      <td>-0.033026</td>\n      <td>0.017482</td>\n      <td>-0.014863</td>\n      <td>0.016572</td>\n      <td>-0.072260</td>\n      <td>0.024719</td>\n      <td>-0.037654</td>\n      <td>-0.001608</td>\n      <td>-0.009617</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>17.765692</td>\n      <td>18.767421</td>\n      <td>18.563219</td>\n      <td>5.234889</td>\n      <td>0.756572</td>\n      <td>1.239086</td>\n      <td>-0.727071</td>\n      <td>-1.738814</td>\n      <td>-2.078783</td>\n      <td>...</td>\n      <td>-0.036041</td>\n      <td>0.011065</td>\n      <td>-0.006174</td>\n      <td>0.017821</td>\n      <td>-0.030732</td>\n      <td>-0.027515</td>\n      <td>-0.018567</td>\n      <td>0.002476</td>\n      <td>-0.011823</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>17.472889</td>\n      <td>18.368493</td>\n      <td>18.044299</td>\n      <td>5.083577</td>\n      <td>0.745658</td>\n      <td>1.200223</td>\n      <td>-0.800412</td>\n      <td>-1.813089</td>\n      <td>-2.117043</td>\n      <td>...</td>\n      <td>-0.013610</td>\n      <td>-0.003827</td>\n      <td>-0.018916</td>\n      <td>0.046067</td>\n      <td>-0.068930</td>\n      <td>0.005377</td>\n      <td>-0.029879</td>\n      <td>0.006491</td>\n      <td>-0.021803</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>16.631755</td>\n      <td>17.107590</td>\n      <td>16.986173</td>\n      <td>4.785861</td>\n      <td>0.705577</td>\n      <td>1.207803</td>\n      <td>-0.814830</td>\n      <td>-1.677964</td>\n      <td>-1.684348</td>\n      <td>...</td>\n      <td>-0.050212</td>\n      <td>0.021235</td>\n      <td>-0.011183</td>\n      <td>0.030903</td>\n      <td>-0.061186</td>\n      <td>-0.018751</td>\n      <td>0.003333</td>\n      <td>-0.020661</td>\n      <td>0.007397</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_4beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    104876\nST      31872\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.312273  0.162467  0.110289  0.114818  0.091114 -0.029557   \ndw_2    0.312273  1.000000  0.840060  0.440370  0.158646  0.415202 -0.437598   \ndw_3    0.162467  0.840060  1.000000  0.613108  0.233954  0.305744 -0.499972   \ndw_4    0.110289  0.440370  0.613108  1.000000  0.900298  0.029004 -0.221348   \ndw_5    0.114818  0.158646  0.233954  0.900298  1.000000 -0.093747 -0.013018   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.023458  0.025353  0.034627  0.031590  0.013505 -0.078775  0.021517   \ncfr_13 -0.014237  0.101591  0.045318  0.027101  0.011685  0.077259  0.004550   \ncfr_14 -0.036773 -0.013728 -0.033912 -0.027459 -0.024332  0.014857  0.010542   \ncfr_15 -0.059384 -0.121356 -0.133216 -0.083792 -0.037581  0.017184  0.080945   \ncfr_16 -0.038783 -0.078300 -0.044818 -0.027346 -0.015057  0.072144 -0.034046   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.006399 -0.000875  0.001703  ... -0.042191 -0.050062 -0.008514   \ndw_2   -0.206089 -0.003727  0.005025  ... -0.143619  0.102186  0.218697   \ndw_3   -0.269989 -0.004282  0.002581  ... -0.201584  0.090697  0.252037   \ndw_4   -0.125818 -0.001509  0.000622  ... -0.139370  0.027890  0.115591   \ndw_5   -0.014289  0.000039 -0.000191  ... -0.065101 -0.007436  0.022364   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.061659  0.000381  0.003797  ... -0.114312 -0.205332 -0.130827   \ncfr_13  0.003053 -0.000895  0.001937  ...  0.110173  0.020152 -0.217039   \ncfr_14  0.014576 -0.000553  0.000869  ...  0.077729  0.198416  0.039598   \ncfr_15  0.046306  0.003503 -0.004316  ...  0.231845  0.160889 -0.064172   \ncfr_16 -0.000916  0.006364 -0.004502  ...  0.210860  0.141500  0.156332   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1    0.005894  0.015042 -0.023458 -0.014237 -0.036773 -0.059384 -0.038783  \ndw_2    0.162054  0.045198  0.025353  0.101591 -0.013728 -0.121356 -0.078300  \ndw_3    0.115305 -0.043451  0.034627  0.045318 -0.033912 -0.133216 -0.044818  \ndw_4    0.036784 -0.040897  0.031590  0.027101 -0.027459 -0.083792 -0.027346  \ndw_5    0.006044 -0.015060  0.013505  0.011685 -0.024332 -0.037581 -0.015057  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12 -0.012334  0.047726  1.000000 -0.024143 -0.054066 -0.277308 -0.170496  \ncfr_13 -0.265132 -0.093551 -0.024143  1.000000  0.126068  0.040084 -0.170708  \ncfr_14 -0.185391 -0.289586 -0.054066  0.126068  1.000000  0.090389 -0.160650  \ncfr_15 -0.148376 -0.122505 -0.277308  0.040084  0.090389  1.000000  0.127273  \ncfr_16  0.069737 -0.016755 -0.170496 -0.170708 -0.160650  0.127273  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.312273</td>\n      <td>0.162467</td>\n      <td>0.110289</td>\n      <td>0.114818</td>\n      <td>0.091114</td>\n      <td>-0.029557</td>\n      <td>0.006399</td>\n      <td>-0.000875</td>\n      <td>0.001703</td>\n      <td>...</td>\n      <td>-0.042191</td>\n      <td>-0.050062</td>\n      <td>-0.008514</td>\n      <td>0.005894</td>\n      <td>0.015042</td>\n      <td>-0.023458</td>\n      <td>-0.014237</td>\n      <td>-0.036773</td>\n      <td>-0.059384</td>\n      <td>-0.038783</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.312273</td>\n      <td>1.000000</td>\n      <td>0.840060</td>\n      <td>0.440370</td>\n      <td>0.158646</td>\n      <td>0.415202</td>\n      <td>-0.437598</td>\n      <td>-0.206089</td>\n      <td>-0.003727</td>\n      <td>0.005025</td>\n      <td>...</td>\n      <td>-0.143619</td>\n      <td>0.102186</td>\n      <td>0.218697</td>\n      <td>0.162054</td>\n      <td>0.045198</td>\n      <td>0.025353</td>\n      <td>0.101591</td>\n      <td>-0.013728</td>\n      <td>-0.121356</td>\n      <td>-0.078300</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.162467</td>\n      <td>0.840060</td>\n      <td>1.000000</td>\n      <td>0.613108</td>\n      <td>0.233954</td>\n      <td>0.305744</td>\n      <td>-0.499972</td>\n      <td>-0.269989</td>\n      <td>-0.004282</td>\n      <td>0.002581</td>\n      <td>...</td>\n      <td>-0.201584</td>\n      <td>0.090697</td>\n      <td>0.252037</td>\n      <td>0.115305</td>\n      <td>-0.043451</td>\n      <td>0.034627</td>\n      <td>0.045318</td>\n      <td>-0.033912</td>\n      <td>-0.133216</td>\n      <td>-0.044818</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.110289</td>\n      <td>0.440370</td>\n      <td>0.613108</td>\n      <td>1.000000</td>\n      <td>0.900298</td>\n      <td>0.029004</td>\n      <td>-0.221348</td>\n      <td>-0.125818</td>\n      <td>-0.001509</td>\n      <td>0.000622</td>\n      <td>...</td>\n      <td>-0.139370</td>\n      <td>0.027890</td>\n      <td>0.115591</td>\n      <td>0.036784</td>\n      <td>-0.040897</td>\n      <td>0.031590</td>\n      <td>0.027101</td>\n      <td>-0.027459</td>\n      <td>-0.083792</td>\n      <td>-0.027346</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.114818</td>\n      <td>0.158646</td>\n      <td>0.233954</td>\n      <td>0.900298</td>\n      <td>1.000000</td>\n      <td>-0.093747</td>\n      <td>-0.013018</td>\n      <td>-0.014289</td>\n      <td>0.000039</td>\n      <td>-0.000191</td>\n      <td>...</td>\n      <td>-0.065101</td>\n      <td>-0.007436</td>\n      <td>0.022364</td>\n      <td>0.006044</td>\n      <td>-0.015060</td>\n      <td>0.013505</td>\n      <td>0.011685</td>\n      <td>-0.024332</td>\n      <td>-0.037581</td>\n      <td>-0.015057</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.023458</td>\n      <td>0.025353</td>\n      <td>0.034627</td>\n      <td>0.031590</td>\n      <td>0.013505</td>\n      <td>-0.078775</td>\n      <td>0.021517</td>\n      <td>0.061659</td>\n      <td>0.000381</td>\n      <td>0.003797</td>\n      <td>...</td>\n      <td>-0.114312</td>\n      <td>-0.205332</td>\n      <td>-0.130827</td>\n      <td>-0.012334</td>\n      <td>0.047726</td>\n      <td>1.000000</td>\n      <td>-0.024143</td>\n      <td>-0.054066</td>\n      <td>-0.277308</td>\n      <td>-0.170496</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.014237</td>\n      <td>0.101591</td>\n      <td>0.045318</td>\n      <td>0.027101</td>\n      <td>0.011685</td>\n      <td>0.077259</td>\n      <td>0.004550</td>\n      <td>0.003053</td>\n      <td>-0.000895</td>\n      <td>0.001937</td>\n      <td>...</td>\n      <td>0.110173</td>\n      <td>0.020152</td>\n      <td>-0.217039</td>\n      <td>-0.265132</td>\n      <td>-0.093551</td>\n      <td>-0.024143</td>\n      <td>1.000000</td>\n      <td>0.126068</td>\n      <td>0.040084</td>\n      <td>-0.170708</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.036773</td>\n      <td>-0.013728</td>\n      <td>-0.033912</td>\n      <td>-0.027459</td>\n      <td>-0.024332</td>\n      <td>0.014857</td>\n      <td>0.010542</td>\n      <td>0.014576</td>\n      <td>-0.000553</td>\n      <td>0.000869</td>\n      <td>...</td>\n      <td>0.077729</td>\n      <td>0.198416</td>\n      <td>0.039598</td>\n      <td>-0.185391</td>\n      <td>-0.289586</td>\n      <td>-0.054066</td>\n      <td>0.126068</td>\n      <td>1.000000</td>\n      <td>0.090389</td>\n      <td>-0.160650</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.059384</td>\n      <td>-0.121356</td>\n      <td>-0.133216</td>\n      <td>-0.083792</td>\n      <td>-0.037581</td>\n      <td>0.017184</td>\n      <td>0.080945</td>\n      <td>0.046306</td>\n      <td>0.003503</td>\n      <td>-0.004316</td>\n      <td>...</td>\n      <td>0.231845</td>\n      <td>0.160889</td>\n      <td>-0.064172</td>\n      <td>-0.148376</td>\n      <td>-0.122505</td>\n      <td>-0.277308</td>\n      <td>0.040084</td>\n      <td>0.090389</td>\n      <td>1.000000</td>\n      <td>0.127273</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.038783</td>\n      <td>-0.078300</td>\n      <td>-0.044818</td>\n      <td>-0.027346</td>\n      <td>-0.015057</td>\n      <td>0.072144</td>\n      <td>-0.034046</td>\n      <td>-0.000916</td>\n      <td>0.006364</td>\n      <td>-0.004502</td>\n      <td>...</td>\n      <td>0.210860</td>\n      <td>0.141500</td>\n      <td>0.156332</td>\n      <td>0.069737</td>\n      <td>-0.016755</td>\n      <td>-0.170496</td>\n      <td>-0.170708</td>\n      <td>-0.160650</td>\n      <td>0.127273</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_135', 'mfw_11', 'fft_213', 'mfw_5', 'fft_145', 'fft_190', 'mfw_13', 'fft_170', 'fft_222', 'fft_244', 'fft_242', 'fft_208', 'fft_197', 'fft_134', 'fft_131', 'fft_225', 'fft_164', 'fft_155', 'fft_250', 'fft_188', 'fft_162', 'fft_151', 'fft_202', 'fft_203', 'fft_199', 'fft_177', 'fft_249', 'fft_200', 'fft_147', 'fft_247', 'fft_253', 'fft_153', 'fft_231', 'fft_198', 'fft_196', 'fft_163', 'fft_214', 'fft_218', 'fft_176', 'fft_130', 'fft_216', 'fft_173', 'fft_159', 'fft_206', 'fft_217', 'fft_171', 'fft_141', 'fft_185', 'fft_256', 'fft_245', 'fft_209', 'fft_142', 'fft_161', 'fft_191', 'fft_248', 'fft_241', 'fft_132', 'fft_204', 'fft_212', 'fft_228', 'fft_150', 'mfw_14', 'fft_174', 'fft_211', 'fft_251', 'fft_180', 'fft_182', 'fft_139', 'fft_194', 'fft_186', 'fft_140', 'fft_226', 'fft_149', 'fft_154', 'mfw_6', 'fft_254', 'fft_193', 'fft_148', 'fft_210', 'fft_189', 'fft_230', 'mfw_10', 'fft_160', 'mfw_15', 'mfw_7', 'fft_227', 'fft_255', 'fft_246', 'fft_146', 'fft_237', 'fft_239', 'fft_167', 'fft_232', 'fft_201', 'fft_240', 'fft_181', 'fft_184', 'fft_229', 'fft_152', 'fft_136', 'fft_138', 'fft_220', 'fft_223', 'fft_219', 'fft_169', 'mfw_16', 'fft_235', 'fft_224', 'fft_215', 'fft_166', 'fft_143', 'mfw_9', 'fft_207', 'fft_236', 'fft_179', 'fft_221', 'fft_234', 'fft_195', 'fft_165', 'fft_252', 'fft_137', 'fft_172', 'fft_178', 'fft_157', 'fft_205', 'fft_175', 'fft_243', 'fft_156', 'mfw_8', 'fft_183', 'fft_144', 'fft_168', 'fft_133', 'cfr_16', 'mfw_12', 'fft_187', 'fft_233', 'fft_238', 'fft_192', 'fft_158'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_24\n",
      "fft_25\n",
      "fft_26\n",
      "fft_27\n",
      "fft_28\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "fft_37\n",
      "fft_38\n",
      "fft_39\n",
      "fft_40\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 76\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\n0  13.102095  13.097001  13.072790  3.706391  0.542614  1.240982 -0.895934   \n1  17.487040  17.476616  17.514101  4.949534  0.713287  1.208352 -0.835234   \n2  17.765692  18.767421  18.563219  5.234889  0.756572  1.239086 -0.727071   \n3  17.472889  18.368493  18.044299  5.083577  0.745658  1.200223 -0.800412   \n4  16.631755  17.107590  16.986173  4.785861  0.705577  1.207803 -0.814830   \n\n      mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -2.712703 -2.663057  0.294201  ... -0.013426  0.064171 -0.069056  0.062074   \n1 -1.803925 -2.177733 -1.533708  ...  0.016671  0.036579 -0.033026  0.017482   \n2 -1.738814 -2.078783 -0.720965  ...  0.020868  0.035213 -0.036041  0.011065   \n3 -1.813089 -2.117043  0.838703  ...  0.026449  0.028665 -0.013610 -0.003827   \n4 -1.677964 -1.684348 -0.600837  ... -0.015116  0.060441 -0.050212  0.021235   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.071315  0.072003 -0.085813  0.018093 -0.024765 -0.023205  \n1 -0.014863  0.016572 -0.072260  0.024719 -0.037654 -0.001608  \n2 -0.006174  0.017821 -0.030732 -0.027515 -0.018567  0.002476  \n3 -0.018916  0.046067 -0.068930  0.005377 -0.029879  0.006491  \n4 -0.011183  0.030903 -0.061186 -0.018751  0.003333 -0.020661  \n\n[5 rows x 76 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.102095</td>\n      <td>13.097001</td>\n      <td>13.072790</td>\n      <td>3.706391</td>\n      <td>0.542614</td>\n      <td>1.240982</td>\n      <td>-0.895934</td>\n      <td>-2.712703</td>\n      <td>-2.663057</td>\n      <td>0.294201</td>\n      <td>...</td>\n      <td>-0.013426</td>\n      <td>0.064171</td>\n      <td>-0.069056</td>\n      <td>0.062074</td>\n      <td>-0.071315</td>\n      <td>0.072003</td>\n      <td>-0.085813</td>\n      <td>0.018093</td>\n      <td>-0.024765</td>\n      <td>-0.023205</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17.487040</td>\n      <td>17.476616</td>\n      <td>17.514101</td>\n      <td>4.949534</td>\n      <td>0.713287</td>\n      <td>1.208352</td>\n      <td>-0.835234</td>\n      <td>-1.803925</td>\n      <td>-2.177733</td>\n      <td>-1.533708</td>\n      <td>...</td>\n      <td>0.016671</td>\n      <td>0.036579</td>\n      <td>-0.033026</td>\n      <td>0.017482</td>\n      <td>-0.014863</td>\n      <td>0.016572</td>\n      <td>-0.072260</td>\n      <td>0.024719</td>\n      <td>-0.037654</td>\n      <td>-0.001608</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17.765692</td>\n      <td>18.767421</td>\n      <td>18.563219</td>\n      <td>5.234889</td>\n      <td>0.756572</td>\n      <td>1.239086</td>\n      <td>-0.727071</td>\n      <td>-1.738814</td>\n      <td>-2.078783</td>\n      <td>-0.720965</td>\n      <td>...</td>\n      <td>0.020868</td>\n      <td>0.035213</td>\n      <td>-0.036041</td>\n      <td>0.011065</td>\n      <td>-0.006174</td>\n      <td>0.017821</td>\n      <td>-0.030732</td>\n      <td>-0.027515</td>\n      <td>-0.018567</td>\n      <td>0.002476</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17.472889</td>\n      <td>18.368493</td>\n      <td>18.044299</td>\n      <td>5.083577</td>\n      <td>0.745658</td>\n      <td>1.200223</td>\n      <td>-0.800412</td>\n      <td>-1.813089</td>\n      <td>-2.117043</td>\n      <td>0.838703</td>\n      <td>...</td>\n      <td>0.026449</td>\n      <td>0.028665</td>\n      <td>-0.013610</td>\n      <td>-0.003827</td>\n      <td>-0.018916</td>\n      <td>0.046067</td>\n      <td>-0.068930</td>\n      <td>0.005377</td>\n      <td>-0.029879</td>\n      <td>0.006491</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16.631755</td>\n      <td>17.107590</td>\n      <td>16.986173</td>\n      <td>4.785861</td>\n      <td>0.705577</td>\n      <td>1.207803</td>\n      <td>-0.814830</td>\n      <td>-1.677964</td>\n      <td>-1.684348</td>\n      <td>-0.600837</td>\n      <td>...</td>\n      <td>-0.015116</td>\n      <td>0.060441</td>\n      <td>-0.050212</td>\n      <td>0.021235</td>\n      <td>-0.011183</td>\n      <td>0.030903</td>\n      <td>-0.061186</td>\n      <td>-0.018751</td>\n      <td>0.003333</td>\n      <td>-0.020661</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 76 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 62.431949615478516 s\n",
      "Accuracy 0.9374771480804388 precision 0.9375832980579194 specificity 0.8884322769311729 recall 0.9374771480804388 f1 0.9375287278860542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 59.781951665878296 s\n",
      "Accuracy 0.9359414990859232 precision 0.9361660540611068 specificity 0.8893976937124515 recall 0.9359414990859232 f1 0.9360474872802995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 60.053954124450684 s\n",
      "Accuracy 0.9348446069469836 precision 0.9349010576218759 specificity 0.8854522371800455 recall 0.9348446069469836 f1 0.9348724134368399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 60.788952589035034 s\n",
      "Accuracy 0.9336014625228519 precision 0.9334730287322267 specificity 0.8776436794064831 recall 0.9336014625228519 f1 0.9335350947390535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 59.035951375961304 s\n",
      "Accuracy 0.9358683729433273 precision 0.9358824132889425 specificity 0.8850282583637353 recall 0.9358683729433273 f1 0.9358753666665501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 61.151949405670166 s\n",
      "Accuracy 0.936453382084095 precision 0.936453382084095 specificity 0.8831184729123218 recall 0.936453382084095 f1 0.936453382084095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 59.92895174026489 s\n",
      "Accuracy 0.9382449725776966 precision 0.9382691619204819 specificity 0.8879586494079607 recall 0.9382449725776966 f1 0.9382569853092461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 59.59795093536377 s\n",
      "Accuracy 0.936745886654479 precision 0.9370909398415277 specificity 0.8906406986955474 recall 0.936745886654479 f1 0.9369044632208458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 58.603952169418335 s\n",
      "Accuracy 0.9357586837294333 precision 0.9360843971681266 specificity 0.8895431251853714 recall 0.9357586837294333 f1 0.9359091396696018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 59.79995155334473 s\n",
      "Accuracy 0.9375868372943327 precision 0.9374071579671566 specificity 0.8843596441904272 recall 0.9375868372943327 f1 0.9374919385785369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 60.46195101737976 s\n",
      "Accuracy 0.9374040219378428 precision 0.9375157673155131 specificity 0.8896489293943077 recall 0.9374040219378428 f1 0.9374582037775774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 60.27294993400574 s\n",
      "Accuracy 0.9371480804387569 precision 0.9371924018842244 specificity 0.8890943143559276 recall 0.9371480804387569 f1 0.937169962947268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 59.93895196914673 s\n",
      "Accuracy 0.9344789762340037 precision 0.9346639201719689 specificity 0.8854271137633358 recall 0.9344789762340037 f1 0.9345673520796396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 60.8359591960907 s\n",
      "Accuracy 0.9372577696526508 precision 0.9374002847361523 specificity 0.8889454077208152 recall 0.9372577696526508 f1 0.9373263772457677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 59.38996362686157 s\n",
      "Accuracy 0.9331992687385741 precision 0.9330269355572813 specificity 0.8800512076776489 recall 0.9331992687385741 f1 0.9331088533318305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 59.84596133232117 s\n",
      "Accuracy 0.9361608775137111 precision 0.9363308537335584 specificity 0.8860809661700505 recall 0.9361608775137111 f1 0.9362423516106564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 60.07296323776245 s\n",
      "Accuracy 0.9363436928702011 precision 0.9363679339285694 specificity 0.8867178897599672 recall 0.9363436928702011 f1 0.9363557325883621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 61.10296320915222 s\n",
      "Accuracy 0.9354296160877513 precision 0.9354434401780765 specificity 0.8859993828678169 recall 0.9354296160877513 f1 0.9354365019126428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 60.23696041107178 s\n",
      "Accuracy 0.9357586837294333 precision 0.9357908176010161 specificity 0.8842006484243919 recall 0.9357586837294333 f1 0.9357746163205053\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 58.34596252441406 s\n",
      "Accuracy 0.9363802559414991 precision 0.9366197848674678 specificity 0.8873128906380857 recall 0.9363802559414991 f1 0.9364932216698202\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 60.79396343231201 s\n",
      "Accuracy 0.9364899451553931 precision 0.936392710793424 specificity 0.884992893978111 recall 0.9364899451553931 f1 0.9364399355536832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 60.03896379470825 s\n",
      "Accuracy 0.9380987202925045 precision 0.9381571938299514 specificity 0.8894441303488734 recall 0.9380987202925045 f1 0.9381274770816469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 59.23896551132202 s\n",
      "Accuracy 0.9361608775137111 precision 0.9364886446472416 specificity 0.8882752570367118 recall 0.9361608775137111 f1 0.9363125238726074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 59.611963510513306 s\n",
      "Accuracy 0.9352833638025594 precision 0.9352329562129953 specificity 0.8804478173724873 recall 0.9352833638025594 f1 0.9352578322293565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 58.38496470451355 s\n",
      "Accuracy 0.9346252285191956 precision 0.9346605771874184 specificity 0.8844729969172251 recall 0.9346252285191956 f1 0.9346427390261384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 59.585963010787964 s\n",
      "Accuracy 0.9378427787934186 precision 0.9381384612627716 specificity 0.8932742723758083 recall 0.9378427787934186 f1 0.9379795665828482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 59.19696521759033 s\n",
      "Accuracy 0.9370018281535649 precision 0.9371244293818001 specificity 0.8895183900704114 recall 0.9370018281535649 f1 0.9370611122329182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 60.17596244812012 s\n",
      "Accuracy 0.9349177330895795 precision 0.9347801080445717 specificity 0.8807979447762766 recall 0.9349177330895795 f1 0.9348462681088998\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 59.70596361160278 s\n",
      "Accuracy 0.9358683729433273 precision 0.9358616534655032 specificity 0.8877116449313756 recall 0.9358683729433273 f1 0.9358650066770764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 59.53396272659302 s\n",
      "Accuracy 0.9337842778793418 precision 0.9340496822594415 specificity 0.8839956331512464 recall 0.9337842778793418 f1 0.9339091625071686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 59.931962966918945 s\n",
      "Accuracy 0.9355758683729434 precision 0.9354946107898688 specificity 0.8843566068932938 recall 0.9355758683729434 f1 0.9355342911711836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 58.54696345329285 s\n",
      "Accuracy 0.9319926873857404 precision 0.9323332628048073 specificity 0.8823440299201677 recall 0.9319926873857404 f1 0.9321509280840776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 59.678964376449585 s\n",
      "Accuracy 0.936636197440585 precision 0.9365853651110277 specificity 0.8859344133086328 recall 0.936636197440585 f1 0.9366104090104785\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 60.15196418762207 s\n",
      "Accuracy 0.9360146252285192 precision 0.9361947633557236 specificity 0.8884746135986119 recall 0.9360146252285192 f1 0.9361005910975367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 59.11396408081055 s\n",
      "Accuracy 0.9363071297989031 precision 0.936670665428783 specificity 0.8881168707619008 recall 0.9363071297989031 f1 0.9364742259209147\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 59.38396501541138 s\n",
      "Accuracy 0.9344424131627057 precision 0.9343367119345716 specificity 0.8823662860943087 recall 0.9344424131627057 f1 0.9343879854779795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 58.844964027404785 s\n",
      "Accuracy 0.9382815356489945 precision 0.9384970089137864 specificity 0.8913244997915365 recall 0.9382815356489945 f1 0.9383832928109057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 59.49796390533447 s\n",
      "Accuracy 0.9342595978062157 precision 0.9342666959626227 specificity 0.8830024947579374 recall 0.9342595978062157 f1 0.9342631403200276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 59.26096487045288 s\n",
      "Accuracy 0.9361974405850091 precision 0.9361601453352592 specificity 0.8861378855334966 recall 0.9361974405850091 f1 0.936178593708382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 59.63296341896057 s\n",
      "Accuracy 0.9342961608775137 precision 0.934327804879228 specificity 0.8845882100611197 recall 0.9342961608775137 f1 0.9343118506902753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 59.567965507507324 s\n",
      "Accuracy 0.9312979890310786 precision 0.9310954749154479 specificity 0.874290030599143 recall 0.9312979890310786 f1 0.9311913967495055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 57.49796414375305 s\n",
      "Accuracy 0.9345521023765996 precision 0.9346318960368324 specificity 0.8837835246827813 recall 0.9345521023765996 f1 0.9345912030926057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 60.09996008872986 s\n",
      "Accuracy 0.9362705667276051 precision 0.9366708586694518 specificity 0.8922087623567194 recall 0.9362705667276051 f1 0.9364520292915509\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 58.58396506309509 s\n",
      "Accuracy 0.9336014625228519 precision 0.9333082421197629 specificity 0.8768525960440089 recall 0.9336014625228519 f1 0.9334420442589748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 59.72096347808838 s\n",
      "Accuracy 0.9361608775137111 precision 0.9362772414267708 specificity 0.8857115271612136 recall 0.9361608775137111 f1 0.9362173597512884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 59.76796317100525 s\n",
      "Accuracy 0.9356489945155393 precision 0.935809113491725 specificity 0.8867591945050033 recall 0.9356489945155393 f1 0.9357258663960851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 60.23996114730835 s\n",
      "Accuracy 0.936782449725777 precision 0.9366277175493036 specificity 0.8843638653608596 recall 0.936782449725777 f1 0.9367014148338879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 59.13096380233765 s\n",
      "Accuracy 0.9349177330895795 precision 0.9349248157767827 specificity 0.8835477265153037 recall 0.9349177330895795 f1 0.934921267841966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 57.796963930130005 s\n",
      "Accuracy 0.9342595978062157 precision 0.9344658276122 specificity 0.8863287581325971 recall 0.9342595978062157 f1 0.9343576017291715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 57.39796566963196 s\n",
      "Accuracy 0.9349542961608776 precision 0.9349865902991427 specificity 0.8833427358342321 recall 0.9349542961608776 f1 0.9349703094560791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 58.97596311569214 s\n",
      "Accuracy 0.9356124314442413 precision 0.9353521035828715 specificity 0.8814862872059684 recall 0.9356124314442413 f1 0.9354714103079671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 59.52496409416199 s\n",
      "Accuracy 0.9364899451553931 precision 0.936536066394962 specificity 0.8856083473911238 recall 0.9364899451553931 f1 0.9365127249924544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 60.12796330451965 s\n",
      "Accuracy 0.9337111517367459 precision 0.9336646337346137 specificity 0.8802465580901309 recall 0.9337111517367459 f1 0.933687614156058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 59.89396119117737 s\n",
      "Accuracy 0.9358683729433273 precision 0.9359321846315701 specificity 0.8859078194215877 recall 0.9358683729433273 f1 0.9358997441789446\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 58.819963216781616 s\n",
      "Accuracy 0.9352833638025594 precision 0.9355109400878768 specificity 0.8879298986224057 recall 0.9352833638025594 f1 0.9353908624052023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 59.676963329315186 s\n",
      "Accuracy 0.9340767824497258 precision 0.9339098343102874 specificity 0.8800706847522972 recall 0.9340767824497258 f1 0.9339893527899329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 59.660964012145996 s\n",
      "Accuracy 0.9364899451553931 precision 0.9365142496716741 specificity 0.8865968069101552 recall 0.9364899451553931 f1 0.9365020164385645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 59.135966062545776 s\n",
      "Accuracy 0.936782449725777 precision 0.9365643310042615 specificity 0.8827564153254026 recall 0.936782449725777 f1 0.9366659031030296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 59.18996524810791 s\n",
      "Accuracy 0.9347349177330896 precision 0.9347108167317552 specificity 0.8846083070910186 recall 0.9347349177330896 f1 0.9347227871110529\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 60.132962226867676 s\n",
      "Accuracy 0.9373308957952468 precision 0.9372970061529114 specificity 0.8869106726846214 recall 0.9373308957952468 f1 0.9373137849640762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 60.077964544296265 s\n",
      "Accuracy 0.9364899451553931 precision 0.936625460237189 specificity 0.8859249118156846 recall 0.9364899451553931 f1 0.9365554230733415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 59.383963108062744 s\n",
      "Accuracy 0.9363071297989031 precision 0.9364274246426397 specificity 0.888206526345789 recall 0.9363071297989031 f1 0.9363653765743079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 59.836966037750244 s\n",
      "Accuracy 0.9346617915904936 precision 0.9346438559483973 specificity 0.8815237624364994 recall 0.9346617915904936 f1 0.9346527823565045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 59.62196183204651 s\n",
      "Accuracy 0.9356489945155393 precision 0.9358938823525698 specificity 0.8850338100624662 recall 0.9356489945155393 f1 0.9357646212356551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 60.22796368598938 s\n",
      "Accuracy 0.936782449725777 precision 0.9367722559600603 specificity 0.8872460171664229 recall 0.936782449725777 f1 0.9367773379920901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 59.05096459388733 s\n",
      "Accuracy 0.936526508226691 precision 0.9367410908502731 specificity 0.8876286875264956 recall 0.936526508226691 f1 0.9366282206730557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 59.47096490859985 s\n",
      "Accuracy 0.9356855575868372 precision 0.9357830136577414 specificity 0.8854321285550127 recall 0.9356855575868372 f1 0.9357330807945342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 60.129963874816895 s\n",
      "Accuracy 0.936563071297989 precision 0.9363598793515627 specificity 0.8815892008686711 recall 0.936563071297989 f1 0.9364552455119012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 59.97196435928345 s\n",
      "Accuracy 0.936672760511883 precision 0.9370718956409319 specificity 0.8918761522462069 recall 0.936672760511883 f1 0.9368538887139486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 58.56696438789368 s\n",
      "Accuracy 0.9380987202925045 precision 0.9379247420254561 specificity 0.8870767029310762 recall 0.9380987202925045 f1 0.9380067079835772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 59.16896343231201 s\n",
      "Accuracy 0.9362340036563072 precision 0.9363270427914571 specificity 0.886328248758842 recall 0.9362340036563072 f1 0.9362794044406059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 59.439964056015015 s\n",
      "Accuracy 0.9363436928702011 precision 0.9365211229549963 specificity 0.8881677648304758 recall 0.9363436928702011 f1 0.9364284489687835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 58.93596625328064 s\n",
      "Accuracy 0.9376234003656307 precision 0.937930969447366 specificity 0.8921854748319309 recall 0.9376234003656307 f1 0.9377655481133805\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 58.603959798812866 s\n",
      "Accuracy 0.9380621572212066 precision 0.9380826203640511 specificity 0.8887568990531631 recall 0.9380621572212066 f1 0.938072328938343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 57.7479510307312 s\n",
      "Accuracy 0.9353564899451554 precision 0.935384280913051 specificity 0.8860264153352342 recall 0.9353564899451554 f1 0.9353702805759461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 59.43295216560364 s\n",
      "Accuracy 0.9357221206581353 precision 0.935626700457793 specificity 0.8834380120916533 recall 0.9357221206581353 f1 0.935673113294999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 58.893954038619995 s\n",
      "Accuracy 0.9342230347349177 precision 0.934219391320255 specificity 0.8804797697895056 recall 0.9342230347349177 f1 0.9342212113698733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 60.22594976425171 s\n",
      "Accuracy 0.9351005484460695 precision 0.9352156373977792 specificity 0.8832690532476889 recall 0.9351005484460695 f1 0.9351564978799011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 59.09695076942444 s\n",
      "Accuracy 0.9368921389396709 precision 0.9369058581216214 specificity 0.887421010650563 recall 0.9368921389396709 f1 0.9368989720929303\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 60.44495129585266 s\n",
      "Accuracy 0.9373674588665448 precision 0.9375217739070039 specificity 0.8888002329418555 recall 0.9373674588665448 f1 0.9374415470059725\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 59.14495229721069 s\n",
      "Accuracy 0.9376234003656307 precision 0.9376099088493934 specificity 0.8881623245747035 recall 0.9376234003656307 f1 0.9376166280943654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 59.57795238494873 s\n",
      "Accuracy 0.9354296160877513 precision 0.9356197381879692 specificity 0.8871807692851269 recall 0.9354296160877513 f1 0.9355202379786588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 59.82495188713074 s\n",
      "Accuracy 0.9343692870201097 precision 0.9343097828174834 specificity 0.8819144614289924 recall 0.9343692870201097 f1 0.9343390591493825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 59.391952991485596 s\n",
      "Accuracy 0.9371480804387569 precision 0.9372074353863012 specificity 0.8877319860557302 recall 0.9371480804387569 f1 0.9371772788560845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 59.02995228767395 s\n",
      "Accuracy 0.9352468007312614 precision 0.9354238505620553 specificity 0.8876496540102344 recall 0.9352468007312614 f1 0.9353314012886923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 59.15595316886902 s\n",
      "Accuracy 0.9347349177330896 precision 0.9347242622446106 specificity 0.8826105318014689 recall 0.9347349177330896 f1 0.9347295751352181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 59.93895077705383 s\n",
      "Accuracy 0.9355393053016453 precision 0.9356509619210689 specificity 0.8859870814468536 recall 0.9355393053016453 f1 0.9355935506809155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 59.64195275306702 s\n",
      "Accuracy 0.9355393053016453 precision 0.9353644714535029 specificity 0.8800361889648035 recall 0.9355393053016453 f1 0.9354475425388058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 58.39493107795715 s\n",
      "Accuracy 0.9350274223034735 precision 0.9350448792835768 specificity 0.8850920774455993 recall 0.9350274223034735 f1 0.935036109815816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 57.62295460700989 s\n",
      "Accuracy 0.9362340036563072 precision 0.9363915964259715 specificity 0.8883739571585031 recall 0.9362340036563072 f1 0.9363096168810957\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 59.2479510307312 s\n",
      "Accuracy 0.9353930530164534 precision 0.9355135199665824 specificity 0.8850584612420244 recall 0.9353930530164534 f1 0.9354514873898094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 58.929948806762695 s\n",
      "Accuracy 0.9354296160877513 precision 0.9353059444650056 specificity 0.8856445110637481 recall 0.9354296160877513 f1 0.9353654242269065\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 59.35195326805115 s\n",
      "Accuracy 0.936526508226691 precision 0.9366337528791654 specificity 0.887056846003623 recall 0.936526508226691 f1 0.936578640605967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 58.217952728271484 s\n",
      "Accuracy 0.936636197440585 precision 0.9365982515931359 specificity 0.8850212911523312 recall 0.936636197440585 f1 0.936617023379005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 58.86395192146301 s\n",
      "Accuracy 0.9363802559414991 precision 0.9364519804139909 specificity 0.8855226562686301 recall 0.9363802559414991 f1 0.9364154533859188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 58.038952589035034 s\n",
      "Accuracy 0.9343327239488117 precision 0.9342356162258572 specificity 0.8813148170928254 recall 0.9343327239488117 f1 0.9342828784928551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 59.713948249816895 s\n",
      "Accuracy 0.9405484460694699 precision 0.9404325047547798 specificity 0.8892795371547745 recall 0.9405484460694699 f1 0.9404882836345284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 59.82595205307007 s\n",
      "Accuracy 0.9358318098720293 precision 0.9359376174810964 specificity 0.8848876312506553 recall 0.9358318098720293 f1 0.9358833178846558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 60.094948053359985 s\n",
      "Accuracy 0.9352102376599635 precision 0.9354011535583547 specificity 0.8867120049815607 recall 0.9352102376599635 f1 0.9353012568960031\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 59.442951679229736 s\n",
      "Accuracy 0.9384277879341865 precision 0.9382726288911947 specificity 0.886457300772605 recall 0.9384277879341865 f1 0.9383463546522809\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 59.6719536781311 s\n",
      "Accuracy 0.9363802559414991 precision 0.9366354129673035 specificity 0.8875749564499115 recall 0.9363802559414991 f1 0.9365001636356501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 59.935951232910156 s\n",
      "Accuracy 0.9374405850091407 precision 0.9376996505347319 specificity 0.8908318770395323 recall 0.9374405850091407 f1 0.9375617846603137\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 59.411954402923584 s\n",
      "Accuracy 0.9368921389396709 precision 0.9369986563438253 specificity 0.8878121180550302 recall 0.9368921389396709 f1 0.9369439072380149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 59.18395137786865 s\n",
      "Accuracy 0.933418647166362 precision 0.9334804735714275 specificity 0.8823129794657486 recall 0.933418647166362 f1 0.9334490875647687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 59.627951860427856 s\n",
      "Accuracy 0.9374405850091407 precision 0.937492975078298 specificity 0.8876339990300345 recall 0.9374405850091407 f1 0.9374664058966593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 61.43153667449951 s\n",
      "Accuracy 0.9375868372943327 precision 0.9378625759385851 specificity 0.8908021263519792 recall 0.9375868372943327 f1 0.9377153862541746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 60.993175983428955 s\n",
      "Accuracy 0.9374771480804388 precision 0.9374903696834778 specificity 0.8905520482474154 recall 0.9374771480804388 f1 0.9374837326689054\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 59.70841693878174 s\n",
      "Accuracy 0.9372943327239488 precision 0.9373535520699399 specificity 0.88799539287006 recall 0.9372943327239488 f1 0.9373234631984788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 60.67556643486023 s\n",
      "Accuracy 0.9380621572212066 precision 0.9380970818914314 specificity 0.8873858947315576 recall 0.9380621572212066 f1 0.9380794521302726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 62.16098642349243 s\n",
      "Accuracy 0.9357586837294333 precision 0.9359161026825707 specificity 0.8862310702858547 recall 0.9357586837294333 f1 0.9358343386576076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 61.6099636554718 s\n",
      "Accuracy 0.9354296160877513 precision 0.9354855004587771 specificity 0.886582914146421 recall 0.9354296160877513 f1 0.9354571391139312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 60.34296274185181 s\n",
      "Accuracy 0.9338208409506399 precision 0.9338639698076067 specificity 0.8829171637864086 recall 0.9338208409506399 f1 0.9338421696531714\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 63.57896280288696 s\n",
      "Accuracy 0.9357952468007312 precision 0.936055401858335 specificity 0.88819820356659 recall 0.9357952468007312 f1 0.9359172650284778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 62.36496162414551 s\n",
      "Accuracy 0.9374040219378428 precision 0.9376035747870467 specificity 0.8908977092532867 recall 0.9374040219378428 f1 0.9374986305919621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 62.372962474823 s\n",
      "Accuracy 0.9351371115173674 precision 0.9353083241864338 specificity 0.8848629337815906 recall 0.9351371115173674 f1 0.9352192212918645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 61.283963441848755 s\n",
      "Accuracy 0.9380255941499086 precision 0.9385317137423611 specificity 0.8936740236386763 recall 0.9380255941499086 f1 0.9382502027812805\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 62.71026659011841 s\n",
      "Accuracy 0.9361608775137111 precision 0.9365019493919349 specificity 0.8891931892130905 recall 0.9361608775137111 f1 0.9363180593913849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 59.18696427345276 s\n",
      "Accuracy 0.9368921389396709 precision 0.9367838846162918 specificity 0.8841302390124453 recall 0.9368921389396709 f1 0.9368363036922148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 61.21596336364746 s\n",
      "Accuracy 0.9336380255941499 precision 0.9337666517496637 specificity 0.8836933882619321 recall 0.9336380255941499 f1 0.9337003372385319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 60.8160285949707 s\n",
      "Accuracy 0.9350274223034735 precision 0.9348513239046449 specificity 0.8820479942255065 recall 0.9350274223034735 f1 0.934934744677069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 61.552242279052734 s\n",
      "Accuracy 0.9375502742230347 precision 0.9375016705114315 specificity 0.8846280443569042 recall 0.9375502742230347 f1 0.9375256430686757\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 60.18396210670471 s\n",
      "Accuracy 0.9342595978062157 precision 0.9342028073471909 specificity 0.8808445276969076 recall 0.9342595978062157 f1 0.9342307795883734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 60.43896484375 s\n",
      "Accuracy 0.9343327239488117 precision 0.9345666843622956 specificity 0.8851066723275813 recall 0.9343327239488117 f1 0.9344433950938008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 60.62681770324707 s\n",
      "Accuracy 0.9358683729433273 precision 0.9361848209857804 specificity 0.8887804545244846 recall 0.9358683729433273 f1 0.9360149883340992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 61.92511463165283 s\n",
      "Accuracy 0.9352102376599635 precision 0.9352384818032676 specificity 0.8846704308721806 recall 0.9352102376599635 f1 0.9352242543971313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 60.75502872467041 s\n",
      "Accuracy 0.9363071297989031 precision 0.9362726974830264 specificity 0.8851112520903357 recall 0.9363071297989031 f1 0.9362897480042088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 60.775962352752686 s\n",
      "Accuracy 0.9368190127970749 precision 0.9367710406313805 specificity 0.885284683318911 recall 0.9368190127970749 f1 0.9367947008312011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 61.7661919593811 s\n",
      "Accuracy 0.9364899451553931 precision 0.9362830360386871 specificity 0.8824289358654299 recall 0.9364899451553931 f1 0.9363798766072766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 60.58589839935303 s\n",
      "Accuracy 0.9350639853747715 precision 0.9350218890016364 specificity 0.8827106077798519 recall 0.9350639853747715 f1 0.9350426991652023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 60.03543210029602 s\n",
      "Accuracy 0.9343327239488117 precision 0.9343982417439364 specificity 0.8828950321687052 recall 0.9343327239488117 f1 0.9343649493029087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 62.64196062088013 s\n",
      "Accuracy 0.936636197440585 precision 0.9369433781456711 specificity 0.888408756711482 recall 0.936636197440585 f1 0.9367788935180429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 61.77799201011658 s\n",
      "Accuracy 0.9361608775137111 precision 0.9364066057421402 specificity 0.8878274325258119 recall 0.9361608775137111 f1 0.9362765423804752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 61.26900887489319 s\n",
      "Accuracy 0.9343692870201097 precision 0.9346453771392592 specificity 0.8862139756055951 recall 0.9343692870201097 f1 0.9344986112104625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 61.44396352767944 s\n",
      "Accuracy 0.9351736745886654 precision 0.9353092819187573 specificity 0.8850771085613671 recall 0.9351736745886654 f1 0.935239220404465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 60.948962688446045 s\n",
      "Accuracy 0.9383546617915904 precision 0.9383478725981108 specificity 0.8883123597944256 recall 0.9383546617915904 f1 0.9383512605187285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 60.48396325111389 s\n",
      "Accuracy 0.9352468007312614 precision 0.9355521037911371 specificity 0.8879815819592676 recall 0.9352468007312614 f1 0.9353886924278905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 60.1330828666687 s\n",
      "Accuracy 0.9351736745886654 precision 0.9349097698498174 specificity 0.88021859218188 recall 0.9351736745886654 f1 0.935030851875849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 61.574795961380005 s\n",
      "Accuracy 0.9356489945155393 precision 0.9357761184320494 specificity 0.8881871255332143 recall 0.9356489945155393 f1 0.9357104389476097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 59.948336362838745 s\n",
      "Accuracy 0.9346252285191956 precision 0.9350549975653927 specificity 0.8862392545951614 recall 0.9346252285191956 f1 0.934820875442034\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 59.83901286125183 s\n",
      "Accuracy 0.936453382084095 precision 0.9367501436257131 specificity 0.8899312192392641 recall 0.936453382084095 f1 0.9365912324062245\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 61.067015171051025 s\n",
      "Accuracy 0.9345886654478976 precision 0.934536176421552 specificity 0.8822947105632032 recall 0.9345886654478976 f1 0.934562050240335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 62.56262421607971 s\n",
      "Accuracy 0.9350639853747715 precision 0.934907996597458 specificity 0.8813034818089994 recall 0.9350639853747715 f1 0.9349824886131219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 61.966962814331055 s\n",
      "Accuracy 0.936526508226691 precision 0.9365620270296594 specificity 0.8851746406125088 recall 0.936526508226691 f1 0.9365441011743793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 62.631433963775635 s\n",
      "Accuracy 0.9321755027422304 precision 0.9319894760994201 specificity 0.8762202742218943 recall 0.9321755027422304 f1 0.932077872986699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 62.9015154838562 s\n",
      "Accuracy 0.936745886654479 precision 0.9368216206846516 specificity 0.8891773721035273 recall 0.936745886654479 f1 0.936782959360326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 61.670241594314575 s\n",
      "Accuracy 0.933016453382084 precision 0.9331369228230637 specificity 0.8809914207247735 recall 0.933016453382084 f1 0.9330750064390367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 60.137107133865356 s\n",
      "Accuracy 0.936965265082267 precision 0.9369380415336005 specificity 0.8866331004446485 recall 0.936965265082267 f1 0.9369515472905988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 58.98496413230896 s\n",
      "Accuracy 0.9371480804387569 precision 0.9372739356760639 specificity 0.8875576497967727 recall 0.9371480804387569 f1 0.9372089701053191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 59.50696420669556 s\n",
      "Accuracy 0.9354661791590494 precision 0.9354626415148573 specificity 0.8835781064216658 recall 0.9354661791590494 f1 0.935464408681098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 58.94996404647827 s\n",
      "Accuracy 0.9362705667276051 precision 0.936138881121589 specificity 0.8831045849541561 recall 0.9362705667276051 f1 0.9362021936916709\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 60.21996068954468 s\n",
      "Accuracy 0.9379159049360146 precision 0.9380214868212019 specificity 0.8891135558328067 recall 0.9379159049360146 f1 0.9379671985692833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 60.13296699523926 s\n",
      "Accuracy 0.9334917733089579 precision 0.9335321361932563 specificity 0.8809194022557617 recall 0.9334917733089579 f1 0.9335117556354032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 59.11396288871765 s\n",
      "Accuracy 0.9356855575868372 precision 0.9357991727845035 specificity 0.8846735158515057 recall 0.9356855575868372 f1 0.9357407706007814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 59.74937868118286 s\n",
      "Accuracy 0.9344058500914076 precision 0.9348431028649576 specificity 0.8897336625986346 recall 0.9344058500914076 f1 0.93460340618608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 60.637566804885864 s\n",
      "Accuracy 0.9357952468007312 precision 0.936063813015404 specificity 0.888138915246404 recall 0.9357952468007312 f1 0.9359209985289921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 62.64681935310364 s\n",
      "Accuracy 0.9358683729433273 precision 0.935671009036022 specificity 0.8823861410649455 recall 0.9358683729433273 f1 0.9357637249433121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 59.63410782814026 s\n",
      "Accuracy 0.9357221206581353 precision 0.9357718237160547 specificity 0.8852333568406757 recall 0.9357221206581353 f1 0.935746648473862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 60.54356551170349 s\n",
      "Accuracy 0.9370018281535649 precision 0.9371945680818572 specificity 0.8887091874862306 recall 0.9370018281535649 f1 0.9370935434831189\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 59.92396402359009 s\n",
      "Accuracy 0.9375137111517368 precision 0.9373736541541061 specificity 0.8860444976522601 recall 0.9375137111517368 f1 0.9374406105579585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 59.077964782714844 s\n",
      "Accuracy 0.9385374771480804 precision 0.9383763578139014 specificity 0.8850558724042197 recall 0.9385374771480804 f1 0.9384528718140721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 60.284990310668945 s\n",
      "Accuracy 0.9350274223034735 precision 0.9349751224489683 specificity 0.8828206452167665 recall 0.9350274223034735 f1 0.9350009009343827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 61.68298864364624 s\n",
      "Accuracy 0.9395246800731262 precision 0.940161968415969 specificity 0.8980924561623655 recall 0.9395246800731262 f1 0.9397986959573538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 60.773961782455444 s\n",
      "Accuracy 0.936453382084095 precision 0.9365764880350622 specificity 0.8864707394246124 recall 0.936453382084095 f1 0.9365130164686056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 61.2249641418457 s\n",
      "Accuracy 0.9358683729433273 precision 0.9359679544418307 specificity 0.8868341470192211 recall 0.9358683729433273 f1 0.9359168735284752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 59.71409511566162 s\n",
      "Accuracy 0.9351736745886654 precision 0.935364076331388 specificity 0.8852255290805955 recall 0.9351736745886654 f1 0.9352645795817746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 60.07268166542053 s\n",
      "Accuracy 0.9371115173674589 precision 0.9374668733035709 specificity 0.8923694255862412 recall 0.9371115173674589 f1 0.937274061525689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 59.820523262023926 s\n",
      "Accuracy 0.9379524680073126 precision 0.937929061305775 specificity 0.8886449996233193 recall 0.9379524680073126 f1 0.9379406834040721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 60.41055417060852 s\n",
      "Accuracy 0.9351005484460695 precision 0.9351630096562987 specificity 0.8824469064772615 recall 0.9351005484460695 f1 0.9351312986375696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 60.735979080200195 s\n",
      "Accuracy 0.9373308957952468 precision 0.937414814586866 specificity 0.8885579283895414 recall 0.9373308957952468 f1 0.9373719011827167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 59.796308517456055 s\n",
      "Accuracy 0.9330895795246801 precision 0.9333064874379775 specificity 0.8814600314966448 recall 0.9330895795246801 f1 0.9331928727496014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 59.9016649723053 s\n",
      "Accuracy 0.933308957952468 precision 0.9333460757057565 specificity 0.8797388472425232 recall 0.933308957952468 f1 0.9333273517615983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 61.159879207611084 s\n",
      "Accuracy 0.9371480804387569 precision 0.9373990730061076 specificity 0.8880817631584078 recall 0.9371480804387569 f1 0.9372660883820418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 62.396950244903564 s\n",
      "Accuracy 0.9341499085923217 precision 0.9341826223796094 specificity 0.8818337183552656 recall 0.9341499085923217 f1 0.9341661318966911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 61.19195103645325 s\n",
      "Accuracy 0.9349542961608776 precision 0.935240644152395 specificity 0.8860594311017381 recall 0.9349542961608776 f1 0.9350882012250132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 59.51195240020752 s\n",
      "Accuracy 0.9344424131627057 precision 0.9346084338438753 specificity 0.885032432316708 recall 0.9344424131627057 f1 0.9345221034778479\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 59.82295203208923 s\n",
      "Accuracy 0.9339305301645339 precision 0.9344163119465303 specificity 0.8865023357419415 recall 0.9339305301645339 f1 0.9341494240202087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 61.082512617111206 s\n",
      "Accuracy 0.936526508226691 precision 0.9368604061620682 specificity 0.8891107158460521 recall 0.936526508226691 f1 0.9366806404244912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 60.084951400756836 s\n",
      "Accuracy 0.9360877513711152 precision 0.93639186280406 specificity 0.8899343536291588 recall 0.9360877513711152 f1 0.9362287820274408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 59.995952129364014 s\n",
      "Accuracy 0.9396343692870202 precision 0.9397560432566504 specificity 0.8916937181618536 recall 0.9396343692870202 f1 0.9396931541022195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 61.95895719528198 s\n",
      "Accuracy 0.9356124314442413 precision 0.9358012488154044 specificity 0.8861760813665508 recall 0.9356124314442413 f1 0.9357025433826393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 59.790393590927124 s\n",
      "Accuracy 0.9336014625228519 precision 0.933661171966866 specificity 0.8801700336715548 recall 0.9336014625228519 f1 0.9336308938904848\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 58.9518084526062 s\n",
      "Accuracy 0.9360511882998171 precision 0.9361707869194023 specificity 0.8860349793632916 recall 0.9360511882998171 f1 0.9361091843673915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 60.365028381347656 s\n",
      "Accuracy 0.9348080438756856 precision 0.9350315231864593 specificity 0.884750895142784 recall 0.9348080438756856 f1 0.934914036462987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 60.68479084968567 s\n",
      "Accuracy 0.9380255941499086 precision 0.9380919195693577 specificity 0.888494697039577 recall 0.9380255941499086 f1 0.9380581549097198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 60.56901526451111 s\n",
      "Accuracy 0.9346983546617916 precision 0.9346911423370015 specificity 0.8814710684667805 recall 0.9346983546617916 f1 0.9346947418666345\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 59.374920129776 s\n",
      "Accuracy 0.936563071297989 precision 0.9365255305468301 specificity 0.8858270146862292 recall 0.936563071297989 f1 0.9365441006584413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 60.29053997993469 s\n",
      "Accuracy 0.936965265082267 precision 0.9369865434425774 specificity 0.8850586634702342 recall 0.936965265082267 f1 0.9369758440745961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 60.30187654495239 s\n",
      "Accuracy 0.9346617915904936 precision 0.9351046255670998 specificity 0.8863977053343661 recall 0.9346617915904936 f1 0.934862884675726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 60.175379037857056 s\n",
      "Accuracy 0.9363802559414991 precision 0.9364722590347039 specificity 0.8873001075085756 recall 0.9363802559414991 f1 0.9364251419609462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 59.554956912994385 s\n",
      "Accuracy 0.9387934186471664 precision 0.9389720915480878 specificity 0.8908465749819391 recall 0.9387934186471664 f1 0.9388785773620184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 60.24482798576355 s\n",
      "Accuracy 0.9372577696526508 precision 0.9373688535493033 specificity 0.8900153495989452 recall 0.9372577696526508 f1 0.9373116261943274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 61.173256635665894 s\n",
      "Accuracy 0.9359780621572212 precision 0.9359277895152611 specificity 0.8864315528554978 recall 0.9359780621572212 f1 0.9359525568377767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 62.246325731277466 s\n",
      "Accuracy 0.9339305301645339 precision 0.9339127650354112 specificity 0.8818997184166291 recall 0.9339305301645339 f1 0.9339216065480337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 60.760751247406006 s\n",
      "Accuracy 0.9345886654478976 precision 0.9349749905596899 specificity 0.888631510718912 recall 0.9345886654478976 f1 0.9347652081709513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 60.7406952381134 s\n",
      "Accuracy 0.9356124314442413 precision 0.9356662489215197 specificity 0.8844445234422613 recall 0.9356124314442413 f1 0.9356389676242184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 59.67483949661255 s\n",
      "Accuracy 0.9346983546617916 precision 0.9347700448925372 specificity 0.8845801537278971 recall 0.9346983546617916 f1 0.9347335433696231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 59.46115279197693 s\n",
      "Accuracy 0.9353199268738575 precision 0.9354228048059225 specificity 0.8868196929736623 recall 0.9353199268738575 f1 0.9353699891785039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 56.861117124557495 s\n",
      "Accuracy 0.9355027422303474 precision 0.935468042595922 specificity 0.8840615862197225 recall 0.9355027422303474 f1 0.9354852273336904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 54.877562522888184 s\n",
      "Accuracy 0.9363436928702011 precision 0.9364982512457317 specificity 0.8880472492579025 recall 0.9363436928702011 f1 0.936417924443038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 54.473564863204956 s\n",
      "Accuracy 0.9360877513711152 precision 0.936245840391684 specificity 0.8880375081873476 recall 0.9360877513711152 f1 0.9361636125657529\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 54.56986856460571 s\n",
      "Accuracy 0.936855575868373 precision 0.9367982385513298 specificity 0.8861795879719443 recall 0.936855575868373 f1 0.9368264286685516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 55.6712760925293 s\n",
      "Accuracy 0.9353564899451554 precision 0.9353564899451554 specificity 0.8848098443318856 recall 0.9353564899451554 f1 0.9353564899451554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 55.35665774345398 s\n",
      "Accuracy 0.9374771480804388 precision 0.9378142424100587 specificity 0.891011974526331 recall 0.9374771480804388 f1 0.9376322693462016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 55.27452731132507 s\n",
      "Accuracy 0.9386471663619744 precision 0.9387164055523747 specificity 0.8896223587445317 recall 0.9386471663619744 f1 0.9386811180171902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 55.68609929084778 s\n",
      "Accuracy 0.936526508226691 precision 0.9366919885302334 specificity 0.8884453303299474 recall 0.936526508226691 f1 0.9366057588852735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 54.3512978553772 s\n",
      "Accuracy 0.9361974405850091 precision 0.9364889837870558 specificity 0.8877822734105721 recall 0.9361974405850091 f1 0.9363333904290196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 55.900373458862305 s\n",
      "Accuracy 0.9322851919561244 precision 0.9321767336052844 specificity 0.8765899133141047 recall 0.9322851919561244 f1 0.932229480106592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 54.90855169296265 s\n",
      "Accuracy 0.9363071297989031 precision 0.9365853016230453 specificity 0.8904208507503268 recall 0.9363071297989031 f1 0.9364367540597348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 56.04304361343384 s\n",
      "Accuracy 0.9378062157221206 precision 0.9378369187681406 specificity 0.8889510848849321 recall 0.9378062157221206 f1 0.9378214329880801\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 54.701316118240356 s\n",
      "Accuracy 0.9347349177330896 precision 0.9350303953816415 specificity 0.8857333089129981 recall 0.9347349177330896 f1 0.9348728912486257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 55.169535398483276 s\n",
      "Accuracy 0.9381352833638026 precision 0.9382790715896312 specificity 0.8887771403093574 recall 0.9381352833638026 f1 0.9382045009006209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 55.24037837982178 s\n",
      "Accuracy 0.9371846435100548 precision 0.937276089175891 specificity 0.8882528963786612 recall 0.9371846435100548 f1 0.9372292464733594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 55.15687966346741 s\n",
      "Accuracy 0.9345155393053016 precision 0.9346447772035984 specificity 0.8838389863029649 recall 0.9345155393053016 f1 0.9345781407413162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 55.115784883499146 s\n",
      "Accuracy 0.9370383912248629 precision 0.9375601993147341 specificity 0.8940518825424496 recall 0.9370383912248629 f1 0.9372689865326127\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 55.45703411102295 s\n",
      "Accuracy 0.9360511882998171 precision 0.9360823581347015 specificity 0.8867803942391104 recall 0.9360511882998171 f1 0.936066640022397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 55.533873319625854 s\n",
      "Accuracy 0.9376965265082267 precision 0.9378535010029753 specificity 0.8895836427803845 recall 0.9376965265082267 f1 0.9377718000844859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 54.983649015426636 s\n",
      "Accuracy 0.9345521023765996 precision 0.9347213473240211 specificity 0.8854368434946208 recall 0.9345521023765996 f1 0.9346332575487828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 55.06321454048157 s\n",
      "Accuracy 0.9378793418647167 precision 0.938033745164231 specificity 0.8890681900387285 recall 0.9378793418647167 f1 0.9379534614358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 54.82861304283142 s\n",
      "Accuracy 0.9334917733089579 precision 0.9333871064591771 specificity 0.8774723837473903 recall 0.9334917733089579 f1 0.9334380433148823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 55.53263592720032 s\n",
      "Accuracy 0.9361608775137111 precision 0.9359117172993866 specificity 0.8825794783979805 recall 0.9361608775137111 f1 0.9360262195423938\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 55.72598576545715 s\n",
      "Accuracy 0.9360877513711152 precision 0.9360073973055787 specificity 0.8854967832766861 recall 0.9360877513711152 f1 0.9360466259340786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 55.56051588058472 s\n",
      "Accuracy 0.936745886654479 precision 0.9369051840395728 specificity 0.887842774961953 recall 0.936745886654479 f1 0.9368223276021027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 53.73536252975464 s\n",
      "Accuracy 0.9350639853747715 precision 0.9352473170865823 specificity 0.8864933198187538 recall 0.9350639853747715 f1 0.9351515506246486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 54.46670651435852 s\n",
      "Accuracy 0.933564899451554 precision 0.9334974218255715 specificity 0.8800655386190336 recall 0.933564899451554 f1 0.9335305664279796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 54.50935626029968 s\n",
      "Accuracy 0.9353564899451554 precision 0.9355173425311678 specificity 0.8862143904693432 recall 0.9353564899451554 f1 0.9354337302422489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 55.510069608688354 s\n",
      "Accuracy 0.9377330895795247 precision 0.9380143517072683 specificity 0.8916362584562518 recall 0.9377330895795247 f1 0.9378639168813905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 55.72695207595825 s\n",
      "Accuracy 0.936965265082267 precision 0.9369791274544635 specificity 0.886652150818087 recall 0.936965265082267 f1 0.9369721697181289\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 54.40361952781677 s\n",
      "Accuracy 0.9370383912248629 precision 0.9373298947700865 specificity 0.8917091681502297 recall 0.9370383912248629 f1 0.9371736361758873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 55.099048376083374 s\n",
      "Accuracy 0.936453382084095 precision 0.9362218670476814 specificity 0.8809753602087111 recall 0.936453382084095 f1 0.9363294183230988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 55.486506938934326 s\n",
      "Accuracy 0.9347349177330896 precision 0.9348346651709566 specificity 0.8829816136450394 recall 0.9347349177330896 f1 0.9347835850874648\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 54.48630380630493 s\n",
      "Accuracy 0.9341499085923217 precision 0.9341391705380298 specificity 0.8816603273191556 recall 0.9341499085923217 f1 0.9341445247356335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 55.83349561691284 s\n",
      "Accuracy 0.9355027422303474 precision 0.9359568718818563 specificity 0.8891039129517068 recall 0.9355027422303474 f1 0.9357076729459436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 55.5985689163208 s\n",
      "Accuracy 0.9382449725776966 precision 0.9382415027918483 specificity 0.8866536200438213 recall 0.9382449725776966 f1 0.9382432360045845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 55.820353507995605 s\n",
      "Accuracy 0.9357586837294333 precision 0.9356295565888294 specificity 0.8804238996440812 recall 0.9357586837294333 f1 0.935691827129409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 55.18567633628845 s\n",
      "Accuracy 0.9370383912248629 precision 0.9369595989338567 specificity 0.8875024306186657 recall 0.9370383912248629 f1 0.9369980462621524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 55.738497495651245 s\n",
      "Accuracy 0.9337477148080439 precision 0.9335971076274509 specificity 0.8801404812654992 recall 0.9337477148080439 f1 0.9336692305502471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 55.542511224746704 s\n",
      "Accuracy 0.9357952468007312 precision 0.9359344783037873 specificity 0.8855947098170264 recall 0.9357952468007312 f1 0.9358624711677517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 55.58650851249695 s\n",
      "Accuracy 0.9371480804387569 precision 0.9372643992089391 specificity 0.8888901106026741 recall 0.9371480804387569 f1 0.9372044397819008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 55.04654145240784 s\n",
      "Accuracy 0.936416819012797 precision 0.9365187891435708 specificity 0.8881695860490244 recall 0.936416819012797 f1 0.9364664206207124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 54.75056076049805 s\n",
      "Accuracy 0.9357952468007312 precision 0.9356805958218299 specificity 0.8835804773311859 recall 0.9357952468007312 f1 0.9357360099549074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 52.9916718006134 s\n",
      "Accuracy 0.9372212065813529 precision 0.9374165074648728 specificity 0.8909353504115666 recall 0.9372212065813529 f1 0.9373138833500764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 55.936487674713135 s\n",
      "Accuracy 0.9352102376599635 precision 0.9351333343859292 specificity 0.8818632531536849 recall 0.9352102376599635 f1 0.9351709830270749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 53.921613931655884 s\n",
      "Accuracy 0.9352833638025594 precision 0.9352417326143511 specificity 0.8837183148170761 recall 0.9352833638025594 f1 0.9352623107186325\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 54.57757115364075 s\n",
      "Accuracy 0.936782449725777 precision 0.9368275830384476 specificity 0.8874849731687722 recall 0.936782449725777 f1 0.9368047371449647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 54.53757452964783 s\n",
      "Accuracy 0.9378793418647167 precision 0.9380840187055655 specificity 0.8907250299949242 recall 0.9378793418647167 f1 0.9379762942018864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 55.56751084327698 s\n",
      "Accuracy 0.9372212065813529 precision 0.9373829688811925 specificity 0.8888156855689893 recall 0.9372212065813529 f1 0.937298730480656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 55.548511266708374 s\n",
      "Accuracy 0.9351005484460695 precision 0.9351697543947625 specificity 0.8834018051653413 recall 0.9351005484460695 f1 0.9351345536409528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 54.26859188079834 s\n",
      "Accuracy 0.9376599634369287 precision 0.93764336666387 specificity 0.8892792268036679 recall 0.9376599634369287 f1 0.9376516238283131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 54.64956498146057 s\n",
      "Accuracy 0.9359414990859232 precision 0.9363599861208737 specificity 0.8893272869690315 recall 0.9359414990859232 f1 0.9361315128844727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 55.39052128791809 s\n",
      "Accuracy 0.9349908592321755 precision 0.9350190461158707 specificity 0.8847059968369526 recall 0.9349908592321755 f1 0.9350048475845316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 55.016544818878174 s\n",
      "Accuracy 0.9368921389396709 precision 0.9369611015608534 specificity 0.8889040862312034 recall 0.9368921389396709 f1 0.9369259621877821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 55.49051284790039 s\n",
      "Accuracy 0.9353199268738575 precision 0.93564334445107 specificity 0.8898000282075826 recall 0.9353199268738575 f1 0.9354693051172077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 55.15753674507141 s\n",
      "Accuracy 0.9350639853747715 precision 0.9351639306553007 specificity 0.8860654599870709 recall 0.9350639853747715 f1 0.9351126737792267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 55.427518367767334 s\n",
      "Accuracy 0.936855575868373 precision 0.9371862337929207 specificity 0.8911121446094826 recall 0.936855575868373 f1 0.9370078700580975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 56.159472703933716 s\n",
      "Accuracy 0.9363802559414991 precision 0.9365384097954403 specificity 0.8881862272982987 recall 0.9363802559414991 f1 0.9364561421988177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 53.177732706069946 s\n",
      "Accuracy 0.9376234003656307 precision 0.9377865468055266 specificity 0.890231868266941 recall 0.9376234003656307 f1 0.9377014733314546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 55.46653413772583 s\n",
      "Accuracy 0.9374040219378428 precision 0.9373172876429251 specificity 0.886227645651671 recall 0.9374040219378428 f1 0.9373595309532156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 54.09854531288147 s\n",
      "Accuracy 0.9344058500914076 precision 0.9345296376669224 specificity 0.8847953010452199 recall 0.9344058500914076 f1 0.9344658503175389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 55.16453671455383 s\n",
      "Accuracy 0.9362705667276051 precision 0.9362740411207778 specificity 0.8857034486074031 recall 0.9362705667276051 f1 0.9362723022701307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 54.63154053688049 s\n",
      "Accuracy 0.9388665447897624 precision 0.9389411067117459 specificity 0.8916151686460689 recall 0.9388665447897624 f1 0.9389030230233794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 54.56405186653137 s\n",
      "Accuracy 0.9346252285191956 precision 0.9347210148900335 specificity 0.8830269370100889 recall 0.9346252285191956 f1 0.9346720046477778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 54.350743532180786 s\n",
      "Accuracy 0.9352468007312614 precision 0.9352085948617038 specificity 0.8837268063505576 recall 0.9352468007312614 f1 0.9352274982901247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 55.032562494277954 s\n",
      "Accuracy 0.9381352833638026 precision 0.9383331101619411 specificity 0.892027258564304 recall 0.9381352833638026 f1 0.9382290169387516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 56.3930127620697 s\n",
      "Accuracy 0.9380621572212066 precision 0.9381232900000678 specificity 0.8905100155606369 recall 0.9380621572212066 f1 0.9380921883080058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 54.77283000946045 s\n",
      "Accuracy 0.9376965265082267 precision 0.9376292608023502 specificity 0.8864796687892242 recall 0.9376965265082267 f1 0.9376622268311621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 55.12456297874451 s\n",
      "Accuracy 0.9356489945155393 precision 0.935593851197012 specificity 0.8839583973934677 recall 0.9356489945155393 f1 0.9356209998111411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 54.47461915016174 s\n",
      "Accuracy 0.93327239488117 precision 0.9337852358080801 specificity 0.8846754053083783 recall 0.93327239488117 f1 0.9335031537094782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 55.54486012458801 s\n",
      "Accuracy 0.9356489945155393 precision 0.9354526728679893 specificity 0.8826954294596723 recall 0.9356489945155393 f1 0.9355448884581052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 54.112085819244385 s\n",
      "Accuracy 0.9352102376599635 precision 0.9352385440782803 specificity 0.884495162101373 recall 0.9352102376599635 f1 0.9352242854530058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 55.46508264541626 s\n",
      "Accuracy 0.9373308957952468 precision 0.9372424762293488 specificity 0.8846786490758914 recall 0.9373308957952468 f1 0.9372855551385125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 54.55081534385681 s\n",
      "Accuracy 0.9360511882998171 precision 0.9362071341103292 specificity 0.8871613719149647 recall 0.9360511882998171 f1 0.9361261103928459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 54.74881315231323 s\n",
      "Accuracy 0.9363071297989031 precision 0.936611563022134 specificity 0.8899981047817984 recall 0.9363071297989031 f1 0.9364482995573121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 55.349862575531006 s\n",
      "Accuracy 0.9392687385740403 precision 0.9394220251483517 specificity 0.8941902426024687 recall 0.9392687385740403 f1 0.9393420379048067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 54.918487548828125 s\n",
      "Accuracy 0.9374040219378428 precision 0.9372656978586803 specificity 0.8852574028361302 recall 0.9374040219378428 f1 0.9373319214189663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 55.84976243972778 s\n",
      "Accuracy 0.9374405850091407 precision 0.9373963477470899 specificity 0.886285463181194 recall 0.9374405850091407 f1 0.9374181848344549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 55.667234659194946 s\n",
      "Accuracy 0.9363436928702011 precision 0.9365002666410993 specificity 0.8870205751045893 recall 0.9363436928702011 f1 0.9364189178404321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 53.85665988922119 s\n",
      "Accuracy 0.93345521023766 precision 0.9334266909629237 specificity 0.8810105578023881 recall 0.93345521023766 f1 0.9334408456323282\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 54.91771459579468 s\n",
      "Accuracy 0.9360146252285192 precision 0.9359512608425972 specificity 0.8822017494486721 recall 0.9360146252285192 f1 0.9359824016599907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 54.834269762039185 s\n",
      "Accuracy 0.9359414990859232 precision 0.9359274735941693 specificity 0.8841915258208494 recall 0.9359414990859232 f1 0.9359344598036741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 55.70657777786255 s\n",
      "Accuracy 0.9371480804387569 precision 0.9371862212405734 specificity 0.8875562428832976 recall 0.9371480804387569 f1 0.9371669502902226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 55.02757692337036 s\n",
      "Accuracy 0.936709323583181 precision 0.9365377058465034 specificity 0.8848720789635689 recall 0.936709323583181 f1 0.9366188673725107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 55.640331506729126 s\n",
      "Accuracy 0.936563071297989 precision 0.9364511246763043 specificity 0.8836204898540206 recall 0.936563071297989 f1 0.9365052836512199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 55.687581062316895 s\n",
      "Accuracy 0.9386837294332724 precision 0.9387140480166961 specificity 0.8904135501539877 recall 0.9386837294332724 f1 0.9386987541595171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 55.01038384437561 s\n",
      "Accuracy 0.9350274223034735 precision 0.9351574001594097 specificity 0.8836782293950524 recall 0.9350274223034735 f1 0.9350903819481603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 55.48297333717346 s\n",
      "Accuracy 0.9349177330895795 precision 0.9350604657000643 specificity 0.8873871503248301 recall 0.9349177330895795 f1 0.9349864932127543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 55.60792899131775 s\n",
      "Accuracy 0.9374405850091407 precision 0.9372991082488549 specificity 0.8852291665625248 recall 0.9374405850091407 f1 0.937366765480979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 55.161216259002686 s\n",
      "Accuracy 0.9385740402193784 precision 0.9386358543671338 specificity 0.8899628228993927 recall 0.9385740402193784 f1 0.9386044077214296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 55.99549078941345 s\n",
      "Accuracy 0.9337477148080439 precision 0.9338824454539542 specificity 0.8823898347325511 recall 0.9337477148080439 f1 0.933812948127111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 55.427649974823 s\n",
      "Accuracy 0.9330530164533821 precision 0.9331535430112367 specificity 0.8813464217586701 recall 0.9330530164533821 f1 0.9331020847353608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 55.365108013153076 s\n",
      "Accuracy 0.9392321755027422 precision 0.9391793470520662 specificity 0.8892045607719631 recall 0.9392321755027422 f1 0.939205332806806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 55.919113874435425 s\n",
      "Accuracy 0.9337111517367459 precision 0.9333958750628364 specificity 0.8777798845394307 recall 0.9337111517367459 f1 0.9335380128638385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 55.52259373664856 s\n",
      "Accuracy 0.9358683729433273 precision 0.9360725359791068 specificity 0.888146463630599 recall 0.9358683729433273 f1 0.935965302604148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 54.10672926902771 s\n",
      "Accuracy 0.936965265082267 precision 0.9370869139001751 specificity 0.8877261068601997 recall 0.936965265082267 f1 0.937024171753549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 55.763333320617676 s\n",
      "Accuracy 0.9351371115173674 precision 0.9352359170806923 specificity 0.8870060794852509 recall 0.9351371115173674 f1 0.9351852345389592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 54.74342894554138 s\n",
      "Accuracy 0.9362340036563072 precision 0.9363046924426139 specificity 0.8865961926384445 recall 0.9362340036563072 f1 0.9362686874480265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 56.34814977645874 s\n",
      "Accuracy 0.9382084095063985 precision 0.9381300919967015 specificity 0.8885786741730416 recall 0.9382084095063985 f1 0.9381682953230671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 55.55122995376587 s\n",
      "Accuracy 0.9342961608775137 precision 0.9343213788167418 specificity 0.8824078781811207 recall 0.9342961608775137 f1 0.9343086891407444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 55.08776926994324 s\n",
      "Accuracy 0.9370018281535649 precision 0.9371866483603444 specificity 0.8887496079807916 recall 0.9370018281535649 f1 0.9370899304651995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 55.748936891555786 s\n",
      "Accuracy 0.9385009140767825 precision 0.9389190999065151 specificity 0.8944956666773868 recall 0.9385009140767825 f1 0.9386892555042686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 55.58436179161072 s\n",
      "Accuracy 0.9351005484460695 precision 0.9351190088943213 specificity 0.8805797515631543 recall 0.9351005484460695 f1 0.9351097368480343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 54.54308867454529 s\n",
      "Accuracy 0.9354661791590494 precision 0.9356416949706351 specificity 0.8884646485571283 recall 0.9354661791590494 f1 0.935550018596111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 55.54401421546936 s\n",
      "Accuracy 0.9351736745886654 precision 0.9354599372562559 specificity 0.8862268187248762 recall 0.9351736745886654 f1 0.9353075232283663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 54.54920506477356 s\n",
      "Accuracy 0.9344058500914076 precision 0.9345485614914218 specificity 0.8827336817039815 recall 0.9344058500914076 f1 0.9344748176789934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 56.22583985328674 s\n",
      "Accuracy 0.9378062157221206 precision 0.9378168333805706 specificity 0.885316648660743 recall 0.9378062157221206 f1 0.9378115093974217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 55.880945444107056 s\n",
      "Accuracy 0.9368190127970749 precision 0.9369467341486519 specificity 0.8885377954027656 recall 0.9368190127970749 f1 0.9368807340503413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 55.3948814868927 s\n",
      "Accuracy 0.9362340036563072 precision 0.9365376892763662 specificity 0.8901416109660801 recall 0.9362340036563072 f1 0.9363748153568379\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 52.96755385398865 s\n",
      "Accuracy 0.9368190127970749 precision 0.9368468053855256 specificity 0.8868580381429004 recall 0.9368190127970749 f1 0.9368328030834177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 55.37880086898804 s\n",
      "Accuracy 0.9338939670932358 precision 0.9341622998745799 specificity 0.8844636095675331 recall 0.9338939670932358 f1 0.9340200942002719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 53.7505202293396 s\n",
      "Accuracy 0.9381718464351005 precision 0.9381480156343193 specificity 0.8873772073210454 recall 0.9381718464351005 f1 0.9381598491187974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 55.587833881378174 s\n",
      "Accuracy 0.9348811700182815 precision 0.9348428503612123 specificity 0.8832908790887367 recall 0.9348811700182815 f1 0.9348618110197936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 54.9364447593689 s\n",
      "Accuracy 0.9331992687385741 precision 0.933298327483797 specificity 0.882637946295702 recall 0.9331992687385741 f1 0.933247608017486\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 55.11951446533203 s\n",
      "Accuracy 0.9379524680073126 precision 0.9381390048637854 specificity 0.8918439222074845 recall 0.9379524680073126 f1 0.9380411039123704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 54.97153663635254 s\n",
      "Accuracy 0.9373308957952468 precision 0.9373659520486269 specificity 0.8866757506648956 recall 0.9373308957952468 f1 0.9373482572228771\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 55.230889558792114 s\n",
      "Accuracy 0.9364899451553931 precision 0.9363843975640675 specificity 0.8835383119060711 recall 0.9364899451553931 f1 0.936435570406331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 56.14352250099182 s\n",
      "Accuracy 0.9346252285191956 precision 0.9349657766488993 specificity 0.8862398191008497 recall 0.9346252285191956 f1 0.934782769561113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 56.45276689529419 s\n",
      "Accuracy 0.9354296160877513 precision 0.9356305403486139 specificity 0.8860105920573248 recall 0.9354296160877513 f1 0.9355252642830069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 55.915549755096436 s\n",
      "Accuracy 0.9360146252285192 precision 0.9361697899172116 specificity 0.8855320720632005 recall 0.9360146252285192 f1 0.9360892770920394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 54.97613525390625 s\n",
      "Accuracy 0.933418647166362 precision 0.9333072061475832 specificity 0.8775252713008012 recall 0.933418647166362 f1 0.9333613327077127\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 54.939154624938965 s\n",
      "Accuracy 0.9346252285191956 precision 0.9347693135841771 specificity 0.8820639160066736 recall 0.9346252285191956 f1 0.934694870746924\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 55.28553628921509 s\n",
      "Accuracy 0.936563071297989 precision 0.9366305013216538 specificity 0.8863443084998917 recall 0.936563071297989 f1 0.9365961875263796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 55.27559804916382 s\n",
      "Accuracy 0.9365996343692871 precision 0.9366705272878267 specificity 0.8865814199370818 recall 0.9365996343692871 f1 0.9366344177195185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 55.8887038230896 s\n",
      "Accuracy 0.936563071297989 precision 0.9368707229914413 specificity 0.8882365843462758 recall 0.936563071297989 f1 0.9367060025961956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 54.882418155670166 s\n",
      "Accuracy 0.9359049360146252 precision 0.93597981237487 specificity 0.8858282712953973 recall 0.9359049360146252 f1 0.9359416456792342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 54.58961486816406 s\n",
      "Accuracy 0.9355027422303474 precision 0.9353141498559191 specificity 0.8833536861828146 recall 0.9355027422303474 f1 0.9354029128727191\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 55.354899406433105 s\n",
      "Accuracy 0.9356124314442413 precision 0.9357081247879234 specificity 0.8868355638142768 recall 0.9356124314442413 f1 0.935659081733087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 55.64447355270386 s\n",
      "Accuracy 0.9363071297989031 precision 0.9363920542196863 specificity 0.8870219258125571 recall 0.9363071297989031 f1 0.9363486412954694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 55.01886868476868 s\n",
      "Accuracy 0.9352102376599635 precision 0.9352243658788617 specificity 0.884160649689511 recall 0.9352102376599635 f1 0.9352172753916814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 56.31688642501831 s\n",
      "Accuracy 0.9361243144424132 precision 0.9359815318339562 specificity 0.8838592287845091 recall 0.9361243144424132 f1 0.9360498636777297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 55.485342502593994 s\n",
      "Accuracy 0.9361974405850091 precision 0.9362292867322115 specificity 0.8851716185926914 recall 0.9361974405850091 f1 0.9362132292993492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 55.53711724281311 s\n",
      "Accuracy 0.9374405850091407 precision 0.9373140673280828 specificity 0.8868048238178535 recall 0.9374405850091407 f1 0.9373748081204079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 55.20179319381714 s\n",
      "Accuracy 0.9368921389396709 precision 0.9367601109008723 specificity 0.8850768999464419 recall 0.9368921389396709 f1 0.9368234704117734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 53.8095018863678 s\n",
      "Accuracy 0.9372943327239488 precision 0.9373733242934201 specificity 0.8897985527348816 recall 0.9372943327239488 f1 0.9373329578435721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 54.80695867538452 s\n",
      "Accuracy 0.9392321755027422 precision 0.9395636666863166 specificity 0.8954188186065685 recall 0.9392321755027422 f1 0.9393839204273554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 55.163344383239746 s\n",
      "Accuracy 0.9344789762340037 precision 0.9346274314423187 specificity 0.8839885016570178 recall 0.9344789762340037 f1 0.9345505694914128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 56.62975811958313 s\n",
      "Accuracy 0.9361974405850091 precision 0.9362869879737463 specificity 0.8861105794978856 recall 0.9361974405850091 f1 0.9362411794279422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 55.128780126571655 s\n",
      "Accuracy 0.9363071297989031 precision 0.9361557433948519 specificity 0.8842789893915483 recall 0.9363071297989031 f1 0.9362279370076004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 55.3178391456604 s\n",
      "Accuracy 0.9362340036563072 precision 0.936582081428912 specificity 0.88960357223245 recall 0.9362340036563072 f1 0.9363940997639483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 55.72178316116333 s\n",
      "Accuracy 0.9376599634369287 precision 0.9377534646940584 specificity 0.8898542104989295 recall 0.9376599634369287 f1 0.9377055092372164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 55.78809666633606 s\n",
      "Accuracy 0.9374405850091407 precision 0.9376052620310548 specificity 0.8911668501647109 recall 0.9374405850091407 f1 0.9375192918426898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 56.13835668563843 s\n",
      "Accuracy 0.9383546617915904 precision 0.9384026159924836 specificity 0.8895532018096689 recall 0.9383546617915904 f1 0.9383783128196221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 55.655487060546875 s\n",
      "Accuracy 0.9357221206581353 precision 0.9360336167968168 specificity 0.8855235302132528 recall 0.9357221206581353 f1 0.9358672055684766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 54.519004106521606 s\n",
      "Accuracy 0.9382084095063985 precision 0.9381813484084437 specificity 0.887774439950385 recall 0.9382084095063985 f1 0.9381947721371541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 56.65794634819031 s\n",
      "Accuracy 0.9351736745886654 precision 0.9351553248929868 specificity 0.8798957977416019 recall 0.9351736745886654 f1 0.935164457825515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 54.838194847106934 s\n",
      "Accuracy 0.9370018281535649 precision 0.9371052616806809 specificity 0.8874012496779058 recall 0.9370018281535649 f1 0.9370521482330747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 55.74124765396118 s\n",
      "Accuracy 0.9341133455210238 precision 0.9343296571207786 specificity 0.8854557038636791 recall 0.9341133455210238 f1 0.9342160038259858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 55.11037087440491 s\n",
      "Accuracy 0.9361608775137111 precision 0.9360601929099445 specificity 0.8846254215253806 recall 0.9361608775137111 f1 0.9361090477678289\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 55.635042905807495 s\n",
      "Accuracy 0.9386471663619744 precision 0.9387782605006094 specificity 0.892037793706307 recall 0.9386471663619744 f1 0.9387103226115241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 54.900957345962524 s\n",
      "Accuracy 0.9328702010968921 precision 0.9328916212613289 specificity 0.8822074410422921 recall 0.9328702010968921 f1 0.9328808526529513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 56.08373403549194 s\n",
      "Accuracy 0.9359049360146252 precision 0.9359366149027243 specificity 0.8854249651733054 recall 0.9359049360146252 f1 0.9359206416467701\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 55.45689558982849 s\n",
      "Accuracy 0.9344424131627057 precision 0.9343092590014542 specificity 0.8812995287554032 recall 0.9344424131627057 f1 0.9343733312416548\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 56.07489252090454 s\n",
      "Accuracy 0.9370383912248629 precision 0.9372484960139071 specificity 0.8865736731387457 recall 0.9370383912248629 f1 0.9371381914588353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 55.8368935585022 s\n",
      "Accuracy 0.9357586837294333 precision 0.9356094565718988 specificity 0.8835353318428467 recall 0.9357586837294333 f1 0.9356807276968568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 54.33689785003662 s\n",
      "Accuracy 0.9351736745886654 precision 0.9353107281343224 specificity 0.8842140620014451 recall 0.9351736745886654 f1 0.9352399348737735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 55.69689345359802 s\n",
      "Accuracy 0.9390859232175502 precision 0.9390471269890748 specificity 0.8911940327628286 recall 0.9390859232175502 f1 0.939066286560648\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 55.093894958496094 s\n",
      "Accuracy 0.9356855575868372 precision 0.9358122622773165 specificity 0.886141502141046 recall 0.9356855575868372 f1 0.9357468893599077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 54.976895332336426 s\n",
      "Accuracy 0.9350639853747715 precision 0.9351500234570077 specificity 0.8852560567461997 recall 0.9350639853747715 f1 0.9351060580412124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 55.240896463394165 s\n",
      "Accuracy 0.9350274223034735 precision 0.9351685330366455 specificity 0.8862506256981098 recall 0.9350274223034735 f1 0.9350954851325805\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 55.06489562988281 s\n",
      "Accuracy 0.9341864716636198 precision 0.9342460847718546 specificity 0.8806397053927048 recall 0.9341864716636198 f1 0.934215853274663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 55.05689477920532 s\n",
      "Accuracy 0.9357952468007312 precision 0.9357060398414908 specificity 0.8831805151201348 recall 0.9357952468007312 f1 0.9357495223659079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 53.71289849281311 s\n",
      "Accuracy 0.9361974405850091 precision 0.9364053426789631 specificity 0.8884357798755911 recall 0.9361974405850091 f1 0.9362960423988935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 54.094897985458374 s\n",
      "Accuracy 0.9380255941499086 precision 0.9380357704930712 specificity 0.8887917654518581 recall 0.9380255941499086 f1 0.9380306673730975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 53.86889624595642 s\n",
      "Accuracy 0.9374040219378428 precision 0.9374318580111883 specificity 0.8870660854476429 recall 0.9374040219378428 f1 0.937417833429611\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 54.91889405250549 s\n",
      "Accuracy 0.9371115173674589 precision 0.9370369242330597 specificity 0.885294556873261 recall 0.9371115173674589 f1 0.9370734146763932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 53.370898723602295 s\n",
      "Accuracy 0.9354296160877513 precision 0.9354439550376404 specificity 0.8830889107906682 recall 0.9354296160877513 f1 0.9354367590025584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 54.733896017074585 s\n",
      "Accuracy 0.9356489945155393 precision 0.9352880672390547 specificity 0.8796358208101263 recall 0.9356489945155393 f1 0.9354461826592568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 55.27689528465271 s\n",
      "Accuracy 0.9373308957952468 precision 0.9374967445963601 specificity 0.8887675590478578 recall 0.9373308957952468 f1 0.9374103067129684\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 55.84989309310913 s\n",
      "Accuracy 0.936526508226691 precision 0.936596453464182 specificity 0.8875963338549736 recall 0.936526508226691 f1 0.9365608212815759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 55.908891916275024 s\n",
      "Accuracy 0.9362340036563072 precision 0.9363341177507142 specificity 0.8866305554731123 recall 0.9362340036563072 f1 0.9362827645568194\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 55.844890117645264 s\n",
      "Accuracy 0.9351005484460695 precision 0.9351472290996485 specificity 0.8838449501035406 recall 0.9351005484460695 f1 0.9351236097124616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 54.916893005371094 s\n",
      "Accuracy 0.9336380255941499 precision 0.9336057620423255 specificity 0.8805366251216901 recall 0.9336380255941499 f1 0.933621760483906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 55.98789358139038 s\n",
      "Accuracy 0.9360877513711152 precision 0.9362387765420769 specificity 0.8877408889224881 recall 0.9360877513711152 f1 0.9361603604165656\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 54.661895751953125 s\n",
      "Accuracy 0.9371846435100548 precision 0.9372751640054219 specificity 0.8890422665572534 recall 0.9371846435100548 f1 0.937228787966725\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 54.46589493751526 s\n",
      "Accuracy 0.9342961608775137 precision 0.934383956610203 specificity 0.879486937117466 recall 0.9342961608775137 f1 0.9343391744900327\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 54.61489462852478 s\n",
      "Accuracy 0.9375502742230347 precision 0.9373089140703008 specificity 0.8856285917502801 recall 0.9375502742230347 f1 0.937419514585035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 55.38489556312561 s\n",
      "Accuracy 0.936782449725777 precision 0.9367997782585986 specificity 0.8866669414728957 recall 0.936782449725777 f1 0.9367910725812023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 54.13689708709717 s\n",
      "Accuracy 0.936782449725777 precision 0.9366998981752346 specificity 0.8868072480463008 recall 0.936782449725777 f1 0.9367401439585863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 55.23589468002319 s\n",
      "Accuracy 0.9348446069469836 precision 0.9351396925532348 specificity 0.8870754993664225 recall 0.9348446069469836 f1 0.9349821766124553\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 54.99189472198486 s\n",
      "Accuracy 0.9348811700182815 precision 0.9349353240822166 specificity 0.8835198626035253 recall 0.9348811700182815 f1 0.9349078756929647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 55.032893657684326 s\n",
      "Accuracy 0.9357952468007312 precision 0.9356366228462475 specificity 0.8834590815038963 recall 0.9357952468007312 f1 0.9357121308121993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 54.255895137786865 s\n",
      "Accuracy 0.9355027422303474 precision 0.9353548275111364 specificity 0.8824579824436563 recall 0.9355027422303474 f1 0.93542558182635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 54.507896184921265 s\n",
      "Accuracy 0.9377330895795247 precision 0.9378048423790254 specificity 0.8902140207363748 recall 0.9377330895795247 f1 0.9377682385004817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 54.04289770126343 s\n",
      "Accuracy 0.9352833638025594 precision 0.935263208675736 specificity 0.8869265401146615 recall 0.9352833638025594 f1 0.9352732276570404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 54.65989589691162 s\n",
      "Accuracy 0.9363802559414991 precision 0.9364990958152154 specificity 0.8891894711152342 recall 0.9363802559414991 f1 0.9364377823964991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 55.035895347595215 s\n",
      "Accuracy 0.9359780621572212 precision 0.9359537310464537 specificity 0.8845466333006087 recall 0.9359780621572212 f1 0.935965815467929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 55.32489204406738 s\n",
      "Accuracy 0.936965265082267 precision 0.9372391661740854 specificity 0.8897483056455058 recall 0.936965265082267 f1 0.9370931582495501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 53.450894355773926 s\n",
      "Accuracy 0.9360146252285192 precision 0.936336019436758 specificity 0.8917454827232161 recall 0.9360146252285192 f1 0.9361627294600359\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 55.10491967201233 s\n",
      "Accuracy 0.9353199268738575 precision 0.9354108059500176 specificity 0.8844073479340826 recall 0.9353199268738575 f1 0.9353643328707252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 54.81994104385376 s\n",
      "Accuracy 0.9336014625228519 precision 0.9334699780391602 specificity 0.8799185734226835 recall 0.9336014625228519 f1 0.9335333471285728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 55.67694139480591 s\n",
      "Accuracy 0.936709323583181 precision 0.9369170904402904 specificity 0.8916964194375807 recall 0.936709323583181 f1 0.9368075306194912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 55.66794300079346 s\n",
      "Accuracy 0.9372577696526508 precision 0.9373205450840105 specificity 0.8880033139300624 recall 0.9372577696526508 f1 0.937288620273952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 56.21194267272949 s\n",
      "Accuracy 0.936636197440585 precision 0.9366396706706909 specificity 0.8859337661924714 recall 0.936636197440585 f1 0.9366379323971674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 54.078943967819214 s\n",
      "Accuracy 0.9348080438756856 precision 0.9350840418444867 specificity 0.886527430034613 recall 0.9348080438756856 f1 0.934937295682126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 54.2249436378479 s\n",
      "Accuracy 0.9351005484460695 precision 0.9350482694650267 specificity 0.8828919387035681 recall 0.9351005484460695 f1 0.9350740373618794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 55.40094447135925 s\n",
      "Accuracy 0.9394515539305301 precision 0.9395453939625711 specificity 0.8935100024303431 recall 0.9394515539305301 f1 0.9394971761710874\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 53.77894568443298 s\n",
      "Accuracy 0.936636197440585 precision 0.9367318123110756 specificity 0.8875101451178508 recall 0.936636197440585 f1 0.9366827997114198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 55.17093849182129 s\n",
      "Accuracy 0.9352468007312614 precision 0.9354731606231448 specificity 0.88692658963873 recall 0.9352468007312614 f1 0.935353867870404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 55.21693992614746 s\n",
      "Accuracy 0.9359414990859232 precision 0.9359065132461216 specificity 0.8836430610679469 recall 0.9359414990859232 f1 0.9359238400568383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 53.67094087600708 s\n",
      "Accuracy 0.9342230347349177 precision 0.9347656516754568 specificity 0.8896012259179482 recall 0.9342230347349177 f1 0.9344638421396406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 54.37293863296509 s\n",
      "Accuracy 0.936672760511883 precision 0.9367214178217845 specificity 0.8874568243528977 recall 0.936672760511883 f1 0.9366967655886349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 55.617937326431274 s\n",
      "Accuracy 0.936855575868373 precision 0.9371096101184012 specificity 0.891953882405073 recall 0.936855575868373 f1 0.9369743545951238\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 55.29293942451477 s\n",
      "Accuracy 0.9348811700182815 precision 0.9349548912453414 specificity 0.8864457091855287 recall 0.9348811700182815 f1 0.934917311511901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 53.518941164016724 s\n",
      "Accuracy 0.9386106032906765 precision 0.9385809051637837 specificity 0.8897696937093428 recall 0.9386106032906765 f1 0.9385956197434349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 54.7259407043457 s\n",
      "Accuracy 0.9374405850091407 precision 0.9377468584116738 specificity 0.891346598850149 recall 0.9374405850091407 f1 0.9375823388820936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 54.23693919181824 s\n",
      "Accuracy 0.9389396709323583 precision 0.9387734286290486 specificity 0.8896177203325512 recall 0.9389396709323583 f1 0.9388517223754266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 54.16994047164917 s\n",
      "Accuracy 0.9356124314442413 precision 0.9360945547031024 specificity 0.8898770222749234 recall 0.9356124314442413 f1 0.935828639214961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 55.157939434051514 s\n",
      "Accuracy 0.9346983546617916 precision 0.9347342909769139 specificity 0.8831946552239267 recall 0.9346983546617916 f1 0.9347161579538038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 54.08393836021423 s\n",
      "Accuracy 0.9318829981718464 precision 0.9319679556814219 specificity 0.8808386239423565 recall 0.9318829981718464 f1 0.9319246180311063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 54.900938987731934 s\n",
      "Accuracy 0.9371115173674589 precision 0.9371183820291067 specificity 0.887247734577592 recall 0.9371115173674589 f1 0.9371149430708268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 55.24993968009949 s\n",
      "Accuracy 0.936416819012797 precision 0.9363196883150684 specificity 0.8850380230434265 recall 0.936416819012797 f1 0.936366862540615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 55.621936082839966 s\n",
      "Accuracy 0.936965265082267 precision 0.9368335965312208 specificity 0.8853247499793842 recall 0.936965265082267 f1 0.9368967773018204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 55.02193999290466 s\n",
      "Accuracy 0.9361243144424132 precision 0.9362045294640086 specificity 0.8879251515761317 recall 0.9361243144424132 f1 0.9361635541352431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 55.29793906211853 s\n",
      "Accuracy 0.9374771480804388 precision 0.9374908276374434 specificity 0.8879748895387842 recall 0.9374771480804388 f1 0.9374839613299816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 54.522939682006836 s\n",
      "Accuracy 0.9395978062157221 precision 0.9395978062157221 specificity 0.8928186471799234 recall 0.9395978062157221 f1 0.9395978062157221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 53.895941734313965 s\n",
      "Accuracy 0.9374771480804388 precision 0.9371502249051984 specificity 0.8834870155844792 recall 0.9374771480804388 f1 0.93729427329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 54.67293953895569 s\n",
      "Accuracy 0.9383912248628885 precision 0.9384975342725985 specificity 0.8915082614757667 recall 0.9383912248628885 f1 0.9384427905504428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 55.45793867111206 s\n",
      "Accuracy 0.9355027422303474 precision 0.9354888757205434 specificity 0.88485475094753 recall 0.9355027422303474 f1 0.9354957826325035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 53.555941104888916 s\n",
      "Accuracy 0.9372577696526508 precision 0.9370205815622641 specificity 0.885101900885653 recall 0.9372577696526508 f1 0.9371296087435176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 55.14393711090088 s\n",
      "Accuracy 0.9368190127970749 precision 0.9368470861069834 specificity 0.8860649851382146 recall 0.9368190127970749 f1 0.9368329430624526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 53.72694110870361 s\n",
      "Accuracy 0.9344058500914076 precision 0.9343425404192988 specificity 0.8814235294398342 recall 0.9344058500914076 f1 0.9343736606230058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 55.730937242507935 s\n",
      "Accuracy 0.9356855575868372 precision 0.935710532362599 specificity 0.8839777647463252 recall 0.9356855575868372 f1 0.9356979637079952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 54.2939395904541 s\n",
      "Accuracy 0.936672760511883 precision 0.9367068802118569 specificity 0.8884067932455536 recall 0.936672760511883 f1 0.9366896560870472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 52.717941761016846 s\n",
      "Accuracy 0.9340767824497258 precision 0.9339359015376126 specificity 0.8803591555392347 recall 0.9340767824497258 f1 0.9340035730307149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 54.468939781188965 s\n",
      "Accuracy 0.936965265082267 precision 0.9367935247510563 specificity 0.8835836036512719 recall 0.936965265082267 f1 0.9368748834075984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 55.05793881416321 s\n",
      "Accuracy 0.9371480804387569 precision 0.9374727726538222 specificity 0.8927132880451227 recall 0.9371480804387569 f1 0.9372974506934898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 54.75793719291687 s\n",
      "Accuracy 0.9370749542961608 precision 0.9374485552511143 specificity 0.8911845588474765 recall 0.9370749542961608 f1 0.9372455676700067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 54.255940198898315 s\n",
      "Accuracy 0.9331992687385741 precision 0.9336636199974165 specificity 0.883113086410914 recall 0.9331992687385741 f1 0.9334103837610931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 53.36893844604492 s\n",
      "Accuracy 0.9359414990859232 precision 0.936338309144734 specificity 0.8901042451960416 recall 0.9359414990859232 f1 0.936122148046615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 55.03593993186951 s\n",
      "Accuracy 0.9349542961608776 precision 0.935074504327545 specificity 0.8849684822101046 recall 0.9349542961608776 f1 0.935012608323519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 55.09093880653381 s\n",
      "Accuracy 0.9361243144424132 precision 0.9362484406821238 specificity 0.8880280527035953 recall 0.9361243144424132 f1 0.9361843652581896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 54.928938150405884 s\n",
      "Accuracy 0.9358318098720293 precision 0.9358710363581152 specificity 0.8845814549771308 recall 0.9358318098720293 f1 0.9358512225590335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 55.14493942260742 s\n",
      "Accuracy 0.9351005484460695 precision 0.9353294447393731 specificity 0.8859361786183174 recall 0.9351005484460695 f1 0.9352088656369331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 53.22094106674194 s\n",
      "Accuracy 0.9394881170018281 precision 0.9393403990784643 specificity 0.8892228482783344 recall 0.9394881170018281 f1 0.9394105694370462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 55.60893654823303 s\n",
      "Accuracy 0.9327239488117002 precision 0.9328387719999398 specificity 0.8791865099688109 recall 0.9327239488117002 f1 0.9327798757222805\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 54.966938495635986 s\n",
      "Accuracy 0.9355758683729434 precision 0.9356110418417449 specificity 0.8854126867840321 recall 0.9355758683729434 f1 0.9355932904178711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 54.8259391784668 s\n",
      "Accuracy 0.936709323583181 precision 0.9367891883703796 specificity 0.8886100653504263 recall 0.936709323583181 f1 0.9367483857311568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 55.67693614959717 s\n",
      "Accuracy 0.9390859232175502 precision 0.9390724132577363 specificity 0.8888586205808152 recall 0.9390859232175502 f1 0.9390791414041758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 54.854939222335815 s\n",
      "Accuracy 0.9331992687385741 precision 0.9331610304297451 specificity 0.8825315258022267 recall 0.9331992687385741 f1 0.933179952974932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 55.9589364528656 s\n",
      "Accuracy 0.9368921389396709 precision 0.9370581755515308 specificity 0.8884075575717878 recall 0.9368921389396709 f1 0.9369716539481522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 54.83594012260437 s\n",
      "Accuracy 0.9357221206581353 precision 0.935823652311121 specificity 0.8852023298973732 recall 0.9357221206581353 f1 0.9357715887553645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 54.91093850135803 s\n",
      "Accuracy 0.9354296160877513 precision 0.935401172570464 specificity 0.8823034036091492 recall 0.9354296160877513 f1 0.9354152879081609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 55.33193922042847 s\n",
      "Accuracy 0.9352468007312614 precision 0.9352008302869472 specificity 0.8820398793429056 recall 0.9352468007312614 f1 0.9352235348804042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 54.51993942260742 s\n",
      "Accuracy 0.9350274223034735 precision 0.9350032937258194 specificity 0.8846818703695474 recall 0.9350274223034735 f1 0.9350152776897468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 55.52493929862976 s\n",
      "Accuracy 0.9344789762340037 precision 0.9347484550798988 specificity 0.884489010600608 recall 0.9344789762340037 f1 0.9346056300433738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 55.12694311141968 s\n",
      "Accuracy 0.9360511882998171 precision 0.9363611413237679 specificity 0.8894820427443562 recall 0.9360511882998171 f1 0.9361948479761294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 55.355937480926514 s\n",
      "Accuracy 0.936453382084095 precision 0.936346732460467 specificity 0.885077758932116 recall 0.936453382084095 f1 0.9363983638627977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 56.05093574523926 s\n",
      "Accuracy 0.936855575868373 precision 0.9370056718878594 specificity 0.8866618215998989 recall 0.936855575868373 f1 0.9369278217234831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 54.64494013786316 s\n",
      "Accuracy 0.9372212065813529 precision 0.9372661295690189 specificity 0.8881007343678698 recall 0.9372212065813529 f1 0.9372433883720421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 55.490938901901245 s\n",
      "Accuracy 0.9364899451553931 precision 0.9364185333519248 specificity 0.8848594396976327 recall 0.9364899451553931 f1 0.9364535078123905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 53.71794080734253 s\n",
      "Accuracy 0.9357221206581353 precision 0.935837962336264 specificity 0.8858114076150866 recall 0.9357221206581353 f1 0.9357783500980886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 55.23893761634827 s\n",
      "Accuracy 0.9387934186471664 precision 0.9391083154947037 specificity 0.8951783631342193 recall 0.9387934186471664 f1 0.938938112284701\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 55.003936529159546 s\n",
      "Accuracy 0.9352833638025594 precision 0.9355960822322863 specificity 0.8871780571545508 recall 0.9352833638025594 f1 0.9354286497766012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 55.25694036483765 s\n",
      "Accuracy 0.9370018281535649 precision 0.937084321862864 specificity 0.886234118475546 recall 0.9370018281535649 f1 0.9370421926193613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 55.03793811798096 s\n",
      "Accuracy 0.9351736745886654 precision 0.9353948647498855 specificity 0.8858230904642843 recall 0.9351736745886654 f1 0.9352785287380183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 53.726940393447876 s\n",
      "Accuracy 0.9349542961608776 precision 0.9347958968113768 specificity 0.8816190199526011 recall 0.9349542961608776 f1 0.934871449540542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 53.14594125747681 s\n",
      "Accuracy 0.9356489945155393 precision 0.9357341735306943 specificity 0.886396932830852 recall 0.9356489945155393 f1 0.9356906369385128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 53.37493944168091 s\n",
      "Accuracy 0.9356124314442413 precision 0.9354451087622296 specificity 0.883565616827404 recall 0.9356124314442413 f1 0.9355244872024236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 56.17393779754639 s\n",
      "Accuracy 0.9390859232175502 precision 0.9391121117282881 specificity 0.8926622595951172 recall 0.9390859232175502 f1 0.9390989118572758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 54.26394057273865 s\n",
      "Accuracy 0.9370383912248629 precision 0.9372399978135664 specificity 0.88987418653051 recall 0.9370383912248629 f1 0.9371340216354803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 54.137939453125 s\n",
      "Accuracy 0.9380987202925045 precision 0.9380347225763858 specificity 0.8866970191313529 recall 0.9380987202925045 f1 0.9380661176335936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 55.62093901634216 s\n",
      "Accuracy 0.9379890310786106 precision 0.9381008142367713 specificity 0.889975047316593 recall 0.9379890310786106 f1 0.9380432240584721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 54.71493721008301 s\n",
      "Accuracy 0.9359049360146252 precision 0.9361273525001074 specificity 0.8858328013864718 recall 0.9359049360146252 f1 0.9360103605522165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 55.393943309783936 s\n",
      "Accuracy 0.9360511882998171 precision 0.9360333247832452 specificity 0.8826083588794355 recall 0.9360511882998171 f1 0.9360422147483219\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 54.34094309806824 s\n",
      "Accuracy 0.9383912248628885 precision 0.9385796308118793 specificity 0.8913572430823318 recall 0.9383912248628885 f1 0.9384807629114419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 55.141942262649536 s\n",
      "Accuracy 0.9360511882998171 precision 0.9362785859388946 specificity 0.8898472585735033 recall 0.9360511882998171 f1 0.9361583985321136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 55.1779420375824 s\n",
      "Accuracy 0.9364899451553931 precision 0.9362599275614898 specificity 0.8843947117422877 recall 0.9364899451553931 f1 0.9363661450778039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 54.79894399642944 s\n",
      "Accuracy 0.9372577696526508 precision 0.9374584277331542 specificity 0.8872573663223196 recall 0.9372577696526508 f1 0.9373532205261675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 54.425944566726685 s\n",
      "Accuracy 0.9338574040219378 precision 0.9340193552896894 specificity 0.8827541438008604 recall 0.9338574040219378 f1 0.9339353364047865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 54.93094515800476 s\n",
      "Accuracy 0.9389762340036563 precision 0.938953358219184 specificity 0.8909376661274914 recall 0.9389762340036563 f1 0.9389647148696704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 53.501946449279785 s\n",
      "Accuracy 0.9348446069469836 precision 0.9348304629880663 specificity 0.8829122199173536 recall 0.9348446069469836 f1 0.9348375085709347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 55.11394476890564 s\n",
      "Accuracy 0.9357586837294333 precision 0.9359082586773243 specificity 0.8862751886409901 recall 0.9357586837294333 f1 0.9358306955837155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 55.25094485282898 s\n",
      "Accuracy 0.9352468007312614 precision 0.9354583239109183 specificity 0.8864602265743438 recall 0.9352468007312614 f1 0.9353472169360344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 52.83394265174866 s\n",
      "Accuracy 0.9358683729433273 precision 0.9357917157163431 specificity 0.8824663005135798 recall 0.9358683729433273 f1 0.9358292381900689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 55.0079448223114 s\n",
      "Accuracy 0.9327970749542962 precision 0.9328267448845001 specificity 0.8792795182381729 recall 0.9327970749542962 f1 0.932811804621814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 53.51594662666321 s\n",
      "Accuracy 0.9365996343692871 precision 0.9364827081979958 specificity 0.8824171849987791 recall 0.9365996343692871 f1 0.9365392346509371\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 54.664945125579834 s\n",
      "Accuracy 0.936855575868373 precision 0.9371406917854196 specificity 0.8899938144175524 recall 0.936855575868373 f1 0.9369883449066461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 55.07194423675537 s\n",
      "Accuracy 0.936453382084095 precision 0.936446434643619 specificity 0.8854597229212777 recall 0.936453382084095 f1 0.9364499017310997\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 55.355945110321045 s\n",
      "Accuracy 0.936636197440585 precision 0.9367664898885252 specificity 0.8891224890011943 recall 0.936636197440585 f1 0.9366990937011033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 54.98594403266907 s\n",
      "Accuracy 0.9375502742230347 precision 0.9376639965720127 specificity 0.8883711156166554 recall 0.9375502742230347 f1 0.9376054318910745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 54.65994668006897 s\n",
      "Accuracy 0.936416819012797 precision 0.9364922396830946 specificity 0.8855465624404556 recall 0.936416819012797 f1 0.9364537961085849\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 55.44894361495972 s\n",
      "Accuracy 0.9359414990859232 precision 0.9359768793915735 specificity 0.8851559774379075 recall 0.9359414990859232 f1 0.935959023754988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 54.23594307899475 s\n",
      "Accuracy 0.9357952468007312 precision 0.9358894556185658 specificity 0.8850677386344509 recall 0.9357952468007312 f1 0.9358412310843736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 54.91494607925415 s\n",
      "Accuracy 0.9357221206581353 precision 0.9357656871164777 specificity 0.8831816657080721 recall 0.9357221206581353 f1 0.9357436639594086\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 54.25094747543335 s\n",
      "Accuracy 0.936526508226691 precision 0.9367320428601295 specificity 0.888032260703292 recall 0.936526508226691 f1 0.9366240860295246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 54.54694151878357 s\n",
      "Accuracy 0.9345521023765996 precision 0.9342782894734718 specificity 0.8778459277361954 recall 0.9345521023765996 f1 0.9344040116508383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 54.55694556236267 s\n",
      "Accuracy 0.9357586837294333 precision 0.9358271515272618 specificity 0.8846539900518569 recall 0.9357586837294333 f1 0.935792319199474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 53.93094563484192 s\n",
      "Accuracy 0.93327239488117 precision 0.9332189654699721 specificity 0.8801455301847083 recall 0.93327239488117 f1 0.9332453107868316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 55.556944131851196 s\n",
      "Accuracy 0.9360146252285192 precision 0.9358933204386342 specificity 0.8835074912070174 recall 0.9360146252285192 f1 0.9359518252622945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 54.06594371795654 s\n",
      "Accuracy 0.9375868372943327 precision 0.9376808762317267 specificity 0.8893695991781471 recall 0.9375868372943327 f1 0.9376326501214808\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 53.8059458732605 s\n",
      "Accuracy 0.9352468007312614 precision 0.9351814732515923 specificity 0.883570105406229 recall 0.9352468007312614 f1 0.9352135420351807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 54.89494490623474 s\n",
      "Accuracy 0.9349177330895795 precision 0.9349598058308377 specificity 0.8855207209790188 recall 0.9349177330895795 f1 0.9349385338954835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 55.07594418525696 s\n",
      "Accuracy 0.9372577696526508 precision 0.9371841122980664 specificity 0.8863575356656006 recall 0.9372577696526508 f1 0.9372201375205094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 55.23794436454773 s\n",
      "Accuracy 0.9391956124314442 precision 0.9389606006594633 specificity 0.8875178359632708 recall 0.9391956124314442 f1 0.9390682033962372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 54.62094521522522 s\n",
      "Accuracy 0.9349177330895795 precision 0.9350051605174714 specificity 0.8838818949887727 recall 0.9349177330895795 f1 0.9349604960550685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 54.719943046569824 s\n",
      "Accuracy 0.9380255941499086 precision 0.9381115735818756 specificity 0.8903633229401959 recall 0.9380255941499086 f1 0.9380675497837309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 56.25794458389282 s\n",
      "Accuracy 0.9337477148080439 precision 0.9336034950558135 specificity 0.8801260565865923 recall 0.9337477148080439 f1 0.9336727059032123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 55.17994427680969 s\n",
      "Accuracy 0.9380987202925045 precision 0.9382557507223981 specificity 0.8916534256164687 recall 0.9380987202925045 f1 0.9381738921309286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 55.30994439125061 s\n",
      "Accuracy 0.9353930530164534 precision 0.9355359536826224 specificity 0.8854663807786072 recall 0.9353930530164534 f1 0.9354619928693646\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 55.23394274711609 s\n",
      "Accuracy 0.9339305301645339 precision 0.933941446252911 specificity 0.880906666534145 recall 0.9339305301645339 f1 0.9339359733507187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 55.60194396972656 s\n",
      "Accuracy 0.9381352833638026 precision 0.93808796247986 specificity 0.8870593195010545 recall 0.9381352833638026 f1 0.9381112952621771\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 54.85894536972046 s\n",
      "Accuracy 0.936453382084095 precision 0.9366082947683182 specificity 0.8898348149774923 recall 0.936453382084095 f1 0.936527669566975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 55.06494426727295 s\n",
      "Accuracy 0.9370018281535649 precision 0.9372059725541887 specificity 0.8873092223852092 recall 0.9370018281535649 f1 0.9370988538106511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 54.17294383049011 s\n",
      "Accuracy 0.9345155393053016 precision 0.9345266426264391 specificity 0.8798072472418199 recall 0.9345155393053016 f1 0.9345210759521236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 55.14494323730469 s\n",
      "Accuracy 0.9350639853747715 precision 0.9352036264170047 specificity 0.8849146357964206 recall 0.9350639853747715 f1 0.9351314249049056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 55.804943799972534 s\n",
      "Accuracy 0.9380987202925045 precision 0.9382652534951836 specificity 0.890718695871643 recall 0.9380987202925045 f1 0.9381783222984543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 55.972941160202026 s\n",
      "Accuracy 0.9361243144424132 precision 0.9364911403126801 specificity 0.8882378070801678 recall 0.9361243144424132 f1 0.9362927764211055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 55.07894587516785 s\n",
      "Accuracy 0.936526508226691 precision 0.936965859228163 specificity 0.8908553475160236 recall 0.936526508226691 f1 0.9367247576908139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 54.77294397354126 s\n",
      "Accuracy 0.9350639853747715 precision 0.9353469314312802 specificity 0.8858942995527327 recall 0.9350639853747715 f1 0.9351964196338117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 54.85394477844238 s\n",
      "Accuracy 0.9370749542961608 precision 0.9373614948670785 specificity 0.8919714376774733 recall 0.9370749542961608 f1 0.9372079892880599\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 54.7319450378418 s\n",
      "Accuracy 0.933674588665448 precision 0.9337414643691498 specificity 0.8808226796030033 recall 0.933674588665448 f1 0.9337074916620557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 54.96594595909119 s\n",
      "Accuracy 0.9360877513711152 precision 0.9359204014171452 specificity 0.8823552777862054 recall 0.9360877513711152 f1 0.935999917962659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 54.906944036483765 s\n",
      "Accuracy 0.9351736745886654 precision 0.9354322877473233 specificity 0.8870049935122298 recall 0.9351736745886654 f1 0.9352951589135643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 54.49994421005249 s\n",
      "Accuracy 0.9371846435100548 precision 0.9371297843889254 specificity 0.8851855897630782 recall 0.9371846435100548 f1 0.9371567866583237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 55.47694396972656 s\n",
      "Accuracy 0.9389396709323583 precision 0.9391253724106788 specificity 0.891226081854666 recall 0.9389396709323583 f1 0.9390280025643177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 55.274943590164185 s\n",
      "Accuracy 0.9345155393053016 precision 0.934729009574624 specificity 0.8852586398817133 recall 0.9345155393053016 f1 0.9346169397132186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 53.75694441795349 s\n",
      "Accuracy 0.9353564899451554 precision 0.9352879346715547 specificity 0.8837509784420593 recall 0.9353564899451554 f1 0.9353215529820457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 55.57994365692139 s\n",
      "Accuracy 0.9395246800731262 precision 0.9394474228597229 specificity 0.8902928276022732 recall 0.9395246800731262 f1 0.9394850906290897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 53.72794699668884 s\n",
      "Accuracy 0.939853747714808 precision 0.9398570667604196 specificity 0.8912284217657431 recall 0.939853747714808 f1 0.9398554055642762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 53.791945934295654 s\n",
      "Accuracy 0.9359780621572212 precision 0.9359677611090765 specificity 0.8859861594293557 recall 0.9359780621572212 f1 0.9359728968177881\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 56.025944232940674 s\n",
      "Accuracy 0.936709323583181 precision 0.9367482384067969 specificity 0.8857194013925708 recall 0.936709323583181 f1 0.9367285796722624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 55.42994427680969 s\n",
      "Accuracy 0.9356489945155393 precision 0.9357664310670568 specificity 0.88466257072764 recall 0.9356489945155393 f1 0.9357060139630062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 55.12194204330444 s\n",
      "Accuracy 0.9348080438756856 precision 0.9348185027841459 specificity 0.8848465810865652 recall 0.9348080438756856 f1 0.9348132585979306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 55.64394474029541 s\n",
      "Accuracy 0.9361974405850091 precision 0.9360987841721663 specificity 0.8836998068646702 recall 0.9361974405850091 f1 0.9361467160232876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 55.182944774627686 s\n",
      "Accuracy 0.9344424131627057 precision 0.9346211463345586 specificity 0.8827804628303565 recall 0.9344424131627057 f1 0.9345281210890669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 55.12194347381592 s\n",
      "Accuracy 0.9363802559414991 precision 0.9363596989690393 specificity 0.8860222848592735 recall 0.9363802559414991 f1 0.9363699179903826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 55.21794319152832 s\n",
      "Accuracy 0.9352102376599635 precision 0.9351409050947644 specificity 0.8827767768784971 recall 0.9352102376599635 f1 0.9351749101868999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 54.867945194244385 s\n",
      "Accuracy 0.9347714808043875 precision 0.9349737617128872 specificity 0.88505211228708 recall 0.9347714808043875 f1 0.9348678187524139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 54.40394473075867 s\n",
      "Accuracy 0.9368190127970749 precision 0.9369669771685518 specificity 0.8856732488786233 recall 0.9368190127970749 f1 0.9368903173263892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 56.05994367599487 s\n",
      "Accuracy 0.9365996343692871 precision 0.9364087660607197 specificity 0.8853143667336721 recall 0.9365996343692871 f1 0.9364982683396824\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 54.82794260978699 s\n",
      "Accuracy 0.9349542961608776 precision 0.935115332287538 specificity 0.8838908593746927 recall 0.9349542961608776 f1 0.9350317527422869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 55.86594247817993 s\n",
      "Accuracy 0.9368190127970749 precision 0.9372321714075511 specificity 0.8909624211540413 recall 0.9368190127970749 f1 0.9370063313441865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 55.17694449424744 s\n",
      "Accuracy 0.9363071297989031 precision 0.9364484211785737 specificity 0.889031146406822 recall 0.9363071297989031 f1 0.9363751523744369\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 55.09794473648071 s\n",
      "Accuracy 0.9357221206581353 precision 0.935875768549923 specificity 0.8861485042909762 recall 0.9357221206581353 f1 0.9357960309184311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 55.26294469833374 s\n",
      "Accuracy 0.9371115173674589 precision 0.9372633301846343 specificity 0.8879568145499667 recall 0.9371115173674589 f1 0.9371844923706905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 54.863945722579956 s\n",
      "Accuracy 0.9362340036563072 precision 0.9365169557459676 specificity 0.8890381908723715 recall 0.9362340036563072 f1 0.9363659643246705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 54.90294408798218 s\n",
      "Accuracy 0.9363802559414991 precision 0.9364842453213725 specificity 0.8893615017063826 recall 0.9363802559414991 f1 0.9364307785384686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 54.82094478607178 s\n",
      "Accuracy 0.9355393053016453 precision 0.9356400816938785 specificity 0.8885436204473844 recall 0.9355393053016453 f1 0.9355883245607157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 55.28594160079956 s\n",
      "Accuracy 0.9369287020109689 precision 0.9370149642989158 specificity 0.8894591671046724 recall 0.9369287020109689 f1 0.9369708063977326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 55.26894474029541 s\n",
      "Accuracy 0.9373308957952468 precision 0.9373791608031589 specificity 0.8884650730421241 recall 0.9373308957952468 f1 0.9373547040384532\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 55.40394353866577 s\n",
      "Accuracy 0.9341864716636198 precision 0.934201071142051 specificity 0.8809155257850377 recall 0.9341864716636198 f1 0.9341937449197558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 53.86894631385803 s\n",
      "Accuracy 0.933674588665448 precision 0.9337930505206353 specificity 0.8827735953958391 recall 0.933674588665448 f1 0.9337321399852045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 54.79494547843933 s\n",
      "Accuracy 0.9365996343692871 precision 0.9365717659429141 specificity 0.8845869915344281 recall 0.9365996343692871 f1 0.9365855935543517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 54.01294541358948 s\n",
      "Accuracy 0.9371846435100548 precision 0.9371170155953034 specificity 0.8857909424107206 recall 0.9371846435100548 f1 0.9371501641298994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 54.73394560813904 s\n",
      "Accuracy 0.936563071297989 precision 0.9366380296890058 specificity 0.8861247090899746 recall 0.936563071297989 f1 0.9365998180660491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 55.006943225860596 s\n",
      "Accuracy 0.9361974405850091 precision 0.9362150925593778 specificity 0.8848727324582254 recall 0.9361974405850091 f1 0.9362062250726639\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 55.415940284729004 s\n",
      "Accuracy 0.9362705667276051 precision 0.9363789401266845 specificity 0.8887611859144963 recall 0.9362705667276051 f1 0.9363231787142469\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 55.022944688797 s\n",
      "Accuracy 0.9351371115173674 precision 0.9354244259602139 specificity 0.8870955208808123 recall 0.9351371115173674 f1 0.9352712761033847\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 54.29694437980652 s\n",
      "Accuracy 0.9357586837294333 precision 0.9357906448164489 specificity 0.8846345377442313 recall 0.9357586837294333 f1 0.9357745301862918\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 55.846943855285645 s\n",
      "Accuracy 0.9350639853747715 precision 0.935129326092529 specificity 0.8835389863527705 recall 0.9350639853747715 f1 0.9350961198183653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 56.064942359924316 s\n",
      "Accuracy 0.9375137111517368 precision 0.9372931411721064 specificity 0.8842604228470102 recall 0.9375137111517368 f1 0.9373954824274384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 54.202945709228516 s\n",
      "Accuracy 0.9382449725776966 precision 0.9385115156113505 specificity 0.8915379906197521 recall 0.9382449725776966 f1 0.9383693859391902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 53.99794554710388 s\n",
      "Accuracy 0.9373308957952468 precision 0.9375349931901223 specificity 0.889095685372966 recall 0.9373308957952468 f1 0.9374277369195245\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 55.08007788658142 s\n",
      "Accuracy 0.9359049360146252 precision 0.9360512422099003 specificity 0.8881101138825022 recall 0.9359049360146252 f1 0.9359753323913045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 55.43194317817688 s\n",
      "Accuracy 0.9329433272394881 precision 0.9330189005529628 specificity 0.8792162561211934 recall 0.9329433272394881 f1 0.9329804536157732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 54.44794487953186 s\n",
      "Accuracy 0.9340402193784277 precision 0.9339845508899063 specificity 0.8823368124895792 recall 0.9340402193784277 f1 0.9340119657379946\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 53.9069459438324 s\n",
      "Accuracy 0.9359049360146252 precision 0.9357979265257771 specificity 0.8821364929940178 recall 0.9359049360146252 f1 0.9358498298272794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 54.95694541931152 s\n",
      "Accuracy 0.9356855575868372 precision 0.9356749954405769 specificity 0.8838441362445582 recall 0.9356855575868372 f1 0.9356802616001524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 55.12494421005249 s\n",
      "Accuracy 0.9342230347349177 precision 0.9341970198226142 specificity 0.8780678120185366 recall 0.9342230347349177 f1 0.9342099452872145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 55.22994518280029 s\n",
      "Accuracy 0.936563071297989 precision 0.9365872886593019 specificity 0.8869190469663072 recall 0.936563071297989 f1 0.9365750990619311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 55.364943742752075 s\n",
      "Accuracy 0.9342230347349177 precision 0.9342999261201159 specificity 0.8827028185212995 recall 0.9342230347349177 f1 0.9342607540853183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 54.242945432662964 s\n",
      "Accuracy 0.9377696526508227 precision 0.9379238811378097 specificity 0.8909919395133954 recall 0.9377696526508227 f1 0.9378435719883892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 54.088942766189575 s\n",
      "Accuracy 0.936636197440585 precision 0.9365440349837602 specificity 0.883902912755489 recall 0.936636197440585 f1 0.9365889012184961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 54.99994349479675 s\n",
      "Accuracy 0.9361974405850091 precision 0.9364819345949306 specificity 0.8897305473114383 recall 0.9361974405850091 f1 0.93632995354504\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 55.8869423866272 s\n",
      "Accuracy 0.9379524680073126 precision 0.9378766119249206 specificity 0.8877584293355493 recall 0.9379524680073126 f1 0.9379136613404566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 55.45594525337219 s\n",
      "Accuracy 0.9372577696526508 precision 0.93732143884319 specificity 0.8868897605915352 recall 0.9372577696526508 f1 0.9372890644065276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 54.07594323158264 s\n",
      "Accuracy 0.9357221206581353 precision 0.9359197663723727 specificity 0.8875121071506464 recall 0.9357221206581353 f1 0.9358161478377705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 54.9689462184906 s\n",
      "Accuracy 0.9370018281535649 precision 0.9370394453761629 specificity 0.8885408229697753 recall 0.9370018281535649 f1 0.9370204374191401\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 54.56094312667847 s\n",
      "Accuracy 0.9330530164533821 precision 0.9330492768904713 specificity 0.8776392691157692 recall 0.9330530164533821 f1 0.9330511450132931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 55.764944076538086 s\n",
      "Accuracy 0.9341499085923217 precision 0.9342731204137052 specificity 0.8824725012059139 recall 0.9341499085923217 f1 0.9342097173223658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 54.40894436836243 s\n",
      "Accuracy 0.936416819012797 precision 0.9362997006441873 specificity 0.8843802841615792 recall 0.936416819012797 f1 0.9363562293379222\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 54.70494341850281 s\n",
      "Accuracy 0.9342595978062157 precision 0.9343873898588374 specificity 0.8821039022415936 recall 0.9342595978062157 f1 0.9343215806908572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 53.25794696807861 s\n",
      "Accuracy 0.9371115173674589 precision 0.937261445759409 specificity 0.8889416189465619 recall 0.9371115173674589 f1 0.9371835634536435\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 53.15294671058655 s\n",
      "Accuracy 0.9354661791590494 precision 0.9356307065172793 specificity 0.8863896512423346 recall 0.9354661791590494 f1 0.9355451088094002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 55.20494318008423 s\n",
      "Accuracy 0.936782449725777 precision 0.9367191301192245 specificity 0.8868236310259696 recall 0.936782449725777 f1 0.9367501945163955\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 54.61194586753845 s\n",
      "Accuracy 0.9390127970749543 precision 0.9393267900432132 specificity 0.8935710922187795 recall 0.9390127970749543 f1 0.9391574903695836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 56.155943632125854 s\n",
      "Accuracy 0.9350639853747715 precision 0.9352725889913691 specificity 0.8859223842039073 recall 0.9350639853747715 f1 0.9351631255881182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 53.74794626235962 s\n",
      "Accuracy 0.9361974405850091 precision 0.9364576973128004 specificity 0.8896616515663177 recall 0.9361974405850091 f1 0.9363192979983593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 54.36094570159912 s\n",
      "Accuracy 0.9359049360146252 precision 0.9362209833434205 specificity 0.8899527373530337 recall 0.9359049360146252 f1 0.9360511308595043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 55.02494239807129 s\n",
      "Accuracy 0.9353199268738575 precision 0.9354963364621854 specificity 0.8844045131445718 recall 0.9353199268738575 f1 0.9354044666971568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 56.09394311904907 s\n",
      "Accuracy 0.9354296160877513 precision 0.9353667367746844 specificity 0.8825191606099454 recall 0.9354296160877513 f1 0.935397638950024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 55.086941957473755 s\n",
      "Accuracy 0.9381718464351005 precision 0.9385104468781 specificity 0.8940208718704281 recall 0.9381718464351005 f1 0.9383269036608144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 55.81494140625 s\n",
      "Accuracy 0.9348811700182815 precision 0.935063645870871 specificity 0.8850140094967591 recall 0.9348811700182815 f1 0.9349684515284272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 55.276944637298584 s\n",
      "Accuracy 0.9354296160877513 precision 0.9355008480965465 specificity 0.8855195532989113 recall 0.9354296160877513 f1 0.9354645736446918\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 54.2979462146759 s\n",
      "Accuracy 0.9347349177330896 precision 0.9346013099935735 specificity 0.8811754870178797 recall 0.9347349177330896 f1 0.9346656005828213\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 54.87594485282898 s\n",
      "Accuracy 0.9360877513711152 precision 0.9358075507200536 specificity 0.8815501938701872 recall 0.9360877513711152 f1 0.9359347926676342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 55.24494481086731 s\n",
      "Accuracy 0.9391590493601463 precision 0.9391073785717908 specificity 0.8908336000909367 recall 0.9391590493601463 f1 0.9391327891088715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 55.41894769668579 s\n",
      "Accuracy 0.9390493601462523 precision 0.9390730906633108 specificity 0.8898967361089007 recall 0.9390493601462523 f1 0.9390611435129542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 55.06994581222534 s\n",
      "Accuracy 0.9359414990859232 precision 0.9361154225623365 specificity 0.8877485881799568 recall 0.9359414990859232 f1 0.9360246707417773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 55.42194151878357 s\n",
      "Accuracy 0.9346983546617916 precision 0.9347562254544081 specificity 0.8833839457210683 recall 0.9346983546617916 f1 0.9347268679892992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 54.261945962905884 s\n",
      "Accuracy 0.9363802559414991 precision 0.9363452787510899 specificity 0.8838988309811587 recall 0.9363802559414991 f1 0.936362600690715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 53.94294595718384 s\n",
      "Accuracy 0.9363071297989031 precision 0.9364204656538684 specificity 0.8878920251967881 recall 0.9363071297989031 f1 0.9363621122000094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 55.84594440460205 s\n",
      "Accuracy 0.9361974405850091 precision 0.9362432869234611 specificity 0.8859170459167015 recall 0.9361974405850091 f1 0.9362200841923403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 54.499943017959595 s\n",
      "Accuracy 0.9359780621572212 precision 0.9359539822609606 specificity 0.8853659665881505 recall 0.9359780621572212 f1 0.9359659413706881\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 53.10094594955444 s\n",
      "Accuracy 0.9356855575868372 precision 0.9356408671499948 specificity 0.8845392071014931 recall 0.9356855575868372 f1 0.9356629335873767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 54.10194373130798 s\n",
      "Accuracy 0.9372577696526508 precision 0.9370571177701372 specificity 0.8840629571207815 recall 0.9372577696526508 f1 0.937151034302551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 55.62594532966614 s\n",
      "Accuracy 0.9359780621572212 precision 0.9360172770058318 specificity 0.8846884303722079 recall 0.9359780621572212 f1 0.9359974688249401\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 54.89994478225708 s\n",
      "Accuracy 0.9342230347349177 precision 0.9341620904846177 specificity 0.8798828793992863 recall 0.9342230347349177 f1 0.9341920833732879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 53.17294669151306 s\n",
      "Accuracy 0.9378062157221206 precision 0.9379532948385746 specificity 0.8888612564652377 recall 0.9378062157221206 f1 0.937876953608173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 54.926944971084595 s\n",
      "Accuracy 0.9352102376599635 precision 0.9351756024873036 specificity 0.8840491016048645 recall 0.9352102376599635 f1 0.9351927554617161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 55.10694479942322 s\n",
      "Accuracy 0.9372212065813529 precision 0.9373358657686054 specificity 0.8900408303512991 recall 0.9372212065813529 f1 0.9372767443922098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 53.96094584465027 s\n",
      "Accuracy 0.9375502742230347 precision 0.937661767408398 specificity 0.889910819713754 recall 0.9375502742230347 f1 0.9376043294696859\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 54.96794557571411 s\n",
      "Accuracy 0.9372943327239488 precision 0.9376067960444184 specificity 0.891773899719043 recall 0.9372943327239488 f1 0.9374386650548151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 55.12694525718689 s\n",
      "Accuracy 0.933382084095064 precision 0.9332449593029211 specificity 0.8803125624038569 recall 0.933382084095064 f1 0.9333109026938284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 54.78294563293457 s\n",
      "Accuracy 0.9378427787934186 precision 0.9377618074884172 specificity 0.8858184606933848 recall 0.9378427787934186 f1 0.9378013291637104\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 55.43894410133362 s\n",
      "Accuracy 0.9364899451553931 precision 0.9364933990975165 specificity 0.8862899497200457 recall 0.9364899451553931 f1 0.9364916704730982\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 55.4339439868927 s\n",
      "Accuracy 0.9352468007312614 precision 0.9353824568015858 specificity 0.8850922843516875 recall 0.9352468007312614 f1 0.9353123694093983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 50.377949714660645 s\n",
      "Accuracy 0.9341499085923217 precision 0.9344083295511818 specificity 0.8863995457100985 recall 0.9341499085923217 f1 0.9342713558014436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 49.29994773864746 s\n",
      "Accuracy 0.9365996343692871 precision 0.9365996343692871 specificity 0.887517359314614 recall 0.9365996343692871 f1 0.9365996343692871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 49.137948751449585 s\n",
      "Accuracy 0.9371846435100548 precision 0.9373490787184151 specificity 0.8893488060810952 recall 0.9371846435100548 f1 0.9372633624405912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 49.547950744628906 s\n",
      "Accuracy 0.9359414990859232 precision 0.93597705307 specificity 0.8847640540023745 recall 0.9359414990859232 f1 0.93595911030501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 47.45995330810547 s\n",
      "Accuracy 0.9373308957952468 precision 0.9372613918531403 specificity 0.8836850365357048 recall 0.9373308957952468 f1 0.9372954710822655\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 49.6359498500824 s\n",
      "Accuracy 0.9342595978062157 precision 0.934354998943831 specificity 0.8831414085121936 recall 0.9342595978062157 f1 0.9343061859067192\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 49.95694947242737 s\n",
      "Accuracy 0.9357952468007312 precision 0.9356985186644925 specificity 0.8823874722589924 recall 0.9357952468007312 f1 0.9357455785427179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 49.132951498031616 s\n",
      "Accuracy 0.9395246800731262 precision 0.9397050905336467 specificity 0.8938041125714827 recall 0.9395246800731262 f1 0.9396103938865107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 50.34494733810425 s\n",
      "Accuracy 0.9351736745886654 precision 0.9351771707052211 specificity 0.884596286758269 recall 0.9351736745886654 f1 0.9351754210028047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 49.076951026916504 s\n",
      "Accuracy 0.9339305301645339 precision 0.9337137708951443 specificity 0.8797686043693864 recall 0.9339305301645339 f1 0.933815205345871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 49.6549506187439 s\n",
      "Accuracy 0.9374040219378428 precision 0.9374040219378428 specificity 0.8894445468714574 recall 0.9374040219378428 f1 0.9374040219378428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 49.57294750213623 s\n",
      "Accuracy 0.9364899451553931 precision 0.9366308208315015 specificity 0.8872754341685016 recall 0.9364899451553931 f1 0.9365578649361798\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 50.431946992874146 s\n",
      "Accuracy 0.9380987202925045 precision 0.9383350749257138 specificity 0.8908259388608551 recall 0.9380987202925045 f1 0.9382098712364645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 50.04395031929016 s\n",
      "Accuracy 0.9379159049360146 precision 0.9380032656272378 specificity 0.8921613804520577 recall 0.9379159049360146 f1 0.9379584774017892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 50.61394906044006 s\n",
      "Accuracy 0.9375868372943327 precision 0.937667949455018 specificity 0.8879195583563466 recall 0.9375868372943327 f1 0.9376265124266139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 49.610947370529175 s\n",
      "Accuracy 0.9358318098720293 precision 0.9360169422490109 specificity 0.8878843045509988 recall 0.9358318098720293 f1 0.9359201028661478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 49.62895083427429 s\n",
      "Accuracy 0.9360511882998171 precision 0.9359601090432488 specificity 0.8845330758695091 recall 0.9360511882998171 f1 0.9360044441408348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 50.10794949531555 s\n",
      "Accuracy 0.9337477148080439 precision 0.9337404869788438 specificity 0.8807703583211489 recall 0.9337477148080439 f1 0.9337440943023139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 50.159950494766235 s\n",
      "Accuracy 0.9351736745886654 precision 0.9352932312081814 specificity 0.8855362447222983 recall 0.9351736745886654 f1 0.9352316615668855\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 50.0999481678009 s\n",
      "Accuracy 0.9363071297989031 precision 0.9363500619785402 specificity 0.8847087568303899 recall 0.9363071297989031 f1 0.9363283561594721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 48.394952058792114 s\n",
      "Accuracy 0.9341864716636198 precision 0.9342812156722157 specificity 0.8836593976714566 recall 0.9341864716636198 f1 0.9342327345045137\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 49.34201622009277 s\n",
      "Accuracy 0.9361608775137111 precision 0.9363396314526514 specificity 0.8856841136015003 recall 0.9361608775137111 f1 0.9362464202418029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 50.71394920349121 s\n",
      "Accuracy 0.9359780621572212 precision 0.9360744550272071 specificity 0.8864799994120668 recall 0.9359780621572212 f1 0.9360250558656784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 49.72695016860962 s\n",
      "Accuracy 0.9374040219378428 precision 0.9373569589572964 specificity 0.8870930576259286 recall 0.9374040219378428 f1 0.937380165293578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 49.361950159072876 s\n",
      "Accuracy 0.9323583180987203 precision 0.9325349932693934 specificity 0.8805525900284067 recall 0.9323583180987203 f1 0.9324431896648101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 49.55195093154907 s\n",
      "Accuracy 0.936782449725777 precision 0.9367114630181478 specificity 0.8854820811417597 recall 0.936782449725777 f1 0.9367462248170716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 49.351948738098145 s\n",
      "Accuracy 0.9351371115173674 precision 0.9351302363828677 specificity 0.8855443189659743 recall 0.9351371115173674 f1 0.9351336674063073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 49.75395083427429 s\n",
      "Accuracy 0.936526508226691 precision 0.9365195034267048 specificity 0.8848455643577063 recall 0.936526508226691 f1 0.9365229991707513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 49.83194923400879 s\n",
      "Accuracy 0.9368190127970749 precision 0.9367468874190659 specificity 0.8877292707026457 recall 0.9368190127970749 f1 0.9367821551803649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 49.7919499874115 s\n",
      "Accuracy 0.9359049360146252 precision 0.9358805467660117 specificity 0.8843167317678631 recall 0.9359049360146252 f1 0.935892660233059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 49.51095128059387 s\n",
      "Accuracy 0.936855575868373 precision 0.9369711850364264 specificity 0.88918658628815 recall 0.936855575868373 f1 0.9369115882877526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 49.58094906806946 s\n",
      "Accuracy 0.9381352833638026 precision 0.9383606568423488 specificity 0.8905205242392957 recall 0.9381352833638026 f1 0.938241568809953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 48.30395174026489 s\n",
      "Accuracy 0.936636197440585 precision 0.9367974147820054 specificity 0.8887189183102552 recall 0.936636197440585 f1 0.936713467646018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 49.088947057724 s\n",
      "Accuracy 0.9356124314442413 precision 0.9356443471397298 specificity 0.8846653323706433 recall 0.9356124314442413 f1 0.9356282554201142\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 50.65394854545593 s\n",
      "Accuracy 0.9352102376599635 precision 0.9353477123477596 specificity 0.8862564901565755 recall 0.9352102376599635 f1 0.9352766047315462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 50.12294960021973 s\n",
      "Accuracy 0.9340402193784277 precision 0.9339222571276264 specificity 0.8804077711953064 recall 0.9340402193784277 f1 0.9339793333548593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 49.15795040130615 s\n",
      "Accuracy 0.936745886654479 precision 0.9366973416751937 specificity 0.8843012607047623 recall 0.936745886654479 f1 0.9367212870880237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 47.871952295303345 s\n",
      "Accuracy 0.9347714808043875 precision 0.9350232761126283 specificity 0.8849558716163728 recall 0.9347714808043875 f1 0.93489018841529\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 49.529951095581055 s\n",
      "Accuracy 0.936672760511883 precision 0.9368001519599124 specificity 0.888650221110584 recall 0.936672760511883 f1 0.9367343211315516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 50.143948793411255 s\n",
      "Accuracy 0.9360511882998171 precision 0.9361404579575076 specificity 0.88627166163363 recall 0.9360511882998171 f1 0.9360947905621979\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 50.06594920158386 s\n",
      "Accuracy 0.9363802559414991 precision 0.9364081782578251 specificity 0.8862430403834974 recall 0.9363802559414991 f1 0.9363941112689426\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 50.022950410842896 s\n",
      "Accuracy 0.9379159049360146 precision 0.9380775870484386 specificity 0.8911069825794448 recall 0.9379159049360146 f1 0.9379932494461488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 49.587949991226196 s\n",
      "Accuracy 0.9384643510054844 precision 0.9383327332836493 specificity 0.8878701146511534 recall 0.9384643510054844 f1 0.9383957446045965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 49.96994996070862 s\n",
      "Accuracy 0.936526508226691 precision 0.9365402289489134 specificity 0.8872053117257903 recall 0.936526508226691 f1 0.9365333422220045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 50.074949502944946 s\n",
      "Accuracy 0.9321023765996344 precision 0.9322900429511363 specificity 0.8809789842580218 recall 0.9321023765996344 f1 0.9321922920378154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 51.602947473526 s\n",
      "Accuracy 0.9358683729433273 precision 0.93583382940525 specificity 0.8846179742612436 recall 0.9358683729433273 f1 0.9358509359008861\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 49.207950830459595 s\n",
      "Accuracy 0.936709323583181 precision 0.9366065800888237 specificity 0.8857617799261563 recall 0.936709323583181 f1 0.9366563631880306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 49.96494817733765 s\n",
      "Accuracy 0.9361608775137111 precision 0.9362748489526882 specificity 0.8873660584293501 recall 0.9361608775137111 f1 0.9362161761723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 50.15194892883301 s\n",
      "Accuracy 0.9351736745886654 precision 0.9354870159321284 specificity 0.8880341592003924 recall 0.9351736745886654 f1 0.935319055148677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 50.198949575424194 s\n",
      "Accuracy 0.9331627056672761 precision 0.9332222335390978 specificity 0.8801737962629612 recall 0.9331627056672761 f1 0.9331920480569268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 49.161951303482056 s\n",
      "Accuracy 0.936782449725777 precision 0.9371821317162689 specificity 0.8892163245806848 recall 0.936782449725777 f1 0.9369646499655864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 50.71194887161255 s\n",
      "Accuracy 0.9357221206581353 precision 0.9359324575447955 specificity 0.8856627024297808 recall 0.9357221206581353 f1 0.9358220868246727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 50.34694981575012 s\n",
      "Accuracy 0.9355758683729434 precision 0.9357037130371137 specificity 0.887704674357677 recall 0.9355758683729434 f1 0.9356376700837264\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 49.02095127105713 s\n",
      "Accuracy 0.9375868372943327 precision 0.9377103770378425 specificity 0.8892834289223902 recall 0.9375868372943327 f1 0.9376465761470505\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 49.79094982147217 s\n",
      "Accuracy 0.9375137111517368 precision 0.9373930368733945 specificity 0.8866778274403776 recall 0.9375137111517368 f1 0.9374511039400909\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 49.57395052909851 s\n",
      "Accuracy 0.9359049360146252 precision 0.9361255532933455 specificity 0.8893705502381216 recall 0.9359049360146252 f1 0.9360091590544493\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 48.75095057487488 s\n",
      "Accuracy 0.9380987202925045 precision 0.9383584880000043 specificity 0.891049087717918 recall 0.9380987202925045 f1 0.9382202211748056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 50.1039502620697 s\n",
      "Accuracy 0.9382449725776966 precision 0.9384149215230786 specificity 0.8926707635892074 recall 0.9382449725776966 f1 0.9383259934571856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 50.54695725440979 s\n",
      "Accuracy 0.9378062157221206 precision 0.937870310148637 specificity 0.8909852524546007 recall 0.9378062157221206 f1 0.93783766932291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 49.85596060752869 s\n",
      "Accuracy 0.9363436928702011 precision 0.9367584868709671 specificity 0.8911591395110688 recall 0.9363436928702011 f1 0.9365315838123803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 48.95096254348755 s\n",
      "Accuracy 0.9358318098720293 precision 0.9357734964560418 specificity 0.8843098980316505 recall 0.9358318098720293 f1 0.935802175529065\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 50.0379581451416 s\n",
      "Accuracy 0.936745886654479 precision 0.9368304046153242 specificity 0.887657503262822 recall 0.936745886654479 f1 0.9367871934175787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 49.36395978927612 s\n",
      "Accuracy 0.9358683729433273 precision 0.9361789544719727 specificity 0.8902517800953648 recall 0.9358683729433273 f1 0.9360121337752485\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 50.213958978652954 s\n",
      "Accuracy 0.9346983546617916 precision 0.934988080935659 specificity 0.8861313689038232 recall 0.9346983546617916 f1 0.9348337263056783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 49.93396043777466 s\n",
      "Accuracy 0.9337111517367459 precision 0.9338727068453225 specificity 0.8828670253931079 recall 0.9337111517367459 f1 0.9337888919030795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 49.61895990371704 s\n",
      "Accuracy 0.9374771480804388 precision 0.9374977122383846 specificity 0.8880459548415945 recall 0.9374771480804388 f1 0.9374873704703038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 50.020960330963135 s\n",
      "Accuracy 0.9347714808043875 precision 0.9350003109719444 specificity 0.8871670383416366 recall 0.9347714808043875 f1 0.9348796170342925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 50.58695936203003 s\n",
      "Accuracy 0.9396709323583181 precision 0.9396113333756214 specificity 0.8889719706073905 recall 0.9396709323583181 f1 0.9396405876391919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 49.77195858955383 s\n",
      "Accuracy 0.9388665447897624 precision 0.9392003847181044 specificity 0.8946359666202383 recall 0.9388665447897624 f1 0.9390194658625372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 50.737959146499634 s\n",
      "Accuracy 0.9368190127970749 precision 0.936998408750384 specificity 0.8893009760172425 recall 0.9368190127970749 f1 0.9369045892973117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 50.10796022415161 s\n",
      "Accuracy 0.9375502742230347 precision 0.9376554613169555 specificity 0.8891870980010059 recall 0.9375502742230347 f1 0.9376013766795146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 49.76595997810364 s\n",
      "Accuracy 0.9352102376599635 precision 0.9353765428989207 specificity 0.8872365572377006 recall 0.9352102376599635 f1 0.9352899281016313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 49.57595944404602 s\n",
      "Accuracy 0.9365996343692871 precision 0.9370276242672162 specificity 0.8913515866252945 recall 0.9365996343692871 f1 0.9367929876518309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 50.75195908546448 s\n",
      "Accuracy 0.9346252285191956 precision 0.9348152007928738 specificity 0.8833225335941635 recall 0.9346252285191956 f1 0.9347160743900503\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 49.520960569381714 s\n",
      "Accuracy 0.9363802559414991 precision 0.9363456584483173 specificity 0.8847719905795308 recall 0.9363802559414991 f1 0.9363627911849848\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 50.186959743499756 s\n",
      "Accuracy 0.9354661791590494 precision 0.9354844999379661 specificity 0.8814197680237287 recall 0.9354661791590494 f1 0.9354752977242924\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 49.58895993232727 s\n",
      "Accuracy 0.9342961608775137 precision 0.9342575789445178 specificity 0.8824264348660282 recall 0.9342961608775137 f1 0.9342766711298892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 49.82296061515808 s\n",
      "Accuracy 0.9346617915904936 precision 0.9347527072711426 specificity 0.8839870740728728 recall 0.9346617915904936 f1 0.9347062207486831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 49.64395785331726 s\n",
      "Accuracy 0.9378062157221206 precision 0.9378294169169349 specificity 0.8908906809074374 recall 0.9378062157221206 f1 0.9378177358619121\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 49.92996072769165 s\n",
      "Accuracy 0.9363436928702011 precision 0.9365310128328297 specificity 0.8872714010731193 recall 0.9363436928702011 f1 0.9364330451988624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 49.90295958518982 s\n",
      "Accuracy 0.9350639853747715 precision 0.9351515608188155 specificity 0.8838300620048485 recall 0.9350639853747715 f1 0.9351068207432158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 50.3619589805603 s\n",
      "Accuracy 0.9363436928702011 precision 0.9365471096984965 specificity 0.8871864507787074 recall 0.9363436928702011 f1 0.9364403863553802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 50.23595976829529 s\n",
      "Accuracy 0.9344789762340037 precision 0.9345382561312893 specificity 0.8812765525688855 recall 0.9344789762340037 f1 0.9345081911687011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 50.993959188461304 s\n",
      "Accuracy 0.9362340036563072 precision 0.9362909095435926 specificity 0.8856230749056108 recall 0.9362340036563072 f1 0.9362620322139382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 50.47595977783203 s\n",
      "Accuracy 0.9391590493601463 precision 0.9393094547090904 specificity 0.8937459758146556 recall 0.9391590493601463 f1 0.9392310523976968\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 50.03596258163452 s\n",
      "Accuracy 0.9353199268738575 precision 0.9353809322229991 specificity 0.8844982165237476 recall 0.9353199268738575 f1 0.93534995239133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 51.03095459938049 s\n",
      "Accuracy 0.9344058500914076 precision 0.9347180407153118 specificity 0.8867320830334112 recall 0.9344058500914076 f1 0.9345509482376108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 50.17296004295349 s\n",
      "Accuracy 0.936672760511883 precision 0.9367223047493218 specificity 0.8860339454229665 recall 0.936672760511883 f1 0.9366972069562807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 49.32196021080017 s\n",
      "Accuracy 0.9361974405850091 precision 0.9361269504844294 specificity 0.8857170388819648 recall 0.9361974405850091 f1 0.9361614690219608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 48.31395888328552 s\n",
      "Accuracy 0.9361974405850091 precision 0.9364969364539634 specificity 0.8879130774887869 recall 0.9361974405850091 f1 0.9363368528091747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 49.866957902908325 s\n",
      "Accuracy 0.9362340036563072 precision 0.9363389296192101 specificity 0.888587410461947 recall 0.9362340036563072 f1 0.9362849914737168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 50.53495979309082 s\n",
      "Accuracy 0.9356124314442413 precision 0.9356017099440602 specificity 0.8825893573849078 recall 0.9356124314442413 f1 0.9356070557092184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 48.355961561203 s\n",
      "Accuracy 0.9365996343692871 precision 0.9365996343692871 specificity 0.886624079468974 recall 0.9365996343692871 f1 0.9365996343692871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 50.22395706176758 s\n",
      "Accuracy 0.9357221206581353 precision 0.9360913055708002 specificity 0.8902762840464207 recall 0.9357221206581353 f1 0.9358910102174989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 49.03196096420288 s\n",
      "Accuracy 0.9354296160877513 precision 0.9356769740040615 specificity 0.8868263558809122 recall 0.9354296160877513 f1 0.9355461170583712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 49.5489604473114 s\n",
      "Accuracy 0.9352102376599635 precision 0.9352385579382959 specificity 0.884456137415963 recall 0.9352102376599635 f1 0.9352242923648434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 49.549960136413574 s\n",
      "Accuracy 0.9354661791590494 precision 0.9354986485355995 specificity 0.8831917009017066 recall 0.9354661791590494 f1 0.9354822793000882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 49.41196012496948 s\n",
      "Accuracy 0.933418647166362 precision 0.9335176045378627 specificity 0.8828519759466623 recall 0.933418647166362 f1 0.9334669343273608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 50.4289824962616 s\n",
      "Accuracy 0.9335283363802559 precision 0.9334095146954324 specificity 0.8795553281242477 recall 0.9335283363802559 f1 0.9334670231120715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 50.605985164642334 s\n",
      "Accuracy 0.936709323583181 precision 0.9364594363291137 specificity 0.8834590677969607 recall 0.936709323583181 f1 0.9365740277725255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 48.81298279762268 s\n",
      "Accuracy 0.9371480804387569 precision 0.9370913954360381 specificity 0.8872190051582128 recall 0.9371480804387569 f1 0.9371192602383254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 48.53998517990112 s\n",
      "Accuracy 0.9360877513711152 precision 0.9363998141979322 specificity 0.8878803706517979 recall 0.9360877513711152 f1 0.9362326528961255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 50.01498532295227 s\n",
      "Accuracy 0.936416819012797 precision 0.9363729058321427 specificity 0.8863053623616657 recall 0.936416819012797 f1 0.9363945838092489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 51.223984479904175 s\n",
      "Accuracy 0.9375137111517368 precision 0.9376752578275493 specificity 0.8891006816528003 recall 0.9375137111517368 f1 0.9375911214140883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 50.630985260009766 s\n",
      "Accuracy 0.9343692870201097 precision 0.9343445913478033 specificity 0.882475041107575 recall 0.9343692870201097 f1 0.9343568586008715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 48.30998516082764 s\n",
      "Accuracy 0.9382084095063985 precision 0.9383221511745254 specificity 0.8887494284964479 recall 0.9382084095063985 f1 0.93826356802011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 49.84798502922058 s\n",
      "Accuracy 0.9352833638025594 precision 0.9353559621317903 specificity 0.8839074918182817 recall 0.9352833638025594 f1 0.9353190007702726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 49.29198622703552 s\n",
      "Accuracy 0.9377330895795247 precision 0.9377635887832398 specificity 0.8894186147246993 recall 0.9377330895795247 f1 0.9377482053175398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 49.774983167648315 s\n",
      "Accuracy 0.9362705667276051 precision 0.9363745330649212 specificity 0.8865590791452234 recall 0.9362705667276051 f1 0.9363211583351042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 49.88698482513428 s\n",
      "Accuracy 0.936672760511883 precision 0.9368726964565154 specificity 0.8902846423037799 recall 0.936672760511883 f1 0.9367675850201546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 49.50098443031311 s\n",
      "Accuracy 0.9357221206581353 precision 0.9356611151358664 specificity 0.8850733472201517 recall 0.9357221206581353 f1 0.9356910848844463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 49.77998614311218 s\n",
      "Accuracy 0.9379159049360146 precision 0.938089183241536 specificity 0.8926384596883102 recall 0.9379159049360146 f1 0.9379984403947518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 49.044984102249146 s\n",
      "Accuracy 0.9360511882998171 precision 0.9363478755232721 specificity 0.8885736486926312 recall 0.9360511882998171 f1 0.9361892430690257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 49.04698443412781 s\n",
      "Accuracy 0.936416819012797 precision 0.9364902318792291 specificity 0.8876811190787688 recall 0.936416819012797 f1 0.9364527992574928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 50.01398491859436 s\n",
      "Accuracy 0.9383912248628885 precision 0.9384904361804826 specificity 0.891454530449339 recall 0.9383912248628885 f1 0.9384394400218383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 49.350985527038574 s\n",
      "Accuracy 0.9350274223034735 precision 0.9353196714982976 specificity 0.8868194096943323 recall 0.9350274223034735 f1 0.935163800067921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 50.92298460006714 s\n",
      "Accuracy 0.936416819012797 precision 0.9365444237243644 specificity 0.886012322043795 recall 0.936416819012797 f1 0.9364785844968772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 50.123982429504395 s\n",
      "Accuracy 0.9357586837294333 precision 0.9356920325344013 specificity 0.8822303691894622 recall 0.9357586837294333 f1 0.9357247566380644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 50.15198993682861 s\n",
      "Accuracy 0.9340402193784277 precision 0.9339070147957896 specificity 0.8790808086043492 recall 0.9340402193784277 f1 0.9339712254974963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 50.591984272003174 s\n",
      "Accuracy 0.9352833638025594 precision 0.9350257825088403 specificity 0.8813200486171829 recall 0.9352833638025594 f1 0.9351440069856847\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 48.60098433494568 s\n",
      "Accuracy 0.9337477148080439 precision 0.933712060808696 specificity 0.880921560077992 recall 0.9337477148080439 f1 0.9337297233155596\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 49.36398530006409 s\n",
      "Accuracy 0.9361243144424132 precision 0.9364669648994488 specificity 0.8897938288758609 recall 0.9361243144424132 f1 0.9362820281278544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 50.516985177993774 s\n",
      "Accuracy 0.9350274223034735 precision 0.9351623784533456 specificity 0.8853759837767807 recall 0.9350274223034735 f1 0.9350926488274617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 50.23898482322693 s\n",
      "Accuracy 0.9350639853747715 precision 0.9349180070009383 specificity 0.8797968331690825 recall 0.9350639853747715 f1 0.934988055915491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 48.96698570251465 s\n",
      "Accuracy 0.9374771480804388 precision 0.9373370911628227 specificity 0.8843177304547771 recall 0.9374771480804388 f1 0.9374041665318393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 48.545984983444214 s\n",
      "Accuracy 0.9372577696526508 precision 0.9372241826934408 specificity 0.8875636570582516 recall 0.9372577696526508 f1 0.9372408107810547\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 50.3219850063324 s\n",
      "Accuracy 0.9351005484460695 precision 0.9350969986198582 specificity 0.8830982950797363 recall 0.9351005484460695 f1 0.9350987718796401\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 49.544984102249146 s\n",
      "Accuracy 0.936526508226691 precision 0.9367858801326245 specificity 0.8863292847173437 recall 0.936526508226691 f1 0.9366484680254786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 49.26098561286926 s\n",
      "Accuracy 0.9356855575868372 precision 0.9356677597259884 specificity 0.8827124309860055 recall 0.9356855575868372 f1 0.9356766170355827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 50.61998438835144 s\n",
      "Accuracy 0.9357586837294333 precision 0.9358575794565989 specificity 0.884286802239483 recall 0.9357586837294333 f1 0.9358069197165578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 49.8969841003418 s\n",
      "Accuracy 0.936709323583181 precision 0.9366517794634045 specificity 0.8858212551757689 recall 0.936709323583181 f1 0.9366800729145943\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 49.85098576545715 s\n",
      "Accuracy 0.9344424131627057 precision 0.9345415079926713 specificity 0.8833473630575961 recall 0.9344424131627057 f1 0.9344907596270735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 50.83298420906067 s\n",
      "Accuracy 0.9382815356489945 precision 0.9381222911807533 specificity 0.8872681891359335 recall 0.9382815356489945 f1 0.9381977548287715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 50.04798460006714 s\n",
      "Accuracy 0.936453382084095 precision 0.936675834978042 specificity 0.8904533244928245 recall 0.936453382084095 f1 0.9365583170860146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 49.782984495162964 s\n",
      "Accuracy 0.9350639853747715 precision 0.9350568470740029 specificity 0.8825173068446795 recall 0.9350639853747715 f1 0.935060409597672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 50.654982805252075 s\n",
      "Accuracy 0.9357221206581353 precision 0.9358279897144866 specificity 0.8875867007379327 recall 0.9357221206581353 f1 0.9357735809005441\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 50.480984926223755 s\n",
      "Accuracy 0.9363802559414991 precision 0.93648668019062 specificity 0.8875747164024396 recall 0.9363802559414991 f1 0.9364319838475943\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 49.26898431777954 s\n",
      "Accuracy 0.9345521023765996 precision 0.9346532759168354 specificity 0.884790000732265 recall 0.9345521023765996 f1 0.9346014041559574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 49.0159854888916 s\n",
      "Accuracy 0.936453382084095 precision 0.9364465685029588 specificity 0.8869801820994867 recall 0.936453382084095 f1 0.9364499687061023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 49.004985094070435 s\n",
      "Accuracy 0.9340767824497258 precision 0.9341310497034007 specificity 0.882886192231723 recall 0.9340767824497258 f1 0.934103546631295\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 49.760986328125 s\n",
      "Accuracy 0.9360146252285192 precision 0.9365625566338476 specificity 0.892195896798914 recall 0.9360146252285192 f1 0.9362565156541472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 49.773983001708984 s\n",
      "Accuracy 0.9341133455210238 precision 0.9342655739261257 specificity 0.8816855855655334 recall 0.9341133455210238 f1 0.9341868085682834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 50.04998540878296 s\n",
      "Accuracy 0.9359049360146252 precision 0.9362847165004428 specificity 0.8890778560655352 recall 0.9359049360146252 f1 0.9360786789517376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 50.5599844455719 s\n",
      "Accuracy 0.9351736745886654 precision 0.935249959425434 specificity 0.8839027072698534 recall 0.9351736745886654 f1 0.9352110876140132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 50.09998536109924 s\n",
      "Accuracy 0.9350639853747715 precision 0.9351746369798978 specificity 0.8836659411706963 recall 0.9350639853747715 f1 0.9351178207438263\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 49.44898462295532 s\n",
      "Accuracy 0.9377330895795247 precision 0.9377850734055503 specificity 0.8884107823366555 recall 0.9377330895795247 f1 0.9377587075509387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 49.29298543930054 s\n",
      "Accuracy 0.9335283363802559 precision 0.9334186263478591 specificity 0.8813342351010205 recall 0.9335283363802559 f1 0.9334718083815168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 49.91898512840271 s\n",
      "Accuracy 0.936672760511883 precision 0.9367719655339883 specificity 0.8876115666285936 recall 0.936672760511883 f1 0.9367210668495769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 49.33198547363281 s\n",
      "Accuracy 0.936672760511883 precision 0.936672760511883 specificity 0.8863320695788517 recall 0.936672760511883 f1 0.936672760511883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 50.02098488807678 s\n",
      "Accuracy 0.936416819012797 precision 0.9364203318282561 specificity 0.8849112473890199 recall 0.936416819012797 f1 0.9364185737581328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 50.48898506164551 s\n",
      "Accuracy 0.9350274223034735 precision 0.9348650400500945 specificity 0.88273762560308 recall 0.9350274223034735 f1 0.9349422846825166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 50.74598455429077 s\n",
      "Accuracy 0.936672760511883 precision 0.9366117870130318 specificity 0.8856238744888866 recall 0.936672760511883 f1 0.9366417369913402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 49.069984436035156 s\n",
      "Accuracy 0.933674588665448 precision 0.9336236126577062 specificity 0.8786584407192106 recall 0.933674588665448 f1 0.9336487755646309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 49.278985023498535 s\n",
      "Accuracy 0.9338574040219378 precision 0.9338394294259157 specificity 0.8809050307791825 recall 0.9338574040219378 f1 0.9338483755260899\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 49.30298399925232 s\n",
      "Accuracy 0.9381718464351005 precision 0.938161815860432 specificity 0.8892542446892822 recall 0.9381718464351005 f1 0.9381668162229931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 49.152984857559204 s\n",
      "Accuracy 0.9348080438756856 precision 0.9348045129850729 specificity 0.883366056349199 recall 0.9348080438756856 f1 0.9348062767837482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 49.70998430252075 s\n",
      "Accuracy 0.9373674588665448 precision 0.9378426432518806 specificity 0.8952076394001023 recall 0.9373674588665448 f1 0.9375787174902069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 50.34898567199707 s\n",
      "Accuracy 0.9361243144424132 precision 0.935986794143747 specificity 0.8833129091316196 recall 0.9361243144424132 f1 0.9360527653137223\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 49.619986057281494 s\n",
      "Accuracy 0.9349177330895795 precision 0.9348213719641212 specificity 0.882238815019143 recall 0.9349177330895795 f1 0.934868258728443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 49.58298397064209 s\n",
      "Accuracy 0.9355027422303474 precision 0.9354680769325201 specificity 0.8841401312185521 recall 0.9355027422303474 f1 0.9354852445591708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 50.431984186172485 s\n",
      "Accuracy 0.9351371115173674 precision 0.9352247183875122 specificity 0.8838436428853675 recall 0.9351371115173674 f1 0.9351799619589962\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 49.50398564338684 s\n",
      "Accuracy 0.9368921389396709 precision 0.936648517316044 specificity 0.8828867522194067 recall 0.9368921389396709 f1 0.9367607015878205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 50.778984785079956 s\n",
      "Accuracy 0.9380255941499086 precision 0.9381488014583157 specificity 0.8897577179104273 recall 0.9380255941499086 f1 0.938085161945594\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 49.824984550476074 s\n",
      "Accuracy 0.9356489945155393 precision 0.9360823032770231 specificity 0.8897035181966253 recall 0.9356489945155393 f1 0.9358450539045768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 49.258984088897705 s\n",
      "Accuracy 0.9363802559414991 precision 0.9365239537633971 specificity 0.8877603998074911 recall 0.9363802559414991 f1 0.9364494644249756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 50.53198480606079 s\n",
      "Accuracy 0.9353564899451554 precision 0.9352209066722226 specificity 0.8857438957036791 recall 0.9353564899451554 f1 0.9352858250492299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 49.43298530578613 s\n",
      "Accuracy 0.9355758683729434 precision 0.9358390794646878 specificity 0.8895771925458037 recall 0.9355758683729434 f1 0.9356990176698743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 50.723984718322754 s\n",
      "Accuracy 0.936745886654479 precision 0.9366901395417445 specificity 0.8836683669882125 recall 0.936745886654479 f1 0.9367175848197443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 50.66798496246338 s\n",
      "Accuracy 0.936453382084095 precision 0.9368135383563355 specificity 0.8889737777722179 recall 0.936453382084095 f1 0.9366188238326066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 49.50998520851135 s\n",
      "Accuracy 0.936965265082267 precision 0.9367033314413201 specificity 0.8840409113761292 recall 0.936965265082267 f1 0.9368226030466198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 50.151968479156494 s\n",
      "Accuracy 0.9355758683729434 precision 0.9353266761040135 specificity 0.8823032494379228 recall 0.9355758683729434 f1 0.9354412394504643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 49.20796608924866 s\n",
      "Accuracy 0.9343327239488117 precision 0.9346456748250477 specificity 0.8864872725839092 recall 0.9343327239488117 f1 0.9344781982599987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 48.93696331977844 s\n",
      "Accuracy 0.9348811700182815 precision 0.9352861719221767 specificity 0.8886171007426883 recall 0.9348811700182815 f1 0.9350656427445552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 50.954965114593506 s\n",
      "Accuracy 0.9340767824497258 precision 0.9342150970240359 specificity 0.8828004152596868 recall 0.9340767824497258 f1 0.9341436840152378\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 49.13696503639221 s\n",
      "Accuracy 0.9371115173674589 precision 0.9371046758475259 specificity 0.8870297902793516 recall 0.9371115173674589 f1 0.9371080899774847\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 50.56596231460571 s\n",
      "Accuracy 0.9348080438756856 precision 0.934856011511043 specificity 0.8814440102721041 recall 0.9348080438756856 f1 0.9348317465223523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 49.84596514701843 s\n",
      "Accuracy 0.9358318098720293 precision 0.935870997968945 specificity 0.8846602010753362 recall 0.9358318098720293 f1 0.9358512034345678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 48.12996578216553 s\n",
      "Accuracy 0.936453382084095 precision 0.9365029256129972 specificity 0.8859094987350226 recall 0.936453382084095 f1 0.9364778287197945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 49.55496621131897 s\n",
      "Accuracy 0.936782449725777 precision 0.9369084310635857 specificity 0.8872584773404394 recall 0.936782449725777 f1 0.9368434073632488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 51.21996355056763 s\n",
      "Accuracy 0.9345155393053016 precision 0.9346454650950696 specificity 0.8834045610313901 recall 0.9345155393053016 f1 0.9345784808522472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 52.37555432319641 s\n",
      "Accuracy 0.9363436928702011 precision 0.9360700281450042 specificity 0.8811705256477786 recall 0.9363436928702011 f1 0.9361948090190642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 49.99972724914551 s\n",
      "Accuracy 0.9363436928702011 precision 0.9364879420368998 specificity 0.8852766249301397 recall 0.9363436928702011 f1 0.9364132803743701\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 50.517600774765015 s\n",
      "Accuracy 0.9358318098720293 precision 0.9358002734050314 specificity 0.8835796319318439 recall 0.9358318098720293 f1 0.9358159071806242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 51.57649493217468 s\n",
      "Accuracy 0.9340767824497258 precision 0.9343195720720595 specificity 0.8861103135540699 recall 0.9340767824497258 f1 0.9341912881718687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 50.27405047416687 s\n",
      "Accuracy 0.9350639853747715 precision 0.9353477694338871 specificity 0.8880347699221987 recall 0.9350639853747715 f1 0.9351964320653456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 51.329017162323 s\n",
      "Accuracy 0.9362705667276051 precision 0.9362267902577405 specificity 0.8864658896288696 recall 0.9362705667276051 f1 0.9362484004881185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 49.612417459487915 s\n",
      "Accuracy 0.9348811700182815 precision 0.9348563514778976 specificity 0.8823548068926851 recall 0.9348811700182815 f1 0.9348686797176274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 50.5040237903595 s\n",
      "Accuracy 0.9349177330895795 precision 0.9354100007424173 specificity 0.8899762541868004 recall 0.9349177330895795 f1 0.9351379725648916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 51.190696477890015 s\n",
      "Accuracy 0.936416819012797 precision 0.9366827767678837 specificity 0.890508957114766 recall 0.936416819012797 f1 0.9365410663286453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 50.30996513366699 s\n",
      "Accuracy 0.9344789762340037 precision 0.9344363797015963 specificity 0.8814377597003962 recall 0.9344789762340037 f1 0.934457440001166\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 47.56535077095032 s\n",
      "Accuracy 0.9337842778793418 precision 0.9336850759436292 specificity 0.8820025933051434 recall 0.9337842778793418 f1 0.9337333029408251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 50.40196704864502 s\n",
      "Accuracy 0.9329433272394881 precision 0.9330643621977351 specificity 0.8805559811763995 recall 0.9329433272394881 f1 0.9330021611439959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 49.51203680038452 s\n",
      "Accuracy 0.9382815356489945 precision 0.9383429169713413 specificity 0.8903304617573043 recall 0.9382815356489945 f1 0.9383116893257424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 51.05800676345825 s\n",
      "Accuracy 0.9353564899451554 precision 0.9355306295772798 specificity 0.8872856234316341 recall 0.9353564899451554 f1 0.9354397841407898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 51.25540471076965 s\n",
      "Accuracy 0.9341133455210238 precision 0.9341786793386988 specificity 0.8829960282804771 recall 0.9341133455210238 f1 0.9341454802674671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 50.71634078025818 s\n",
      "Accuracy 0.9358683729433273 precision 0.9359394930722209 specificity 0.8859011090645786 recall 0.9358683729433273 f1 0.9359032727807438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 50.659255027770996 s\n",
      "Accuracy 0.9352468007312614 precision 0.9353079036055519 specificity 0.8843273321103492 recall 0.9352468007312614 f1 0.935276874999589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 49.4324517250061 s\n",
      "Accuracy 0.9359414990859232 precision 0.9359550638700989 specificity 0.8877473432279835 recall 0.9359414990859232 f1 0.9359482553309838\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 50.87555480003357 s\n",
      "Accuracy 0.9360511882998171 precision 0.9361548978313271 specificity 0.8866247662012012 recall 0.9360511882998171 f1 0.9361016550175683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 50.9906210899353 s\n",
      "Accuracy 0.9322120658135283 precision 0.9322639976591569 specificity 0.8796382993010885 recall 0.9322120658135283 f1 0.9322377112833945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 51.00639581680298 s\n",
      "Accuracy 0.9368921389396709 precision 0.9371416337858106 specificity 0.8896939787544069 recall 0.9368921389396709 f1 0.9370092495297787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 50.70382332801819 s\n",
      "Accuracy 0.9365996343692871 precision 0.9368771587099353 specificity 0.8884630523990414 recall 0.9365996343692871 f1 0.9367293198594813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 50.2128963470459 s\n",
      "Accuracy 0.9372212065813529 precision 0.9371910166788907 specificity 0.887760913217884 recall 0.9372212065813529 f1 0.9372059778131508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 52.10998487472534 s\n",
      "Accuracy 0.9386837294332724 precision 0.9385543472728956 specificity 0.8892614281785819 recall 0.9386837294332724 f1 0.9386162525805468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 51.13494515419006 s\n",
      "Accuracy 0.9351736745886654 precision 0.9350945896879553 specificity 0.8830458785283667 recall 0.9351736745886654 f1 0.9351332594220272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 50.11924767494202 s\n",
      "Accuracy 0.936416819012797 precision 0.9364689479071266 specificity 0.8874326001962912 recall 0.936416819012797 f1 0.9364425128722568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 50.36610150337219 s\n",
      "Accuracy 0.9379159049360146 precision 0.9379796309035192 specificity 0.8871964936386567 recall 0.9379159049360146 f1 0.9379472251277852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 50.36444568634033 s\n",
      "Accuracy 0.9360146252285192 precision 0.936069958052406 specificity 0.8876930115507211 recall 0.9360146252285192 f1 0.9360418721347996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 50.6450879573822 s\n",
      "Accuracy 0.933235831809872 precision 0.933235831809872 specificity 0.8812509031471537 recall 0.933235831809872 f1 0.933235831809872\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 50.52093982696533 s\n",
      "Accuracy 0.936416819012797 precision 0.9367614678733004 specificity 0.8914639525868364 recall 0.936416819012797 f1 0.9365749901259663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 49.201972007751465 s\n",
      "Accuracy 0.9344789762340037 precision 0.9344717378420017 specificity 0.8810528238974531 recall 0.9344789762340037 f1 0.934475350407654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 49.67545461654663 s\n",
      "Accuracy 0.9361243144424132 precision 0.936250307311088 specificity 0.8868548418338823 recall 0.9361243144424132 f1 0.9361852878062387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 49.289467096328735 s\n",
      "Accuracy 0.936965265082267 precision 0.9371726050201905 specificity 0.8906043074245691 recall 0.936965265082267 f1 0.9370634074419234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 50.91897177696228 s\n",
      "Accuracy 0.9349908592321755 precision 0.9353650549580511 specificity 0.8887095655164593 recall 0.9349908592321755 f1 0.9351622586584006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 50.13402700424194 s\n",
      "Accuracy 0.9357586837294333 precision 0.935691295774516 specificity 0.8813286825842952 recall 0.9357586837294333 f1 0.9357243858969342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 50.630549907684326 s\n",
      "Accuracy 0.9357221206581353 precision 0.9357011641426282 specificity 0.8841412186084361 recall 0.9357221206581353 f1 0.9357115828285436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 51.37946557998657 s\n",
      "Accuracy 0.9364899451553931 precision 0.936421167885974 specificity 0.8877460602506198 recall 0.9364899451553931 f1 0.9364548345415453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 49.59222769737244 s\n",
      "Accuracy 0.9340036563071298 precision 0.9339218111894092 specificity 0.8796514075621569 recall 0.9340036563071298 f1 0.9339618582549817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 50.642879486083984 s\n",
      "Accuracy 0.9324314442413163 precision 0.9323120070731362 specificity 0.8785668421895962 recall 0.9324314442413163 f1 0.9323698350638399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 49.79945087432861 s\n",
      "Accuracy 0.9376965265082267 precision 0.9378178353865683 specificity 0.8883856603736284 recall 0.9376965265082267 f1 0.937755254417568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 50.56842494010925 s\n",
      "Accuracy 0.9382084095063985 precision 0.9381547951218824 specificity 0.8875266582606224 recall 0.9382084095063985 f1 0.9381811750787289\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 49.27746772766113 s\n",
      "Accuracy 0.9355758683729434 precision 0.9353147347975705 specificity 0.8803746835363646 recall 0.9355758683729434 f1 0.9354346623111014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 49.769451379776 s\n",
      "Accuracy 0.9361974405850091 precision 0.9364063338876915 specificity 0.8880599100514386 recall 0.9361974405850091 f1 0.9362965287813619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 50.195438623428345 s\n",
      "Accuracy 0.9360146252285192 precision 0.936050086907321 specificity 0.8850139656663225 recall 0.9360146252285192 f1 0.9360321903571975\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 49.729453802108765 s\n",
      "Accuracy 0.9362340036563072 precision 0.9361246901802912 specificity 0.883020827437922 recall 0.9362340036563072 f1 0.9361776417393854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 49.66945505142212 s\n",
      "Accuracy 0.9361243144424132 precision 0.9363811488185477 specificity 0.8881730405245746 recall 0.9361243144424132 f1 0.9362448747224382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 50.2764368057251 s\n",
      "Accuracy 0.9355393053016453 precision 0.9355500221239655 specificity 0.8833126350657912 recall 0.9355393053016453 f1 0.9355446487731598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 49.36146426200867 s\n",
      "Accuracy 0.9348811700182815 precision 0.9352424021257528 specificity 0.8886268102919809 recall 0.9348811700182815 f1 0.935047051809327\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 48.43449401855469 s\n",
      "Accuracy 0.9355393053016453 precision 0.9355427342723321 specificity 0.8863180556691225 recall 0.9355393053016453 f1 0.9355410181494913\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 49.30469727516174 s\n",
      "Accuracy 0.9345155393053016 precision 0.9347218955929035 specificity 0.8848780193471597 recall 0.9345155393053016 f1 0.9346137436232145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 50.19643712043762 s\n",
      "Accuracy 0.9378062157221206 precision 0.9377766843428874 specificity 0.8897495103217264 recall 0.9378062157221206 f1 0.9377913166480625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 50.06644296646118 s\n",
      "Accuracy 0.9364899451553931 precision 0.9370581340491886 specificity 0.8930105040361678 recall 0.9364899451553931 f1 0.9367395629965695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 49.1564724445343 s\n",
      "Accuracy 0.9371846435100548 precision 0.9372195233365482 specificity 0.886991766401404 recall 0.9371846435100548 f1 0.9372019172149374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 48.86247777938843 s\n",
      "Accuracy 0.9377330895795247 precision 0.9377780998417221 specificity 0.8882437642184658 recall 0.9377330895795247 f1 0.9377553137103438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 49.66045570373535 s\n",
      "Accuracy 0.9351736745886654 precision 0.935212360962184 specificity 0.8853084308598291 recall 0.9351736745886654 f1 0.9351928191757615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 49.52645969390869 s\n",
      "Accuracy 0.9386471663619744 precision 0.9387975898283075 specificity 0.8896194080441981 recall 0.9386471663619744 f1 0.9387194217299731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 49.88244867324829 s\n",
      "Accuracy 0.9379159049360146 precision 0.9379022833337565 specificity 0.887581321211169 recall 0.9379159049360146 f1 0.9379090674703449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 49.434462547302246 s\n",
      "Accuracy 0.9368921389396709 precision 0.9369906285531175 specificity 0.8883083434244736 recall 0.9368921389396709 f1 0.9369400887970503\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 49.90644812583923 s\n",
      "Accuracy 0.9349908592321755 precision 0.9352880648529559 specificity 0.8888399880990872 recall 0.9349908592321755 f1 0.9351290359709146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 50.35743689537048 s\n",
      "Accuracy 0.9359780621572212 precision 0.936017161970142 specificity 0.8849244633637081 recall 0.9359780621572212 f1 0.9359974115179078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 48.12450313568115 s\n",
      "Accuracy 0.9360146252285192 precision 0.9361754487200565 specificity 0.8866335737649792 recall 0.9360146252285192 f1 0.9360918356751354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 48.48949098587036 s\n",
      "Accuracy 0.9353199268738575 precision 0.9354343613531328 specificity 0.8838689107608658 recall 0.9353199268738575 f1 0.93537554974897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 48.38949489593506 s\n",
      "Accuracy 0.9342595978062157 precision 0.9344933585625658 specificity 0.8851294524922215 recall 0.9342595978062157 f1 0.9343701743590553\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 49.39546322822571 s\n",
      "Accuracy 0.9378793418647167 precision 0.9380908856342544 specificity 0.8910745987897808 recall 0.9378793418647167 f1 0.9379793507075253\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 50.62542533874512 s\n",
      "Accuracy 0.9365996343692871 precision 0.9367800941025363 specificity 0.8887015794652239 recall 0.9365996343692871 f1 0.9366857406709792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 49.23546886444092 s\n",
      "Accuracy 0.9383180987202925 precision 0.9384762930073007 specificity 0.8912260031794773 recall 0.9383180987202925 f1 0.938393837901883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 48.049503803253174 s\n",
      "Accuracy 0.936782449725777 precision 0.9368963383484832 specificity 0.8902848226002276 recall 0.936782449725777 f1 0.9368376123365235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 49.79845070838928 s\n",
      "Accuracy 0.9353930530164534 precision 0.9352809556344583 specificity 0.8829167542938751 recall 0.9353930530164534 f1 0.9353352053862192\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 49.627156257629395 s\n",
      "Accuracy 0.9361243144424132 precision 0.9361415625271068 specificity 0.8866573627840373 recall 0.9361243144424132 f1 0.9361328973465749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 51.16440677642822 s\n",
      "Accuracy 0.9358318098720293 precision 0.9356530409955031 specificity 0.8812411823061693 recall 0.9358318098720293 f1 0.9357377441650854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 50.72142267227173 s\n",
      "Accuracy 0.9345521023765996 precision 0.9345163318239151 specificity 0.8810905179848316 recall 0.9345521023765996 f1 0.9345340514345254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 49.65445375442505 s\n",
      "Accuracy 0.9379159049360146 precision 0.9378173417192365 specificity 0.8871789733438692 recall 0.9379159049360146 f1 0.9378651266776101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 49.411463499069214 s\n",
      "Accuracy 0.936745886654479 precision 0.9369548941782272 specificity 0.8898457243608822 recall 0.936745886654479 f1 0.9368448557655403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 50.296433210372925 s\n",
      "Accuracy 0.9378793418647167 precision 0.9380390661329205 specificity 0.8902121566090518 recall 0.9378793418647167 f1 0.9379558454935562\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 50.437949657440186 s\n",
      "Accuracy 0.936453382084095 precision 0.9363173009658574 specificity 0.8824704730438512 recall 0.936453382084095 f1 0.9363826679540418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 50.30343556404114 s\n",
      "Accuracy 0.9375137111517368 precision 0.9375444742887299 specificity 0.8886337992684845 recall 0.9375137111517368 f1 0.9375289586709581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 50.60042381286621 s\n",
      "Accuracy 0.9374040219378428 precision 0.9374592512607521 specificity 0.8886484441237739 recall 0.9374040219378428 f1 0.9374312129831929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 47.39552593231201 s\n",
      "Accuracy 0.9359049360146252 precision 0.9361018814979994 specificity 0.886295941406925 recall 0.9359049360146252 f1 0.9359987556064429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 49.044474601745605 s\n",
      "Accuracy 0.9343692870201097 precision 0.9345383377532342 specificity 0.8835135661300488 recall 0.9343692870201097 f1 0.9344504725775572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 50.08244252204895 s\n",
      "Accuracy 0.9363802559414991 precision 0.9366415185136057 specificity 0.888238932772898 recall 0.9363802559414991 f1 0.9365027806481558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 50.334434270858765 s\n",
      "Accuracy 0.9356489945155393 precision 0.9359493624496789 specificity 0.8861585847764509 recall 0.9356489945155393 f1 0.9357890814517447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 50.004443407058716 s\n",
      "Accuracy 0.9359049360146252 precision 0.9357856128980011 specificity 0.8826450660913371 recall 0.9359049360146252 f1 0.9358432387646305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 48.79448342323303 s\n",
      "Accuracy 0.9362340036563072 precision 0.9364828452249123 specificity 0.8894721857511967 recall 0.9362340036563072 f1 0.9363508317425093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 50.01245999336243 s\n",
      "Accuracy 0.9373308957952468 precision 0.937767508398986 specificity 0.8935009863092995 recall 0.9373308957952468 f1 0.9375270998073318\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 50.1594398021698 s\n",
      "Accuracy 0.9342595978062157 precision 0.9342104884397842 specificity 0.8820405320989172 recall 0.9342595978062157 f1 0.9342347208414242\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 49.817450523376465 s\n",
      "Accuracy 0.936453382084095 precision 0.9365388596601261 specificity 0.8865950814492786 recall 0.936453382084095 f1 0.9364951668971736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 50.151240825653076 s\n",
      "Accuracy 0.9344789762340037 precision 0.9344930822210725 specificity 0.8838720773954363 recall 0.9344789762340037 f1 0.9344860030058543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 49.05347466468811 s\n",
      "Accuracy 0.9350274223034735 precision 0.9349894818329494 specificity 0.8841580442352965 recall 0.9350274223034735 f1 0.9350082533688492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 48.9064781665802 s\n",
      "Accuracy 0.936965265082267 precision 0.9373449271194968 specificity 0.8907467754394193 recall 0.936965265082267 f1 0.9371385626947413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 48.95447778701782 s\n",
      "Accuracy 0.9348811700182815 precision 0.9353204745006509 specificity 0.8888884977295418 recall 0.9348811700182815 f1 0.9350799419708542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 50.17644119262695 s\n",
      "Accuracy 0.936782449725777 precision 0.9370626898001259 specificity 0.8912872888834704 recall 0.936782449725777 f1 0.9369128475221182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 50.01844334602356 s\n",
      "Accuracy 0.9387202925045703 precision 0.9390131666046289 specificity 0.8924659435232228 recall 0.9387202925045703 f1 0.9388560711547703\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 48.33196306228638 s\n",
      "Accuracy 0.9361974405850091 precision 0.9363363447876178 specificity 0.8882061883223807 recall 0.9361974405850091 f1 0.9362643927965135\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 48.57613515853882 s\n",
      "Accuracy 0.9357952468007312 precision 0.9358749223020718 specificity 0.8846299614926613 recall 0.9357952468007312 f1 0.9358342814849904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 49.93410873413086 s\n",
      "Accuracy 0.9363071297989031 precision 0.9363278516445859 specificity 0.8867892991841797 recall 0.9363071297989031 f1 0.9363174314003078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 48.522135972976685 s\n",
      "Accuracy 0.9338574040219378 precision 0.9339508963834295 specificity 0.8812163576648359 recall 0.9338574040219378 f1 0.9339031173352667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 49.46511960029602 s\n",
      "Accuracy 0.9368921389396709 precision 0.9366484542684697 specificity 0.8828666101305548 recall 0.9368921389396709 f1 0.9367606692096515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 47.45715546607971 s\n",
      "Accuracy 0.9377330895795247 precision 0.9379210525046553 specificity 0.89112375825809 recall 0.9377330895795247 f1 0.9378224333536517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 48.94772982597351 s\n",
      "Accuracy 0.9357221206581353 precision 0.9359637959824881 specificity 0.8861684382613293 recall 0.9357221206581353 f1 0.9358361705500129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 50.34110379219055 s\n",
      "Accuracy 0.9340402193784277 precision 0.9339682025894953 specificity 0.8790527418347944 recall 0.9340402193784277 f1 0.9340035468048936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 48.82376313209534 s\n",
      "Accuracy 0.9345886654478976 precision 0.9348446356246171 specificity 0.8874424587727345 recall 0.9345886654478976 f1 0.9347088895765697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 49.21712136268616 s\n",
      "Accuracy 0.936563071297989 precision 0.9369298066697788 specificity 0.8904571272771833 recall 0.936563071297989 f1 0.9367309352024205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 50.75209450721741 s\n",
      "Accuracy 0.9375868372943327 precision 0.9375634191809984 specificity 0.8884066822701671 recall 0.9375868372943327 f1 0.9375750472005173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 48.7071328163147 s\n",
      "Accuracy 0.9363071297989031 precision 0.936452936159532 specificity 0.8865570546996921 recall 0.9363071297989031 f1 0.9363773800564761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 50.31916403770447 s\n",
      "Accuracy 0.9357221206581353 precision 0.9358764345926139 specificity 0.8858001078071731 recall 0.9357221206581353 f1 0.9357963593818666\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 49.83711314201355 s\n",
      "Accuracy 0.9357586837294333 precision 0.9356496249681892 specificity 0.8805099474374659 recall 0.9357586837294333 f1 0.9357025439305723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 50.80909562110901 s\n",
      "Accuracy 0.9349177330895795 precision 0.9349902019153407 specificity 0.8838399262929957 recall 0.9349177330895795 f1 0.9349533075216678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 49.628116607666016 s\n",
      "Accuracy 0.9378062157221206 precision 0.9375995323192474 specificity 0.8873319212740157 recall 0.9378062157221206 f1 0.9376954635761744\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 50.59409976005554 s\n",
      "Accuracy 0.9346252285191956 precision 0.9349366042609941 specificity 0.8870882059587794 recall 0.9346252285191956 f1 0.9347699124981712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 49.96711015701294 s\n",
      "Accuracy 0.9345155393053016 precision 0.9344909355484342 specificity 0.8828548287166493 recall 0.9345155393053016 f1 0.9345031568614652\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 50.104108810424805 s\n",
      "Accuracy 0.9344058500914076 precision 0.9344272231153882 specificity 0.8832627363959422 recall 0.9344058500914076 f1 0.9344164774732097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 48.89512896537781 s\n",
      "Accuracy 0.936636197440585 precision 0.9367760872336829 specificity 0.887920308997612 recall 0.936636197440585 f1 0.9367036279097434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 49.16812610626221 s\n",
      "Accuracy 0.9380621572212066 precision 0.938089669390654 specificity 0.8883536314800569 recall 0.9380621572212066 f1 0.9380758066651333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 49.75011324882507 s\n",
      "Accuracy 0.9362705667276051 precision 0.9363379559687989 specificity 0.8862224742832385 recall 0.9362705667276051 f1 0.9363036640172739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 50.72509574890137 s\n",
      "Accuracy 0.9344424131627057 precision 0.9342095236147208 specificity 0.8785473878501836 recall 0.9344424131627057 f1 0.9343180673427027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 50.12810826301575 s\n",
      "Accuracy 0.9355758683729434 precision 0.9355898587259843 specificity 0.8851459229802091 recall 0.9355758683729434 f1 0.9355828371909144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 50.31710362434387 s\n",
      "Accuracy 0.9368190127970749 precision 0.9373520833979205 specificity 0.8935907533483394 recall 0.9368190127970749 f1 0.9370543344561193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 49.00312781333923 s\n",
      "Accuracy 0.936965265082267 precision 0.9369037876794156 specificity 0.8851322074587558 recall 0.936965265082267 f1 0.936933986829381\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 49.80111384391785 s\n",
      "Accuracy 0.9370383912248629 precision 0.9369054464604242 specificity 0.8846108485819787 recall 0.9370383912248629 f1 0.9369692548783851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 50.15310716629028 s\n",
      "Accuracy 0.9360146252285192 precision 0.9361328111886303 specificity 0.8843578503655264 recall 0.9360146252285192 f1 0.9360720107388957\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 49.68211579322815 s\n",
      "Accuracy 0.936855575868373 precision 0.9367695191172075 specificity 0.8835885920840901 recall 0.936855575868373 f1 0.9368115017540279\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 49.106125831604004 s\n",
      "Accuracy 0.9389031078610603 precision 0.9387881406119672 specificity 0.8870754521494271 recall 0.9389031078610603 f1 0.9388435668567799\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 49.87011218070984 s\n",
      "Accuracy 0.9360877513711152 precision 0.9362828163953604 specificity 0.8855191262088514 recall 0.9360877513711152 f1 0.9361807812473746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 50.89509129524231 s\n",
      "Accuracy 0.9356124314442413 precision 0.93567213982744 specificity 0.8863732541321687 recall 0.9356124314442413 f1 0.9356418110643535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 48.49913692474365 s\n",
      "Accuracy 0.9358683729433273 precision 0.9360087326494261 specificity 0.884982506291495 recall 0.9358683729433273 f1 0.9359361530780556\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 49.09712600708008 s\n",
      "Accuracy 0.9379159049360146 precision 0.9379367359317003 specificity 0.887284522718606 recall 0.9379159049360146 f1 0.9379262602624882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 50.441102027893066 s\n",
      "Accuracy 0.9384277879341865 precision 0.9384210882708814 specificity 0.8893732211036562 recall 0.9384277879341865 f1 0.9384244314542837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 49.90710997581482 s\n",
      "Accuracy 0.9365996343692871 precision 0.9366864893529441 specificity 0.885397716466131 recall 0.9365996343692871 f1 0.9366421012831648\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 48.87412977218628 s\n",
      "Accuracy 0.9380621572212066 precision 0.9381980180847979 specificity 0.893071572993066 recall 0.9380621572212066 f1 0.9381274670026165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 50.26410245895386 s\n",
      "Accuracy 0.9339670932358318 precision 0.9341157652408849 specificity 0.8835575793643881 recall 0.9339670932358318 f1 0.9340388032648947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 48.61115312576294 s\n",
      "Accuracy 0.9360877513711152 precision 0.9364744234166054 specificity 0.8886786510507859 recall 0.9360877513711152 f1 0.9362645477298671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 50.18110680580139 s\n",
      "Accuracy 0.9355758683729434 precision 0.9357794047497732 specificity 0.8882020347617343 recall 0.9355758683729434 f1 0.9356725013002954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 50.13610768318176 s\n",
      "Accuracy 0.9372212065813529 precision 0.93738234974393 specificity 0.8891166335769938 recall 0.9372212065813529 f1 0.9372984255953417\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 49.46411943435669 s\n",
      "Accuracy 0.9391590493601463 precision 0.9393081296664931 specificity 0.8906355612920834 recall 0.9391590493601463 f1 0.9392306310919952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 50.365103244781494 s\n",
      "Accuracy 0.9372577696526508 precision 0.9374653836922041 specificity 0.8906895687458488 recall 0.9372577696526508 f1 0.9373560344293116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 50.07310962677002 s\n",
      "Accuracy 0.9340036563071298 precision 0.9342612902498587 specificity 0.8839295460621451 recall 0.9340036563071298 f1 0.9341250862501759\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 50.8440945148468 s\n",
      "Accuracy 0.9350639853747715 precision 0.9350711696110652 specificity 0.8824763140478669 recall 0.9350639853747715 f1 0.9350675708612323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 49.94010901451111 s\n",
      "Accuracy 0.9351736745886654 precision 0.9356051350172736 specificity 0.8888808845065385 recall 0.9351736745886654 f1 0.9353692020766129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 49.7301127910614 s\n",
      "Accuracy 0.9352468007312614 precision 0.9356312159838792 specificity 0.8894787116866225 recall 0.9352468007312614 f1 0.9354223414343732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 47.4291558265686 s\n",
      "Accuracy 0.9374405850091407 precision 0.9375518702039969 specificity 0.8873856532615001 recall 0.9374405850091407 f1 0.9374946237252543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 49.84811282157898 s\n",
      "Accuracy 0.9362705667276051 precision 0.9360374592781214 specificity 0.8813524244955452 recall 0.9362705667276051 f1 0.9361456008368281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 49.858110189437866 s\n",
      "Accuracy 0.9383546617915904 precision 0.9384876274932026 specificity 0.8907784680415879 recall 0.9383546617915904 f1 0.9384187468656568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 50.29610466957092 s\n",
      "Accuracy 0.9346983546617916 precision 0.9349005122087196 specificity 0.8850559653993675 recall 0.9346983546617916 f1 0.9347946345335193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 50.841092109680176 s\n",
      "Accuracy 0.9345886654478976 precision 0.9346210917298546 specificity 0.8828037788534872 recall 0.9345886654478976 f1 0.9346047449840111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 50.136106729507446 s\n",
      "Accuracy 0.9327605118829981 precision 0.933172861979251 specificity 0.8856957632825845 recall 0.9327605118829981 f1 0.9329488057667568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 50.101107358932495 s\n",
      "Accuracy 0.9362705667276051 precision 0.9363804655714185 specificity 0.8876782726561157 recall 0.9362705667276051 f1 0.936323933608662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 49.09112310409546 s\n",
      "Accuracy 0.9372212065813529 precision 0.9369908799844173 specificity 0.8846300351974558 recall 0.9372212065813529 f1 0.9370971975414083\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 49.78611397743225 s\n",
      "Accuracy 0.9351371115173674 precision 0.9353415662895987 specificity 0.8875696618868611 recall 0.9351371115173674 f1 0.9352342116210451\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 49.892112016677856 s\n",
      "Accuracy 0.9389031078610603 precision 0.9393423177927571 specificity 0.8949407822353426 recall 0.9389031078610603 f1 0.9390999963631658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 49.038127422332764 s\n",
      "Accuracy 0.9368921389396709 precision 0.9373156777330405 specificity 0.8907288112337375 recall 0.9368921389396709 f1 0.9370838833767898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 49.16112446784973 s\n",
      "Accuracy 0.9360146252285192 precision 0.9364158048786516 specificity 0.8910179820669804 recall 0.9360146252285192 f1 0.9361968281024375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 51.73707723617554 s\n",
      "Accuracy 0.9357952468007312 precision 0.9357672723085116 specificity 0.8838469758360084 recall 0.9357952468007312 f1 0.935781153464783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 50.18010687828064 s\n",
      "Accuracy 0.9351005484460695 precision 0.935042445228039 specificity 0.8841999825837643 recall 0.9351005484460695 f1 0.9350710224060093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 50.02610921859741 s\n",
      "Accuracy 0.9358318098720293 precision 0.9359200428205354 specificity 0.8870617188044599 recall 0.9358318098720293 f1 0.9358748997328876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 50.196106910705566 s\n",
      "Accuracy 0.9355758683729434 precision 0.9355479567866715 specificity 0.8839074923711718 recall 0.9355758683729434 f1 0.9355618067499482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 48.826130867004395 s\n",
      "Accuracy 0.9352468007312614 precision 0.9355341181794212 specificity 0.8859732290924155 recall 0.9352468007312614 f1 0.935381159268774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 50.302101850509644 s\n",
      "Accuracy 0.9386471663619744 precision 0.9389960312893949 specificity 0.8929885281160443 recall 0.9386471663619744 f1 0.9388068966577181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 48.020143270492554 s\n",
      "Accuracy 0.9374405850091407 precision 0.9373632025371497 specificity 0.8859509075285397 recall 0.9374405850091407 f1 0.9374010124905353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 50.78909659385681 s\n",
      "Accuracy 0.9372577696526508 precision 0.937457856612806 specificity 0.8905990912687647 recall 0.9372577696526508 f1 0.9373526459887372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 48.347140073776245 s\n",
      "Accuracy 0.9375868372943327 precision 0.9374258031279284 specificity 0.8874512598960954 recall 0.9375868372943327 f1 0.9375020281866637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 50.69009733200073 s\n",
      "Accuracy 0.9375502742230347 precision 0.9375502742230347 specificity 0.8868698654873235 recall 0.9375502742230347 f1 0.9375502742230347\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 50.703097343444824 s\n",
      "Accuracy 0.9363802559414991 precision 0.936387162814061 specificity 0.8863593865070609 recall 0.9363802559414991 f1 0.9363837027727587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 51.36408305168152 s\n",
      "Accuracy 0.9372943327239488 precision 0.9374026540389356 specificity 0.8894167903437868 recall 0.9372943327239488 f1 0.937346906895119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 50.848095655441284 s\n",
      "Accuracy 0.9380987202925045 precision 0.9382972198621775 specificity 0.8902315740774724 recall 0.9380987202925045 f1 0.9381929335900526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 49.45216774940491 s\n",
      "Accuracy 0.9371846435100548 precision 0.9374361625163674 specificity 0.8917346844409099 recall 0.9371846435100548 f1 0.9373023604861664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 49.45248556137085 s\n",
      "Accuracy 0.9376965265082267 precision 0.9378995016716416 specificity 0.8897608912528173 recall 0.9376965265082267 f1 0.937792802631779\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 49.833481788635254 s\n",
      "Accuracy 0.9348080438756856 precision 0.9350471623712537 specificity 0.8850510449588078 recall 0.9348080438756856 f1 0.9349210551546284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 49.64648413658142 s\n",
      "Accuracy 0.9362705667276051 precision 0.9364406719259538 specificity 0.8879268699336619 recall 0.9362705667276051 f1 0.9363519768111606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 50.04847717285156 s\n",
      "Accuracy 0.9379159049360146 precision 0.9378568320117872 specificity 0.888719635089218 recall 0.9379159049360146 f1 0.9378858325119207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 49.29248762130737 s\n",
      "Accuracy 0.9360146252285192 precision 0.9361296511960497 specificity 0.8865504975018299 recall 0.9360146252285192 f1 0.936070447420719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 48.96949028968811 s\n",
      "Accuracy 0.9353930530164534 precision 0.9355453735003414 specificity 0.8845788462926106 recall 0.9353930530164534 f1 0.9354664268916977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 49.36148691177368 s\n",
      "Accuracy 0.9359414990859232 precision 0.9361106055803711 specificity 0.8863610114353088 recall 0.9359414990859232 f1 0.9360225506297041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 48.840492486953735 s\n",
      "Accuracy 0.9380255941499086 precision 0.9380886829095912 specificity 0.8922864748929424 recall 0.9380255941499086 f1 0.9380565472358463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 50.48247504234314 s\n",
      "Accuracy 0.9365996343692871 precision 0.9366783344295914 specificity 0.8860906473042012 recall 0.9365996343692871 f1 0.9366381800085269\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 50.32347393035889 s\n",
      "Accuracy 0.9372212065813529 precision 0.9373528505788742 specificity 0.8886768635593693 recall 0.9372212065813529 f1 0.9372847603363136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 49.170488595962524 s\n",
      "Accuracy 0.9354296160877513 precision 0.935347924998403 specificity 0.8838621112043351 recall 0.9354296160877513 f1 0.9353878214306479\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 50.26747703552246 s\n",
      "Accuracy 0.9357586837294333 precision 0.9357760682969742 specificity 0.8858345593785564 recall 0.9357586837294333 f1 0.9357673348734069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 51.672462463378906 s\n",
      "Accuracy 0.9343327239488117 precision 0.9344944525693939 specificity 0.8851475898803537 recall 0.9343327239488117 f1 0.9344104196731747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 50.00248169898987 s\n",
      "Accuracy 0.9361608775137111 precision 0.9359862382522638 specificity 0.8818698297368326 recall 0.9361608775137111 f1 0.936069048594925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 50.32947325706482 s\n",
      "Accuracy 0.9361243144424132 precision 0.9362718643068965 specificity 0.8875821264716849 recall 0.9361243144424132 f1 0.9361953198425348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 49.68448328971863 s\n",
      "Accuracy 0.9356489945155393 precision 0.9358740466990223 specificity 0.8861999667633507 recall 0.9356489945155393 f1 0.9357555637804875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 49.789482831954956 s\n",
      "Accuracy 0.9362340036563072 precision 0.9361447109448984 specificity 0.8833309266923421 recall 0.9362340036563072 f1 0.9361882321759922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 51.19246482849121 s\n",
      "Accuracy 0.9360511882998171 precision 0.936179314379361 specificity 0.8854633953043451 recall 0.9360511882998171 f1 0.9361132170705375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 50.10147833824158 s\n",
      "Accuracy 0.9341499085923217 precision 0.9341251358792476 specificity 0.8821033819417329 recall 0.9341499085923217 f1 0.9341374416953793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 50.293477296829224 s\n",
      "Accuracy 0.9350639853747715 precision 0.9350366378427297 specificity 0.885230794518845 recall 0.9350639853747715 f1 0.9350502069263679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 50.93246865272522 s\n",
      "Accuracy 0.9348446069469836 precision 0.934895485527078 specificity 0.8828417830552419 recall 0.9348446069469836 f1 0.9348697219489753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 49.27348732948303 s\n",
      "Accuracy 0.9370749542961608 precision 0.9370643623770062 specificity 0.8843746384044047 recall 0.9370749542961608 f1 0.9370696432471516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 45.54852628707886 s\n",
      "Accuracy 0.9357952468007312 precision 0.9356723077786728 specificity 0.8823321560508147 recall 0.9357952468007312 f1 0.9357316233152464\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 46.0315215587616 s\n",
      "Accuracy 0.9344424131627057 precision 0.9347820901705375 specificity 0.8852722309644238 recall 0.9344424131627057 f1 0.9345997777419106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 45.439525842666626 s\n",
      "Accuracy 0.9338208409506399 precision 0.9340396117602877 specificity 0.8843546585884631 recall 0.9338208409506399 f1 0.9339247181312952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 44.8535315990448 s\n",
      "Accuracy 0.933308957952468 precision 0.9333160585738228 specificity 0.8824359589530494 recall 0.933308957952468 f1 0.9333125017428429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 45.747525215148926 s\n",
      "Accuracy 0.9372577696526508 precision 0.9371787879631666 specificity 0.8874369368250508 recall 0.9372577696526508 f1 0.9372173276045358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 46.155518770217896 s\n",
      "Accuracy 0.936526508226691 precision 0.9364924244112697 specificity 0.8860284831405845 recall 0.936526508226691 f1 0.9365093009980201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 45.385525941848755 s\n",
      "Accuracy 0.9357221206581353 precision 0.9360966594846813 specificity 0.8891379393326813 recall 0.9357221206581353 f1 0.9358936042237432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 46.02251982688904 s\n",
      "Accuracy 0.9352468007312614 precision 0.9350037068649659 specificity 0.8814012763170244 recall 0.9352468007312614 f1 0.9351159674215922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 46.309518337249756 s\n",
      "Accuracy 0.936526508226691 precision 0.9365550798112608 specificity 0.8844880703136854 recall 0.936526508226691 f1 0.9365406871934624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 45.81952381134033 s\n",
      "Accuracy 0.9357586837294333 precision 0.9356734058292916 specificity 0.8837453588129252 recall 0.9357586837294333 f1 0.9357150111911523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 45.52652597427368 s\n",
      "Accuracy 0.9339305301645339 precision 0.9338040498027224 specificity 0.8811805483765666 recall 0.9339305301645339 f1 0.9338650447757455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 45.30252647399902 s\n",
      "Accuracy 0.936563071297989 precision 0.9367141243448805 specificity 0.8859692666550297 recall 0.936563071297989 f1 0.9366357953718877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 45.178532123565674 s\n",
      "Accuracy 0.9378427787934186 precision 0.9379730478680856 specificity 0.8875892892253162 recall 0.9378427787934186 f1 0.9379057414869857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 45.00752854347229 s\n",
      "Accuracy 0.9384277879341865 precision 0.9385044387444791 specificity 0.8892398605415978 recall 0.9384277879341865 f1 0.9384653052927231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 45.01953148841858 s\n",
      "Accuracy 0.936453382084095 precision 0.9365454382217431 specificity 0.8872982257487838 recall 0.936453382084095 f1 0.9364982937848257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 46.09652066230774 s\n",
      "Accuracy 0.9354296160877513 precision 0.9353219184003971 specificity 0.8837857280059905 recall 0.9354296160877513 f1 0.9353740812661272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 45.94552206993103 s\n",
      "Accuracy 0.933235831809872 precision 0.9333020680525863 specificity 0.8813646602511401 recall 0.933235831809872 f1 0.9332684185790591\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 45.86152267456055 s\n",
      "Accuracy 0.9360146252285192 precision 0.9362382090540571 specificity 0.8869616675951552 recall 0.9360146252285192 f1 0.9361204584507745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 45.9005229473114 s\n",
      "Accuracy 0.9374771480804388 precision 0.9377160701305722 specificity 0.8933856390462552 recall 0.9374771480804388 f1 0.937589058650243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 45.132527589797974 s\n",
      "Accuracy 0.936782449725777 precision 0.9366565865054667 specificity 0.8868605181825429 recall 0.936782449725777 f1 0.936717017255402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 44.27654004096985 s\n",
      "Accuracy 0.9378427787934186 precision 0.937898124487593 specificity 0.888739511759382 recall 0.9378427787934186 f1 0.9378700262741373\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 45.50352668762207 s\n",
      "Accuracy 0.9361243144424132 precision 0.9359796049749434 specificity 0.8828034541456937 recall 0.9361243144424132 f1 0.9360488859994349\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 45.32452750205994 s\n",
      "Accuracy 0.9359414990859232 precision 0.936022089395399 specificity 0.883781567166251 recall 0.9359414990859232 f1 0.935980986953894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 46.1305193901062 s\n",
      "Accuracy 0.9346983546617916 precision 0.9348671178196608 specificity 0.885755791291427 recall 0.9346983546617916 f1 0.9347792688021261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 46.56051325798035 s\n",
      "Accuracy 0.9371115173674589 precision 0.9370495549266237 specificity 0.8845843115721925 recall 0.9371115173674589 f1 0.9370799944633782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 46.57551574707031 s\n",
      "Accuracy 0.9372212065813529 precision 0.9371324227197317 specificity 0.8871163079879962 recall 0.9372212065813529 f1 0.937175610005014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 45.83652377128601 s\n",
      "Accuracy 0.9375868372943327 precision 0.9378634659322514 specificity 0.8928123832716073 recall 0.9375868372943327 f1 0.9377154179180085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 45.928521156311035 s\n",
      "Accuracy 0.9336380255941499 precision 0.9338582082764116 specificity 0.8852154755093667 recall 0.9336380255941499 f1 0.9337424480315113\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "split_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "smote_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, (split_seed, smote_seed) in enumerate(zip(split_seeds, smote_seeds)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=split_seed)\n",
    "    smote = SMOTE(random_state=smote_seed, n_jobs=THREADS_TO_USE)\n",
    "    x_smote, y_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_smote, y_smote)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(split_seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.937477     0.888432   0.937583  0.937477  0.937529\n1  0.935941     0.889398   0.936166  0.935941  0.936047\n2  0.934845     0.885452   0.934901  0.934845  0.934872\n3  0.933601     0.877644   0.933473  0.933601  0.933535\n4  0.935868     0.885028   0.935882  0.935868  0.935875\n5  0.936453     0.883118   0.936453  0.936453  0.936453\n6  0.938245     0.887959   0.938269  0.938245  0.938257\n7  0.936746     0.890641   0.937091  0.936746  0.936904\n8  0.935759     0.889543   0.936084  0.935759  0.935909\n9  0.937587     0.884360   0.937407  0.937587  0.937492",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.937477</td>\n      <td>0.888432</td>\n      <td>0.937583</td>\n      <td>0.937477</td>\n      <td>0.937529</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.935941</td>\n      <td>0.889398</td>\n      <td>0.936166</td>\n      <td>0.935941</td>\n      <td>0.936047</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.934845</td>\n      <td>0.885452</td>\n      <td>0.934901</td>\n      <td>0.934845</td>\n      <td>0.934872</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.933601</td>\n      <td>0.877644</td>\n      <td>0.933473</td>\n      <td>0.933601</td>\n      <td>0.933535</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.935868</td>\n      <td>0.885028</td>\n      <td>0.935882</td>\n      <td>0.935868</td>\n      <td>0.935875</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.936453</td>\n      <td>0.883118</td>\n      <td>0.936453</td>\n      <td>0.936453</td>\n      <td>0.936453</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.938245</td>\n      <td>0.887959</td>\n      <td>0.938269</td>\n      <td>0.938245</td>\n      <td>0.938257</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.936746</td>\n      <td>0.890641</td>\n      <td>0.937091</td>\n      <td>0.936746</td>\n      <td>0.936904</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.935759</td>\n      <td>0.889543</td>\n      <td>0.936084</td>\n      <td>0.935759</td>\n      <td>0.935909</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.937587</td>\n      <td>0.884360</td>\n      <td>0.937407</td>\n      <td>0.937587</td>\n      <td>0.937492</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.9360684460694698\n",
      "Precision 0.9361477682493539\n",
      "Specificity 0.886154738184183\n",
      "Recall 0.9360684460694698\n",
      "F1 0.9361042595066206\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_4beats_smote_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}