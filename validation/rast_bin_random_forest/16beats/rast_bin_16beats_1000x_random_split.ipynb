{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 16 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1  \\\n0  e0106  65.861928  67.716291  67.206386  18.973287  2.756737  0.736288   \n1  e0106  67.175188  66.539171  66.278974  18.879508  2.752145  0.710574   \n2  e0106  67.331260  67.526064  67.904703  19.526248  2.883850  0.724048   \n3  e0106  66.507411  69.358972  68.845433  19.399284  2.811633  0.728870   \n4  e0106  71.500586  69.600473  69.015425  19.518971  2.844739  0.706509   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.634501 -1.015121 -0.279539  ... -0.038497  0.024202 -0.033980  0.046029   \n1 -0.608829 -1.008338 -0.375129  ... -0.045707  0.028543 -0.033995  0.039226   \n2 -0.611290 -1.007119 -0.471325  ... -0.064803  0.051981 -0.056875  0.061396   \n3 -0.631538 -1.076715 -0.451683  ... -0.042918  0.033450 -0.043966  0.053377   \n4 -0.610843 -1.008555 -0.438800  ... -0.047597  0.025825 -0.031552  0.048798   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.071080  0.009209 -0.027384 -0.007471 -0.007113    NSR  \n1 -0.065687 -0.004942 -0.011601 -0.016082 -0.002783    NSR  \n2 -0.081542  0.009957 -0.023760 -0.019310  0.008258    NSR  \n3 -0.073200  0.002332 -0.021755 -0.003223 -0.021226    NSR  \n4 -0.093202  0.026254 -0.038423 -0.005951 -0.003403    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>65.861928</td>\n      <td>67.716291</td>\n      <td>67.206386</td>\n      <td>18.973287</td>\n      <td>2.756737</td>\n      <td>0.736288</td>\n      <td>-0.634501</td>\n      <td>-1.015121</td>\n      <td>-0.279539</td>\n      <td>...</td>\n      <td>-0.038497</td>\n      <td>0.024202</td>\n      <td>-0.033980</td>\n      <td>0.046029</td>\n      <td>-0.071080</td>\n      <td>0.009209</td>\n      <td>-0.027384</td>\n      <td>-0.007471</td>\n      <td>-0.007113</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>67.175188</td>\n      <td>66.539171</td>\n      <td>66.278974</td>\n      <td>18.879508</td>\n      <td>2.752145</td>\n      <td>0.710574</td>\n      <td>-0.608829</td>\n      <td>-1.008338</td>\n      <td>-0.375129</td>\n      <td>...</td>\n      <td>-0.045707</td>\n      <td>0.028543</td>\n      <td>-0.033995</td>\n      <td>0.039226</td>\n      <td>-0.065687</td>\n      <td>-0.004942</td>\n      <td>-0.011601</td>\n      <td>-0.016082</td>\n      <td>-0.002783</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>67.331260</td>\n      <td>67.526064</td>\n      <td>67.904703</td>\n      <td>19.526248</td>\n      <td>2.883850</td>\n      <td>0.724048</td>\n      <td>-0.611290</td>\n      <td>-1.007119</td>\n      <td>-0.471325</td>\n      <td>...</td>\n      <td>-0.064803</td>\n      <td>0.051981</td>\n      <td>-0.056875</td>\n      <td>0.061396</td>\n      <td>-0.081542</td>\n      <td>0.009957</td>\n      <td>-0.023760</td>\n      <td>-0.019310</td>\n      <td>0.008258</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>66.507411</td>\n      <td>69.358972</td>\n      <td>68.845433</td>\n      <td>19.399284</td>\n      <td>2.811633</td>\n      <td>0.728870</td>\n      <td>-0.631538</td>\n      <td>-1.076715</td>\n      <td>-0.451683</td>\n      <td>...</td>\n      <td>-0.042918</td>\n      <td>0.033450</td>\n      <td>-0.043966</td>\n      <td>0.053377</td>\n      <td>-0.073200</td>\n      <td>0.002332</td>\n      <td>-0.021755</td>\n      <td>-0.003223</td>\n      <td>-0.021226</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>71.500586</td>\n      <td>69.600473</td>\n      <td>69.015425</td>\n      <td>19.518971</td>\n      <td>2.844739</td>\n      <td>0.706509</td>\n      <td>-0.610843</td>\n      <td>-1.008555</td>\n      <td>-0.438800</td>\n      <td>...</td>\n      <td>-0.047597</td>\n      <td>0.025825</td>\n      <td>-0.031552</td>\n      <td>0.048798</td>\n      <td>-0.093202</td>\n      <td>0.026254</td>\n      <td>-0.038423</td>\n      <td>-0.005951</td>\n      <td>-0.003403</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_16beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    26200\nST      7965\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.219210  0.101301  0.071494  0.053500  0.102907 -0.028753   \ndw_2    0.219210  1.000000  0.838628  0.486610  0.180151  0.408486 -0.502032   \ndw_3    0.101301  0.838628  1.000000  0.680243  0.272747  0.255846 -0.548064   \ndw_4    0.071494  0.486610  0.680243  1.000000  0.880644 -0.012857 -0.262781   \ndw_5    0.053500  0.180151  0.272747  0.880644  1.000000 -0.126287 -0.018966   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.057237  0.034692  0.061458  0.050791  0.019165 -0.138724  0.094631   \ncfr_13 -0.042960  0.128171  0.046053  0.024330  0.013247  0.077703 -0.006064   \ncfr_14 -0.052143  0.009246 -0.019790 -0.029443 -0.034829  0.004839  0.022487   \ncfr_15 -0.079161 -0.115564 -0.131894 -0.102508 -0.053621  0.045425  0.082850   \ncfr_16 -0.066310 -0.075292 -0.046861 -0.042964 -0.029838  0.074518 -0.038814   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.044410 -0.002493  0.004377  ... -0.077538 -0.054871 -0.040977   \ndw_2   -0.337710  0.001285  0.018225  ... -0.123426  0.167397  0.237288   \ndw_3   -0.460442  0.004292  0.010350  ... -0.203574  0.143928  0.272752   \ndw_4   -0.246875  0.003327  0.003775  ... -0.154983  0.064231  0.121135   \ndw_5   -0.039939  0.000859  0.000096  ... -0.070726  0.009459  0.007874   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.121316 -0.001690  0.004790  ... -0.134379 -0.207376 -0.072612   \ncfr_13  0.009997  0.003478 -0.000130  ...  0.147883  0.041925 -0.211124   \ncfr_14  0.027808  0.003788 -0.003911  ...  0.109109  0.222240  0.044405   \ncfr_15  0.052462  0.001549 -0.008696  ...  0.279721  0.160473 -0.089826   \ncfr_16 -0.011343  0.011160 -0.005962  ...  0.257415  0.135676  0.188556   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.037365 -0.023672 -0.057237 -0.042960 -0.052143 -0.079161 -0.066310  \ndw_2    0.168364  0.049215  0.034692  0.128171  0.009246 -0.115564 -0.075292  \ndw_3    0.119350 -0.051559  0.061458  0.046053 -0.019790 -0.131894 -0.046861  \ndw_4    0.050684 -0.040099  0.050791  0.024330 -0.029443 -0.102508 -0.042964  \ndw_5    0.021196  0.000299  0.019165  0.013247 -0.034829 -0.053621 -0.029838  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.035689  0.062709  1.000000  0.019376  0.001574 -0.345510 -0.225272  \ncfr_13 -0.268978 -0.011602  0.019376  1.000000  0.223072  0.131959 -0.159064  \ncfr_14 -0.175685 -0.289441  0.001574  0.223072  1.000000  0.198522 -0.135727  \ncfr_15 -0.144377 -0.074435 -0.345510  0.131959  0.198522  1.000000  0.297959  \ncfr_16  0.150307  0.005543 -0.225272 -0.159064 -0.135727  0.297959  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.219210</td>\n      <td>0.101301</td>\n      <td>0.071494</td>\n      <td>0.053500</td>\n      <td>0.102907</td>\n      <td>-0.028753</td>\n      <td>0.044410</td>\n      <td>-0.002493</td>\n      <td>0.004377</td>\n      <td>...</td>\n      <td>-0.077538</td>\n      <td>-0.054871</td>\n      <td>-0.040977</td>\n      <td>-0.037365</td>\n      <td>-0.023672</td>\n      <td>-0.057237</td>\n      <td>-0.042960</td>\n      <td>-0.052143</td>\n      <td>-0.079161</td>\n      <td>-0.066310</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.219210</td>\n      <td>1.000000</td>\n      <td>0.838628</td>\n      <td>0.486610</td>\n      <td>0.180151</td>\n      <td>0.408486</td>\n      <td>-0.502032</td>\n      <td>-0.337710</td>\n      <td>0.001285</td>\n      <td>0.018225</td>\n      <td>...</td>\n      <td>-0.123426</td>\n      <td>0.167397</td>\n      <td>0.237288</td>\n      <td>0.168364</td>\n      <td>0.049215</td>\n      <td>0.034692</td>\n      <td>0.128171</td>\n      <td>0.009246</td>\n      <td>-0.115564</td>\n      <td>-0.075292</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.101301</td>\n      <td>0.838628</td>\n      <td>1.000000</td>\n      <td>0.680243</td>\n      <td>0.272747</td>\n      <td>0.255846</td>\n      <td>-0.548064</td>\n      <td>-0.460442</td>\n      <td>0.004292</td>\n      <td>0.010350</td>\n      <td>...</td>\n      <td>-0.203574</td>\n      <td>0.143928</td>\n      <td>0.272752</td>\n      <td>0.119350</td>\n      <td>-0.051559</td>\n      <td>0.061458</td>\n      <td>0.046053</td>\n      <td>-0.019790</td>\n      <td>-0.131894</td>\n      <td>-0.046861</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.071494</td>\n      <td>0.486610</td>\n      <td>0.680243</td>\n      <td>1.000000</td>\n      <td>0.880644</td>\n      <td>-0.012857</td>\n      <td>-0.262781</td>\n      <td>-0.246875</td>\n      <td>0.003327</td>\n      <td>0.003775</td>\n      <td>...</td>\n      <td>-0.154983</td>\n      <td>0.064231</td>\n      <td>0.121135</td>\n      <td>0.050684</td>\n      <td>-0.040099</td>\n      <td>0.050791</td>\n      <td>0.024330</td>\n      <td>-0.029443</td>\n      <td>-0.102508</td>\n      <td>-0.042964</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.053500</td>\n      <td>0.180151</td>\n      <td>0.272747</td>\n      <td>0.880644</td>\n      <td>1.000000</td>\n      <td>-0.126287</td>\n      <td>-0.018966</td>\n      <td>-0.039939</td>\n      <td>0.000859</td>\n      <td>0.000096</td>\n      <td>...</td>\n      <td>-0.070726</td>\n      <td>0.009459</td>\n      <td>0.007874</td>\n      <td>0.021196</td>\n      <td>0.000299</td>\n      <td>0.019165</td>\n      <td>0.013247</td>\n      <td>-0.034829</td>\n      <td>-0.053621</td>\n      <td>-0.029838</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.057237</td>\n      <td>0.034692</td>\n      <td>0.061458</td>\n      <td>0.050791</td>\n      <td>0.019165</td>\n      <td>-0.138724</td>\n      <td>0.094631</td>\n      <td>0.121316</td>\n      <td>-0.001690</td>\n      <td>0.004790</td>\n      <td>...</td>\n      <td>-0.134379</td>\n      <td>-0.207376</td>\n      <td>-0.072612</td>\n      <td>0.035689</td>\n      <td>0.062709</td>\n      <td>1.000000</td>\n      <td>0.019376</td>\n      <td>0.001574</td>\n      <td>-0.345510</td>\n      <td>-0.225272</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.042960</td>\n      <td>0.128171</td>\n      <td>0.046053</td>\n      <td>0.024330</td>\n      <td>0.013247</td>\n      <td>0.077703</td>\n      <td>-0.006064</td>\n      <td>0.009997</td>\n      <td>0.003478</td>\n      <td>-0.000130</td>\n      <td>...</td>\n      <td>0.147883</td>\n      <td>0.041925</td>\n      <td>-0.211124</td>\n      <td>-0.268978</td>\n      <td>-0.011602</td>\n      <td>0.019376</td>\n      <td>1.000000</td>\n      <td>0.223072</td>\n      <td>0.131959</td>\n      <td>-0.159064</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.052143</td>\n      <td>0.009246</td>\n      <td>-0.019790</td>\n      <td>-0.029443</td>\n      <td>-0.034829</td>\n      <td>0.004839</td>\n      <td>0.022487</td>\n      <td>0.027808</td>\n      <td>0.003788</td>\n      <td>-0.003911</td>\n      <td>...</td>\n      <td>0.109109</td>\n      <td>0.222240</td>\n      <td>0.044405</td>\n      <td>-0.175685</td>\n      <td>-0.289441</td>\n      <td>0.001574</td>\n      <td>0.223072</td>\n      <td>1.000000</td>\n      <td>0.198522</td>\n      <td>-0.135727</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.079161</td>\n      <td>-0.115564</td>\n      <td>-0.131894</td>\n      <td>-0.102508</td>\n      <td>-0.053621</td>\n      <td>0.045425</td>\n      <td>0.082850</td>\n      <td>0.052462</td>\n      <td>0.001549</td>\n      <td>-0.008696</td>\n      <td>...</td>\n      <td>0.279721</td>\n      <td>0.160473</td>\n      <td>-0.089826</td>\n      <td>-0.144377</td>\n      <td>-0.074435</td>\n      <td>-0.345510</td>\n      <td>0.131959</td>\n      <td>0.198522</td>\n      <td>1.000000</td>\n      <td>0.297959</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.066310</td>\n      <td>-0.075292</td>\n      <td>-0.046861</td>\n      <td>-0.042964</td>\n      <td>-0.029838</td>\n      <td>0.074518</td>\n      <td>-0.038814</td>\n      <td>-0.011343</td>\n      <td>0.011160</td>\n      <td>-0.005962</td>\n      <td>...</td>\n      <td>0.257415</td>\n      <td>0.135676</td>\n      <td>0.188556</td>\n      <td>0.150307</td>\n      <td>0.005543</td>\n      <td>-0.225272</td>\n      <td>-0.159064</td>\n      <td>-0.135727</td>\n      <td>0.297959</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mfw_11', 'fft_231', 'fft_171', 'fft_217', 'fft_148', 'fft_153', 'fft_177', 'fft_198', 'fft_132', 'fft_246', 'fft_247', 'fft_250', 'mfw_14', 'fft_145', 'fft_152', 'fft_249', 'fft_255', 'fft_226', 'fft_167', 'fft_172', 'fft_158', 'fft_212', 'fft_205', 'fft_248', 'fft_238', 'fft_133', 'fft_232', 'mfw_9', 'fft_237', 'fft_179', 'fft_193', 'fft_223', 'fft_163', 'fft_181', 'fft_136', 'fft_222', 'fft_155', 'fft_185', 'fft_140', 'fft_164', 'fft_137', 'fft_225', 'fft_240', 'mfw_10', 'fft_180', 'fft_130', 'fft_151', 'fft_162', 'fft_242', 'fft_156', 'fft_187', 'fft_252', 'fft_241', 'fft_228', 'fft_202', 'fft_214', 'fft_215', 'mfw_12', 'fft_204', 'fft_134', 'fft_166', 'fft_220', 'fft_176', 'fft_210', 'fft_182', 'fft_147', 'fft_143', 'fft_150', 'fft_157', 'fft_245', 'fft_216', 'fft_218', 'fft_194', 'fft_227', 'fft_192', 'fft_174', 'fft_131', 'fft_199', 'fft_168', 'mfw_7', 'fft_188', 'fft_229', 'fft_144', 'fft_224', 'mfw_8', 'fft_159', 'fft_254', 'mfw_5', 'fft_141', 'fft_200', 'fft_173', 'fft_234', 'fft_197', 'fft_251', 'fft_230', 'fft_138', 'fft_207', 'fft_175', 'fft_170', 'fft_146', 'fft_191', 'fft_203', 'fft_253', 'mfw_15', 'fft_169', 'mfw_16', 'fft_165', 'fft_190', 'fft_235', 'fft_135', 'fft_154', 'fft_189', 'mfw_13', 'fft_243', 'fft_196', 'fft_161', 'fft_206', 'fft_239', 'fft_213', 'fft_256', 'fft_211', 'fft_139', 'mfw_6', 'fft_184', 'fft_149', 'fft_201', 'fft_160', 'fft_233', 'fft_142', 'fft_209', 'fft_221', 'fft_208', 'fft_195', 'fft_236', 'cfr_16', 'fft_186', 'fft_219', 'fft_183', 'fft_178', 'fft_244'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_24\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_13\n",
      "ar_14\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 73\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1     mfw_2  \\\n0  65.861928  67.716291  67.206386  18.973287  2.756737  0.736288 -0.634501   \n1  67.175188  66.539171  66.278974  18.879508  2.752145  0.710574 -0.608829   \n2  67.331260  67.526064  67.904703  19.526248  2.883850  0.724048 -0.611290   \n3  66.507411  69.358972  68.845433  19.399284  2.811633  0.728870 -0.631538   \n4  71.500586  69.600473  69.015425  19.518971  2.844739  0.706509 -0.610843   \n\n      mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -1.015121 -0.279539  0.905306  ...  0.020720  0.039231 -0.038497  0.024202   \n1 -1.008338 -0.375129 -0.354970  ...  0.009445  0.040896 -0.045707  0.028543   \n2 -1.007119 -0.471325  1.782405  ...  0.011313  0.048344 -0.064803  0.051981   \n3 -1.076715 -0.451683 -3.475203  ...  0.013055  0.040612 -0.042918  0.033450   \n4 -1.008555 -0.438800 -1.080058  ...  0.004456  0.042616 -0.047597  0.025825   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.033980  0.046029 -0.071080  0.009209 -0.027384 -0.007471  \n1 -0.033995  0.039226 -0.065687 -0.004942 -0.011601 -0.016082  \n2 -0.056875  0.061396 -0.081542  0.009957 -0.023760 -0.019310  \n3 -0.043966  0.053377 -0.073200  0.002332 -0.021755 -0.003223  \n4 -0.031552  0.048798 -0.093202  0.026254 -0.038423 -0.005951  \n\n[5 rows x 73 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>65.861928</td>\n      <td>67.716291</td>\n      <td>67.206386</td>\n      <td>18.973287</td>\n      <td>2.756737</td>\n      <td>0.736288</td>\n      <td>-0.634501</td>\n      <td>-1.015121</td>\n      <td>-0.279539</td>\n      <td>0.905306</td>\n      <td>...</td>\n      <td>0.020720</td>\n      <td>0.039231</td>\n      <td>-0.038497</td>\n      <td>0.024202</td>\n      <td>-0.033980</td>\n      <td>0.046029</td>\n      <td>-0.071080</td>\n      <td>0.009209</td>\n      <td>-0.027384</td>\n      <td>-0.007471</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.175188</td>\n      <td>66.539171</td>\n      <td>66.278974</td>\n      <td>18.879508</td>\n      <td>2.752145</td>\n      <td>0.710574</td>\n      <td>-0.608829</td>\n      <td>-1.008338</td>\n      <td>-0.375129</td>\n      <td>-0.354970</td>\n      <td>...</td>\n      <td>0.009445</td>\n      <td>0.040896</td>\n      <td>-0.045707</td>\n      <td>0.028543</td>\n      <td>-0.033995</td>\n      <td>0.039226</td>\n      <td>-0.065687</td>\n      <td>-0.004942</td>\n      <td>-0.011601</td>\n      <td>-0.016082</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.331260</td>\n      <td>67.526064</td>\n      <td>67.904703</td>\n      <td>19.526248</td>\n      <td>2.883850</td>\n      <td>0.724048</td>\n      <td>-0.611290</td>\n      <td>-1.007119</td>\n      <td>-0.471325</td>\n      <td>1.782405</td>\n      <td>...</td>\n      <td>0.011313</td>\n      <td>0.048344</td>\n      <td>-0.064803</td>\n      <td>0.051981</td>\n      <td>-0.056875</td>\n      <td>0.061396</td>\n      <td>-0.081542</td>\n      <td>0.009957</td>\n      <td>-0.023760</td>\n      <td>-0.019310</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>66.507411</td>\n      <td>69.358972</td>\n      <td>68.845433</td>\n      <td>19.399284</td>\n      <td>2.811633</td>\n      <td>0.728870</td>\n      <td>-0.631538</td>\n      <td>-1.076715</td>\n      <td>-0.451683</td>\n      <td>-3.475203</td>\n      <td>...</td>\n      <td>0.013055</td>\n      <td>0.040612</td>\n      <td>-0.042918</td>\n      <td>0.033450</td>\n      <td>-0.043966</td>\n      <td>0.053377</td>\n      <td>-0.073200</td>\n      <td>0.002332</td>\n      <td>-0.021755</td>\n      <td>-0.003223</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>71.500586</td>\n      <td>69.600473</td>\n      <td>69.015425</td>\n      <td>19.518971</td>\n      <td>2.844739</td>\n      <td>0.706509</td>\n      <td>-0.610843</td>\n      <td>-1.008555</td>\n      <td>-0.438800</td>\n      <td>-1.080058</td>\n      <td>...</td>\n      <td>0.004456</td>\n      <td>0.042616</td>\n      <td>-0.047597</td>\n      <td>0.025825</td>\n      <td>-0.031552</td>\n      <td>0.048798</td>\n      <td>-0.093202</td>\n      <td>0.026254</td>\n      <td>-0.038423</td>\n      <td>-0.005951</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 73 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 6.879000902175903 s\n",
      "Accuracy 0.9212644519244841 precision 0.9212516838329105 specificity 0.7910038518609159 recall 0.9212644519244841 f1 0.9179817145263145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 6.727000713348389 s\n",
      "Accuracy 0.9250695155861262 precision 0.9249867979605548 specificity 0.7883104185943403 recall 0.9250695155861262 f1 0.9218281594746525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 6.675617218017578 s\n",
      "Accuracy 0.9282891848382848 precision 0.9279357029057943 specificity 0.8131980699252332 recall 0.9282891848382848 f1 0.9258228311306522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 6.623206377029419 s\n",
      "Accuracy 0.9224352407434508 precision 0.9225400491159809 specificity 0.7815502800960596 recall 0.9224352407434508 f1 0.918891067605033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 6.755907297134399 s\n",
      "Accuracy 0.9255085613932387 precision 0.9258653613739412 specificity 0.7896218171827809 recall 0.9255085613932387 f1 0.9221902036237513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 6.683000564575195 s\n",
      "Accuracy 0.9180447826723255 precision 0.9176170310580739 specificity 0.7754977407602938 recall 0.9180447826723255 f1 0.9143737820101893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 6.812001705169678 s\n",
      "Accuracy 0.9221425435387092 precision 0.9223211922447742 specificity 0.7858087757441098 recall 0.9221425435387092 f1 0.9186854196324195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 6.627999305725098 s\n",
      "Accuracy 0.9278501390311723 precision 0.9274185559245001 specificity 0.80749782056671 recall 0.9278501390311723 f1 0.9252636334751436\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 6.726998329162598 s\n",
      "Accuracy 0.9231669837553051 precision 0.9224147277412775 specificity 0.798790175056024 recall 0.9231669837553051 f1 0.9203793166670234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 6.672557830810547 s\n",
      "Accuracy 0.92228889214108 precision 0.9215329701784013 specificity 0.8050504785311137 recall 0.92228889214108 f1 0.9196533605087414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 6.756548166275024 s\n",
      "Accuracy 0.9230206351529343 precision 0.922744288107078 specificity 0.7956567033630892 recall 0.9230206351529343 f1 0.9199818751561488\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 6.742431879043579 s\n",
      "Accuracy 0.9259476072003512 precision 0.9253578623424609 specificity 0.7976415434206212 recall 0.9259476072003512 f1 0.9231299539566661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 6.69032096862793 s\n",
      "Accuracy 0.9278501390311723 precision 0.9273980014164064 specificity 0.8083868814073017 recall 0.9278501390311723 f1 0.9252923010254743\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 6.592999219894409 s\n",
      "Accuracy 0.924337772574272 precision 0.9235671359349722 specificity 0.8006672275823595 recall 0.924337772574272 f1 0.9216308255060147\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 6.6931681632995605 s\n",
      "Accuracy 0.9313625054880725 precision 0.9311077092139072 specificity 0.8120734016383108 recall 0.9313625054880725 f1 0.9288969416951064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 6.588001251220703 s\n",
      "Accuracy 0.9209717547197425 precision 0.9204934604488518 specificity 0.7896353662524012 recall 0.9209717547197425 f1 0.9177906044677844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 6.659536361694336 s\n",
      "Accuracy 0.9303380652714767 precision 0.9302853464931162 specificity 0.81119794385609 recall 0.9303380652714767 f1 0.9277704524397782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 6.459570646286011 s\n",
      "Accuracy 0.9249231669837553 precision 0.9244919113223615 specificity 0.7988517330150676 recall 0.9249231669837553 f1 0.9220592964501493\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 6.631864786148071 s\n",
      "Accuracy 0.9206790575150008 precision 0.9209870076204508 specificity 0.7933780576935838 recall 0.9206790575150008 f1 0.9173583430060664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 6.797997236251831 s\n",
      "Accuracy 0.9189228742865506 precision 0.9182745717428019 specificity 0.7851952114170311 recall 0.9189228742865506 f1 0.9156285719287719\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 6.575999021530151 s\n",
      "Accuracy 0.9246304697790136 precision 0.9248835457611919 specificity 0.8019305679617795 recall 0.9246304697790136 f1 0.9216349486330159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 6.687000751495361 s\n",
      "Accuracy 0.921410800526855 precision 0.9213564998499465 specificity 0.7810472353494415 recall 0.921410800526855 f1 0.9178711631796174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 6.611999988555908 s\n",
      "Accuracy 0.9238987267671593 precision 0.9234703635418247 specificity 0.7965418188333199 recall 0.9238987267671593 f1 0.9209517258773942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 6.741999864578247 s\n",
      "Accuracy 0.920386360310259 precision 0.9205205028598844 specificity 0.779716109443418 recall 0.920386360310259 f1 0.9167282204921071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 6.6949989795684814 s\n",
      "Accuracy 0.921410800526855 precision 0.9217674856786896 specificity 0.7876658965393283 recall 0.921410800526855 f1 0.9179376650224724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 6.593332529067993 s\n",
      "Accuracy 0.9198009659007756 precision 0.9190424465183454 specificity 0.7892234751040136 recall 0.9198009659007756 f1 0.9166811875627229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 6.686503171920776 s\n",
      "Accuracy 0.9221425435387092 precision 0.9213339300234569 specificity 0.7907564327152959 recall 0.9221425435387092 f1 0.9191373088459392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 6.668999433517456 s\n",
      "Accuracy 0.9287282306453973 precision 0.9280248277356792 specificity 0.797743964140751 recall 0.9287282306453973 f1 0.926019273177181\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 6.79552435874939 s\n",
      "Accuracy 0.923313332357676 precision 0.9227273628018021 specificity 0.80167208338449 recall 0.923313332357676 f1 0.9205433477849514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 6.632000207901001 s\n",
      "Accuracy 0.9202400117078882 precision 0.9199804037294037 specificity 0.7958814178036225 recall 0.9202400117078882 f1 0.9171437341150384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 6.735730409622192 s\n",
      "Accuracy 0.9240450753695302 precision 0.9235073716304443 specificity 0.7940978064965436 recall 0.9240450753695302 f1 0.921074387902803\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 6.783001661300659 s\n",
      "Accuracy 0.926240304405093 precision 0.9268614077161305 specificity 0.8015288147751275 recall 0.926240304405093 f1 0.9231749153160251\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 6.7389976978302 s\n",
      "Accuracy 0.9228742865505635 precision 0.923774028604185 specificity 0.7899018079313364 recall 0.9228742865505635 f1 0.9193619870947977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 6.616000175476074 s\n",
      "Accuracy 0.9258012585979803 precision 0.925294714437471 specificity 0.8009513974199444 recall 0.9258012585979803 f1 0.9230353934408306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 6.704087495803833 s\n",
      "Accuracy 0.9237523781647885 precision 0.9231553489874372 specificity 0.7920899138953768 recall 0.9237523781647885 f1 0.9207426929137785\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 6.748932600021362 s\n",
      "Accuracy 0.9221425435387092 precision 0.9215438793755493 specificity 0.7928982894004218 recall 0.9221425435387092 f1 0.9191183346308304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 6.738000392913818 s\n",
      "Accuracy 0.9218498463339675 precision 0.9215546290982506 specificity 0.7916398222848046 recall 0.9218498463339675 f1 0.9186835528569324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 6.704168319702148 s\n",
      "Accuracy 0.919508268696034 precision 0.9191561597900662 specificity 0.7868989301378413 recall 0.919508268696034 f1 0.9161757218239952\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 6.778698921203613 s\n",
      "Accuracy 0.9244841211766428 precision 0.9247074292323127 specificity 0.7997902997291546 recall 0.9244841211766428 f1 0.9214385979509305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 6.724998950958252 s\n",
      "Accuracy 0.9238987267671593 precision 0.9237231336442457 specificity 0.8001319951990465 recall 0.9238987267671593 f1 0.9209645692644182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 6.846041679382324 s\n",
      "Accuracy 0.9260939558027221 precision 0.925723246676166 specificity 0.7947993727814572 recall 0.9260939558027221 f1 0.9231331537819816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 6.750000238418579 s\n",
      "Accuracy 0.9227279379481926 precision 0.9230455889550422 specificity 0.7854817809973955 recall 0.9227279379481926 f1 0.919239173754691\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 6.657998085021973 s\n",
      "Accuracy 0.9237523781647885 precision 0.9233134501360603 specificity 0.8011051345887544 recall 0.9237523781647885 f1 0.9209251107439687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 6.666008472442627 s\n",
      "Accuracy 0.9301917166691058 precision 0.9298757581207912 specificity 0.8137737069233019 recall 0.9301917166691058 f1 0.9277619787112483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 6.640001058578491 s\n",
      "Accuracy 0.92228889214108 precision 0.9218168480982889 specificity 0.7990525101495745 recall 0.92228889214108 f1 0.919389336881138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 6.70891809463501 s\n",
      "Accuracy 0.9219961949363383 precision 0.921542928930304 specificity 0.7853178297188008 recall 0.9219961949363383 f1 0.9187129531506506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 6.771981477737427 s\n",
      "Accuracy 0.9250695155861262 precision 0.9253809324566894 specificity 0.7951575498423478 recall 0.9250695155861262 f1 0.9218944182336125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 6.68999981880188 s\n",
      "Accuracy 0.9215571491292258 precision 0.9219394519962438 specificity 0.7919504003869977 recall 0.9215571491292258 f1 0.9181973011648574\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 6.708998918533325 s\n",
      "Accuracy 0.9244841211766428 precision 0.9250169898534438 specificity 0.8000635110017307 recall 0.9244841211766428 f1 0.92136503039812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 6.68799901008606 s\n",
      "Accuracy 0.9237523781647885 precision 0.9238471306437106 specificity 0.7946918735146207 recall 0.9237523781647885 f1 0.9205939285970692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 6.624000072479248 s\n",
      "Accuracy 0.9287282306453973 precision 0.9285899660114469 specificity 0.8098749269702114 recall 0.9287282306453973 f1 0.9261227692763523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 6.693000793457031 s\n",
      "Accuracy 0.9269720474169472 precision 0.9272714672754848 specificity 0.7973564795833356 recall 0.9269720474169472 f1 0.9239005833879498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 6.79999852180481 s\n",
      "Accuracy 0.9218498463339675 precision 0.9215636356724071 specificity 0.7879799543878426 recall 0.9218498463339675 f1 0.9185814769196762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 6.637170076370239 s\n",
      "Accuracy 0.9224352407434508 precision 0.9216054155445594 specificity 0.7909188802995929 recall 0.9224352407434508 f1 0.919449351184058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 6.785999059677124 s\n",
      "Accuracy 0.9221425435387092 precision 0.92207233896708 specificity 0.7947132395888751 recall 0.9221425435387092 f1 0.9189964748166185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 6.82657265663147 s\n",
      "Accuracy 0.924191423971901 precision 0.924129953754992 specificity 0.7896141753567107 recall 0.924191423971901 f1 0.9209555030495833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 6.9296040534973145 s\n",
      "Accuracy 0.9198009659007756 precision 0.9202121213166923 specificity 0.78166466435598 recall 0.9198009659007756 f1 0.9161065003703069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 6.73099946975708 s\n",
      "Accuracy 0.9282891848382848 precision 0.9278228136425716 specificity 0.8095389704868274 recall 0.9282891848382848 f1 0.9257727794341323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 6.752000331878662 s\n",
      "Accuracy 0.9212644519244841 precision 0.9212882766288252 specificity 0.7926051728778633 recall 0.9212644519244841 f1 0.9180146699349467\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 6.693999528884888 s\n",
      "Accuracy 0.9236060295624177 precision 0.9233561141898362 specificity 0.7954294738595644 recall 0.9236060295624177 f1 0.9205658420574976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 6.6978232860565186 s\n",
      "Accuracy 0.921410800526855 precision 0.9216168080416292 specificity 0.7809152268842329 recall 0.921410800526855 f1 0.9177933861250391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 6.617022752761841 s\n",
      "Accuracy 0.9234596809600468 precision 0.9234905567700828 specificity 0.792565817970943 recall 0.9234596809600468 f1 0.920256808137875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 6.735000848770142 s\n",
      "Accuracy 0.923313332357676 precision 0.9229814549653261 specificity 0.7904060594322411 recall 0.923313332357676 f1 0.9201597337586397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 6.6289989948272705 s\n",
      "Accuracy 0.9224352407434508 precision 0.9223253502257237 specificity 0.7963829942842975 recall 0.9224352407434508 f1 0.9193519136348353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 6.68499755859375 s\n",
      "Accuracy 0.9277037904288014 precision 0.9277905846499834 specificity 0.7906053593057425 recall 0.9277037904288014 f1 0.9245407436438374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 6.704106569290161 s\n",
      "Accuracy 0.9238987267671593 precision 0.9241088504390896 specificity 0.7816147862194659 recall 0.9238987267671593 f1 0.9203673352929058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 6.586416959762573 s\n",
      "Accuracy 0.928142836235914 precision 0.927466849678607 specificity 0.8041512943795648 recall 0.928142836235914 f1 0.9255676694007217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 6.5889997482299805 s\n",
      "Accuracy 0.9278501390311723 precision 0.9275745650387588 specificity 0.7989489139660242 recall 0.9278501390311723 f1 0.9250036921615404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 6.618999719619751 s\n",
      "Accuracy 0.9228742865505635 precision 0.9228533838112497 specificity 0.7873491063477978 recall 0.9228742865505635 f1 0.9195337116167261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 6.65161919593811 s\n",
      "Accuracy 0.9256549099956095 precision 0.9251621444032203 specificity 0.8065090851381931 recall 0.9256549099956095 f1 0.9230220316878992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 6.782999038696289 s\n",
      "Accuracy 0.9211181033221133 precision 0.9200587188784785 specificity 0.7938696722175135 recall 0.9211181033221133 f1 0.9182787127228956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 6.860002756118774 s\n",
      "Accuracy 0.920386360310259 precision 0.9208366806932873 specificity 0.776475103372375 recall 0.920386360310259 f1 0.9165514722421685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 6.692166090011597 s\n",
      "Accuracy 0.9263866530074638 precision 0.9259233323079865 specificity 0.8072812078043166 recall 0.9263866530074638 f1 0.923776984213368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 6.753674268722534 s\n",
      "Accuracy 0.9265330016098346 precision 0.9258798598418553 specificity 0.8006938006406066 recall 0.9265330016098346 f1 0.923828597651274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 6.749999523162842 s\n",
      "Accuracy 0.923313332357676 precision 0.9237016105252058 specificity 0.786868047645797 recall 0.923313332357676 f1 0.9198580528112718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 6.673000335693359 s\n",
      "Accuracy 0.9231669837553051 precision 0.9231757326121875 specificity 0.7945613054930478 recall 0.9231669837553051 f1 0.9200164093237112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 6.672266006469727 s\n",
      "Accuracy 0.9228742865505635 precision 0.9228035671255918 specificity 0.7895571285623111 recall 0.9228742865505635 f1 0.9196073123041619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 6.602328777313232 s\n",
      "Accuracy 0.9192155714912923 precision 0.9185385232496114 specificity 0.7869237807031633 recall 0.9192155714912923 f1 0.9159875886634045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 6.618796348571777 s\n",
      "Accuracy 0.9212644519244841 precision 0.9209997311691883 specificity 0.7903849179579822 recall 0.9212644519244841 f1 0.9180411055649692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 6.843510627746582 s\n",
      "Accuracy 0.921410800526855 precision 0.9215901995183569 specificity 0.7913947582565884 recall 0.921410800526855 f1 0.9180873697159092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 6.758998394012451 s\n",
      "Accuracy 0.9244841211766428 precision 0.9240456231010982 specificity 0.8004664305618541 recall 0.9244841211766428 f1 0.9216550298057283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 6.689001798629761 s\n",
      "Accuracy 0.9227279379481926 precision 0.9219766384018703 specificity 0.7971848731928567 recall 0.9227279379481926 f1 0.9198878477100507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 7.308912515640259 s\n",
      "Accuracy 0.9265330016098346 precision 0.9256868818910753 specificity 0.8035559621408074 recall 0.9265330016098346 f1 0.9239759467957434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 6.916868448257446 s\n",
      "Accuracy 0.9215571491292258 precision 0.9205681005299909 specificity 0.7938400357805757 recall 0.9215571491292258 f1 0.9186961522034608\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 6.9639732837677 s\n",
      "Accuracy 0.9208254061173716 precision 0.9207014268710492 specificity 0.7984719583483041 recall 0.9208254061173716 f1 0.9177696557254769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 6.821999549865723 s\n",
      "Accuracy 0.9227279379481926 precision 0.9224350725259641 specificity 0.7956116507428304 recall 0.9227279379481926 f1 0.9196868661378522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 6.891999006271362 s\n",
      "Accuracy 0.9224352407434508 precision 0.9219499306731395 specificity 0.7857784735214043 recall 0.9224352407434508 f1 0.9191862234611745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 6.6940016746521 s\n",
      "Accuracy 0.9260939558027221 precision 0.9255223224523819 specificity 0.7933347917925169 recall 0.9260939558027221 f1 0.9231635306473815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 6.655999422073364 s\n",
      "Accuracy 0.9178984340699546 precision 0.917634282225176 specificity 0.7754542317541 recall 0.9178984340699546 f1 0.9141700483870244\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 6.763999700546265 s\n",
      "Accuracy 0.9234596809600468 precision 0.9230521069201233 specificity 0.7994228847833266 recall 0.9234596809600468 f1 0.9205719597484877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 6.831531524658203 s\n",
      "Accuracy 0.9221425435387092 precision 0.9222652895149033 specificity 0.7902441331062934 recall 0.9221425435387092 f1 0.9188207849558794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 6.7238593101501465 s\n",
      "Accuracy 0.924337772574272 precision 0.9243990614002819 specificity 0.8026270832516187 recall 0.924337772574272 f1 0.9214071314870392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 6.826139211654663 s\n",
      "Accuracy 0.9246304697790136 precision 0.9248801162160891 specificity 0.7947526918959987 recall 0.9246304697790136 f1 0.9214511696813127\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 6.609483957290649 s\n",
      "Accuracy 0.9247768183813845 precision 0.9246484776184877 specificity 0.793764348179997 recall 0.9247768183813845 f1 0.9216828192893283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 6.694000005722046 s\n",
      "Accuracy 0.9221425435387092 precision 0.9218026430455717 specificity 0.7806038654238978 recall 0.9221425435387092 f1 0.9186976995835922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 6.802001476287842 s\n",
      "Accuracy 0.927118396019318 precision 0.9269394313057787 specificity 0.7936168340185279 recall 0.927118396019318 f1 0.9240925759874691\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 6.78099799156189 s\n",
      "Accuracy 0.9212644519244841 precision 0.9213459578868465 specificity 0.7908042106805019 recall 0.9212644519244841 f1 0.9179491036307964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 6.6712327003479 s\n",
      "Accuracy 0.9263866530074638 precision 0.9264347818786183 specificity 0.7988051871861538 recall 0.9263866530074638 f1 0.9234065367312425\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 6.422004461288452 s\n",
      "Accuracy 0.9282891848382848 precision 0.9286268539341851 specificity 0.8014413593973977 recall 0.9282891848382848 f1 0.9253388009747291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 6.714999198913574 s\n",
      "Accuracy 0.9268256988145763 precision 0.9267641633374664 specificity 0.8001810778474389 recall 0.9268256988145763 f1 0.9239214019969265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 6.616640090942383 s\n",
      "Accuracy 0.925215864188497 precision 0.9246551697509479 specificity 0.7997325523717468 recall 0.925215864188497 f1 0.922425341618374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 6.822511196136475 s\n",
      "Accuracy 0.9247768183813845 precision 0.9243984365876053 specificity 0.8044641303522124 recall 0.9247768183813845 f1 0.9220363144962258\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 6.577181100845337 s\n",
      "Accuracy 0.919508268696034 precision 0.9192411492475725 specificity 0.7865374862342087 recall 0.919508268696034 f1 0.9161384955801621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 6.6370015144348145 s\n",
      "Accuracy 0.9227279379481926 precision 0.9221129689098629 specificity 0.7980742386590055 recall 0.9227279379481926 f1 0.9198611950951329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 6.607999801635742 s\n",
      "Accuracy 0.9255085613932387 precision 0.9255617896509193 specificity 0.8014449498763156 recall 0.9255085613932387 f1 0.9225742155546157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 6.725000619888306 s\n",
      "Accuracy 0.9253622127908678 precision 0.9250396730710184 specificity 0.801910026521416 recall 0.9253622127908678 f1 0.922550098094474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 6.935626745223999 s\n",
      "Accuracy 0.920386360310259 precision 0.9201780202446067 specificity 0.7929059706637575 recall 0.920386360310259 f1 0.9171951540866067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 6.887855529785156 s\n",
      "Accuracy 0.9246304697790136 precision 0.9247458895561281 specificity 0.790796927647336 recall 0.9246304697790136 f1 0.921385567726506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 6.629000663757324 s\n",
      "Accuracy 0.9278501390311723 precision 0.9274042793800096 specificity 0.8029290793188893 recall 0.9278501390311723 f1 0.9251567741978556\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 6.544998645782471 s\n",
      "Accuracy 0.9209717547197425 precision 0.9208055242162714 specificity 0.7807421725558854 recall 0.9209717547197425 f1 0.9174454650627824\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 6.798999547958374 s\n",
      "Accuracy 0.9208254061173716 precision 0.9210969920735507 specificity 0.773367640609203 recall 0.9208254061173716 f1 0.9169638659337742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 6.728199243545532 s\n",
      "Accuracy 0.9209717547197425 precision 0.9207135077960643 specificity 0.7933448280406443 recall 0.9209717547197425 f1 0.9178207382548953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 6.5085289478302 s\n",
      "Accuracy 0.9227279379481926 precision 0.9223981175251785 specificity 0.7919715372948419 recall 0.9227279379481926 f1 0.9196016404292815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 6.557839632034302 s\n",
      "Accuracy 0.9284355334406557 precision 0.92794070822768 specificity 0.8068757842437346 recall 0.9284355334406557 f1 0.9258674436896542\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 6.6030004024505615 s\n",
      "Accuracy 0.9266793502122055 precision 0.9264507703367145 specificity 0.7957880628757814 recall 0.9266793502122055 f1 0.9237123602742396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 6.728020429611206 s\n",
      "Accuracy 0.9258012585979803 precision 0.9258664423189384 specificity 0.794352099705212 recall 0.9258012585979803 f1 0.9226903270522742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 6.652681827545166 s\n",
      "Accuracy 0.9221425435387092 precision 0.9215290833949672 specificity 0.7885608623272923 recall 0.9221425435387092 f1 0.9190058735346731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 6.690822601318359 s\n",
      "Accuracy 0.9306307624762183 precision 0.9304911587281461 specificity 0.8081207520377884 recall 0.9306307624762183 f1 0.9280234575001107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 7.073030948638916 s\n",
      "Accuracy 0.9288745792477682 precision 0.9296447348755066 specificity 0.805890352373023 recall 0.9288745792477682 f1 0.9259389025806395\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 6.886767625808716 s\n",
      "Accuracy 0.9285818820430265 precision 0.9289546139269944 specificity 0.8048611918323111 recall 0.9285818820430265 f1 0.9257116870692429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 6.7313313484191895 s\n",
      "Accuracy 0.9240450753695302 precision 0.9235726865530812 specificity 0.7851576225098282 recall 0.9240450753695302 f1 0.920816506379088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 6.763999938964844 s\n",
      "Accuracy 0.9218498463339675 precision 0.9215343842997641 specificity 0.7825079152658785 recall 0.9218498463339675 f1 0.918441515937933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 6.904996633529663 s\n",
      "Accuracy 0.9256549099956095 precision 0.9260457639781282 specificity 0.7920952618417729 recall 0.9256549099956095 f1 0.922394750387236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 6.928795099258423 s\n",
      "Accuracy 0.917605736865213 precision 0.9169696562604407 specificity 0.7875841485182209 recall 0.917605736865213 f1 0.9143461913104398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 6.7179999351501465 s\n",
      "Accuracy 0.9234596809600468 precision 0.9232788866639446 specificity 0.7937627997506953 recall 0.9234596809600468 f1 0.9203510063038601\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 6.613136053085327 s\n",
      "Accuracy 0.9228742865505635 precision 0.9230439887201013 specificity 0.7982177450913428 recall 0.9228742865505635 f1 0.9197683533392323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 6.562240839004517 s\n",
      "Accuracy 0.9293136250548807 precision 0.9284785244755639 specificity 0.800751762869027 recall 0.9293136250548807 f1 0.9267433094028422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 6.693001985549927 s\n",
      "Accuracy 0.9256549099956095 precision 0.9262563090902844 specificity 0.794532123993079 recall 0.9256549099956095 f1 0.9224037083346001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 6.66107439994812 s\n",
      "Accuracy 0.9266793502122055 precision 0.9262481031719433 specificity 0.7944985838884568 recall 0.9266793502122055 f1 0.9237448272786268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 6.631065130233765 s\n",
      "Accuracy 0.9219961949363383 precision 0.9216692480036198 specificity 0.7826562044435817 recall 0.9219961949363383 f1 0.9185993889044046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 6.654001235961914 s\n",
      "Accuracy 0.9230206351529343 precision 0.9219973105356003 specificity 0.7894562092525631 recall 0.9230206351529343 f1 0.9200867012228419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 6.4810004234313965 s\n",
      "Accuracy 0.924191423971901 precision 0.9235983542066557 specificity 0.7940621840883694 recall 0.924191423971901 f1 0.9212424919506297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 6.506999254226685 s\n",
      "Accuracy 0.9238987267671593 precision 0.9234515614167488 specificity 0.7917730363901166 recall 0.9238987267671593 f1 0.9208328087181014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 6.639611721038818 s\n",
      "Accuracy 0.9208254061173716 precision 0.9205870206188572 specificity 0.7875407190613982 recall 0.9208254061173716 f1 0.9175055675168269\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 6.609200716018677 s\n",
      "Accuracy 0.9217034977315967 precision 0.9218322034399724 specificity 0.7883351015813228 recall 0.9217034977315967 f1 0.918317952929031\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 6.694509267807007 s\n",
      "Accuracy 0.9200936631055173 precision 0.9196650410682615 specificity 0.784205780933341 recall 0.9200936631055173 f1 0.9167243591973996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 6.6659996509552 s\n",
      "Accuracy 0.9256549099956095 precision 0.9250444826219946 specificity 0.8010147816783478 recall 0.9256549099956095 f1 0.9229242727679021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 6.835999488830566 s\n",
      "Accuracy 0.9250695155861262 precision 0.9250231770756923 specificity 0.8011548572487356 recall 0.9250695155861262 f1 0.9221472831667575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 6.577242851257324 s\n",
      "Accuracy 0.9212644519244841 precision 0.9202720928802303 specificity 0.7794977272360022 recall 0.9212644519244841 f1 0.9179966316249036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 6.517163276672363 s\n",
      "Accuracy 0.918483828479438 precision 0.9179407959982522 specificity 0.7859886784928068 recall 0.918483828479438 f1 0.915165359792792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 6.584997653961182 s\n",
      "Accuracy 0.9234596809600468 precision 0.9233229145566298 specificity 0.7936507784813955 recall 0.9234596809600468 f1 0.9203346895438854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 6.592827081680298 s\n",
      "Accuracy 0.9202400117078882 precision 0.920213724418726 specificity 0.7855762370183377 recall 0.9202400117078882 f1 0.9167876861689428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 6.515002012252808 s\n",
      "Accuracy 0.923313332357676 precision 0.922674815021211 specificity 0.7921674413049952 recall 0.923313332357676 f1 0.9203102220875102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 6.73762059211731 s\n",
      "Accuracy 0.9250695155861262 precision 0.9252901197944512 specificity 0.7883150165348106 recall 0.9250695155861262 f1 0.9217424454559904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 6.497600555419922 s\n",
      "Accuracy 0.9284355334406557 precision 0.9281655910606449 specificity 0.8040543094234377 recall 0.9284355334406557 f1 0.9257248106350358\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 6.532998561859131 s\n",
      "Accuracy 0.9217034977315967 precision 0.9216536681940253 specificity 0.7914460832068455 recall 0.9217034977315967 f1 0.9184536391428749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 6.806999683380127 s\n",
      "Accuracy 0.9190692228889215 precision 0.9180294818233351 specificity 0.7938085953292997 recall 0.9190692228889215 f1 0.9161770918020353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 6.718885183334351 s\n",
      "Accuracy 0.9279964876335431 precision 0.9278680500808381 specificity 0.8068934212955317 recall 0.9279964876335431 f1 0.9253017098013437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 6.634999990463257 s\n",
      "Accuracy 0.9219961949363383 precision 0.9213059798415372 specificity 0.7882977102549872 recall 0.9219961949363383 f1 0.9188762716937212\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 6.441164970397949 s\n",
      "Accuracy 0.9221425435387092 precision 0.9222287636812967 specificity 0.7886056874474733 recall 0.9221425435387092 f1 0.9187869246086146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 6.547998905181885 s\n",
      "Accuracy 0.921410800526855 precision 0.9206080836760976 specificity 0.7966485646663859 recall 0.921410800526855 f1 0.9185487862849867\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 6.55500054359436 s\n",
      "Accuracy 0.9224352407434508 precision 0.9216634000677908 specificity 0.7985061700219162 recall 0.9224352407434508 f1 0.9196325791924678\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 6.561392307281494 s\n",
      "Accuracy 0.9266793502122055 precision 0.9263067147591356 specificity 0.8053022396002437 recall 0.9266793502122055 f1 0.92399566564708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 6.627214431762695 s\n",
      "Accuracy 0.9303380652714767 precision 0.9299534903308194 specificity 0.8089172687635299 recall 0.9303380652714767 f1 0.9278204087882315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 6.680503845214844 s\n",
      "Accuracy 0.9190692228889215 precision 0.9184820757590166 specificity 0.7883154488943305 recall 0.9190692228889215 f1 0.9158455892146309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 6.697999954223633 s\n",
      "Accuracy 0.9303380652714767 precision 0.9297131062760671 specificity 0.8117921470253487 recall 0.9303380652714767 f1 0.9279725609925568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 6.686952114105225 s\n",
      "Accuracy 0.9198009659007756 precision 0.9194215758523453 specificity 0.7889287771137787 recall 0.9198009659007756 f1 0.9165408888325094\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 6.588992595672607 s\n",
      "Accuracy 0.9218498463339675 precision 0.9217139630248695 specificity 0.7883279905753496 recall 0.9218498463339675 f1 0.9185445832344825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 6.6342949867248535 s\n",
      "Accuracy 0.9208254061173716 precision 0.9209348140124797 specificity 0.7854233561620645 recall 0.9208254061173716 f1 0.917344116399475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 6.699509859085083 s\n",
      "Accuracy 0.9265330016098346 precision 0.9264868456245391 specificity 0.8060344094737055 recall 0.9265330016098346 f1 0.923763267640142\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 6.565999269485474 s\n",
      "Accuracy 0.9236060295624177 precision 0.9234331703475567 specificity 0.8029247798092694 recall 0.9236060295624177 f1 0.9207377332144415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 6.727001428604126 s\n",
      "Accuracy 0.9247768183813845 precision 0.9242439234603881 specificity 0.8010581801570685 recall 0.9247768183813845 f1 0.9220014179017453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 6.5979979038238525 s\n",
      "Accuracy 0.9238987267671593 precision 0.9238866826145594 specificity 0.7881922970393456 recall 0.9238987267671593 f1 0.9206037199754435\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 6.718063831329346 s\n",
      "Accuracy 0.9231669837553051 precision 0.9232209674895457 specificity 0.7966124200536813 recall 0.9231669837553051 f1 0.9200574937181067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 6.557000398635864 s\n",
      "Accuracy 0.9151178106249085 precision 0.9154919281483959 specificity 0.7818597317895271 recall 0.9151178106249085 f1 0.9113239618796894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 6.502000093460083 s\n",
      "Accuracy 0.92228889214108 precision 0.9216850415115461 specificity 0.7857895581701455 recall 0.92228889214108 f1 0.9190770181690798\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 6.629927158355713 s\n",
      "Accuracy 0.9225815893458218 precision 0.9219085043642156 specificity 0.7876937330994942 recall 0.9225815893458218 f1 0.9194531929662473\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 7.248149871826172 s\n",
      "Accuracy 0.9306307624762183 precision 0.9308522034744879 specificity 0.7979199709924802 recall 0.9306307624762183 f1 0.9276833806337413\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 7.37303900718689 s\n",
      "Accuracy 0.9212644519244841 precision 0.9205482067523134 specificity 0.7948715384774963 recall 0.9212644519244841 f1 0.9183177233193556\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 6.796510696411133 s\n",
      "Accuracy 0.9279964876335431 precision 0.9273461831168289 specificity 0.8117941970295521 recall 0.9279964876335431 f1 0.9255959426738173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 6.595000982284546 s\n",
      "Accuracy 0.9288745792477682 precision 0.9284924310532003 specificity 0.8045698683588601 recall 0.9288745792477682 f1 0.9262219451200742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 6.734678745269775 s\n",
      "Accuracy 0.9250695155861262 precision 0.9253292541633141 specificity 0.7998886372577839 recall 0.9250695155861262 f1 0.9220292815512713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 6.680999517440796 s\n",
      "Accuracy 0.9265330016098346 precision 0.9263714793429504 specificity 0.7961430328465557 recall 0.9265330016098346 f1 0.9235509445360783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 6.751001596450806 s\n",
      "Accuracy 0.9236060295624177 precision 0.9234950702405887 specificity 0.7933731772068111 recall 0.9236060295624177 f1 0.9204693462180765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 6.708999872207642 s\n",
      "Accuracy 0.9211181033221133 precision 0.9202366678230912 specificity 0.7871985500614322 recall 0.9211181033221133 f1 0.9180187885891453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 6.734085321426392 s\n",
      "Accuracy 0.9202400117078882 precision 0.920607140134415 specificity 0.7795740319888611 recall 0.9202400117078882 f1 0.9165101067527043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 6.495997667312622 s\n",
      "Accuracy 0.9247768183813845 precision 0.9242960167580735 specificity 0.7978600928064501 recall 0.9247768183813845 f1 0.9219009310037626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 6.607739210128784 s\n",
      "Accuracy 0.9228742865505635 precision 0.9227281643434327 specificity 0.7883370962969533 recall 0.9228742865505635 f1 0.9195972485433196\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 6.6359992027282715 s\n",
      "Accuracy 0.9263866530074638 precision 0.9260364390204687 specificity 0.7991363394092489 recall 0.9263866530074638 f1 0.9235354165565004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 6.642998933792114 s\n",
      "Accuracy 0.9253622127908678 precision 0.9252308797356453 specificity 0.8006787112990285 recall 0.9253622127908678 f1 0.92245929880233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 6.624999046325684 s\n",
      "Accuracy 0.924337772574272 precision 0.9237951788435329 specificity 0.7969677233077522 recall 0.924337772574272 f1 0.9214504042850465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 6.56128454208374 s\n",
      "Accuracy 0.9198009659007756 precision 0.9196053590302609 specificity 0.7784210256462826 recall 0.9198009659007756 f1 0.9161874981481765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 6.804884195327759 s\n",
      "Accuracy 0.9218498463339675 precision 0.9213795513344799 specificity 0.7917550975233759 recall 0.9218498463339675 f1 0.9187438625014649\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 6.760320425033569 s\n",
      "Accuracy 0.9206790575150008 precision 0.9212050226775027 specificity 0.7864683240308408 recall 0.9206790575150008 f1 0.9171108676589715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 6.597001552581787 s\n",
      "Accuracy 0.9265330016098346 precision 0.925828549278588 specificity 0.8052841555453346 recall 0.9265330016098346 f1 0.9239635546298652\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 6.6349992752075195 s\n",
      "Accuracy 0.92228889214108 precision 0.9221061700533515 specificity 0.7882791867422037 recall 0.92228889214108 f1 0.9190071204257882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 6.659420728683472 s\n",
      "Accuracy 0.9228742865505635 precision 0.9221602661575146 specificity 0.7977013784564023 recall 0.9228742865505635 f1 0.9200369992656282\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 6.6183857917785645 s\n",
      "Accuracy 0.9303380652714767 precision 0.9302346965519829 specificity 0.8017084702653713 recall 0.9303380652714767 f1 0.9275635851321468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 6.597999572753906 s\n",
      "Accuracy 0.9250695155861262 precision 0.9243023971214689 specificity 0.7914043530693184 recall 0.9250695155861262 f1 0.922135246003718\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 6.604222059249878 s\n",
      "Accuracy 0.9219961949363383 precision 0.9206459665428902 specificity 0.7949777059030452 recall 0.9219961949363383 f1 0.9193468174942472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 6.572509288787842 s\n",
      "Accuracy 0.9272647446216888 precision 0.9267076296850674 specificity 0.8064155875332943 recall 0.9272647446216888 f1 0.9246836572886105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 6.798186779022217 s\n",
      "Accuracy 0.9268256988145763 precision 0.9266317168129781 specificity 0.7937364914388119 recall 0.9268256988145763 f1 0.9238002000530591\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 6.613996267318726 s\n",
      "Accuracy 0.9227279379481926 precision 0.9219881094612099 specificity 0.8010047145786469 recall 0.9227279379481926 f1 0.9199858778880134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 6.719205141067505 s\n",
      "Accuracy 0.9198009659007756 precision 0.9193949298124791 specificity 0.7839161226152979 recall 0.9198009659007756 f1 0.916408957534066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 6.533998727798462 s\n",
      "Accuracy 0.9282891848382848 precision 0.9281876573033411 specificity 0.8053164339478528 recall 0.9282891848382848 f1 0.9255542997201264\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 6.461127519607544 s\n",
      "Accuracy 0.9240450753695302 precision 0.9235985779297753 specificity 0.7982492512432591 recall 0.9240450753695302 f1 0.9211519071747442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 6.529999017715454 s\n",
      "Accuracy 0.9208254061173716 precision 0.9199871940910379 specificity 0.7929824231665321 recall 0.9208254061173716 f1 0.9178637155274877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 6.5269999504089355 s\n",
      "Accuracy 0.926240304405093 precision 0.9263234481158711 specificity 0.8042795132905173 recall 0.926240304405093 f1 0.9233839603329845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 6.702603340148926 s\n",
      "Accuracy 0.9230206351529343 precision 0.9222267859306783 specificity 0.780280843663783 recall 0.9230206351529343 f1 0.9197461747222322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 6.668123245239258 s\n",
      "Accuracy 0.9238987267671593 precision 0.9232072232234141 specificity 0.8026071153137225 recall 0.9238987267671593 f1 0.9212035303342889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 6.619000673294067 s\n",
      "Accuracy 0.924191423971901 precision 0.9248865301023608 specificity 0.7906162229816547 recall 0.924191423971901 f1 0.9207798501359354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 6.5759992599487305 s\n",
      "Accuracy 0.9218498463339675 precision 0.9213832551151857 specificity 0.7919172188370754 recall 0.9218498463339675 f1 0.9187470137680304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 6.6167120933532715 s\n",
      "Accuracy 0.9225815893458218 precision 0.9221653778667337 specificity 0.795318669743148 recall 0.9225815893458218 f1 0.9195695927482747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 6.721117973327637 s\n",
      "Accuracy 0.9293136250548807 precision 0.9288853632177152 specificity 0.8000883616989417 recall 0.9293136250548807 f1 0.9265784245412576\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 6.680938720703125 s\n",
      "Accuracy 0.9249231669837553 precision 0.9242950448466655 specificity 0.8043509109829942 recall 0.9249231669837553 f1 0.9222695968467393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 6.577550649642944 s\n",
      "Accuracy 0.925215864188497 precision 0.9249232823816509 specificity 0.8026595166966043 recall 0.925215864188497 f1 0.9224101925353624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 6.572000026702881 s\n",
      "Accuracy 0.9288745792477682 precision 0.9284459269651939 specificity 0.8062426120254174 recall 0.9288745792477682 f1 0.9262776624473283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 6.666000127792358 s\n",
      "Accuracy 0.9215571491292258 precision 0.9217969135902206 specificity 0.7855767983582174 recall 0.9215571491292258 f1 0.9180620996014675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 6.636600494384766 s\n",
      "Accuracy 0.92228889214108 precision 0.9219599333215492 specificity 0.7859759927481418 recall 0.92228889214108 f1 0.9189904963269842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 6.654999732971191 s\n",
      "Accuracy 0.9291672764525098 precision 0.9290713504631979 specificity 0.8032026171297801 recall 0.9291672764525098 f1 0.9263990723845321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 6.66375207901001 s\n",
      "Accuracy 0.9237523781647885 precision 0.9235979259598233 specificity 0.7963121611750846 recall 0.9237523781647885 f1 0.9207091304050103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 6.514997720718384 s\n",
      "Accuracy 0.9206790575150008 precision 0.9205829536092016 specificity 0.7867639768333289 recall 0.9206790575150008 f1 0.9172909255514766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 6.580999374389648 s\n",
      "Accuracy 0.9240450753695302 precision 0.9239752087175513 specificity 0.7951766637422428 recall 0.9240450753695302 f1 0.920953407769768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 6.51099967956543 s\n",
      "Accuracy 0.9244841211766428 precision 0.9241969033416291 specificity 0.8016378250921046 recall 0.9244841211766428 f1 0.9216357256659418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 6.670510292053223 s\n",
      "Accuracy 0.9209717547197425 precision 0.9203945752487436 specificity 0.7945283731373654 recall 0.9209717547197425 f1 0.9179591276765132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 6.7339982986450195 s\n",
      "Accuracy 0.9238987267671593 precision 0.9230842302577089 specificity 0.798708467096425 recall 0.9238987267671593 f1 0.9211482797071862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 6.646504878997803 s\n",
      "Accuracy 0.927118396019318 precision 0.9261928529300854 specificity 0.800215281070082 recall 0.927118396019318 f1 0.9245220472177959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 6.485999584197998 s\n",
      "Accuracy 0.9238987267671593 precision 0.9227691098786521 specificity 0.7997410917223879 recall 0.9238987267671593 f1 0.9213119253819569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 6.665997505187988 s\n",
      "Accuracy 0.924191423971901 precision 0.9236485562755742 specificity 0.800036321255211 recall 0.924191423971901 f1 0.9213809667574303\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 6.62910795211792 s\n",
      "Accuracy 0.9268256988145763 precision 0.9263988096385624 specificity 0.8033400450988896 recall 0.9268256988145763 f1 0.9241142926780851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 6.564000844955444 s\n",
      "Accuracy 0.9189228742865506 precision 0.9186122826360088 specificity 0.7880605828409988 recall 0.9189228742865506 f1 0.9155964542193177\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 6.529999017715454 s\n",
      "Accuracy 0.928142836235914 precision 0.9270966402876619 specificity 0.8113255332542672 recall 0.928142836235914 f1 0.9259040781637056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 6.600653648376465 s\n",
      "Accuracy 0.9211181033221133 precision 0.9203469177881031 specificity 0.7902413530756541 recall 0.9211181033221133 f1 0.91806111022151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 6.6074745655059814 s\n",
      "Accuracy 0.9259476072003512 precision 0.9254569406804982 specificity 0.7984992426401337 recall 0.9259476072003512 f1 0.923117241373969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 6.665998220443726 s\n",
      "Accuracy 0.9215571491292258 precision 0.9205942702914254 specificity 0.7965149631843899 recall 0.9215571491292258 f1 0.9187592396972213\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 6.573000431060791 s\n",
      "Accuracy 0.9237523781647885 precision 0.9232306304756001 specificity 0.7936052900916007 recall 0.9237523781647885 f1 0.9207565471771236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 6.6638288497924805 s\n",
      "Accuracy 0.9181911312746963 precision 0.9183729803597666 specificity 0.7801461013851169 recall 0.9181911312746963 f1 0.9144745290272241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 6.672999620437622 s\n",
      "Accuracy 0.9227279379481926 precision 0.9225749041651526 specificity 0.7937365211361236 recall 0.9227279379481926 f1 0.9195935702242589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 6.673001289367676 s\n",
      "Accuracy 0.9268256988145763 precision 0.9266994545780382 specificity 0.7924908062734451 recall 0.9268256988145763 f1 0.9237485272573779\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 6.673097848892212 s\n",
      "Accuracy 0.9237523781647885 precision 0.9236427165632823 specificity 0.7919564975209116 recall 0.9237523781647885 f1 0.920581500817487\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 6.562081813812256 s\n",
      "Accuracy 0.9244841211766428 precision 0.9236641755997186 specificity 0.7921090742151405 recall 0.9244841211766428 f1 0.9215744269449729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 6.6005189418792725 s\n",
      "Accuracy 0.9224352407434508 precision 0.9222703956365069 specificity 0.7897531199340673 recall 0.9224352407434508 f1 0.9191912025308175\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 6.6279990673065186 s\n",
      "Accuracy 0.9258012585979803 precision 0.9257085001237509 specificity 0.8003140915640604 recall 0.9258012585979803 f1 0.9228870002748846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 6.5680015087127686 s\n",
      "Accuracy 0.9269720474169472 precision 0.9263566070537612 specificity 0.8060243504852258 recall 0.9269720474169472 f1 0.9243965375660024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 6.702462434768677 s\n",
      "Accuracy 0.918483828479438 precision 0.9187496170751311 specificity 0.7828501065407338 recall 0.918483828479438 f1 0.9148289207771662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 6.720071315765381 s\n",
      "Accuracy 0.9219961949363383 precision 0.9216510605422851 specificity 0.7880723307683213 recall 0.9219961949363383 f1 0.9187526023240875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 6.480490684509277 s\n",
      "Accuracy 0.9258012585979803 precision 0.9248788992809733 specificity 0.7905142709839488 recall 0.9258012585979803 f1 0.9229224575188057\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 6.728000640869141 s\n",
      "Accuracy 0.9189228742865506 precision 0.9188962517451804 specificity 0.7836840789928278 recall 0.9189228742865506 f1 0.9153854614172037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 6.747997522354126 s\n",
      "Accuracy 0.9250695155861262 precision 0.9244210378560006 specificity 0.7987144367890145 recall 0.9250695155861262 f1 0.9222811494750661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 7.298295974731445 s\n",
      "Accuracy 0.9250695155861262 precision 0.9249262566911733 specificity 0.7877457411617745 recall 0.9250695155861262 f1 0.92183155112239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 6.862524747848511 s\n",
      "Accuracy 0.9187765256841797 precision 0.9185801262780862 specificity 0.7780036117884043 recall 0.9187765256841797 f1 0.9151242350370602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 6.601541757583618 s\n",
      "Accuracy 0.9227279379481926 precision 0.9224878070564254 specificity 0.7939568159664045 recall 0.9227279379481926 f1 0.9196262309082658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 6.383557319641113 s\n",
      "Accuracy 0.9227279379481926 precision 0.922492943334825 specificity 0.7769193620898037 recall 0.9227279379481926 f1 0.9191662797418795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 6.714534759521484 s\n",
      "Accuracy 0.9253622127908678 precision 0.9255913890773099 specificity 0.7975980270913848 recall 0.9253622127908678 f1 0.9222782852025255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 6.628539800643921 s\n",
      "Accuracy 0.9297526708619933 precision 0.9294608433313777 specificity 0.8048021497198717 recall 0.9297526708619933 f1 0.9270955140273986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 6.747532367706299 s\n",
      "Accuracy 0.9199473145031465 precision 0.9196700541148342 specificity 0.7900082568072635 recall 0.9199473145031465 f1 0.9166878517350949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 6.671537637710571 s\n",
      "Accuracy 0.9272647446216888 precision 0.9265058939403807 specificity 0.805449481775589 recall 0.9272647446216888 f1 0.9247353458762396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 6.862524509429932 s\n",
      "Accuracy 0.9304844138738475 precision 0.92969493238803 specificity 0.8124921140429306 recall 0.9304844138738475 f1 0.9282032744485208\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 7.156503200531006 s\n",
      "Accuracy 0.9246304697790136 precision 0.9245409707676405 specificity 0.7926743551884057 recall 0.9246304697790136 f1 0.9214932191267021\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 6.951518774032593 s\n",
      "Accuracy 0.9250695155861262 precision 0.9258943334960255 specificity 0.7881739545517586 recall 0.9250695155861262 f1 0.9215857051621233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 7.405487537384033 s\n",
      "Accuracy 0.9238987267671593 precision 0.9239844274824754 specificity 0.7904130580218975 recall 0.9238987267671593 f1 0.9206341358016278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 6.6585400104522705 s\n",
      "Accuracy 0.9219961949363383 precision 0.9221071486678576 specificity 0.7867007777126368 recall 0.9219961949363383 f1 0.91857847258926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 6.724530458450317 s\n",
      "Accuracy 0.9269720474169472 precision 0.9269491104015193 specificity 0.800538983129495 recall 0.9269720474169472 f1 0.9240686389033662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 6.8485260009765625 s\n",
      "Accuracy 0.9221425435387092 precision 0.9219560931161511 specificity 0.7895572727229693 recall 0.9221425435387092 f1 0.9188928789859439\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 7.183501482009888 s\n",
      "Accuracy 0.92228889214108 precision 0.9219762897739548 specificity 0.7887679036699548 recall 0.92228889214108 f1 0.9190607634543831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 7.012514114379883 s\n",
      "Accuracy 0.9247768183813845 precision 0.9245481032091124 specificity 0.7976010185156126 recall 0.9247768183813845 f1 0.9218123517505861\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 7.088510036468506 s\n",
      "Accuracy 0.9206790575150008 precision 0.9210043748426471 specificity 0.7824631783957502 recall 0.9206790575150008 f1 0.9170525920508151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 7.128505229949951 s\n",
      "Accuracy 0.9234596809600468 precision 0.9229810346397153 specificity 0.7884582896871768 recall 0.9234596809600468 f1 0.9203059231347225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 7.1225059032440186 s\n",
      "Accuracy 0.9217034977315967 precision 0.9211185143843759 specificity 0.7861301419667014 recall 0.9217034977315967 f1 0.918479843386561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 6.831526517868042 s\n",
      "Accuracy 0.9259476072003512 precision 0.9261432125281271 specificity 0.7917537351828761 recall 0.9259476072003512 f1 0.9227380293050922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 7.074509382247925 s\n",
      "Accuracy 0.927118396019318 precision 0.9265351638266344 specificity 0.8063715687265657 recall 0.927118396019318 f1 0.9245426923778328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 6.30156135559082 s\n",
      "Accuracy 0.924337772574272 precision 0.9241074139795405 specificity 0.7955219007206515 recall 0.924337772574272 f1 0.9213102869336905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 6.260570287704468 s\n",
      "Accuracy 0.9202400117078882 precision 0.9203757868577217 specificity 0.7836943524247447 recall 0.9202400117078882 f1 0.9166887166513022\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 6.341557264328003 s\n",
      "Accuracy 0.924191423971901 precision 0.9242033636945769 specificity 0.7952686925152149 recall 0.924191423971901 f1 0.9210816079206501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 6.099578619003296 s\n",
      "Accuracy 0.9238987267671593 precision 0.9237707647300799 specificity 0.7981986745912403 recall 0.9238987267671593 f1 0.9208998462291768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 6.2625651359558105 s\n",
      "Accuracy 0.9221425435387092 precision 0.9214753923412021 specificity 0.8020028742230761 recall 0.9221425435387092 f1 0.9193886078558923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 6.169571876525879 s\n",
      "Accuracy 0.9193619200936631 precision 0.9190774423495017 specificity 0.7871506690703518 recall 0.9193619200936631 f1 0.9160114825397543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 6.064579486846924 s\n",
      "Accuracy 0.9253622127908678 precision 0.9244128820333657 specificity 0.7977763266010106 recall 0.9253622127908678 f1 0.9226738828455624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 6.440554141998291 s\n",
      "Accuracy 0.9258012585979803 precision 0.9260965472568282 specificity 0.795827889253193 recall 0.9258012585979803 f1 0.9226647829839887\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 6.467209339141846 s\n",
      "Accuracy 0.925215864188497 precision 0.9250682071859453 specificity 0.7971006410624286 recall 0.925215864188497 f1 0.922223513777787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 6.420231342315674 s\n",
      "Accuracy 0.9237523781647885 precision 0.9242765292803246 specificity 0.7931085952848268 recall 0.9237523781647885 f1 0.9204379337003912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 6.1985695362091064 s\n",
      "Accuracy 0.9244841211766428 precision 0.9241417259725107 specificity 0.7951193382205303 recall 0.9244841211766428 f1 0.921484938418362\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 6.579543828964233 s\n",
      "Accuracy 0.9255085613932387 precision 0.9248540129673186 specificity 0.790895574591752 recall 0.9255085613932387 f1 0.9225304506377184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 6.424269914627075 s\n",
      "Accuracy 0.9215571491292258 precision 0.9216055438237145 specificity 0.7885535890540694 recall 0.9215571491292258 f1 0.9181968208359675\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 6.705976247787476 s\n",
      "Accuracy 0.9218498463339675 precision 0.9218560340239468 specificity 0.7812767180001575 recall 0.9218498463339675 f1 0.9183105994968046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 6.671558856964111 s\n",
      "Accuracy 0.9238987267671593 precision 0.9237272429182294 specificity 0.7898049911649244 recall 0.9238987267671593 f1 0.9206934488067807\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 6.589541673660278 s\n",
      "Accuracy 0.9255085613932387 precision 0.9252358045564449 specificity 0.7925657713580708 recall 0.9255085613932387 f1 0.9224455152926526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 6.611541986465454 s\n",
      "Accuracy 0.921410800526855 precision 0.9210446562304008 specificity 0.7963269604864349 recall 0.921410800526855 f1 0.9183847540641068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 6.618173360824585 s\n",
      "Accuracy 0.9279964876335431 precision 0.927725696336414 specificity 0.7977008769143692 recall 0.9279964876335431 f1 0.9251213473169203\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 6.614147901535034 s\n",
      "Accuracy 0.9199473145031465 precision 0.9187375142679708 specificity 0.782059195562065 recall 0.9199473145031465 f1 0.9168097498246511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 6.507547378540039 s\n",
      "Accuracy 0.9238987267671593 precision 0.9236805900483909 specificity 0.7940765244172112 recall 0.9238987267671593 f1 0.9208197973924742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 6.542546272277832 s\n",
      "Accuracy 0.9250695155861262 precision 0.9245287192498501 specificity 0.8054693218303177 recall 0.9250695155861262 f1 0.9224159059531581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 6.519899845123291 s\n",
      "Accuracy 0.919508268696034 precision 0.9189633536433084 specificity 0.7918287786840689 recall 0.919508268696034 f1 0.9163786359408055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 6.635740280151367 s\n",
      "Accuracy 0.925215864188497 precision 0.9244370648265051 specificity 0.8083545564735266 recall 0.925215864188497 f1 0.9227286252058792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 6.6869707107543945 s\n",
      "Accuracy 0.9256549099956095 precision 0.9256002378104748 specificity 0.7992474833279721 recall 0.9256549099956095 f1 0.9226992580462366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 6.609541177749634 s\n",
      "Accuracy 0.9234596809600468 precision 0.9232432310827863 specificity 0.7921430108873653 recall 0.9234596809600468 f1 0.9203192481420817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 6.62807559967041 s\n",
      "Accuracy 0.9234596809600468 precision 0.9230372037174593 specificity 0.800620211240236 recall 0.9234596809600468 f1 0.9206083324810843\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 6.568516492843628 s\n",
      "Accuracy 0.9265330016098346 precision 0.9259622111240579 specificity 0.8081660114101007 recall 0.9265330016098346 f1 0.9239860701811667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 6.525566577911377 s\n",
      "Accuracy 0.9192155714912923 precision 0.919286730715398 specificity 0.7826780343594734 recall 0.9192155714912923 f1 0.9156284363367635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 6.507552146911621 s\n",
      "Accuracy 0.9274110932240597 precision 0.9273190954411187 specificity 0.8058899851162958 recall 0.9274110932240597 f1 0.9246690540245792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 6.837524652481079 s\n",
      "Accuracy 0.917605736865213 precision 0.917723379838062 specificity 0.7834863006404588 recall 0.917605736865213 f1 0.9139892983689274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 6.640539884567261 s\n",
      "Accuracy 0.9263866530074638 precision 0.9267537858149334 specificity 0.8072735336773397 recall 0.9263866530074638 f1 0.9235312848605516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 6.687536716461182 s\n",
      "Accuracy 0.9208254061173716 precision 0.9204761015078414 specificity 0.7907361060616838 recall 0.9208254061173716 f1 0.9176286975052882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 6.595656871795654 s\n",
      "Accuracy 0.9217034977315967 precision 0.9217472848892648 specificity 0.7955699878798055 recall 0.9217034977315967 f1 0.918537718507167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 6.810528755187988 s\n",
      "Accuracy 0.9221425435387092 precision 0.9222136231345744 specificity 0.7901827629325224 recall 0.9221425435387092 f1 0.9188337424193747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 6.618422746658325 s\n",
      "Accuracy 0.92228889214108 precision 0.9225083235462448 specificity 0.7860214699666854 recall 0.92228889214108 f1 0.9188299978235411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 6.674536466598511 s\n",
      "Accuracy 0.9224352407434508 precision 0.9218322102502624 specificity 0.7902075113813036 recall 0.9224352407434508 f1 0.9193464723794077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 6.607660293579102 s\n",
      "Accuracy 0.924337772574272 precision 0.9246661668466177 specificity 0.7895651327893658 recall 0.924337772574272 f1 0.9209955221796797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 6.524476766586304 s\n",
      "Accuracy 0.9234596809600468 precision 0.9232283160336077 specificity 0.7935534411366161 recall 0.9234596809600468 f1 0.9203610709949104\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 6.679539680480957 s\n",
      "Accuracy 0.9205327089126298 precision 0.920617578049167 specificity 0.7782806274087489 recall 0.9205327089126298 f1 0.9168523351975164\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 6.628537654876709 s\n",
      "Accuracy 0.923313332357676 precision 0.9223453361713744 specificity 0.7961485466654427 recall 0.923313332357676 f1 0.9205446214633557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 6.562575578689575 s\n",
      "Accuracy 0.9192155714912923 precision 0.9189050017547917 specificity 0.7893197355342675 recall 0.9192155714912923 f1 0.9159312028710442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 6.661015510559082 s\n",
      "Accuracy 0.924337772574272 precision 0.9240777025712106 specificity 0.7877557560799457 recall 0.924337772574272 f1 0.9211169282189903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 6.735532999038696 s\n",
      "Accuracy 0.9231669837553051 precision 0.9229473827167851 specificity 0.7927542399646785 recall 0.9231669837553051 f1 0.9200369000721664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 6.66153883934021 s\n",
      "Accuracy 0.9258012585979803 precision 0.9256320407853648 specificity 0.7966819758165916 recall 0.9258012585979803 f1 0.922818095635176\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 6.592543363571167 s\n",
      "Accuracy 0.9217034977315967 precision 0.9213814751195819 specificity 0.7836709668690585 recall 0.9217034977315967 f1 0.9183252887753889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 6.5822765827178955 s\n",
      "Accuracy 0.9249231669837553 precision 0.9251627013497943 specificity 0.7909407636708846 recall 0.9249231669837553 f1 0.9216551426423218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 6.729278564453125 s\n",
      "Accuracy 0.9294599736572515 precision 0.9295314350069385 specificity 0.8086407707047829 recall 0.9294599736572515 f1 0.9267791113592481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 6.571819067001343 s\n",
      "Accuracy 0.9202400117078882 precision 0.9198602989491954 specificity 0.7945335347869251 recall 0.9202400117078882 f1 0.9171452453364025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 6.651539325714111 s\n",
      "Accuracy 0.9263866530074638 precision 0.9259854969380633 specificity 0.7946484824297548 recall 0.9263866530074638 f1 0.923438947442728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 6.6595375537872314 s\n",
      "Accuracy 0.9199473145031465 precision 0.9198587354748122 specificity 0.785818271875037 recall 0.9199473145031465 f1 0.916513104465547\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 6.7816526889801025 s\n",
      "Accuracy 0.9225815893458218 precision 0.9224651540462874 specificity 0.7946971511249387 recall 0.9225815893458218 f1 0.9194584960017326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 6.56854510307312 s\n",
      "Accuracy 0.9199473145031465 precision 0.9193296564148009 specificity 0.7905162120077104 recall 0.9199473145031465 f1 0.9168158429639879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 6.52754807472229 s\n",
      "Accuracy 0.9219961949363383 precision 0.92157934160415 specificity 0.7908745890542116 recall 0.9219961949363383 f1 0.918851877831136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 6.6058666706085205 s\n",
      "Accuracy 0.9196546172984048 precision 0.9200006604266957 specificity 0.7828879199379912 recall 0.9196546172984048 f1 0.916008198887278\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 6.608401536941528 s\n",
      "Accuracy 0.918483828479438 precision 0.9181463415180509 specificity 0.7811207243583224 recall 0.918483828479438 f1 0.9149576973564438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 6.710534572601318 s\n",
      "Accuracy 0.9230206351529343 precision 0.922474421280915 specificity 0.7969458224415038 recall 0.9230206351529343 f1 0.9201055802947985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 6.648541450500488 s\n",
      "Accuracy 0.9180447826723255 precision 0.917434696881917 specificity 0.7850924564601577 recall 0.9180447826723255 f1 0.9147137136481235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 6.764043092727661 s\n",
      "Accuracy 0.9205327089126298 precision 0.9200682027589245 specificity 0.7921453551847517 recall 0.9205327089126298 f1 0.9174063620987937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 6.70553731918335 s\n",
      "Accuracy 0.923313332357676 precision 0.9235049885016932 specificity 0.7991837589489851 recall 0.923313332357676 f1 0.9202359555906363\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 6.584605693817139 s\n",
      "Accuracy 0.9230206351529343 precision 0.9224598633135976 specificity 0.7868590153389051 recall 0.9230206351529343 f1 0.9198410800461068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 6.5195472240448 s\n",
      "Accuracy 0.9158495536367628 precision 0.9152441533856313 specificity 0.7819557163620556 recall 0.9158495536367628 f1 0.9123743208956405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 6.618540525436401 s\n",
      "Accuracy 0.9228742865505635 precision 0.9229933461030234 specificity 0.7891368656918233 recall 0.9228742865505635 f1 0.9195414641893737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 6.617541313171387 s\n",
      "Accuracy 0.9244841211766428 precision 0.9241320560577183 specificity 0.7863211770596432 recall 0.9244841211766428 f1 0.9212584733568575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 6.521389484405518 s\n",
      "Accuracy 0.9237523781647885 precision 0.9231052335413249 specificity 0.8006472713493487 recall 0.9237523781647885 f1 0.9209863442464831\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 6.61087441444397 s\n",
      "Accuracy 0.9234596809600468 precision 0.9230148589408329 specificity 0.7958517866726784 recall 0.9234596809600468 f1 0.9204904523559059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 6.622541427612305 s\n",
      "Accuracy 0.9209717547197425 precision 0.9217151809860992 specificity 0.787697145355679 recall 0.9209717547197425 f1 0.9173901645764692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 6.5335469245910645 s\n",
      "Accuracy 0.919508268696034 precision 0.9196923148704824 specificity 0.7844445313662762 recall 0.919508268696034 f1 0.9159463306503483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 6.603541135787964 s\n",
      "Accuracy 0.927118396019318 precision 0.9266581842781172 specificity 0.8086416507404479 recall 0.927118396019318 f1 0.9245554043735528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 6.542260646820068 s\n",
      "Accuracy 0.9231669837553051 precision 0.9232473255287541 specificity 0.7933884699499273 recall 0.9231669837553051 f1 0.9199649373421621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 6.691904783248901 s\n",
      "Accuracy 0.9227279379481926 precision 0.9226340886160376 specificity 0.790006734325388 recall 0.9227279379481926 f1 0.9194763144164371\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 6.497549295425415 s\n",
      "Accuracy 0.930045368066735 precision 0.9296276693352431 specificity 0.8059255546795209 recall 0.930045368066735 f1 0.9274622254454086\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 6.546546697616577 s\n",
      "Accuracy 0.929020927850139 precision 0.9281218143726823 specificity 0.80497274208473 recall 0.929020927850139 f1 0.9265741332691443\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 6.519295692443848 s\n",
      "Accuracy 0.9353139177520855 precision 0.9349466501052164 specificity 0.8239551658342357 recall 0.9353139177520855 f1 0.9332226227394916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 6.578536748886108 s\n",
      "Accuracy 0.924191423971901 precision 0.923967060376686 specificity 0.7908974749448481 recall 0.924191423971901 f1 0.9210381379784383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 6.760464668273926 s\n",
      "Accuracy 0.9256549099956095 precision 0.9251811815820956 specificity 0.7960989935381156 recall 0.9256549099956095 f1 0.9227510565159587\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 6.518548965454102 s\n",
      "Accuracy 0.9293136250548807 precision 0.9293549450007084 specificity 0.8063508188217706 recall 0.9293136250548807 f1 0.9265839335607373\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 6.621640205383301 s\n",
      "Accuracy 0.9287282306453973 precision 0.9290646039641238 specificity 0.8038069656703061 recall 0.9287282306453973 f1 0.9258452611400227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 6.441553354263306 s\n",
      "Accuracy 0.924191423971901 precision 0.9241987751702754 specificity 0.8077899537694261 recall 0.924191423971901 f1 0.9214058693291093\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 6.051827907562256 s\n",
      "Accuracy 0.920386360310259 precision 0.9205240013804568 specificity 0.7867582692537254 recall 0.920386360310259 f1 0.9169233322797261\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 6.2535669803619385 s\n",
      "Accuracy 0.9224352407434508 precision 0.9224091807386726 specificity 0.7916619607186726 recall 0.9224352407434508 f1 0.9192010211929945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 6.3565592765808105 s\n",
      "Accuracy 0.9227279379481926 precision 0.9228724997336797 specificity 0.7872259677398048 recall 0.9227279379481926 f1 0.9193332474353786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 6.279564380645752 s\n",
      "Accuracy 0.926240304405093 precision 0.9256484977269417 specificity 0.8060078839090385 recall 0.926240304405093 f1 0.9236412875637431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 6.342560052871704 s\n",
      "Accuracy 0.928142836235914 precision 0.9283466536812515 specificity 0.8037810593225699 recall 0.928142836235914 f1 0.9252813493919844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 6.302563428878784 s\n",
      "Accuracy 0.9227279379481926 precision 0.9222914302780931 specificity 0.7931220921836224 recall 0.9227279379481926 f1 0.9196672279039106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 7.107508420944214 s\n",
      "Accuracy 0.9255085613932387 precision 0.9250873295607871 specificity 0.789799041967154 recall 0.9255085613932387 f1 0.9224220761418247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 7.039512395858765 s\n",
      "Accuracy 0.926240304405093 precision 0.9262389592363097 specificity 0.7979693935809609 recall 0.926240304405093 f1 0.9232500364232845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 6.552544593811035 s\n",
      "Accuracy 0.9236060295624177 precision 0.9224220629918971 specificity 0.7977687503755178 recall 0.9236060295624177 f1 0.92098529923447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 6.593543767929077 s\n",
      "Accuracy 0.9249231669837553 precision 0.924635017033547 specificity 0.7995779556992181 recall 0.9249231669837553 f1 0.9220313093981645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 6.792528390884399 s\n",
      "Accuracy 0.9221425435387092 precision 0.9216475774514168 specificity 0.788054992412863 recall 0.9221425435387092 f1 0.9189512994902954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 6.667538166046143 s\n",
      "Accuracy 0.9240450753695302 precision 0.9230615774701927 specificity 0.7948163750437881 recall 0.9240450753695302 f1 0.9212632972372706\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 6.8935229778289795 s\n",
      "Accuracy 0.921410800526855 precision 0.9219252210659971 specificity 0.7947081527345478 recall 0.921410800526855 f1 0.9180881994409168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 6.731535911560059 s\n",
      "Accuracy 0.924337772574272 precision 0.9243614588809115 specificity 0.7897136649485652 recall 0.924337772574272 f1 0.9210833725048897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 6.901519536972046 s\n",
      "Accuracy 0.919508268696034 precision 0.9191577786954531 specificity 0.7926854442289637 recall 0.919508268696034 f1 0.9163374433933679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 6.995514869689941 s\n",
      "Accuracy 0.9217034977315967 precision 0.9221577559055412 specificity 0.7887410434765421 recall 0.9217034977315967 f1 0.9182411392139832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 6.955518960952759 s\n",
      "Accuracy 0.9255085613932387 precision 0.9247574179252108 specificity 0.8025971386447117 recall 0.9255085613932387 f1 0.9228680616665417\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 6.595542907714844 s\n",
      "Accuracy 0.9192155714912923 precision 0.9186499784572094 specificity 0.7805632085385338 recall 0.9192155714912923 f1 0.9157672542149999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 6.634540319442749 s\n",
      "Accuracy 0.9260939558027221 precision 0.9253691118059182 specificity 0.7991575813859476 recall 0.9260939558027221 f1 0.9233677481697392\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 6.759530544281006 s\n",
      "Accuracy 0.925215864188497 precision 0.9255627520674543 specificity 0.7926705902167979 recall 0.925215864188497 f1 0.9219710487564763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 6.5965423583984375 s\n",
      "Accuracy 0.9178984340699546 precision 0.9170439953261748 specificity 0.7798230977684109 recall 0.9178984340699546 f1 0.9144993433898903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 6.789529085159302 s\n",
      "Accuracy 0.924191423971901 precision 0.9235156529933534 specificity 0.7993239025630086 recall 0.924191423971901 f1 0.9214102664520457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 6.637538433074951 s\n",
      "Accuracy 0.9227279379481926 precision 0.9221239796100033 specificity 0.7913522904161747 recall 0.9227279379481926 f1 0.9196771709986815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 6.864524841308594 s\n",
      "Accuracy 0.9231669837553051 precision 0.9220758796314241 specificity 0.7916918561207121 recall 0.9231669837553051 f1 0.920326923300627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 7.049511909484863 s\n",
      "Accuracy 0.9237523781647885 precision 0.9235321043862167 specificity 0.7911977287060291 recall 0.9237523781647885 f1 0.9205951324715842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 6.898522138595581 s\n",
      "Accuracy 0.9215571491292258 precision 0.9212584656212822 specificity 0.7901976087711334 recall 0.9215571491292258 f1 0.9183461335352585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 6.5905420780181885 s\n",
      "Accuracy 0.9234596809600468 precision 0.9234442525388427 specificity 0.7926743841115386 recall 0.9234596809600468 f1 0.920273045810915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 6.836525917053223 s\n",
      "Accuracy 0.9215571491292258 precision 0.9215116884527425 specificity 0.795157920884267 recall 0.9215571491292258 f1 0.9184031182763532\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 6.794530153274536 s\n",
      "Accuracy 0.9205327089126298 precision 0.9201285095643632 specificity 0.7683474972206809 recall 0.9205327089126298 f1 0.9167203361858844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 6.8685243129730225 s\n",
      "Accuracy 0.9215571491292258 precision 0.9211039865593265 specificity 0.7931658706862533 recall 0.9215571491292258 f1 0.9184772257702929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 6.510546684265137 s\n",
      "Accuracy 0.9291672764525098 precision 0.9294534193997722 specificity 0.7958297709280042 recall 0.9291672764525098 f1 0.9261158254766724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 6.395557403564453 s\n",
      "Accuracy 0.9200936631055173 precision 0.9200639776058466 specificity 0.7803301424597346 recall 0.9200936631055173 f1 0.9164920237136023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 6.564544916152954 s\n",
      "Accuracy 0.9263866530074638 precision 0.9264609854176798 specificity 0.8023480080313077 recall 0.9263866530074638 f1 0.9234876802857024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 6.66661810874939 s\n",
      "Accuracy 0.923313332357676 precision 0.9233135892973108 specificity 0.7926825707043301 recall 0.923313332357676 f1 0.9201189546960054\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 6.526547908782959 s\n",
      "Accuracy 0.9263866530074638 precision 0.926908116751056 specificity 0.7893231429707193 recall 0.9263866530074638 f1 0.9230414046330387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 6.545546770095825 s\n",
      "Accuracy 0.921410800526855 precision 0.9212041472414153 specificity 0.7853145461613746 recall 0.921410800526855 f1 0.9180341800283564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 6.590543270111084 s\n",
      "Accuracy 0.9178984340699546 precision 0.9178706832780649 specificity 0.7788551936625729 recall 0.9178984340699546 f1 0.9141972257581291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 6.537546634674072 s\n",
      "Accuracy 0.9294599736572515 precision 0.929258996365109 specificity 0.799265454651225 recall 0.9294599736572515 f1 0.926636024694104\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 6.4375529289245605 s\n",
      "Accuracy 0.9250695155861262 precision 0.9250870992614857 specificity 0.795351784749856 recall 0.9250695155861262 f1 0.921980393066481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 6.595165014266968 s\n",
      "Accuracy 0.9231669837553051 precision 0.9230565225066206 specificity 0.7976750733387622 recall 0.9231669837553051 f1 0.9201335668688638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 6.560544490814209 s\n",
      "Accuracy 0.9237523781647885 precision 0.9231971376136019 specificity 0.7862260099141585 recall 0.9237523781647885 f1 0.9205725456123616\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 6.528547048568726 s\n",
      "Accuracy 0.9206790575150008 precision 0.9205706141684754 specificity 0.7883465100791365 recall 0.9206790575150008 f1 0.9173382947131385\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 6.573544502258301 s\n",
      "Accuracy 0.9272647446216888 precision 0.9268488114843355 specificity 0.8076567300876234 recall 0.9272647446216888 f1 0.9246652798460189\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 6.4829418659210205 s\n",
      "Accuracy 0.9272647446216888 precision 0.9267434445786091 specificity 0.8044591657575967 recall 0.9272647446216888 f1 0.9246226024304233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 6.618541717529297 s\n",
      "Accuracy 0.9178984340699546 precision 0.918007064443926 specificity 0.7779157694432476 recall 0.9178984340699546 f1 0.9141304893623613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 6.699536561965942 s\n",
      "Accuracy 0.9294599736572515 precision 0.9298889483760574 specificity 0.7996422862399875 recall 0.9294599736572515 f1 0.9264704738452806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 6.529450416564941 s\n",
      "Accuracy 0.9234596809600468 precision 0.9239362971290817 specificity 0.7942926382667631 recall 0.9234596809600468 f1 0.9201816213449867\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 6.616531133651733 s\n",
      "Accuracy 0.9230206351529343 precision 0.9225956944483613 specificity 0.788989268523636 recall 0.9230206351529343 f1 0.9198524532042934\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 6.429582834243774 s\n",
      "Accuracy 0.9234596809600468 precision 0.92333195350791 specificity 0.7919196264104625 recall 0.9234596809600468 f1 0.9202863338937033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 6.644540309906006 s\n",
      "Accuracy 0.9238987267671593 precision 0.9235215774619804 specificity 0.7929662095462268 recall 0.9238987267671593 f1 0.9208411277409078\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 6.521762371063232 s\n",
      "Accuracy 0.9244841211766428 precision 0.924193567210431 specificity 0.8014848170052721 recall 0.9244841211766428 f1 0.9216328506114068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 6.628538370132446 s\n",
      "Accuracy 0.9225815893458218 precision 0.9219285783619061 specificity 0.7975602986725234 recall 0.9225815893458218 f1 0.9197118729549204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 6.590543985366821 s\n",
      "Accuracy 0.92228889214108 precision 0.921887650125327 specificity 0.7868698666981183 recall 0.92228889214108 f1 0.9190380037078769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 6.568544626235962 s\n",
      "Accuracy 0.9272647446216888 precision 0.9271480865140242 specificity 0.7973836842550543 recall 0.9272647446216888 f1 0.9243173945024231\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 6.507547855377197 s\n",
      "Accuracy 0.9219961949363383 precision 0.921415394302905 specificity 0.7894013429047142 recall 0.9219961949363383 f1 0.9188674824053745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 6.623537540435791 s\n",
      "Accuracy 0.9171666910581004 precision 0.917377711980496 specificity 0.7763435042249972 recall 0.9171666910581004 f1 0.9133047925489898\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 6.561237096786499 s\n",
      "Accuracy 0.9253622127908678 precision 0.9249691750082314 specificity 0.7904771103551896 recall 0.9253622127908678 f1 0.9222803026147592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 6.486556053161621 s\n",
      "Accuracy 0.924337772574272 precision 0.9242468989451772 specificity 0.803987727887823 recall 0.924337772574272 f1 0.921486356293895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 6.645655632019043 s\n",
      "Accuracy 0.9266793502122055 precision 0.927284991630007 specificity 0.7925156129649118 recall 0.9266793502122055 f1 0.9234015302269701\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 6.560481071472168 s\n",
      "Accuracy 0.9224352407434508 precision 0.9218033395586871 specificity 0.7961743753577855 recall 0.9224352407434508 f1 0.9195175996516004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 6.705536842346191 s\n",
      "Accuracy 0.9218498463339675 precision 0.9212913676473923 specificity 0.8005602482556854 recall 0.9218498463339675 f1 0.9190121537312139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 6.609748363494873 s\n",
      "Accuracy 0.9219961949363383 precision 0.9217803819593918 specificity 0.7875851984021656 recall 0.9219961949363383 f1 0.9186987041421824\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 6.682668447494507 s\n",
      "Accuracy 0.9190692228889215 precision 0.9187391708151567 specificity 0.7878778051328711 recall 0.9190692228889215 f1 0.9157471505430835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 6.64124059677124 s\n",
      "Accuracy 0.9208254061173716 precision 0.9198381371586345 specificity 0.7913931392501541 recall 0.9208254061173716 f1 0.917879395513964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 6.501547336578369 s\n",
      "Accuracy 0.9287282306453973 precision 0.9291958911514744 specificity 0.8028187712399695 recall 0.9287282306453973 f1 0.9257880556357033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 6.661538600921631 s\n",
      "Accuracy 0.9277037904288014 precision 0.9275731745672514 specificity 0.8010524775011233 recall 0.9277037904288014 f1 0.9248610940552565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 6.423554420471191 s\n",
      "Accuracy 0.927118396019318 precision 0.9269629380854317 specificity 0.8077234538788198 recall 0.927118396019318 f1 0.9244344665935489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 6.536585569381714 s\n",
      "Accuracy 0.9225815893458218 precision 0.9223792066589577 specificity 0.7887479616063707 recall 0.9225815893458218 f1 0.9193255449432639\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 6.6200480461120605 s\n",
      "Accuracy 0.9234596809600468 precision 0.9228459891755049 specificity 0.7956951676732621 recall 0.9234596809600468 f1 0.9205447398275745\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 6.602263450622559 s\n",
      "Accuracy 0.9198009659007756 precision 0.9202868001149032 specificity 0.7749009591029877 recall 0.9198009659007756 f1 0.9158956606096411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 6.609542369842529 s\n",
      "Accuracy 0.9279964876335431 precision 0.9281237827321657 specificity 0.796702763496312 recall 0.9279964876335431 f1 0.9249799430978541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 6.582543134689331 s\n",
      "Accuracy 0.9246304697790136 precision 0.9245057771407096 specificity 0.7996667058704113 recall 0.9246304697790136 f1 0.921684160476454\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 6.575544834136963 s\n",
      "Accuracy 0.924337772574272 precision 0.9239078513358902 specificity 0.7883926401567036 recall 0.924337772574272 f1 0.921187997616353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 6.6449596881866455 s\n",
      "Accuracy 0.9208254061173716 precision 0.9205625978948164 specificity 0.7905274967117267 recall 0.9208254061173716 f1 0.9175954058272315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 6.489462614059448 s\n",
      "Accuracy 0.9215571491292258 precision 0.921230092408813 specificity 0.7948527124692215 recall 0.9215571491292258 f1 0.9184815560165899\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 6.617058992385864 s\n",
      "Accuracy 0.9244841211766428 precision 0.923557690798907 specificity 0.7957296131464238 recall 0.9244841211766428 f1 0.9217127032568989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 6.52754807472229 s\n",
      "Accuracy 0.9238987267671593 precision 0.9231713559024497 specificity 0.7922965141285898 recall 0.9238987267671593 f1 0.9209450824391071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 6.583543300628662 s\n",
      "Accuracy 0.9294599736572515 precision 0.9296203531702617 specificity 0.8061295377837002 recall 0.9294599736572515 f1 0.9266951957869886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 6.546546936035156 s\n",
      "Accuracy 0.9275574418264305 precision 0.9266703565342895 specificity 0.8003278593712276 recall 0.9275574418264305 f1 0.9249576791772912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 6.5972678661346436 s\n",
      "Accuracy 0.928142836235914 precision 0.9281151209527241 specificity 0.8060721373525869 recall 0.928142836235914 f1 0.9254014864961785\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 6.560739994049072 s\n",
      "Accuracy 0.9217034977315967 precision 0.9213566823801321 specificity 0.7965285934111572 recall 0.9217034977315967 f1 0.9186826437590024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 6.6315391063690186 s\n",
      "Accuracy 0.9212644519244841 precision 0.9206142614823535 specificity 0.7960174212893883 recall 0.9212644519244841 f1 0.9183248043737041\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 6.62871241569519 s\n",
      "Accuracy 0.9238987267671593 precision 0.9240878841103135 specificity 0.788098873640627 recall 0.9238987267671593 f1 0.9205444793479276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 6.577545404434204 s\n",
      "Accuracy 0.9282891848382848 precision 0.927587703526638 specificity 0.8104101258994739 recall 0.9282891848382848 f1 0.9258800422957323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 6.622540235519409 s\n",
      "Accuracy 0.9218498463339675 precision 0.9212486811423376 specificity 0.7879124361877634 recall 0.9218498463339675 f1 0.9186841773677344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 6.456099033355713 s\n",
      "Accuracy 0.927118396019318 precision 0.9269531008380567 specificity 0.7987496208514591 recall 0.927118396019318 f1 0.924216119330085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 6.521057605743408 s\n",
      "Accuracy 0.9221425435387092 precision 0.9215616808831057 specificity 0.7881125976894946 recall 0.9221425435387092 f1 0.9189822758828559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 6.687535524368286 s\n",
      "Accuracy 0.9244841211766428 precision 0.9248255819257427 specificity 0.7884431721713125 recall 0.9244841211766428 f1 0.9211128433420585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 6.894522190093994 s\n",
      "Accuracy 0.9240450753695302 precision 0.923709400322377 specificity 0.8013810532199825 recall 0.9240450753695302 f1 0.921196733591288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 6.609532833099365 s\n",
      "Accuracy 0.9278501390311723 precision 0.9278146717028777 specificity 0.8064556049760643 recall 0.9278501390311723 f1 0.9251142778100824\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 6.642504692077637 s\n",
      "Accuracy 0.9174593882628421 precision 0.9178540926021294 specificity 0.7831171486154568 recall 0.9174593882628421 f1 0.9137523726409928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 6.437553644180298 s\n",
      "Accuracy 0.9294599736572515 precision 0.9291365740956764 specificity 0.7996844617899426 recall 0.9294599736572515 f1 0.9266843145347368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 6.498552560806274 s\n",
      "Accuracy 0.9219961949363383 precision 0.9219034372367555 specificity 0.7821401298673719 recall 0.9219961949363383 f1 0.9185134363377107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 6.5665435791015625 s\n",
      "Accuracy 0.9268256988145763 precision 0.9265695731200757 specificity 0.7994261171192305 recall 0.9268256988145763 f1 0.9239615706944522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 6.546477556228638 s\n",
      "Accuracy 0.927118396019318 precision 0.9277459437934675 specificity 0.7962312641621938 recall 0.927118396019318 f1 0.9239393211833236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 6.609781742095947 s\n",
      "Accuracy 0.9231669837553051 precision 0.9229983090033883 specificity 0.7991377422249633 recall 0.9231669837553051 f1 0.9201896547664428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 6.584382057189941 s\n",
      "Accuracy 0.9253622127908678 precision 0.9242935286390656 specificity 0.8084951329875194 recall 0.9253622127908678 f1 0.9230092770171896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 6.661538124084473 s\n",
      "Accuracy 0.9234596809600468 precision 0.9238004018415709 specificity 0.7879498770715424 recall 0.9234596809600468 f1 0.9200494257756755\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 6.5205464363098145 s\n",
      "Accuracy 0.9225815893458218 precision 0.9225612997068676 specificity 0.7926193049151729 recall 0.9225815893458218 f1 0.9193746415121873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 6.600491046905518 s\n",
      "Accuracy 0.9266793502122055 precision 0.9263811429808627 specificity 0.8107611616316804 recall 0.9266793502122055 f1 0.9241064853456963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 6.872522354125977 s\n",
      "Accuracy 0.9208254061173716 precision 0.9206397019061775 specificity 0.78354814845693 recall 0.9208254061173716 f1 0.9173790100769904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 6.858524799346924 s\n",
      "Accuracy 0.925215864188497 precision 0.9251416780121435 specificity 0.8005485657979242 recall 0.925215864188497 f1 0.9222894834630927\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 6.945653915405273 s\n",
      "Accuracy 0.9240450753695302 precision 0.9244456026293868 specificity 0.7914045068058219 recall 0.9240450753695302 f1 0.920724714514909\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 6.677539110183716 s\n",
      "Accuracy 0.9238987267671593 precision 0.9237639081628123 specificity 0.7870618038137189 recall 0.9238987267671593 f1 0.9206101346385978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 6.652538061141968 s\n",
      "Accuracy 0.9199473145031465 precision 0.9201539871459921 specificity 0.79201151256224 recall 0.9199473145031465 f1 0.9166006196624482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 6.782530307769775 s\n",
      "Accuracy 0.9121908385774916 precision 0.9120608714154907 specificity 0.7637502655073207 recall 0.9121908385774916 f1 0.9079064591954619\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 6.509548902511597 s\n",
      "Accuracy 0.9249231669837553 precision 0.9244350930537587 specificity 0.7861791358951771 recall 0.9249231669837553 f1 0.9217498073956697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 6.537421941757202 s\n",
      "Accuracy 0.9202400117078882 precision 0.9201631312199284 specificity 0.7833933009234897 recall 0.9202400117078882 f1 0.9167417844737928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 6.622127056121826 s\n",
      "Accuracy 0.926240304405093 precision 0.925693702354235 specificity 0.7970829000060295 recall 0.926240304405093 f1 0.9233999283344461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 6.59953498840332 s\n",
      "Accuracy 0.9253622127908678 precision 0.9248226233465637 specificity 0.8013114907561044 recall 0.9253622127908678 f1 0.9226077896148972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 6.558563709259033 s\n",
      "Accuracy 0.9237523781647885 precision 0.9234852016099725 specificity 0.7869020899298493 recall 0.9237523781647885 f1 0.9204963183353797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 6.655940294265747 s\n",
      "Accuracy 0.9228742865505635 precision 0.9229398288983771 specificity 0.7935117426783586 recall 0.9228742865505635 f1 0.9196730239781217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 6.588540554046631 s\n",
      "Accuracy 0.9240450753695302 precision 0.9237976362616761 specificity 0.7954758837177283 recall 0.9240450753695302 f1 0.921015125085284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 6.54754638671875 s\n",
      "Accuracy 0.9236060295624177 precision 0.923609416455256 specificity 0.7985884673480559 recall 0.9236060295624177 f1 0.9205723010654491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 6.684537172317505 s\n",
      "Accuracy 0.9227279379481926 precision 0.9222218972128918 specificity 0.7938368258518786 recall 0.9227279379481926 f1 0.9197097885773569\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 6.58654260635376 s\n",
      "Accuracy 0.9234596809600468 precision 0.9232419511702319 specificity 0.7856287724587853 recall 0.9234596809600468 f1 0.9201469906588954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 6.739687204360962 s\n",
      "Accuracy 0.9205327089126298 precision 0.920455495760831 specificity 0.7890189258766219 recall 0.9205327089126298 f1 0.9171977676818102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 6.6205408573150635 s\n",
      "Accuracy 0.9206790575150008 precision 0.9205500072117843 specificity 0.7936300469151027 recall 0.9206790575150008 f1 0.9174897203466111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 6.6238343715667725 s\n",
      "Accuracy 0.9212644519244841 precision 0.9205628670892296 specificity 0.7955038559395831 recall 0.9212644519244841 f1 0.9183296176702014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 6.697535514831543 s\n",
      "Accuracy 0.9303380652714767 precision 0.9303931466452126 specificity 0.807644056489209 recall 0.9303380652714767 f1 0.927656917819433\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 6.610052108764648 s\n",
      "Accuracy 0.92228889214108 precision 0.9214551210611666 specificity 0.7884678259992728 recall 0.92228889214108 f1 0.9192341699594201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 6.563544988632202 s\n",
      "Accuracy 0.9272647446216888 precision 0.9267814289111642 specificity 0.8062897535317312 recall 0.9272647446216888 f1 0.9246546080688033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 6.556543827056885 s\n",
      "Accuracy 0.9189228742865506 precision 0.9188526763393436 specificity 0.7796916432072941 recall 0.9189228742865506 f1 0.9152846328040272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 6.668538570404053 s\n",
      "Accuracy 0.9234596809600468 precision 0.9228743838405739 specificity 0.8056906097080374 recall 0.9234596809600468 f1 0.9207977715077846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 6.695535898208618 s\n",
      "Accuracy 0.9202400117078882 precision 0.9207523247130871 specificity 0.7784502486805365 recall 0.9202400117078882 f1 0.9164403709319133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 6.5646936893463135 s\n",
      "Accuracy 0.925215864188497 precision 0.9258911509930128 specificity 0.7873445588575431 recall 0.925215864188497 f1 0.9217504365329499\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 6.614482879638672 s\n",
      "Accuracy 0.9238987267671593 precision 0.9233540374857888 specificity 0.79876329820097 recall 0.9238987267671593 f1 0.9210495800818749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 6.609541416168213 s\n",
      "Accuracy 0.9228742865505635 precision 0.9225952245323115 specificity 0.7968716500281952 recall 0.9228742865505635 f1 0.9198654097806561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 6.624540328979492 s\n",
      "Accuracy 0.9238987267671593 precision 0.9235165792788141 specificity 0.7907107322102903 recall 0.9238987267671593 f1 0.920783447618628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 6.660538196563721 s\n",
      "Accuracy 0.9237523781647885 precision 0.9240648008444919 specificity 0.7906607145016306 recall 0.9237523781647885 f1 0.9204285442594774\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 6.592541694641113 s\n",
      "Accuracy 0.9272647446216888 precision 0.9272301631626614 specificity 0.8036379623033912 recall 0.9272647446216888 f1 0.9244475648517323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 6.571548223495483 s\n",
      "Accuracy 0.9238987267671593 precision 0.9237086382112502 specificity 0.7953595858642185 recall 0.9238987267671593 f1 0.9208447090250856\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 6.610841751098633 s\n",
      "Accuracy 0.9234596809600468 precision 0.9232744391872407 specificity 0.8017087268545738 recall 0.9234596809600468 f1 0.9205606572117914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 6.587413311004639 s\n",
      "Accuracy 0.9277037904288014 precision 0.9273614128195646 specificity 0.8073411133583772 recall 0.9277037904288014 f1 0.9250809033780564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 6.593544006347656 s\n",
      "Accuracy 0.9218498463339675 precision 0.9211991592287273 specificity 0.7965464202014396 recall 0.9218498463339675 f1 0.9189368324087129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 6.57154393196106 s\n",
      "Accuracy 0.9205327089126298 precision 0.9205726486808858 specificity 0.7832186019080155 recall 0.9205327089126298 f1 0.9170028436983377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 6.569544553756714 s\n",
      "Accuracy 0.9288745792477682 precision 0.9290372336968907 specificity 0.80555906302244 recall 0.9288745792477682 f1 0.9260829490087108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 6.51229190826416 s\n",
      "Accuracy 0.9200936631055173 precision 0.9196726396701432 specificity 0.7903008345098567 recall 0.9200936631055173 f1 0.9168920662863091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 6.529749393463135 s\n",
      "Accuracy 0.9253622127908678 precision 0.9250242259730754 specificity 0.8069597607414803 recall 0.9253622127908678 f1 0.9226830561717414\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 6.637117385864258 s\n",
      "Accuracy 0.9250695155861262 precision 0.9252430210267464 specificity 0.7981356297882397 recall 0.9250695155861262 f1 0.9220078999592711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 6.628863573074341 s\n",
      "Accuracy 0.9256549099956095 precision 0.9260567958521614 specificity 0.7873647116103825 recall 0.9256549099956095 f1 0.9222706594668237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 6.598031044006348 s\n",
      "Accuracy 0.9208254061173716 precision 0.9213196337998156 specificity 0.783346357412802 recall 0.9208254061173716 f1 0.9171826652821232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 6.627540111541748 s\n",
      "Accuracy 0.9244841211766428 precision 0.923628811585119 specificity 0.7922391615714526 recall 0.9244841211766428 f1 0.9215916583121516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 6.4955480098724365 s\n",
      "Accuracy 0.9256549099956095 precision 0.9252035587694795 specificity 0.7991053564704705 recall 0.9256549099956095 f1 0.9228201539084052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 6.6665380001068115 s\n",
      "Accuracy 0.9240450753695302 precision 0.9236325251550758 specificity 0.7959491062928088 recall 0.9240450753695302 f1 0.9210805458947512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 6.560545444488525 s\n",
      "Accuracy 0.9247768183813845 precision 0.9241766561089894 specificity 0.792348414668266 recall 0.9247768183813845 f1 0.9217992619533582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 6.586228847503662 s\n",
      "Accuracy 0.9211181033221133 precision 0.9209085485278125 specificity 0.785964888584271 recall 0.9211181033221133 f1 0.9177530020629555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 6.536115884780884 s\n",
      "Accuracy 0.9250695155861262 precision 0.9246530286637158 specificity 0.7922274501480436 recall 0.9250695155861262 f1 0.9220332841184872\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 6.553545713424683 s\n",
      "Accuracy 0.9253622127908678 precision 0.9247492170176741 specificity 0.7997223428693193 recall 0.9253622127908678 f1 0.9225932129099852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 6.523546457290649 s\n",
      "Accuracy 0.9240450753695302 precision 0.9238403192467592 specificity 0.7953598152939702 recall 0.9240450753695302 f1 0.9209988585461237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 6.536547660827637 s\n",
      "Accuracy 0.928142836235914 precision 0.9283709555807044 specificity 0.8001074507833184 recall 0.928142836235914 f1 0.9251855330449873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 6.616359710693359 s\n",
      "Accuracy 0.9259476072003512 precision 0.9261310206936652 specificity 0.7960552151935127 recall 0.9259476072003512 f1 0.9228504688313085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 6.65053915977478 s\n",
      "Accuracy 0.9250695155861262 precision 0.9245226402325871 specificity 0.8069398386296259 recall 0.9250695155861262 f1 0.9224556120881711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 6.549545049667358 s\n",
      "Accuracy 0.920386360310259 precision 0.9194885689939725 specificity 0.7920890198659044 recall 0.920386360310259 f1 0.917413822691002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 6.453554391860962 s\n",
      "Accuracy 0.9206790575150008 precision 0.9203050704536788 specificity 0.7850933636920013 recall 0.9206790575150008 f1 0.9173310259408296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 6.634938716888428 s\n",
      "Accuracy 0.9259476072003512 precision 0.9257774890312576 specificity 0.7973283184070978 recall 0.9259476072003512 f1 0.9229844337000638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 6.629018306732178 s\n",
      "Accuracy 0.9259476072003512 precision 0.9260846278526689 specificity 0.7913707193817361 recall 0.9259476072003512 f1 0.9227443868284422\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 6.503548622131348 s\n",
      "Accuracy 0.9247768183813845 precision 0.9247452111995564 specificity 0.7938580180873012 recall 0.9247768183813845 f1 0.9216566411463276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 6.574543714523315 s\n",
      "Accuracy 0.9192155714912923 precision 0.9187166415601911 specificity 0.7852496014496594 recall 0.9192155714912923 f1 0.9158780167997767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 6.507548570632935 s\n",
      "Accuracy 0.9234596809600468 precision 0.923458167055485 specificity 0.7955047022314459 recall 0.9234596809600468 f1 0.9203434574603708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 6.514548063278198 s\n",
      "Accuracy 0.921410800526855 precision 0.9210249415721747 specificity 0.7916666655756052 recall 0.921410800526855 f1 0.9182645504074192\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 6.573270559310913 s\n",
      "Accuracy 0.9297526708619933 precision 0.9295249762936858 specificity 0.7993038873323448 recall 0.9297526708619933 f1 0.9269448784167578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 6.678534746170044 s\n",
      "Accuracy 0.9227279379481926 precision 0.923032995911865 specificity 0.7945366255120001 recall 0.9227279379481926 f1 0.9194845365504505\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 6.734685659408569 s\n",
      "Accuracy 0.925215864188497 precision 0.9247076126984688 specificity 0.7945775508614401 recall 0.925215864188497 f1 0.9222745430949276\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 7.171533584594727 s\n",
      "Accuracy 0.9247768183813845 precision 0.9241255421167281 specificity 0.8009795065366856 recall 0.9247768183813845 f1 0.9220418588445835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 6.869523525238037 s\n",
      "Accuracy 0.9296063222596225 precision 0.9287719484465599 specificity 0.811902237753943 recall 0.9296063222596225 f1 0.9273128221195119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 6.688536882400513 s\n",
      "Accuracy 0.9219961949363383 precision 0.9220081467402804 specificity 0.7955571014805078 recall 0.9219961949363383 f1 0.9188455037909307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 6.814503908157349 s\n",
      "Accuracy 0.9259476072003512 precision 0.9260771438396482 specificity 0.7981958189043831 recall 0.9259476072003512 f1 0.9229193865409577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 6.626540899276733 s\n",
      "Accuracy 0.9244841211766428 precision 0.9239785913830373 specificity 0.7916010544652671 recall 0.9244841211766428 f1 0.9214472852811577\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 6.739532947540283 s\n",
      "Accuracy 0.923313332357676 precision 0.9240523978271928 specificity 0.7848422649986193 recall 0.923313332357676 f1 0.9197153804712516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 6.482550621032715 s\n",
      "Accuracy 0.9282891848382848 precision 0.9280516561893477 specificity 0.807067508465402 recall 0.9282891848382848 f1 0.9256380069901213\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 6.642539739608765 s\n",
      "Accuracy 0.9250695155861262 precision 0.924983560858154 specificity 0.8014266845592842 recall 0.9250695155861262 f1 0.9221658961121039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 6.560460329055786 s\n",
      "Accuracy 0.9224352407434508 precision 0.9221595627631748 specificity 0.7910612599908742 recall 0.9224352407434508 f1 0.9192606062776342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 6.678102731704712 s\n",
      "Accuracy 0.9256549099956095 precision 0.9254677629244034 specificity 0.8035559998820372 recall 0.9256549099956095 f1 0.9228478451755711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 6.603584289550781 s\n",
      "Accuracy 0.923313332357676 precision 0.9229145551543041 specificity 0.8010670504016068 recall 0.923313332357676 f1 0.920462879767902\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 6.545547246932983 s\n",
      "Accuracy 0.9247768183813845 precision 0.9245539526748827 specificity 0.7936735271005191 recall 0.9247768183813845 f1 0.9217092497099876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 6.637539625167847 s\n",
      "Accuracy 0.9236060295624177 precision 0.9237823602029888 specificity 0.7884065130670481 recall 0.9236060295624177 f1 0.9202560230357032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 6.754532098770142 s\n",
      "Accuracy 0.9200936631055173 precision 0.9195086400170581 specificity 0.7870693395820055 recall 0.9200936631055173 f1 0.9168574987987828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 6.646008014678955 s\n",
      "Accuracy 0.920386360310259 precision 0.9203484625461137 specificity 0.7791216965686313 recall 0.920386360310259 f1 0.9167610289672008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 6.576101303100586 s\n",
      "Accuracy 0.9246304697790136 precision 0.9243955164611855 specificity 0.7966446221067652 recall 0.9246304697790136 f1 0.9216400480091439\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 6.7199485301971436 s\n",
      "Accuracy 0.9255085613932387 precision 0.9258487210422026 specificity 0.79139241919472 recall 0.9255085613932387 f1 0.9222399940807418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 6.566545486450195 s\n",
      "Accuracy 0.9236060295624177 precision 0.9228806811755433 specificity 0.8049077955274415 recall 0.9236060295624177 f1 0.9209786078575519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 6.719532489776611 s\n",
      "Accuracy 0.9246304697790136 precision 0.9238975701696414 specificity 0.8018169439659805 recall 0.9246304697790136 f1 0.9219449153837315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 6.51166296005249 s\n",
      "Accuracy 0.9259476072003512 precision 0.9258660345358444 specificity 0.8036753042702393 recall 0.9259476072003512 f1 0.9231176605997817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 6.613117218017578 s\n",
      "Accuracy 0.9228742865505635 precision 0.9231702663406243 specificity 0.7901445918971057 recall 0.9228742865505635 f1 0.9195198070698906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 6.555977821350098 s\n",
      "Accuracy 0.917605736865213 precision 0.9171672563701833 specificity 0.782955786890968 recall 0.917605736865213 f1 0.9141441723898154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 6.606538534164429 s\n",
      "Accuracy 0.9288745792477682 precision 0.9286028934722869 specificity 0.8059849814061649 recall 0.9288745792477682 f1 0.9262202645068233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 6.6105430126190186 s\n",
      "Accuracy 0.928142836235914 precision 0.9276691922388651 specificity 0.8028245110857963 recall 0.928142836235914 f1 0.9254627124833475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 6.8097288608551025 s\n",
      "Accuracy 0.924191423971901 precision 0.9239616246704474 specificity 0.7948795808767672 recall 0.924191423971901 f1 0.9211437485784536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 6.605062246322632 s\n",
      "Accuracy 0.9246304697790136 precision 0.9244844464231627 specificity 0.7965677089376966 recall 0.9246304697790136 f1 0.9216107969563527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 6.627353191375732 s\n",
      "Accuracy 0.9183374798770672 precision 0.9178135922109625 specificity 0.7897872067405138 recall 0.9183374798770672 f1 0.9151179156657535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 6.642537832260132 s\n",
      "Accuracy 0.923313332357676 precision 0.9227577045436016 specificity 0.7958871536515495 recall 0.923313332357676 f1 0.9203797597289283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 6.5935328006744385 s\n",
      "Accuracy 0.9148251134201668 precision 0.9149608429757513 specificity 0.7897816113643965 recall 0.9148251134201668 f1 0.9113279134522949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 6.555235385894775 s\n",
      "Accuracy 0.926240304405093 precision 0.9259647969817412 specificity 0.7979142137349075 recall 0.926240304405093 f1 0.9233311781496967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 6.6295387744903564 s\n",
      "Accuracy 0.9212644519244841 precision 0.9207871765456281 specificity 0.7770119653478713 recall 0.9212644519244841 f1 0.917740941749415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 6.635065793991089 s\n",
      "Accuracy 0.9199473145031465 precision 0.9186212182510627 specificity 0.7845563161098531 recall 0.9199473145031465 f1 0.9169362348794402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 6.550182580947876 s\n",
      "Accuracy 0.929020927850139 precision 0.927848758918609 specificity 0.799147600402578 recall 0.929020927850139 f1 0.926554435133989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 6.618540287017822 s\n",
      "Accuracy 0.927118396019318 precision 0.9269924846975071 specificity 0.7984628772900162 recall 0.927118396019318 f1 0.9241971502013971\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 6.382555723190308 s\n",
      "Accuracy 0.9255085613932387 precision 0.924877385243065 specificity 0.7880805071789062 recall 0.9255085613932387 f1 0.922449186358198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 6.555541276931763 s\n",
      "Accuracy 0.925215864188497 precision 0.9251386521492089 specificity 0.7960660460990298 recall 0.925215864188497 f1 0.9221760165777444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 6.617541313171387 s\n",
      "Accuracy 0.9263866530074638 precision 0.9254948152734698 specificity 0.8008593298024714 recall 0.9263866530074638 f1 0.9237765344333003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 6.598052501678467 s\n",
      "Accuracy 0.9253622127908678 precision 0.9249171057372205 specificity 0.8019816129532422 recall 0.9253622127908678 f1 0.9225923564826999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 6.536136627197266 s\n",
      "Accuracy 0.9268256988145763 precision 0.9262495587855376 specificity 0.8000095579505914 recall 0.9268256988145763 f1 0.9240826675326042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 6.646639585494995 s\n",
      "Accuracy 0.9192155714912923 precision 0.9190642358305553 specificity 0.7860633898880165 recall 0.9192155714912923 f1 0.9157898024822763\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 6.626539945602417 s\n",
      "Accuracy 0.927118396019318 precision 0.9274562400147233 specificity 0.8073897175768826 recall 0.927118396019318 f1 0.9242880289370886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 6.631540298461914 s\n",
      "Accuracy 0.9227279379481926 precision 0.922829402991268 specificity 0.7828772571283538 recall 0.9227279379481926 f1 0.919228457929425\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 6.56854510307312 s\n",
      "Accuracy 0.9244841211766428 precision 0.9243097689749763 specificity 0.7924181229290975 recall 0.9244841211766428 f1 0.9213622027842939\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 6.703007459640503 s\n",
      "Accuracy 0.9211181033221133 precision 0.9214619204420057 specificity 0.7855666123422037 recall 0.9211181033221133 f1 0.9175836330736884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 6.708943605422974 s\n",
      "Accuracy 0.9171666910581004 precision 0.9161951872040307 specificity 0.7741041212490033 recall 0.9171666910581004 f1 0.9136240690765749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 6.587541580200195 s\n",
      "Accuracy 0.924191423971901 precision 0.9243833997999265 specificity 0.7968363439590926 recall 0.924191423971901 f1 0.9210717268007549\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 6.632539510726929 s\n",
      "Accuracy 0.9258012585979803 precision 0.9251937735526278 specificity 0.7980795218411535 recall 0.9258012585979803 f1 0.9229978248213637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 6.507104396820068 s\n",
      "Accuracy 0.9258012585979803 precision 0.9253685719727844 specificity 0.8025265088406246 recall 0.9258012585979803 f1 0.923050101385966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 6.681546688079834 s\n",
      "Accuracy 0.924337772574272 precision 0.9245375818671241 specificity 0.7908758528767711 recall 0.924337772574272 f1 0.9210643547414947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 6.7995285987854 s\n",
      "Accuracy 0.9268256988145763 precision 0.9261077702658436 specificity 0.8090962422520532 recall 0.9268256988145763 f1 0.9243628009759043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 6.675536632537842 s\n",
      "Accuracy 0.9244841211766428 precision 0.9241902271196657 specificity 0.8013316131177205 recall 0.9244841211766428 f1 0.9216299719729101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 6.575543403625488 s\n",
      "Accuracy 0.9219961949363383 precision 0.9219732806334489 specificity 0.7875031434199882 recall 0.9219961949363383 f1 0.9186386084663344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 6.652572393417358 s\n",
      "Accuracy 0.9196546172984048 precision 0.9195488244564631 specificity 0.7794121441368592 recall 0.9196546172984048 f1 0.916038118558768\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 6.91811203956604 s\n",
      "Accuracy 0.9219961949363383 precision 0.921683811847183 specificity 0.7935107765953161 recall 0.9219961949363383 f1 0.918889148375042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 6.608549356460571 s\n",
      "Accuracy 0.9260939558027221 precision 0.9258797546245477 specificity 0.806297994167475 recall 0.9260939558027221 f1 0.9233727787069198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 6.9009153842926025 s\n",
      "Accuracy 0.9215571491292258 precision 0.9208333238100004 specificity 0.7922356972968726 recall 0.9215571491292258 f1 0.9185472362630507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 6.5335469245910645 s\n",
      "Accuracy 0.9279964876335431 precision 0.9276273088443691 specificity 0.7992347174303388 recall 0.9279964876335431 f1 0.9251903982387095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 6.757530927658081 s\n",
      "Accuracy 0.9244841211766428 precision 0.924511772719058 specificity 0.7996224899682088 recall 0.9244841211766428 f1 0.9214888327212732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 6.633538007736206 s\n",
      "Accuracy 0.924191423971901 precision 0.9240012081791937 specificity 0.7946027711978035 recall 0.924191423971901 f1 0.9211243366332723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 6.667533874511719 s\n",
      "Accuracy 0.923313332357676 precision 0.9227018601446562 specificity 0.7952090052066891 recall 0.923313332357676 f1 0.920381493863758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 6.888522386550903 s\n",
      "Accuracy 0.920386360310259 precision 0.9201419534435432 specificity 0.7933243884777518 recall 0.920386360310259 f1 0.917217922707544\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 6.4236814975738525 s\n",
      "Accuracy 0.9256549099956095 precision 0.9257161986789971 specificity 0.7957615323111373 recall 0.9256549099956095 f1 0.9225774265037539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 6.313560485839844 s\n",
      "Accuracy 0.9256549099956095 precision 0.925331844431986 specificity 0.801198647501389 recall 0.9256549099956095 f1 0.9228310387063999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 6.512547969818115 s\n",
      "Accuracy 0.9187765256841797 precision 0.9178172002759065 specificity 0.7821141493493975 recall 0.9187765256841797 f1 0.9155065221674736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 6.5205466747283936 s\n",
      "Accuracy 0.9196546172984048 precision 0.9202619912157182 specificity 0.7894386251994233 recall 0.9196546172984048 f1 0.9161239812877294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 6.576544523239136 s\n",
      "Accuracy 0.9200936631055173 precision 0.919735984848098 specificity 0.794851462335287 recall 0.9200936631055173 f1 0.9169974732051146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 6.4305548667907715 s\n",
      "Accuracy 0.9250695155861262 precision 0.924407233542233 specificity 0.7944269384706236 recall 0.9250695155861262 f1 0.9221751668909598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 6.485549449920654 s\n",
      "Accuracy 0.926240304405093 precision 0.9258666373048915 specificity 0.7973679354614429 recall 0.926240304405093 f1 0.9233488633775805\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 6.711535215377808 s\n",
      "Accuracy 0.9298990194643642 precision 0.9294596237642019 specificity 0.8041727539318427 recall 0.9298990194643642 f1 0.9272784754770728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 6.514547348022461 s\n",
      "Accuracy 0.9190692228889215 precision 0.9190233131917505 specificity 0.7792187516924858 recall 0.9190692228889215 f1 0.9154141011697972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 6.487551212310791 s\n",
      "Accuracy 0.923313332357676 precision 0.9232993834020928 specificity 0.7920345970490517 recall 0.923313332357676 f1 0.9201059596169119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 6.440552473068237 s\n",
      "Accuracy 0.924191423971901 precision 0.9239592544988593 specificity 0.8008817593004127 recall 0.924191423971901 f1 0.9213002014571348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 6.475550651550293 s\n",
      "Accuracy 0.9221425435387092 precision 0.9221245377699154 specificity 0.7949230271429056 recall 0.9221425435387092 f1 0.9189867327177138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 6.481551170349121 s\n",
      "Accuracy 0.923313332357676 precision 0.9227534529492402 specificity 0.8010912301884946 recall 0.923313332357676 f1 0.9205187456432838\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 6.63254189491272 s\n",
      "Accuracy 0.9279964876335431 precision 0.9274789420499976 specificity 0.8019951471292078 recall 0.9279964876335431 f1 0.9253079788160552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 6.412554502487183 s\n",
      "Accuracy 0.9187765256841797 precision 0.9189940945923134 specificity 0.7867480724623654 recall 0.9187765256841797 f1 0.9152529185083239\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 6.522546291351318 s\n",
      "Accuracy 0.9237523781647885 precision 0.9238775718746183 specificity 0.7891612744785993 recall 0.9237523781647885 f1 0.9204401557856868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 6.862524747848511 s\n",
      "Accuracy 0.9187765256841797 precision 0.9187303099266813 specificity 0.784305544506601 recall 0.9187765256841797 f1 0.9152590264346159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 6.938519239425659 s\n",
      "Accuracy 0.920386360310259 precision 0.9207606297226795 specificity 0.7902187179135138 recall 0.920386360310259 f1 0.9169544807123484\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 6.8775224685668945 s\n",
      "Accuracy 0.9297526708619933 precision 0.9295270511918218 specificity 0.8081799125936028 recall 0.9297526708619933 f1 0.9271544983332348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 6.653539419174194 s\n",
      "Accuracy 0.9218498463339675 precision 0.9217824960622871 specificity 0.7892134586961222 recall 0.9218498463339675 f1 0.9185481142445729\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 6.825527667999268 s\n",
      "Accuracy 0.9209717547197425 precision 0.9209675854005407 specificity 0.7811449014183919 recall 0.9209717547197425 f1 0.9174084995383497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 6.762529373168945 s\n",
      "Accuracy 0.925215864188497 precision 0.9245503270773521 specificity 0.8002815385125006 recall 0.925215864188497 f1 0.9224773124506066\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 6.653539180755615 s\n",
      "Accuracy 0.9231669837553051 precision 0.9232753463061487 specificity 0.7946646017820417 recall 0.9231669837553051 f1 0.9199907382200696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 6.527547359466553 s\n",
      "Accuracy 0.9240450753695302 precision 0.9237663511256246 specificity 0.7898568286032771 recall 0.9240450753695302 f1 0.9208778645737445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 6.720534324645996 s\n",
      "Accuracy 0.916581296648617 precision 0.91563537313129 specificity 0.7829747881512303 recall 0.916581296648617 f1 0.9132793498790446\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 6.713533639907837 s\n",
      "Accuracy 0.9255085613932387 precision 0.9256880802089127 specificity 0.7983424290032762 recall 0.9255085613932387 f1 0.9224603753601834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 6.469552040100098 s\n",
      "Accuracy 0.9284355334406557 precision 0.928307137449623 specificity 0.8002405661764336 recall 0.9284355334406557 f1 0.9255890234067865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 6.674536943435669 s\n",
      "Accuracy 0.9190692228889215 precision 0.9184099943814781 specificity 0.7888486243657534 recall 0.9190692228889215 f1 0.915886265980237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 6.555543899536133 s\n",
      "Accuracy 0.924191423971901 precision 0.9233050024700896 specificity 0.8013323881268332 recall 0.924191423971901 f1 0.9215454616092609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 6.518547534942627 s\n",
      "Accuracy 0.9205327089126298 precision 0.9197756756959441 specificity 0.7886245628209659 recall 0.9205327089126298 f1 0.917412103433328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 6.717535018920898 s\n",
      "Accuracy 0.9284355334406557 precision 0.9281267897401397 specificity 0.8082755290481735 recall 0.9284355334406557 f1 0.925839020666999\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 6.5675435066223145 s\n",
      "Accuracy 0.9282891848382848 precision 0.9288811798937681 specificity 0.8040421397511043 recall 0.9282891848382848 f1 0.92533811994666\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 6.651538610458374 s\n",
      "Accuracy 0.9236060295624177 precision 0.9241568798780062 specificity 0.7960724211589498 recall 0.9236060295624177 f1 0.9203592870271193\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 6.609541416168213 s\n",
      "Accuracy 0.9255085613932387 precision 0.924889791978307 specificity 0.7925725753350981 recall 0.9255085613932387 f1 0.9225610028043723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 6.70253586769104 s\n",
      "Accuracy 0.9301917166691058 precision 0.9297832486036163 specificity 0.8070440717006221 recall 0.9301917166691058 f1 0.9276349928720564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 6.743531703948975 s\n",
      "Accuracy 0.92228889214108 precision 0.9219826968108122 specificity 0.7869888752833547 recall 0.92228889214108 f1 0.9190106753481188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 6.7105348110198975 s\n",
      "Accuracy 0.9265330016098346 precision 0.9256151146315177 specificity 0.80491817462255 recall 0.9265330016098346 f1 0.9240408315921694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 6.5495452880859375 s\n",
      "Accuracy 0.926240304405093 precision 0.9265324739061492 specificity 0.795547450448657 recall 0.926240304405093 f1 0.9231080096150125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 6.566546440124512 s\n",
      "Accuracy 0.9199473145031465 precision 0.9205421275997889 specificity 0.7779370019899337 recall 0.9199473145031465 f1 0.9161039416200761\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 6.63753867149353 s\n",
      "Accuracy 0.924337772574272 precision 0.9238887597747167 specificity 0.7935751625033433 recall 0.924337772574272 f1 0.9213300094162042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 6.583542823791504 s\n",
      "Accuracy 0.9224352407434508 precision 0.922952760535461 specificity 0.7979301614259797 recall 0.9224352407434508 f1 0.9192204216956448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 6.769533157348633 s\n",
      "Accuracy 0.9258012585979803 precision 0.9257160999547722 specificity 0.7940548238716592 recall 0.9258012585979803 f1 0.9227262118603073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 6.6215386390686035 s\n",
      "Accuracy 0.9224352407434508 precision 0.9235104747924066 specificity 0.7870998429976255 recall 0.9224352407434508 f1 0.9187956733126604\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 6.640538454055786 s\n",
      "Accuracy 0.9303380652714767 precision 0.9304191400246755 specificity 0.8090026702805398 recall 0.9303380652714767 f1 0.927681319728123\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 6.63654088973999 s\n",
      "Accuracy 0.9255085613932387 precision 0.9253420966067271 specificity 0.7975888056597127 recall 0.9255085613932387 f1 0.9225409418231534\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 6.679536581039429 s\n",
      "Accuracy 0.924337772574272 precision 0.9242996982653467 specificity 0.793659163349069 recall 0.924337772574272 f1 0.9212040199128411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 6.573544502258301 s\n",
      "Accuracy 0.9275574418264305 precision 0.9275604281799887 specificity 0.8112249299657327 recall 0.9275574418264305 f1 0.9249204423126024\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 6.569544553756714 s\n",
      "Accuracy 0.925215864188497 precision 0.9252761247724507 specificity 0.7935036058455416 recall 0.925215864188497 f1 0.9220706114669335\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 6.453552961349487 s\n",
      "Accuracy 0.9217034977315967 precision 0.9219281631779114 specificity 0.794853389909173 recall 0.9217034977315967 f1 0.9184677141791163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 6.506546258926392 s\n",
      "Accuracy 0.9211181033221133 precision 0.9211766935885505 specificity 0.7955459377813701 recall 0.9211181033221133 f1 0.917935058959596\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 6.653537273406982 s\n",
      "Accuracy 0.9231669837553051 precision 0.922997174816123 specificity 0.795000747837994 recall 0.9231669837553051 f1 0.920081023616959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 6.569544553756714 s\n",
      "Accuracy 0.924337772574272 precision 0.92433699307116 specificity 0.7975953070189088 recall 0.924337772574272 f1 0.9212952127664429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 6.6045427322387695 s\n",
      "Accuracy 0.924337772574272 precision 0.9244208580470029 specificity 0.7970560151944422 recall 0.924337772574272 f1 0.9212572992485883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 6.814527750015259 s\n",
      "Accuracy 0.9236060295624177 precision 0.923401385918355 specificity 0.7974828903667421 recall 0.9236060295624177 f1 0.9206055878758892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 6.804530620574951 s\n",
      "Accuracy 0.9189228742865506 precision 0.9190129539561901 specificity 0.7820728557615485 recall 0.9189228742865506 f1 0.9153058398223421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 6.653536558151245 s\n",
      "Accuracy 0.9272647446216888 precision 0.9271506257059973 specificity 0.7997462795277809 recall 0.9272647446216888 f1 0.9243750892551171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 6.742532253265381 s\n",
      "Accuracy 0.9225815893458218 precision 0.9223383216885402 specificity 0.7931597936219984 recall 0.9225815893458218 f1 0.9194563291275492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 6.516550064086914 s\n",
      "Accuracy 0.921410800526855 precision 0.922028394368328 specificity 0.7992946692706491 recall 0.921410800526855 f1 0.9181863043418305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 6.723532438278198 s\n",
      "Accuracy 0.9230206351529343 precision 0.9223957635502205 specificity 0.7970290334832268 recall 0.9230206351529343 f1 0.9201356911618267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 6.568543195724487 s\n",
      "Accuracy 0.9268256988145763 precision 0.9267738368961339 specificity 0.8006510044882381 recall 0.9268256988145763 f1 0.9239302420875045\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 6.570544481277466 s\n",
      "Accuracy 0.9225815893458218 precision 0.9228438335692108 specificity 0.7918381139063289 recall 0.9225815893458218 f1 0.9192744415836032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 6.404557943344116 s\n",
      "Accuracy 0.920386360310259 precision 0.9199550272414619 specificity 0.7872808757650215 recall 0.920386360310259 f1 0.9171108321025565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 6.617540121078491 s\n",
      "Accuracy 0.9258012585979803 precision 0.9251156701427407 specificity 0.8067622556110344 recall 0.9258012585979803 f1 0.9232477038764302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 6.572542667388916 s\n",
      "Accuracy 0.9177520854675838 precision 0.9182279337915432 specificity 0.768665024137676 recall 0.9177520854675838 f1 0.9136091422456889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 6.5035483837127686 s\n",
      "Accuracy 0.9193619200936631 precision 0.9183922633190414 specificity 0.7787337937849375 recall 0.9193619200936631 f1 0.9160128262421908\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 6.459551572799683 s\n",
      "Accuracy 0.9224352407434508 precision 0.9223910639609877 specificity 0.7908503251087775 recall 0.9224352407434508 f1 0.9191845852962218\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 6.397554397583008 s\n",
      "Accuracy 0.9291672764525098 precision 0.9284413493494282 specificity 0.8108328452249354 recall 0.9291672764525098 f1 0.9267949252473747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 6.455553293228149 s\n",
      "Accuracy 0.9250695155861262 precision 0.924751216192754 specificity 0.783998961288909 recall 0.9250695155861262 f1 0.9217880550202867\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 6.483550071716309 s\n",
      "Accuracy 0.9192155714912923 precision 0.9190247918295191 specificity 0.7844028972243396 recall 0.9192155714912923 f1 0.9157549348907728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 6.588543891906738 s\n",
      "Accuracy 0.9228742865505635 precision 0.9229958325293841 specificity 0.7960437416705328 recall 0.9228742865505635 f1 0.9197243072893457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 6.873525142669678 s\n",
      "Accuracy 0.927118396019318 precision 0.9269305819568366 specificity 0.7998303502599722 recall 0.927118396019318 f1 0.9242497590913477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 6.805528163909912 s\n",
      "Accuracy 0.9200936631055173 precision 0.9200223893520508 specificity 0.7893355263940643 recall 0.9200936631055173 f1 0.9167556709829143\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 6.676535606384277 s\n",
      "Accuracy 0.9253622127908678 precision 0.925012750994371 specificity 0.7986692944800409 recall 0.9253622127908678 f1 0.9224762786240653\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 6.55354642868042 s\n",
      "Accuracy 0.9266793502122055 precision 0.9267334941987629 specificity 0.8028350464574759 recall 0.9266793502122055 f1 0.9238044312202672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 6.530547142028809 s\n",
      "Accuracy 0.92228889214108 precision 0.9220887597488125 specificity 0.8016756149123496 recall 0.92228889214108 f1 0.9193708229971477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 6.4205546379089355 s\n",
      "Accuracy 0.9284355334406557 precision 0.9283370869029804 specificity 0.7994699843997772 recall 0.9284355334406557 f1 0.9255614207279138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 6.443552494049072 s\n",
      "Accuracy 0.9253622127908678 precision 0.9251456457899853 specificity 0.7987720969404853 recall 0.9253622127908678 f1 0.9224368254177683\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 6.470549583435059 s\n",
      "Accuracy 0.9234596809600468 precision 0.9224985939546333 specificity 0.7953861234133197 recall 0.9234596809600468 f1 0.9206706937708627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 6.597540855407715 s\n",
      "Accuracy 0.9218498463339675 precision 0.9218108927271621 specificity 0.794726277392754 recall 0.9218498463339675 f1 0.918688548329987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 6.5315470695495605 s\n",
      "Accuracy 0.9260939558027221 precision 0.9249419001903112 specificity 0.7938784565087357 recall 0.9260939558027221 f1 0.9234101906828657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 6.670537233352661 s\n",
      "Accuracy 0.9259476072003512 precision 0.9259654576152326 specificity 0.7904340706099414 recall 0.9259476072003512 f1 0.9227540976876926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 6.684537649154663 s\n",
      "Accuracy 0.921410800526855 precision 0.9211061988970185 specificity 0.7912901532391454 recall 0.921410800526855 f1 0.9182280755305854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 6.54654598236084 s\n",
      "Accuracy 0.9260939558027221 precision 0.9261042536829632 specificity 0.7978047065608033 recall 0.9260939558027221 f1 0.9230928542235771\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 6.650538444519043 s\n",
      "Accuracy 0.9259476072003512 precision 0.9257936307737955 specificity 0.7959217739995739 recall 0.9259476072003512 f1 0.922943953670313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 6.5445473194122314 s\n",
      "Accuracy 0.9234596809600468 precision 0.9230478560706893 specificity 0.7954148799768765 recall 0.9234596809600468 f1 0.9204679470432778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 6.524547100067139 s\n",
      "Accuracy 0.9217034977315967 precision 0.9211638703518419 specificity 0.7937068417145793 recall 0.9217034977315967 f1 0.9186709199108185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 6.67053747177124 s\n",
      "Accuracy 0.9219961949363383 precision 0.9214269542704512 specificity 0.7841678984777096 recall 0.9219961949363383 f1 0.9187206780235055\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 6.675538063049316 s\n",
      "Accuracy 0.9236060295624177 precision 0.9230512028065646 specificity 0.7933988839279404 recall 0.9236060295624177 f1 0.920612828464584\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 6.611604928970337 s\n",
      "Accuracy 0.9230206351529343 precision 0.922406858920063 specificity 0.7902357229886716 recall 0.9230206351529343 f1 0.919950211108514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 6.645110607147217 s\n",
      "Accuracy 0.9199473145031465 precision 0.9193687870543802 specificity 0.7867535241683641 recall 0.9199473145031465 f1 0.9166966163570229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 6.586545467376709 s\n",
      "Accuracy 0.924191423971901 precision 0.9241372050066418 specificity 0.7922014222796567 recall 0.924191423971901 f1 0.921020983229199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 6.729533672332764 s\n",
      "Accuracy 0.9186301770818088 precision 0.9186908471200884 specificity 0.7794235817940661 recall 0.9186301770818088 f1 0.9149384559134226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 6.608541488647461 s\n",
      "Accuracy 0.9164349480462461 precision 0.9155141275832378 specificity 0.7717042550280938 recall 0.9164349480462461 f1 0.9127809725729905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 6.577546119689941 s\n",
      "Accuracy 0.9196546172984048 precision 0.9194028869614096 specificity 0.7878311791316974 recall 0.9196546172984048 f1 0.9163197156811932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 6.61653995513916 s\n",
      "Accuracy 0.9256549099956095 precision 0.9255437612043329 specificity 0.8008898350456387 recall 0.9256549099956095 f1 0.9227575236142326\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 6.474551439285278 s\n",
      "Accuracy 0.9231669837553051 precision 0.9228142219914933 specificity 0.7908571091099156 recall 0.9231669837553051 f1 0.9200285944583507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 6.476551294326782 s\n",
      "Accuracy 0.9208254061173716 precision 0.9207016583797741 specificity 0.7862428418736682 recall 0.9208254061173716 f1 0.9174347067639456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 6.613539218902588 s\n",
      "Accuracy 0.9227279379481926 precision 0.9226784581125814 specificity 0.7941580863513781 recall 0.9227279379481926 f1 0.9195738373455329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 6.585545539855957 s\n",
      "Accuracy 0.9240450753695302 precision 0.9236679587614056 specificity 0.7874454274041085 recall 0.9240450753695302 f1 0.9208457406531133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 6.511547565460205 s\n",
      "Accuracy 0.9250695155861262 precision 0.924890029026992 specificity 0.7970561863829829 recall 0.9250695155861262 f1 0.9220824061939356\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 6.457552671432495 s\n",
      "Accuracy 0.9288745792477682 precision 0.9285295676164592 specificity 0.8002019270911602 recall 0.9288745792477682 f1 0.926104549697804\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 6.650541305541992 s\n",
      "Accuracy 0.9268256988145763 precision 0.926843726946112 specificity 0.8040422123279392 recall 0.9268256988145763 f1 0.9239940519036605\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 6.494547367095947 s\n",
      "Accuracy 0.9237523781647885 precision 0.9232962873608093 specificity 0.7927140624115725 recall 0.9237523781647885 f1 0.9207107984066247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 6.640541076660156 s\n",
      "Accuracy 0.9250695155861262 precision 0.924323451563083 specificity 0.7941947565658812 recall 0.9250695155861262 f1 0.9222001291852989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 7.120497941970825 s\n",
      "Accuracy 0.9238987267671593 precision 0.9235305750007587 specificity 0.8011827215130345 recall 0.9238987267671593 f1 0.9210528812090756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 6.780530214309692 s\n",
      "Accuracy 0.9211181033221133 precision 0.9202979510421931 specificity 0.7931880124749451 recall 0.9211181033221133 f1 0.9181613696413302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 6.830526113510132 s\n",
      "Accuracy 0.9212644519244841 precision 0.9210735392837576 specificity 0.7915742895926885 recall 0.9212644519244841 f1 0.9180506145679864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 6.779529094696045 s\n",
      "Accuracy 0.9190692228889215 precision 0.9186935291497357 specificity 0.7780263344969763 recall 0.9190692228889215 f1 0.9154816116059188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 6.7505340576171875 s\n",
      "Accuracy 0.9217034977315967 precision 0.9212034408226047 specificity 0.7935939824158069 recall 0.9217034977315967 f1 0.9186542530999018\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 6.6335413455963135 s\n",
      "Accuracy 0.9219961949363383 precision 0.9207479735548838 specificity 0.789923039729405 recall 0.9219961949363383 f1 0.9191515705464823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 6.630540609359741 s\n",
      "Accuracy 0.9211181033221133 precision 0.9209984396508294 specificity 0.7834663454627685 recall 0.9211181033221133 f1 0.9176568896061291\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 6.659536600112915 s\n",
      "Accuracy 0.9219961949363383 precision 0.9213604494071552 specificity 0.7888508152399302 recall 0.9219961949363383 f1 0.9188718249077462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 6.596543312072754 s\n",
      "Accuracy 0.9244841211766428 precision 0.9248611482482777 specificity 0.7926668205495015 recall 0.9244841211766428 f1 0.9212134870919995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 6.697535276412964 s\n",
      "Accuracy 0.9303380652714767 precision 0.9303474329985542 specificity 0.8028597903927552 recall 0.9303380652714767 f1 0.9275579256152077\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 6.6195409297943115 s\n",
      "Accuracy 0.9211181033221133 precision 0.9207516215604428 specificity 0.7893025444898493 recall 0.9211181033221133 f1 0.9178942394289793\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 6.739532947540283 s\n",
      "Accuracy 0.9205327089126298 precision 0.9210150143623932 specificity 0.7886348140530284 recall 0.9205327089126298 f1 0.9170321520940288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 6.656537055969238 s\n",
      "Accuracy 0.9294599736572515 precision 0.9288831095619134 specificity 0.8032462924281936 recall 0.9294599736572515 f1 0.9268552522221506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 6.656538486480713 s\n",
      "Accuracy 0.9221425435387092 precision 0.9216295486434589 specificity 0.8019780476656163 recall 0.9221425435387092 f1 0.9193324568385315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 6.648539781570435 s\n",
      "Accuracy 0.9240450753695302 precision 0.9231239031338336 specificity 0.8038600756369918 recall 0.9240450753695302 f1 0.9214777499070321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 6.736532211303711 s\n",
      "Accuracy 0.9230206351529343 precision 0.9225087870277084 specificity 0.7909936946917677 recall 0.9230206351529343 f1 0.9199351425821987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 6.508551597595215 s\n",
      "Accuracy 0.923313332357676 precision 0.9224216086914956 specificity 0.802665857574589 recall 0.923313332357676 f1 0.9206877356645168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 6.643537282943726 s\n",
      "Accuracy 0.9258012585979803 precision 0.9262741686650577 specificity 0.7969256110121058 recall 0.9258012585979803 f1 0.9226465615668359\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 6.6445395946502686 s\n",
      "Accuracy 0.919508268696034 precision 0.9197370204003059 specificity 0.7794356428505125 recall 0.919508268696034 f1 0.9157925037892491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 6.734534025192261 s\n",
      "Accuracy 0.9253622127908678 precision 0.9251966725816767 specificity 0.7969465471412254 recall 0.9253622127908678 f1 0.9223746484871622\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 6.6915366649627686 s\n",
      "Accuracy 0.9237523781647885 precision 0.9240034679219774 specificity 0.7950058635934532 recall 0.9237523781647885 f1 0.9205590164052341\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 6.586542844772339 s\n",
      "Accuracy 0.9206790575150008 precision 0.9204113891581036 specificity 0.7876611314083688 recall 0.9206790575150008 f1 0.9173682371327739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 6.634539842605591 s\n",
      "Accuracy 0.9205327089126298 precision 0.9204833246730925 specificity 0.7881040562494885 recall 0.9205327089126298 f1 0.9171642559748157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 6.689538240432739 s\n",
      "Accuracy 0.9256549099956095 precision 0.9254024117753127 specificity 0.8004823253976282 recall 0.9256549099956095 f1 0.9227904846060019\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 6.625539064407349 s\n",
      "Accuracy 0.9221425435387092 precision 0.922016103401844 specificity 0.7901075515864684 recall 0.9221425435387092 f1 0.9188895079411606\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 6.611540794372559 s\n",
      "Accuracy 0.9250695155861262 precision 0.9252063834917694 specificity 0.7964005597230301 recall 0.9250695155861262 f1 0.9219736094874538\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 6.690535068511963 s\n",
      "Accuracy 0.9225815893458218 precision 0.9222818346440554 specificity 0.7946613168946309 recall 0.9225815893458218 f1 0.9195142135989671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 6.7885308265686035 s\n",
      "Accuracy 0.9249231669837553 precision 0.9240781139818173 specificity 0.8042459925357968 recall 0.9249231669837553 f1 0.9223510757833957\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 6.664536714553833 s\n",
      "Accuracy 0.9155568564320211 precision 0.9157089533905362 specificity 0.7751388122149415 recall 0.9155568564320211 f1 0.9116336378564982\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 6.558543920516968 s\n",
      "Accuracy 0.9253622127908678 precision 0.9248174179380241 specificity 0.7874882186236368 recall 0.9253622127908678 f1 0.9222536327949766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 6.8565263748168945 s\n",
      "Accuracy 0.9208254061173716 precision 0.9204081762707668 specificity 0.7858495717621391 recall 0.9208254061173716 f1 0.9175159923204477\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 6.703533887863159 s\n",
      "Accuracy 0.9187765256841797 precision 0.9184773816792228 specificity 0.7819841608119346 recall 0.9187765256841797 f1 0.9152701944610457\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 6.713533639907837 s\n",
      "Accuracy 0.9173130396604713 precision 0.916921361624848 specificity 0.7797948582155214 recall 0.9173130396604713 f1 0.9137369123312046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 6.720534086227417 s\n",
      "Accuracy 0.9183374798770672 precision 0.9176531442152328 specificity 0.7814042698742082 recall 0.9183374798770672 f1 0.9149329062624112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 6.514547348022461 s\n",
      "Accuracy 0.9275574418264305 precision 0.9271269090580674 specificity 0.8024113127979093 recall 0.9275574418264305 f1 0.9248398575892129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 6.758531332015991 s\n",
      "Accuracy 0.9249231669837553 precision 0.9246950086084048 specificity 0.7962147432336732 recall 0.9249231669837553 f1 0.9219261368053628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 6.692737102508545 s\n",
      "Accuracy 0.9282891848382848 precision 0.9279341201345926 specificity 0.8073290473983509 recall 0.9282891848382848 f1 0.9256819276923072\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 6.710930109024048 s\n",
      "Accuracy 0.9236060295624177 precision 0.9233352697146966 specificity 0.8024057392548056 recall 0.9236060295624177 f1 0.9207547743479523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 6.586931943893433 s\n",
      "Accuracy 0.9217034977315967 precision 0.9219375142509899 specificity 0.7930211999113493 recall 0.9217034977315967 f1 0.9184157203649772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 6.7219297885894775 s\n",
      "Accuracy 0.9221425435387092 precision 0.9220454016005247 specificity 0.7914097507345998 recall 0.9221425435387092 f1 0.9189157946840698\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 6.781930446624756 s\n",
      "Accuracy 0.927118396019318 precision 0.9269240777174986 specificity 0.7995136480513712 recall 0.927118396019318 f1 0.924243902219343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 6.675928115844727 s\n",
      "Accuracy 0.9246304697790136 precision 0.9239551185329166 specificity 0.80276131584799 recall 0.9246304697790136 f1 0.9219476319704781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 6.8740234375 s\n",
      "Accuracy 0.9277037904288014 precision 0.9281803125109186 specificity 0.8052212636548975 recall 0.9277037904288014 f1 0.9247971260701128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 7.005963087081909 s\n",
      "Accuracy 0.9263866530074638 precision 0.9256689157883522 specificity 0.7952132897512693 recall 0.9263866530074638 f1 0.9235638694239068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 6.6429314613342285 s\n",
      "Accuracy 0.9227279379481926 precision 0.922420333177791 specificity 0.8007567876266234 recall 0.9227279379481926 f1 0.9198279748871475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 6.470932722091675 s\n",
      "Accuracy 0.925215864188497 precision 0.9253954626365949 specificity 0.7871120373648243 recall 0.925215864188497 f1 0.9218727268398016\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 6.793928623199463 s\n",
      "Accuracy 0.9255085613932387 precision 0.924421700499493 specificity 0.8080908969086006 recall 0.9255085613932387 f1 0.923156560221194\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 6.983510971069336 s\n",
      "Accuracy 0.9268256988145763 precision 0.9266429169300449 specificity 0.7986941518293128 recall 0.9268256988145763 f1 0.9239206737710063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 6.810927867889404 s\n",
      "Accuracy 0.9253622127908678 precision 0.9251654471162136 specificity 0.8037961192128649 recall 0.9253622127908678 f1 0.9225582693784851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 6.749248027801514 s\n",
      "Accuracy 0.92228889214108 precision 0.9226253134257151 specificity 0.7864960567919153 recall 0.92228889214108 f1 0.9188111962804427\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 6.839879751205444 s\n",
      "Accuracy 0.925215864188497 precision 0.9252486127898236 specificity 0.7921944360988749 recall 0.925215864188497 f1 0.9220448284281676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 6.701929092407227 s\n",
      "Accuracy 0.9296063222596225 precision 0.9289521475391233 specificity 0.8037385108270226 recall 0.9296063222596225 f1 0.9270448819267154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 6.665989637374878 s\n",
      "Accuracy 0.9263866530074638 precision 0.9261389417073806 specificity 0.8019844888680124 recall 0.9263866530074638 f1 0.9235741348144914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 6.617263078689575 s\n",
      "Accuracy 0.9247768183813845 precision 0.9246390088821487 specificity 0.7954950226281476 recall 0.9247768183813845 f1 0.9217303193820043\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 6.751167058944702 s\n",
      "Accuracy 0.9230206351529343 precision 0.9233907209394465 specificity 0.794312763989897 recall 0.9230206351529343 f1 0.9197606704997581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 7.143290281295776 s\n",
      "Accuracy 0.9212644519244841 precision 0.9213275584854106 specificity 0.7899958576584061 recall 0.9212644519244841 f1 0.9179323138063974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 6.662887334823608 s\n",
      "Accuracy 0.9255085613932387 precision 0.9257559975495262 specificity 0.7919435122100065 recall 0.9255085613932387 f1 0.9222787901319287\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 6.831111907958984 s\n",
      "Accuracy 0.9255085613932387 precision 0.9252962814363543 specificity 0.8017066859067127 recall 0.9255085613932387 f1 0.9226595098270073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 6.608571290969849 s\n",
      "Accuracy 0.9219961949363383 precision 0.9225350151094279 specificity 0.7788063800418525 recall 0.9219961949363383 f1 0.9182485832704935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 6.656187295913696 s\n",
      "Accuracy 0.9293136250548807 precision 0.9290969857422444 specificity 0.802242385892749 recall 0.9293136250548807 f1 0.9265622225962492\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 6.657144546508789 s\n",
      "Accuracy 0.9287282306453973 precision 0.928561377184311 specificity 0.8041604846035629 recall 0.9287282306453973 f1 0.9259945265435754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 6.559692144393921 s\n",
      "Accuracy 0.924191423971901 precision 0.9241476666138116 specificity 0.7970786446515677 recall 0.924191423971901 f1 0.9211447825857947\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 6.628745079040527 s\n",
      "Accuracy 0.924337772574272 precision 0.9239450419538591 specificity 0.7961580630031692 recall 0.924337772574272 f1 0.9213786562840662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 6.738847255706787 s\n",
      "Accuracy 0.9212644519244841 precision 0.9211533391380292 specificity 0.7888287455073243 recall 0.9212644519244841 f1 0.9179514584685283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 6.669223070144653 s\n",
      "Accuracy 0.923313332357676 precision 0.9229223218881579 specificity 0.7917870537771499 recall 0.923313332357676 f1 0.9202154955229687\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 6.742770671844482 s\n",
      "Accuracy 0.9297526708619933 precision 0.9297573781528069 specificity 0.7995874739096169 recall 0.9297526708619933 f1 0.9268827201382925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 6.663020372390747 s\n",
      "Accuracy 0.9205327089126298 precision 0.9206201872980317 specificity 0.79188050938407 recall 0.9205327089126298 f1 0.9172286690315633\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 6.678889274597168 s\n",
      "Accuracy 0.9228742865505635 precision 0.9223025579144869 specificity 0.7896248458063823 recall 0.9228742865505635 f1 0.9197692561842498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 6.728161573410034 s\n",
      "Accuracy 0.9247768183813845 precision 0.9254572041141426 specificity 0.7933104657764096 recall 0.9247768183813845 f1 0.9214535080583259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 6.595767974853516 s\n",
      "Accuracy 0.9253622127908678 precision 0.9248032033895873 specificity 0.8040301304730729 recall 0.9253622127908678 f1 0.9226840405304748\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 6.623838186264038 s\n",
      "Accuracy 0.9274110932240597 precision 0.9276294354412575 specificity 0.7905449962398075 recall 0.9274110932240597 f1 0.9242026691965795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 6.5538811683654785 s\n",
      "Accuracy 0.9310698082833309 precision 0.9307964108856908 specificity 0.8097370545311635 recall 0.9310698082833309 f1 0.9285504287535069\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 6.636083126068115 s\n",
      "Accuracy 0.9237523781647885 precision 0.9236015705697525 specificity 0.7878637283917943 recall 0.9237523781647885 f1 0.9204860406687964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 6.675692558288574 s\n",
      "Accuracy 0.9228742865505635 precision 0.9223299001591525 specificity 0.7945974237537359 recall 0.9228742865505635 f1 0.9198929014874437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 6.672202825546265 s\n",
      "Accuracy 0.9265330016098346 precision 0.9261015860958258 specificity 0.8056927913088016 recall 0.9265330016098346 f1 0.9238757186402539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 6.640655994415283 s\n",
      "Accuracy 0.923313332357676 precision 0.9224884463009481 specificity 0.7993715901244353 recall 0.923313332357676 f1 0.920572511731306\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 6.656295299530029 s\n",
      "Accuracy 0.9217034977315967 precision 0.9219829515559477 specificity 0.7927641975943291 recall 0.9217034977315967 f1 0.9183964372132669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 6.622761011123657 s\n",
      "Accuracy 0.920386360310259 precision 0.9196515127442138 specificity 0.7924373634283005 recall 0.920386360310259 f1 0.9173606568037986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 6.5280585289001465 s\n",
      "Accuracy 0.9266793502122055 precision 0.9259807803020665 specificity 0.8044091820668029 recall 0.9266793502122055 f1 0.924088599598082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 6.61261773109436 s\n",
      "Accuracy 0.9250695155861262 precision 0.9248489644457292 specificity 0.7951342498330316 recall 0.9250695155861262 f1 0.9220457055932144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 6.539144992828369 s\n",
      "Accuracy 0.9224352407434508 precision 0.9220269558188363 specificity 0.7931280552187547 recall 0.9224352407434508 f1 0.9193587740554329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 6.600017786026001 s\n",
      "Accuracy 0.9244841211766428 precision 0.9239928473640036 specificity 0.8053722885191515 recall 0.9244841211766428 f1 0.9217995495028631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 6.730851650238037 s\n",
      "Accuracy 0.92228889214108 precision 0.9216177493541025 specificity 0.7973505329610254 recall 0.92228889214108 f1 0.9194141478169965\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 6.673895597457886 s\n",
      "Accuracy 0.9219961949363383 precision 0.9221842825440298 specificity 0.7901607688609595 recall 0.9219961949363383 f1 0.9186505307954432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 6.676091909408569 s\n",
      "Accuracy 0.9240450753695302 precision 0.9235330812175078 specificity 0.789438954354539 recall 0.9240450753695302 f1 0.9209429785105112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 6.623820781707764 s\n",
      "Accuracy 0.916581296648617 precision 0.916925893302434 specificity 0.776644143906897 recall 0.916581296648617 f1 0.9126761412415886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 6.671111583709717 s\n",
      "Accuracy 0.9301917166691058 precision 0.9299209237949435 specificity 0.8160745585795135 recall 0.9301917166691058 f1 0.927800920871564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 6.6017491817474365 s\n",
      "Accuracy 0.924191423971901 precision 0.9243661504571125 specificity 0.7937060503788333 recall 0.924191423971901 f1 0.9209951133876091\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 6.650904655456543 s\n",
      "Accuracy 0.9227279379481926 precision 0.9223704717108915 specificity 0.7927328841890308 recall 0.9227279379481926 f1 0.9196308827114525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 6.565149307250977 s\n",
      "Accuracy 0.9196546172984048 precision 0.9189154072335237 specificity 0.7842525958975113 recall 0.9196546172984048 f1 0.9163835984147823\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 6.739841461181641 s\n",
      "Accuracy 0.9155568564320211 precision 0.9154727498897347 specificity 0.7722086517163109 recall 0.9155568564320211 f1 0.9116142849751163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 6.725858211517334 s\n",
      "Accuracy 0.9231669837553051 precision 0.9220018425454062 specificity 0.7929189811185049 recall 0.9231669837553051 f1 0.9203941464992599\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 6.610530376434326 s\n",
      "Accuracy 0.9259476072003512 precision 0.9257311419238782 specificity 0.8055286641346067 recall 0.9259476072003512 f1 0.9232050251360842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 6.641564846038818 s\n",
      "Accuracy 0.9263866530074638 precision 0.9260657493979424 specificity 0.8025501531544385 recall 0.9263866530074638 f1 0.9236115104715409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 6.725858449935913 s\n",
      "Accuracy 0.928142836235914 precision 0.9274911902289877 specificity 0.8035371230294924 recall 0.928142836235914 f1 0.9255434875873907\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 6.567948341369629 s\n",
      "Accuracy 0.9274110932240597 precision 0.9267106930088456 specificity 0.8088167011753836 recall 0.9274110932240597 f1 0.9249455269023792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 6.6286749839782715 s\n",
      "Accuracy 0.9218498463339675 precision 0.9215163964164377 specificity 0.7838196381862663 recall 0.9218498463339675 f1 0.9184830908667605\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 6.908008098602295 s\n",
      "Accuracy 0.9202400117078882 precision 0.9196402974630961 specificity 0.7924305077544306 recall 0.9202400117078882 f1 0.9171619186026582\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 6.929954290390015 s\n",
      "Accuracy 0.9200936631055173 precision 0.9203567655321684 specificity 0.7838808881009947 recall 0.9200936631055173 f1 0.9165086056238755\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 7.572498083114624 s\n",
      "Accuracy 0.9218498463339675 precision 0.9218951013665609 specificity 0.7920325680807278 recall 0.9218498463339675 f1 0.9185915159053012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 6.641245126724243 s\n",
      "Accuracy 0.9228742865505635 precision 0.9220835733456206 specificity 0.7908390097993889 recall 0.9228742865505635 f1 0.9198814501303252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 7.120012521743774 s\n",
      "Accuracy 0.9269720474169472 precision 0.9270146078579476 specificity 0.796834450856083 recall 0.9269720474169472 f1 0.9239578648212208\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 6.792472839355469 s\n",
      "Accuracy 0.9246304697790136 precision 0.9244996295945321 specificity 0.7929528562079421 recall 0.9246304697790136 f1 0.9215127658597383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 6.774652719497681 s\n",
      "Accuracy 0.9228742865505635 precision 0.9228753224675921 specificity 0.7860656320492962 recall 0.9228742865505635 f1 0.9194929848898149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 6.612969636917114 s\n",
      "Accuracy 0.9224352407434508 precision 0.9226339393635588 specificity 0.7858286997636463 recall 0.9224352407434508 f1 0.9189805675460061\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 6.762921333312988 s\n",
      "Accuracy 0.9236060295624177 precision 0.923039274507882 specificity 0.7983945186379172 recall 0.9236060295624177 f1 0.9207488212652187\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 6.929519891738892 s\n",
      "Accuracy 0.9187765256841797 precision 0.9189060237148662 specificity 0.7957873342012262 recall 0.9187765256841797 f1 0.9155324333559702\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 6.803843975067139 s\n",
      "Accuracy 0.9294599736572515 precision 0.9299039377317236 specificity 0.8004377098846426 recall 0.9294599736572515 f1 0.9264857056964926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 6.938284158706665 s\n",
      "Accuracy 0.9212644519244841 precision 0.9204718732009233 specificity 0.7981614873178294 recall 0.9212644519244841 f1 0.9184370905899695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 6.696850538253784 s\n",
      "Accuracy 0.9282891848382848 precision 0.9276039145121704 specificity 0.8024658293456677 recall 0.9282891848382848 f1 0.9256792644479602\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 6.755882501602173 s\n",
      "Accuracy 0.9227279379481926 precision 0.9227031774062076 specificity 0.795267470352347 recall 0.9227279379481926 f1 0.9195960594155778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 6.970006227493286 s\n",
      "Accuracy 0.9208254061173716 precision 0.9208792265866292 specificity 0.7896620878016942 recall 0.9208254061173716 f1 0.9174766384332044\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 6.708868026733398 s\n",
      "Accuracy 0.9224352407434508 precision 0.9219644439085174 specificity 0.7903590154621652 recall 0.9224352407434508 f1 0.9193051249304758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 6.874571084976196 s\n",
      "Accuracy 0.9291672764525098 precision 0.9291178090459498 specificity 0.8100098241514287 recall 0.9291672764525098 f1 0.9265473853519863\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 6.645048379898071 s\n",
      "Accuracy 0.9154105078296503 precision 0.9152918303285364 specificity 0.7863573350482851 recall 0.9154105078296503 f1 0.9118983538067771\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 6.871081113815308 s\n",
      "Accuracy 0.9272647446216888 precision 0.9272097407575978 specificity 0.8048322735186658 recall 0.9272647446216888 f1 0.9244828612652702\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 6.78693413734436 s\n",
      "Accuracy 0.9140933704083126 precision 0.9132905672654275 specificity 0.7762219861185595 recall 0.9140933704083126 f1 0.9104732571045338\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 6.721930027008057 s\n",
      "Accuracy 0.9274110932240597 precision 0.926888222617967 specificity 0.8031106235782182 recall 0.9274110932240597 f1 0.9247392220749661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 6.7784812450408936 s\n",
      "Accuracy 0.9228742865505635 precision 0.9225286055593868 specificity 0.7996963089114832 recall 0.9228742865505635 f1 0.9199615181165255\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 6.838877201080322 s\n",
      "Accuracy 0.9231669837553051 precision 0.9226061495184509 specificity 0.8004641527648466 recall 0.9231669837553051 f1 0.9203532863967968\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 6.677020311355591 s\n",
      "Accuracy 0.9208254061173716 precision 0.9205651748819347 specificity 0.7886315930283959 recall 0.9208254061173716 f1 0.9175424473957037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 6.725583553314209 s\n",
      "Accuracy 0.924337772574272 precision 0.9238404950911936 specificity 0.7971618514067165 recall 0.924337772574272 f1 0.9214398165795878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 6.66664719581604 s\n",
      "Accuracy 0.9212644519244841 precision 0.9206204359041679 specificity 0.7855502229168767 recall 0.9212644519244841 f1 0.9180347317820056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 6.910712003707886 s\n",
      "Accuracy 0.9265330016098346 precision 0.9269178060976345 specificity 0.8016848294068566 recall 0.9265330016098346 f1 0.9235370765327628\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 6.926925182342529 s\n",
      "Accuracy 0.9238987267671593 precision 0.9234984449362946 specificity 0.8016090139304338 recall 0.9238987267671593 f1 0.9210745764394311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 6.373941659927368 s\n",
      "Accuracy 0.9234596809600468 precision 0.9227482732744873 specificity 0.7912994859680915 recall 0.9234596809600468 f1 0.9204632925378412\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 6.152442455291748 s\n",
      "Accuracy 0.9206790575150008 precision 0.9206930908680293 specificity 0.7872301728252112 recall 0.9206790575150008 f1 0.9172713846804776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 6.3443145751953125 s\n",
      "Accuracy 0.924337772574272 precision 0.9243855845535061 specificity 0.7861211660144013 recall 0.924337772574272 f1 0.9209824787079003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 6.179783821105957 s\n",
      "Accuracy 0.9274110932240597 precision 0.927191691868048 specificity 0.8059794093557223 recall 0.9274110932240597 f1 0.9247099078102404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 6.191424608230591 s\n",
      "Accuracy 0.9219961949363383 precision 0.9223492857512645 specificity 0.7857119152305306 recall 0.9219961949363383 f1 0.9184853958563972\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 6.199082374572754 s\n",
      "Accuracy 0.926240304405093 precision 0.9264480121630597 specificity 0.803468426684751 recall 0.926240304405093 f1 0.9233293805099507\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 6.0586488246917725 s\n",
      "Accuracy 0.920386360310259 precision 0.9204747793854298 specificity 0.7868523140717946 recall 0.920386360310259 f1 0.9169398636009134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 6.147217750549316 s\n",
      "Accuracy 0.9211181033221133 precision 0.920663150787458 specificity 0.7912534109978432 recall 0.9211181033221133 f1 0.9179768784567812\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 6.134848356246948 s\n",
      "Accuracy 0.9278501390311723 precision 0.9277101027385718 specificity 0.7968076011266001 recall 0.9278501390311723 f1 0.9249094914742924\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 6.1579430103302 s\n",
      "Accuracy 0.9228742865505635 precision 0.9230602149740443 specificity 0.7898566758622529 recall 0.9228742865505635 f1 0.919542063067634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 5.9379355907440186 s\n",
      "Accuracy 0.924337772574272 precision 0.9241556176773454 specificity 0.7977421882384542 recall 0.924337772574272 f1 0.9213529749724481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 6.121937274932861 s\n",
      "Accuracy 0.925215864188497 precision 0.9246861277694651 specificity 0.7955177229778609 recall 0.925215864188497 f1 0.9223061524545341\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 5.953937292098999 s\n",
      "Accuracy 0.928142836235914 precision 0.9281200285629676 specificity 0.8018117165573061 recall 0.928142836235914 f1 0.9252967795600064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 6.130936622619629 s\n",
      "Accuracy 0.9250695155861262 precision 0.9250519737294988 specificity 0.7959477497463859 recall 0.9250695155861262 f1 0.9220058136454179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 5.9819371700286865 s\n",
      "Accuracy 0.9269720474169472 precision 0.9266054955822963 specificity 0.8068629553622791 recall 0.9269720474169472 f1 0.9243308375912381\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 5.910937309265137 s\n",
      "Accuracy 0.9221425435387092 precision 0.921608529323371 specificity 0.7939091586358704 recall 0.9221425435387092 f1 0.9191230557510421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 6.104935646057129 s\n",
      "Accuracy 0.9249231669837553 precision 0.9247706403310498 specificity 0.7954964241825948 recall 0.9249231669837553 f1 0.921884499986918\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 6.096935510635376 s\n",
      "Accuracy 0.9247768183813845 precision 0.9247412508611934 specificity 0.7959025181259808 recall 0.9247768183813845 f1 0.9217105057147058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 6.105936765670776 s\n",
      "Accuracy 0.9244841211766428 precision 0.9242790474981877 specificity 0.8054004279035488 recall 0.9244841211766428 f1 0.921706458907113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 5.9769368171691895 s\n",
      "Accuracy 0.9230206351529343 precision 0.9227326601473498 specificity 0.7910803307265655 recall 0.9230206351529343 f1 0.9198640655011918\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 6.214935064315796 s\n",
      "Accuracy 0.926240304405093 precision 0.9260129924822107 specificity 0.7981073385097532 recall 0.926240304405093 f1 0.9233209830387389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 6.12193751335144 s\n",
      "Accuracy 0.9246304697790136 precision 0.9243032159528793 specificity 0.8023844111225326 recall 0.9246304697790136 f1 0.9218170683626583\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 6.1159348487854 s\n",
      "Accuracy 0.9208254061173716 precision 0.9208280493848654 specificity 0.789597879217844 recall 0.9208254061173716 f1 0.9174896617914959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 6.172935962677002 s\n",
      "Accuracy 0.9284355334406557 precision 0.927973689367969 specificity 0.8006944991333372 recall 0.9284355334406557 f1 0.9257059627776923\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 6.103935718536377 s\n",
      "Accuracy 0.9178984340699546 precision 0.9182517306893732 specificity 0.7789668474293319 recall 0.9178984340699546 f1 0.9140931365099603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 6.081937551498413 s\n",
      "Accuracy 0.9221425435387092 precision 0.9219115168147483 specificity 0.7917296805506062 recall 0.9221425435387092 f1 0.9189651740366543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 6.122934579849243 s\n",
      "Accuracy 0.9250695155861262 precision 0.9249045951754302 specificity 0.7934350760565408 recall 0.9250695155861262 f1 0.9219849889155597\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 6.025937557220459 s\n",
      "Accuracy 0.9234596809600468 precision 0.9241231062004404 specificity 0.7820684042355941 recall 0.9234596809600468 f1 0.9198101336756851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 6.108935832977295 s\n",
      "Accuracy 0.9279964876335431 precision 0.9286150921050714 specificity 0.8009805154195945 recall 0.9279964876335431 f1 0.9249577636181778\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 6.117936372756958 s\n",
      "Accuracy 0.9258012585979803 precision 0.9260230935834016 specificity 0.7922565359835366 recall 0.9258012585979803 f1 0.9225936853671209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 6.035937309265137 s\n",
      "Accuracy 0.9249231669837553 precision 0.9253971468813722 specificity 0.7867855201378103 recall 0.9249231669837553 f1 0.921485753199403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 5.932937860488892 s\n",
      "Accuracy 0.9227279379481926 precision 0.9222595566987332 specificity 0.7877830176532381 recall 0.9227279379481926 f1 0.919534663264686\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 5.878934383392334 s\n",
      "Accuracy 0.9224352407434508 precision 0.9225527011536019 specificity 0.7797010345929816 recall 0.9224352407434508 f1 0.9188373244708841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 6.099933862686157 s\n",
      "Accuracy 0.9244841211766428 precision 0.9240063444707827 specificity 0.7948376751309575 recall 0.9244841211766428 f1 0.9215223045194694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 6.002936363220215 s\n",
      "Accuracy 0.9227279379481926 precision 0.9222849461904298 specificity 0.7908895970589283 recall 0.9227279379481926 f1 0.9196096338930023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 6.038937568664551 s\n",
      "Accuracy 0.9217034977315967 precision 0.9213131412274636 specificity 0.7827427134944362 recall 0.9217034977315967 f1 0.9183217537256771\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 6.1419360637664795 s\n",
      "Accuracy 0.9279964876335431 precision 0.9274435172424288 specificity 0.811358456453165 recall 0.9279964876335431 f1 0.9255492272845617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 6.014934778213501 s\n",
      "Accuracy 0.9282891848382848 precision 0.9278655465461835 specificity 0.8134800477048331 recall 0.9282891848382848 f1 0.9258531653736404\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 6.097934722900391 s\n",
      "Accuracy 0.9212644519244841 precision 0.9207912322333306 specificity 0.7891757603435411 recall 0.9212644519244841 f1 0.9180757039445884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 6.041936874389648 s\n",
      "Accuracy 0.9208254061173716 precision 0.9203463206647349 specificity 0.7889913115408183 recall 0.9208254061173716 f1 0.9176234059159085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 6.079934597015381 s\n",
      "Accuracy 0.920386360310259 precision 0.9209787657692451 specificity 0.7878363878293627 recall 0.920386360310259 f1 0.9168320298240079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 6.049935579299927 s\n",
      "Accuracy 0.9221425435387092 precision 0.9217936799363855 specificity 0.7925421449516623 recall 0.9221425435387092 f1 0.9190243796795498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 6.062937021255493 s\n",
      "Accuracy 0.9260939558027221 precision 0.925460248544562 specificity 0.8052072549293579 recall 0.9260939558027221 f1 0.9234872303711411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 6.087938070297241 s\n",
      "Accuracy 0.92228889214108 precision 0.9218318416856068 specificity 0.7922755106782063 recall 0.92228889214108 f1 0.9192024305825359\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 6.019935846328735 s\n",
      "Accuracy 0.9238987267671593 precision 0.9238895471557269 specificity 0.7928662600298518 recall 0.9238987267671593 f1 0.9207255897704304\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 6.069935321807861 s\n",
      "Accuracy 0.9269720474169472 precision 0.926947771893907 specificity 0.7982023906841963 recall 0.9269720474169472 f1 0.9240110437561919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 6.1229352951049805 s\n",
      "Accuracy 0.9294599736572515 precision 0.9289143631533775 specificity 0.8104619490405478 recall 0.9294599736572515 f1 0.9270165245717548\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 6.04593563079834 s\n",
      "Accuracy 0.9231669837553051 precision 0.9238006456560267 specificity 0.7871709433885113 recall 0.9231669837553051 f1 0.9196533412312006\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 5.997938632965088 s\n",
      "Accuracy 0.9212644519244841 precision 0.9211357470029595 specificity 0.7942804858405327 recall 0.9212644519244841 f1 0.9181052639485521\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 6.033936023712158 s\n",
      "Accuracy 0.9193619200936631 precision 0.9192611406111799 specificity 0.780440588716544 recall 0.9193619200936631 f1 0.9157654262269973\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 6.17293643951416 s\n",
      "Accuracy 0.9285818820430265 precision 0.9284344943501892 specificity 0.8128805309651529 recall 0.9285818820430265 f1 0.9260480864651988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 6.001936912536621 s\n",
      "Accuracy 0.9221425435387092 precision 0.9217113308291407 specificity 0.7908666361813245 recall 0.9221425435387092 f1 0.919006126735005\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 6.044937372207642 s\n",
      "Accuracy 0.9268256988145763 precision 0.9265712032972432 specificity 0.8015978008034366 recall 0.9268256988145763 f1 0.9240150889910442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 6.110933780670166 s\n",
      "Accuracy 0.9206790575150008 precision 0.9196851811057615 specificity 0.7921623549125382 recall 0.9206790575150008 f1 0.9177542245082405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 6.16893458366394 s\n",
      "Accuracy 0.9183374798770672 precision 0.9186774676460617 specificity 0.7897218582338658 recall 0.9183374798770672 f1 0.9148549988311047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 5.909937858581543 s\n",
      "Accuracy 0.9236060295624177 precision 0.9234468319006462 specificity 0.7889940899833086 recall 0.9236060295624177 f1 0.9203684384797437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 5.999937295913696 s\n",
      "Accuracy 0.9244841211766428 precision 0.9244875816161943 specificity 0.7917986027211799 recall 0.9244841211766428 f1 0.9212934445153528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 6.0099382400512695 s\n",
      "Accuracy 0.9285818820430265 precision 0.9276532693846956 specificity 0.8035888265660067 recall 0.9285818820430265 f1 0.9261040007334053\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 6.031938076019287 s\n",
      "Accuracy 0.924191423971901 precision 0.9245450540820284 specificity 0.7924710704026368 recall 0.924191423971901 f1 0.9209147711350981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 6.0149359703063965 s\n",
      "Accuracy 0.9294599736572515 precision 0.9298220218730991 specificity 0.7988070684578109 recall 0.9294599736572515 f1 0.926467568264572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 6.150935411453247 s\n",
      "Accuracy 0.9234596809600468 precision 0.9236152436651663 specificity 0.7914334844010524 recall 0.9234596809600468 f1 0.9201917693362474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 6.010937690734863 s\n",
      "Accuracy 0.9180447826723255 precision 0.918528469529455 specificity 0.7804630817073948 recall 0.9180447826723255 f1 0.9142518529956246\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 6.113936185836792 s\n",
      "Accuracy 0.9227279379481926 precision 0.922555085965694 specificity 0.7969592982942485 recall 0.9227279379481926 f1 0.9196852172873133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 6.147933006286621 s\n",
      "Accuracy 0.9236060295624177 precision 0.9234543507324722 specificity 0.7978377338786719 recall 0.9236060295624177 f1 0.9205986532852769\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 5.927938461303711 s\n",
      "Accuracy 0.9227279379481926 precision 0.9224879824543236 specificity 0.7877325051218526 recall 0.9227279379481926 f1 0.9194598203900641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 6.041937351226807 s\n",
      "Accuracy 0.9236060295624177 precision 0.9234702265374743 specificity 0.7922382653715155 recall 0.9236060295624177 f1 0.9204469494747163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 5.9919373989105225 s\n",
      "Accuracy 0.919508268696034 precision 0.9187594210893935 specificity 0.7850531994945359 recall 0.919508268696034 f1 0.9162600353052107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 6.150935173034668 s\n",
      "Accuracy 0.9244841211766428 precision 0.924217554824613 specificity 0.7986125104974768 recall 0.9244841211766428 f1 0.9215512005755516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 6.103934049606323 s\n",
      "Accuracy 0.925215864188497 precision 0.925577145605716 specificity 0.800745796208003 recall 0.925215864188497 f1 0.9221737977753515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 6.0809361934661865 s\n",
      "Accuracy 0.9238987267671593 precision 0.9239672464659067 specificity 0.7942068375499429 recall 0.9238987267671593 f1 0.920738362678658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 6.0309364795684814 s\n",
      "Accuracy 0.9240450753695302 precision 0.9233897098269779 specificity 0.797923926069069 recall 0.9240450753695302 f1 0.9212166226575281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 6.104935646057129 s\n",
      "Accuracy 0.9234596809600468 precision 0.922915655106182 specificity 0.7970045223307825 recall 0.9234596809600468 f1 0.9205547639011877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 6.119933843612671 s\n",
      "Accuracy 0.9275574418264305 precision 0.9272416881867435 specificity 0.7977634596652683 recall 0.9275574418264305 f1 0.9246877011703274\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 6.22343897819519 s\n",
      "Accuracy 0.9247768183813845 precision 0.924737838758739 specificity 0.795742861782335 recall 0.9247768183813845 f1 0.9217073907352241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 6.218911647796631 s\n",
      "Accuracy 0.9227279379481926 precision 0.9226325467626666 specificity 0.7877452722156914 recall 0.9227279379481926 f1 0.9194162501411575\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 6.243858814239502 s\n",
      "Accuracy 0.9202400117078882 precision 0.9195799802718723 specificity 0.788096981896598 recall 0.9202400117078882 f1 0.9170625015591721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 6.070019006729126 s\n",
      "Accuracy 0.9247768183813845 precision 0.9242606984007883 specificity 0.8018295054259535 recall 0.9247768183813845 f1 0.9220154332708428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 6.090813875198364 s\n",
      "Accuracy 0.9199473145031465 precision 0.9202828138215016 specificity 0.7815427644922812 recall 0.9199473145031465 f1 0.9162734005012685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 6.083312034606934 s\n",
      "Accuracy 0.9227279379481926 precision 0.9230414575213196 specificity 0.7877578503514233 recall 0.9227279379481926 f1 0.9193013580757676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 6.111395835876465 s\n",
      "Accuracy 0.9227279379481926 precision 0.9218380831530496 specificity 0.7910418789377877 recall 0.9227279379481926 f1 0.9197757130459536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 6.077279567718506 s\n",
      "Accuracy 0.9244841211766428 precision 0.9235838114063541 specificity 0.8001508440483215 recall 0.9244841211766428 f1 0.9218187325658128\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 6.2676002979278564 s\n",
      "Accuracy 0.9236060295624177 precision 0.923742644383955 specificity 0.7865592463647507 recall 0.9236060295624177 f1 0.9202181634883899\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 6.2810752391815186 s\n",
      "Accuracy 0.9284355334406557 precision 0.9285889166937517 specificity 0.8051674451522577 recall 0.9284355334406557 f1 0.9256275855432697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 6.1398231983184814 s\n",
      "Accuracy 0.9238987267671593 precision 0.9232964293826345 specificity 0.7866780148531753 recall 0.9238987267671593 f1 0.9207509426863267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 6.054930925369263 s\n",
      "Accuracy 0.9205327089126298 precision 0.9201602658775541 specificity 0.7741113681537857 recall 0.9205327089126298 f1 0.916873194570167\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 6.1419641971588135 s\n",
      "Accuracy 0.9303380652714767 precision 0.9300738841196017 specificity 0.808930183607377 recall 0.9303380652714767 f1 0.9277817604459183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 6.162850856781006 s\n",
      "Accuracy 0.9186301770818088 precision 0.9185659343933938 specificity 0.7763807209469494 recall 0.9186301770818088 f1 0.9148875202936042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 6.1390061378479 s\n",
      "Accuracy 0.9219961949363383 precision 0.9221042349835152 specificity 0.7842428032486473 recall 0.9219961949363383 f1 0.9185125724992365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 6.160926818847656 s\n",
      "Accuracy 0.9293136250548807 precision 0.9287839812214027 specificity 0.7990770327397442 recall 0.9293136250548807 f1 0.9265885467736348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 6.146944761276245 s\n",
      "Accuracy 0.9187765256841797 precision 0.9191220545960153 specificity 0.7783603099085227 recall 0.9187765256841797 f1 0.9149788672377588\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 6.210043430328369 s\n",
      "Accuracy 0.9244841211766428 precision 0.924146441173729 specificity 0.7993219795419438 recall 0.9244841211766428 f1 0.921592220069411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 6.1508026123046875 s\n",
      "Accuracy 0.9221425435387092 precision 0.922932413433795 specificity 0.7831653831964146 recall 0.9221425435387092 f1 0.9184555056309243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 6.214909315109253 s\n",
      "Accuracy 0.9250695155861262 precision 0.9246256848466655 specificity 0.802685566006824 recall 0.9250695155861262 f1 0.922311216788039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 6.150935888290405 s\n",
      "Accuracy 0.9234596809600468 precision 0.9240441761454828 specificity 0.7838089935033573 recall 0.9234596809600468 f1 0.9198763512854412\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 6.138802528381348 s\n",
      "Accuracy 0.9208254061173716 precision 0.9210743703329087 specificity 0.7937717025958497 recall 0.9208254061173716 f1 0.9175346092293419\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 6.2372071743011475 s\n",
      "Accuracy 0.9206790575150008 precision 0.9204585000866924 specificity 0.793677377196957 recall 0.9206790575150008 f1 0.9175190896416971\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 6.074814796447754 s\n",
      "Accuracy 0.926240304405093 precision 0.9263104345697256 specificity 0.8014130500809657 recall 0.926240304405093 f1 0.9233160179188786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 6.0810065269470215 s\n",
      "Accuracy 0.9268256988145763 precision 0.9267424020176133 specificity 0.7968762527248833 recall 0.9268256988145763 f1 0.92384551305029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 6.009398698806763 s\n",
      "Accuracy 0.9260939558027221 precision 0.9261630145921526 specificity 0.8006292215435353 recall 0.9260939558027221 f1 0.9231471508311662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 6.0572896003723145 s\n",
      "Accuracy 0.9236060295624177 precision 0.9232941089849995 specificity 0.7986113232201701 recall 0.9236060295624177 f1 0.9206688626995183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 6.279269456863403 s\n",
      "Accuracy 0.9202400117078882 precision 0.9199547763298781 specificity 0.7947938729039076 recall 0.9202400117078882 f1 0.9171219031600067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 6.203850984573364 s\n",
      "Accuracy 0.9205327089126298 precision 0.9203558231570441 specificity 0.7847143811000132 recall 0.9205327089126298 f1 0.9171086457147062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 6.088468551635742 s\n",
      "Accuracy 0.9215571491292258 precision 0.921702638778091 specificity 0.7883558107563459 recall 0.9215571491292258 f1 0.9181639398180713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 6.230987548828125 s\n",
      "Accuracy 0.9285818820430265 precision 0.9280830137848519 specificity 0.8053870015820427 recall 0.9285818820430265 f1 0.9259821859706107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 6.144766092300415 s\n",
      "Accuracy 0.921410800526855 precision 0.9217675528692113 specificity 0.7852487859189146 recall 0.921410800526855 f1 0.9178715295180936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 6.085904836654663 s\n",
      "Accuracy 0.9272647446216888 precision 0.9277094988230704 specificity 0.7959277894812375 recall 0.9272647446216888 f1 0.9241271655219003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 6.104768753051758 s\n",
      "Accuracy 0.9238987267671593 precision 0.9231771179975355 specificity 0.7978486327743473 recall 0.9238987267671593 f1 0.9210897595569739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 6.280283451080322 s\n",
      "Accuracy 0.9277037904288014 precision 0.9275867874369588 specificity 0.7994996148338772 recall 0.9277037904288014 f1 0.9248189391720835\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 6.186810255050659 s\n",
      "Accuracy 0.9224352407434508 precision 0.9217825264054542 specificity 0.8004230320015925 recall 0.9224352407434508 f1 0.9196391801356383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 6.003041505813599 s\n",
      "Accuracy 0.9236060295624177 precision 0.9232439804516667 specificity 0.7882707544412391 recall 0.9236060295624177 f1 0.9204126126239741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 6.019892692565918 s\n",
      "Accuracy 0.9279964876335431 precision 0.9272755120046673 specificity 0.810025359168117 recall 0.9279964876335431 f1 0.9255799654687311\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 6.1459667682647705 s\n",
      "Accuracy 0.9240450753695302 precision 0.9237097403411473 specificity 0.793498486236014 recall 0.9240450753695302 f1 0.9209913049993222\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 6.284788608551025 s\n",
      "Accuracy 0.9253622127908678 precision 0.9246813931263483 specificity 0.8001438158685109 recall 0.9253622127908678 f1 0.9226288893317581\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 6.071902275085449 s\n",
      "Accuracy 0.9217034977315967 precision 0.9211880488220836 specificity 0.7910600897025851 recall 0.9217034977315967 f1 0.9185906248763545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 6.2029619216918945 s\n",
      "Accuracy 0.9211181033221133 precision 0.9209238027221113 specificity 0.784515690697683 recall 0.9211181033221133 f1 0.9177084284279433\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 6.243943452835083 s\n",
      "Accuracy 0.9225815893458218 precision 0.9230033567719729 specificity 0.7894937393066234 recall 0.9225815893458218 f1 0.919169339709741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 6.092177391052246 s\n",
      "Accuracy 0.9192155714912923 precision 0.9185844984293317 specificity 0.7758923958862055 recall 0.9192155714912923 f1 0.9156559283414438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 6.175533771514893 s\n",
      "Accuracy 0.9218498463339675 precision 0.9212892243566428 specificity 0.7933846962791158 recall 0.9218498463339675 f1 0.9188190070884519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 6.200722932815552 s\n",
      "Accuracy 0.9224352407434508 precision 0.9217380380094495 specificity 0.7932950825206119 recall 0.9224352407434508 f1 0.9194637917368504\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 6.239850282669067 s\n",
      "Accuracy 0.9234596809600468 precision 0.9230980348594451 specificity 0.8033481021647858 recall 0.9234596809600468 f1 0.920659503261247\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 6.133350849151611 s\n",
      "Accuracy 0.9217034977315967 precision 0.9216205839464069 specificity 0.7899865991487889 recall 0.9217034977315967 f1 0.9184238922433162\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 6.081752777099609 s\n",
      "Accuracy 0.9230206351529343 precision 0.922308640245578 specificity 0.7858418154873653 recall 0.9230206351529343 f1 0.9198671153131784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 6.270815372467041 s\n",
      "Accuracy 0.9231669837553051 precision 0.923436413542332 specificity 0.7880270587574136 recall 0.9231669837553051 f1 0.9197704588645046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 6.111226797103882 s\n",
      "Accuracy 0.9307771110785892 precision 0.9306992356909897 specificity 0.8098274673360777 recall 0.9307771110785892 f1 0.9281941029070271\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 6.01596999168396 s\n",
      "Accuracy 0.9227279379481926 precision 0.9232268083550377 specificity 0.793821356589207 recall 0.9227279379481926 f1 0.9194149025178407\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 6.125909090042114 s\n",
      "Accuracy 0.9272647446216888 precision 0.9270821894361821 specificity 0.7986021003005599 recall 0.9272647446216888 f1 0.9243674220131342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 6.184525966644287 s\n",
      "Accuracy 0.928142836235914 precision 0.927903239744691 specificity 0.7977436714933867 recall 0.928142836235914 f1 0.9252624961135579\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 6.1210339069366455 s\n",
      "Accuracy 0.9231669837553051 precision 0.9232162172407623 specificity 0.7897049181686856 recall 0.9231669837553051 f1 0.9198761899421775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 6.216742515563965 s\n",
      "Accuracy 0.925215864188497 precision 0.9254379102400365 specificity 0.8034707988674958 recall 0.925215864188497 f1 0.9222799670850241\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 6.1050310134887695 s\n",
      "Accuracy 0.9237523781647885 precision 0.9232315896015973 specificity 0.8028424852308315 recall 0.9237523781647885 f1 0.9209985492467004\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 6.245976448059082 s\n",
      "Accuracy 0.9263866530074638 precision 0.9258992190716053 specificity 0.7985723787313898 recall 0.9263866530074638 f1 0.9235668413289969\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 6.279063701629639 s\n",
      "Accuracy 0.9249231669837553 precision 0.9255492420438615 specificity 0.7915118077991704 recall 0.9249231669837553 f1 0.9215701838599928\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 6.225672960281372 s\n",
      "Accuracy 0.9234596809600468 precision 0.923876793838558 specificity 0.789010708464712 recall 0.9234596809600468 f1 0.9200574701615034\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 6.242934465408325 s\n",
      "Accuracy 0.9259476072003512 precision 0.9256998241051857 specificity 0.7978945126670653 recall 0.9259476072003512 f1 0.9230226681968415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 6.116150140762329 s\n",
      "Accuracy 0.9246304697790136 precision 0.9240600053887686 specificity 0.8075576431832929 recall 0.9246304697790136 f1 0.9220328034821148\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 6.056126832962036 s\n",
      "Accuracy 0.9246304697790136 precision 0.9240616309036548 specificity 0.7950916999936128 recall 0.9246304697790136 f1 0.9217099472758001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 6.139910697937012 s\n",
      "Accuracy 0.9196546172984048 precision 0.9186598449947139 specificity 0.7885858186100934 recall 0.9196546172984048 f1 0.9166060801211986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 6.086192607879639 s\n",
      "Accuracy 0.9236060295624177 precision 0.9233580518832923 specificity 0.7849237972938006 recall 0.9236060295624177 f1 0.9202877375821217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 6.0882673263549805 s\n",
      "Accuracy 0.9200936631055173 precision 0.9197424160095272 specificity 0.7894465728329702 recall 0.9200936631055173 f1 0.9168454841287412\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 6.063920259475708 s\n",
      "Accuracy 0.921410800526855 precision 0.9214974116434012 specificity 0.7960505949424732 recall 0.921410800526855 f1 0.9182395670896161\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 6.18984580039978 s\n",
      "Accuracy 0.9244841211766428 precision 0.9244169276690667 specificity 0.7952187547917656 recall 0.9244841211766428 f1 0.9214027502322483\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 6.061486482620239 s\n",
      "Accuracy 0.9247768183813845 precision 0.9245990117515528 specificity 0.7957727733473896 recall 0.9247768183813845 f1 0.9217496010212409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 6.049837350845337 s\n",
      "Accuracy 0.928142836235914 precision 0.9287798862459367 specificity 0.7914708342585981 recall 0.928142836235914 f1 0.9248696482804063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 6.205723762512207 s\n",
      "Accuracy 0.9237523781647885 precision 0.9233750040882329 specificity 0.7923148621307227 recall 0.9237523781647885 f1 0.9206743110469625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 6.234877109527588 s\n",
      "Accuracy 0.9227279379481926 precision 0.9230540955520534 specificity 0.780821744308714 recall 0.9227279379481926 f1 0.9191113155054834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 6.191169261932373 s\n",
      "Accuracy 0.9211181033221133 precision 0.9212846427085507 specificity 0.7871049434894636 recall 0.9211181033221133 f1 0.9176742258701936\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 6.15660548210144 s\n",
      "Accuracy 0.9237523781647885 precision 0.9242113450394144 specificity 0.7925671315699153 recall 0.9237523781647885 f1 0.920440326186481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 6.136561870574951 s\n",
      "Accuracy 0.9230206351529343 precision 0.9228575267526287 specificity 0.7966922847306164 recall 0.9230206351529343 f1 0.9199741111967766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 5.871944189071655 s\n",
      "Accuracy 0.9249231669837553 precision 0.924542449917232 specificity 0.8011886445995002 recall 0.9249231669837553 f1 0.9221025128038112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 5.51161003112793 s\n",
      "Accuracy 0.9269720474169472 precision 0.9262807476978614 specificity 0.8006051263043359 recall 0.9269720474169472 f1 0.9242891760771058\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 5.565079927444458 s\n",
      "Accuracy 0.9246304697790136 precision 0.9247193999378914 specificity 0.7987795325507399 recall 0.9246304697790136 f1 0.921599227170448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 5.711143970489502 s\n",
      "Accuracy 0.9272647446216888 precision 0.9266089633829904 specificity 0.8104057918040001 recall 0.9272647446216888 f1 0.9248186443339523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 5.564946889877319 s\n",
      "Accuracy 0.9296063222596225 precision 0.9294843902818616 specificity 0.8084685904209198 recall 0.9296063222596225 f1 0.9269803169651113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 5.634956121444702 s\n",
      "Accuracy 0.9219961949363383 precision 0.9225801510836275 specificity 0.7808984943429936 recall 0.9219961949363383 f1 0.9182943490577662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 5.681543588638306 s\n",
      "Accuracy 0.9230206351529343 precision 0.9229133221907377 specificity 0.7950516608633263 recall 0.9230206351529343 f1 0.9199138965005206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 5.632232666015625 s\n",
      "Accuracy 0.924337772574272 precision 0.9242858670578568 specificity 0.7838157666665764 recall 0.924337772574272 f1 0.9209507132067011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 5.535661935806274 s\n",
      "Accuracy 0.9291672764525098 precision 0.9284930934022528 specificity 0.811719645247934 recall 0.9291672764525098 f1 0.9267960489397087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 5.552949666976929 s\n",
      "Accuracy 0.9170203424557295 precision 0.9161627252539732 specificity 0.7798563406249814 recall 0.9170203424557295 f1 0.9136018089895906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 5.516164779663086 s\n",
      "Accuracy 0.9268256988145763 precision 0.9274204718301168 specificity 0.8009724450123098 recall 0.9268256988145763 f1 0.923765842627891\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 5.599989652633667 s\n",
      "Accuracy 0.9217034977315967 precision 0.921282717141491 specificity 0.7874836575286885 recall 0.9217034977315967 f1 0.9184614124228361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 5.55104660987854 s\n",
      "Accuracy 0.9315088540904435 precision 0.9310836245145051 specificity 0.813924023265446 recall 0.9315088540904435 f1 0.9291443453686309\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 5.632490158081055 s\n",
      "Accuracy 0.9212644519244841 precision 0.921868414745453 specificity 0.7881434734856291 recall 0.9212644519244841 f1 0.9177368748635482\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 5.678202152252197 s\n",
      "Accuracy 0.9249231669837553 precision 0.9249730788897965 specificity 0.7961513240816348 recall 0.9249231669837553 f1 0.9218419568697837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 5.528919219970703 s\n",
      "Accuracy 0.9205327089126298 precision 0.9207216332722736 specificity 0.7780995221424437 recall 0.9205327089126298 f1 0.9168180128982032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 5.455831050872803 s\n",
      "Accuracy 0.9265330016098346 precision 0.926384449062153 specificity 0.7899734800797147 recall 0.9265330016098346 f1 0.9233916307288931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 5.566864728927612 s\n",
      "Accuracy 0.9190692228889215 precision 0.9186882317898579 specificity 0.7838060064351576 recall 0.9190692228889215 f1 0.9156481755229696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 5.521336317062378 s\n",
      "Accuracy 0.9259476072003512 precision 0.9258339481642021 specificity 0.7933991752294618 recall 0.9259476072003512 f1 0.922867893771513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 5.6035706996917725 s\n",
      "Accuracy 0.9181911312746963 precision 0.917430594820747 specificity 0.7864657577706193 recall 0.9181911312746963 f1 0.9149573112754757\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 5.473105430603027 s\n",
      "Accuracy 0.9265330016098346 precision 0.9261525427625883 specificity 0.7962908289048465 recall 0.9265330016098346 f1 0.9236234069224679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 5.570261716842651 s\n",
      "Accuracy 0.9277037904288014 precision 0.9272954183862406 specificity 0.8021416267796274 recall 0.9277037904288014 f1 0.9249753593285867\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 5.522886037826538 s\n",
      "Accuracy 0.9278501390311723 precision 0.9281085515781674 specificity 0.8049664367160247 recall 0.9278501390311723 f1 0.9249965315281361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 5.5631115436553955 s\n",
      "Accuracy 0.9238987267671593 precision 0.9242478496261587 specificity 0.795579184737424 recall 0.9238987267671593 f1 0.9206975343661365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 5.62400484085083 s\n",
      "Accuracy 0.9277037904288014 precision 0.9271729252424713 specificity 0.8039417945589551 recall 0.9277037904288014 f1 0.92506143307676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 5.497140645980835 s\n",
      "Accuracy 0.927118396019318 precision 0.9265770138155687 specificity 0.8028857188567714 recall 0.927118396019318 f1 0.9244412156875528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 5.5627617835998535 s\n",
      "Accuracy 0.9212644519244841 precision 0.9214653777557476 specificity 0.7847200890199988 recall 0.9212644519244841 f1 0.9177492197776956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 5.601708650588989 s\n",
      "Accuracy 0.9266793502122055 precision 0.9258308556797894 specificity 0.8055827108960487 recall 0.9266793502122055 f1 0.924177721818283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 5.462932586669922 s\n",
      "Accuracy 0.9244841211766428 precision 0.9242145348281272 specificity 0.7964410302434992 recall 0.9244841211766428 f1 0.9214960098343047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 5.609167575836182 s\n",
      "Accuracy 0.924191423971901 precision 0.9238036067885201 specificity 0.7876047587463622 recall 0.924191423971901 f1 0.9210034742386434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 5.550754070281982 s\n",
      "Accuracy 0.9230206351529343 precision 0.9233952998551171 specificity 0.7871813896053552 recall 0.9230206351529343 f1 0.9195697916739324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 5.592186212539673 s\n",
      "Accuracy 0.9279964876335431 precision 0.9278280739999456 specificity 0.8049221669803907 recall 0.9279964876335431 f1 0.9252659770969096\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 5.466155290603638 s\n",
      "Accuracy 0.923313332357676 precision 0.9233787486196077 specificity 0.7911684936717734 recall 0.923313332357676 f1 0.9200602433731717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 5.642331600189209 s\n",
      "Accuracy 0.9224352407434508 precision 0.9217280313610176 specificity 0.7892785211884031 recall 0.9224352407434508 f1 0.9193586744605717\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 5.556845188140869 s\n",
      "Accuracy 0.9228742865505635 precision 0.9227661824933334 specificity 0.796425370781352 recall 0.9228742865505635 f1 0.9198009387471945\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 5.754123687744141 s\n",
      "Accuracy 0.924191423971901 precision 0.9248246446320761 specificity 0.7981726564566842 recall 0.924191423971901 f1 0.9209921603955468\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 5.4637837409973145 s\n",
      "Accuracy 0.9296063222596225 precision 0.9287340021689025 specificity 0.8131134321034401 recall 0.9296063222596225 f1 0.9273585585266626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 5.595925807952881 s\n",
      "Accuracy 0.9234596809600468 precision 0.9228988654633428 specificity 0.7980708495862923 recall 0.9234596809600468 f1 0.9205887824803396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 5.90494179725647 s\n",
      "Accuracy 0.9238987267671593 precision 0.9231800312799352 specificity 0.8030401670023617 recall 0.9238987267671593 f1 0.9212252117004738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 5.51332426071167 s\n",
      "Accuracy 0.9219961949363383 precision 0.9219752083701132 specificity 0.7919624980747236 recall 0.9219961949363383 f1 0.9187584853516866\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 5.533143043518066 s\n",
      "Accuracy 0.9249231669837553 precision 0.9250530956049265 specificity 0.7999140911466087 recall 0.9249231669837553 f1 0.9219158592955402\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 5.56051230430603 s\n",
      "Accuracy 0.9228742865505635 precision 0.9228515002836513 specificity 0.7960505329506249 recall 0.9228742865505635 f1 0.9197657788088206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 5.660706520080566 s\n",
      "Accuracy 0.9183374798770672 precision 0.917774558468823 specificity 0.7827392620851586 recall 0.9183374798770672 f1 0.9149289971318735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 5.572100639343262 s\n",
      "Accuracy 0.9187765256841797 precision 0.9188977555485102 specificity 0.7781748289912201 recall 0.9187765256841797 f1 0.9150355500811033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 5.4998414516448975 s\n",
      "Accuracy 0.9218498463339675 precision 0.9212268071420939 specificity 0.7942550734616959 recall 0.9218498463339675 f1 0.9188646839922154\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 5.595594882965088 s\n",
      "Accuracy 0.9272647446216888 precision 0.9275387255839317 specificity 0.8050220614403334 recall 0.9272647446216888 f1 0.9243960031786319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 5.59335994720459 s\n",
      "Accuracy 0.923313332357676 precision 0.9225592267649324 specificity 0.7975775893883715 recall 0.923313332357676 f1 0.9204971026340781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 5.43490743637085 s\n",
      "Accuracy 0.925215864188497 precision 0.9254227970029885 specificity 0.8004681147335265 recall 0.925215864188497 f1 0.9222078050189747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 5.503067255020142 s\n",
      "Accuracy 0.9277037904288014 precision 0.927229145813715 specificity 0.7968795275197272 recall 0.9277037904288014 f1 0.9248678092678383\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 5.580423831939697 s\n",
      "Accuracy 0.9219961949363383 precision 0.9230993003417381 specificity 0.7857107352398386 recall 0.9219961949363383 f1 0.9183010638523991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 5.5535337924957275 s\n",
      "Accuracy 0.9260939558027221 precision 0.9268284199827606 specificity 0.8010025042997019 recall 0.9260939558027221 f1 0.9229848804266625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 5.566048622131348 s\n",
      "Accuracy 0.9265330016098346 precision 0.9258091983969869 specificity 0.8043655971459069 recall 0.9265330016098346 f1 0.9239478349794406\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 5.447640895843506 s\n",
      "Accuracy 0.9263866530074638 precision 0.9257001178099435 specificity 0.7929477501942163 recall 0.9263866530074638 f1 0.923494554528623\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 5.672899961471558 s\n",
      "Accuracy 0.921410800526855 precision 0.9217708193804851 specificity 0.7925399739590244 recall 0.921410800526855 f1 0.9180695223052558\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 5.541616916656494 s\n",
      "Accuracy 0.9200936631055173 precision 0.9196325812934115 specificity 0.7788313868848101 recall 0.9200936631055173 f1 0.9165838881580302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 5.509941339492798 s\n",
      "Accuracy 0.9224352407434508 precision 0.9220720014865513 specificity 0.7891972785148974 recall 0.9224352407434508 f1 0.919238418535731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 5.576411724090576 s\n",
      "Accuracy 0.9258012585979803 precision 0.9256206375439481 specificity 0.8004031779410076 recall 0.9258012585979803 f1 0.9229157232709618\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 5.759772062301636 s\n",
      "Accuracy 0.9246304697790136 precision 0.9240259038174516 specificity 0.8076878242264242 recall 0.9246304697790136 f1 0.9220485690991845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 5.578042507171631 s\n",
      "Accuracy 0.9253622127908678 precision 0.9251557187073892 specificity 0.8033419507006294 recall 0.9253622127908678 f1 0.9225497762470181\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, seed in enumerate(seeds):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.921264     0.791004   0.921252  0.921264  0.917982\n1  0.925070     0.788310   0.924987  0.925070  0.921828\n2  0.928289     0.813198   0.927936  0.928289  0.925823\n3  0.922435     0.781550   0.922540  0.922435  0.918891\n4  0.925509     0.789622   0.925865  0.925509  0.922190\n5  0.918045     0.775498   0.917617  0.918045  0.914374\n6  0.922143     0.785809   0.922321  0.922143  0.918685\n7  0.927850     0.807498   0.927419  0.927850  0.925264\n8  0.923167     0.798790   0.922415  0.923167  0.920379\n9  0.922289     0.805050   0.921533  0.922289  0.919653",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.921264</td>\n      <td>0.791004</td>\n      <td>0.921252</td>\n      <td>0.921264</td>\n      <td>0.917982</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.925070</td>\n      <td>0.788310</td>\n      <td>0.924987</td>\n      <td>0.925070</td>\n      <td>0.921828</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.928289</td>\n      <td>0.813198</td>\n      <td>0.927936</td>\n      <td>0.928289</td>\n      <td>0.925823</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.922435</td>\n      <td>0.781550</td>\n      <td>0.922540</td>\n      <td>0.922435</td>\n      <td>0.918891</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.925509</td>\n      <td>0.789622</td>\n      <td>0.925865</td>\n      <td>0.925509</td>\n      <td>0.922190</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.918045</td>\n      <td>0.775498</td>\n      <td>0.917617</td>\n      <td>0.918045</td>\n      <td>0.914374</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.922143</td>\n      <td>0.785809</td>\n      <td>0.922321</td>\n      <td>0.922143</td>\n      <td>0.918685</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.927850</td>\n      <td>0.807498</td>\n      <td>0.927419</td>\n      <td>0.927850</td>\n      <td>0.925264</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.923167</td>\n      <td>0.798790</td>\n      <td>0.922415</td>\n      <td>0.923167</td>\n      <td>0.920379</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.922289</td>\n      <td>0.805050</td>\n      <td>0.921533</td>\n      <td>0.922289</td>\n      <td>0.919653</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.9237851602517196\n",
      "Precision 0.9235594429956415\n",
      "Specificity 0.7942738913735855\n",
      "Recall 0.9237851602517196\n",
      "F1 0.9207134391673997\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_16beats_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}