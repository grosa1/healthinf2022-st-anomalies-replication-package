{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ST Sloping - 16 beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1  \\\n0  e0106  65.861928  67.716291  67.206386  18.973287  2.756737  0.736288   \n1  e0106  67.175188  66.539171  66.278974  18.879508  2.752145  0.710574   \n2  e0106  67.331260  67.526064  67.904703  19.526248  2.883850  0.724048   \n3  e0106  66.507411  69.358972  68.845433  19.399284  2.811633  0.728870   \n4  e0106  71.500586  69.600473  69.015425  19.518971  2.844739  0.706509   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.634501 -1.015121 -0.279539  ... -0.038497  0.024202 -0.033980  0.046029   \n1 -0.608829 -1.008338 -0.375129  ... -0.045707  0.028543 -0.033995  0.039226   \n2 -0.611290 -1.007119 -0.471325  ... -0.064803  0.051981 -0.056875  0.061396   \n3 -0.631538 -1.076715 -0.451683  ... -0.042918  0.033450 -0.043966  0.053377   \n4 -0.610843 -1.008555 -0.438800  ... -0.047597  0.025825 -0.031552  0.048798   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.071080  0.009209 -0.027384 -0.007471 -0.007113    NSR  \n1 -0.065687 -0.004942 -0.011601 -0.016082 -0.002783    NSR  \n2 -0.081542  0.009957 -0.023760 -0.019310  0.008258    NSR  \n3 -0.073200  0.002332 -0.021755 -0.003223 -0.021226    NSR  \n4 -0.093202  0.026254 -0.038423 -0.005951 -0.003403    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>65.861928</td>\n      <td>67.716291</td>\n      <td>67.206386</td>\n      <td>18.973287</td>\n      <td>2.756737</td>\n      <td>0.736288</td>\n      <td>-0.634501</td>\n      <td>-1.015121</td>\n      <td>-0.279539</td>\n      <td>...</td>\n      <td>-0.038497</td>\n      <td>0.024202</td>\n      <td>-0.033980</td>\n      <td>0.046029</td>\n      <td>-0.071080</td>\n      <td>0.009209</td>\n      <td>-0.027384</td>\n      <td>-0.007471</td>\n      <td>-0.007113</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>67.175188</td>\n      <td>66.539171</td>\n      <td>66.278974</td>\n      <td>18.879508</td>\n      <td>2.752145</td>\n      <td>0.710574</td>\n      <td>-0.608829</td>\n      <td>-1.008338</td>\n      <td>-0.375129</td>\n      <td>...</td>\n      <td>-0.045707</td>\n      <td>0.028543</td>\n      <td>-0.033995</td>\n      <td>0.039226</td>\n      <td>-0.065687</td>\n      <td>-0.004942</td>\n      <td>-0.011601</td>\n      <td>-0.016082</td>\n      <td>-0.002783</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>67.331260</td>\n      <td>67.526064</td>\n      <td>67.904703</td>\n      <td>19.526248</td>\n      <td>2.883850</td>\n      <td>0.724048</td>\n      <td>-0.611290</td>\n      <td>-1.007119</td>\n      <td>-0.471325</td>\n      <td>...</td>\n      <td>-0.064803</td>\n      <td>0.051981</td>\n      <td>-0.056875</td>\n      <td>0.061396</td>\n      <td>-0.081542</td>\n      <td>0.009957</td>\n      <td>-0.023760</td>\n      <td>-0.019310</td>\n      <td>0.008258</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>66.507411</td>\n      <td>69.358972</td>\n      <td>68.845433</td>\n      <td>19.399284</td>\n      <td>2.811633</td>\n      <td>0.728870</td>\n      <td>-0.631538</td>\n      <td>-1.076715</td>\n      <td>-0.451683</td>\n      <td>...</td>\n      <td>-0.042918</td>\n      <td>0.033450</td>\n      <td>-0.043966</td>\n      <td>0.053377</td>\n      <td>-0.073200</td>\n      <td>0.002332</td>\n      <td>-0.021755</td>\n      <td>-0.003223</td>\n      <td>-0.021226</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>71.500586</td>\n      <td>69.600473</td>\n      <td>69.015425</td>\n      <td>19.518971</td>\n      <td>2.844739</td>\n      <td>0.706509</td>\n      <td>-0.610843</td>\n      <td>-1.008555</td>\n      <td>-0.438800</td>\n      <td>...</td>\n      <td>-0.047597</td>\n      <td>0.025825</td>\n      <td>-0.031552</td>\n      <td>0.048798</td>\n      <td>-0.093202</td>\n      <td>0.026254</td>\n      <td>-0.038423</td>\n      <td>-0.005951</td>\n      <td>-0.003403</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_16beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    26200\nST      7965\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.219210  0.101301  0.071494  0.053500  0.102907 -0.028753   \ndw_2    0.219210  1.000000  0.838628  0.486610  0.180151  0.408486 -0.502032   \ndw_3    0.101301  0.838628  1.000000  0.680243  0.272747  0.255846 -0.548064   \ndw_4    0.071494  0.486610  0.680243  1.000000  0.880644 -0.012857 -0.262781   \ndw_5    0.053500  0.180151  0.272747  0.880644  1.000000 -0.126287 -0.018966   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.057237  0.034692  0.061458  0.050791  0.019165 -0.138724  0.094631   \ncfr_13 -0.042960  0.128171  0.046053  0.024330  0.013247  0.077703 -0.006064   \ncfr_14 -0.052143  0.009246 -0.019790 -0.029443 -0.034829  0.004839  0.022487   \ncfr_15 -0.079161 -0.115564 -0.131894 -0.102508 -0.053621  0.045425  0.082850   \ncfr_16 -0.066310 -0.075292 -0.046861 -0.042964 -0.029838  0.074518 -0.038814   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.044410 -0.002493  0.004377  ... -0.077538 -0.054871 -0.040977   \ndw_2   -0.337710  0.001285  0.018225  ... -0.123426  0.167397  0.237288   \ndw_3   -0.460442  0.004292  0.010350  ... -0.203574  0.143928  0.272752   \ndw_4   -0.246875  0.003327  0.003775  ... -0.154983  0.064231  0.121135   \ndw_5   -0.039939  0.000859  0.000096  ... -0.070726  0.009459  0.007874   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.121316 -0.001690  0.004790  ... -0.134379 -0.207376 -0.072612   \ncfr_13  0.009997  0.003478 -0.000130  ...  0.147883  0.041925 -0.211124   \ncfr_14  0.027808  0.003788 -0.003911  ...  0.109109  0.222240  0.044405   \ncfr_15  0.052462  0.001549 -0.008696  ...  0.279721  0.160473 -0.089826   \ncfr_16 -0.011343  0.011160 -0.005962  ...  0.257415  0.135676  0.188556   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.037365 -0.023672 -0.057237 -0.042960 -0.052143 -0.079161 -0.066310  \ndw_2    0.168364  0.049215  0.034692  0.128171  0.009246 -0.115564 -0.075292  \ndw_3    0.119350 -0.051559  0.061458  0.046053 -0.019790 -0.131894 -0.046861  \ndw_4    0.050684 -0.040099  0.050791  0.024330 -0.029443 -0.102508 -0.042964  \ndw_5    0.021196  0.000299  0.019165  0.013247 -0.034829 -0.053621 -0.029838  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.035689  0.062709  1.000000  0.019376  0.001574 -0.345510 -0.225272  \ncfr_13 -0.268978 -0.011602  0.019376  1.000000  0.223072  0.131959 -0.159064  \ncfr_14 -0.175685 -0.289441  0.001574  0.223072  1.000000  0.198522 -0.135727  \ncfr_15 -0.144377 -0.074435 -0.345510  0.131959  0.198522  1.000000  0.297959  \ncfr_16  0.150307  0.005543 -0.225272 -0.159064 -0.135727  0.297959  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.219210</td>\n      <td>0.101301</td>\n      <td>0.071494</td>\n      <td>0.053500</td>\n      <td>0.102907</td>\n      <td>-0.028753</td>\n      <td>0.044410</td>\n      <td>-0.002493</td>\n      <td>0.004377</td>\n      <td>...</td>\n      <td>-0.077538</td>\n      <td>-0.054871</td>\n      <td>-0.040977</td>\n      <td>-0.037365</td>\n      <td>-0.023672</td>\n      <td>-0.057237</td>\n      <td>-0.042960</td>\n      <td>-0.052143</td>\n      <td>-0.079161</td>\n      <td>-0.066310</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.219210</td>\n      <td>1.000000</td>\n      <td>0.838628</td>\n      <td>0.486610</td>\n      <td>0.180151</td>\n      <td>0.408486</td>\n      <td>-0.502032</td>\n      <td>-0.337710</td>\n      <td>0.001285</td>\n      <td>0.018225</td>\n      <td>...</td>\n      <td>-0.123426</td>\n      <td>0.167397</td>\n      <td>0.237288</td>\n      <td>0.168364</td>\n      <td>0.049215</td>\n      <td>0.034692</td>\n      <td>0.128171</td>\n      <td>0.009246</td>\n      <td>-0.115564</td>\n      <td>-0.075292</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.101301</td>\n      <td>0.838628</td>\n      <td>1.000000</td>\n      <td>0.680243</td>\n      <td>0.272747</td>\n      <td>0.255846</td>\n      <td>-0.548064</td>\n      <td>-0.460442</td>\n      <td>0.004292</td>\n      <td>0.010350</td>\n      <td>...</td>\n      <td>-0.203574</td>\n      <td>0.143928</td>\n      <td>0.272752</td>\n      <td>0.119350</td>\n      <td>-0.051559</td>\n      <td>0.061458</td>\n      <td>0.046053</td>\n      <td>-0.019790</td>\n      <td>-0.131894</td>\n      <td>-0.046861</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.071494</td>\n      <td>0.486610</td>\n      <td>0.680243</td>\n      <td>1.000000</td>\n      <td>0.880644</td>\n      <td>-0.012857</td>\n      <td>-0.262781</td>\n      <td>-0.246875</td>\n      <td>0.003327</td>\n      <td>0.003775</td>\n      <td>...</td>\n      <td>-0.154983</td>\n      <td>0.064231</td>\n      <td>0.121135</td>\n      <td>0.050684</td>\n      <td>-0.040099</td>\n      <td>0.050791</td>\n      <td>0.024330</td>\n      <td>-0.029443</td>\n      <td>-0.102508</td>\n      <td>-0.042964</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.053500</td>\n      <td>0.180151</td>\n      <td>0.272747</td>\n      <td>0.880644</td>\n      <td>1.000000</td>\n      <td>-0.126287</td>\n      <td>-0.018966</td>\n      <td>-0.039939</td>\n      <td>0.000859</td>\n      <td>0.000096</td>\n      <td>...</td>\n      <td>-0.070726</td>\n      <td>0.009459</td>\n      <td>0.007874</td>\n      <td>0.021196</td>\n      <td>0.000299</td>\n      <td>0.019165</td>\n      <td>0.013247</td>\n      <td>-0.034829</td>\n      <td>-0.053621</td>\n      <td>-0.029838</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.057237</td>\n      <td>0.034692</td>\n      <td>0.061458</td>\n      <td>0.050791</td>\n      <td>0.019165</td>\n      <td>-0.138724</td>\n      <td>0.094631</td>\n      <td>0.121316</td>\n      <td>-0.001690</td>\n      <td>0.004790</td>\n      <td>...</td>\n      <td>-0.134379</td>\n      <td>-0.207376</td>\n      <td>-0.072612</td>\n      <td>0.035689</td>\n      <td>0.062709</td>\n      <td>1.000000</td>\n      <td>0.019376</td>\n      <td>0.001574</td>\n      <td>-0.345510</td>\n      <td>-0.225272</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.042960</td>\n      <td>0.128171</td>\n      <td>0.046053</td>\n      <td>0.024330</td>\n      <td>0.013247</td>\n      <td>0.077703</td>\n      <td>-0.006064</td>\n      <td>0.009997</td>\n      <td>0.003478</td>\n      <td>-0.000130</td>\n      <td>...</td>\n      <td>0.147883</td>\n      <td>0.041925</td>\n      <td>-0.211124</td>\n      <td>-0.268978</td>\n      <td>-0.011602</td>\n      <td>0.019376</td>\n      <td>1.000000</td>\n      <td>0.223072</td>\n      <td>0.131959</td>\n      <td>-0.159064</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.052143</td>\n      <td>0.009246</td>\n      <td>-0.019790</td>\n      <td>-0.029443</td>\n      <td>-0.034829</td>\n      <td>0.004839</td>\n      <td>0.022487</td>\n      <td>0.027808</td>\n      <td>0.003788</td>\n      <td>-0.003911</td>\n      <td>...</td>\n      <td>0.109109</td>\n      <td>0.222240</td>\n      <td>0.044405</td>\n      <td>-0.175685</td>\n      <td>-0.289441</td>\n      <td>0.001574</td>\n      <td>0.223072</td>\n      <td>1.000000</td>\n      <td>0.198522</td>\n      <td>-0.135727</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.079161</td>\n      <td>-0.115564</td>\n      <td>-0.131894</td>\n      <td>-0.102508</td>\n      <td>-0.053621</td>\n      <td>0.045425</td>\n      <td>0.082850</td>\n      <td>0.052462</td>\n      <td>0.001549</td>\n      <td>-0.008696</td>\n      <td>...</td>\n      <td>0.279721</td>\n      <td>0.160473</td>\n      <td>-0.089826</td>\n      <td>-0.144377</td>\n      <td>-0.074435</td>\n      <td>-0.345510</td>\n      <td>0.131959</td>\n      <td>0.198522</td>\n      <td>1.000000</td>\n      <td>0.297959</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.066310</td>\n      <td>-0.075292</td>\n      <td>-0.046861</td>\n      <td>-0.042964</td>\n      <td>-0.029838</td>\n      <td>0.074518</td>\n      <td>-0.038814</td>\n      <td>-0.011343</td>\n      <td>0.011160</td>\n      <td>-0.005962</td>\n      <td>...</td>\n      <td>0.257415</td>\n      <td>0.135676</td>\n      <td>0.188556</td>\n      <td>0.150307</td>\n      <td>0.005543</td>\n      <td>-0.225272</td>\n      <td>-0.159064</td>\n      <td>-0.135727</td>\n      <td>0.297959</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_244', 'fft_248', 'fft_151', 'fft_165', 'fft_164', 'fft_216', 'fft_162', 'fft_177', 'fft_247', 'fft_202', 'fft_153', 'fft_238', 'fft_212', 'fft_249', 'fft_231', 'fft_181', 'fft_239', 'fft_243', 'fft_246', 'fft_191', 'fft_251', 'fft_167', 'fft_168', 'fft_138', 'fft_170', 'fft_155', 'fft_176', 'fft_228', 'fft_163', 'fft_182', 'fft_229', 'fft_196', 'fft_204', 'fft_205', 'mfw_7', 'fft_185', 'fft_187', 'mfw_8', 'fft_135', 'fft_145', 'fft_169', 'fft_195', 'fft_148', 'fft_156', 'mfw_14', 'cfr_16', 'fft_192', 'fft_190', 'fft_186', 'fft_158', 'fft_159', 'fft_213', 'fft_234', 'fft_142', 'fft_223', 'fft_178', 'fft_171', 'fft_201', 'fft_253', 'fft_200', 'fft_221', 'fft_207', 'fft_133', 'fft_226', 'fft_255', 'fft_217', 'fft_141', 'fft_188', 'fft_189', 'fft_206', 'fft_214', 'fft_147', 'fft_211', 'fft_139', 'fft_250', 'fft_132', 'fft_220', 'fft_143', 'fft_232', 'fft_227', 'fft_173', 'fft_245', 'fft_154', 'fft_134', 'fft_160', 'mfw_16', 'mfw_5', 'fft_161', 'fft_150', 'fft_179', 'fft_199', 'fft_149', 'fft_193', 'fft_146', 'fft_175', 'fft_209', 'mfw_15', 'fft_144', 'fft_184', 'mfw_13', 'fft_210', 'fft_235', 'fft_136', 'mfw_6', 'fft_218', 'fft_256', 'fft_224', 'mfw_11', 'fft_219', 'fft_131', 'fft_183', 'fft_233', 'fft_180', 'fft_203', 'fft_157', 'fft_166', 'fft_237', 'fft_222', 'fft_254', 'fft_242', 'fft_174', 'fft_140', 'fft_241', 'fft_230', 'fft_152', 'fft_236', 'fft_198', 'fft_215', 'mfw_12', 'fft_197', 'fft_130', 'fft_240', 'fft_252', 'mfw_10', 'fft_225', 'fft_172', 'fft_208', 'fft_137', 'mfw_9', 'fft_194'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_24\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_13\n",
      "ar_14\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 73\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1     mfw_2  \\\n0  65.861928  67.716291  67.206386  18.973287  2.756737  0.736288 -0.634501   \n1  67.175188  66.539171  66.278974  18.879508  2.752145  0.710574 -0.608829   \n2  67.331260  67.526064  67.904703  19.526248  2.883850  0.724048 -0.611290   \n3  66.507411  69.358972  68.845433  19.399284  2.811633  0.728870 -0.631538   \n4  71.500586  69.600473  69.015425  19.518971  2.844739  0.706509 -0.610843   \n\n      mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -1.015121 -0.279539  0.905306  ...  0.020720  0.039231 -0.038497  0.024202   \n1 -1.008338 -0.375129 -0.354970  ...  0.009445  0.040896 -0.045707  0.028543   \n2 -1.007119 -0.471325  1.782405  ...  0.011313  0.048344 -0.064803  0.051981   \n3 -1.076715 -0.451683 -3.475203  ...  0.013055  0.040612 -0.042918  0.033450   \n4 -1.008555 -0.438800 -1.080058  ...  0.004456  0.042616 -0.047597  0.025825   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.033980  0.046029 -0.071080  0.009209 -0.027384 -0.007471  \n1 -0.033995  0.039226 -0.065687 -0.004942 -0.011601 -0.016082  \n2 -0.056875  0.061396 -0.081542  0.009957 -0.023760 -0.019310  \n3 -0.043966  0.053377 -0.073200  0.002332 -0.021755 -0.003223  \n4 -0.031552  0.048798 -0.093202  0.026254 -0.038423 -0.005951  \n\n[5 rows x 73 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>65.861928</td>\n      <td>67.716291</td>\n      <td>67.206386</td>\n      <td>18.973287</td>\n      <td>2.756737</td>\n      <td>0.736288</td>\n      <td>-0.634501</td>\n      <td>-1.015121</td>\n      <td>-0.279539</td>\n      <td>0.905306</td>\n      <td>...</td>\n      <td>0.020720</td>\n      <td>0.039231</td>\n      <td>-0.038497</td>\n      <td>0.024202</td>\n      <td>-0.033980</td>\n      <td>0.046029</td>\n      <td>-0.071080</td>\n      <td>0.009209</td>\n      <td>-0.027384</td>\n      <td>-0.007471</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.175188</td>\n      <td>66.539171</td>\n      <td>66.278974</td>\n      <td>18.879508</td>\n      <td>2.752145</td>\n      <td>0.710574</td>\n      <td>-0.608829</td>\n      <td>-1.008338</td>\n      <td>-0.375129</td>\n      <td>-0.354970</td>\n      <td>...</td>\n      <td>0.009445</td>\n      <td>0.040896</td>\n      <td>-0.045707</td>\n      <td>0.028543</td>\n      <td>-0.033995</td>\n      <td>0.039226</td>\n      <td>-0.065687</td>\n      <td>-0.004942</td>\n      <td>-0.011601</td>\n      <td>-0.016082</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.331260</td>\n      <td>67.526064</td>\n      <td>67.904703</td>\n      <td>19.526248</td>\n      <td>2.883850</td>\n      <td>0.724048</td>\n      <td>-0.611290</td>\n      <td>-1.007119</td>\n      <td>-0.471325</td>\n      <td>1.782405</td>\n      <td>...</td>\n      <td>0.011313</td>\n      <td>0.048344</td>\n      <td>-0.064803</td>\n      <td>0.051981</td>\n      <td>-0.056875</td>\n      <td>0.061396</td>\n      <td>-0.081542</td>\n      <td>0.009957</td>\n      <td>-0.023760</td>\n      <td>-0.019310</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>66.507411</td>\n      <td>69.358972</td>\n      <td>68.845433</td>\n      <td>19.399284</td>\n      <td>2.811633</td>\n      <td>0.728870</td>\n      <td>-0.631538</td>\n      <td>-1.076715</td>\n      <td>-0.451683</td>\n      <td>-3.475203</td>\n      <td>...</td>\n      <td>0.013055</td>\n      <td>0.040612</td>\n      <td>-0.042918</td>\n      <td>0.033450</td>\n      <td>-0.043966</td>\n      <td>0.053377</td>\n      <td>-0.073200</td>\n      <td>0.002332</td>\n      <td>-0.021755</td>\n      <td>-0.003223</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>71.500586</td>\n      <td>69.600473</td>\n      <td>69.015425</td>\n      <td>19.518971</td>\n      <td>2.844739</td>\n      <td>0.706509</td>\n      <td>-0.610843</td>\n      <td>-1.008555</td>\n      <td>-0.438800</td>\n      <td>-1.080058</td>\n      <td>...</td>\n      <td>0.004456</td>\n      <td>0.042616</td>\n      <td>-0.047597</td>\n      <td>0.025825</td>\n      <td>-0.031552</td>\n      <td>0.048798</td>\n      <td>-0.093202</td>\n      <td>0.026254</td>\n      <td>-0.038423</td>\n      <td>-0.005951</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 73 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest - 1000x random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHqWY1rsf1N1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 1000 - 10.00189733505249 s\n",
      "Accuracy 0.9278501390311723 precision 0.9280582765249591 specificity 0.874974256532364 recall 0.9278501390311723 f1 0.9279498539371704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 1000 - 9.824832677841187 s\n",
      "Accuracy 0.9341431289331187 precision 0.9337910071109814 specificity 0.8787596809327278 recall 0.9341431289331187 f1 0.9339464157902667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 1000 - 9.768711566925049 s\n",
      "Accuracy 0.9298990194643642 precision 0.9293954349414173 specificity 0.8621738619189023 recall 0.9298990194643642 f1 0.9296142078279875\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 1000 - 9.817463874816895 s\n",
      "Accuracy 0.9296063222596225 precision 0.9299210164245244 specificity 0.8758431235949137 recall 0.9296063222596225 f1 0.9297542226691559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "5 of 1000 - 9.885002374649048 s\n",
      "Accuracy 0.9250695155861262 precision 0.9247002018836469 specificity 0.8596442456306258 recall 0.9250695155861262 f1 0.9248697680560305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "6 of 1000 - 9.852041721343994 s\n",
      "Accuracy 0.931947899897556 precision 0.9317890694038047 specificity 0.8748987310547964 recall 0.931947899897556 f1 0.9318652848472799\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 1000 - 9.710401773452759 s\n",
      "Accuracy 0.9373627981852773 precision 0.9373627981852773 specificity 0.8905806710154149 recall 0.9373627981852773 f1 0.9373627981852773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 1000 - 9.819992542266846 s\n",
      "Accuracy 0.9315088540904435 precision 0.9316036962074538 specificity 0.8750347187575978 recall 0.9315088540904435 f1 0.9315553193465463\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 1000 - 9.498509407043457 s\n",
      "Accuracy 0.9332650373188937 precision 0.9333835353716615 specificity 0.8825587596888135 recall 0.9332650373188937 f1 0.9333226096615289\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 1000 - 9.693103075027466 s\n",
      "Accuracy 0.9322405971022977 precision 0.9321668429025353 specificity 0.8761493755980815 recall 0.9322405971022977 f1 0.9322030584131117\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 1000 - 9.830089807510376 s\n",
      "Accuracy 0.9307771110785892 precision 0.9310551766090083 specificity 0.8767754358825206 recall 0.9307771110785892 f1 0.930908533750621\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 1000 - 9.760376453399658 s\n",
      "Accuracy 0.9325332943070394 precision 0.9326450210071688 specificity 0.8752400936731205 recall 0.9325332943070394 f1 0.9325878441942637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 1000 - 9.853482246398926 s\n",
      "Accuracy 0.9294599736572515 precision 0.9291467199746611 specificity 0.8695368014358845 recall 0.9294599736572515 f1 0.9292906338254158\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 1000 - 9.732926607131958 s\n",
      "Accuracy 0.9316552026928143 precision 0.9320929378858789 specificity 0.8827132854679145 recall 0.9316552026928143 f1 0.9318550796296068\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 1000 - 9.79202151298523 s\n",
      "Accuracy 0.933850431728377 precision 0.9337361608071494 specificity 0.8782342358719049 recall 0.933850431728377 f1 0.9337915937708111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 1000 - 10.138428688049316 s\n",
      "Accuracy 0.936631055173423 precision 0.9369326703613043 specificity 0.8840734655467516 recall 0.936631055173423 f1 0.9367720773265192\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 1000 - 10.36873197555542 s\n",
      "Accuracy 0.9360456607639397 precision 0.935560883357551 specificity 0.877597886708242 recall 0.9360456607639397 f1 0.9357582648296059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 1000 - 9.925067901611328 s\n",
      "Accuracy 0.9285818820430265 precision 0.9287152379883926 specificity 0.8694540980967578 recall 0.9285818820430265 f1 0.9286468685053545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 1000 - 8.935914039611816 s\n",
      "Accuracy 0.9307771110785892 precision 0.9312624072632019 specificity 0.8802919539556321 recall 0.9307771110785892 f1 0.9309977890882658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 1000 - 9.1016845703125 s\n",
      "Accuracy 0.9282891848382848 precision 0.9285302232634077 specificity 0.8690968363140645 recall 0.9282891848382848 f1 0.9284045158253125\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 1000 - 9.106974124908447 s\n",
      "Accuracy 0.931947899897556 precision 0.9319041451297952 specificity 0.8779075456162929 recall 0.931947899897556 f1 0.9319257864605802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 1000 - 8.961687326431274 s\n",
      "Accuracy 0.9315088540904435 precision 0.9318653318359543 specificity 0.8803891566836852 recall 0.9315088540904435 f1 0.931674413671333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 1000 - 9.081544876098633 s\n",
      "Accuracy 0.9304844138738475 precision 0.9304990588533888 specificity 0.8786146958345703 recall 0.9304844138738475 f1 0.9304917105120901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 1000 - 9.162007808685303 s\n",
      "Accuracy 0.9268256988145763 precision 0.9273813651697502 specificity 0.8756007510117072 recall 0.9268256988145763 f1 0.9270772177176441\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 1000 - 9.083798885345459 s\n",
      "Accuracy 0.929020927850139 precision 0.9295242345562997 specificity 0.8758324745493549 recall 0.929020927850139 f1 0.9292505801137716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 1000 - 9.018110275268555 s\n",
      "Accuracy 0.9372164495829065 precision 0.9369414191412988 specificity 0.8803736636574165 recall 0.9372164495829065 f1 0.9370670039301754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 1000 - 8.93617844581604 s\n",
      "Accuracy 0.9312161568857017 precision 0.9315019433177638 specificity 0.8801072368696139 recall 0.9312161568857017 f1 0.9313505946198491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 1000 - 9.030396699905396 s\n",
      "Accuracy 0.9344358261378604 precision 0.9344358261378604 specificity 0.8833898778779457 recall 0.9344358261378604 f1 0.9344358261378604\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 1000 - 9.045031547546387 s\n",
      "Accuracy 0.9318015512951852 precision 0.9323699806480696 specificity 0.8833527033682297 recall 0.9318015512951852 f1 0.9320555702424618\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 1000 - 9.057027578353882 s\n",
      "Accuracy 0.93092345968096 precision 0.9312101088175739 specificity 0.8796610927338896 recall 0.93092345968096 f1 0.9310583366420012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 1000 - 9.068873405456543 s\n",
      "Accuracy 0.9331186887165227 precision 0.933381370063503 specificity 0.883156377137247 recall 0.9331186887165227 f1 0.9332424500734364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 1000 - 8.89774775505066 s\n",
      "Accuracy 0.9291672764525098 precision 0.9290495825910224 specificity 0.8733257786589991 recall 0.9291672764525098 f1 0.9291067667713138\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 1000 - 9.011648178100586 s\n",
      "Accuracy 0.9325332943070394 precision 0.9329691847303104 specificity 0.8836752857207687 recall 0.9325332943070394 f1 0.9327321637372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 1000 - 9.063039302825928 s\n",
      "Accuracy 0.9255085613932387 precision 0.9250209970714665 specificity 0.859148292726822 recall 0.9255085613932387 f1 0.9252361910423712\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 1000 - 9.024146795272827 s\n",
      "Accuracy 0.9332650373188937 precision 0.9331774738837064 specificity 0.87710615042872 recall 0.9332650373188937 f1 0.9332202978353736\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "36 of 1000 - 9.400002479553223 s\n",
      "Accuracy 0.9269720474169472 precision 0.9265619835466674 specificity 0.8601780492544985 recall 0.9269720474169472 f1 0.9267476630140772\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 1000 - 9.098661422729492 s\n",
      "Accuracy 0.9249231669837553 precision 0.9250038721480922 specificity 0.868864432814254 recall 0.9249231669837553 f1 0.9249628793062334\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 1000 - 9.110531568527222 s\n",
      "Accuracy 0.9253622127908678 precision 0.9253305386802558 specificity 0.8676235955871403 recall 0.9253622127908678 f1 0.9253462727405528\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 1000 - 8.869863033294678 s\n",
      "Accuracy 0.9313625054880725 precision 0.9312636931874786 specificity 0.878389625512376 recall 0.9313625054880725 f1 0.9313118262350532\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 1000 - 8.959386825561523 s\n",
      "Accuracy 0.9361920093663105 precision 0.9362211114842508 specificity 0.8828469836347959 recall 0.9361920093663105 f1 0.9362064530461023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 1000 - 8.996213912963867 s\n",
      "Accuracy 0.9348748719449729 precision 0.9345539545216229 specificity 0.8789556174218149 recall 0.9348748719449729 f1 0.9346978234368539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 1000 - 9.025007009506226 s\n",
      "Accuracy 0.9253622127908678 precision 0.9252122431248733 specificity 0.8687411626180969 recall 0.9253622127908678 f1 0.9252846721261522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 1000 - 8.369375228881836 s\n",
      "Accuracy 0.930045368066735 precision 0.9300143448006302 specificity 0.8720443284034743 recall 0.930045368066735 f1 0.9300297508550641\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "44 of 1000 - 8.378110647201538 s\n",
      "Accuracy 0.9335577345236353 precision 0.9342883530566375 specificity 0.8896580797027247 recall 0.9335577345236353 f1 0.9338726836574297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 1000 - 8.383191585540771 s\n",
      "Accuracy 0.93092345968096 precision 0.9308368219883152 specificity 0.8767671713065959 recall 0.93092345968096 f1 0.9308792026000852\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 1000 - 8.218733072280884 s\n",
      "Accuracy 0.9297526708619933 precision 0.9304501846979838 specificity 0.8808779574157024 recall 0.9297526708619933 f1 0.9300598887200593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 1000 - 8.188642024993896 s\n",
      "Accuracy 0.9298990194643642 precision 0.9298826353370505 specificity 0.8674127854796801 recall 0.9298990194643642 f1 0.9298908005554232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 1000 - 8.336332559585571 s\n",
      "Accuracy 0.9344358261378604 precision 0.9343821133567045 specificity 0.8853870993413258 recall 0.9344358261378604 f1 0.9344085537691039\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "49 of 1000 - 8.321508646011353 s\n",
      "Accuracy 0.9306307624762183 precision 0.9307219634502378 specificity 0.8779138351100131 recall 0.9306307624762183 f1 0.9306754260284114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "50 of 1000 - 8.258133172988892 s\n",
      "Accuracy 0.9323869457046685 precision 0.9323288229038139 specificity 0.8779788184070899 recall 0.9323869457046685 f1 0.9323574632564396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 1000 - 8.475523948669434 s\n",
      "Accuracy 0.9329723401141519 precision 0.9335809853630863 specificity 0.8841448892215749 recall 0.9329723401141519 f1 0.9332424880063963\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "52 of 1000 - 8.444105625152588 s\n",
      "Accuracy 0.929020927850139 precision 0.9290656121074835 specificity 0.8772826875345665 recall 0.929020927850139 f1 0.9290430389117948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 1000 - 8.362542390823364 s\n",
      "Accuracy 0.9342894775354895 precision 0.935188707211183 specificity 0.8924007247540822 recall 0.9342894775354895 f1 0.9346659640864364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 1000 - 8.435372352600098 s\n",
      "Accuracy 0.9310698082833309 precision 0.931382535420563 specificity 0.877342565973066 recall 0.9310698082833309 f1 0.9312166509735498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 1000 - 8.157092094421387 s\n",
      "Accuracy 0.9334113859212645 precision 0.9333672012836676 specificity 0.877872137828881 recall 0.9334113859212645 f1 0.9333890542007919\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 1000 - 8.364436626434326 s\n",
      "Accuracy 0.935752963559198 precision 0.9359468357800219 specificity 0.8858712124721678 recall 0.935752963559198 f1 0.9358454136294758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "57 of 1000 - 8.307982921600342 s\n",
      "Accuracy 0.9285818820430265 precision 0.9286753502892632 specificity 0.8746054512259869 recall 0.9285818820430265 f1 0.9286276843466145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "58 of 1000 - 8.370417594909668 s\n",
      "Accuracy 0.9350212205473438 precision 0.934749705100264 specificity 0.877013276819289 recall 0.9350212205473438 f1 0.9348747149547526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "59 of 1000 - 8.316956281661987 s\n",
      "Accuracy 0.930045368066735 precision 0.9307120940342513 specificity 0.8849379156292688 recall 0.930045368066735 f1 0.9303377839049501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "60 of 1000 - 8.294154405593872 s\n",
      "Accuracy 0.9310698082833309 precision 0.9314817653070842 specificity 0.8800145791577797 recall 0.9310698082833309 f1 0.9312594304698555\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "61 of 1000 - 8.279693365097046 s\n",
      "Accuracy 0.9234596809600468 precision 0.9234756430100668 specificity 0.8672028717977848 recall 0.9234596809600468 f1 0.9234676365755129\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "62 of 1000 - 8.397594928741455 s\n",
      "Accuracy 0.9265330016098346 precision 0.9263251764305609 specificity 0.8683767993887437 recall 0.9265330016098346 f1 0.9264240310659696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "63 of 1000 - 8.342755794525146 s\n",
      "Accuracy 0.9348748719449729 precision 0.9351008886834625 specificity 0.8854200282377868 recall 0.9348748719449729 f1 0.9349819416475837\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "64 of 1000 - 8.226465940475464 s\n",
      "Accuracy 0.9318015512951852 precision 0.9314194511045961 specificity 0.8711722298291332 recall 0.9318015512951852 f1 0.9315896589469536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "65 of 1000 - 8.405684471130371 s\n",
      "Accuracy 0.9307771110785892 precision 0.9307316568626779 specificity 0.874027030736792 recall 0.9307771110785892 f1 0.9307541467847794\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "66 of 1000 - 8.319052696228027 s\n",
      "Accuracy 0.928142836235914 precision 0.9284522998506164 specificity 0.876369040392203 recall 0.928142836235914 f1 0.9282882675701674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "67 of 1000 - 8.316646814346313 s\n",
      "Accuracy 0.9369237523781648 precision 0.9370569261877935 specificity 0.8853042094958926 recall 0.9369237523781648 f1 0.9369881628955345\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "68 of 1000 - 8.386051893234253 s\n",
      "Accuracy 0.9344358261378604 precision 0.9344358261378604 specificity 0.8817181565767279 recall 0.9344358261378604 f1 0.9344358261378604\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "69 of 1000 - 8.351013422012329 s\n",
      "Accuracy 0.9315088540904435 precision 0.9317908285539669 specificity 0.8814300671784272 recall 0.9315088540904435 f1 0.9316414090664354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "70 of 1000 - 8.393611907958984 s\n",
      "Accuracy 0.929020927850139 precision 0.9289748588003656 specificity 0.8719038992896194 recall 0.929020927850139 f1 0.928997657964732\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "71 of 1000 - 8.4199800491333 s\n",
      "Accuracy 0.9263866530074638 precision 0.9264686358272509 specificity 0.8682956938629935 recall 0.9263866530074638 f1 0.9264269946257508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "72 of 1000 - 8.363386631011963 s\n",
      "Accuracy 0.9238987267671593 precision 0.9238311330793728 specificity 0.8598117954583848 recall 0.9238987267671593 f1 0.9238645118740204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "73 of 1000 - 8.293530941009521 s\n",
      "Accuracy 0.9318015512951852 precision 0.9323014793863199 specificity 0.8818246346584658 recall 0.9318015512951852 f1 0.9320279073937733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "74 of 1000 - 8.533101797103882 s\n",
      "Accuracy 0.9332650373188937 precision 0.9334757918843642 specificity 0.884012742604982 recall 0.9332650373188937 f1 0.9333652947440694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "75 of 1000 - 8.311543941497803 s\n",
      "Accuracy 0.9325332943070394 precision 0.9324284279213699 specificity 0.8739756751579121 recall 0.9325332943070394 f1 0.9324795506368797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "76 of 1000 - 8.392038345336914 s\n",
      "Accuracy 0.931947899897556 precision 0.932505767467617 specificity 0.8820487183024904 recall 0.931947899897556 f1 0.9321982044301629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "77 of 1000 - 8.373461246490479 s\n",
      "Accuracy 0.9313625054880725 precision 0.9312337117389387 specificity 0.8763216037805186 recall 0.9313625054880725 f1 0.9312959883325845\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "78 of 1000 - 8.373562812805176 s\n",
      "Accuracy 0.931947899897556 precision 0.9324846730973401 specificity 0.8853186689869021 recall 0.931947899897556 f1 0.9321880576031989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "79 of 1000 - 8.466809272766113 s\n",
      "Accuracy 0.9288745792477682 precision 0.9297450039560006 specificity 0.8802660304371431 recall 0.9288745792477682 f1 0.9292500633693003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "80 of 1000 - 8.380002737045288 s\n",
      "Accuracy 0.9272647446216888 precision 0.92734736575438 specificity 0.8680831191591828 recall 0.9272647446216888 f1 0.9273053998051132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "81 of 1000 - 8.363631010055542 s\n",
      "Accuracy 0.9345821747402312 precision 0.9344340330189177 specificity 0.8819234371493073 recall 0.9345821747402312 f1 0.9345049178255808\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "82 of 1000 - 8.278368473052979 s\n",
      "Accuracy 0.9315088540904435 precision 0.9314188387884106 specificity 0.8738197848499955 recall 0.9315088540904435 f1 0.9314628918373429\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "83 of 1000 - 8.497062683105469 s\n",
      "Accuracy 0.9279964876335431 precision 0.9285729095508551 specificity 0.8794132849561611 recall 0.9279964876335431 f1 0.928255096010981\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "84 of 1000 - 8.411031723022461 s\n",
      "Accuracy 0.9263866530074638 precision 0.9269510750196488 specificity 0.8770619422957692 recall 0.9263866530074638 f1 0.9266411363623792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "85 of 1000 - 8.40355396270752 s\n",
      "Accuracy 0.9337040831260062 precision 0.9333417411889005 specificity 0.873848924558572 recall 0.9337040831260062 f1 0.9335033866298539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "86 of 1000 - 8.258648157119751 s\n",
      "Accuracy 0.9363383579686814 precision 0.9361428291184071 specificity 0.8833860064472346 recall 0.9363383579686814 f1 0.9362346182338023\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "87 of 1000 - 8.318374395370483 s\n",
      "Accuracy 0.9313625054880725 precision 0.9324906777275107 specificity 0.8898046095564477 recall 0.9313625054880725 f1 0.9318244781418727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "88 of 1000 - 8.262665748596191 s\n",
      "Accuracy 0.9304844138738475 precision 0.9307245315233635 specificity 0.8775551734076855 recall 0.9304844138738475 f1 0.9305985891610983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "89 of 1000 - 8.31072449684143 s\n",
      "Accuracy 0.9266793502122055 precision 0.9266020798529359 specificity 0.8691365146138847 recall 0.9266793502122055 f1 0.9266400684444527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "90 of 1000 - 8.34704041481018 s\n",
      "Accuracy 0.9382408897995024 precision 0.938351154721037 specificity 0.8912256305204433 recall 0.9382408897995024 f1 0.9382943269596783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "91 of 1000 - 8.30399227142334 s\n",
      "Accuracy 0.932825991511781 precision 0.9326438726147399 specificity 0.8768915039726654 recall 0.932825991511781 f1 0.9327304669053229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "92 of 1000 - 8.646049737930298 s\n",
      "Accuracy 0.9334113859212645 precision 0.9336446131555463 specificity 0.8818905966829542 recall 0.9334113859212645 f1 0.9335220561388431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "93 of 1000 - 8.584028720855713 s\n",
      "Accuracy 0.9335577345236353 precision 0.9333434840793982 specificity 0.8794516070849431 recall 0.9335577345236353 f1 0.9334438812046617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "94 of 1000 - 8.508052825927734 s\n",
      "Accuracy 0.9278501390311723 precision 0.9275001699787057 specificity 0.8688109260087017 recall 0.9278501390311723 f1 0.9276589436195104\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "95 of 1000 - 8.55294680595398 s\n",
      "Accuracy 0.9258012585979803 precision 0.9257854404975242 specificity 0.86843718964085 recall 0.9258012585979803 f1 0.9257933237686052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "96 of 1000 - 8.499540090560913 s\n",
      "Accuracy 0.9331186887165227 precision 0.9331902576780332 specificity 0.8838335415328968 recall 0.9331186887165227 f1 0.9331538238289376\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "97 of 1000 - 8.654090642929077 s\n",
      "Accuracy 0.9341431289331187 precision 0.93385017435234 specificity 0.877208895226007 recall 0.9341431289331187 f1 0.9339837799617895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "98 of 1000 - 8.57683277130127 s\n",
      "Accuracy 0.9312161568857017 precision 0.9309285074326977 specificity 0.8704363514613672 recall 0.9312161568857017 f1 0.9310616847875721\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "99 of 1000 - 8.54109811782837 s\n",
      "Accuracy 0.9304844138738475 precision 0.930851372291659 specificity 0.8814691646007208 recall 0.9304844138738475 f1 0.9306542244701576\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "100 of 1000 - 8.34600830078125 s\n",
      "Accuracy 0.9313625054880725 precision 0.9314699813378984 specificity 0.8779606171660322 recall 0.9313625054880725 f1 0.9314149589579221\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "101 of 1000 - 8.364670276641846 s\n",
      "Accuracy 0.930045368066735 precision 0.9296817367961893 specificity 0.8693572892938214 recall 0.930045368066735 f1 0.9298457228992887\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "102 of 1000 - 8.541774272918701 s\n",
      "Accuracy 0.928142836235914 precision 0.9279253247900314 specificity 0.8707264941896125 recall 0.928142836235914 f1 0.928028247332391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "103 of 1000 - 9.04525637626648 s\n",
      "Accuracy 0.9326796429094102 precision 0.9326501794134018 specificity 0.8779433614377469 recall 0.9326796429094102 f1 0.9326648054807359\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "104 of 1000 - 8.979238033294678 s\n",
      "Accuracy 0.931947899897556 precision 0.9318752113457645 specificity 0.8772252560359429 recall 0.931947899897556 f1 0.9319108987486681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "105 of 1000 - 9.067495584487915 s\n",
      "Accuracy 0.9351675691497147 precision 0.9356152557497596 specificity 0.8900692148094194 recall 0.9351675691497147 f1 0.9353694238543139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "106 of 1000 - 8.89910888671875 s\n",
      "Accuracy 0.9323869457046685 precision 0.9320430491017572 specificity 0.8750071004230864 recall 0.9323869457046685 f1 0.9321971870337535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "107 of 1000 - 8.981994390487671 s\n",
      "Accuracy 0.9306307624762183 precision 0.9306307624762183 specificity 0.875024320452325 recall 0.9306307624762183 f1 0.9306307624762183\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "108 of 1000 - 9.134806632995605 s\n",
      "Accuracy 0.9326796429094102 precision 0.9323863161630257 specificity 0.8764607362616958 recall 0.9326796429094102 f1 0.9325202440277681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "109 of 1000 - 8.892765045166016 s\n",
      "Accuracy 0.9275574418264305 precision 0.9275117881719066 specificity 0.87189147994311 recall 0.9275574418264305 f1 0.9275343826724028\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "110 of 1000 - 9.063497066497803 s\n",
      "Accuracy 0.9278501390311723 precision 0.9279985574919537 specificity 0.8704962796926164 recall 0.9278501390311723 f1 0.9279222290587243\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "111 of 1000 - 9.069177627563477 s\n",
      "Accuracy 0.9277037904288014 precision 0.927209882887326 specificity 0.8610323303248661 recall 0.9277037904288014 f1 0.9274261344488889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "112 of 1000 - 9.053279876708984 s\n",
      "Accuracy 0.93092345968096 precision 0.931179501430648 specificity 0.8783230950303923 recall 0.93092345968096 f1 0.9310447760878279\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "113 of 1000 - 9.22551155090332 s\n",
      "Accuracy 0.9342894775354895 precision 0.9335662248354996 specificity 0.8689532646111526 recall 0.9342894775354895 f1 0.9338138878690092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "114 of 1000 - 9.228999853134155 s\n",
      "Accuracy 0.9304844138738475 precision 0.9302963579581782 specificity 0.8730461566636976 recall 0.9304844138738475 f1 0.9303859482477248\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "115 of 1000 - 9.226288318634033 s\n",
      "Accuracy 0.933850431728377 precision 0.9349805646685873 specificity 0.8900124598937404 recall 0.933850431728377 f1 0.9343141576318765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "116 of 1000 - 9.229594945907593 s\n",
      "Accuracy 0.9318015512951852 precision 0.9319503918117888 specificity 0.8821918316659397 recall 0.9318015512951852 f1 0.9318733813322515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "117 of 1000 - 9.158104658126831 s\n",
      "Accuracy 0.9287282306453973 precision 0.9286232339821056 specificity 0.871905017184614 recall 0.9287282306453973 f1 0.9286744566290224\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "118 of 1000 - 8.982033967971802 s\n",
      "Accuracy 0.9277037904288014 precision 0.9275000829398167 specificity 0.8706867295445576 recall 0.9277037904288014 f1 0.9275968717572113\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "119 of 1000 - 9.149519681930542 s\n",
      "Accuracy 0.9298990194643642 precision 0.9299429006436949 specificity 0.8792818860975551 recall 0.9298990194643642 f1 0.9299207290338672\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "120 of 1000 - 9.404515027999878 s\n",
      "Accuracy 0.926240304405093 precision 0.9262723589491834 specificity 0.8688918928317824 recall 0.926240304405093 f1 0.9262562282096453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "121 of 1000 - 10.067352294921875 s\n",
      "Accuracy 0.926240304405093 precision 0.9269752747473702 specificity 0.8735436946072518 recall 0.926240304405093 f1 0.9265664014872669\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "122 of 1000 - 9.609048128128052 s\n",
      "Accuracy 0.9277037904288014 precision 0.9277352444932181 specificity 0.8714152132557338 recall 0.9277037904288014 f1 0.9277194136484165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "123 of 1000 - 9.656470537185669 s\n",
      "Accuracy 0.9306307624762183 precision 0.9307231215026327 specificity 0.8768417586827585 recall 0.9306307624762183 f1 0.930676000957858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "124 of 1000 - 9.683532476425171 s\n",
      "Accuracy 0.9297526708619933 precision 0.9299110459257462 specificity 0.8757196150370251 recall 0.9297526708619933 f1 0.9298292486496008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "125 of 1000 - 9.61342740058899 s\n",
      "Accuracy 0.9325332943070394 precision 0.9324603765770583 specificity 0.8772712934855806 recall 0.9325332943070394 f1 0.9324961750594862\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "126 of 1000 - 9.648619651794434 s\n",
      "Accuracy 0.9304844138738475 precision 0.9301982087981885 specificity 0.8741629863847794 recall 0.9304844138738475 f1 0.9303298254002037\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "127 of 1000 - 9.613864183425903 s\n",
      "Accuracy 0.9266793502122055 precision 0.9271102969261595 specificity 0.8730485918128773 recall 0.9266793502122055 f1 0.9268786789820205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "128 of 1000 - 9.678063154220581 s\n",
      "Accuracy 0.9323869457046685 precision 0.9319898601323672 specificity 0.8770924923004946 recall 0.9323869457046685 f1 0.9321617280873749\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "129 of 1000 - 9.69865369796753 s\n",
      "Accuracy 0.9320942484999268 precision 0.9325501759731422 specificity 0.883100685317277 recall 0.9320942484999268 f1 0.9323017233297277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "130 of 1000 - 9.541105031967163 s\n",
      "Accuracy 0.9275574418264305 precision 0.9275423301395079 specificity 0.8734093513884056 recall 0.9275574418264305 f1 0.9275498602966787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "131 of 1000 - 9.59195590019226 s\n",
      "Accuracy 0.928142836235914 precision 0.9282950442080297 specificity 0.8683165847371257 recall 0.928142836235914 f1 0.9282167977904796\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "132 of 1000 - 9.59608769416809 s\n",
      "Accuracy 0.9199473145031465 precision 0.9195051044588787 specificity 0.8558240103607373 recall 0.9199473145031465 f1 0.9197048291739336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "133 of 1000 - 9.634798288345337 s\n",
      "Accuracy 0.9323869457046685 precision 0.9321583527559762 specificity 0.8735436771342053 recall 0.9323869457046685 f1 0.9322658313657873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "134 of 1000 - 9.635360479354858 s\n",
      "Accuracy 0.9318015512951852 precision 0.9325296334270677 specificity 0.8838182529384464 recall 0.9318015512951852 f1 0.9321193898175324\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "135 of 1000 - 9.660542488098145 s\n",
      "Accuracy 0.934728523342602 precision 0.9345568667356164 specificity 0.8765418739606486 recall 0.934728523342602 f1 0.9346388125715107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "136 of 1000 - 9.62140941619873 s\n",
      "Accuracy 0.9350212205473438 precision 0.9351389540363038 specificity 0.884139105545501 recall 0.9350212205473438 f1 0.9350783930267541\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "137 of 1000 - 9.557000875473022 s\n",
      "Accuracy 0.9323869457046685 precision 0.9326826709575556 specificity 0.8875352442717482 recall 0.9323869457046685 f1 0.9325245728030498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "138 of 1000 - 9.725758075714111 s\n",
      "Accuracy 0.9323869457046685 precision 0.9323569987224134 specificity 0.8763979437922845 recall 0.9323869457046685 f1 0.9323718661550411\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "139 of 1000 - 9.716158628463745 s\n",
      "Accuracy 0.9334113859212645 precision 0.9340355877949384 specificity 0.8851072158579107 recall 0.9334113859212645 f1 0.9336873556513993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "140 of 1000 - 9.707025527954102 s\n",
      "Accuracy 0.93092345968096 precision 0.931301195727961 specificity 0.8748257987086046 recall 0.93092345968096 f1 0.9310994298166079\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "141 of 1000 - 9.624090909957886 s\n",
      "Accuracy 0.9268256988145763 precision 0.927486886999715 specificity 0.8780343311789965 recall 0.9268256988145763 f1 0.9271194314288351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "142 of 1000 - 10.336999416351318 s\n",
      "Accuracy 0.9334113859212645 precision 0.9336194207927964 specificity 0.8784470622916314 recall 0.9334113859212645 f1 0.9335108788637226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "143 of 1000 - 9.725040197372437 s\n",
      "Accuracy 0.9296063222596225 precision 0.929532855970865 specificity 0.8750729842078689 recall 0.9296063222596225 f1 0.9295689406134782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "144 of 1000 - 9.71852159500122 s\n",
      "Accuracy 0.9341431289331187 precision 0.933958786606318 specificity 0.8820216392145929 recall 0.9341431289331187 f1 0.9340458289100685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "145 of 1000 - 9.701998949050903 s\n",
      "Accuracy 0.9274110932240597 precision 0.9275732930358908 specificity 0.8721952676401054 recall 0.9274110932240597 f1 0.9274896027958821\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "146 of 1000 - 9.635042667388916 s\n",
      "Accuracy 0.9332650373188937 precision 0.9340327843823005 specificity 0.885266810342211 recall 0.9332650373188937 f1 0.9335977038352136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "147 of 1000 - 9.564527034759521 s\n",
      "Accuracy 0.9326796429094102 precision 0.9326796429094102 specificity 0.8784668694434121 recall 0.9326796429094102 f1 0.9326796429094102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "148 of 1000 - 9.647512197494507 s\n",
      "Accuracy 0.9260939558027221 precision 0.9257895929819352 specificity 0.8669389966238558 recall 0.9260939558027221 f1 0.9259304083119783\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "149 of 1000 - 9.474045515060425 s\n",
      "Accuracy 0.9360456607639397 precision 0.9360034562295868 specificity 0.8830821350007598 recall 0.9360456607639397 f1 0.9360243182114626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "150 of 1000 - 9.5660240650177 s\n",
      "Accuracy 0.9301917166691058 precision 0.9299522452107205 specificity 0.8732186794678074 recall 0.9301917166691058 f1 0.9300644315896249\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "151 of 1000 - 9.510000944137573 s\n",
      "Accuracy 0.930045368066735 precision 0.9301383979366641 specificity 0.8758752957275607 recall 0.930045368066735 f1 0.93009094341207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "152 of 1000 - 9.463044881820679 s\n",
      "Accuracy 0.9323869457046685 precision 0.9326246987475737 specificity 0.8853913321209979 recall 0.9323869457046685 f1 0.9324992240047758\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "153 of 1000 - 9.97504186630249 s\n",
      "Accuracy 0.9323869457046685 precision 0.9324469266896005 specificity 0.8791476910736894 recall 0.9323869457046685 f1 0.9324165154235072\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "154 of 1000 - 9.706000804901123 s\n",
      "Accuracy 0.9334113859212645 precision 0.9336127247984847 specificity 0.8812816793769431 recall 0.9334113859212645 f1 0.9335075846720025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "155 of 1000 - 9.553560733795166 s\n",
      "Accuracy 0.9263866530074638 precision 0.9265414016095082 specificity 0.8657074869934843 recall 0.9263866530074638 f1 0.9264618980481217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "156 of 1000 - 9.64504861831665 s\n",
      "Accuracy 0.9296063222596225 precision 0.9297879077498196 specificity 0.8723940652411829 recall 0.9296063222596225 f1 0.9296939182147036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "157 of 1000 - 9.739105701446533 s\n",
      "Accuracy 0.9339967803307478 precision 0.9342341283371047 specificity 0.8807578134737756 recall 0.9339967803307478 f1 0.9341094471818883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "158 of 1000 - 9.8331458568573 s\n",
      "Accuracy 0.9272647446216888 precision 0.9273773643663251 specificity 0.8714543218793623 recall 0.9272647446216888 f1 0.9273197850347974\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "159 of 1000 - 9.600000381469727 s\n",
      "Accuracy 0.9284355334406557 precision 0.9286109986084511 specificity 0.8747516840196141 recall 0.9284355334406557 f1 0.9285201325323832\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "160 of 1000 - 9.723999977111816 s\n",
      "Accuracy 0.9297526708619933 precision 0.9297526708619933 specificity 0.8748079623924454 recall 0.9297526708619933 f1 0.9297526708619933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "161 of 1000 - 10.31056547164917 s\n",
      "Accuracy 0.930045368066735 precision 0.9294143082754867 specificity 0.8658476675742307 recall 0.930045368066735 f1 0.9296636986984895\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "162 of 1000 - 10.04602575302124 s\n",
      "Accuracy 0.9320942484999268 precision 0.9321892232064946 specificity 0.8752454447176654 recall 0.9320942484999268 f1 0.9321407754911474\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "163 of 1000 - 9.688066482543945 s\n",
      "Accuracy 0.9335577345236353 precision 0.9332125986425408 specificity 0.8752032360716518 recall 0.9335577345236353 f1 0.9333671759556647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "164 of 1000 - 9.821999311447144 s\n",
      "Accuracy 0.9303380652714767 precision 0.9305630710961028 specificity 0.8766518375189131 recall 0.9303380652714767 f1 0.930445433899115\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "165 of 1000 - 9.203927278518677 s\n",
      "Accuracy 0.93092345968096 precision 0.9312023682404528 specificity 0.8819551936382585 recall 0.93092345968096 f1 0.9310545470253957\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "166 of 1000 - 8.870125532150269 s\n",
      "Accuracy 0.93092345968096 precision 0.9310450393286803 specificity 0.8790265583353868 recall 0.93092345968096 f1 0.9309825852066879\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "167 of 1000 - 9.109513282775879 s\n",
      "Accuracy 0.9224352407434508 precision 0.9227584120341602 specificity 0.8632860878959308 recall 0.9224352407434508 f1 0.9225884926663217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "168 of 1000 - 9.003001689910889 s\n",
      "Accuracy 0.9266793502122055 precision 0.9270668596794731 specificity 0.8742129733869054 recall 0.9266793502122055 f1 0.9268595143875782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "169 of 1000 - 8.977050065994263 s\n",
      "Accuracy 0.9325332943070394 precision 0.9327387261604279 specificity 0.8790144713659126 recall 0.9325332943070394 f1 0.9326315352688865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "170 of 1000 - 8.884998798370361 s\n",
      "Accuracy 0.9332650373188937 precision 0.9334142056480829 specificity 0.882913378503022 recall 0.9332650373188937 f1 0.9333370027471876\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "171 of 1000 - 8.832459211349487 s\n",
      "Accuracy 0.932825991511781 precision 0.9330242091484877 specificity 0.88222762025002 recall 0.932825991511781 f1 0.9329206731034533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "172 of 1000 - 9.024070978164673 s\n",
      "Accuracy 0.9313625054880725 precision 0.9315318983873956 specificity 0.8795689541101718 recall 0.9313625054880725 f1 0.9314440445049906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "173 of 1000 - 8.858032941818237 s\n",
      "Accuracy 0.9363383579686814 precision 0.9366500268980413 specificity 0.8903530136213749 recall 0.9363383579686814 f1 0.9364825964809387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "174 of 1000 - 8.925015211105347 s\n",
      "Accuracy 0.9306307624762183 precision 0.9302112124290254 specificity 0.8720263015529013 recall 0.9306307624762183 f1 0.9303941898365611\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "175 of 1000 - 8.96513557434082 s\n",
      "Accuracy 0.935752963559198 precision 0.9357671837635128 specificity 0.8839973598171518 recall 0.935752963559198 f1 0.9357600470863192\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "176 of 1000 - 8.85247540473938 s\n",
      "Accuracy 0.9287282306453973 precision 0.9284963948290982 specificity 0.865333462420183 recall 0.9287282306453973 f1 0.9286063289265033\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "177 of 1000 - 9.033527135848999 s\n",
      "Accuracy 0.9274110932240597 precision 0.9268962417879376 specificity 0.8613283765958646 recall 0.9274110932240597 f1 0.9271193976889184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "178 of 1000 - 9.081009864807129 s\n",
      "Accuracy 0.9291672764525098 precision 0.9292301294263453 specificity 0.873264967728139 recall 0.9291672764525098 f1 0.9291982847968131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "179 of 1000 - 8.856552839279175 s\n",
      "Accuracy 0.9310698082833309 precision 0.9313082444240306 specificity 0.8785319267182016 recall 0.9310698082833309 f1 0.9311831337438471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "180 of 1000 - 8.985993146896362 s\n",
      "Accuracy 0.9325332943070394 precision 0.9327938965303574 specificity 0.883433569953699 recall 0.9325332943070394 f1 0.9326560682731082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "181 of 1000 - 8.80888843536377 s\n",
      "Accuracy 0.935752963559198 precision 0.9361391101260459 specificity 0.8886201145524338 recall 0.935752963559198 f1 0.9359295284900286\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "182 of 1000 - 9.25855803489685 s\n",
      "Accuracy 0.9323869457046685 precision 0.9322386358130015 specificity 0.8732932007949755 recall 0.9323869457046685 f1 0.9323101168112514\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "183 of 1000 - 8.95093846321106 s\n",
      "Accuracy 0.9278501390311723 precision 0.9290733014158395 specificity 0.8797745250946113 recall 0.9278501390311723 f1 0.92835877417733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "184 of 1000 - 9.049503087997437 s\n",
      "Accuracy 0.9335577345236353 precision 0.9337127123818568 specificity 0.8798876706338306 recall 0.9335577345236353 f1 0.9336325630561766\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "185 of 1000 - 9.12008023262024 s\n",
      "Accuracy 0.929020927850139 precision 0.9290668927562982 specificity 0.8749083573158483 recall 0.929020927850139 f1 0.9290436770365634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "186 of 1000 - 9.157829284667969 s\n",
      "Accuracy 0.9369237523781648 precision 0.9367482449421624 specificity 0.8818812044119227 recall 0.9369237523781648 f1 0.9368314491070409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "187 of 1000 - 9.064793586730957 s\n",
      "Accuracy 0.9348748719449729 precision 0.9350673506206914 specificity 0.8859063406716274 recall 0.9348748719449729 f1 0.9349666656449603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "188 of 1000 - 9.037062644958496 s\n",
      "Accuracy 0.9268256988145763 precision 0.9269524182701929 specificity 0.8730185644490419 recall 0.9268256988145763 f1 0.9268874160200546\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "189 of 1000 - 9.371218919754028 s\n",
      "Accuracy 0.9316552026928143 precision 0.931579900536417 specificity 0.8740475419744761 recall 0.9316552026928143 f1 0.9316168880563565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "190 of 1000 - 9.25597882270813 s\n",
      "Accuracy 0.9323869457046685 precision 0.9325365544694599 specificity 0.8821341048761122 recall 0.9323869457046685 f1 0.9324591447560957\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "191 of 1000 - 9.131035089492798 s\n",
      "Accuracy 0.9310698082833309 precision 0.9309679505397856 specificity 0.8757283307976598 recall 0.9310698082833309 f1 0.9310175958938662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "192 of 1000 - 9.364000797271729 s\n",
      "Accuracy 0.9323869457046685 precision 0.9328028586910493 specificity 0.8838904841273335 recall 0.9323869457046685 f1 0.9325772653623566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "193 of 1000 - 9.252426862716675 s\n",
      "Accuracy 0.9326796429094102 precision 0.9332872573619467 specificity 0.8840771709888035 recall 0.9326796429094102 f1 0.9329493662399855\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "194 of 1000 - 8.975998878479004 s\n",
      "Accuracy 0.9339967803307478 precision 0.9338958914333436 specificity 0.8780469106561897 recall 0.9339967803307478 f1 0.9339450288345771\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "195 of 1000 - 9.216055154800415 s\n",
      "Accuracy 0.9323869457046685 precision 0.932648910349946 specificity 0.8772248185527551 recall 0.9323869457046685 f1 0.932511097396225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "196 of 1000 - 9.314011096954346 s\n",
      "Accuracy 0.9345821747402312 precision 0.9347463049935666 specificity 0.8841642050415838 recall 0.9345821747402312 f1 0.9346610454110533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "197 of 1000 - 9.266271829605103 s\n",
      "Accuracy 0.9285818820430265 precision 0.9290002897424083 specificity 0.8807684672510228 recall 0.9285818820430265 f1 0.9287738485787398\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "198 of 1000 - 9.485020160675049 s\n",
      "Accuracy 0.9326796429094102 precision 0.933262702749398 specificity 0.8817733349733945 recall 0.9326796429094102 f1 0.9329405050283995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "199 of 1000 - 9.496537208557129 s\n",
      "Accuracy 0.9279964876335431 precision 0.9281549693726099 specificity 0.874591544418821 recall 0.9279964876335431 f1 0.9280731486741008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "200 of 1000 - 9.706508874893188 s\n",
      "Accuracy 0.9318015512951852 precision 0.932019147648553 specificity 0.8804458620738926 recall 0.9318015512951852 f1 0.9319052240821327\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "201 of 1000 - 9.168002367019653 s\n",
      "Accuracy 0.9332650373188937 precision 0.9330210296511181 specificity 0.877349331362328 recall 0.9332650373188937 f1 0.9331344756250475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "202 of 1000 - 9.380924463272095 s\n",
      "Accuracy 0.9379481925947607 precision 0.9376659883593074 specificity 0.8818224451103577 recall 0.9379481925947607 f1 0.9377939907026064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "203 of 1000 - 9.239508390426636 s\n",
      "Accuracy 0.9303380652714767 precision 0.930396900088768 specificity 0.879543435623255 recall 0.9303380652714767 f1 0.9303670705706734\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "204 of 1000 - 9.40499997138977 s\n",
      "Accuracy 0.9287282306453973 precision 0.9289077785786234 specificity 0.8728911233896868 recall 0.9287282306453973 f1 0.9288148397866498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "205 of 1000 - 9.237000226974487 s\n",
      "Accuracy 0.9263866530074638 precision 0.9262389529089539 specificity 0.8615026245784101 recall 0.9263866530074638 f1 0.9263106579058215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "206 of 1000 - 9.222997665405273 s\n",
      "Accuracy 0.9287282306453973 precision 0.9284137843492358 specificity 0.8721344156506939 recall 0.9287282306453973 f1 0.9285573449923775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "207 of 1000 - 9.234999418258667 s\n",
      "Accuracy 0.9322405971022977 precision 0.9327356316764016 specificity 0.8861583174160197 recall 0.9322405971022977 f1 0.9324632524973144\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "208 of 1000 - 9.307046890258789 s\n",
      "Accuracy 0.934728523342602 precision 0.9350344723528493 specificity 0.8864123721815091 recall 0.934728523342602 f1 0.9348709706549346\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "209 of 1000 - 9.265555381774902 s\n",
      "Accuracy 0.931947899897556 precision 0.932428948870892 specificity 0.8818681114167632 recall 0.931947899897556 f1 0.9321663490297966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "210 of 1000 - 9.336523056030273 s\n",
      "Accuracy 0.9278501390311723 precision 0.9278976822531533 specificity 0.8712857329190871 recall 0.9278501390311723 f1 0.9278736765362067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "211 of 1000 - 9.906997680664062 s\n",
      "Accuracy 0.9282891848382848 precision 0.9291672195978075 specificity 0.8790295458020844 recall 0.9282891848382848 f1 0.9286685069278713\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "212 of 1000 - 9.639058351516724 s\n",
      "Accuracy 0.931947899897556 precision 0.9321356492918467 specificity 0.8859976092025528 recall 0.931947899897556 f1 0.9320374554636643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "213 of 1000 - 9.77158784866333 s\n",
      "Accuracy 0.9312161568857017 precision 0.9314633126969359 specificity 0.8815005628697337 recall 0.9312161568857017 f1 0.9313330999344265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "214 of 1000 - 10.023000001907349 s\n",
      "Accuracy 0.931947899897556 precision 0.9319622097759079 specificity 0.8813311429712022 recall 0.931947899897556 f1 0.9319550289270178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "215 of 1000 - 10.43010950088501 s\n",
      "Accuracy 0.9307771110785892 precision 0.9310056109749946 specificity 0.8819131926790326 recall 0.9307771110785892 f1 0.9308855668190396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "216 of 1000 - 9.950017213821411 s\n",
      "Accuracy 0.9278501390311723 precision 0.928028859834474 specificity 0.8727713778149533 recall 0.9278501390311723 f1 0.927936358277494\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "217 of 1000 - 10.05703067779541 s\n",
      "Accuracy 0.9296063222596225 precision 0.9292144814212685 specificity 0.8706030487057965 recall 0.9296063222596225 f1 0.9293884413185942\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "218 of 1000 - 10.037593841552734 s\n",
      "Accuracy 0.9360456607639397 precision 0.9360315278073327 specificity 0.8836867686080508 recall 0.9360456607639397 f1 0.9360385676270476\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "219 of 1000 - 10.11151123046875 s\n",
      "Accuracy 0.9306307624762183 precision 0.9301989741290526 specificity 0.8696444637572689 recall 0.9306307624762183 f1 0.9303878210679589\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "220 of 1000 - 10.134066581726074 s\n",
      "Accuracy 0.9298990194643642 precision 0.9293858881626597 specificity 0.8644520208420188 recall 0.9298990194643642 f1 0.9296058940813894\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "221 of 1000 - 10.067999839782715 s\n",
      "Accuracy 0.931947899897556 precision 0.9332631834727022 specificity 0.8968429900354105 recall 0.931947899897556 f1 0.9324635574366438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "222 of 1000 - 9.901999235153198 s\n",
      "Accuracy 0.9310698082833309 precision 0.9315158687140376 specificity 0.8807018300157127 recall 0.9310698082833309 f1 0.93127379411226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "223 of 1000 - 9.805023431777954 s\n",
      "Accuracy 0.935752963559198 precision 0.9352861462634723 specificity 0.8744635340185318 recall 0.935752963559198 f1 0.9354824465358316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "224 of 1000 - 9.814549922943115 s\n",
      "Accuracy 0.9325332943070394 precision 0.9327425181244525 specificity 0.877407772443366 recall 0.9325332943070394 f1 0.9326334013472886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "225 of 1000 - 9.688038110733032 s\n",
      "Accuracy 0.933850431728377 precision 0.934401830866423 specificity 0.8873865710773665 recall 0.933850431728377 f1 0.9340958499229877\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "226 of 1000 - 9.820508241653442 s\n",
      "Accuracy 0.9360456607639397 precision 0.9362044426461761 specificity 0.8877231128983045 recall 0.9360456607639397 f1 0.9361218609729303\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "227 of 1000 - 9.684509754180908 s\n",
      "Accuracy 0.9279964876335431 precision 0.9289169112262853 specificity 0.8791048430354886 recall 0.9279964876335431 f1 0.9283920553967407\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "228 of 1000 - 9.660000562667847 s\n",
      "Accuracy 0.933850431728377 precision 0.9342941295984611 specificity 0.8865881895770761 recall 0.933850431728377 f1 0.9340517461530012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "229 of 1000 - 9.726036071777344 s\n",
      "Accuracy 0.9315088540904435 precision 0.9322263907590472 specificity 0.8796429628148283 recall 0.9315088540904435 f1 0.9318251436919964\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "230 of 1000 - 9.794018030166626 s\n",
      "Accuracy 0.9227279379481926 precision 0.922795487708978 specificity 0.8629680980455047 recall 0.9227279379481926 f1 0.9227613021101118\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "231 of 1000 - 9.801563024520874 s\n",
      "Accuracy 0.9282891848382848 precision 0.9280057348637147 specificity 0.870364190261814 recall 0.9282891848382848 f1 0.9281370846340559\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "232 of 1000 - 9.640999555587769 s\n",
      "Accuracy 0.9265330016098346 precision 0.9276889250631811 specificity 0.8781049483102974 recall 0.9265330016098346 f1 0.9270182871837348\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "233 of 1000 - 9.805001020431519 s\n",
      "Accuracy 0.9356066149568272 precision 0.9355240400236363 specificity 0.8831534468533591 recall 0.9356066149568272 f1 0.9355643725013431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "234 of 1000 - 9.69804048538208 s\n",
      "Accuracy 0.9298990194643642 precision 0.9297014149251173 specificity 0.8684064477710173 recall 0.9298990194643642 f1 0.9297957229742367\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "235 of 1000 - 9.886060953140259 s\n",
      "Accuracy 0.9266793502122055 precision 0.9263001955263103 specificity 0.8670631680008026 recall 0.9266793502122055 f1 0.9264709449713439\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "236 of 1000 - 10.05872893333435 s\n",
      "Accuracy 0.93092345968096 precision 0.9311131652218116 specificity 0.8775213097704414 recall 0.93092345968096 f1 0.9310145367464377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "237 of 1000 - 10.048001050949097 s\n",
      "Accuracy 0.93092345968096 precision 0.9312830750446159 specificity 0.8792433609461116 recall 0.93092345968096 f1 0.9310905990464432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "238 of 1000 - 9.897040843963623 s\n",
      "Accuracy 0.9315088540904435 precision 0.931189334143976 specificity 0.8686840232174134 recall 0.9315088540904435 f1 0.9313361001028105\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "239 of 1000 - 9.975000143051147 s\n",
      "Accuracy 0.9279964876335431 precision 0.9287408761814564 specificity 0.8790111831542919 recall 0.9279964876335431 f1 0.9283232469555297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "240 of 1000 - 9.99899935722351 s\n",
      "Accuracy 0.9297526708619933 precision 0.9297526708619933 specificity 0.8707962355940427 recall 0.9297526708619933 f1 0.9297526708619933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "241 of 1000 - 9.901044368743896 s\n",
      "Accuracy 0.9316552026928143 precision 0.9317269035329108 specificity 0.8828113224856539 recall 0.9316552026928143 f1 0.9316904098454513\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "242 of 1000 - 10.033135890960693 s\n",
      "Accuracy 0.9331186887165227 precision 0.9331943371669664 specificity 0.8792904541627203 recall 0.9331186887165227 f1 0.933155850871288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "243 of 1000 - 9.867047548294067 s\n",
      "Accuracy 0.9335577345236353 precision 0.9332897447624466 specificity 0.8774393360328256 recall 0.9335577345236353 f1 0.9334131599440615\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "244 of 1000 - 9.64000153541565 s\n",
      "Accuracy 0.9285818820430265 precision 0.9287819189675421 specificity 0.8713538040036916 recall 0.9285818820430265 f1 0.9286781148735209\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "245 of 1000 - 9.273000717163086 s\n",
      "Accuracy 0.9331186887165227 precision 0.9330760776297622 specificity 0.8807231496694953 recall 0.9331186887165227 f1 0.9330971472827245\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "246 of 1000 - 9.38499903678894 s\n",
      "Accuracy 0.9322405971022977 precision 0.932314077468102 specificity 0.8811981181033229 recall 0.9322405971022977 f1 0.9322766860227389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "247 of 1000 - 9.333001375198364 s\n",
      "Accuracy 0.9301917166691058 precision 0.9303665445345378 specificity 0.8761432109848365 recall 0.9301917166691058 f1 0.9302759636856961\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "248 of 1000 - 9.388506412506104 s\n",
      "Accuracy 0.9287282306453973 precision 0.928872509539041 specificity 0.873570563649284 recall 0.9287282306453973 f1 0.9287982591432197\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "249 of 1000 - 8.769519090652466 s\n",
      "Accuracy 0.9322405971022977 precision 0.932350623910415 specificity 0.8764392064060634 recall 0.9322405971022977 f1 0.9322943071442217\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "250 of 1000 - 8.669983148574829 s\n",
      "Accuracy 0.9339967803307478 precision 0.9339519280899437 specificity 0.8768915145663606 recall 0.9339967803307478 f1 0.9339741124573746\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "251 of 1000 - 8.571518898010254 s\n",
      "Accuracy 0.9337040831260062 precision 0.9337481129849232 specificity 0.8812191663883179 recall 0.9337040831260062 f1 0.9337258605597428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "252 of 1000 - 8.483568906784058 s\n",
      "Accuracy 0.9335577345236353 precision 0.9331557865145287 specificity 0.8723820074277795 recall 0.9335577345236353 f1 0.9333325812462829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "253 of 1000 - 8.820025444030762 s\n",
      "Accuracy 0.9329723401141519 precision 0.9331572062188688 specificity 0.8809902207398359 recall 0.9329723401141519 f1 0.9330609776228409\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "254 of 1000 - 9.121540784835815 s\n",
      "Accuracy 0.9315088540904435 precision 0.9325430828464031 specificity 0.8881669246762444 recall 0.9315088540904435 f1 0.9319389270831412\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "255 of 1000 - 9.114030599594116 s\n",
      "Accuracy 0.9322405971022977 precision 0.932499550799617 specificity 0.8837609031339825 recall 0.9322405971022977 f1 0.9323625786437565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "256 of 1000 - 9.162680864334106 s\n",
      "Accuracy 0.932825991511781 precision 0.932873028933894 specificity 0.8750384475304239 recall 0.932825991511781 f1 0.9328492686096143\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "257 of 1000 - 8.91172170639038 s\n",
      "Accuracy 0.9316552026928143 precision 0.9318308656354327 specificity 0.8766098752184309 recall 0.9316552026928143 f1 0.9317398291257543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "258 of 1000 - 9.117109060287476 s\n",
      "Accuracy 0.9316552026928143 precision 0.9319856970704661 specificity 0.8824987975997849 recall 0.9316552026928143 f1 0.9318089896374658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "259 of 1000 - 9.043998956680298 s\n",
      "Accuracy 0.9320942484999268 precision 0.9324750420504377 specificity 0.8834695799177853 recall 0.9320942484999268 f1 0.9322696502732437\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "260 of 1000 - 9.036008596420288 s\n",
      "Accuracy 0.9265330016098346 precision 0.9261693172172552 specificity 0.8617065992512138 recall 0.9265330016098346 f1 0.9263359909017029\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "261 of 1000 - 9.183636903762817 s\n",
      "Accuracy 0.9284355334406557 precision 0.9285486697638266 specificity 0.871734089125028 recall 0.9284355334406557 f1 0.9284908201106644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "262 of 1000 - 8.998336553573608 s\n",
      "Accuracy 0.9363383579686814 precision 0.9363248080102593 specificity 0.8871658656566713 recall 0.9363383579686814 f1 0.9363315566655236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "263 of 1000 - 8.98711371421814 s\n",
      "Accuracy 0.93092345968096 precision 0.9313631167984484 specificity 0.8852750430286621 recall 0.93092345968096 f1 0.9311232190245753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "264 of 1000 - 8.74399995803833 s\n",
      "Accuracy 0.9294599736572515 precision 0.9297206185424494 specificity 0.8758385655891409 recall 0.9294599736572515 f1 0.9295836163056609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "265 of 1000 - 8.886007070541382 s\n",
      "Accuracy 0.9256549099956095 precision 0.926019349283013 specificity 0.8745776727920865 recall 0.9256549099956095 f1 0.9258248304797002\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "266 of 1000 - 8.502841234207153 s\n",
      "Accuracy 0.93092345968096 precision 0.9314116998582848 specificity 0.8832176881906811 recall 0.93092345968096 f1 0.9311443107211465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "267 of 1000 - 8.539223432540894 s\n",
      "Accuracy 0.93092345968096 precision 0.9315280901041886 specificity 0.8832152146494867 recall 0.93092345968096 f1 0.9311921537575762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "268 of 1000 - 8.619996309280396 s\n",
      "Accuracy 0.9383872384018732 precision 0.9384844842409655 specificity 0.890235953488563 recall 0.9383872384018732 f1 0.9384345560992035\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "269 of 1000 - 8.582010269165039 s\n",
      "Accuracy 0.9313625054880725 precision 0.9314385277860384 specificity 0.8778540570030212 recall 0.9313625054880725 f1 0.9313998616963313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "270 of 1000 - 8.51500153541565 s\n",
      "Accuracy 0.9310698082833309 precision 0.9309408339534102 specificity 0.8760535453852634 recall 0.9310698082833309 f1 0.9310032042440379\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "271 of 1000 - 8.819633722305298 s\n",
      "Accuracy 0.9315088540904435 precision 0.9319395662622999 specificity 0.8803088326251284 recall 0.9315088540904435 f1 0.9317064557223627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "272 of 1000 - 9.449508428573608 s\n",
      "Accuracy 0.9312161568857017 precision 0.9311554596395226 specificity 0.8736447763006304 recall 0.9312161568857017 f1 0.9311853844370448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "273 of 1000 - 9.146520137786865 s\n",
      "Accuracy 0.93092345968096 precision 0.9312967988775503 specificity 0.8842881559602175 recall 0.93092345968096 f1 0.9310953540602883\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "274 of 1000 - 9.052587985992432 s\n",
      "Accuracy 0.9353139177520855 precision 0.9351785987862627 specificity 0.8824002391406432 recall 0.9353139177520855 f1 0.9352436104072025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "275 of 1000 - 9.385106801986694 s\n",
      "Accuracy 0.9268256988145763 precision 0.9279748322855731 specificity 0.8788870572403976 recall 0.9268256988145763 f1 0.9273076231003331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "276 of 1000 - 9.52699875831604 s\n",
      "Accuracy 0.929020927850139 precision 0.9294705142395675 specificity 0.8786124146238615 recall 0.929020927850139 f1 0.9292268815787449\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "277 of 1000 - 10.111512184143066 s\n",
      "Accuracy 0.9288745792477682 precision 0.9283088417226573 specificity 0.8640813556424876 recall 0.9288745792477682 f1 0.9285450569257234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "278 of 1000 - 10.020583868026733 s\n",
      "Accuracy 0.9275574418264305 precision 0.92766391874076 specificity 0.8764564427268755 recall 0.9275574418264305 f1 0.927609432065206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "279 of 1000 - 9.606000900268555 s\n",
      "Accuracy 0.9370701009805357 precision 0.9370981360714981 specificity 0.8863675006792755 recall 0.9370701009805357 f1 0.9370840118679696\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "280 of 1000 - 9.61650824546814 s\n",
      "Accuracy 0.9369237523781648 precision 0.9367599899789392 specificity 0.8872390710521042 recall 0.9369237523781648 f1 0.9368374291309889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "281 of 1000 - 9.630000114440918 s\n",
      "Accuracy 0.9315088540904435 precision 0.9310355995437949 specificity 0.8662497256904155 recall 0.9315088540904435 f1 0.9312410742071272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "282 of 1000 - 9.52855396270752 s\n",
      "Accuracy 0.9335577345236353 precision 0.9335008048477655 specificity 0.8803208962808746 recall 0.9335577345236353 f1 0.9335288480670048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "283 of 1000 - 9.472999334335327 s\n",
      "Accuracy 0.9322405971022977 precision 0.9319966870643643 specificity 0.8726111424637295 recall 0.9322405971022977 f1 0.9321109310221593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "284 of 1000 - 9.58155083656311 s\n",
      "Accuracy 0.9274110932240597 precision 0.9281973221793113 specificity 0.878714064456014 recall 0.9274110932240597 f1 0.9277545025065922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "285 of 1000 - 9.552557229995728 s\n",
      "Accuracy 0.9304844138738475 precision 0.9304991162924162 specificity 0.878293505930015 recall 0.9304844138738475 f1 0.9304917391975726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "286 of 1000 - 9.580999374389648 s\n",
      "Accuracy 0.9307771110785892 precision 0.9313063878070563 specificity 0.8794376346799117 recall 0.9307771110785892 f1 0.9310165274413084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "287 of 1000 - 9.473545789718628 s\n",
      "Accuracy 0.929020927850139 precision 0.9292577934146604 specificity 0.8777993952882834 recall 0.929020927850139 f1 0.9291335622150624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "288 of 1000 - 9.662041187286377 s\n",
      "Accuracy 0.929020927850139 precision 0.9293722974506757 specificity 0.8754758952881707 recall 0.929020927850139 f1 0.9291851068634188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "289 of 1000 - 9.466001272201538 s\n",
      "Accuracy 0.9320942484999268 precision 0.9321555544963964 specificity 0.8771170828533071 recall 0.9320942484999268 f1 0.9321244783611312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "290 of 1000 - 8.968120574951172 s\n",
      "Accuracy 0.9325332943070394 precision 0.9323731568712503 specificity 0.8744845105903054 recall 0.9325332943070394 f1 0.9324500027469531\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "291 of 1000 - 8.997409582138062 s\n",
      "Accuracy 0.9323869457046685 precision 0.9324758918916899 specificity 0.8810373205239969 recall 0.9323869457046685 f1 0.9324304785340212\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "292 of 1000 - 9.419999122619629 s\n",
      "Accuracy 0.9287282306453973 precision 0.9283439324209983 specificity 0.8667868526263346 recall 0.9287282306453973 f1 0.9285168990706896\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "293 of 1000 - 9.142001390457153 s\n",
      "Accuracy 0.9335577345236353 precision 0.9333652931732394 specificity 0.8783178816710897 recall 0.9335577345236353 f1 0.933456332769878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "294 of 1000 - 9.109999656677246 s\n",
      "Accuracy 0.9263866530074638 precision 0.9262166663078742 specificity 0.8661615405500542 recall 0.9263866530074638 f1 0.9262985114721566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "295 of 1000 - 9.050508737564087 s\n",
      "Accuracy 0.9335577345236353 precision 0.9345820405093456 specificity 0.8906804957943815 recall 0.9335577345236353 f1 0.9339819888308047\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "296 of 1000 - 9.378999471664429 s\n",
      "Accuracy 0.9303380652714767 precision 0.9308160014395879 specificity 0.8777814768886035 recall 0.9303380652714767 f1 0.9305564380946106\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "297 of 1000 - 9.564038515090942 s\n",
      "Accuracy 0.9298990194643642 precision 0.9298840782255183 specificity 0.8756911797389177 recall 0.9298990194643642 f1 0.9298915228504179\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "298 of 1000 - 9.630000829696655 s\n",
      "Accuracy 0.9335577345236353 precision 0.9344277682951204 specificity 0.888419514473452 recall 0.9335577345236353 f1 0.9339270989143287\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "299 of 1000 - 9.594507217407227 s\n",
      "Accuracy 0.9307771110785892 precision 0.9312615082310018 specificity 0.8804532526495439 recall 0.9307771110785892 f1 0.9309973543274108\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "300 of 1000 - 9.762999057769775 s\n",
      "Accuracy 0.9337040831260062 precision 0.9339656054580016 specificity 0.8838992217844048 recall 0.9337040831260062 f1 0.9338272455916552\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "301 of 1000 - 9.973050832748413 s\n",
      "Accuracy 0.9320942484999268 precision 0.931792214474643 specificity 0.8737987622013917 recall 0.9320942484999268 f1 0.9319304273197101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "302 of 1000 - 9.630001306533813 s\n",
      "Accuracy 0.9339967803307478 precision 0.9339286687048755 specificity 0.8835754719360119 recall 0.9339967803307478 f1 0.9339620724841465\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "303 of 1000 - 9.565999507904053 s\n",
      "Accuracy 0.9288745792477682 precision 0.9291201688186779 specificity 0.8805040630709832 recall 0.9288745792477682 f1 0.9289908545616828\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "304 of 1000 - 9.513999223709106 s\n",
      "Accuracy 0.9335577345236353 precision 0.9333584940869403 specificity 0.8754221964801052 recall 0.9335577345236353 f1 0.9334528708359652\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "305 of 1000 - 9.599511861801147 s\n",
      "Accuracy 0.9348748719449729 precision 0.9349722773749126 specificity 0.8879953239421009 recall 0.9348748719449729 f1 0.9349223022236645\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "306 of 1000 - 9.446000099182129 s\n",
      "Accuracy 0.9354602663544563 precision 0.9353390849294247 specificity 0.8833536983559163 recall 0.9354602663544563 f1 0.9353975355232585\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "307 of 1000 - 9.57900094985962 s\n",
      "Accuracy 0.9297526708619933 precision 0.9302410270319083 specificity 0.8754198821747424 recall 0.9297526708619933 f1 0.9299761730973882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "308 of 1000 - 9.45650863647461 s\n",
      "Accuracy 0.9296063222596225 precision 0.9298818943055259 specificity 0.8768241752995259 recall 0.9296063222596225 f1 0.9297365831188684\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "309 of 1000 - 9.420000314712524 s\n",
      "Accuracy 0.9282891848382848 precision 0.9295186866483316 specificity 0.8815432509417326 recall 0.9282891848382848 f1 0.928797951391425\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "310 of 1000 - 9.53404951095581 s\n",
      "Accuracy 0.9353139177520855 precision 0.9358911364670139 specificity 0.8845498597266985 recall 0.9353139177520855 f1 0.9355713901365431\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "311 of 1000 - 9.547537803649902 s\n",
      "Accuracy 0.9269720474169472 precision 0.9269881711644993 specificity 0.8682929656629944 recall 0.9269720474169472 f1 0.9269800832106692\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "312 of 1000 - 9.498000383377075 s\n",
      "Accuracy 0.9323869457046685 precision 0.9328609809650464 specificity 0.8799176809093416 recall 0.9323869457046685 f1 0.9326031357759433\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "313 of 1000 - 9.818000078201294 s\n",
      "Accuracy 0.9316552026928143 precision 0.9316086932498068 specificity 0.8724584045808544 recall 0.9316552026928143 f1 0.9316317073307461\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "314 of 1000 - 9.70903992652893 s\n",
      "Accuracy 0.930045368066735 precision 0.9301076360012082 specificity 0.8745910890596695 recall 0.930045368066735 f1 0.9300760827078806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "315 of 1000 - 9.519550561904907 s\n",
      "Accuracy 0.9268256988145763 precision 0.9274977922504695 specificity 0.876584778407524 recall 0.9268256988145763 f1 0.927124671338775\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "316 of 1000 - 9.105117321014404 s\n",
      "Accuracy 0.9312161568857017 precision 0.9324295232339653 specificity 0.8852117971598001 recall 0.9312161568857017 f1 0.9317153857379333\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "317 of 1000 - 9.11797046661377 s\n",
      "Accuracy 0.9341431289331187 precision 0.9341716905877598 specificity 0.8832213911499184 recall 0.9341431289331187 f1 0.934157304722988\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "318 of 1000 - 9.460640907287598 s\n",
      "Accuracy 0.9304844138738475 precision 0.9299679545791446 specificity 0.864075047202644 recall 0.9304844138738475 f1 0.9301893809797976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "319 of 1000 - 9.257574796676636 s\n",
      "Accuracy 0.9293136250548807 precision 0.9293289750667445 specificity 0.8739867562549473 recall 0.9293136250548807 f1 0.9293212740036556\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "320 of 1000 - 9.27666163444519 s\n",
      "Accuracy 0.9234596809600468 precision 0.9240767206692128 specificity 0.8731425690917386 recall 0.9234596809600468 f1 0.9237373103673351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "321 of 1000 - 9.071094274520874 s\n",
      "Accuracy 0.932825991511781 precision 0.9333063624521092 specificity 0.8826004949698294 recall 0.932825991511781 f1 0.9330439780029914\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "322 of 1000 - 9.30047345161438 s\n",
      "Accuracy 0.9334113859212645 precision 0.9330899139793749 specificity 0.8723295830642802 recall 0.9334113859212645 f1 0.9332364051272884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "323 of 1000 - 8.550732135772705 s\n",
      "Accuracy 0.9266793502122055 precision 0.9266026153681709 specificity 0.8697487454338965 recall 0.9266793502122055 f1 0.9266403376871405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "324 of 1000 - 8.432672262191772 s\n",
      "Accuracy 0.936631055173423 precision 0.9367010837535847 specificity 0.8876177371923923 recall 0.936631055173423 f1 0.936665408390445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "325 of 1000 - 8.43387484550476 s\n",
      "Accuracy 0.9301917166691058 precision 0.9301152296958903 specificity 0.8719084240084406 recall 0.9301917166691058 f1 0.9301528130320731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "326 of 1000 - 8.120093584060669 s\n",
      "Accuracy 0.9247768183813845 precision 0.9248097292192367 specificity 0.8656483629053388 recall 0.9247768183813845 f1 0.9247931704063935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "327 of 1000 - 8.230443000793457 s\n",
      "Accuracy 0.9342894775354895 precision 0.9348743162640373 specificity 0.8856527613832951 recall 0.9342894775354895 f1 0.9345493920755475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "328 of 1000 - 8.504008531570435 s\n",
      "Accuracy 0.9303380652714767 precision 0.9301612323030737 specificity 0.8718652019465589 recall 0.9303380652714767 f1 0.9302458532636617\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "329 of 1000 - 8.701787948608398 s\n",
      "Accuracy 0.9306307624762183 precision 0.9304001214317186 specificity 0.871957225548161 recall 0.9306307624762183 f1 0.9305086915066667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "330 of 1000 - 8.379598617553711 s\n",
      "Accuracy 0.9287282306453973 precision 0.9282758269532102 specificity 0.8670512729497043 recall 0.9287282306453973 f1 0.9284734743402827\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "331 of 1000 - 8.5531485080719 s\n",
      "Accuracy 0.93092345968096 precision 0.9308915521827252 specificity 0.8699528594976106 recall 0.93092345968096 f1 0.9309073986163374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "332 of 1000 - 8.561014890670776 s\n",
      "Accuracy 0.9293136250548807 precision 0.9289025355995822 specificity 0.8663842626348451 recall 0.9293136250548807 f1 0.9290858218593464\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "333 of 1000 - 8.45299243927002 s\n",
      "Accuracy 0.9372164495829065 precision 0.9372888173182425 specificity 0.8853350869169613 recall 0.9372164495829065 f1 0.9372519614565882\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "334 of 1000 - 8.42993426322937 s\n",
      "Accuracy 0.928142836235914 precision 0.9285982967654206 specificity 0.8768744515844412 recall 0.928142836235914 f1 0.9283517483255384\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "335 of 1000 - 8.467205047607422 s\n",
      "Accuracy 0.9370701009805357 precision 0.9372177766150591 specificity 0.8860410816766869 recall 0.9370701009805357 f1 0.9371412550408073\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "336 of 1000 - 8.357889890670776 s\n",
      "Accuracy 0.9312161568857017 precision 0.9309857114541322 specificity 0.8723053894443816 recall 0.9312161568857017 f1 0.9310941567428568\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "337 of 1000 - 8.769850969314575 s\n",
      "Accuracy 0.9313625054880725 precision 0.931289905266102 specificity 0.8770136092362177 recall 0.9313625054880725 f1 0.9313255515128015\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "338 of 1000 - 8.358166933059692 s\n",
      "Accuracy 0.9322405971022977 precision 0.9322857193561207 specificity 0.8783341599617882 recall 0.9322405971022977 f1 0.9322629211997399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "339 of 1000 - 8.322844743728638 s\n",
      "Accuracy 0.9304844138738475 precision 0.9303813574127838 specificity 0.8744306056461967 recall 0.9304844138738475 f1 0.9304316023513817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "340 of 1000 - 8.356831073760986 s\n",
      "Accuracy 0.935752963559198 precision 0.9358556272346251 specificity 0.8843756697051106 recall 0.935752963559198 f1 0.9358029907626776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "341 of 1000 - 8.21088171005249 s\n",
      "Accuracy 0.929020927850139 precision 0.9293466152956786 specificity 0.8723374844931835 recall 0.929020927850139 f1 0.9291742458607432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "342 of 1000 - 8.120938777923584 s\n",
      "Accuracy 0.9288745792477682 precision 0.9295332266898911 specificity 0.8798767191287803 recall 0.9288745792477682 f1 0.929166613275955\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "343 of 1000 - 8.31216025352478 s\n",
      "Accuracy 0.9279964876335431 precision 0.928680010306207 specificity 0.8813181853822772 recall 0.9279964876335431 f1 0.9282974679523754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "344 of 1000 - 8.029165029525757 s\n",
      "Accuracy 0.9358993121615689 precision 0.9367684780474821 specificity 0.8944802399441737 recall 0.9358993121615689 f1 0.9362630318909061\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "345 of 1000 - 7.918689489364624 s\n",
      "Accuracy 0.9310698082833309 precision 0.9310552184814044 specificity 0.878333897857596 recall 0.9310698082833309 f1 0.9310624873871421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "346 of 1000 - 7.958003520965576 s\n",
      "Accuracy 0.9353139177520855 precision 0.93566761818048 specificity 0.8915430544939359 recall 0.9353139177520855 f1 0.9354758357539642\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "347 of 1000 - 8.257563352584839 s\n",
      "Accuracy 0.930045368066735 precision 0.930625064351321 specificity 0.8803947123095388 recall 0.930045368066735 f1 0.9303051590670339\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "348 of 1000 - 8.05052661895752 s\n",
      "Accuracy 0.9334113859212645 precision 0.9343089929687846 specificity 0.8833474572229489 recall 0.9334113859212645 f1 0.9337958461574365\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "349 of 1000 - 8.122102737426758 s\n",
      "Accuracy 0.9279964876335431 precision 0.9277784607373819 specificity 0.8647842665478892 recall 0.9279964876335431 f1 0.9278822827409787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "350 of 1000 - 7.803483486175537 s\n",
      "Accuracy 0.9348748719449729 precision 0.9354358504999196 specificity 0.8895430582295606 recall 0.9348748719449729 f1 0.9351232285647074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "351 of 1000 - 7.936410188674927 s\n",
      "Accuracy 0.9312161568857017 precision 0.9314661398612267 specificity 0.8805525054755519 recall 0.9312161568857017 f1 0.9313344870637003\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "352 of 1000 - 7.834795236587524 s\n",
      "Accuracy 0.9218498463339675 precision 0.9218846037751245 specificity 0.858777257647603 recall 0.9218498463339675 f1 0.9218671217151064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "353 of 1000 - 7.914944171905518 s\n",
      "Accuracy 0.9337040831260062 precision 0.9342096720631518 specificity 0.8854564121513459 recall 0.9337040831260062 f1 0.9339315715326842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "354 of 1000 - 7.980463743209839 s\n",
      "Accuracy 0.9312161568857017 precision 0.9314900715806376 specificity 0.8836164122157993 recall 0.9312161568857017 f1 0.9313447831648184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "355 of 1000 - 7.977200269699097 s\n",
      "Accuracy 0.9316552026928143 precision 0.9324922413609636 specificity 0.8835849783061216 recall 0.9316552026928143 f1 0.9320157166845977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "356 of 1000 - 7.794008493423462 s\n",
      "Accuracy 0.9334113859212645 precision 0.9335499426116465 specificity 0.8798914994704007 recall 0.9334113859212645 f1 0.9334785136934592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "357 of 1000 - 7.852354288101196 s\n",
      "Accuracy 0.933850431728377 precision 0.9335564810769929 specificity 0.8825710668276988 recall 0.933850431728377 f1 0.933688537547767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "358 of 1000 - 7.8550004959106445 s\n",
      "Accuracy 0.9279964876335431 precision 0.9270561452744909 specificity 0.855332844971349 recall 0.9279964876335431 f1 0.9273554060942049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "359 of 1000 - 7.852999687194824 s\n",
      "Accuracy 0.9379481925947607 precision 0.9374332541152456 specificity 0.8773449661293603 recall 0.9379481925947607 f1 0.9376379502061052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "360 of 1000 - 8.125977516174316 s\n",
      "Accuracy 0.9275574418264305 precision 0.9279263022499866 specificity 0.8790546135831773 recall 0.9275574418264305 f1 0.9277284341554921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "361 of 1000 - 7.9827680587768555 s\n",
      "Accuracy 0.9391189814137275 precision 0.9396404137143138 specificity 0.8957044702169011 recall 0.9391189814137275 f1 0.9393488991436816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "362 of 1000 - 7.85114598274231 s\n",
      "Accuracy 0.9293136250548807 precision 0.9295536399790424 specificity 0.8768537263687769 recall 0.9293136250548807 f1 0.9294277962919124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "363 of 1000 - 7.858062744140625 s\n",
      "Accuracy 0.931947899897556 precision 0.9321445952591592 specificity 0.8823110299558806 recall 0.931947899897556 f1 0.932041859170297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "364 of 1000 - 7.895582675933838 s\n",
      "Accuracy 0.9344358261378604 precision 0.9342079728842441 specificity 0.8832568522749925 recall 0.9344358261378604 f1 0.934313460647491\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "365 of 1000 - 7.881292104721069 s\n",
      "Accuracy 0.9315088540904435 precision 0.9316002486148375 specificity 0.878252722080112 recall 0.9315088540904435 f1 0.9315536079927408\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "366 of 1000 - 7.919134855270386 s\n",
      "Accuracy 0.9294599736572515 precision 0.9293151097158622 specificity 0.8738405108045233 recall 0.9294599736572515 f1 0.9293849444938561\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "367 of 1000 - 7.870306015014648 s\n",
      "Accuracy 0.9310698082833309 precision 0.931396728187027 specificity 0.8830047295730155 recall 0.9310698082833309 f1 0.9312218964220156\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "368 of 1000 - 7.992905855178833 s\n",
      "Accuracy 0.9310698082833309 precision 0.9311145490082962 specificity 0.8783752986359962 recall 0.9310698082833309 f1 0.9310919442555213\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "369 of 1000 - 8.049140214920044 s\n",
      "Accuracy 0.937655495390019 precision 0.9379364408291143 specificity 0.894944738783517 recall 0.937655495390019 f1 0.9377855426539715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "370 of 1000 - 8.030627250671387 s\n",
      "Accuracy 0.9266793502122055 precision 0.927045228213193 specificity 0.8702441693658938 recall 0.9266793502122055 f1 0.9268507971500517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "371 of 1000 - 7.9787046909332275 s\n",
      "Accuracy 0.9296063222596225 precision 0.9299127926791603 specificity 0.8781637709611357 recall 0.9296063222596225 f1 0.9297501987675343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "372 of 1000 - 7.878275394439697 s\n",
      "Accuracy 0.9335577345236353 precision 0.9333543695549393 specificity 0.87365222785343 recall 0.9335577345236353 f1 0.9334507706637586\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "373 of 1000 - 7.824629306793213 s\n",
      "Accuracy 0.934728523342602 precision 0.9345462938621855 specificity 0.8832001215479979 recall 0.934728523342602 f1 0.9346322772586014\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "374 of 1000 - 7.845469951629639 s\n",
      "Accuracy 0.93092345968096 precision 0.9313655487694059 specificity 0.8848310189173947 recall 0.93092345968096 f1 0.9311243964309373\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "375 of 1000 - 7.938258171081543 s\n",
      "Accuracy 0.9287282306453973 precision 0.9287127973479766 specificity 0.8722491905217775 recall 0.9287282306453973 f1 0.928720487924955\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "376 of 1000 - 7.906059265136719 s\n",
      "Accuracy 0.9320942484999268 precision 0.9328679892736099 specificity 0.888334070832588 recall 0.9320942484999268 f1 0.9324264938243065\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "377 of 1000 - 7.931233882904053 s\n",
      "Accuracy 0.9320942484999268 precision 0.9317264576345844 specificity 0.8788498388704272 recall 0.9320942484999268 f1 0.9318871168448635\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "378 of 1000 - 7.9334986209869385 s\n",
      "Accuracy 0.930045368066735 precision 0.9302941074288071 specificity 0.8802167824258837 recall 0.930045368066735 f1 0.930163140055405\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "379 of 1000 - 7.911024570465088 s\n",
      "Accuracy 0.9306307624762183 precision 0.9303805017512057 specificity 0.8740360768523868 recall 0.9306307624762183 f1 0.9304971663465813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "380 of 1000 - 7.951812028884888 s\n",
      "Accuracy 0.9287282306453973 precision 0.9300358092065437 specificity 0.8852543555952337 recall 0.9287282306453973 f1 0.9292598555380926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "381 of 1000 - 7.8794050216674805 s\n",
      "Accuracy 0.9315088540904435 precision 0.9318926363545168 specificity 0.8824199434619636 recall 0.9315088540904435 f1 0.9316857679480132\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "382 of 1000 - 7.9406211376190186 s\n",
      "Accuracy 0.9341431289331187 precision 0.9342570042266513 specificity 0.8862609795979434 recall 0.9341431289331187 f1 0.934198402660637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "383 of 1000 - 7.907552003860474 s\n",
      "Accuracy 0.9332650373188937 precision 0.9334169583668587 specificity 0.8814016531026047 recall 0.9332650373188937 f1 0.9333383620749987\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "384 of 1000 - 7.893464803695679 s\n",
      "Accuracy 0.9285818820430265 precision 0.9285507341304567 specificity 0.8708944231616631 recall 0.9285818820430265 f1 0.9285662034395966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "385 of 1000 - 7.930915355682373 s\n",
      "Accuracy 0.9379481925947607 precision 0.9382416009462239 specificity 0.8918692172474465 recall 0.9379481925947607 f1 0.938084282289925\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "386 of 1000 - 7.831990480422974 s\n",
      "Accuracy 0.9301917166691058 precision 0.9305984567675671 specificity 0.880514272434229 recall 0.9301917166691058 f1 0.9303789006095189\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "387 of 1000 - 7.903491973876953 s\n",
      "Accuracy 0.9364847065710522 precision 0.9368420874893483 specificity 0.891557776993021 recall 0.9364847065710522 f1 0.9366482844752864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "388 of 1000 - 7.88157844543457 s\n",
      "Accuracy 0.9279964876335431 precision 0.9282712640588163 specificity 0.8701059018422856 recall 0.9279964876335431 f1 0.9281271368863613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "389 of 1000 - 7.8609747886657715 s\n",
      "Accuracy 0.9291672764525098 precision 0.9291989261849133 specificity 0.8716898596454556 recall 0.9291672764525098 f1 0.9291829962404536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "390 of 1000 - 7.8359692096710205 s\n",
      "Accuracy 0.9296063222596225 precision 0.9297870316330276 specificity 0.8728361676475346 recall 0.9296063222596225 f1 0.9296934856734215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "391 of 1000 - 7.978500127792358 s\n",
      "Accuracy 0.9345821747402312 precision 0.934538733327722 specificity 0.8799244579109776 recall 0.9345821747402312 f1 0.9345602139645784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "392 of 1000 - 7.9494123458862305 s\n",
      "Accuracy 0.9341431289331187 precision 0.9345631246292981 specificity 0.884271132808574 recall 0.9341431289331187 f1 0.9343352073018456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "393 of 1000 - 8.051025152206421 s\n",
      "Accuracy 0.9323869457046685 precision 0.932328707186537 specificity 0.8778125728844698 recall 0.9323869457046685 f1 0.9323574051085233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "394 of 1000 - 8.041782140731812 s\n",
      "Accuracy 0.9301917166691058 precision 0.9303309663409552 specificity 0.8775334011365273 recall 0.9301917166691058 f1 0.9302592355203394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "395 of 1000 - 7.9446702003479 s\n",
      "Accuracy 0.9320942484999268 precision 0.933141299527325 specificity 0.8876093493059373 recall 0.9320942484999268 f1 0.9325299920854206\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "396 of 1000 - 7.982137680053711 s\n",
      "Accuracy 0.9285818820430265 precision 0.928548552894013 specificity 0.8645943980279477 recall 0.9285818820430265 f1 0.928565110313715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "397 of 1000 - 7.896001815795898 s\n",
      "Accuracy 0.9312161568857017 precision 0.9307769732129926 specificity 0.8684175773184388 recall 0.9312161568857017 f1 0.9309692458886374\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "398 of 1000 - 7.833580017089844 s\n",
      "Accuracy 0.9358993121615689 precision 0.9367015664038011 specificity 0.8927304596619285 recall 0.9358993121615689 f1 0.9362397206463126\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "399 of 1000 - 7.888058662414551 s\n",
      "Accuracy 0.928142836235914 precision 0.9283236248319103 specificity 0.8719145188754712 recall 0.928142836235914 f1 0.9282300706223345\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "400 of 1000 - 7.901697874069214 s\n",
      "Accuracy 0.9353139177520855 precision 0.9354545857406086 specificity 0.8888071638203229 recall 0.9353139177520855 f1 0.9353816486471445\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "401 of 1000 - 8.039116621017456 s\n",
      "Accuracy 0.9307771110785892 precision 0.930562667817778 specificity 0.8732224404315453 recall 0.9307771110785892 f1 0.9306639752701131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "402 of 1000 - 7.802578926086426 s\n",
      "Accuracy 0.9307771110785892 precision 0.9304755224412883 specificity 0.8698707405408592 recall 0.9307771110785892 f1 0.930614604866535\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "403 of 1000 - 7.883682727813721 s\n",
      "Accuracy 0.924337772574272 precision 0.9240783670798594 specificity 0.8634432942127739 recall 0.924337772574272 f1 0.9242006247341941\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "404 of 1000 - 8.026607275009155 s\n",
      "Accuracy 0.9316552026928143 precision 0.931553829877319 specificity 0.8764360739588383 recall 0.9316552026928143 f1 0.9316032294831101\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "405 of 1000 - 7.964958667755127 s\n",
      "Accuracy 0.9323869457046685 precision 0.9320967725203971 specificity 0.8771944091505516 recall 0.9323869457046685 f1 0.9322291960642826\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "406 of 1000 - 7.999776124954224 s\n",
      "Accuracy 0.9316552026928143 precision 0.931787501400689 specificity 0.882650289572981 recall 0.9316552026928143 f1 0.9317192620513636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "407 of 1000 - 7.922575235366821 s\n",
      "Accuracy 0.9301917166691058 precision 0.9303585193592552 specificity 0.8801246204983317 recall 0.9301917166691058 f1 0.9302720021361387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "408 of 1000 - 7.880640745162964 s\n",
      "Accuracy 0.9312161568857017 precision 0.9312824783064089 specificity 0.869484585384808 recall 0.9312161568857017 f1 0.9312488850525982\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "409 of 1000 - 7.908802270889282 s\n",
      "Accuracy 0.9279964876335431 precision 0.9280275101188263 specificity 0.8727946181568145 recall 0.9279964876335431 f1 0.9280118953446967\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "410 of 1000 - 7.8745951652526855 s\n",
      "Accuracy 0.9278501390311723 precision 0.927407180047041 specificity 0.8684680578863129 recall 0.9278501390311723 f1 0.927600470291332\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "411 of 1000 - 7.875040531158447 s\n",
      "Accuracy 0.9331186887165227 precision 0.9334447974561682 specificity 0.8845760929668832 recall 0.9331186887165227 f1 0.9332702220500897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "412 of 1000 - 8.213911533355713 s\n",
      "Accuracy 0.9375091467876482 precision 0.9379850683834089 specificity 0.8930806056652221 recall 0.9375091467876482 f1 0.9377216830481027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "413 of 1000 - 7.883915662765503 s\n",
      "Accuracy 0.9325332943070394 precision 0.9326679047271205 specificity 0.8817855468665681 recall 0.9325332943070394 f1 0.9325984842478336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "414 of 1000 - 8.016016960144043 s\n",
      "Accuracy 0.9312161568857017 precision 0.9317335131757767 specificity 0.8848526823078015 recall 0.9312161568857017 f1 0.9314484413851741\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "415 of 1000 - 8.088890790939331 s\n",
      "Accuracy 0.9304844138738475 precision 0.9302285249232223 specificity 0.8760748547543866 recall 0.9304844138738475 f1 0.9303471300696767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "416 of 1000 - 7.9646642208099365 s\n",
      "Accuracy 0.9325332943070394 precision 0.9328638854311667 specificity 0.8830575646637931 recall 0.9325332943070394 f1 0.9326870592240296\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "417 of 1000 - 7.971020460128784 s\n",
      "Accuracy 0.9323869457046685 precision 0.9326787981178505 specificity 0.8790422576698812 recall 0.9323869457046685 f1 0.9325242821012235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "418 of 1000 - 8.15214729309082 s\n",
      "Accuracy 0.9326796429094102 precision 0.9332951066242617 specificity 0.8829645229293082 recall 0.9326796429094102 f1 0.9329531266428098\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "419 of 1000 - 8.00430178642273 s\n",
      "Accuracy 0.9265330016098346 precision 0.9271511401299473 specificity 0.8781168999365896 recall 0.9265330016098346 f1 0.9268091188424764\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "420 of 1000 - 8.19600796699524 s\n",
      "Accuracy 0.9337040831260062 precision 0.9335597969917466 specificity 0.883510482599952 recall 0.9337040831260062 f1 0.9336288021344726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "421 of 1000 - 8.031177282333374 s\n",
      "Accuracy 0.9301917166691058 precision 0.930771179328177 specificity 0.8834512963596367 recall 0.9301917166691058 f1 0.9304499415570517\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "422 of 1000 - 7.924897909164429 s\n",
      "Accuracy 0.9335577345236353 precision 0.9340439244788634 specificity 0.8854290389012236 recall 0.9335577345236353 f1 0.933777176406654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "423 of 1000 - 7.859032392501831 s\n",
      "Accuracy 0.9323869457046685 precision 0.9323572354812283 specificity 0.8770776454778477 recall 0.9323869457046685 f1 0.9323719848294829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "424 of 1000 - 8.053890705108643 s\n",
      "Accuracy 0.9269720474169472 precision 0.927051279948813 specificity 0.8717069049287975 recall 0.9269720474169472 f1 0.9270110188806985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "425 of 1000 - 7.978560924530029 s\n",
      "Accuracy 0.9373627981852773 precision 0.9373627981852773 specificity 0.8918628755050061 recall 0.9373627981852773 f1 0.9373627981852773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "426 of 1000 - 7.941391944885254 s\n",
      "Accuracy 0.9301917166691058 precision 0.9297487162341851 specificity 0.8649852953777413 recall 0.9301917166691058 f1 0.9299444695596434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "427 of 1000 - 7.955636262893677 s\n",
      "Accuracy 0.9277037904288014 precision 0.9278325914706106 specificity 0.8721123673037006 recall 0.9277037904288014 f1 0.9277665298061595\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "428 of 1000 - 7.905418872833252 s\n",
      "Accuracy 0.9372164495829065 precision 0.9372844445332215 specificity 0.8902198037882496 recall 0.9372164495829065 f1 0.9372497899700081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "429 of 1000 - 7.99759316444397 s\n",
      "Accuracy 0.9320942484999268 precision 0.9325316245819737 specificity 0.8865168823047523 recall 0.9320942484999268 f1 0.9322927497773993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "430 of 1000 - 7.817065000534058 s\n",
      "Accuracy 0.935752963559198 precision 0.9355163351954824 specificity 0.8767725567615869 recall 0.935752963559198 f1 0.9356268074363738\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "431 of 1000 - 7.915327310562134 s\n",
      "Accuracy 0.9313625054880725 precision 0.9310929220678598 specificity 0.8721756206163093 recall 0.9313625054880725 f1 0.9312181524871533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "432 of 1000 - 7.879007816314697 s\n",
      "Accuracy 0.9322405971022977 precision 0.9329380021980408 specificity 0.8853298285038422 recall 0.9322405971022977 f1 0.9325453924359991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "433 of 1000 - 7.903999090194702 s\n",
      "Accuracy 0.9316552026928143 precision 0.9315601967123539 specificity 0.8816513578301567 recall 0.9316552026928143 f1 0.9316064404047868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "434 of 1000 - 8.150310516357422 s\n",
      "Accuracy 0.9337040831260062 precision 0.9343355469871396 specificity 0.8896232106670021 recall 0.9337040831260062 f1 0.9339803098452906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "435 of 1000 - 7.98199725151062 s\n",
      "Accuracy 0.9318015512951852 precision 0.9318329474510955 specificity 0.87387426120691 recall 0.9318015512951852 f1 0.9318171426011038\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "436 of 1000 - 7.865326166152954 s\n",
      "Accuracy 0.931947899897556 precision 0.9322808190211124 specificity 0.8820819476260064 recall 0.931947899897556 f1 0.9321028463937316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "437 of 1000 - 7.905392169952393 s\n",
      "Accuracy 0.9310698082833309 precision 0.9308125775829023 specificity 0.8759370563041701 recall 0.9310698082833309 f1 0.9309317991843524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "438 of 1000 - 7.819355726242065 s\n",
      "Accuracy 0.9298990194643642 precision 0.9298249132600976 specificity 0.8744988141769581 recall 0.9298990194643642 f1 0.9298613146567869\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "439 of 1000 - 7.916888952255249 s\n",
      "Accuracy 0.93092345968096 precision 0.9306874115358122 specificity 0.8700683697598591 recall 0.93092345968096 f1 0.9307986169826806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "440 of 1000 - 8.129832744598389 s\n",
      "Accuracy 0.9323869457046685 precision 0.9326593215288483 specificity 0.8848394443912908 recall 0.9323869457046685 f1 0.9325147532958201\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "441 of 1000 - 8.094183444976807 s\n",
      "Accuracy 0.9316552026928143 precision 0.9320484061579866 specificity 0.8761788587453662 recall 0.9316552026928143 f1 0.9318376758086103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "442 of 1000 - 8.03806734085083 s\n",
      "Accuracy 0.9315088540904435 precision 0.9316309588470645 specificity 0.8790165628845665 recall 0.9315088540904435 f1 0.9315682329168453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "443 of 1000 - 7.89692497253418 s\n",
      "Accuracy 0.9329723401141519 precision 0.9338167028889642 specificity 0.8904229227868825 recall 0.9329723401141519 f1 0.9333298584452081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "444 of 1000 - 7.760439872741699 s\n",
      "Accuracy 0.9363383579686814 precision 0.9359786032789001 specificity 0.8802012835566885 recall 0.9363383579686814 f1 0.9361360082610506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "445 of 1000 - 7.580596208572388 s\n",
      "Accuracy 0.9353139177520855 precision 0.9356695878656439 specificity 0.8911197077877417 recall 0.9353139177520855 f1 0.9354767910025062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "446 of 1000 - 7.636307001113892 s\n",
      "Accuracy 0.9334113859212645 precision 0.9329807191902196 specificity 0.8729741368027764 recall 0.9334113859212645 f1 0.9331669477630328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "447 of 1000 - 7.548810005187988 s\n",
      "Accuracy 0.9296063222596225 precision 0.9295601818553552 specificity 0.8720834175850041 recall 0.9296063222596225 f1 0.9295830156090754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "448 of 1000 - 7.57352089881897 s\n",
      "Accuracy 0.9298990194643642 precision 0.9299136435578164 specificity 0.8783925942832216 recall 0.9298990194643642 f1 0.9299063057737489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "449 of 1000 - 7.6660475730896 s\n",
      "Accuracy 0.9356066149568272 precision 0.9354751561938359 specificity 0.8848035495713128 recall 0.9356066149568272 f1 0.935538257987481\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "450 of 1000 - 7.6383373737335205 s\n",
      "Accuracy 0.9310698082833309 precision 0.9313048616021111 specificity 0.8797530294189497 recall 0.9310698082833309 f1 0.9311814720077984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "451 of 1000 - 7.656805753707886 s\n",
      "Accuracy 0.9297526708619933 precision 0.9300710068761182 specificity 0.8798423343294564 recall 0.9297526708619933 f1 0.9299015207796234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "452 of 1000 - 7.6050331592559814 s\n",
      "Accuracy 0.9310698082833309 precision 0.9312155915120696 specificity 0.8740298494873315 recall 0.9310698082833309 f1 0.9311405463239046\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "453 of 1000 - 7.689016342163086 s\n",
      "Accuracy 0.9284355334406557 precision 0.9289762298030662 specificity 0.875883994191367 recall 0.9284355334406557 f1 0.928680858126958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "454 of 1000 - 7.666938781738281 s\n",
      "Accuracy 0.9345821747402312 precision 0.9345679298343688 specificity 0.8822453818887226 recall 0.9345821747402312 f1 0.934575025847601\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "455 of 1000 - 7.569044351577759 s\n",
      "Accuracy 0.937655495390019 precision 0.9380406974891505 specificity 0.8936654555259635 recall 0.937655495390019 f1 0.9378302956276912\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "456 of 1000 - 7.60210919380188 s\n",
      "Accuracy 0.9306307624762183 precision 0.930660080102887 specificity 0.8790807171036017 recall 0.9306307624762183 f1 0.9306453178911315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "457 of 1000 - 7.565270662307739 s\n",
      "Accuracy 0.9291672764525098 precision 0.9294362868898278 specificity 0.8728081279456248 recall 0.9291672764525098 f1 0.929295039888211\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "458 of 1000 - 7.539215564727783 s\n",
      "Accuracy 0.9358993121615689 precision 0.9357889230931591 specificity 0.8821139334776937 recall 0.9358993121615689 f1 0.935842409127525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "459 of 1000 - 7.487045764923096 s\n",
      "Accuracy 0.932825991511781 precision 0.9328104808907287 specificity 0.8740234964607841 recall 0.932825991511781 f1 0.932818209302382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "460 of 1000 - 7.635965347290039 s\n",
      "Accuracy 0.9316552026928143 precision 0.9319807813949358 specificity 0.8837322114294701 recall 0.9316552026928143 f1 0.93180659210322\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "461 of 1000 - 7.729800462722778 s\n",
      "Accuracy 0.9307771110785892 precision 0.9313682690419297 specificity 0.8821833933339842 recall 0.9307771110785892 f1 0.9310408347577892\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "462 of 1000 - 7.826905727386475 s\n",
      "Accuracy 0.9320942484999268 precision 0.9328573952957617 specificity 0.8848884601264776 recall 0.9320942484999268 f1 0.9324251390695524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "463 of 1000 - 7.833737850189209 s\n",
      "Accuracy 0.9323869457046685 precision 0.9324473382636503 specificity 0.8785700678019345 recall 0.9323869457046685 f1 0.9324167201980471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "464 of 1000 - 7.680782079696655 s\n",
      "Accuracy 0.9342894775354895 precision 0.9346799155856543 specificity 0.8867206812056657 recall 0.9342894775354895 f1 0.9344682935003956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "465 of 1000 - 7.7291951179504395 s\n",
      "Accuracy 0.9265330016098346 precision 0.9265015808729211 specificity 0.868991931361954 recall 0.9265330016098346 f1 0.9265171877286915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "466 of 1000 - 7.691549062728882 s\n",
      "Accuracy 0.9265330016098346 precision 0.9269483686271226 specificity 0.8721345470121704 recall 0.9265330016098346 f1 0.9267257808157711\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "467 of 1000 - 7.596418142318726 s\n",
      "Accuracy 0.9304844138738475 precision 0.9307270665976759 specificity 0.8766360602279133 recall 0.9304844138738475 f1 0.9305998347168\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "468 of 1000 - 7.641999244689941 s\n",
      "Accuracy 0.9360456607639397 precision 0.9366018993967287 specificity 0.8910875162886968 recall 0.9360456607639397 f1 0.9362914829888357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "469 of 1000 - 7.687986135482788 s\n",
      "Accuracy 0.9310698082833309 precision 0.9305661046663931 specificity 0.8664843834204549 recall 0.9310698082833309 f1 0.9307812929347765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "470 of 1000 - 7.639668703079224 s\n",
      "Accuracy 0.9296063222596225 precision 0.929054021407706 specificity 0.8678373868175833 recall 0.9296063222596225 f1 0.9292816660382753\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "471 of 1000 - 7.674001693725586 s\n",
      "Accuracy 0.9350212205473438 precision 0.93499247830736 specificity 0.881278325725724 recall 0.9350212205473438 f1 0.9350067428256281\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "472 of 1000 - 7.671008586883545 s\n",
      "Accuracy 0.9284355334406557 precision 0.9285132078212908 specificity 0.8742993502758573 recall 0.9284355334406557 f1 0.9284737239131493\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "473 of 1000 - 7.6804845333099365 s\n",
      "Accuracy 0.9312161568857017 precision 0.9311868412541519 specificity 0.8775628578111014 recall 0.9312161568857017 f1 0.931201394670842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "474 of 1000 - 7.547667980194092 s\n",
      "Accuracy 0.9383872384018732 precision 0.9390663355765251 specificity 0.8969439163418913 recall 0.9383872384018732 f1 0.9386779042569015\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "475 of 1000 - 7.5833213329315186 s\n",
      "Accuracy 0.9348748719449729 precision 0.9354195215244729 specificity 0.8862049173381036 recall 0.9348748719449729 f1 0.9351182326255204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "476 of 1000 - 7.514045000076294 s\n",
      "Accuracy 0.9332650373188937 precision 0.9338603812329215 specificity 0.8862355986555995 recall 0.9332650373188937 f1 0.9335287462880598\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "477 of 1000 - 7.542504787445068 s\n",
      "Accuracy 0.9291672764525098 precision 0.9287539280197407 specificity 0.8682864733790576 recall 0.9291672764525098 f1 0.9289369931834512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "478 of 1000 - 7.4360058307647705 s\n",
      "Accuracy 0.9307771110785892 precision 0.9308846414438365 specificity 0.8775703576412648 recall 0.9307771110785892 f1 0.9308295968060631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "479 of 1000 - 7.5410027503967285 s\n",
      "Accuracy 0.9325332943070394 precision 0.9319739433082167 specificity 0.8677177517180652 recall 0.9325332943070394 f1 0.9322038084574777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "480 of 1000 - 7.360014200210571 s\n",
      "Accuracy 0.9312161568857017 precision 0.9318615041971567 specificity 0.8776318227679517 recall 0.9312161568857017 f1 0.9315043176861205\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "481 of 1000 - 7.44304633140564 s\n",
      "Accuracy 0.9350212205473438 precision 0.9348250304614407 specificity 0.8774101545760472 recall 0.9350212205473438 f1 0.9349178507634737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "482 of 1000 - 7.504013299942017 s\n",
      "Accuracy 0.9249231669837553 precision 0.9244582832493758 specificity 0.8585339902025168 recall 0.9249231669837553 f1 0.9246655476622854\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "483 of 1000 - 7.5411272048950195 s\n",
      "Accuracy 0.9304844138738475 precision 0.9307678785486557 specificity 0.8748621720427909 recall 0.9304844138738475 f1 0.9306184986708985\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "484 of 1000 - 7.5215232372283936 s\n",
      "Accuracy 0.928142836235914 precision 0.9289270550393774 specificity 0.8818837056955768 recall 0.928142836235914 f1 0.9284832453286056\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "485 of 1000 - 7.427973031997681 s\n",
      "Accuracy 0.931947899897556 precision 0.9322111123748122 specificity 0.8822338029087261 recall 0.931947899897556 f1 0.9320719828366726\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "486 of 1000 - 7.813000679016113 s\n",
      "Accuracy 0.936777403775794 precision 0.9368927267594703 specificity 0.8868558664396983 recall 0.936777403775794 f1 0.9368333613349299\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "487 of 1000 - 7.905581474304199 s\n",
      "Accuracy 0.9304844138738475 precision 0.9304691828945161 specificity 0.874369814186251 recall 0.9304844138738475 f1 0.9304767721114654\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "488 of 1000 - 8.22318959236145 s\n",
      "Accuracy 0.9304844138738475 precision 0.9304690619180069 specificity 0.8736787882993271 recall 0.9304844138738475 f1 0.9304767115510124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "489 of 1000 - 7.956000328063965 s\n",
      "Accuracy 0.934728523342602 precision 0.9349337370011711 specificity 0.8870739913350718 recall 0.934728523342602 f1 0.934826005633393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "490 of 1000 - 7.875308036804199 s\n",
      "Accuracy 0.9316552026928143 precision 0.9312631784085604 specificity 0.8714060581305462 recall 0.9316552026928143 f1 0.9314368937701978\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "491 of 1000 - 7.736809730529785 s\n",
      "Accuracy 0.9310698082833309 precision 0.9316658253831123 specificity 0.8816870835279201 recall 0.9310698082833309 f1 0.9313358036013075\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "492 of 1000 - 7.624010801315308 s\n",
      "Accuracy 0.9279964876335431 precision 0.9281234255396272 specificity 0.8735746143025664 recall 0.9279964876335431 f1 0.9280583004821478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "493 of 1000 - 7.778087377548218 s\n",
      "Accuracy 0.9332650373188937 precision 0.9332947238222961 specificity 0.8795525128640914 recall 0.9332650373188937 f1 0.9332797747789353\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "494 of 1000 - 7.67399787902832 s\n",
      "Accuracy 0.9284355334406557 precision 0.9286406886549677 specificity 0.8765834210623823 recall 0.9284355334406557 f1 0.928533761980319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "495 of 1000 - 7.648409366607666 s\n",
      "Accuracy 0.929020927850139 precision 0.9294085141932698 specificity 0.8757527125485314 recall 0.929020927850139 f1 0.9292009204356428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "496 of 1000 - 7.642915487289429 s\n",
      "Accuracy 0.9323869457046685 precision 0.9323869457046685 specificity 0.876159562115166 recall 0.9323869457046685 f1 0.9323869457046685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "497 of 1000 - 7.552001953125 s\n",
      "Accuracy 0.9288745792477682 precision 0.9286078135078826 specificity 0.8677298369714125 recall 0.9288745792477682 f1 0.9287326567411716\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "498 of 1000 - 7.601983308792114 s\n",
      "Accuracy 0.9334113859212645 precision 0.933519247144374 specificity 0.8788548730977213 recall 0.9334113859212645 f1 0.9334640113436458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "499 of 1000 - 7.643565654754639 s\n",
      "Accuracy 0.9315088540904435 precision 0.9321035747742865 specificity 0.8850336478585287 recall 0.9315088540904435 f1 0.9317726641692204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "500 of 1000 - 7.798515558242798 s\n",
      "Accuracy 0.9361920093663105 precision 0.9355733247354584 specificity 0.8748110356946025 recall 0.9361920093663105 f1 0.9357982369114064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "501 of 1000 - 7.730044364929199 s\n",
      "Accuracy 0.9323869457046685 precision 0.9331633937370745 specificity 0.8882768090662848 recall 0.9323869457046685 f1 0.9327203694660943\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "502 of 1000 - 7.610505104064941 s\n",
      "Accuracy 0.9291672764525098 precision 0.9296943815555739 specificity 0.881834895231291 recall 0.9291672764525098 f1 0.9294046104123903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "503 of 1000 - 7.826216220855713 s\n",
      "Accuracy 0.9342894775354895 precision 0.9340824053569188 specificity 0.8778200192006655 recall 0.9342894775354895 f1 0.9341799426942013\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "504 of 1000 - 7.7568182945251465 s\n",
      "Accuracy 0.931947899897556 precision 0.9319039712693321 specificity 0.8775761315292313 recall 0.931947899897556 f1 0.9319256992082232\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "505 of 1000 - 7.7700724601745605 s\n",
      "Accuracy 0.9307771110785892 precision 0.9312597162076035 specificity 0.8807744440219307 recall 0.9307771110785892 f1 0.9309964877233506\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "506 of 1000 - 7.711047410964966 s\n",
      "Accuracy 0.9301917166691058 precision 0.9297248825355304 specificity 0.8689409593380948 recall 0.9301917166691058 f1 0.9299260245483824\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "507 of 1000 - 7.698987245559692 s\n",
      "Accuracy 0.9360456607639397 precision 0.9358686548448719 specificity 0.880777683256057 recall 0.9360456607639397 f1 0.9359526263370321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "508 of 1000 - 7.803915023803711 s\n",
      "Accuracy 0.9325332943070394 precision 0.9331128850942739 specificity 0.8851392264508768 recall 0.9325332943070394 f1 0.9327910880128032\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "509 of 1000 - 7.608030796051025 s\n",
      "Accuracy 0.93092345968096 precision 0.9304285608235368 specificity 0.8696847243404324 recall 0.93092345968096 f1 0.93063787711937\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "510 of 1000 - 7.779037237167358 s\n",
      "Accuracy 0.9344358261378604 precision 0.9343778420344988 specificity 0.879266278635673 recall 0.9344358261378604 f1 0.9344064069552316\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "511 of 1000 - 7.7300004959106445 s\n",
      "Accuracy 0.9312161568857017 precision 0.9311860476473418 specificity 0.8752995294265242 recall 0.9312161568857017 f1 0.9312009969042302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "512 of 1000 - 7.885519742965698 s\n",
      "Accuracy 0.9354602663544563 precision 0.9358494500651124 specificity 0.8877843290725786 recall 0.9354602663544563 f1 0.9356383369173681\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "513 of 1000 - 7.781508445739746 s\n",
      "Accuracy 0.9313625054880725 precision 0.9314378648805984 specificity 0.8785933731286224 recall 0.9313625054880725 f1 0.9313995322325984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "514 of 1000 - 7.583050966262817 s\n",
      "Accuracy 0.9339967803307478 precision 0.934041838659819 specificity 0.87944779869577 recall 0.9339967803307478 f1 0.9340190695197235\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "515 of 1000 - 7.683379888534546 s\n",
      "Accuracy 0.9284355334406557 precision 0.9283277469007866 specificity 0.8694446595222959 recall 0.9284355334406557 f1 0.9283803557516564\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "516 of 1000 - 7.668006420135498 s\n",
      "Accuracy 0.9278501390311723 precision 0.9279915636955575 specificity 0.8747840023007961 recall 0.9278501390311723 f1 0.9279187669933053\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "517 of 1000 - 7.682616949081421 s\n",
      "Accuracy 0.9279964876335431 precision 0.9284709047742692 specificity 0.8768299240654148 recall 0.9279964876335431 f1 0.9282134717238102\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "518 of 1000 - 7.772157430648804 s\n",
      "Accuracy 0.9325332943070394 precision 0.9326125635791902 specificity 0.8748651152228885 recall 0.9325332943070394 f1 0.9325722585121995\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "519 of 1000 - 7.738999605178833 s\n",
      "Accuracy 0.9278501390311723 precision 0.9286658298314443 specificity 0.8782006003529004 recall 0.9278501390311723 f1 0.9282056448203174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "520 of 1000 - 7.72504448890686 s\n",
      "Accuracy 0.9339967803307478 precision 0.9353875444625522 specificity 0.8911733795331842 recall 0.9339967803307478 f1 0.9345511101614097\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "521 of 1000 - 7.615703821182251 s\n",
      "Accuracy 0.930045368066735 precision 0.9312528270539142 specificity 0.884648855059374 recall 0.930045368066735 f1 0.930542656188536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "522 of 1000 - 7.571839094161987 s\n",
      "Accuracy 0.9312161568857017 precision 0.9317217847087643 specificity 0.8804282113891776 recall 0.9312161568857017 f1 0.9314453593738489\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "523 of 1000 - 7.766052722930908 s\n",
      "Accuracy 0.9306307624762183 precision 0.9309565675157346 specificity 0.8784311279598349 recall 0.9306307624762183 f1 0.9307832007849629\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "524 of 1000 - 7.648613452911377 s\n",
      "Accuracy 0.9304844138738475 precision 0.9302883457828389 specificity 0.8693891400034285 recall 0.9304844138738475 f1 0.9303818784408084\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "525 of 1000 - 7.732096433639526 s\n",
      "Accuracy 0.9313625054880725 precision 0.9313204152273394 specificity 0.8807304893893638 recall 0.9313625054880725 f1 0.931341228320802\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "526 of 1000 - 7.5630409717559814 s\n",
      "Accuracy 0.9269720474169472 precision 0.9270504380323717 specificity 0.8726408558088593 recall 0.9269720474169472 f1 0.9270106002258917\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "527 of 1000 - 7.627518653869629 s\n",
      "Accuracy 0.9284355334406557 precision 0.9297280134857113 specificity 0.8825796960161842 recall 0.9284355334406557 f1 0.9289657513110511\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "528 of 1000 - 7.678828477859497 s\n",
      "Accuracy 0.9326796429094102 precision 0.9331337223935201 specificity 0.8838502147905962 recall 0.9326796429094102 f1 0.9328861415234548\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "529 of 1000 - 7.610456228256226 s\n",
      "Accuracy 0.9303380652714767 precision 0.9308773474542766 specificity 0.880722502472319 recall 0.9303380652714767 f1 0.9305810721174848\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "530 of 1000 - 7.863671064376831 s\n",
      "Accuracy 0.93092345968096 precision 0.9305345971253594 specificity 0.8693197850549406 recall 0.93092345968096 f1 0.9307082022210034\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "531 of 1000 - 7.749033212661743 s\n",
      "Accuracy 0.9345821747402312 precision 0.9349038241508372 specificity 0.8866729248748513 recall 0.9345821747402312 f1 0.9347314168691677\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "532 of 1000 - 7.668044805526733 s\n",
      "Accuracy 0.9318015512951852 precision 0.9325772302022025 specificity 0.8832476923773798 recall 0.9318015512951852 f1 0.9321384976675305\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "533 of 1000 - 7.689050912857056 s\n",
      "Accuracy 0.935752963559198 precision 0.935883625058442 specificity 0.886149267905097 recall 0.935752963559198 f1 0.9358161520933858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "534 of 1000 - 7.642116069793701 s\n",
      "Accuracy 0.9274110932240597 precision 0.927575815016111 specificity 0.8708045738417043 recall 0.9274110932240597 f1 0.9274908499763143\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "535 of 1000 - 7.635630130767822 s\n",
      "Accuracy 0.9318015512951852 precision 0.9322313984147732 specificity 0.8806829172691891 recall 0.9318015512951852 f1 0.9319986975047727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "536 of 1000 - 7.614468336105347 s\n",
      "Accuracy 0.929020927850139 precision 0.9294038112793578 specificity 0.8768383569848228 recall 0.929020927850139 f1 0.9291986287043508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "537 of 1000 - 7.723508596420288 s\n",
      "Accuracy 0.9310698082833309 precision 0.9315268179329479 specificity 0.8785720740782307 recall 0.9310698082833309 f1 0.9312790996817393\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "538 of 1000 - 7.7771875858306885 s\n",
      "Accuracy 0.9297526708619933 precision 0.9295238795665006 specificity 0.8722254781269199 recall 0.9297526708619933 f1 0.9296315850916916\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "539 of 1000 - 7.631946563720703 s\n",
      "Accuracy 0.9301917166691058 precision 0.9300313781453856 specificity 0.873215648894228 recall 0.9301917166691058 f1 0.9301083777041799\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "540 of 1000 - 7.722731113433838 s\n",
      "Accuracy 0.9297526708619933 precision 0.9296365635618883 specificity 0.8747785828305507 recall 0.9297526708619933 f1 0.9296929552626444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "541 of 1000 - 7.726362466812134 s\n",
      "Accuracy 0.928142836235914 precision 0.928012560257211 specificity 0.8736779032010354 recall 0.928142836235914 f1 0.9280756166092512\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "542 of 1000 - 7.856108665466309 s\n",
      "Accuracy 0.9288745792477682 precision 0.9294300293930933 specificity 0.8770791846603723 recall 0.9288745792477682 f1 0.929125643874088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "543 of 1000 - 7.726074934005737 s\n",
      "Accuracy 0.9307771110785892 precision 0.9308902203556647 specificity 0.873117011804775 recall 0.9307771110785892 f1 0.9308323631786929\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "544 of 1000 - 7.633030652999878 s\n",
      "Accuracy 0.9353139177520855 precision 0.9349059390041333 specificity 0.8760967683677883 recall 0.9353139177520855 f1 0.9350824041809124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "545 of 1000 - 7.6912195682525635 s\n",
      "Accuracy 0.9272647446216888 precision 0.9270162931284375 specificity 0.8686751677436235 recall 0.9272647446216888 f1 0.9271330317539532\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "546 of 1000 - 7.665022850036621 s\n",
      "Accuracy 0.9358993121615689 precision 0.9360162966562552 specificity 0.8851811879984293 recall 0.9358993121615689 f1 0.935956102941152\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "547 of 1000 - 7.723155498504639 s\n",
      "Accuracy 0.9294599736572515 precision 0.9292043779587496 specificity 0.8717149143838044 recall 0.9294599736572515 f1 0.9293237215549921\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "548 of 1000 - 7.83902645111084 s\n",
      "Accuracy 0.9334113859212645 precision 0.9337038205632098 specificity 0.884588112579867 recall 0.9334113859212645 f1 0.9335481563643008\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "549 of 1000 - 7.717833995819092 s\n",
      "Accuracy 0.9304844138738475 precision 0.9302982567930589 specificity 0.8739064242331863 recall 0.9304844138738475 f1 0.9303869127448724\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "550 of 1000 - 7.6755406856536865 s\n",
      "Accuracy 0.9320942484999268 precision 0.9319797533441398 specificity 0.8771705985619938 recall 0.9320942484999268 f1 0.9320353192062139\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "551 of 1000 - 7.690000057220459 s\n",
      "Accuracy 0.93092345968096 precision 0.9308690137841246 specificity 0.8823757040633077 recall 0.93092345968096 f1 0.9308958289054394\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "552 of 1000 - 7.768873453140259 s\n",
      "Accuracy 0.9298990194643642 precision 0.9301426687136726 specificity 0.875907886290496 recall 0.9298990194643642 f1 0.930014953729433\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "553 of 1000 - 7.742604970932007 s\n",
      "Accuracy 0.9296063222596225 precision 0.9297825554348623 specificity 0.8750842291346562 recall 0.9296063222596225 f1 0.9296912757501462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "554 of 1000 - 7.704009056091309 s\n",
      "Accuracy 0.9335577345236353 precision 0.9338008737605347 specificity 0.8843512014596302 recall 0.9335577345236353 f1 0.9336725999763508\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "555 of 1000 - 7.681427717208862 s\n",
      "Accuracy 0.9293136250548807 precision 0.9292980443827649 specificity 0.8717314152249465 recall 0.9293136250548807 f1 0.9293058084559307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "556 of 1000 - 7.779212713241577 s\n",
      "Accuracy 0.9291672764525098 precision 0.9295899451357305 specificity 0.8803244022602468 recall 0.9291672764525098 f1 0.9293612483809313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "557 of 1000 - 7.607064485549927 s\n",
      "Accuracy 0.9363383579686814 precision 0.9361346428711504 specificity 0.8801125868645787 recall 0.9363383579686814 f1 0.9362304392684663\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "558 of 1000 - 7.6969804763793945 s\n",
      "Accuracy 0.9332650373188937 precision 0.9333831927325897 specificity 0.8827946651697429 recall 0.9332650373188937 f1 0.9333224400435397\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "559 of 1000 - 7.867019176483154 s\n",
      "Accuracy 0.9265330016098346 precision 0.9261413545006686 specificity 0.86126492791584 recall 0.9265330016098346 f1 0.9263193622482009\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "560 of 1000 - 7.781011581420898 s\n",
      "Accuracy 0.9221425435387092 precision 0.9227051234877983 specificity 0.8642254321047161 recall 0.9221425435387092 f1 0.9224007037287637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "561 of 1000 - 7.803323745727539 s\n",
      "Accuracy 0.9334113859212645 precision 0.9331761480467666 specificity 0.8762199530293494 recall 0.9334113859212645 f1 0.9332860834342136\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "562 of 1000 - 7.668017148971558 s\n",
      "Accuracy 0.9307771110785892 precision 0.9307627161326846 specificity 0.8792649013865962 recall 0.9307771110785892 f1 0.9307698877795418\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "563 of 1000 - 7.6452953815460205 s\n",
      "Accuracy 0.9307771110785892 precision 0.931145395909803 specificity 0.8813637776165063 recall 0.9307771110785892 f1 0.9309475408319211\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "564 of 1000 - 7.702078342437744 s\n",
      "Accuracy 0.9326796429094102 precision 0.9328581346005773 specificity 0.8837005924667672 recall 0.9326796429094102 f1 0.9327651476380366\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "565 of 1000 - 7.7555224895477295 s\n",
      "Accuracy 0.929020927850139 precision 0.9295140488370118 specificity 0.8776687730273613 recall 0.929020927850139 f1 0.9292456485487178\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "566 of 1000 - 7.648502826690674 s\n",
      "Accuracy 0.9348748719449729 precision 0.9346386870351485 specificity 0.8843430147186172 recall 0.9348748719449729 f1 0.9347473873730048\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "567 of 1000 - 7.659208059310913 s\n",
      "Accuracy 0.9312161568857017 precision 0.9314359399508713 specificity 0.879230836230007 recall 0.9312161568857017 f1 0.9313209256889612\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "568 of 1000 - 7.6559998989105225 s\n",
      "Accuracy 0.9312161568857017 precision 0.9314960664285713 specificity 0.8818509898679838 recall 0.9312161568857017 f1 0.9313477178155171\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "569 of 1000 - 7.673020124435425 s\n",
      "Accuracy 0.9320942484999268 precision 0.9322187916863729 specificity 0.8776732767437888 recall 0.9320942484999268 f1 0.9321548278161791\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "570 of 1000 - 7.605836391448975 s\n",
      "Accuracy 0.9316552026928143 precision 0.9318237421179937 specificity 0.8801730984728652 recall 0.9316552026928143 f1 0.931736314158328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "571 of 1000 - 7.631446361541748 s\n",
      "Accuracy 0.936631055173423 precision 0.9363628860004084 specificity 0.8821283801409282 recall 0.936631055173423 f1 0.9364851997717992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "572 of 1000 - 7.632149696350098 s\n",
      "Accuracy 0.9325332943070394 precision 0.9322738215626877 specificity 0.8759163236319737 recall 0.9325332943070394 f1 0.9323940366307472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "573 of 1000 - 7.665520906448364 s\n",
      "Accuracy 0.9291672764525098 precision 0.9293602837747782 specificity 0.8749349871882851 recall 0.9291672764525098 f1 0.9292600268998225\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "574 of 1000 - 7.699550151824951 s\n",
      "Accuracy 0.9310698082833309 precision 0.9305522761690247 specificity 0.8640819558800101 recall 0.9310698082833309 f1 0.9307740446373954\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "575 of 1000 - 7.739681720733643 s\n",
      "Accuracy 0.9332650373188937 precision 0.9332933056796128 specificity 0.8835350143520314 recall 0.9332650373188937 f1 0.9332790674899515\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "576 of 1000 - 7.523070812225342 s\n",
      "Accuracy 0.9274110932240597 precision 0.9272050568639318 specificity 0.8695659893866388 recall 0.9274110932240597 f1 0.9273030014168776\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "577 of 1000 - 7.672638177871704 s\n",
      "Accuracy 0.925215864188497 precision 0.9253270758391321 specificity 0.8713347987636471 recall 0.925215864188497 f1 0.9252702224479771\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "578 of 1000 - 7.739524841308594 s\n",
      "Accuracy 0.9307771110785892 precision 0.9307611890658147 specificity 0.8705563106665367 recall 0.9307771110785892 f1 0.930769123329624\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "579 of 1000 - 7.573684453964233 s\n",
      "Accuracy 0.930045368066735 precision 0.9301741767581251 specificity 0.8734926876112356 recall 0.930045368066735 f1 0.9301080844422267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "580 of 1000 - 7.534530878067017 s\n",
      "Accuracy 0.9350212205473438 precision 0.935109829611334 specificity 0.8828982676641969 recall 0.9350212205473438 f1 0.9350645679806833\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "581 of 1000 - 7.618821144104004 s\n",
      "Accuracy 0.929020927850139 precision 0.92912622014435 specificity 0.8782732019279553 recall 0.929020927850139 f1 0.9290723185808227\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "582 of 1000 - 7.6325273513793945 s\n",
      "Accuracy 0.935752963559198 precision 0.9362281119446608 specificity 0.8855764821155964 recall 0.935752963559198 f1 0.935967957284516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "583 of 1000 - 7.6494975090026855 s\n",
      "Accuracy 0.9332650373188937 precision 0.9330205267167567 specificity 0.8771815872547538 recall 0.9332650373188937 f1 0.9331342182198704\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "584 of 1000 - 7.661541223526001 s\n",
      "Accuracy 0.93092345968096 precision 0.9305117810470335 specificity 0.869336623794934 recall 0.93092345968096 f1 0.930693736007731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "585 of 1000 - 7.528509616851807 s\n",
      "Accuracy 0.9296063222596225 precision 0.9304869390511219 specificity 0.882070787834235 recall 0.9296063222596225 f1 0.9299843785623688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "586 of 1000 - 7.635723829269409 s\n",
      "Accuracy 0.9394116786184692 precision 0.9397011680941123 specificity 0.8938793774380532 recall 0.9394116786184692 f1 0.9395457436038991\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "587 of 1000 - 7.613008975982666 s\n",
      "Accuracy 0.9316552026928143 precision 0.9314416974632538 specificity 0.8740148239843389 recall 0.9316552026928143 f1 0.931542506807578\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "588 of 1000 - 7.522609710693359 s\n",
      "Accuracy 0.9307771110785892 precision 0.9303552710509461 specificity 0.8694908996227293 recall 0.9307771110785892 f1 0.9305407481064025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "589 of 1000 - 7.6407740116119385 s\n",
      "Accuracy 0.937655495390019 precision 0.9379438856503135 specificity 0.8929974281802363 recall 0.937655495390019 f1 0.9377891661244131\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "590 of 1000 - 7.6628782749176025 s\n",
      "Accuracy 0.9298990194643642 precision 0.930136027392429 specificity 0.8783070933191858 recall 0.9298990194643642 f1 0.9300116899239665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "591 of 1000 - 7.621035575866699 s\n",
      "Accuracy 0.9287282306453973 precision 0.928744553357722 specificity 0.8681266240332677 recall 0.9287282306453973 f1 0.9287363654908173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "592 of 1000 - 7.815155029296875 s\n",
      "Accuracy 0.9329723401141519 precision 0.9337018430018261 specificity 0.8893280425488329 recall 0.9329723401141519 f1 0.9332869562454814\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "593 of 1000 - 7.720824956893921 s\n",
      "Accuracy 0.923313332357676 precision 0.923313332357676 specificity 0.8558333286506585 recall 0.923313332357676 f1 0.923313332357676\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "594 of 1000 - 7.640042781829834 s\n",
      "Accuracy 0.9296063222596225 precision 0.9294730426982739 specificity 0.8725176229929471 recall 0.9296063222596225 f1 0.9295375640398466\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "595 of 1000 - 7.821964502334595 s\n",
      "Accuracy 0.9329723401141519 precision 0.9329723401141519 specificity 0.8794894872443539 recall 0.9329723401141519 f1 0.9329723401141519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "596 of 1000 - 7.702731132507324 s\n",
      "Accuracy 0.930045368066735 precision 0.92998614767968 specificity 0.8751412977448106 recall 0.930045368066735 f1 0.9300153410935307\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "597 of 1000 - 7.6736366748809814 s\n",
      "Accuracy 0.9323869457046685 precision 0.9325131581767602 specificity 0.8766791396695996 recall 0.9323869457046685 f1 0.9324483479356618\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "598 of 1000 - 7.731186628341675 s\n",
      "Accuracy 0.9312161568857017 precision 0.9307508477309808 specificity 0.871424868755324 recall 0.9312161568857017 f1 0.9309493897980062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "599 of 1000 - 7.782177686691284 s\n",
      "Accuracy 0.928142836235914 precision 0.9289579062838615 specificity 0.8784919543254597 recall 0.928142836235914 f1 0.9284979484986846\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "600 of 1000 - 7.693305969238281 s\n",
      "Accuracy 0.9297526708619933 precision 0.9303902171232914 specificity 0.8833160695786941 recall 0.9297526708619933 f1 0.9300343775953959\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "601 of 1000 - 7.789507150650024 s\n",
      "Accuracy 0.9307771110785892 precision 0.9313170563861216 specificity 0.883985915891822 recall 0.9307771110785892 f1 0.931019012981858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "602 of 1000 - 7.731470346450806 s\n",
      "Accuracy 0.9385335870042442 precision 0.9387020486205414 specificity 0.8918938510603678 recall 0.9385335870042442 f1 0.9386139936812321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "603 of 1000 - 7.744129657745361 s\n",
      "Accuracy 0.9293136250548807 precision 0.9287988828539234 specificity 0.8705658596930251 recall 0.9293136250548807 f1 0.9290126866672708\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "604 of 1000 - 7.604533433914185 s\n",
      "Accuracy 0.9303380652714767 precision 0.9305691959495856 specificity 0.8742545110384157 recall 0.9303380652714767 f1 0.9304484467876836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "605 of 1000 - 7.6813805103302 s\n",
      "Accuracy 0.9310698082833309 precision 0.9309428884600082 specificity 0.877375205672769 recall 0.9310698082833309 f1 0.9310042428266071\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "606 of 1000 - 7.671011447906494 s\n",
      "Accuracy 0.9350212205473438 precision 0.9349058263166224 specificity 0.8779940905062668 recall 0.9350212205473438 f1 0.9349617996046155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "607 of 1000 - 7.7825140953063965 s\n",
      "Accuracy 0.9294599736572515 precision 0.9301474294868651 specificity 0.8819212743112688 recall 0.9294599736572515 f1 0.9297624586055052\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "608 of 1000 - 7.724036693572998 s\n",
      "Accuracy 0.9274110932240597 precision 0.9275734493468623 specificity 0.8721092784812912 recall 0.9274110932240597 f1 0.927489680095699\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "609 of 1000 - 7.714034795761108 s\n",
      "Accuracy 0.9277037904288014 precision 0.9287750244941276 specificity 0.8820115782202373 recall 0.9277037904288014 f1 0.9281533131848886\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "610 of 1000 - 7.6080405712127686 s\n",
      "Accuracy 0.9337040831260062 precision 0.9336050466278952 specificity 0.8794394502089399 recall 0.9337040831260062 f1 0.9336532691139537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "611 of 1000 - 7.875112771987915 s\n",
      "Accuracy 0.9247768183813845 precision 0.9255197121610854 specificity 0.8714636364900227 recall 0.9247768183813845 f1 0.9251070971585565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "612 of 1000 - 7.7587151527404785 s\n",
      "Accuracy 0.9322405971022977 precision 0.9326855802671481 specificity 0.8817139985143821 recall 0.9322405971022977 f1 0.9324439074290897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "613 of 1000 - 7.661355257034302 s\n",
      "Accuracy 0.9369237523781648 precision 0.9369385092130229 specificity 0.8815686636903356 recall 0.9369237523781648 f1 0.9369311036126173\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "614 of 1000 - 7.663045644760132 s\n",
      "Accuracy 0.9320942484999268 precision 0.9326647038970293 specificity 0.8832590450004043 recall 0.9320942484999268 f1 0.932349180703456\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "615 of 1000 - 7.62909460067749 s\n",
      "Accuracy 0.9293136250548807 precision 0.9297078292517558 specificity 0.8744098214228658 recall 0.9293136250548807 f1 0.9294968148449284\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "616 of 1000 - 7.6065099239349365 s\n",
      "Accuracy 0.9345821747402312 precision 0.9345678875527568 specificity 0.8820044211042432 recall 0.9345821747402312 f1 0.9345750046792475\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "617 of 1000 - 7.674169301986694 s\n",
      "Accuracy 0.933850431728377 precision 0.9337154979988941 specificity 0.8818774472370882 recall 0.933850431728377 f1 0.9337803482254926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "618 of 1000 - 7.627748250961304 s\n",
      "Accuracy 0.9345821747402312 precision 0.9352115425333947 specificity 0.8905523953381865 recall 0.9345821747402312 f1 0.9348571651853659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "619 of 1000 - 7.642483711242676 s\n",
      "Accuracy 0.9337040831260062 precision 0.9335804708654192 specificity 0.8808774243235994 recall 0.9337040831260062 f1 0.9336401502848372\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "620 of 1000 - 7.69802713394165 s\n",
      "Accuracy 0.928142836235914 precision 0.9281273522465864 specificity 0.8716364972242775 recall 0.928142836235914 f1 0.9281350682442966\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "621 of 1000 - 7.679237604141235 s\n",
      "Accuracy 0.9293136250548807 precision 0.928997130587011 specificity 0.8718705479121542 recall 0.9293136250548807 f1 0.9291416312184636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "622 of 1000 - 7.6359405517578125 s\n",
      "Accuracy 0.9301917166691058 precision 0.9299551678352702 specificity 0.8742379791661598 recall 0.9301917166691058 f1 0.9300659232741229\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "623 of 1000 - 7.600471496582031 s\n",
      "Accuracy 0.9341431289331187 precision 0.9343473464091475 specificity 0.8870821187671953 recall 0.9341431289331187 f1 0.9342401429928234\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "624 of 1000 - 7.744000196456909 s\n",
      "Accuracy 0.9372164495829065 precision 0.9375213179332581 specificity 0.8926432562426625 recall 0.9372164495829065 f1 0.9373573069165811\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "625 of 1000 - 7.534019470214844 s\n",
      "Accuracy 0.929020927850139 precision 0.9284470073995644 specificity 0.8644092454897577 recall 0.929020927850139 f1 0.9286850832047063\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "626 of 1000 - 7.601094007492065 s\n",
      "Accuracy 0.9266793502122055 precision 0.9270257707073912 specificity 0.8751871487275071 recall 0.9266793502122055 f1 0.9268412842494971\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "627 of 1000 - 7.651519775390625 s\n",
      "Accuracy 0.9301917166691058 precision 0.9298772657510611 specificity 0.8728053744380775 recall 0.9301917166691058 f1 0.9300206879234638\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "628 of 1000 - 7.751054525375366 s\n",
      "Accuracy 0.9332650373188937 precision 0.9333533685193569 specificity 0.8821257080001743 recall 0.9332650373188937 f1 0.933308259074107\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "629 of 1000 - 7.645998477935791 s\n",
      "Accuracy 0.9337040831260062 precision 0.9340315380474393 specificity 0.8846256263917281 recall 0.9337040831260062 f1 0.9338562249953373\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "630 of 1000 - 7.626000165939331 s\n",
      "Accuracy 0.9296063222596225 precision 0.9295281717832842 specificity 0.8696711729664728 recall 0.9296063222596225 f1 0.9295665846957836\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "631 of 1000 - 7.5532331466674805 s\n",
      "Accuracy 0.9303380652714767 precision 0.9309516325304332 specificity 0.8815294421660654 recall 0.9303380652714767 f1 0.9306111788290864\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "632 of 1000 - 7.6760241985321045 s\n",
      "Accuracy 0.9320942484999268 precision 0.9320659314969861 specificity 0.8808792707932807 recall 0.9320942484999268 f1 0.9320799861809527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "633 of 1000 - 7.739002466201782 s\n",
      "Accuracy 0.9313625054880725 precision 0.9311460457899463 specificity 0.8727015333285774 recall 0.9313625054880725 f1 0.9312483173461134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "634 of 1000 - 7.598008155822754 s\n",
      "Accuracy 0.9275574418264305 precision 0.9277263535505632 specificity 0.8774372905414657 recall 0.9275574418264305 f1 0.9276388216443596\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "635 of 1000 - 7.6608359813690186 s\n",
      "Accuracy 0.9322405971022977 precision 0.932344901439421 specificity 0.880992281566559 recall 0.9322405971022977 f1 0.932291470322497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "636 of 1000 - 7.577979564666748 s\n",
      "Accuracy 0.9331186887165227 precision 0.9329046358724326 specificity 0.8744837519993999 recall 0.9331186887165227 f1 0.9330056482978731\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "637 of 1000 - 7.714049577713013 s\n",
      "Accuracy 0.9278501390311723 precision 0.928472513578455 specificity 0.8812643259716659 recall 0.9278501390311723 f1 0.9281265269132797\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "638 of 1000 - 7.667039632797241 s\n",
      "Accuracy 0.9360456607639397 precision 0.9362987949571342 specificity 0.8880567367332777 recall 0.9360456607639397 f1 0.9361645902597298\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "639 of 1000 - 7.673007965087891 s\n",
      "Accuracy 0.9369237523781648 precision 0.9370788115275505 specificity 0.8901094078939037 recall 0.9369237523781648 f1 0.9369980976320236\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "640 of 1000 - 7.540568828582764 s\n",
      "Accuracy 0.9288745792477682 precision 0.9286555824409553 specificity 0.8647799973443318 recall 0.9288745792477682 f1 0.9287598483802523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "641 of 1000 - 7.542003631591797 s\n",
      "Accuracy 0.9348748719449729 precision 0.9350924694861257 specificity 0.888435321965708 recall 0.9348748719449729 f1 0.9349778120204765\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "642 of 1000 - 7.703001022338867 s\n",
      "Accuracy 0.9337040831260062 precision 0.9336050466278952 specificity 0.8794394502089399 recall 0.9337040831260062 f1 0.9336532691139537\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "643 of 1000 - 7.679052114486694 s\n",
      "Accuracy 0.936777403775794 precision 0.9366972557875167 specificity 0.8861090076891521 recall 0.936777403775794 f1 0.9367363761930997\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "644 of 1000 - 7.6260223388671875 s\n",
      "Accuracy 0.9318015512951852 precision 0.9318320929381967 specificity 0.8763081259979068 recall 0.9318015512951852 f1 0.9318167163882303\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "645 of 1000 - 7.5945093631744385 s\n",
      "Accuracy 0.931947899897556 precision 0.9324925925754428 specificity 0.8840965306257011 recall 0.931947899897556 f1 0.932191867136134\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "646 of 1000 - 7.735039710998535 s\n",
      "Accuracy 0.933850431728377 precision 0.9339730388150197 specificity 0.880057300264882 recall 0.933850431728377 f1 0.9339100308415199\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "647 of 1000 - 7.453082323074341 s\n",
      "Accuracy 0.9279964876335431 precision 0.9280604261049081 specificity 0.8710679926319369 recall 0.9279964876335431 f1 0.9280280395956889\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "648 of 1000 - 7.532999753952026 s\n",
      "Accuracy 0.929020927850139 precision 0.928770572661693 specificity 0.8688485641343809 recall 0.929020927850139 f1 0.9288881520600842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "649 of 1000 - 7.518508672714233 s\n",
      "Accuracy 0.9323869457046685 precision 0.932724067325647 specificity 0.8856124700830188 recall 0.9323869457046685 f1 0.9325430018620285\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "650 of 1000 - 7.425028085708618 s\n",
      "Accuracy 0.9287282306453973 precision 0.9292561068265558 specificity 0.8782335232735125 recall 0.9287282306453973 f1 0.9289673117627001\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "651 of 1000 - 7.563977003097534 s\n",
      "Accuracy 0.9315088540904435 precision 0.9319210391339415 specificity 0.8761369897682151 recall 0.9315088540904435 f1 0.9316995736568288\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "652 of 1000 - 7.39990234375 s\n",
      "Accuracy 0.9313625054880725 precision 0.9318114308456249 specificity 0.8803467475582303 recall 0.9313625054880725 f1 0.9315678413071493\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "653 of 1000 - 7.458505868911743 s\n",
      "Accuracy 0.9342894775354895 precision 0.9345425438474626 specificity 0.8869386546034136 recall 0.9342894775354895 f1 0.9344084696433637\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "654 of 1000 - 7.490051746368408 s\n",
      "Accuracy 0.9323869457046685 precision 0.9321907061525525 specificity 0.8761425093186636 recall 0.9323869457046685 f1 0.9322836554337977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "655 of 1000 - 7.466858386993408 s\n",
      "Accuracy 0.9361920093663105 precision 0.9364365774009108 specificity 0.8855453954562181 recall 0.9361920093663105 f1 0.9363074444185092\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "656 of 1000 - 7.6250433921813965 s\n",
      "Accuracy 0.9306307624762183 precision 0.9313658552104359 specificity 0.8868972593152572 recall 0.9306307624762183 f1 0.9309487916885204\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "657 of 1000 - 7.6222147941589355 s\n",
      "Accuracy 0.9279964876335431 precision 0.9279641012395742 specificity 0.8670214293702715 recall 0.9279964876335431 f1 0.9279801888022186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "658 of 1000 - 7.4765894412994385 s\n",
      "Accuracy 0.9282891848382848 precision 0.9285195791295824 specificity 0.873277478401587 recall 0.9282891848382848 f1 0.9283992762662127\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "659 of 1000 - 7.518012046813965 s\n",
      "Accuracy 0.9334113859212645 precision 0.9332849379669951 specificity 0.8788918949552291 recall 0.9334113859212645 f1 0.9333460233105421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "660 of 1000 - 7.55854606628418 s\n",
      "Accuracy 0.9370701009805357 precision 0.9377373894262245 specificity 0.8950104442235925 recall 0.9370701009805357 f1 0.9373573748829308\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "661 of 1000 - 7.479008674621582 s\n",
      "Accuracy 0.936777403775794 precision 0.9367225742452813 specificity 0.8850635115337612 recall 0.936777403775794 f1 0.9367495626910762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "662 of 1000 - 7.524574279785156 s\n",
      "Accuracy 0.9315088540904435 precision 0.9313909953263044 specificity 0.8744207505865417 recall 0.9315088540904435 f1 0.9314482334013795\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "663 of 1000 - 7.546509265899658 s\n",
      "Accuracy 0.9325332943070394 precision 0.9323744509803673 specificity 0.875180506426947 recall 0.9325332943070394 f1 0.9324506588710715\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "664 of 1000 - 7.669042110443115 s\n",
      "Accuracy 0.9334113859212645 precision 0.9328679676664338 specificity 0.8753612446299506 recall 0.9334113859212645 f1 0.9330815921362993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "665 of 1000 - 7.4890546798706055 s\n",
      "Accuracy 0.9326796429094102 precision 0.9326207882823067 specificity 0.8770811447779151 recall 0.9326796429094102 f1 0.9326497918106289\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "666 of 1000 - 7.606068134307861 s\n",
      "Accuracy 0.9345821747402312 precision 0.934786536184227 specificity 0.8807209793642934 recall 0.9345821747402312 f1 0.9346798213465671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "667 of 1000 - 7.448010683059692 s\n",
      "Accuracy 0.9332650373188937 precision 0.9339055142347255 specificity 0.8855317884299223 recall 0.9332650373188937 f1 0.9335472695575536\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "668 of 1000 - 7.410001754760742 s\n",
      "Accuracy 0.9323869457046685 precision 0.9320316599774576 specificity 0.872308371110063 recall 0.9323869457046685 f1 0.9321912985641572\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "669 of 1000 - 7.582237005233765 s\n",
      "Accuracy 0.9329723401141519 precision 0.9330947276528846 specificity 0.8796923025366643 recall 0.9329723401141519 f1 0.9330318414602525\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "670 of 1000 - 7.48346209526062 s\n",
      "Accuracy 0.9306307624762183 precision 0.9303114587905285 specificity 0.8683736466589828 recall 0.9306307624762183 f1 0.9304582056063321\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "671 of 1000 - 7.484025239944458 s\n",
      "Accuracy 0.9312161568857017 precision 0.931184826533474 specificity 0.8717818994083315 recall 0.9312161568857017 f1 0.9312003848627438\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "672 of 1000 - 7.544000148773193 s\n",
      "Accuracy 0.9260939558027221 precision 0.926428959001148 specificity 0.8678134862937091 recall 0.9260939558027221 f1 0.9262520228893601\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "673 of 1000 - 7.494033575057983 s\n",
      "Accuracy 0.9301917166691058 precision 0.9306127601645247 specificity 0.8775029360959695 recall 0.9301917166691058 f1 0.9303858508706984\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "674 of 1000 - 7.504009246826172 s\n",
      "Accuracy 0.9269720474169472 precision 0.9270891344141734 specificity 0.8677222485641304 recall 0.9269720474169472 f1 0.9270293068328878\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "675 of 1000 - 7.5085084438323975 s\n",
      "Accuracy 0.93092345968096 precision 0.9314518798515155 specificity 0.8828807313647887 recall 0.93092345968096 f1 0.9311611271023019\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "676 of 1000 - 7.627054214477539 s\n",
      "Accuracy 0.9291672764525098 precision 0.9295240713801163 specificity 0.8787549544980008 recall 0.9291672764525098 f1 0.9293331883955709\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "677 of 1000 - 7.48052453994751 s\n",
      "Accuracy 0.9272647446216888 precision 0.9270168001611839 specificity 0.8688513845871315 recall 0.9272647446216888 f1 0.9271332902230651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "678 of 1000 - 7.506998777389526 s\n",
      "Accuracy 0.9351675691497147 precision 0.9353022090686526 specificity 0.8833541500974061 recall 0.9351675691497147 f1 0.9352327329593639\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "679 of 1000 - 7.513036727905273 s\n",
      "Accuracy 0.9332650373188937 precision 0.9337706424392649 specificity 0.8818606126520712 recall 0.9332650373188937 f1 0.9334938882469694\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "680 of 1000 - 7.619521856307983 s\n",
      "Accuracy 0.932825991511781 precision 0.9329001355130463 specificity 0.8808043463149914 recall 0.932825991511781 f1 0.9328624075085781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "681 of 1000 - 7.433010578155518 s\n",
      "Accuracy 0.929020927850139 precision 0.9290364780701966 specificity 0.8726903998574365 recall 0.929020927850139 f1 0.9290286768397452\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "682 of 1000 - 7.602017879486084 s\n",
      "Accuracy 0.9345821747402312 precision 0.9346242916375838 specificity 0.8852957182064779 recall 0.9345821747402312 f1 0.9346029978550805\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "683 of 1000 - 7.6435229778289795 s\n",
      "Accuracy 0.9259476072003512 precision 0.9259159654682514 specificity 0.8680402843876203 recall 0.9259476072003512 f1 0.9259316829795887\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "684 of 1000 - 7.589029788970947 s\n",
      "Accuracy 0.9310698082833309 precision 0.9305843526177657 specificity 0.8658869212379696 recall 0.9310698082833309 f1 0.9307941696413153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "685 of 1000 - 7.619009017944336 s\n",
      "Accuracy 0.9323869457046685 precision 0.9321075189650609 specificity 0.8734513006214066 recall 0.9323869457046685 f1 0.9322365964989415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "686 of 1000 - 7.454646587371826 s\n",
      "Accuracy 0.9394116786184692 precision 0.9392395321288236 specificity 0.8897517198106407 recall 0.9394116786184692 f1 0.9393203865317103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "687 of 1000 - 7.611999750137329 s\n",
      "Accuracy 0.9351675691497147 precision 0.9359145505104836 specificity 0.8866519519904118 recall 0.9351675691497147 f1 0.9354915045735351\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "688 of 1000 - 7.555997848510742 s\n",
      "Accuracy 0.9323869457046685 precision 0.9325713939280741 specificity 0.8808200566700674 recall 0.9323869457046685 f1 0.9324753930493551\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "689 of 1000 - 7.54650616645813 s\n",
      "Accuracy 0.9304844138738475 precision 0.9304082539436401 specificity 0.8724408338212746 recall 0.9304844138738475 f1 0.9304456733547897\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "690 of 1000 - 7.582178354263306 s\n",
      "Accuracy 0.9316552026928143 precision 0.9313108388542096 specificity 0.8718324417305975 recall 0.9316552026928143 f1 0.9314664474708391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "691 of 1000 - 7.455019950866699 s\n",
      "Accuracy 0.9277037904288014 precision 0.9282095125678753 specificity 0.8779541329862919 recall 0.9277037904288014 f1 0.9279335774891428\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "692 of 1000 - 7.508009195327759 s\n",
      "Accuracy 0.9322405971022977 precision 0.9327136199693111 specificity 0.883509181166101 recall 0.9322405971022977 f1 0.9324551242846523\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "693 of 1000 - 7.565702438354492 s\n",
      "Accuracy 0.9269720474169472 precision 0.9276998913439699 specificity 0.8776668453870844 recall 0.9269720474169472 f1 0.9272928720422786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "694 of 1000 - 7.569508075714111 s\n",
      "Accuracy 0.931947899897556 precision 0.931770070936052 specificity 0.8783964692022979 recall 0.931947899897556 f1 0.931854584002185\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "695 of 1000 - 7.567510366439819 s\n",
      "Accuracy 0.9272647446216888 precision 0.926953009919131 specificity 0.8653796515181926 recall 0.9272647446216888 f1 0.9270973309158989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "696 of 1000 - 7.568612575531006 s\n",
      "Accuracy 0.93092345968096 precision 0.9308064558986329 specificity 0.8747425063041346 recall 0.93092345968096 f1 0.9308632777952496\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "697 of 1000 - 7.575999975204468 s\n",
      "Accuracy 0.9351675691497147 precision 0.9365722480561519 specificity 0.8975534532410335 recall 0.9351675691497147 f1 0.9357152630667926\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "698 of 1000 - 7.598008394241333 s\n",
      "Accuracy 0.9315088540904435 precision 0.9311856172727975 specificity 0.8741389581285945 recall 0.9315088540904435 f1 0.9313321141224539\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "699 of 1000 - 7.451256275177002 s\n",
      "Accuracy 0.9246304697790136 precision 0.9252847527560454 specificity 0.8745695228194412 recall 0.9246304697790136 f1 0.9249228932738601\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "700 of 1000 - 7.556508541107178 s\n",
      "Accuracy 0.9298990194643642 precision 0.9302599557922341 specificity 0.8824395828795685 recall 0.9298990194643642 f1 0.9300659491994213\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "701 of 1000 - 7.4785239696502686 s\n",
      "Accuracy 0.9322405971022977 precision 0.9324749883617328 specificity 0.8807321189582263 recall 0.9322405971022977 f1 0.9323518879612389\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "702 of 1000 - 7.5230536460876465 s\n",
      "Accuracy 0.9282891848382848 precision 0.9284146493729242 specificity 0.874765376236917 recall 0.9282891848382848 f1 0.9283502643665342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "703 of 1000 - 7.473310947418213 s\n",
      "Accuracy 0.9318015512951852 precision 0.9317093740546705 specificity 0.8718622263957307 recall 0.9318015512951852 f1 0.931754497967272\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "704 of 1000 - 7.602004528045654 s\n",
      "Accuracy 0.9320942484999268 precision 0.9327408972493185 specificity 0.8838447433723311 recall 0.9320942484999268 f1 0.9323797356766297\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "705 of 1000 - 7.476506471633911 s\n",
      "Accuracy 0.9323869457046685 precision 0.932695671566847 specificity 0.8841274302643497 recall 0.9323869457046685 f1 0.9325309188783992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "706 of 1000 - 7.451021909713745 s\n",
      "Accuracy 0.9278501390311723 precision 0.9278341714622947 specificity 0.8687197019766949 recall 0.9278501390311723 f1 0.927842129028111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "707 of 1000 - 7.492045164108276 s\n",
      "Accuracy 0.9353139177520855 precision 0.9352855041217862 specificity 0.8823798206773698 recall 0.9353139177520855 f1 0.9352996045338342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "708 of 1000 - 7.609048843383789 s\n",
      "Accuracy 0.9298990194643642 precision 0.9302069093920066 specificity 0.8779549985314783 recall 0.9298990194643642 f1 0.9300435721458566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "709 of 1000 - 7.594153165817261 s\n",
      "Accuracy 0.932825991511781 precision 0.9326976160089205 specificity 0.8773424218232775 recall 0.932825991511781 f1 0.932759663243145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "710 of 1000 - 7.555034399032593 s\n",
      "Accuracy 0.9337040831260062 precision 0.933046473135153 specificity 0.8685921201375246 recall 0.9337040831260062 f1 0.9332936358656009\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "711 of 1000 - 7.53752326965332 s\n",
      "Accuracy 0.9275574418264305 precision 0.927666939082735 specificity 0.8740936275343161 recall 0.9275574418264305 f1 0.9276109305902784\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "712 of 1000 - 7.604557514190674 s\n",
      "Accuracy 0.9277037904288014 precision 0.9274394602179106 specificity 0.8679918624680402 recall 0.9277037904288014 f1 0.9275631814522671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "713 of 1000 - 7.578124523162842 s\n",
      "Accuracy 0.9301917166691058 precision 0.9302691609673103 specificity 0.8755834863829797 recall 0.9301917166691058 f1 0.9302297850028233\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "714 of 1000 - 7.487507343292236 s\n",
      "Accuracy 0.9382408897995024 precision 0.9380173818601728 specificity 0.8780539571439584 recall 0.9382408897995024 f1 0.9381220459987931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "715 of 1000 - 7.442518711090088 s\n",
      "Accuracy 0.9303380652714767 precision 0.9305648012124569 specificity 0.8759767802248436 recall 0.9303380652714767 f1 0.9304462849686421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "716 of 1000 - 7.458009243011475 s\n",
      "Accuracy 0.9297526708619933 precision 0.9300386688117699 specificity 0.8790953175504632 recall 0.9297526708619933 f1 0.9298872951283387\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "717 of 1000 - 7.584276914596558 s\n",
      "Accuracy 0.928142836235914 precision 0.9288296679808705 specificity 0.8783718256691578 recall 0.928142836235914 f1 0.9284469829558237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "718 of 1000 - 7.498007535934448 s\n",
      "Accuracy 0.9285818820430265 precision 0.9282600561722658 specificity 0.8667850738967564 recall 0.9285818820430265 f1 0.9284082224064083\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "719 of 1000 - 7.446507930755615 s\n",
      "Accuracy 0.931947899897556 precision 0.9323125218658831 specificity 0.882989362104116 recall 0.931947899897556 f1 0.9321164383903169\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "720 of 1000 - 7.636999607086182 s\n",
      "Accuracy 0.9320942484999268 precision 0.9320645267069777 specificity 0.8768858286332577 recall 0.9320942484999268 f1 0.9320792820501337\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "721 of 1000 - 7.580038785934448 s\n",
      "Accuracy 0.9337040831260062 precision 0.9339106500839518 specificity 0.8792492268518786 recall 0.9337040831260062 f1 0.9338028441447211\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "722 of 1000 - 7.58122181892395 s\n",
      "Accuracy 0.9335577345236353 precision 0.9336501655799279 specificity 0.8784752004640155 recall 0.9335577345236353 f1 0.9336029887653088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "723 of 1000 - 7.562999963760376 s\n",
      "Accuracy 0.9316552026928143 precision 0.9318565072176889 specificity 0.8802060331997049 recall 0.9316552026928143 f1 0.931751439736455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "724 of 1000 - 7.583008766174316 s\n",
      "Accuracy 0.925215864188497 precision 0.9254651912663212 specificity 0.870906675034948 recall 0.925215864188497 f1 0.9253347698948163\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "725 of 1000 - 7.49100923538208 s\n",
      "Accuracy 0.9315088540904435 precision 0.9321815425093021 specificity 0.8799270421676455 recall 0.9315088540904435 f1 0.931806951316357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "726 of 1000 - 7.515001058578491 s\n",
      "Accuracy 0.9268256988145763 precision 0.927090669458128 specificity 0.872706846784791 recall 0.9268256988145763 f1 0.92695158198266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "727 of 1000 - 7.551138401031494 s\n",
      "Accuracy 0.9382408897995024 precision 0.9380317199553071 specificity 0.891253360546287 recall 0.9382408897995024 f1 0.9381278601980756\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "728 of 1000 - 7.6299989223480225 s\n",
      "Accuracy 0.9358993121615689 precision 0.9357334513184686 specificity 0.8799820484681599 recall 0.9358993121615689 f1 0.9358125108027072\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "729 of 1000 - 7.499518394470215 s\n",
      "Accuracy 0.9335577345236353 precision 0.9332968545902717 specificity 0.879579836723244 recall 0.9335577345236353 f1 0.9334168090282884\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "730 of 1000 - 7.418009996414185 s\n",
      "Accuracy 0.9318015512951852 precision 0.932023558828563 specificity 0.8787309988384732 recall 0.9318015512951852 f1 0.9319073929084722\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "731 of 1000 - 7.570022106170654 s\n",
      "Accuracy 0.9296063222596225 precision 0.9299237151957258 specificity 0.8750770234988593 recall 0.9296063222596225 f1 0.9297555431652277\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "732 of 1000 - 7.575531005859375 s\n",
      "Accuracy 0.9323869457046685 precision 0.9325980994098909 specificity 0.8833020185498115 recall 0.9323869457046685 f1 0.9324874304496074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "733 of 1000 - 7.578055143356323 s\n",
      "Accuracy 0.9345821747402312 precision 0.9355851718661997 specificity 0.8914035869225987 recall 0.9345821747402312 f1 0.934998193938603\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "734 of 1000 - 7.575042486190796 s\n",
      "Accuracy 0.9320942484999268 precision 0.9321513460561415 specificity 0.8829840359676193 recall 0.9320942484999268 f1 0.9321223844128266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "735 of 1000 - 7.621998310089111 s\n",
      "Accuracy 0.933850431728377 precision 0.9347874990721314 specificity 0.8944027997220264 recall 0.933850431728377 f1 0.9342383060305786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "736 of 1000 - 7.422520875930786 s\n",
      "Accuracy 0.9312161568857017 precision 0.9317469627223982 specificity 0.8827076352363186 recall 0.9312161568857017 f1 0.9314549221274697\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "737 of 1000 - 7.64300012588501 s\n",
      "Accuracy 0.9369237523781648 precision 0.936640301811978 specificity 0.883977613200341 recall 0.9369237523781648 f1 0.9367679972846259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "738 of 1000 - 7.573537588119507 s\n",
      "Accuracy 0.9304844138738475 precision 0.9308274623529896 specificity 0.8785515798127985 recall 0.9304844138738475 f1 0.9306444169125806\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "739 of 1000 - 7.565551519393921 s\n",
      "Accuracy 0.9288745792477682 precision 0.9287804536269519 specificity 0.868470561864354 recall 0.9288745792477682 f1 0.9288265651137447\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "740 of 1000 - 7.447526693344116 s\n",
      "Accuracy 0.9344358261378604 precision 0.9351891665543499 specificity 0.8923199048757733 recall 0.9344358261378604 f1 0.9347575614115027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "741 of 1000 - 7.476028203964233 s\n",
      "Accuracy 0.9344358261378604 precision 0.9346491007795003 specificity 0.8837741620399665 recall 0.9344358261378604 f1 0.9345372785634257\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "742 of 1000 - 7.518001317977905 s\n",
      "Accuracy 0.9297526708619933 precision 0.9300662646199603 specificity 0.8810938322762388 recall 0.9297526708619933 f1 0.9298992029903906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "743 of 1000 - 7.696033239364624 s\n",
      "Accuracy 0.9318015512951852 precision 0.9315372691116192 specificity 0.8777383135127467 recall 0.9318015512951852 f1 0.9316590138677705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "744 of 1000 - 7.5119993686676025 s\n",
      "Accuracy 0.9312161568857017 precision 0.9309326477726003 specificity 0.871692642598164 recall 0.9312161568857017 f1 0.9310638071916149\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "745 of 1000 - 7.526999473571777 s\n",
      "Accuracy 0.9313625054880725 precision 0.9317372931616222 specificity 0.8802643427914952 recall 0.9313625054880725 f1 0.9315360458897917\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "746 of 1000 - 7.5600104331970215 s\n",
      "Accuracy 0.9320942484999268 precision 0.9322810641517577 specificity 0.8795603334508332 recall 0.9320942484999268 f1 0.9321838702244076\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "747 of 1000 - 7.453523397445679 s\n",
      "Accuracy 0.9288745792477682 precision 0.9284656570972757 specificity 0.8580671205330268 recall 0.9288745792477682 f1 0.9286517234018146\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "748 of 1000 - 7.452999830245972 s\n",
      "Accuracy 0.9315088540904435 precision 0.9323468625420424 specificity 0.8856357756177516 recall 0.9315088540904435 f1 0.9318679449734557\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "749 of 1000 - 7.4350855350494385 s\n",
      "Accuracy 0.9312161568857017 precision 0.9309606672341791 specificity 0.8725718120750149 recall 0.9312161568857017 f1 0.9310798515751042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "750 of 1000 - 7.526999473571777 s\n",
      "Accuracy 0.9260939558027221 precision 0.925734189965157 specificity 0.8656549290306589 recall 0.9260939558027221 f1 0.9258979141733614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "751 of 1000 - 7.552999973297119 s\n",
      "Accuracy 0.933850431728377 precision 0.933850431728377 specificity 0.881149113035691 recall 0.933850431728377 f1 0.933850431728377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "752 of 1000 - 7.473032474517822 s\n",
      "Accuracy 0.9298990194643642 precision 0.9302705365140758 specificity 0.8800341942161054 recall 0.9298990194643642 f1 0.9300711030780502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "753 of 1000 - 7.589998006820679 s\n",
      "Accuracy 0.9291672764525098 precision 0.9292606277319521 specificity 0.8750600210850723 recall 0.9291672764525098 f1 0.929213017001155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "754 of 1000 - 7.4731080532073975 s\n",
      "Accuracy 0.9294599736572515 precision 0.9292103335497869 specificity 0.8736779959153029 recall 0.9294599736572515 f1 0.9293267639739323\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "755 of 1000 - 7.589009046554565 s\n",
      "Accuracy 0.9284355334406557 precision 0.9283296711688592 specificity 0.8710367916193058 recall 0.9284355334406557 f1 0.9283813256732498\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "756 of 1000 - 7.566563367843628 s\n",
      "Accuracy 0.9298990194643642 precision 0.9302017254089141 specificity 0.8794106522726446 recall 0.9298990194643642 f1 0.930041035904522\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "757 of 1000 - 7.565000772476196 s\n",
      "Accuracy 0.9301917166691058 precision 0.9304963906581554 specificity 0.8790500195312662 recall 0.9301917166691058 f1 0.9303346776284502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "758 of 1000 - 7.5460052490234375 s\n",
      "Accuracy 0.9351675691497147 precision 0.935098459340413 specificity 0.8830620780318061 recall 0.9351675691497147 f1 0.9351323532856906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "759 of 1000 - 7.618352890014648 s\n",
      "Accuracy 0.9303380652714767 precision 0.9304950190227871 specificity 0.8768568078355726 recall 0.9303380652714767 f1 0.9304139301485906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "760 of 1000 - 7.596536874771118 s\n",
      "Accuracy 0.9301917166691058 precision 0.9300620829914327 specificity 0.8751719200170622 recall 0.9301917166691058 f1 0.9301247923773328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "761 of 1000 - 7.566561460494995 s\n",
      "Accuracy 0.9370701009805357 precision 0.9370701009805357 specificity 0.8842549610529967 recall 0.9370701009805357 f1 0.9370701009805357\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "762 of 1000 - 7.491002321243286 s\n",
      "Accuracy 0.9345821747402312 precision 0.9347203776681703 specificity 0.8808039920474449 recall 0.9345821747402312 f1 0.9346491089080727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "763 of 1000 - 7.515107154846191 s\n",
      "Accuracy 0.931947899897556 precision 0.9316918574714116 specificity 0.8767259539078819 recall 0.931947899897556 f1 0.9318104398890531\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "764 of 1000 - 7.6280012130737305 s\n",
      "Accuracy 0.9361920093663105 precision 0.9355786370880289 specificity 0.8769725115380657 recall 0.9361920093663105 f1 0.935795654364906\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "765 of 1000 - 7.484990358352661 s\n",
      "Accuracy 0.9285818820430265 precision 0.9282543233855548 specificity 0.8651999288935962 recall 0.9285818820430265 f1 0.9284052805561329\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "766 of 1000 - 7.570560932159424 s\n",
      "Accuracy 0.9331186887165227 precision 0.9339542760483263 specificity 0.8893133791378923 recall 0.9331186887165227 f1 0.9334740104665342\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "767 of 1000 - 7.469001770019531 s\n",
      "Accuracy 0.9288745792477682 precision 0.9292137591931358 specificity 0.8736994626774374 recall 0.9288745792477682 f1 0.9290336793546545\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "768 of 1000 - 7.583999156951904 s\n",
      "Accuracy 0.9320942484999268 precision 0.9323386731559731 specificity 0.8829797297982515 recall 0.9320942484999268 f1 0.9322098120910155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "769 of 1000 - 7.537999868392944 s\n",
      "Accuracy 0.9237523781647885 precision 0.9232687197250324 specificity 0.854311390052001 recall 0.9237523781647885 f1 0.9234852525054518\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "770 of 1000 - 7.522029161453247 s\n",
      "Accuracy 0.9282891848382848 precision 0.9285447577386322 specificity 0.8768009499795302 recall 0.9282891848382848 f1 0.9284103881906948\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "771 of 1000 - 7.4290008544921875 s\n",
      "Accuracy 0.9353139177520855 precision 0.9350757985072815 specificity 0.8802595127418581 recall 0.9353139177520855 f1 0.9351862373729904\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "772 of 1000 - 7.606507778167725 s\n",
      "Accuracy 0.927118396019318 precision 0.9276377601411612 specificity 0.87519278915644 recall 0.927118396019318 f1 0.9273548744473472\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "773 of 1000 - 7.504031181335449 s\n",
      "Accuracy 0.9363383579686814 precision 0.9361404118568148 specificity 0.8824233278051561 recall 0.9363383579686814 f1 0.9362333842854315\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "774 of 1000 - 7.56177020072937 s\n",
      "Accuracy 0.936777403775794 precision 0.9363451126404455 specificity 0.8757688450909717 recall 0.936777403775794 f1 0.9365297307919501\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "775 of 1000 - 7.524868011474609 s\n",
      "Accuracy 0.9331186887165227 precision 0.9333493364241242 specificity 0.8826381960561285 recall 0.9331186887165227 f1 0.933228105248025\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "776 of 1000 - 7.5991387367248535 s\n",
      "Accuracy 0.9265330016098346 precision 0.9267292569942993 specificity 0.8718318111555948 recall 0.9265330016098346 f1 0.9266274196155473\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "777 of 1000 - 7.618000030517578 s\n",
      "Accuracy 0.9284355334406557 precision 0.9288550843240192 specificity 0.8766347789375136 recall 0.9284355334406557 f1 0.9286291326099625\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "778 of 1000 - 7.492006540298462 s\n",
      "Accuracy 0.9353139177520855 precision 0.9353717940349864 specificity 0.8837856168377981 recall 0.9353139177520855 f1 0.935342431419364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "779 of 1000 - 7.58503532409668 s\n",
      "Accuracy 0.9306307624762183 precision 0.9309584199886319 specificity 0.8779349577556254 recall 0.9306307624762183 f1 0.9307841057470027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "780 of 1000 - 7.47800087928772 s\n",
      "Accuracy 0.9325332943070394 precision 0.9329740744654589 specificity 0.8827300688729907 recall 0.9325332943070394 f1 0.9327345308164977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "781 of 1000 - 7.619068145751953 s\n",
      "Accuracy 0.9298990194643642 precision 0.9297621067740129 specificity 0.8703065647889214 recall 0.9298990194643642 f1 0.9298284207292122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "782 of 1000 - 7.469054222106934 s\n",
      "Accuracy 0.9285818820430265 precision 0.9292124312095987 specificity 0.8778517964776351 recall 0.9285818820430265 f1 0.9288635410221829\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "783 of 1000 - 7.65005087852478 s\n",
      "Accuracy 0.9297526708619933 precision 0.9296920657081094 specificity 0.872999489786248 recall 0.9297526708619933 f1 0.9297219490761868\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "784 of 1000 - 7.517999649047852 s\n",
      "Accuracy 0.9297526708619933 precision 0.9307640857893739 specificity 0.8806827837271591 recall 0.9297526708619933 f1 0.9301820059310336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "785 of 1000 - 7.495119571685791 s\n",
      "Accuracy 0.9339967803307478 precision 0.9338939432080109 specificity 0.8764141803784274 recall 0.9339967803307478 f1 0.9339440458194735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "786 of 1000 - 7.497532844543457 s\n",
      "Accuracy 0.9310698082833309 precision 0.9306316181218471 specificity 0.8706566609336078 recall 0.9310698082833309 f1 0.9308219619308088\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "787 of 1000 - 7.570040225982666 s\n",
      "Accuracy 0.9307771110785892 precision 0.9308228367515802 specificity 0.8763665175746709 recall 0.9307771110785892 f1 0.9307997382402844\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "788 of 1000 - 7.42203688621521 s\n",
      "Accuracy 0.9288745792477682 precision 0.9293194644954412 specificity 0.8756498931109092 recall 0.9288745792477682 f1 0.9290793761344153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "789 of 1000 - 7.550127744674683 s\n",
      "Accuracy 0.9348748719449729 precision 0.9348893996858658 specificity 0.8817611837705807 recall 0.9348748719449729 f1 0.9348821092136252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "790 of 1000 - 7.470067501068115 s\n",
      "Accuracy 0.9294599736572515 precision 0.9293656048213135 specificity 0.8685340048667192 recall 0.9294599736572515 f1 0.9294118330709165\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "791 of 1000 - 7.495581388473511 s\n",
      "Accuracy 0.9318015512951852 precision 0.9324895561956543 specificity 0.8836012269994881 recall 0.9318015512951852 f1 0.9321036574970767\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "792 of 1000 - 7.455885171890259 s\n",
      "Accuracy 0.935752963559198 precision 0.9361199213952891 specificity 0.8925941217682807 recall 0.935752963559198 f1 0.9359202372827478\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "793 of 1000 - 7.565516233444214 s\n",
      "Accuracy 0.9344358261378604 precision 0.9343005130753386 specificity 0.8819576930656938 recall 0.9344358261378604 f1 0.9343655391789302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "794 of 1000 - 7.4505462646484375 s\n",
      "Accuracy 0.9323869457046685 precision 0.9325124233287798 specificity 0.8771932863057097 recall 0.9323869457046685 f1 0.9324479841031373\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "795 of 1000 - 7.479523420333862 s\n",
      "Accuracy 0.9315088540904435 precision 0.9318335871582701 specificity 0.8792902233753006 recall 0.9315088540904435 f1 0.9316607053320695\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "796 of 1000 - 7.576085329055786 s\n",
      "Accuracy 0.9351675691497147 precision 0.9353264414469212 specificity 0.8871342657624419 recall 0.9351675691497147 f1 0.9352438342849116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "797 of 1000 - 7.48999810218811 s\n",
      "Accuracy 0.9326796429094102 precision 0.932794410146644 specificity 0.8847553766129839 recall 0.9326796429094102 f1 0.9327353750210442\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "798 of 1000 - 7.55899977684021 s\n",
      "Accuracy 0.9323869457046685 precision 0.9320133032060933 specificity 0.8732832305542342 recall 0.9323869457046685 f1 0.9321793447262905\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "799 of 1000 - 7.52203893661499 s\n",
      "Accuracy 0.9322405971022977 precision 0.9318431140606097 specificity 0.874965583122866 recall 0.9322405971022977 f1 0.932016625894124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "800 of 1000 - 7.4815075397491455 s\n",
      "Accuracy 0.9296063222596225 precision 0.9296828244037751 specificity 0.8762908066712625 recall 0.9296063222596225 f1 0.9296439248667361\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "801 of 1000 - 7.559999704360962 s\n",
      "Accuracy 0.9322405971022977 precision 0.9320322532200791 specificity 0.8763409174830602 recall 0.9322405971022977 f1 0.9321305054752042\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "802 of 1000 - 7.567021608352661 s\n",
      "Accuracy 0.9322405971022977 precision 0.9326007470382053 specificity 0.8842072621363574 recall 0.9322405971022977 f1 0.9324069326203283\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "803 of 1000 - 7.464184999465942 s\n",
      "Accuracy 0.928142836235914 precision 0.9284243137750722 specificity 0.8740160146392993 recall 0.928142836235914 f1 0.9282760674231424\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "804 of 1000 - 7.5900092124938965 s\n",
      "Accuracy 0.9344358261378604 precision 0.9342182369008011 specificity 0.8786220217737065 recall 0.9344358261378604 f1 0.9343202232153198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "805 of 1000 - 7.4900007247924805 s\n",
      "Accuracy 0.9255085613932387 precision 0.9251372481973543 specificity 0.8626012171541481 recall 0.9255085613932387 f1 0.9253066469883401\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "806 of 1000 - 7.573074579238892 s\n",
      "Accuracy 0.9356066149568272 precision 0.9359391089212223 specificity 0.8888880991693452 recall 0.9356066149568272 f1 0.9357601371361997\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "807 of 1000 - 7.560009241104126 s\n",
      "Accuracy 0.93092345968096 precision 0.93092345968096 specificity 0.8746105299167314 recall 0.93092345968096 f1 0.93092345968096\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "808 of 1000 - 7.488506555557251 s\n",
      "Accuracy 0.9301917166691058 precision 0.9302721690017054 specificity 0.8722004031771351 recall 0.9301917166691058 f1 0.9302312802035451\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "809 of 1000 - 7.473036050796509 s\n",
      "Accuracy 0.93092345968096 precision 0.9306975849838647 specificity 0.8738706723414017 recall 0.93092345968096 f1 0.9308038048312381\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "810 of 1000 - 7.534000396728516 s\n",
      "Accuracy 0.9354602663544563 precision 0.9355627850921929 specificity 0.8843187294654008 recall 0.9354602663544563 f1 0.9355102246173111\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "811 of 1000 - 7.653999328613281 s\n",
      "Accuracy 0.9287282306453973 precision 0.9290776295225079 specificity 0.8757856402025372 recall 0.9287282306453973 f1 0.9288914695757657\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "812 of 1000 - 7.5360352993011475 s\n",
      "Accuracy 0.9337040831260062 precision 0.9348480649578967 specificity 0.8940690920382107 recall 0.9337040831260062 f1 0.9341667290181931\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "813 of 1000 - 7.407901048660278 s\n",
      "Accuracy 0.932825991511781 precision 0.9331823018375955 specificity 0.8854774672708607 recall 0.932825991511781 f1 0.9329904047760973\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "814 of 1000 - 7.50206732749939 s\n",
      "Accuracy 0.9325332943070394 precision 0.932871758315682 specificity 0.8810625146008274 recall 0.9325332943070394 f1 0.9326908970915777\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "815 of 1000 - 7.6585235595703125 s\n",
      "Accuracy 0.9331186887165227 precision 0.9331337395725905 specificity 0.8778091806821112 recall 0.9331186887165227 f1 0.9331261875554354\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "816 of 1000 - 7.568007230758667 s\n",
      "Accuracy 0.9306307624762183 precision 0.9304040975501005 specificity 0.873436853856439 recall 0.9306307624762183 f1 0.9305107188083352\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "817 of 1000 - 7.542524099349976 s\n",
      "Accuracy 0.9306307624762183 precision 0.9305998477136819 specificity 0.8726708598806382 recall 0.9306307624762183 f1 0.930615199203265\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "818 of 1000 - 7.615079164505005 s\n",
      "Accuracy 0.9323869457046685 precision 0.9318859941161093 specificity 0.8723745601774394 recall 0.9323869457046685 f1 0.932094146231302\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "819 of 1000 - 7.530117511749268 s\n",
      "Accuracy 0.9344358261378604 precision 0.9351411293875916 specificity 0.8885232382495049 recall 0.9344358261378604 f1 0.9347419917931593\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "820 of 1000 - 7.573038816452026 s\n",
      "Accuracy 0.9356066149568272 precision 0.9361959549623536 specificity 0.893995421181541 recall 0.9356066149568272 f1 0.9358638347595543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "821 of 1000 - 7.481065273284912 s\n",
      "Accuracy 0.9312161568857017 precision 0.9320046058864613 specificity 0.8813500285442728 recall 0.9312161568857017 f1 0.931559376721611\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "822 of 1000 - 7.477990627288818 s\n",
      "Accuracy 0.9297526708619933 precision 0.9299105888329484 specificity 0.8759712021894771 recall 0.9297526708619933 f1 0.9298290227297396\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "823 of 1000 - 7.593999147415161 s\n",
      "Accuracy 0.9230206351529343 precision 0.9232959632014771 specificity 0.866796761094285 recall 0.9230206351529343 f1 0.9231517691605226\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "824 of 1000 - 7.569072723388672 s\n",
      "Accuracy 0.9266793502122055 precision 0.9263083235950872 specificity 0.8631823222418277 recall 0.9266793502122055 f1 0.9264774511310735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "825 of 1000 - 7.583000898361206 s\n",
      "Accuracy 0.9297526708619933 precision 0.929516509480689 specificity 0.8694827775447257 recall 0.9297526708619933 f1 0.9296278286556834\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "826 of 1000 - 7.417052745819092 s\n",
      "Accuracy 0.9282891848382848 precision 0.9281362249151808 specificity 0.8685222200501419 recall 0.9282891848382848 f1 0.9282100814002082\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "827 of 1000 - 7.539036512374878 s\n",
      "Accuracy 0.9318015512951852 precision 0.9311681248789192 specificity 0.8701708965679416 recall 0.9318015512951852 f1 0.9314079142844298\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "828 of 1000 - 7.495878219604492 s\n",
      "Accuracy 0.9358993121615689 precision 0.935926713694476 specificity 0.8874803307781388 recall 0.9358993121615689 f1 0.9359129080573754\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "829 of 1000 - 7.687500476837158 s\n",
      "Accuracy 0.9391189814137275 precision 0.9391728750139173 specificity 0.8915624032308752 recall 0.9391189814137275 f1 0.9391455022447186\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "830 of 1000 - 7.489535331726074 s\n",
      "Accuracy 0.9287282306453973 precision 0.9292531952580385 specificity 0.8787181114140901 recall 0.9287282306453973 f1 0.9289659047497789\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "831 of 1000 - 7.528562545776367 s\n",
      "Accuracy 0.9293136250548807 precision 0.9288505294337439 specificity 0.8692716270159726 recall 0.9293136250548807 f1 0.9290500901952434\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "832 of 1000 - 7.681512117385864 s\n",
      "Accuracy 0.933850431728377 precision 0.9337043154902386 specificity 0.8885175381750599 recall 0.933850431728377 f1 0.9337737176594983\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "833 of 1000 - 7.457000970840454 s\n",
      "Accuracy 0.9323869457046685 precision 0.9334516759452217 specificity 0.8864037338379935 recall 0.9323869457046685 f1 0.9328307907089124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "834 of 1000 - 7.493944883346558 s\n",
      "Accuracy 0.9277037904288014 precision 0.9276133757285474 specificity 0.8714274598446785 recall 0.9277037904288014 f1 0.9276576521631782\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "835 of 1000 - 7.594070911407471 s\n",
      "Accuracy 0.9269720474169472 precision 0.9276480547728172 specificity 0.8789039410199151 recall 0.9269720474169472 f1 0.9272712878645198\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "836 of 1000 - 7.498532295227051 s\n",
      "Accuracy 0.9313625054880725 precision 0.9313480207164393 specificity 0.879091234320506 recall 0.9313625054880725 f1 0.9313552371177328\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "837 of 1000 - 7.5057642459869385 s\n",
      "Accuracy 0.9268256988145763 precision 0.9270585420302784 specificity 0.8714130828097407 recall 0.9268256988145763 f1 0.926937045288373\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "838 of 1000 - 7.550009489059448 s\n",
      "Accuracy 0.9342894775354895 precision 0.9343911082049234 specificity 0.884326990474062 recall 0.9342894775354895 f1 0.9343390068933901\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "839 of 1000 - 7.532545328140259 s\n",
      "Accuracy 0.936631055173423 precision 0.9368815557253991 specificity 0.889265185305149 recall 0.936631055173423 f1 0.936748664065157\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "840 of 1000 - 7.613000154495239 s\n",
      "Accuracy 0.9278501390311723 precision 0.9274609721486832 specificity 0.8653105798274711 recall 0.9278501390311723 f1 0.9276364146100112\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "841 of 1000 - 7.546998977661133 s\n",
      "Accuracy 0.9342894775354895 precision 0.9347284218244115 specificity 0.8842929104533217 recall 0.9342894775354895 f1 0.9344895863869214\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "842 of 1000 - 7.3799989223480225 s\n",
      "Accuracy 0.930045368066735 precision 0.9305414200787603 specificity 0.8812598331578139 recall 0.930045368066735 f1 0.9302701280604133\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "843 of 1000 - 7.4938578605651855 s\n",
      "Accuracy 0.9316552026928143 precision 0.9320257377936412 specificity 0.881438080103564 recall 0.9316552026928143 f1 0.9318266458678497\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "844 of 1000 - 7.528435707092285 s\n",
      "Accuracy 0.9354602663544563 precision 0.9355017037626282 specificity 0.8870689720705129 recall 0.9354602663544563 f1 0.9354807495523662\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "845 of 1000 - 7.531768083572388 s\n",
      "Accuracy 0.9293136250548807 precision 0.9292986177787154 specificity 0.874989679608077 recall 0.9293136250548807 f1 0.9293060954874626\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "846 of 1000 - 7.537441253662109 s\n",
      "Accuracy 0.9360456607639397 precision 0.9362447198607707 specificity 0.8838643278908342 recall 0.9360456607639397 f1 0.9361406503378124\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "847 of 1000 - 7.567471981048584 s\n",
      "Accuracy 0.9312161568857017 precision 0.9321571738931971 specificity 0.8881401169467309 recall 0.9312161568857017 f1 0.9316116156680915\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "848 of 1000 - 7.550497770309448 s\n",
      "Accuracy 0.934728523342602 precision 0.9348134704291278 specificity 0.8861158519489886 recall 0.934728523342602 f1 0.934770056010614\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "849 of 1000 - 7.541439533233643 s\n",
      "Accuracy 0.930045368066735 precision 0.9307460749154423 specificity 0.8806933587285463 recall 0.930045368066735 f1 0.9303540329108215\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "850 of 1000 - 7.4839489459991455 s\n",
      "Accuracy 0.9354602663544563 precision 0.9359839979650648 specificity 0.8898680327095553 recall 0.9354602663544563 f1 0.9356934723832789\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "851 of 1000 - 7.558459997177124 s\n",
      "Accuracy 0.9322405971022977 precision 0.9325300699585191 specificity 0.8846430179196101 recall 0.9322405971022977 f1 0.9323759961828085\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "852 of 1000 - 7.485450029373169 s\n",
      "Accuracy 0.9303380652714767 precision 0.9299605195047198 specificity 0.8715742589634282 recall 0.9303380652714767 f1 0.930128755910145\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "853 of 1000 - 7.56636118888855 s\n",
      "Accuracy 0.9364847065710522 precision 0.937094570673804 specificity 0.8919814422474899 recall 0.9364847065710522 f1 0.9367514721007751\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "854 of 1000 - 7.6149742603302 s\n",
      "Accuracy 0.9307771110785892 precision 0.9306484757661817 specificity 0.8761196862445353 recall 0.9307771110785892 f1 0.9307106827755728\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "855 of 1000 - 7.498962640762329 s\n",
      "Accuracy 0.9260939558027221 precision 0.9262793342452563 specificity 0.8683724816629393 recall 0.9260939558027221 f1 0.9261835006646533\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "856 of 1000 - 7.49844765663147 s\n",
      "Accuracy 0.929020927850139 precision 0.9293194793297352 specificity 0.8799912422035042 recall 0.929020927850139 f1 0.9291609645739599\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "857 of 1000 - 7.532439947128296 s\n",
      "Accuracy 0.9306307624762183 precision 0.9314605559973365 specificity 0.8812057029966048 recall 0.9306307624762183 f1 0.9309901372170841\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "858 of 1000 - 7.4884419441223145 s\n",
      "Accuracy 0.9282891848382848 precision 0.9282891848382848 specificity 0.8738985736397963 recall 0.9282891848382848 f1 0.9282891848382848\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "859 of 1000 - 7.48895788192749 s\n",
      "Accuracy 0.9329723401141519 precision 0.9329723401141519 specificity 0.8784968143412888 recall 0.9329723401141519 f1 0.9329723401141519\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "860 of 1000 - 7.582433462142944 s\n",
      "Accuracy 0.9326796429094102 precision 0.9327110701010854 specificity 0.8742658666574827 recall 0.9326796429094102 f1 0.9326952489959566\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "861 of 1000 - 7.5100061893463135 s\n",
      "Accuracy 0.9313625054880725 precision 0.9320544088427639 specificity 0.8853345954331637 recall 0.9313625054880725 f1 0.9316649326929114\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "862 of 1000 - 7.6174376010894775 s\n",
      "Accuracy 0.9313625054880725 precision 0.9318194677928623 specificity 0.8787804383089974 recall 0.9313625054880725 f1 0.9315717349146391\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "863 of 1000 - 7.483931541442871 s\n",
      "Accuracy 0.9298990194643642 precision 0.9295346723030868 specificity 0.8661774106864559 recall 0.9298990194643642 f1 0.9297001754464462\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "864 of 1000 - 7.494948148727417 s\n",
      "Accuracy 0.931947899897556 precision 0.9320852156083971 specificity 0.8797780728821198 recall 0.931947899897556 f1 0.9320144364171682\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "865 of 1000 - 7.577998638153076 s\n",
      "Accuracy 0.9293136250548807 precision 0.9294471852192209 specificity 0.8804374404006146 recall 0.9293136250548807 f1 0.9293783406944502\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "866 of 1000 - 7.4949586391448975 s\n",
      "Accuracy 0.9296063222596225 precision 0.9302730943923359 specificity 0.8820434048384161 recall 0.9296063222596225 f1 0.929900488599453\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "867 of 1000 - 7.568436145782471 s\n",
      "Accuracy 0.9315088540904435 precision 0.9317557228207075 specificity 0.8817849503079235 recall 0.9315088540904435 f1 0.9316256431150842\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "868 of 1000 - 7.58937931060791 s\n",
      "Accuracy 0.930045368066735 precision 0.93023264850011 specificity 0.8780829863795011 recall 0.930045368066735 f1 0.9301352720642064\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "869 of 1000 - 7.418337345123291 s\n",
      "Accuracy 0.9345821747402312 precision 0.9342959676379867 specificity 0.8759892063423466 recall 0.9345821747402312 f1 0.9344272277973631\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "870 of 1000 - 7.535468816757202 s\n",
      "Accuracy 0.9288745792477682 precision 0.9289391879054616 specificity 0.8706245971648843 recall 0.9288745792477682 f1 0.9289064622587399\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "871 of 1000 - 7.51247763633728 s\n",
      "Accuracy 0.9341431289331187 precision 0.9339171892987563 specificity 0.8753448528998281 recall 0.9341431289331187 f1 0.9340232768509565\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "872 of 1000 - 7.578473329544067 s\n",
      "Accuracy 0.9294599736572515 precision 0.9293446424461321 specificity 0.8751812924860424 recall 0.9294599736572515 f1 0.9294006531094455\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "873 of 1000 - 7.696429967880249 s\n",
      "Accuracy 0.9323869457046685 precision 0.9323869457046685 specificity 0.8781882617066965 recall 0.9323869457046685 f1 0.9323869457046685\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "874 of 1000 - 7.410956144332886 s\n",
      "Accuracy 0.9329723401141519 precision 0.9332193562199825 specificity 0.8826730028177036 recall 0.9329723401141519 f1 0.9330891337737087\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "875 of 1000 - 7.474447250366211 s\n",
      "Accuracy 0.9335577345236353 precision 0.9340170431355436 specificity 0.8834848545548526 recall 0.9335577345236353 f1 0.9337666333865526\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "876 of 1000 - 7.4824676513671875 s\n",
      "Accuracy 0.9287282306453973 precision 0.9288062732087721 specificity 0.8740616832379102 recall 0.9287282306453973 f1 0.9287666028969049\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "877 of 1000 - 7.422451019287109 s\n",
      "Accuracy 0.9322405971022977 precision 0.9323463247404764 specificity 0.8798671279201726 recall 0.9322405971022977 f1 0.9322921759081237\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "878 of 1000 - 7.520452260971069 s\n",
      "Accuracy 0.9291672764525098 precision 0.9293281580213353 specificity 0.8739836976199743 recall 0.9291672764525098 f1 0.9292451036059195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "879 of 1000 - 7.554954528808594 s\n",
      "Accuracy 0.9296063222596225 precision 0.9298391249142063 specificity 0.8796267908639807 recall 0.9296063222596225 f1 0.9297169372006259\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "880 of 1000 - 7.535896301269531 s\n",
      "Accuracy 0.9306307624762183 precision 0.9307557065225834 specificity 0.8765277627460247 recall 0.9306307624762183 f1 0.9306915577203534\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "881 of 1000 - 7.487510919570923 s\n",
      "Accuracy 0.9337040831260062 precision 0.933745530350493 specificity 0.8860164188866215 recall 0.9337040831260062 f1 0.9337245741411813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "882 of 1000 - 7.513548851013184 s\n",
      "Accuracy 0.9315088540904435 precision 0.9322496172794525 specificity 0.8820832710572579 recall 0.9315088540904435 f1 0.931832825375825\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "883 of 1000 - 7.472649574279785 s\n",
      "Accuracy 0.9258012585979803 precision 0.9263775335896828 specificity 0.8748080185533752 recall 0.9258012585979803 f1 0.9260615691132336\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "884 of 1000 - 7.5304529666900635 s\n",
      "Accuracy 0.9318015512951852 precision 0.9315159657004385 specificity 0.8713211296878485 recall 0.9318015512951852 f1 0.931648090482737\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "885 of 1000 - 7.488440275192261 s\n",
      "Accuracy 0.9260939558027221 precision 0.9264917036367681 specificity 0.8714642852090339 recall 0.9260939558027221 f1 0.926279166854935\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "886 of 1000 - 7.422476291656494 s\n",
      "Accuracy 0.9318015512951852 precision 0.9319251675145009 specificity 0.8781446638874592 recall 0.9318015512951852 f1 0.9318616751365958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "887 of 1000 - 7.573913097381592 s\n",
      "Accuracy 0.9259476072003512 precision 0.9255745684480552 specificity 0.8653706522755954 recall 0.9259476072003512 f1 0.9257436207923989\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "888 of 1000 - 7.54956316947937 s\n",
      "Accuracy 0.9312161568857017 precision 0.9315576681748068 specificity 0.8837783710123331 recall 0.9312161568857017 f1 0.9313744490047089\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "889 of 1000 - 7.448443412780762 s\n",
      "Accuracy 0.9363383579686814 precision 0.9364112159429184 specificity 0.8842797852744547 recall 0.9363383579686814 f1 0.9363741178670122\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "890 of 1000 - 7.465434312820435 s\n",
      "Accuracy 0.933850431728377 precision 0.9349297509839324 specificity 0.8938074226140482 recall 0.933850431728377 f1 0.934290534185007\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "891 of 1000 - 7.607472896575928 s\n",
      "Accuracy 0.9337040831260062 precision 0.9342310600917257 specificity 0.8880951290762337 recall 0.9337040831260062 f1 0.9339391959392119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "892 of 1000 - 7.553435802459717 s\n",
      "Accuracy 0.9296063222596225 precision 0.9294165347197085 specificity 0.8718278681126685 recall 0.9296063222596225 f1 0.9295070048310571\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "893 of 1000 - 7.440486431121826 s\n",
      "Accuracy 0.9332650373188937 precision 0.9333241939926455 specificity 0.8808095538512495 recall 0.9332650373188937 f1 0.933294194270933\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "894 of 1000 - 7.468798398971558 s\n",
      "Accuracy 0.9282891848382848 precision 0.9279767870286679 specificity 0.8692414780472169 recall 0.9282891848382848 f1 0.9281203889782885\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "895 of 1000 - 7.638979196548462 s\n",
      "Accuracy 0.9356066149568272 precision 0.9354193271332492 specificity 0.8814906680635939 recall 0.9356066149568272 f1 0.9355077573480757\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "896 of 1000 - 7.441491365432739 s\n",
      "Accuracy 0.9288745792477682 precision 0.9289658875012015 specificity 0.8767680007990553 recall 0.9288745792477682 f1 0.9289193070848932\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "897 of 1000 - 7.475961446762085 s\n",
      "Accuracy 0.928142836235914 precision 0.9283220642388774 specificity 0.8726962188561568 recall 0.928142836235914 f1 0.9282292998523847\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "898 of 1000 - 7.536236524581909 s\n",
      "Accuracy 0.9315088540904435 precision 0.9313908767604743 specificity 0.8743341805333872 recall 0.9315088540904435 f1 0.9314481735314368\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "899 of 1000 - 7.557398796081543 s\n",
      "Accuracy 0.9323869457046685 precision 0.9320041047780754 specificity 0.871240035381486 recall 0.9323869457046685 f1 0.9321745759800659\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "900 of 1000 - 7.60634183883667 s\n",
      "Accuracy 0.9331186887165227 precision 0.9329877621299958 specificity 0.8758258890739117 recall 0.9331186887165227 f1 0.9330510655156792\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "901 of 1000 - 7.560467958450317 s\n",
      "Accuracy 0.9332650373188937 precision 0.9335875050901525 specificity 0.8810396404973521 recall 0.9332650373188937 f1 0.9334156515488817\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "902 of 1000 - 7.458596229553223 s\n",
      "Accuracy 0.9360456607639397 precision 0.9358898645676468 specificity 0.8785179455954099 recall 0.9360456607639397 f1 0.9359644829430612\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "903 of 1000 - 7.479475259780884 s\n",
      "Accuracy 0.9279964876335431 precision 0.9280582210744405 specificity 0.8741473010156969 recall 0.9279964876335431 f1 0.9280269420220773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "904 of 1000 - 7.568940162658691 s\n",
      "Accuracy 0.9389726328113567 precision 0.9394966852014823 specificity 0.8978637688192386 recall 0.9389726328113567 f1 0.9392024038621252\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "905 of 1000 - 7.5834736824035645 s\n",
      "Accuracy 0.9301917166691058 precision 0.9307446980360379 specificity 0.8750273382058429 recall 0.9301917166691058 f1 0.9304426753557671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "906 of 1000 - 7.388448238372803 s\n",
      "Accuracy 0.9341431289331187 precision 0.9343297000950173 specificity 0.8809242104560846 recall 0.9341431289331187 f1 0.9342325737391688\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "907 of 1000 - 7.602518796920776 s\n",
      "Accuracy 0.9329723401141519 precision 0.9335434371706519 specificity 0.8893992001709379 recall 0.9329723401141519 f1 0.9332245028934661\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "908 of 1000 - 7.4453489780426025 s\n",
      "Accuracy 0.9320942484999268 precision 0.9322511344789259 specificity 0.877953299293377 recall 0.9320942484999268 f1 0.9321700475189151\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "909 of 1000 - 7.436445474624634 s\n",
      "Accuracy 0.9307771110785892 precision 0.9306442708059957 specificity 0.8734010863862547 recall 0.9307771110785892 f1 0.93070855722313\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "910 of 1000 - 7.563440799713135 s\n",
      "Accuracy 0.9296063222596225 precision 0.9295605014203867 specificity 0.8726947987685956 recall 0.9296063222596225 f1 0.9295831759553727\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "911 of 1000 - 7.5613813400268555 s\n",
      "Accuracy 0.9250695155861262 precision 0.9249122925843845 specificity 0.8643950210984561 recall 0.9250695155861262 f1 0.9249883137722432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "912 of 1000 - 7.464144706726074 s\n",
      "Accuracy 0.9293136250548807 precision 0.9293296074495914 specificity 0.8703952791046451 recall 0.9293136250548807 f1 0.9293215898283611\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "913 of 1000 - 7.50331711769104 s\n",
      "Accuracy 0.9316552026928143 precision 0.9317926898302876 specificity 0.8794963883585889 recall 0.9316552026928143 f1 0.9317218283384119\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "914 of 1000 - 7.479483604431152 s\n",
      "Accuracy 0.9326796429094102 precision 0.9330570958838904 specificity 0.884595921041906 recall 0.9326796429094102 f1 0.9328533616813658\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "915 of 1000 - 7.4865052700042725 s\n",
      "Accuracy 0.9294599736572515 precision 0.930375749093239 specificity 0.8849939820395184 recall 0.9294599736572515 f1 0.9298485959838643\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "916 of 1000 - 7.5574729442596436 s\n",
      "Accuracy 0.9266793502122055 precision 0.9265417156666342 specificity 0.8681926181675566 recall 0.9266793502122055 f1 0.9266084341860671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "917 of 1000 - 7.440448999404907 s\n",
      "Accuracy 0.9316552026928143 precision 0.9313896173630523 specificity 0.873577720157563 recall 0.9316552026928143 f1 0.9315128761802651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "918 of 1000 - 7.6109938621521 s\n",
      "Accuracy 0.9329723401141519 precision 0.9336727679033541 specificity 0.8829058515310919 recall 0.9329723401141519 f1 0.933280032076992\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "919 of 1000 - 7.533773899078369 s\n",
      "Accuracy 0.9294599736572515 precision 0.9296514825467407 specificity 0.8757985504074528 recall 0.9294599736572515 f1 0.9295519776578858\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "920 of 1000 - 7.580773830413818 s\n",
      "Accuracy 0.9323869457046685 precision 0.9332555219491265 specificity 0.8831911303067058 recall 0.9323869457046685 f1 0.932760141198159\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "921 of 1000 - 7.409453392028809 s\n",
      "Accuracy 0.9301917166691058 precision 0.9302997124309865 specificity 0.876853982992782 recall 0.9301917166691058 f1 0.9302444383322067\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "922 of 1000 - 7.422290563583374 s\n",
      "Accuracy 0.930045368066735 precision 0.9301383979366641 specificity 0.8758752957275607 recall 0.930045368066735 f1 0.93009094341207\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "923 of 1000 - 7.5154454708099365 s\n",
      "Accuracy 0.9298990194643642 precision 0.9294831808551646 specificity 0.870343526073726 recall 0.9298990194643642 f1 0.9296659381787293\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "924 of 1000 - 7.467787742614746 s\n",
      "Accuracy 0.9260939558027221 precision 0.926511328288631 specificity 0.8668866347276227 recall 0.9260939558027221 f1 0.9262887442612674\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "925 of 1000 - 7.550396203994751 s\n",
      "Accuracy 0.9312161568857017 precision 0.9308396194858423 specificity 0.8721634733045311 recall 0.9312161568857017 f1 0.9310072372991548\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "926 of 1000 - 7.514097452163696 s\n",
      "Accuracy 0.9392653300160984 precision 0.9393061088667535 specificity 0.8904931362256119 recall 0.9392653300160984 f1 0.9392854783922739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "927 of 1000 - 7.424445629119873 s\n",
      "Accuracy 0.9320942484999268 precision 0.9320942484999268 specificity 0.8746658848372098 recall 0.9320942484999268 f1 0.9320942484999268\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "928 of 1000 - 7.531475305557251 s\n",
      "Accuracy 0.9284355334406557 precision 0.9285138904026593 specificity 0.8735400497478787 recall 0.9284355334406557 f1 0.9284740632784116\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "929 of 1000 - 7.609437465667725 s\n",
      "Accuracy 0.9301917166691058 precision 0.9304898619041264 specificity 0.8808768843828702 recall 0.9301917166691058 f1 0.9303314838457781\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "930 of 1000 - 7.534286737442017 s\n",
      "Accuracy 0.9307771110785892 precision 0.9301637265785552 specificity 0.8672606638575024 recall 0.9307771110785892 f1 0.9304068052392036\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "931 of 1000 - 7.570473909378052 s\n",
      "Accuracy 0.9284355334406557 precision 0.9281342688463066 specificity 0.868914072854074 recall 0.9284355334406557 f1 0.928273389457911\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "932 of 1000 - 7.4490227699279785 s\n",
      "Accuracy 0.935752963559198 precision 0.9356811965792112 specificity 0.880283623456741 recall 0.935752963559198 f1 0.935716407204689\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "933 of 1000 - 7.396484375 s\n",
      "Accuracy 0.9313625054880725 precision 0.9313469832952204 specificity 0.8731771172132089 recall 0.9313625054880725 f1 0.9313547177766403\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "934 of 1000 - 7.464024305343628 s\n",
      "Accuracy 0.933850431728377 precision 0.9342239356126267 specificity 0.8777621874607979 recall 0.933850431728377 f1 0.9340240628563421\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "935 of 1000 - 7.63348388671875 s\n",
      "Accuracy 0.9325332943070394 precision 0.9328913549826962 specificity 0.8848809984529888 recall 0.9325332943070394 f1 0.9326985862394103\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "936 of 1000 - 7.441470623016357 s\n",
      "Accuracy 0.9258012585979803 precision 0.9266855323002293 specificity 0.8787366012978697 recall 0.9258012585979803 f1 0.9261825064007865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "937 of 1000 - 7.459542751312256 s\n",
      "Accuracy 0.9332650373188937 precision 0.9334430673587989 specificity 0.8842756343787356 recall 0.9332650373188937 f1 0.9333502993542458\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "938 of 1000 - 7.397452354431152 s\n",
      "Accuracy 0.9310698082833309 precision 0.9313050853719277 specificity 0.8796724378226729 recall 0.9310698082833309 f1 0.9311815819305317\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "939 of 1000 - 7.543437480926514 s\n",
      "Accuracy 0.9342894775354895 precision 0.9347518413564553 specificity 0.8868465769996898 recall 0.9342894775354895 f1 0.9344985456511786\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "940 of 1000 - 7.445487976074219 s\n",
      "Accuracy 0.9348748719449729 precision 0.9352504884954653 specificity 0.890201317203302 recall 0.9348748719449729 f1 0.9350464387374788\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "941 of 1000 - 7.5229575634002686 s\n",
      "Accuracy 0.9304844138738475 precision 0.9307215755005115 specificity 0.8786228013668512 recall 0.9304844138738475 f1 0.9305971367664599\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "942 of 1000 - 7.522438049316406 s\n",
      "Accuracy 0.9318015512951852 precision 0.9335948698491917 specificity 0.8976858098235966 recall 0.9318015512951852 f1 0.9324734505329865\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "943 of 1000 - 7.595432758331299 s\n",
      "Accuracy 0.9293136250548807 precision 0.9291188975601777 specificity 0.8694405345588763 recall 0.9293136250548807 f1 0.9292118084547081\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "944 of 1000 - 7.563117504119873 s\n",
      "Accuracy 0.927118396019318 precision 0.927959879721506 specificity 0.8772510089481814 recall 0.927118396019318 f1 0.9274845843182873\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "945 of 1000 - 7.523505210876465 s\n",
      "Accuracy 0.9287282306453973 precision 0.9291143710126658 specificity 0.8758926369962396 recall 0.9287282306453973 f1 0.9289075453960155\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "946 of 1000 - 7.456475257873535 s\n",
      "Accuracy 0.9306307624762183 precision 0.9307210838588729 specificity 0.8787251531754805 recall 0.9306307624762183 f1 0.930674989341986\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "947 of 1000 - 7.481206893920898 s\n",
      "Accuracy 0.9291672764525098 precision 0.9294441496564443 specificity 0.8701076208225432 recall 0.9291672764525098 f1 0.9292989005937012\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "948 of 1000 - 7.4694836139678955 s\n",
      "Accuracy 0.93092345968096 precision 0.9313030921333048 specificity 0.882925780332173 recall 0.93092345968096 f1 0.9310984143890733\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "949 of 1000 - 7.420029878616333 s\n",
      "Accuracy 0.9331186887165227 precision 0.9329582216650538 specificity 0.8745903952963732 recall 0.9331186887165227 f1 0.9330352157413184\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "950 of 1000 - 7.546990394592285 s\n",
      "Accuracy 0.9320942484999268 precision 0.9322846923081626 specificity 0.8778983601936111 recall 0.9320942484999268 f1 0.9321856581030953\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "951 of 1000 - 7.55048394203186 s\n",
      "Accuracy 0.9337040831260062 precision 0.9336376033034955 specificity 0.8852660845116554 recall 0.9337040831260062 f1 0.9336701977801839\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "952 of 1000 - 7.478787422180176 s\n",
      "Accuracy 0.9298990194643642 precision 0.9305417246148945 specificity 0.8799928565287407 recall 0.9298990194643642 f1 0.9301847086791267\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "953 of 1000 - 7.523438930511475 s\n",
      "Accuracy 0.924337772574272 precision 0.9244567547462187 specificity 0.8646709209852744 recall 0.924337772574272 f1 0.9243959947596636\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "954 of 1000 - 7.479023694992065 s\n",
      "Accuracy 0.9353139177520855 precision 0.9354284517581604 specificity 0.8865220517719945 recall 0.9353139177520855 f1 0.9353695034296634\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "955 of 1000 - 7.376474857330322 s\n",
      "Accuracy 0.9282891848382848 precision 0.9290070459874403 specificity 0.8772240246906653 recall 0.9282891848382848 f1 0.9286065367361622\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "956 of 1000 - 7.541651248931885 s\n",
      "Accuracy 0.9259476072003512 precision 0.9262555554233153 specificity 0.8700977193745999 recall 0.9259476072003512 f1 0.9260932001384956\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "957 of 1000 - 7.4924116134643555 s\n",
      "Accuracy 0.9334113859212645 precision 0.933368114066483 specificity 0.8796228512826908 recall 0.9334113859212645 f1 0.9333895123399174\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "958 of 1000 - 7.504492282867432 s\n",
      "Accuracy 0.9266793502122055 precision 0.9273889335388259 specificity 0.8796696932678645 recall 0.9266793502122055 f1 0.9269915036950059\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "959 of 1000 - 7.452440977096558 s\n",
      "Accuracy 0.9304844138738475 precision 0.9303246166713548 specificity 0.8736513787921257 recall 0.9304844138738475 f1 0.9304013425918944\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "960 of 1000 - 7.5369553565979 s\n",
      "Accuracy 0.9307771110785892 precision 0.9308242943293837 specificity 0.8736220230719619 recall 0.9307771110785892 f1 0.9308004644240592\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "961 of 1000 - 7.440743684768677 s\n",
      "Accuracy 0.928142836235914 precision 0.9278889080835022 specificity 0.8671805729541016 recall 0.928142836235914 f1 0.928008285207554\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "962 of 1000 - 7.476007699966431 s\n",
      "Accuracy 0.9318015512951852 precision 0.931531201772768 specificity 0.8759249905371623 recall 0.9318015512951852 f1 0.9316559029923062\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "963 of 1000 - 7.478447914123535 s\n",
      "Accuracy 0.9350212205473438 precision 0.9349635328086197 specificity 0.880002619614118 recall 0.9350212205473438 f1 0.9349919484165524\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "964 of 1000 - 7.487438440322876 s\n",
      "Accuracy 0.929020927850139 precision 0.9289758073847485 specificity 0.8737092025510562 recall 0.929020927850139 f1 0.9289981339084994\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "965 of 1000 - 7.451443672180176 s\n",
      "Accuracy 0.9322405971022977 precision 0.9321969896336085 specificity 0.8783475584507281 recall 0.9322405971022977 f1 0.9322185570937787\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "966 of 1000 - 7.417428016662598 s\n",
      "Accuracy 0.9272647446216888 precision 0.9271529259720547 specificity 0.8654872564636455 recall 0.9272647446216888 f1 0.9272075452256922\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "967 of 1000 - 7.5104475021362305 s\n",
      "Accuracy 0.9297526708619933 precision 0.9300130406650599 specificity 0.8761167617100233 recall 0.9297526708619933 f1 0.9298761651880647\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "968 of 1000 - 7.459449529647827 s\n",
      "Accuracy 0.9291672764525098 precision 0.929522405622868 specificity 0.8791538832817374 recall 0.9291672764525098 f1 0.9293323758194811\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "969 of 1000 - 7.486671209335327 s\n",
      "Accuracy 0.9303380652714767 precision 0.9306629898521064 specificity 0.8784754461044275 recall 0.9303380652714767 f1 0.9304900942415893\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "970 of 1000 - 7.512543439865112 s\n",
      "Accuracy 0.9269720474169472 precision 0.927113902003078 specificity 0.873985986221485 recall 0.9269720474169472 f1 0.9270409000434262\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "971 of 1000 - 7.528437852859497 s\n",
      "Accuracy 0.924337772574272 precision 0.9243214010387634 specificity 0.8644847240815661 recall 0.924337772574272 f1 0.9243295609781471\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "972 of 1000 - 7.478454351425171 s\n",
      "Accuracy 0.9310698082833309 precision 0.931407954422595 specificity 0.8801799276493621 recall 0.9310698082833309 f1 0.9312273734244343\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "973 of 1000 - 7.757604598999023 s\n",
      "Accuracy 0.9331186887165227 precision 0.9328000269828037 specificity 0.8729626443246806 recall 0.9331186887165227 f1 0.9329451884164816\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "974 of 1000 - 7.5484418869018555 s\n",
      "Accuracy 0.927118396019318 precision 0.9268245370799998 specificity 0.8667070973016108 recall 0.927118396019318 f1 0.926961053664813\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "975 of 1000 - 7.6184375286102295 s\n",
      "Accuracy 0.9335577345236353 precision 0.9334986666293006 specificity 0.8772346525197214 recall 0.9335577345236353 f1 0.9335277734700153\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "976 of 1000 - 7.503260612487793 s\n",
      "Accuracy 0.9284355334406557 precision 0.9288893144689305 specificity 0.8773999830732423 recall 0.9284355334406557 f1 0.9286435945645382\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "977 of 1000 - 7.5393054485321045 s\n",
      "Accuracy 0.9296063222596225 precision 0.9301332350583081 specificity 0.8790114702273164 recall 0.9296063222596225 f1 0.9298447946041609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "978 of 1000 - 7.5619611740112305 s\n",
      "Accuracy 0.9344358261378604 precision 0.9344358261378604 specificity 0.8819600392088073 recall 0.9344358261378604 f1 0.9344358261378604\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "979 of 1000 - 7.544969320297241 s\n",
      "Accuracy 0.9312161568857017 precision 0.9311263792830623 specificity 0.8738987011687063 recall 0.9312161568857017 f1 0.9311703163880723\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "980 of 1000 - 7.6024391651153564 s\n",
      "Accuracy 0.9307771110785892 precision 0.931180665809598 specificity 0.8731746812452962 recall 0.9307771110785892 f1 0.930964711119375\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "981 of 1000 - 7.65717625617981 s\n",
      "Accuracy 0.9294599736572515 precision 0.9290794870865849 specificity 0.8705571635519198 recall 0.9294599736572515 f1 0.9292492720242415\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "982 of 1000 - 7.6083009243011475 s\n",
      "Accuracy 0.9332650373188937 precision 0.9334925826002889 specificity 0.8774573827383657 recall 0.9332650373188937 f1 0.9333735456501651\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "983 of 1000 - 7.596431493759155 s\n",
      "Accuracy 0.935752963559198 precision 0.9358854031671549 specificity 0.8850587241798337 recall 0.935752963559198 f1 0.93581703066977\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "984 of 1000 - 7.633089780807495 s\n",
      "Accuracy 0.9296063222596225 precision 0.9293851084039848 specificity 0.8699786289841444 recall 0.9296063222596225 f1 0.929489789006887\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "985 of 1000 - 7.612987518310547 s\n",
      "Accuracy 0.9322405971022977 precision 0.9324808828479124 specificity 0.8785935238404183 recall 0.9322405971022977 f1 0.9323547821569679\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "986 of 1000 - 7.417733669281006 s\n",
      "Accuracy 0.9313625054880725 precision 0.9314078934084509 specificity 0.8773344175962228 recall 0.9313625054880725 f1 0.9313849634107312\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "987 of 1000 - 7.491441965103149 s\n",
      "Accuracy 0.9360456607639397 precision 0.9365336242430258 specificity 0.8900456090773302 recall 0.9360456607639397 f1 0.9362642496976752\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "988 of 1000 - 7.519143342971802 s\n",
      "Accuracy 0.9320942484999268 precision 0.9319196269169903 specificity 0.8738125179089316 recall 0.9320942484999268 f1 0.932003109673266\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "989 of 1000 - 7.600432395935059 s\n",
      "Accuracy 0.9263866530074638 precision 0.9262432134122304 specificity 0.8642858905674607 recall 0.9263866530074638 f1 0.9263128095001903\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "990 of 1000 - 7.363471508026123 s\n",
      "Accuracy 0.930045368066735 precision 0.9307650303486457 specificity 0.8834875982026785 recall 0.930045368066735 f1 0.9303597229540527\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "991 of 1000 - 8.069918632507324 s\n",
      "Accuracy 0.9316552026928143 precision 0.9315242413304563 specificity 0.8750677292131208 recall 0.9316552026928143 f1 0.9315875851616725\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "992 of 1000 - 7.621588230133057 s\n",
      "Accuracy 0.9291672764525098 precision 0.9292902983510288 specificity 0.8769738120036203 recall 0.9291672764525098 f1 0.9292271360673735\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "993 of 1000 - 7.6931397914886475 s\n",
      "Accuracy 0.931947899897556 precision 0.9318205020834827 specificity 0.8775254214169718 recall 0.931947899897556 f1 0.9318820796337747\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "994 of 1000 - 7.545955419540405 s\n",
      "Accuracy 0.9316552026928143 precision 0.9314028665725469 specificity 0.8693477270742204 recall 0.9316552026928143 f1 0.9315212666324671\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "995 of 1000 - 7.563432693481445 s\n",
      "Accuracy 0.9354602663544563 precision 0.9355293142039984 specificity 0.8880112749171059 recall 0.9354602663544563 f1 0.9354941381172459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "996 of 1000 - 7.728056192398071 s\n",
      "Accuracy 0.928142836235914 precision 0.9284200718821538 specificity 0.8753604075348362 recall 0.928142836235914 f1 0.9282739860155739\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "997 of 1000 - 7.572206258773804 s\n",
      "Accuracy 0.9356066149568272 precision 0.9360738441147658 specificity 0.8901305327133591 recall 0.9356066149568272 f1 0.9358165825931294\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "998 of 1000 - 7.586458921432495 s\n",
      "Accuracy 0.9337040831260062 precision 0.933806593246538 specificity 0.8832830197803349 recall 0.9337040831260062 f1 0.9337540537254027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "999 of 1000 - 7.540440082550049 s\n",
      "Accuracy 0.9287282306453973 precision 0.9291687528442497 specificity 0.8801527739448641 recall 0.9287282306453973 f1 0.9289298212010804\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "1000 of 1000 - 7.639430046081543 s\n",
      "Accuracy 0.9307771110785892 precision 0.9314912911200051 specificity 0.8821812864149073 recall 0.9307771110785892 f1 0.9310903376025391\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "split_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "smote_seeds = random.sample(range(1, 2**32 - 1), 1000)\n",
    "for i, (split_seed, smote_seed) in enumerate(zip(split_seeds, smote_seeds)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_fsel, y, test_size=0.2, random_state=split_seed)\n",
    "    smote = SMOTE(random_state=smote_seed, n_jobs=THREADS_TO_USE)\n",
    "    x_smote, y_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE).fit(x_smote, y_smote)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "     }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(split_seeds), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.927850     0.874974   0.928058  0.927850  0.927950\n1  0.934143     0.878760   0.933791  0.934143  0.933946\n2  0.929899     0.862174   0.929395  0.929899  0.929614\n3  0.929606     0.875843   0.929921  0.929606  0.929754\n4  0.925070     0.859644   0.924700  0.925070  0.924870\n5  0.931948     0.874899   0.931789  0.931948  0.931865\n6  0.937363     0.890581   0.937363  0.937363  0.937363\n7  0.931509     0.875035   0.931604  0.931509  0.931555\n8  0.933265     0.882559   0.933384  0.933265  0.933323\n9  0.932241     0.876149   0.932167  0.932241  0.932203",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.927850</td>\n      <td>0.874974</td>\n      <td>0.928058</td>\n      <td>0.927850</td>\n      <td>0.927950</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.934143</td>\n      <td>0.878760</td>\n      <td>0.933791</td>\n      <td>0.934143</td>\n      <td>0.933946</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.929899</td>\n      <td>0.862174</td>\n      <td>0.929395</td>\n      <td>0.929899</td>\n      <td>0.929614</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.929606</td>\n      <td>0.875843</td>\n      <td>0.929921</td>\n      <td>0.929606</td>\n      <td>0.929754</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.925070</td>\n      <td>0.859644</td>\n      <td>0.924700</td>\n      <td>0.925070</td>\n      <td>0.924870</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.931948</td>\n      <td>0.874899</td>\n      <td>0.931789</td>\n      <td>0.931948</td>\n      <td>0.931865</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.937363</td>\n      <td>0.890581</td>\n      <td>0.937363</td>\n      <td>0.937363</td>\n      <td>0.937363</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.931509</td>\n      <td>0.875035</td>\n      <td>0.931604</td>\n      <td>0.931509</td>\n      <td>0.931555</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.933265</td>\n      <td>0.882559</td>\n      <td>0.933384</td>\n      <td>0.933265</td>\n      <td>0.933323</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.932241</td>\n      <td>0.876149</td>\n      <td>0.932167</td>\n      <td>0.932241</td>\n      <td>0.932203</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.9313112834772428\n",
      "Precision 0.9314484816068016\n",
      "Specificity 0.8779169959094805\n",
      "Recall 0.9313112834772428\n",
      "F1 0.9313648122610468\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_16beats_smote_1000x_random_split.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}