{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Paper CHF - 16 beats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvvfuiWpEhzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sU5Wt4HhzLod"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "THREADS_TO_USE = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "8Np3QbHCz3aM",
    "outputId": "fde427c8-b2d8-476c-ee8c-25840d4bed62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id       dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1  \\\n0  e0106  65.861928  67.716291  67.206386  18.973287  2.756737  0.736288   \n1  e0106  67.175188  66.539171  66.278974  18.879508  2.752145  0.710574   \n2  e0106  67.331260  67.526064  67.904703  19.526248  2.883850  0.724048   \n3  e0106  66.507411  69.358972  68.845433  19.399284  2.811633  0.728870   \n4  e0106  71.500586  69.600473  69.015425  19.518971  2.844739  0.706509   \n\n      mfw_2     mfw_3     mfw_4  ...     cfr_8     cfr_9    cfr_10    cfr_11  \\\n0 -0.634501 -1.015121 -0.279539  ... -0.038497  0.024202 -0.033980  0.046029   \n1 -0.608829 -1.008338 -0.375129  ... -0.045707  0.028543 -0.033995  0.039226   \n2 -0.611290 -1.007119 -0.471325  ... -0.064803  0.051981 -0.056875  0.061396   \n3 -0.631538 -1.076715 -0.451683  ... -0.042918  0.033450 -0.043966  0.053377   \n4 -0.610843 -1.008555 -0.438800  ... -0.047597  0.025825 -0.031552  0.048798   \n\n     cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  label  \n0 -0.071080  0.009209 -0.027384 -0.007471 -0.007113    NSR  \n1 -0.065687 -0.004942 -0.011601 -0.016082 -0.002783    NSR  \n2 -0.081542  0.009957 -0.023760 -0.019310  0.008258    NSR  \n3 -0.073200  0.002332 -0.021755 -0.003223 -0.021226    NSR  \n4 -0.093202  0.026254 -0.038423 -0.005951 -0.003403    NSR  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>...</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e0106</td>\n      <td>65.861928</td>\n      <td>67.716291</td>\n      <td>67.206386</td>\n      <td>18.973287</td>\n      <td>2.756737</td>\n      <td>0.736288</td>\n      <td>-0.634501</td>\n      <td>-1.015121</td>\n      <td>-0.279539</td>\n      <td>...</td>\n      <td>-0.038497</td>\n      <td>0.024202</td>\n      <td>-0.033980</td>\n      <td>0.046029</td>\n      <td>-0.071080</td>\n      <td>0.009209</td>\n      <td>-0.027384</td>\n      <td>-0.007471</td>\n      <td>-0.007113</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0106</td>\n      <td>67.175188</td>\n      <td>66.539171</td>\n      <td>66.278974</td>\n      <td>18.879508</td>\n      <td>2.752145</td>\n      <td>0.710574</td>\n      <td>-0.608829</td>\n      <td>-1.008338</td>\n      <td>-0.375129</td>\n      <td>...</td>\n      <td>-0.045707</td>\n      <td>0.028543</td>\n      <td>-0.033995</td>\n      <td>0.039226</td>\n      <td>-0.065687</td>\n      <td>-0.004942</td>\n      <td>-0.011601</td>\n      <td>-0.016082</td>\n      <td>-0.002783</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0106</td>\n      <td>67.331260</td>\n      <td>67.526064</td>\n      <td>67.904703</td>\n      <td>19.526248</td>\n      <td>2.883850</td>\n      <td>0.724048</td>\n      <td>-0.611290</td>\n      <td>-1.007119</td>\n      <td>-0.471325</td>\n      <td>...</td>\n      <td>-0.064803</td>\n      <td>0.051981</td>\n      <td>-0.056875</td>\n      <td>0.061396</td>\n      <td>-0.081542</td>\n      <td>0.009957</td>\n      <td>-0.023760</td>\n      <td>-0.019310</td>\n      <td>0.008258</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e0106</td>\n      <td>66.507411</td>\n      <td>69.358972</td>\n      <td>68.845433</td>\n      <td>19.399284</td>\n      <td>2.811633</td>\n      <td>0.728870</td>\n      <td>-0.631538</td>\n      <td>-1.076715</td>\n      <td>-0.451683</td>\n      <td>...</td>\n      <td>-0.042918</td>\n      <td>0.033450</td>\n      <td>-0.043966</td>\n      <td>0.053377</td>\n      <td>-0.073200</td>\n      <td>0.002332</td>\n      <td>-0.021755</td>\n      <td>-0.003223</td>\n      <td>-0.021226</td>\n      <td>NSR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0106</td>\n      <td>71.500586</td>\n      <td>69.600473</td>\n      <td>69.015425</td>\n      <td>19.518971</td>\n      <td>2.844739</td>\n      <td>0.706509</td>\n      <td>-0.610843</td>\n      <td>-1.008555</td>\n      <td>-0.438800</td>\n      <td>...</td>\n      <td>-0.047597</td>\n      <td>0.025825</td>\n      <td>-0.031552</td>\n      <td>0.048798</td>\n      <td>-0.093202</td>\n      <td>0.026254</td>\n      <td>-0.038423</td>\n      <td>-0.005951</td>\n      <td>-0.003403</td>\n      <td>NSR</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 312 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/st_dataset_16beats.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5dViKffmM1R-",
    "outputId": "c6ff05eb-09aa-4f7c-be89-009ac7afd18f"
   },
   "outputs": [],
   "source": [
    "data['label'].replace(\"ST-\", \"ST\", inplace=True)\n",
    "data['label'].replace(\"ST+\", \"ST\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "id": "X_zZ_EZS05-I",
    "outputId": "9011c6c1-3750-4c63-dd0f-06e1f07dcbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NSR    26200\nST      7965\nName: label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HA9xJsHxEMxs",
    "outputId": "6e5b8808-767f-4c54-e5fe-13b714e9a8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar', title='Category', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "oTFBnfVnrDcu",
    "outputId": "9160f9de-983c-44a9-ffd1-e2cbaffee427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            dw_1      dw_2      dw_3      dw_4      dw_5     mfw_1     mfw_2  \\\ndw_1    1.000000  0.219210  0.101301  0.071494  0.053500  0.102907 -0.028753   \ndw_2    0.219210  1.000000  0.838628  0.486610  0.180151  0.408486 -0.502032   \ndw_3    0.101301  0.838628  1.000000  0.680243  0.272747  0.255846 -0.548064   \ndw_4    0.071494  0.486610  0.680243  1.000000  0.880644 -0.012857 -0.262781   \ndw_5    0.053500  0.180151  0.272747  0.880644  1.000000 -0.126287 -0.018966   \n...          ...       ...       ...       ...       ...       ...       ...   \ncfr_12 -0.057237  0.034692  0.061458  0.050791  0.019165 -0.138724  0.094631   \ncfr_13 -0.042960  0.128171  0.046053  0.024330  0.013247  0.077703 -0.006064   \ncfr_14 -0.052143  0.009246 -0.019790 -0.029443 -0.034829  0.004839  0.022487   \ncfr_15 -0.079161 -0.115564 -0.131894 -0.102508 -0.053621  0.045425  0.082850   \ncfr_16 -0.066310 -0.075292 -0.046861 -0.042964 -0.029838  0.074518 -0.038814   \n\n           mfw_3     mfw_4     mfw_5  ...     cfr_7     cfr_8     cfr_9  \\\ndw_1    0.044410 -0.002493  0.004377  ... -0.077538 -0.054871 -0.040977   \ndw_2   -0.337710  0.001285  0.018225  ... -0.123426  0.167397  0.237288   \ndw_3   -0.460442  0.004292  0.010350  ... -0.203574  0.143928  0.272752   \ndw_4   -0.246875  0.003327  0.003775  ... -0.154983  0.064231  0.121135   \ndw_5   -0.039939  0.000859  0.000096  ... -0.070726  0.009459  0.007874   \n...          ...       ...       ...  ...       ...       ...       ...   \ncfr_12  0.121316 -0.001690  0.004790  ... -0.134379 -0.207376 -0.072612   \ncfr_13  0.009997  0.003478 -0.000130  ...  0.147883  0.041925 -0.211124   \ncfr_14  0.027808  0.003788 -0.003911  ...  0.109109  0.222240  0.044405   \ncfr_15  0.052462  0.001549 -0.008696  ...  0.279721  0.160473 -0.089826   \ncfr_16 -0.011343  0.011160 -0.005962  ...  0.257415  0.135676  0.188556   \n\n          cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15    cfr_16  \ndw_1   -0.037365 -0.023672 -0.057237 -0.042960 -0.052143 -0.079161 -0.066310  \ndw_2    0.168364  0.049215  0.034692  0.128171  0.009246 -0.115564 -0.075292  \ndw_3    0.119350 -0.051559  0.061458  0.046053 -0.019790 -0.131894 -0.046861  \ndw_4    0.050684 -0.040099  0.050791  0.024330 -0.029443 -0.102508 -0.042964  \ndw_5    0.021196  0.000299  0.019165  0.013247 -0.034829 -0.053621 -0.029838  \n...          ...       ...       ...       ...       ...       ...       ...  \ncfr_12  0.035689  0.062709  1.000000  0.019376  0.001574 -0.345510 -0.225272  \ncfr_13 -0.268978 -0.011602  0.019376  1.000000  0.223072  0.131959 -0.159064  \ncfr_14 -0.175685 -0.289441  0.001574  0.223072  1.000000  0.198522 -0.135727  \ncfr_15 -0.144377 -0.074435 -0.345510  0.131959  0.198522  1.000000  0.297959  \ncfr_16  0.150307  0.005543 -0.225272 -0.159064 -0.135727  0.297959  1.000000  \n\n[310 rows x 310 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>mfw_5</th>\n      <th>...</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n      <th>cfr_16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dw_1</th>\n      <td>1.000000</td>\n      <td>0.219210</td>\n      <td>0.101301</td>\n      <td>0.071494</td>\n      <td>0.053500</td>\n      <td>0.102907</td>\n      <td>-0.028753</td>\n      <td>0.044410</td>\n      <td>-0.002493</td>\n      <td>0.004377</td>\n      <td>...</td>\n      <td>-0.077538</td>\n      <td>-0.054871</td>\n      <td>-0.040977</td>\n      <td>-0.037365</td>\n      <td>-0.023672</td>\n      <td>-0.057237</td>\n      <td>-0.042960</td>\n      <td>-0.052143</td>\n      <td>-0.079161</td>\n      <td>-0.066310</td>\n    </tr>\n    <tr>\n      <th>dw_2</th>\n      <td>0.219210</td>\n      <td>1.000000</td>\n      <td>0.838628</td>\n      <td>0.486610</td>\n      <td>0.180151</td>\n      <td>0.408486</td>\n      <td>-0.502032</td>\n      <td>-0.337710</td>\n      <td>0.001285</td>\n      <td>0.018225</td>\n      <td>...</td>\n      <td>-0.123426</td>\n      <td>0.167397</td>\n      <td>0.237288</td>\n      <td>0.168364</td>\n      <td>0.049215</td>\n      <td>0.034692</td>\n      <td>0.128171</td>\n      <td>0.009246</td>\n      <td>-0.115564</td>\n      <td>-0.075292</td>\n    </tr>\n    <tr>\n      <th>dw_3</th>\n      <td>0.101301</td>\n      <td>0.838628</td>\n      <td>1.000000</td>\n      <td>0.680243</td>\n      <td>0.272747</td>\n      <td>0.255846</td>\n      <td>-0.548064</td>\n      <td>-0.460442</td>\n      <td>0.004292</td>\n      <td>0.010350</td>\n      <td>...</td>\n      <td>-0.203574</td>\n      <td>0.143928</td>\n      <td>0.272752</td>\n      <td>0.119350</td>\n      <td>-0.051559</td>\n      <td>0.061458</td>\n      <td>0.046053</td>\n      <td>-0.019790</td>\n      <td>-0.131894</td>\n      <td>-0.046861</td>\n    </tr>\n    <tr>\n      <th>dw_4</th>\n      <td>0.071494</td>\n      <td>0.486610</td>\n      <td>0.680243</td>\n      <td>1.000000</td>\n      <td>0.880644</td>\n      <td>-0.012857</td>\n      <td>-0.262781</td>\n      <td>-0.246875</td>\n      <td>0.003327</td>\n      <td>0.003775</td>\n      <td>...</td>\n      <td>-0.154983</td>\n      <td>0.064231</td>\n      <td>0.121135</td>\n      <td>0.050684</td>\n      <td>-0.040099</td>\n      <td>0.050791</td>\n      <td>0.024330</td>\n      <td>-0.029443</td>\n      <td>-0.102508</td>\n      <td>-0.042964</td>\n    </tr>\n    <tr>\n      <th>dw_5</th>\n      <td>0.053500</td>\n      <td>0.180151</td>\n      <td>0.272747</td>\n      <td>0.880644</td>\n      <td>1.000000</td>\n      <td>-0.126287</td>\n      <td>-0.018966</td>\n      <td>-0.039939</td>\n      <td>0.000859</td>\n      <td>0.000096</td>\n      <td>...</td>\n      <td>-0.070726</td>\n      <td>0.009459</td>\n      <td>0.007874</td>\n      <td>0.021196</td>\n      <td>0.000299</td>\n      <td>0.019165</td>\n      <td>0.013247</td>\n      <td>-0.034829</td>\n      <td>-0.053621</td>\n      <td>-0.029838</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>cfr_12</th>\n      <td>-0.057237</td>\n      <td>0.034692</td>\n      <td>0.061458</td>\n      <td>0.050791</td>\n      <td>0.019165</td>\n      <td>-0.138724</td>\n      <td>0.094631</td>\n      <td>0.121316</td>\n      <td>-0.001690</td>\n      <td>0.004790</td>\n      <td>...</td>\n      <td>-0.134379</td>\n      <td>-0.207376</td>\n      <td>-0.072612</td>\n      <td>0.035689</td>\n      <td>0.062709</td>\n      <td>1.000000</td>\n      <td>0.019376</td>\n      <td>0.001574</td>\n      <td>-0.345510</td>\n      <td>-0.225272</td>\n    </tr>\n    <tr>\n      <th>cfr_13</th>\n      <td>-0.042960</td>\n      <td>0.128171</td>\n      <td>0.046053</td>\n      <td>0.024330</td>\n      <td>0.013247</td>\n      <td>0.077703</td>\n      <td>-0.006064</td>\n      <td>0.009997</td>\n      <td>0.003478</td>\n      <td>-0.000130</td>\n      <td>...</td>\n      <td>0.147883</td>\n      <td>0.041925</td>\n      <td>-0.211124</td>\n      <td>-0.268978</td>\n      <td>-0.011602</td>\n      <td>0.019376</td>\n      <td>1.000000</td>\n      <td>0.223072</td>\n      <td>0.131959</td>\n      <td>-0.159064</td>\n    </tr>\n    <tr>\n      <th>cfr_14</th>\n      <td>-0.052143</td>\n      <td>0.009246</td>\n      <td>-0.019790</td>\n      <td>-0.029443</td>\n      <td>-0.034829</td>\n      <td>0.004839</td>\n      <td>0.022487</td>\n      <td>0.027808</td>\n      <td>0.003788</td>\n      <td>-0.003911</td>\n      <td>...</td>\n      <td>0.109109</td>\n      <td>0.222240</td>\n      <td>0.044405</td>\n      <td>-0.175685</td>\n      <td>-0.289441</td>\n      <td>0.001574</td>\n      <td>0.223072</td>\n      <td>1.000000</td>\n      <td>0.198522</td>\n      <td>-0.135727</td>\n    </tr>\n    <tr>\n      <th>cfr_15</th>\n      <td>-0.079161</td>\n      <td>-0.115564</td>\n      <td>-0.131894</td>\n      <td>-0.102508</td>\n      <td>-0.053621</td>\n      <td>0.045425</td>\n      <td>0.082850</td>\n      <td>0.052462</td>\n      <td>0.001549</td>\n      <td>-0.008696</td>\n      <td>...</td>\n      <td>0.279721</td>\n      <td>0.160473</td>\n      <td>-0.089826</td>\n      <td>-0.144377</td>\n      <td>-0.074435</td>\n      <td>-0.345510</td>\n      <td>0.131959</td>\n      <td>0.198522</td>\n      <td>1.000000</td>\n      <td>0.297959</td>\n    </tr>\n    <tr>\n      <th>cfr_16</th>\n      <td>-0.066310</td>\n      <td>-0.075292</td>\n      <td>-0.046861</td>\n      <td>-0.042964</td>\n      <td>-0.029838</td>\n      <td>0.074518</td>\n      <td>-0.038814</td>\n      <td>-0.011343</td>\n      <td>0.011160</td>\n      <td>-0.005962</td>\n      <td>...</td>\n      <td>0.257415</td>\n      <td>0.135676</td>\n      <td>0.188556</td>\n      <td>0.150307</td>\n      <td>0.005543</td>\n      <td>-0.225272</td>\n      <td>-0.159064</td>\n      <td>-0.135727</td>\n      <td>0.297959</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows Ã— 310 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUvaDuwxTvzR"
   },
   "outputs": [],
   "source": [
    "y = data['label'].values\n",
    "X = data.loc[:, ~data.columns.isin([\"id\", \"label\"])].copy()\n",
    "patient_ids = data[\"id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exclude features with corr > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.95:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_247', 'fft_218', 'fft_182', 'fft_244', 'fft_137', 'fft_185', 'mfw_5', 'fft_153', 'fft_178', 'fft_205', 'fft_157', 'fft_246', 'fft_204', 'fft_220', 'fft_232', 'mfw_8', 'fft_158', 'fft_235', 'fft_243', 'fft_213', 'fft_166', 'fft_194', 'fft_208', 'cfr_16', 'fft_181', 'fft_132', 'fft_174', 'fft_252', 'fft_211', 'fft_228', 'fft_251', 'fft_130', 'fft_245', 'fft_237', 'fft_131', 'fft_134', 'fft_196', 'fft_242', 'fft_164', 'fft_148', 'fft_214', 'fft_186', 'fft_152', 'fft_206', 'fft_253', 'fft_168', 'fft_151', 'fft_177', 'fft_138', 'fft_231', 'fft_254', 'fft_165', 'fft_163', 'fft_147', 'fft_159', 'fft_175', 'fft_238', 'fft_176', 'fft_234', 'fft_172', 'fft_179', 'fft_222', 'fft_142', 'fft_188', 'fft_212', 'fft_193', 'fft_216', 'fft_210', 'fft_155', 'fft_136', 'mfw_12', 'fft_154', 'fft_161', 'fft_227', 'fft_203', 'fft_207', 'mfw_16', 'fft_139', 'fft_183', 'fft_201', 'fft_223', 'fft_192', 'fft_189', 'fft_170', 'fft_156', 'fft_236', 'fft_180', 'mfw_10', 'fft_135', 'fft_173', 'fft_144', 'fft_160', 'fft_146', 'mfw_11', 'fft_200', 'fft_250', 'fft_167', 'mfw_15', 'fft_255', 'fft_217', 'fft_224', 'fft_195', 'fft_162', 'fft_202', 'fft_198', 'fft_226', 'fft_149', 'fft_209', 'mfw_9', 'fft_233', 'fft_230', 'fft_187', 'fft_143', 'fft_256', 'fft_150', 'fft_215', 'fft_191', 'fft_145', 'fft_197', 'mfw_6', 'fft_199', 'fft_141', 'fft_225', 'fft_140', 'fft_184', 'fft_239', 'fft_190', 'fft_229', 'fft_169', 'mfw_7', 'fft_241', 'fft_248', 'fft_240', 'fft_249', 'fft_221', 'mfw_13', 'fft_133', 'mfw_14', 'fft_219', 'fft_171'}\n"
     ]
    }
   ],
   "source": [
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest embeded for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_no_corr = [col for col in X.columns if col not in correlated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SelectFromModel(estimator=RandomForestClassifier(n_jobs=4, random_state=101),\n                threshold='1.25*median')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state=101, n_jobs=THREADS_TO_USE), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X[cols_no_corr], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_1\n",
      "dw_2\n",
      "dw_3\n",
      "dw_4\n",
      "dw_5\n",
      "mfw_1\n",
      "mfw_2\n",
      "mfw_3\n",
      "mfw_4\n",
      "fft_1\n",
      "fft_2\n",
      "fft_3\n",
      "fft_4\n",
      "fft_5\n",
      "fft_6\n",
      "fft_7\n",
      "fft_8\n",
      "fft_9\n",
      "fft_10\n",
      "fft_11\n",
      "fft_12\n",
      "fft_13\n",
      "fft_14\n",
      "fft_15\n",
      "fft_16\n",
      "fft_17\n",
      "fft_18\n",
      "fft_19\n",
      "fft_20\n",
      "fft_21\n",
      "fft_22\n",
      "fft_23\n",
      "fft_24\n",
      "fft_29\n",
      "fft_30\n",
      "fft_31\n",
      "fft_32\n",
      "fft_33\n",
      "fft_34\n",
      "fft_35\n",
      "fft_36\n",
      "ar_1\n",
      "ar_2\n",
      "ar_3\n",
      "ar_4\n",
      "ar_5\n",
      "ar_6\n",
      "ar_7\n",
      "ar_8\n",
      "ar_9\n",
      "ar_10\n",
      "ar_11\n",
      "ar_12\n",
      "ar_13\n",
      "ar_14\n",
      "ar_15\n",
      "ar_16\n",
      "var\n",
      "cfr_1\n",
      "cfr_2\n",
      "cfr_3\n",
      "cfr_4\n",
      "cfr_5\n",
      "cfr_6\n",
      "cfr_7\n",
      "cfr_8\n",
      "cfr_9\n",
      "cfr_10\n",
      "cfr_11\n",
      "cfr_12\n",
      "cfr_13\n",
      "cfr_14\n",
      "cfr_15 \n",
      "selected features: 73\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X[cols_no_corr].loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "print('\\n'.join(embeded_rf_feature), '\\nselected features:', len(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization best features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_dict = dict(zip(cols_no_corr, embeded_rf_selector.estimator_.feature_importances_))\n",
    "features_dict = dict(sorted(features_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_features = dict()\n",
    "for index, (key, value) in enumerate(features_dict.items()):\n",
    "    if index < 8:\n",
    "        best_features[key] = value\n",
    "\n",
    "plt.bar(range(len(best_features)), list(best_features.values()), align='center', )\n",
    "plt.xticks(ticks=range(len(best_features)), labels=best_features.keys())\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance level')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "        dw_1       dw_2       dw_3       dw_4      dw_5     mfw_1     mfw_2  \\\n0  65.861928  67.716291  67.206386  18.973287  2.756737  0.736288 -0.634501   \n1  67.175188  66.539171  66.278974  18.879508  2.752145  0.710574 -0.608829   \n2  67.331260  67.526064  67.904703  19.526248  2.883850  0.724048 -0.611290   \n3  66.507411  69.358972  68.845433  19.399284  2.811633  0.728870 -0.631538   \n4  71.500586  69.600473  69.015425  19.518971  2.844739  0.706509 -0.610843   \n\n      mfw_3     mfw_4     fft_1  ...     cfr_6     cfr_7     cfr_8     cfr_9  \\\n0 -1.015121 -0.279539  0.905306  ...  0.020720  0.039231 -0.038497  0.024202   \n1 -1.008338 -0.375129 -0.354970  ...  0.009445  0.040896 -0.045707  0.028543   \n2 -1.007119 -0.471325  1.782405  ...  0.011313  0.048344 -0.064803  0.051981   \n3 -1.076715 -0.451683 -3.475203  ...  0.013055  0.040612 -0.042918  0.033450   \n4 -1.008555 -0.438800 -1.080058  ...  0.004456  0.042616 -0.047597  0.025825   \n\n     cfr_10    cfr_11    cfr_12    cfr_13    cfr_14    cfr_15  \n0 -0.033980  0.046029 -0.071080  0.009209 -0.027384 -0.007471  \n1 -0.033995  0.039226 -0.065687 -0.004942 -0.011601 -0.016082  \n2 -0.056875  0.061396 -0.081542  0.009957 -0.023760 -0.019310  \n3 -0.043966  0.053377 -0.073200  0.002332 -0.021755 -0.003223  \n4 -0.031552  0.048798 -0.093202  0.026254 -0.038423 -0.005951  \n\n[5 rows x 73 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dw_1</th>\n      <th>dw_2</th>\n      <th>dw_3</th>\n      <th>dw_4</th>\n      <th>dw_5</th>\n      <th>mfw_1</th>\n      <th>mfw_2</th>\n      <th>mfw_3</th>\n      <th>mfw_4</th>\n      <th>fft_1</th>\n      <th>...</th>\n      <th>cfr_6</th>\n      <th>cfr_7</th>\n      <th>cfr_8</th>\n      <th>cfr_9</th>\n      <th>cfr_10</th>\n      <th>cfr_11</th>\n      <th>cfr_12</th>\n      <th>cfr_13</th>\n      <th>cfr_14</th>\n      <th>cfr_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>65.861928</td>\n      <td>67.716291</td>\n      <td>67.206386</td>\n      <td>18.973287</td>\n      <td>2.756737</td>\n      <td>0.736288</td>\n      <td>-0.634501</td>\n      <td>-1.015121</td>\n      <td>-0.279539</td>\n      <td>0.905306</td>\n      <td>...</td>\n      <td>0.020720</td>\n      <td>0.039231</td>\n      <td>-0.038497</td>\n      <td>0.024202</td>\n      <td>-0.033980</td>\n      <td>0.046029</td>\n      <td>-0.071080</td>\n      <td>0.009209</td>\n      <td>-0.027384</td>\n      <td>-0.007471</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.175188</td>\n      <td>66.539171</td>\n      <td>66.278974</td>\n      <td>18.879508</td>\n      <td>2.752145</td>\n      <td>0.710574</td>\n      <td>-0.608829</td>\n      <td>-1.008338</td>\n      <td>-0.375129</td>\n      <td>-0.354970</td>\n      <td>...</td>\n      <td>0.009445</td>\n      <td>0.040896</td>\n      <td>-0.045707</td>\n      <td>0.028543</td>\n      <td>-0.033995</td>\n      <td>0.039226</td>\n      <td>-0.065687</td>\n      <td>-0.004942</td>\n      <td>-0.011601</td>\n      <td>-0.016082</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.331260</td>\n      <td>67.526064</td>\n      <td>67.904703</td>\n      <td>19.526248</td>\n      <td>2.883850</td>\n      <td>0.724048</td>\n      <td>-0.611290</td>\n      <td>-1.007119</td>\n      <td>-0.471325</td>\n      <td>1.782405</td>\n      <td>...</td>\n      <td>0.011313</td>\n      <td>0.048344</td>\n      <td>-0.064803</td>\n      <td>0.051981</td>\n      <td>-0.056875</td>\n      <td>0.061396</td>\n      <td>-0.081542</td>\n      <td>0.009957</td>\n      <td>-0.023760</td>\n      <td>-0.019310</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>66.507411</td>\n      <td>69.358972</td>\n      <td>68.845433</td>\n      <td>19.399284</td>\n      <td>2.811633</td>\n      <td>0.728870</td>\n      <td>-0.631538</td>\n      <td>-1.076715</td>\n      <td>-0.451683</td>\n      <td>-3.475203</td>\n      <td>...</td>\n      <td>0.013055</td>\n      <td>0.040612</td>\n      <td>-0.042918</td>\n      <td>0.033450</td>\n      <td>-0.043966</td>\n      <td>0.053377</td>\n      <td>-0.073200</td>\n      <td>0.002332</td>\n      <td>-0.021755</td>\n      <td>-0.003223</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>71.500586</td>\n      <td>69.600473</td>\n      <td>69.015425</td>\n      <td>19.518971</td>\n      <td>2.844739</td>\n      <td>0.706509</td>\n      <td>-0.610843</td>\n      <td>-1.008555</td>\n      <td>-0.438800</td>\n      <td>-1.080058</td>\n      <td>...</td>\n      <td>0.004456</td>\n      <td>0.042616</td>\n      <td>-0.047597</td>\n      <td>0.025825</td>\n      <td>-0.031552</td>\n      <td>0.048798</td>\n      <td>-0.093202</td>\n      <td>0.026254</td>\n      <td>-0.038423</td>\n      <td>-0.005951</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 73 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsel = X[embeded_rf_feature]\n",
    "X_fsel.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest - L1SO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['e0106', 'e0110', 'e0115', 'e0129', 'e0133', 'e0151', 'e0202',\n       'e0203', 'e0204', 'e0205', 'e0206', 'e0207', 'e0208', 'e0210',\n       'e0211', 'e0212', 'e0213', 'e0302', 'e0303', 'e0304', 'e0305',\n       'e0306', 'e0403', 'e0404', 'e0405', 'e0406', 'e0408', 'e0409',\n       'e0410', 'e0411', 'e0413', 'e0415', 'e0417', 'e0418', 'e0515',\n       'e0601', 'e0602', 'e0603', 'e0605', 'e0606', 'e0607', 'e0609',\n       'e0610', 'e0611', 'e0612', 'e0613', 'e0614', 'e0615', 'e0704',\n       'e0801', 'e0808', 'e0817', 'e0818', 'e1301', 'e1302', 'e1304'],\n      dtype=object)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvds = X_fsel.copy()\n",
    "cvds[\"patient_id\"] = patient_ids\n",
    "cvds[\"label\"] = y\n",
    "\n",
    "patients = np.unique(cvds[\"patient_id\"].values)\n",
    "patients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "classes = np.unique(label_encoder.inverse_transform(y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def eval_metrics(tp, tn, fp, fn):\n",
    "    acc = (tp + tn) /(tp + tn + fp + fn)\n",
    "    sens = tp / (tp+fn)\n",
    "    spec = tn / (tn+fp)\n",
    "    precision = tp / (tp+fp)\n",
    "    recall = tp / (tp+fn)\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "    return acc, sens, spec, precision, recall, f1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "1 of 56 - 3.0579988956451416 s\n",
      "Accuracy 0.8181818181818182 precision 0.8512396694214877 specificity 0.18181818181818182 recall 0.8181818181818182 f1 0.7363636363636364\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "2 of 56 - 3.0570003986358643 s\n",
      "Accuracy 0.801354401805869 precision 0.8408144754877731 specificity 0.1986455981941309 recall 0.801354401805869 f1 0.7129844928347958\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "3 of 56 - 2.9389994144439697 s\n",
      "Accuracy 0.9197183098591549 precision 0.9261634596310255 specificity 0.08028169014084507 recall 0.9197183098591549 f1 0.8812561354923377\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "4 of 56 - 2.888000249862671 s\n",
      "Accuracy 0.865546218487395 precision 0.8836240378504344 specificity 0.13445378151260504 recall 0.865546218487395 f1 0.803164509046862\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "5 of 56 - 2.8435099124908447 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "6 of 56 - 3.0630006790161133 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "7 of 56 - 2.891998052597046 s\n",
      "Accuracy 0.7113237639553429 precision 0.7946577332122534 specificity 0.2886762360446571 recall 0.7113237639553429 f1 0.5913334552173027\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "8 of 56 - 3.0379998683929443 s\n",
      "Accuracy 0.7402190923317684 precision 0.8077052123206988 specificity 0.2597809076682316 recall 0.7402190923317684 f1 0.6297187602031051\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "9 of 56 - 2.8859992027282715 s\n",
      "Accuracy 0.9834254143646409 precision 0.9752415690301224 specificity 0.01237878143955492 recall 0.9834254143646409 f1 0.9793163945274627\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "10 of 56 - 2.984999179840088 s\n",
      "Accuracy 0.6511936339522546 precision 0.7728595149476885 specificity 0.34880636604774534 recall 0.6511936339522546 f1 0.513632247824188\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "11 of 56 - 2.863001823425293 s\n",
      "Accuracy 0.7747093023255814 precision 0.7402804292491034 specificity 0.28124057343383174 recall 0.7747093023255814 f1 0.6982217394405993\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "12 of 56 - 2.906998872756958 s\n",
      "Accuracy 0.7549668874172185 precision 0.8150081136792245 specificity 0.24503311258278146 recall 0.7549668874172185 f1 0.649556416343871\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "13 of 56 - 3.056037187576294 s\n",
      "Accuracy 0.9056261343012704 precision 0.9145325608281922 specificity 0.09437386569872959 recall 0.9056261343012704 f1 0.8607760781263504\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "14 of 56 - 2.8289999961853027 s\n",
      "Accuracy 0.8090909090909091 precision 0.8455371900826446 specificity 0.19090909090909092 recall 0.8090909090909091 f1 0.723709456372773\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "15 of 56 - 2.7039973735809326 s\n",
      "Accuracy 0.8192389006342494 precision 0.8519134756781642 specificity 0.18076109936575052 recall 0.8192389006342494 f1 0.7378386379913344\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "16 of 56 - 2.7320404052734375 s\n",
      "Accuracy 0.9488304093567251 precision 0.9514487363633254 specificity 0.05116959064327485 recall 0.9488304093567251 f1 0.9239173828544857\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "17 of 56 - 2.752000570297241 s\n",
      "Accuracy 0.7130681818181818 precision 0.7953980501033058 specificity 0.2869318181818182 recall 0.7130681818181818 f1 0.5936322176993819\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "18 of 56 - 2.651282787322998 s\n",
      "Accuracy 0.9700690713737529 precision 0.9709649318621824 specificity 0.029930928626247123 recall 0.9700690713737529 f1 0.9553309748472331\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "19 of 56 - 2.70500111579895 s\n",
      "Accuracy 0.8586762075134168 precision 0.8786486218362076 specificity 0.1413237924865832 recall 0.8586762075134168 f1 0.7933870637275074\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "20 of 56 - 2.727999448776245 s\n",
      "Accuracy 0.9895038167938931 precision 0.9896139866557894 specificity 0.01049618320610687 recall 0.9895038167938931 f1 0.9842834129642851\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "21 of 56 - 2.545923948287964 s\n",
      "Accuracy 0.8134453781512605 precision 0.8482480050843867 specificity 0.1865546218487395 recall 0.8134453781512605 f1 0.7297637868863949\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "22 of 56 - 2.5509986877441406 s\n",
      "Accuracy 0.6733466933867736 precision 0.7800490761081281 specificity 0.32665330661322645 recall 0.6733466933867736 f1 0.5419029676118705\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "23 of 56 - 2.678999185562134 s\n",
      "Accuracy 0.33276157804459694 precision 0.7779686897781335 specificity 0.6672384219554031 recall 0.33276157804459694 f1 0.16616665673269448\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "24 of 56 - 2.554520845413208 s\n",
      "Accuracy 0.8447488584474886 precision 0.8688517754008466 specificity 0.1552511415525114 recall 0.8447488584474886 f1 0.7736561327365613\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "25 of 56 - 2.678011417388916 s\n",
      "Accuracy 0.6814285714285714 precision 0.7834995894909688 specificity 0.33619257394587787 recall 0.6814285714285714 f1 0.5580448009361609\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "26 of 56 - 2.649561643600464 s\n",
      "Accuracy 0.7314487632508834 precision 0.537258826104631 specificity 0.26614159819489974 recall 0.7314487632508834 f1 0.6194923198961563\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "27 of 56 - 2.65201735496521 s\n",
      "Accuracy 0.6084656084656085 precision 0.7934696942813404 specificity 0.14689501531606794 recall 0.6084656084656085 f1 0.6861872358087665\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "28 of 56 - 2.7290005683898926 s\n",
      "Accuracy 0.05459057071960298 precision 0.9539688292859732 specificity 0.9519283341043866 recall 0.05459057071960298 f1 0.016819679568300664\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "29 of 56 - 2.648000717163086 s\n",
      "Accuracy 0.14345991561181434 precision 0.8771208317755346 specificity 0.8565400843881856 recall 0.14345991561181434 f1 0.03599732199853644\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "30 of 56 - 2.608520269393921 s\n",
      "Accuracy 0.9217252396166135 precision 0.852411501597444 specificity 0.0765446565771582 recall 0.9217252396166135 f1 0.8857143615933543\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "31 of 56 - 2.6460518836975098 s\n",
      "Accuracy 0.8947368421052632 precision 0.8692383131742398 specificity 0.2867233711843185 recall 0.8947368421052632 f1 0.875623268698061\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "32 of 56 - 2.7640020847320557 s\n",
      "Accuracy 0.5067934782608695 precision 0.7564921775513916 specificity 0.5429447416344184 recall 0.5067934782608695 f1 0.3671417227847444\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "33 of 56 - 2.7599968910217285 s\n",
      "Accuracy 0.8494809688581315 precision 0.8721369475940183 specificity 0.15051903114186851 recall 0.8494809688581315 f1 0.7803464091849254\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "34 of 56 - 2.7745134830474854 s\n",
      "Accuracy 0.8950953678474114 precision 0.9175509466989134 specificity 0.4888939421623067 recall 0.8950953678474114 f1 0.9049591207095319\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "35 of 56 - 2.7195143699645996 s\n",
      "Accuracy 0.9473684210526315 precision 0.9501385041551246 specificity 0.05263157894736842 recall 0.9473684210526315 f1 0.9217638691322904\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "36 of 56 - 2.73252534866333 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "37 of 56 - 2.722999095916748 s\n",
      "Accuracy 0.8945868945868946 precision 0.905698817379729 specificity 0.10541310541310542 recall 0.8945868945868946 f1 0.84481288691815\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "38 of 56 - 2.738762617111206 s\n",
      "Accuracy 0.046 precision 0.956116 specificity 0.954 recall 0.046 f1 0.004045889101338432\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "39 of 56 - 2.826000213623047 s\n",
      "Accuracy 0.7595628415300546 precision 0.6589984033821313 specificity 0.2425607799113406 recall 0.7595628415300546 f1 0.6594755752209516\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "40 of 56 - 2.8930187225341797 s\n",
      "Accuracy 0.8131147540983606 precision 0.8480408492340769 specificity 0.18688524590163935 recall 0.8131147540983606 f1 0.7293036492455459\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "41 of 56 - 2.8829994201660156 s\n",
      "Accuracy 0.362095531587057 precision 0.7690176424082564 specificity 0.637904468412943 recall 0.362095531587057 f1 0.19251685502931762\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "42 of 56 - 2.8195207118988037 s\n",
      "Accuracy 0.940677966101695 precision 0.9441970698075267 specificity 0.059322033898305086 recall 0.940677966101695 f1 0.9119236177929095\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "43 of 56 - 2.8509998321533203 s\n",
      "Accuracy 0.8571428571428571 precision 0.8775510204081632 specificity 0.14285714285714285 recall 0.8571428571428571 f1 0.7912087912087911\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "44 of 56 - 2.8580403327941895 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "45 of 56 - 3.177999973297119 s\n",
      "Accuracy 0.6139954853273137 precision 0.7629949706750098 specificity 0.3860045146726862 recall 0.6139954853273137 f1 0.4671518098154667\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "46 of 56 - 3.0240471363067627 s\n",
      "Accuracy 0.7559523809523809 precision 0.8155116213151927 specificity 0.24404761904761904 recall 0.7559523809523809 f1 0.6508878127522195\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "47 of 56 - 3.1319987773895264 s\n",
      "Accuracy 0.44397759103641454 precision 0.5401992816053867 specificity 0.5749163846920936 recall 0.44397759103641454 f1 0.3561004619999011\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "48 of 56 - 3.011000156402588 s\n",
      "Accuracy 0.9846491228070176 precision 0.9830237928893029 specificity 0.20869899249231727 recall 0.9846491228070176 f1 0.9838047962282968\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "49 of 56 - 2.912508964538574 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "50 of 56 - 2.9090001583099365 s\n",
      "Accuracy 1.0 precision 1.0 specificity 0.0 recall 1.0 f1 1.0\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "51 of 56 - 3.0445101261138916 s\n",
      "Accuracy 0.12693935119887165 precision 0.746918137794836 specificity 0.8694584240073697 recall 0.12693935119887165 f1 0.04010492952078264\n",
      "#---------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marco\\pycharmprojects\\paper-st-sloping\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      "52 of 56 - 2.9910004138946533 s\n",
      "Accuracy 0.9959349593495935 precision 1.0 specificity 0.0 recall 0.9959349593495935 f1 0.9979633401221996\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "53 of 56 - 3.154507875442505 s\n",
      "Accuracy 0.7604327666151468 precision 0.802747167870327 specificity 0.389971520487976 recall 0.7604327666151468 f1 0.6914119740251182\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "54 of 56 - 2.8438799381256104 s\n",
      "Accuracy 0.8652094717668488 precision 0.8833779582682207 specificity 0.13479052823315119 recall 0.8652094717668488 f1 0.8026845685336976\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "55 of 56 - 2.937061071395874 s\n",
      "Accuracy 0.9053030303030303 precision 0.9142705463728191 specificity 0.0946969696969697 recall 0.9053030303030303 f1 0.8603078498704742\n",
      "#---------------------#\n",
      "#---------------------#\n",
      "56 of 56 - 2.903076171875 s\n",
      "Accuracy 0.7751004016064257 precision 0.8256802309640167 specificity 0.2248995983935743 recall 0.7751004016064257 f1 0.6768976357920369\n",
      "#---------------------#\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "tot = len(patients)\n",
    "for i, patient in enumerate(patients):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train and Test split\n",
    "    df1 = cvds.loc[cvds[\"patient_id\"] != patient]\n",
    "    df2 = cvds.loc[cvds[\"patient_id\"] == patient]\n",
    "\n",
    "    y_train = df1[\"label\"].values\n",
    "    x_train = df1.loc[:, ~df1.columns.isin(['patient_id', 'label'])]\n",
    "    y_test = df2[\"label\"].values\n",
    "    x_test = df2.loc[:, ~df2.columns.isin(['patient_id', 'label'])]\n",
    "\n",
    "    # Training\n",
    "    model = RandomForestClassifier(random_state=101, max_depth=6, n_jobs=THREADS_TO_USE).fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Decode\n",
    "    y_test_dec = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_dec = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # get metrics\n",
    "    report = classification_report(y_true=y_test_dec, y_pred=y_pred_dec, zero_division=1, output_dict=True)\n",
    "    specificity = specificity_score(y_true=y_test_dec, y_pred=y_pred_dec, average=\"weighted\")\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    # save result in result_df\n",
    "    result_df = result_df.append({\n",
    "        \"accuracy\": acc,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    # Log result\n",
    "    print(\"#---------------------#\")\n",
    "    print(i+1, \"of\", len(patients), \"-\", elapsed_seconds, \"s\")\n",
    "    print(\"Accuracy\", acc, \"precision\", precision, \"specificity\", specificity, \"recall\", recall, \"f1\", f1)\n",
    "    print(\"#---------------------#\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "   accuracy  specificity  precision    recall        f1\n0  0.818182     0.181818   0.851240  0.818182  0.736364\n1  0.801354     0.198646   0.840814  0.801354  0.712984\n2  0.919718     0.080282   0.926163  0.919718  0.881256\n3  0.865546     0.134454   0.883624  0.865546  0.803165\n4  1.000000     0.000000   1.000000  1.000000  1.000000\n5  1.000000     0.000000   1.000000  1.000000  1.000000\n6  0.711324     0.288676   0.794658  0.711324  0.591333\n7  0.740219     0.259781   0.807705  0.740219  0.629719\n8  0.983425     0.012379   0.975242  0.983425  0.979316\n9  0.651194     0.348806   0.772860  0.651194  0.513632",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>specificity</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.818182</td>\n      <td>0.181818</td>\n      <td>0.851240</td>\n      <td>0.818182</td>\n      <td>0.736364</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.801354</td>\n      <td>0.198646</td>\n      <td>0.840814</td>\n      <td>0.801354</td>\n      <td>0.712984</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.919718</td>\n      <td>0.080282</td>\n      <td>0.926163</td>\n      <td>0.919718</td>\n      <td>0.881256</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.865546</td>\n      <td>0.134454</td>\n      <td>0.883624</td>\n      <td>0.865546</td>\n      <td>0.803165</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.711324</td>\n      <td>0.288676</td>\n      <td>0.794658</td>\n      <td>0.711324</td>\n      <td>0.591333</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.740219</td>\n      <td>0.259781</td>\n      <td>0.807705</td>\n      <td>0.740219</td>\n      <td>0.629719</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.983425</td>\n      <td>0.012379</td>\n      <td>0.975242</td>\n      <td>0.983425</td>\n      <td>0.979316</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.651194</td>\n      <td>0.348806</td>\n      <td>0.772860</td>\n      <td>0.651194</td>\n      <td>0.513632</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Total ########\n",
      "Accuracy 0.7648984666932309\n",
      "Precision 0.8621142676195659\n",
      "Specificity 0.24937663117294886\n",
      "Recall 0.7648984666932309\n",
      "F1 0.7016536626666616\n"
     ]
    }
   ],
   "source": [
    "print(\"######## Total ########\")\n",
    "print(\"Accuracy\", result_df[\"accuracy\"].mean())\n",
    "print(\"Precision\", result_df[\"precision\"].mean())\n",
    "print(\"Specificity\",  result_df[\"specificity\"].mean())\n",
    "print(\"Recall\",  result_df[\"recall\"].mean())\n",
    "print(\"F1\",  result_df[\"f1\"].mean())\n",
    "\n",
    "result_df.to_csv('result/bin_16beats_l1so.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "congestive_heart_failure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}